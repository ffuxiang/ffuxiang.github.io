
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
        <meta name="author" content="ffx">
      
      
        <link rel="canonical" href="https://ffuxiang.gitee.io/transformer/DeDETR/">
      
      
        <link rel="prev" href="../DETR/">
      
      
        <link rel="next" href="../Maskformer/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.4.14">
    
    
      
        <title>Deformable DETR - ffx的个人博客</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.fad675c6.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#deformable_detr" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="ffx的个人博客" class="md-header__button md-logo" aria-label="ffx的个人博客" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            ffx的个人博客
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Deformable DETR
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://ffuxiang.gitee.io/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    Ffuxiang
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="ffx的个人博客" class="md-nav__button md-logo" aria-label="ffx的个人博客" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    ffx的个人博客
  </label>
  
    <div class="md-nav__source">
      <a href="https://ffuxiang.gitee.io/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    Ffuxiang
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    首页
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../resume/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    个人简历
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../fined_domain/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    细粒度/域适应笔记
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    目标检测
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            目标检测
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../detection/detection_sum/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    目标检测汇总
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_2" >
        
          
          <label class="md-nav__link" for="__nav_4_2" id="__nav_4_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    关键概念
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_2">
            <span class="md-nav__icon md-icon"></span>
            关键概念
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../detection/concept/anchor/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    锚点
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../detection/concept/regression/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    回归参数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../detection/concept/IoU/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    IoU
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_3" >
        
          
          <label class="md-nav__link" for="__nav_4_3" id="__nav_4_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    通用程序
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_3">
            <span class="md-nav__icon md-icon"></span>
            通用程序
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_3_1" >
        
          
          <label class="md-nav__link" for="__nav_4_3_1" id="__nav_4_3_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    数据增强
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_3_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_3_1">
            <span class="md-nav__icon md-icon"></span>
            数据增强
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../detection/program/data_augment/affine/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    仿射变换
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../detection/program/data_augment/mosaic/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mosaic增强
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../detection/program/anchor_gen/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    锚点生成
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../detection/program/anchor_match/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    锚点匹配
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../detection/program/regression/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    参数编码解码
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../detection/program/IoU/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    计算IoU
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../detection/program/train/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    训练程序
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_4" >
        
          
          <label class="md-nav__link" for="__nav_4_4" id="__nav_4_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    检测网络
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_4">
            <span class="md-nav__icon md-icon"></span>
            检测网络
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_4_1" >
        
          
          <label class="md-nav__link" for="__nav_4_4_1" id="__nav_4_4_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Faster R-CNN
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_4_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_4_1">
            <span class="md-nav__icon md-icon"></span>
            Faster R-CNN
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../detection/network/Faster_RCNN/structure/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    网络结构
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../detection/network/Faster_RCNN/RPN/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    RPN模块
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../detection/network/Faster_RCNN/ROI_Head/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ROI Head模块
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../detection/network/RetinaNet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    RetinaNet
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_4_3" >
        
          
          <label class="md-nav__link" for="__nav_4_4_3" id="__nav_4_4_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    YOLO系列
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_4_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_4_3">
            <span class="md-nav__icon md-icon"></span>
            YOLO系列
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../detection/network/YOLO/YOLOv3_SPP/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    YOLOv3-SPP
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../detection/network/YOLO/YOLOv4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    YOLOv4
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../DETR/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DETR
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Deformable DETR
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Deformable DETR
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      综述
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      主要思想
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      方法
    </span>
  </a>
  
    <nav class="md-nav" aria-label="方法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      可变注意力模块
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      多尺度可变注意力模块
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tf" class="md-nav__link">
    <span class="md-ellipsis">
      可变形的TF编码器
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    <span class="md-ellipsis">
      源码实现
    </span>
  </a>
  
    <nav class="md-nav" aria-label="源码实现">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    <span class="md-ellipsis">
      流程
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformer" class="md-nav__link">
    <span class="md-ellipsis">
      Transformer模块
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Transformer模块">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    <span class="md-ellipsis">
      编码器
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    <span class="md-ellipsis">
      可变注意力模块
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_10" class="md-nav__link">
    <span class="md-ellipsis">
      解码器
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_5" >
        
          
          <label class="md-nav__link" for="__nav_4_5" id="__nav_4_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    常用模块
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_5">
            <span class="md-nav__icon md-icon"></span>
            常用模块
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../detection/module/FPN/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    FPN
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../detection/module/FL/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    FL
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../detection/module/NL/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NL
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    自动驾驶
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            自动驾驶
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_1" >
        
          
          <label class="md-nav__link" for="__nav_5_1" id="__nav_5_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    论文笔记
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_1">
            <span class="md-nav__icon md-icon"></span>
            论文笔记
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../auto/paper/HADAR/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    HADAR
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../auto/paper/BEVFormer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BEVFormer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Deformable DETR
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Deformable DETR
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      综述
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      主要思想
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      方法
    </span>
  </a>
  
    <nav class="md-nav" aria-label="方法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      可变注意力模块
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      多尺度可变注意力模块
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tf" class="md-nav__link">
    <span class="md-ellipsis">
      可变形的TF编码器
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    <span class="md-ellipsis">
      源码实现
    </span>
  </a>
  
    <nav class="md-nav" aria-label="源码实现">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    <span class="md-ellipsis">
      流程
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformer" class="md-nav__link">
    <span class="md-ellipsis">
      Transformer模块
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Transformer模块">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    <span class="md-ellipsis">
      编码器
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    <span class="md-ellipsis">
      可变注意力模块
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_10" class="md-nav__link">
    <span class="md-ellipsis">
      解码器
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../auto/PCV/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    点云可视化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../auto/PCC/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    点云与图像映射
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_4" >
        
          
          <label class="md-nav__link" for="__nav_5_4" id="__nav_5_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    视觉SLAM
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_4">
            <span class="md-nav__icon md-icon"></span>
            视觉SLAM
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../auto/SLAM/SLAM_ch3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    三维空间刚体运动
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" checked>
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    transformer系列
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            transformer系列
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../transformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ViT/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ViT
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Swin/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Swin Transformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../DETR/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DETR
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Deformable DETR
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Deformable DETR
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      综述
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      主要思想
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      方法
    </span>
  </a>
  
    <nav class="md-nav" aria-label="方法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      可变注意力模块
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      多尺度可变注意力模块
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tf" class="md-nav__link">
    <span class="md-ellipsis">
      可变形的TF编码器
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    <span class="md-ellipsis">
      源码实现
    </span>
  </a>
  
    <nav class="md-nav" aria-label="源码实现">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    <span class="md-ellipsis">
      流程
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformer" class="md-nav__link">
    <span class="md-ellipsis">
      Transformer模块
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Transformer模块">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    <span class="md-ellipsis">
      编码器
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    <span class="md-ellipsis">
      可变注意力模块
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_10" class="md-nav__link">
    <span class="md-ellipsis">
      解码器
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Maskformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Maskformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ViT_Adapter/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ViT Adapter
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../DINO/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DINO
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../CLIP/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CLIP及相关改进工作
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    强化学习
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            强化学习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../RL/DQN/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DQN算法
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../RL/AC/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AC算法
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../RL/PPO/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PPO算法
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../RL/DDPG/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DDPG算法
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../RL/landing_guide/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    《RL落地指南》笔记
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8" >
        
          
          <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    图像增强
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            图像增强
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8_1" >
        
          
          <label class="md-nav__link" for="__nav_8_1" id="__nav_8_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    HDR
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_8_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8_1">
            <span class="md-nav__icon md-icon"></span>
            HDR
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../img_enhance/HDR/HDR-Transformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    HDT-Transformer
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8_2" >
        
          
          <label class="md-nav__link" for="__nav_8_2" id="__nav_8_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    扩散模型
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_8_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8_2">
            <span class="md-nav__icon md-icon"></span>
            扩散模型
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../img_enhance/DDPM/DDPM/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DDPM
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../img_enhance/DDPM/GDP/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    GDP
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8_3" >
        
          
          <label class="md-nav__link" for="__nav_8_3" id="__nav_8_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    数据集
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_8_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8_3">
            <span class="md-nav__icon md-icon"></span>
            数据集
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../img_enhance/dataset/deraining/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    去雨
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../img_enhance/dataset/HDR_dataset/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    HDR
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8_4" >
        
          
          <label class="md-nav__link" for="__nav_8_4" id="__nav_8_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    评测指标
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_8_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8_4">
            <span class="md-nav__icon md-icon"></span>
            评测指标
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../img_enhance/matrix/PSNR/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PSNR
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../img_enhance/matrix/SSIM/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SSIM
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_9" >
        
          
          <label class="md-nav__link" for="__nav_9" id="__nav_9_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    其他论文
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9">
            <span class="md-nav__icon md-icon"></span>
            其他论文
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../other_paper/PartialConv/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    局部卷积
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../other_paper/attention/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    注意力机制
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../other_paper/Cycle_GAN/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Cycle GAN
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../other_paper/saliency_sampling/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    显著性采样
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../other_paper/GradCAM/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Grad-CAM
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_10" >
        
          
          <label class="md-nav__link" for="__nav_10" id="__nav_10_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_10">
            <span class="md-nav__icon md-icon"></span>
            PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/sum_pytorch/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch学习笔记汇总
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_10_2" >
        
          
          <label class="md-nav__link" for="__nav_10_2" id="__nav_10_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    nn方法
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_10_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_10_2">
            <span class="md-nav__icon md-icon"></span>
            nn方法
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_10_2_1" >
        
          
          <label class="md-nav__link" for="__nav_10_2_1" id="__nav_10_2_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    网络结构
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_10_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_10_2_1">
            <span class="md-nav__icon md-icon"></span>
            网络结构
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/nn/layers/nn.Linear/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nn.Linear
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/nn/layers/nn.Conv2d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nn.Conv2d
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/nn/layers/nn.BatchNorm2d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nn.BatchNorm2d
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/nn/layers/nn.AvgPool2d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nn.AvgPool2d
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/nn/layers/nn.AdaptiveAvgPool2d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nn.AdaptiveAvgPool2d
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/nn/layers/nn.Dropout/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nn.Dropout
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/nn/layers/nn.MultiheadAttention/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nn.MultiheadAttention
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/nn/layers/nn.Embedding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nn.Embedding
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_10_2_2" >
        
          
          <label class="md-nav__link" for="__nav_10_2_2" id="__nav_10_2_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    激活函数
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_10_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_10_2_2">
            <span class="md-nav__icon md-icon"></span>
            激活函数
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/nn/activations/nn.ReLU/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nn.ReLU
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/nn/activations/nn.LeakyReLU/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nn.LeakyReLU
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/nn/activations/nn.PReLU/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nn.PReLU
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/nn/activations/nn.Sigmoid/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nn.Sigmoid
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/nn/activations/nn.Tanh/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nn.Tanh
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/nn/activations/nn.GELU/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nn.GeLU
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_10_2_3" >
        
          
          <label class="md-nav__link" for="__nav_10_2_3" id="__nav_10_2_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    损失函数
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_10_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_10_2_3">
            <span class="md-nav__icon md-icon"></span>
            损失函数
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/nn/loss_functions/nn.L1Loss/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nn.L1Loss
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/nn/loss_functions/nn.MSELoss/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nn.MSELoss
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/nn/loss_functions/nn.CrossEntropyLoss/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nn.CrossEntropyLoss
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/nn/loss_functions/nn.KLDivLoss/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nn.KLDivLoss
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/nn/loss_functions/nn.MarginRankingLoss/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nn.MarginRankingLoss
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/nn/loss_functions/nn.SmoothL1Loss/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nn.SmoothL1Loss
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/nn/loss_functions/nn.TripletMarginLoss/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nn.TripletMarginLoss
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_10_2_4" >
        
          
          <label class="md-nav__link" for="__nav_10_2_4" id="__nav_10_2_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    nn.functional方法
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_10_2_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_10_2_4">
            <span class="md-nav__icon md-icon"></span>
            nn.functional方法
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/nn/F/F.interpolate/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    F.interpolate
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/nn/F/F.normalize/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    F.normalize
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_10_3" >
        
          
          <label class="md-nav__link" for="__nav_10_3" id="__nav_10_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    utils.data方法
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_10_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_10_3">
            <span class="md-nav__icon md-icon"></span>
            utils.data方法
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/data/data.RandomSampler/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    data.RandomSampler
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/data/data.WeightedRandomSampler/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    data.WeightedRandomSampler
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/data/data.BatchSampler/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    data.BatchSampler
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_10_4" >
        
          
          <label class="md-nav__link" for="__nav_10_4" id="__nav_10_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    optim方法
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_10_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_10_4">
            <span class="md-nav__icon md-icon"></span>
            optim方法
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/optim/LambdaLR/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LambdaLR
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_10_5" >
        
          
          <label class="md-nav__link" for="__nav_10_5" id="__nav_10_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    torch方法
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_10_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_10_5">
            <span class="md-nav__icon md-icon"></span>
            torch方法
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/torch/torch.cat_torch.stack/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.cat与torch.stack
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/torch/torch.chunk/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.chunk
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/torch/torch.clamp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.clamp
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/torch/torch.div/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.div
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/torch/torch.ge_gt_le_lt_ne_eq/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.ge_gt_le_lt_ne_eq
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/torch/torch.from_numpy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.from_numpy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/torch/torch.gather/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.gather
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/torch/torch.index_select/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.index_select
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/torch/torch.max/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.max
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/torch/torch.mul/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.mul
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/torch/torch.nonzero/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.nonzero
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/torch/torch.repeat_interleave_tensor.repeat/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.repeat_interleave与tensor.repeat
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/torch/torch.squeeze_torch.unsqueeze/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.squeeze与torch.unsqueeze
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/torch/torch.transpose_tensor.permute/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.transpose与tensor.permute
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/torch/torch.where/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.where
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_10_6" >
        
          
          <label class="md-nav__link" for="__nav_10_6" id="__nav_10_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    其他方法
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_10_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_10_6">
            <span class="md-nav__icon md-icon"></span>
            其他方法
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/other_method/hook/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    hook模块
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/other_method/train_eval/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    train与eval
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/other_method/cuda/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    cuda方法
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../PyTorch/question/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    常见问题
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_11" >
        
          
          <label class="md-nav__link" for="__nav_11" id="__nav_11_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    常用Python库
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_11">
            <span class="md-nav__icon md-icon"></span>
            常用Python库
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../python/tqdm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tqdm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../python/rearrange/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rearrange
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_12" >
        
          
          <label class="md-nav__link" for="__nav_12" id="__nav_12_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    LaTeX
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_12_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_12">
            <span class="md-nav__icon md-icon"></span>
            LaTeX
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LaTeX/symbol/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    特殊符号
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_13" >
        
          
          <label class="md-nav__link" for="__nav_13" id="__nav_13_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Linux
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_13_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_13">
            <span class="md-nav__icon md-icon"></span>
            Linux
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_13_1" >
        
          
          <label class="md-nav__link" for="__nav_13_1" id="__nav_13_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Linux常用指令
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_13_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_13_1">
            <span class="md-nav__icon md-icon"></span>
            Linux常用指令
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Linux/instruct/conda_pip/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    conda pip
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Linux/instruct/bypy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bypy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Linux/instruct/screen/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    screen命令
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Linux/instruct/apt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    apt命令
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Linux/instruct/PID/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    查看进程信息
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_13_2" >
        
          
          <label class="md-nav__link" for="__nav_13_2" id="__nav_13_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    报错记录
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_13_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_13_2">
            <span class="md-nav__icon md-icon"></span>
            报错记录
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Linux/error/sum_error/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    汇总
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_13_2_2" >
        
          
          <label class="md-nav__link" for="__nav_13_2_2" id="__nav_13_2_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    系统相关
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_13_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_13_2_2">
            <span class="md-nav__icon md-icon"></span>
            系统相关
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Linux/error/linux1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Failed CC version
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_13_2_3" >
        
          
          <label class="md-nav__link" for="__nav_13_2_3" id="__nav_13_2_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    NVIDIA
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_13_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_13_2_3">
            <span class="md-nav__icon md-icon"></span>
            NVIDIA
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Linux/error/nvidia/nvidia1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NVIDIA-SMI has failed
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Linux/error/nvidia/nvidia2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NVIDIA kernel module already loaded
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_14" >
        
          
          <label class="md-nav__link" for="__nav_14" id="__nav_14_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    其他
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_14_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_14">
            <span class="md-nav__icon md-icon"></span>
            其他
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../other/email/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    邮件模板
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../other/website/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    网站汇总
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../other/program/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    常用程序
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      综述
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      主要思想
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      方法
    </span>
  </a>
  
    <nav class="md-nav" aria-label="方法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      可变注意力模块
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      多尺度可变注意力模块
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tf" class="md-nav__link">
    <span class="md-ellipsis">
      可变形的TF编码器
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    <span class="md-ellipsis">
      源码实现
    </span>
  </a>
  
    <nav class="md-nav" aria-label="源码实现">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    <span class="md-ellipsis">
      流程
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformer" class="md-nav__link">
    <span class="md-ellipsis">
      Transformer模块
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Transformer模块">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    <span class="md-ellipsis">
      编码器
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    <span class="md-ellipsis">
      可变注意力模块
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_10" class="md-nav__link">
    <span class="md-ellipsis">
      解码器
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="deformable_detr">Deformable DETR——笔记<a class="headerlink" href="#deformable_detr" title="Permanent link">&para;</a></h1>
<h2 id="_1">综述<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h2>
<blockquote>
<p>会议时间：ICLR 2021</p>
<p>论文地址：<a href="https://openreview.net/pdf?id=gZ9hCDWe6ke">https://openreview.net/pdf?id=gZ9hCDWe6ke</a></p>
<p>源码地址：<a href="https://github.com/fundamentalvision/Deformable-DETR">https://github.com/fundamentalvision/Deformable-DETR</a></p>
</blockquote>
<h2 id="_2">主要思想<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h2>
<p>&emsp;&emsp;DETR是第一个利用Transformer实现的端到端的目标检测算法，大大简化了目标检测算法的实现过程，但是他仍存在两个问题：①与现有目标检测算法相比，它需要非常长的训练时间来收敛，<strong>收敛速度特别慢</strong>（在COCO数据集上，需要500个epoch才能收敛）；②<strong>DETR难以检测小目标</strong>。如今的目标检测算法通常使用<strong>多尺度特征来检测不同尺度下的物体</strong>，在高分辨率图像中检测小物体，但是DETR中的多头注意力运算模块对特征尺寸非常敏感，对于一张高分辨率的特征图会产生难以估计的计算量（复杂度呈平方增长）。</p>
<p>&emsp;&emsp;多头注意力模块初始化后，在计算特征映射时，每个像素点都会与特征图中所有像素点产生一次注意力运算，并且所有的注意力会施加几乎一样的注意力权重，而注意力运算的目的肯定是想要让注意力权重集中在某几个区域，这也是注意力模块的优化趋势，对于每个像素点来说，<strong>从大量的区域中挑选出几个有意义的区域是非常难的</strong>，这也是为什么DETR训练周期很长的一个重要原因，而且训练的时长也会和特征图尺寸密切相关；同时，TF编码器中的注意力运算与像素数值呈平方变化关系，因此高分辨率图像在计算注意力时会产生非常高的计算消耗。</p>
<p>&emsp;&emsp;注意<strong>问题的逻辑关系</strong>：稠密的注意力运算要求大量的注意力权重，优化这些权重需要很长的训练时间，因此导致DETR收敛慢（问题1），这一问题同样是Transformer模块处理图像数据时的通病，不同于自然语言，<strong>图像数据本身具有信息稀疏的特点</strong>，特征数据尺寸非常大，利用稠密的注意力会产生很多冗余的计算量（<strong>注意力是解决信息稀疏的一个有效策略，会提升算法性能上限，但是稠密的注意力机制会大大增加计算量，会抬高算法成本，注意底层逻辑关系，引入一个模块在解决某个问题的同时也会引入新的问题</strong>）；同时传统的Transformer计算量与特征尺寸密切相关，分辨率高的特征会大大增加注意力的计算量，因此直接导致算法不能利用浅层特征做检测，即不能利用多尺度特征做预测，从而导致算法在检测小目标物体上性能不好。</p>
<p>&emsp;&emsp;对于这一问题，一种有效的解决方法就是将稠密的注意力运算转为<strong>稀疏的注意力运算</strong>，在图像领域中，可变形卷积是一种处理稀疏空间位置强大而有效的机制，其中的稀疏采样思想可以应用到Transformer注意力机制中，进一步改进注意力的计算策略。</p>
<p>&emsp;&emsp;本文中，作者提出了可变形的DETR算法（Deformable DETR），<strong>缓解了原始DETR中收敛速度慢以及计算复杂度高的问题</strong>。作者提出了可变形注意力模块，它<strong>同时结合了可变形卷积中稀疏空间采样的优点和Transformer中位置关系建模的能力</strong>，让每个元素关注一小组采样位置，作为特征图所有像素中突出的k数据元素的预滤波器。该模块可以自然地扩展到聚合多尺度特征，而无需FPN的帮助，在Deformable DETR中，作者使用（多尺度）可变形注意力模块来代替传统的Transformer注意力模块，具体如下图所示：</p>
<p><center></p>
<p><img alt="DeDETR_3" src="../img/DeDETR_3.jpg" /></p>
<p></center></p>
<p>注：利用可变形注意力运算代替传统的注意力运算，在提升算法计算速度的同时，肯定也会降低模型检测精度的上限（会在一定程度上削弱模型的特征表示能力），注意这种平衡取舍的关系。换句话说，如果有大量的训练数据，并且对检测速度没有要求，则利用传统的Transformer做注意力运算效果更好。</p>
<h2 id="_3">方法<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h2>
<p>DETR网络结构：</p>
<p><center></p>
<p><img alt="DeDETR_2" src="../img/DeDETR_2.jpg" /></p>
<p></center></p>
<h3 id="_4">可变注意力模块<a class="headerlink" href="#_4" title="Permanent link">&para;</a></h3>
<p>&emsp;&emsp;将Transformer应用于图像特征提取的过程中时，存在一个核心的问题：Transformer模块会考虑所有空间位置的权重，为了解决这一问题，作者提出了可变注意力模块。受到可变卷积模块的启发，可变注意力模块<strong>只关注参考点周围的一小部分关键采样点</strong>，不考虑特征图的尺寸大小，如下图所示，通过为每个查询query分配少量、固定数量的键keys（这里的键也就是参考点，即后面的采样点），q中每个元素和固定数量的键k做相似度计算，大大减少了计算量（原来的k是整个特征图，现在只选取其中少量的特征数据），可以减轻收敛慢和特征空间分辨率大所带来的问题。</p>
<p>注：注意力计算的本质，就是对于q中每个元素，计算与k的相似度，进一步对 k对应的v 做加权操作，求出q对应的&rsquo;v&rsquo;。</p>
<p><center></p>
<p><img alt="DeDETR_1" src="../img/DeDETR_1.jpg" /></p>
<p></center></p>
<p>给定一个输入特征图<span class="arithmatex"><span class="MathJax_Preview">x\in R^{C\times H\times W}</span><script type="math/tex">x\in R^{C\times H\times W}</script></span>，假设<span class="arithmatex"><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span>表示一个带有内容特征<span class="arithmatex"><span class="MathJax_Preview">z_q</span><script type="math/tex">z_q</script></span>和二维参考点<span class="arithmatex"><span class="MathJax_Preview">p_q</span><script type="math/tex">p_q</script></span>的查询向量，可变注意力特征的计算公式可以表示为：
<div><span class="MathJax_Preview">$$
DeAtt(z_q,p_q,x)=\sum^M_{m=1}W_m[\sum^K_{k=1}A_{mqk}\cdot W_m'x(p_q+\Delta p_{mqk})]
$$</span><script type="math/tex; mode=display">
DeAtt(z_q,p_q,x)=\sum^M_{m=1}W_m[\sum^K_{k=1}A_{mqk}\cdot W_m'x(p_q+\Delta p_{mqk})]
</script>
</div>
其中，<span class="arithmatex"><span class="MathJax_Preview">m</span><script type="math/tex">m</script></span>表示注意力的头数，<span class="arithmatex"><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>表示所采样的键的序号，<span class="arithmatex"><span class="MathJax_Preview">K</span><script type="math/tex">K</script></span>表示总采样的键数，采样数要远小于图像特征尺寸<span class="arithmatex"><span class="MathJax_Preview">(K\ll HW)</span><script type="math/tex">(K\ll HW)</script></span>，<span class="arithmatex"><span class="MathJax_Preview">\Delta p_{mqk}</span><script type="math/tex">\Delta p_{mqk}</script></span>和<span class="arithmatex"><span class="MathJax_Preview">A_{mqk}</span><script type="math/tex">A_{mqk}</script></span>分别表示第<span class="arithmatex"><span class="MathJax_Preview">m</span><script type="math/tex">m</script></span>个注意力头、第<span class="arithmatex"><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>个采样点的采样偏移量和注意力权重。注意力权重<span class="arithmatex"><span class="MathJax_Preview">A_{mqk}</span><script type="math/tex">A_{mqk}</script></span>的范围在<span class="arithmatex"><span class="MathJax_Preview">[0,1]</span><script type="math/tex">[0,1]</script></span>内，通过<span class="arithmatex"><span class="MathJax_Preview">\sum^K_{k=1}A_{mqk}=1</span><script type="math/tex">\sum^K_{k=1}A_{mqk}=1</script></span>引入的约束进行归一化操作（softmax运算），<span class="arithmatex"><span class="MathJax_Preview">\Delta p_{mqk}\in R^2</span><script type="math/tex">\Delta p_{mqk}\in R^2</script></span>为无约束范围的二维实数。由于<span class="arithmatex"><span class="MathJax_Preview">p_q+\Delta p_{mqk}</span><script type="math/tex">p_q+\Delta p_{mqk}</script></span>不是整数，无法直接用于平移操作，对此作者采用<strong>双线性插值操作（bilinear interpolation）来实现采样过程</strong>，即<span class="arithmatex"><span class="MathJax_Preview">x(p_q+\Delta p_{mqk})</span><script type="math/tex">x(p_q+\Delta p_{mqk})</script></span>，<span class="arithmatex"><span class="MathJax_Preview">\Delta p_{mqk}</span><script type="math/tex">\Delta p_{mqk}</script></span>和<span class="arithmatex"><span class="MathJax_Preview">A_{mqk}</span><script type="math/tex">A_{mqk}</script></span>通过查询特征<span class="arithmatex"><span class="MathJax_Preview">z_q</span><script type="math/tex">z_q</script></span>上的线性投影得到。在实际应用中，将查询特征<span class="arithmatex"><span class="MathJax_Preview">z_q</span><script type="math/tex">z_q</script></span>传入线性回归层，得到通道数为<span class="arithmatex"><span class="MathJax_Preview">2MK</span><script type="math/tex">2MK</script></span>的采样偏移量编码<span class="arithmatex"><span class="MathJax_Preview">\Delta p_{mqk}</span><script type="math/tex">\Delta p_{mqk}</script></span>和通道数为<span class="arithmatex"><span class="MathJax_Preview">MK</span><script type="math/tex">MK</script></span>的注意力权重<span class="arithmatex"><span class="MathJax_Preview">A_{mqk}</span><script type="math/tex">A_{mqk}</script></span>（权重会经过一次softmax运算）。</p>
<p>&emsp;&emsp;可变形注意力模块用于处理关键元素的卷积特征，设<span class="arithmatex"><span class="MathJax_Preview">N_q</span><script type="math/tex">N_q</script></span>为查询元素的数量，当<span class="arithmatex"><span class="MathJax_Preview">MK</span><script type="math/tex">MK</script></span>较小时，可变卷积模块的复杂度为<span class="arithmatex"><span class="MathJax_Preview">O(2N_qC^2+\min(HWC^2,N_qKC^2))</span><script type="math/tex">O(2N_qC^2+\min(HWC^2,N_qKC^2))</script></span>，将其应用于DETR的<strong>编码器</strong>时，有<span class="arithmatex"><span class="MathJax_Preview">N_q=HW</span><script type="math/tex">N_q=HW</script></span>，复杂度变为<span class="arithmatex"><span class="MathJax_Preview">O(HWC^2)</span><script type="math/tex">O(HWC^2)</script></span>，<strong>复杂度与空间大小呈线性关系</strong>，当其应用于DETR的<strong>解码器</strong>时，有<span class="arithmatex"><span class="MathJax_Preview">N_q=N</span><script type="math/tex">N_q=N</script></span>（<span class="arithmatex"><span class="MathJax_Preview">N</span><script type="math/tex">N</script></span>为物体查询向量的数量(object queries)），<strong>复杂度变为<span class="arithmatex"><span class="MathJax_Preview">O(NKC^2)</span><script type="math/tex">O(NKC^2)</script></span>，与空间尺寸<span class="arithmatex"><span class="MathJax_Preview">HW</span><script type="math/tex">HW</script></span>无关</strong>。</p>
<p>注：<strong>对于特征图上的每个像素点</strong>，传统的多头注意力机制，会对特征图上所有的点都求一次权重，即特征图上所有的点都会对该点产生影响，计算量比较大，而且比较冗余，在可变形注意力模块中，只会选取图里的<span class="arithmatex"><span class="MathJax_Preview">K</span><script type="math/tex">K</script></span>个点求一次权重，即<strong>只选取对当前点影响比较大的<span class="arithmatex"><span class="MathJax_Preview">K</span><script type="math/tex">K</script></span>个点，来对当前点产生影响</strong>，大幅度减小了运算量。</p>
<h3 id="_5">多尺度可变注意力模块<a class="headerlink" href="#_5" title="Permanent link">&para;</a></h3>
<p>&emsp;&emsp;由于多尺度特征可以灵活表示大物体和小物体，当前大部分目标检测算法都用到了多尺度特征，本算法的可变形注意力模块可以自然地扩展到多尺度特征图上。</p>
<p>&emsp;&emsp;假设<span class="arithmatex"><span class="MathJax_Preview">\{x^l\}^L_{l=1}</span><script type="math/tex">\{x^l\}^L_{l=1}</script></span>为多尺度特征图，其中<span class="arithmatex"><span class="MathJax_Preview">x^l\in R^{C\times H_l\times W_l}</span><script type="math/tex">x^l\in R^{C\times H_l\times W_l}</script></span>，假设<span class="arithmatex"><span class="MathJax_Preview">\hat p\in[0,1]^2</span><script type="math/tex">\hat p\in[0,1]^2</script></span>为每个查询向量<span class="arithmatex"><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span>参考点的归一化坐标，多尺度可变注意力模块可以表示为：
<div><span class="MathJax_Preview">$$
MSDeAtt(z_q,\hat p_q,\{x^l\}^L_{l=1})=\sum^M_{m=1}W_m[\sum^L_{l=1}\sum^K_{k=1}A_{mlqk}\cdot W_m'x^l(\phi_l(\hat p_q)+\Delta p_{mlqk})]
$$</span><script type="math/tex; mode=display">
MSDeAtt(z_q,\hat p_q,\{x^l\}^L_{l=1})=\sum^M_{m=1}W_m[\sum^L_{l=1}\sum^K_{k=1}A_{mlqk}\cdot W_m'x^l(\phi_l(\hat p_q)+\Delta p_{mlqk})]
</script>
</div>
其中<span class="arithmatex"><span class="MathJax_Preview">m</span><script type="math/tex">m</script></span>表示注意力头的索引序号，<span class="arithmatex"><span class="MathJax_Preview">l</span><script type="math/tex">l</script></span>表示输入特征的层级索引，<span class="arithmatex"><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>表示采样点的索引，<span class="arithmatex"><span class="MathJax_Preview">\Delta p_{mlqk}</span><script type="math/tex">\Delta p_{mlqk}</script></span>和<span class="arithmatex"><span class="MathJax_Preview">A_{mlqk}</span><script type="math/tex">A_{mlqk}</script></span>分别表示第<span class="arithmatex"><span class="MathJax_Preview">l</span><script type="math/tex">l</script></span>层特征、第<span class="arithmatex"><span class="MathJax_Preview">m</span><script type="math/tex">m</script></span>个注意力头的，采样点的偏移量和第<span class="arithmatex"><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>个采样点的注意力权重，注意力权重<span class="arithmatex"><span class="MathJax_Preview">A_{mlqk}</span><script type="math/tex">A_{mlqk}</script></span>会由公式<span class="arithmatex"><span class="MathJax_Preview">\sum^L_{l=1}\sum^K_{k=1}A_{mlqk}=1</span><script type="math/tex">\sum^L_{l=1}\sum^K_{k=1}A_{mlqk}=1</script></span>进行归一化。为了清晰地表述图像的尺度，作者使用<strong>归一化后的坐标<span class="arithmatex"><span class="MathJax_Preview">\hat p_q\in[0,1]^2</span><script type="math/tex">\hat p_q\in[0,1]^2</script></span>来表示每个参考采样点</strong>，其中<span class="arithmatex"><span class="MathJax_Preview">(0,0)</span><script type="math/tex">(0,0)</script></span>和<span class="arithmatex"><span class="MathJax_Preview">(1,1)</span><script type="math/tex">(1,1)</script></span>分别表示图像的左上角和右下角。式中的函数<span class="arithmatex"><span class="MathJax_Preview">\phi_l(\hat p_q)</span><script type="math/tex">\phi_l(\hat p_q)</script></span>将归一化坐标<span class="arithmatex"><span class="MathJax_Preview">\hat p_q</span><script type="math/tex">\hat p_q</script></span>重新缩放为第<span class="arithmatex"><span class="MathJax_Preview">l</span><script type="math/tex">l</script></span>层的输入特征图，多尺度可变形注意力模块与之前的单尺度版本非常相似，区别在于它从多个尺度特征图中采样<span class="arithmatex"><span class="MathJax_Preview">KL</span><script type="math/tex">KL</script></span>个点，而不是从单尺度特征图中采样<span class="arithmatex"><span class="MathJax_Preview">K</span><script type="math/tex">K</script></span>个点。简单来说，就是将所有层级的序列特征沿层级方向合并（合并之前会在每个层级特征上分别添加一个层级编码特征），之后在不同层级上预设参考点（层级越浅，则参考点步幅越小），进一步传入可变形注意力模块。</p>
<p>&emsp;&emsp;当<span class="arithmatex"><span class="MathJax_Preview">K=L=1</span><script type="math/tex">K=L=1</script></span>，并且<span class="arithmatex"><span class="MathJax_Preview">W_m'\in R^{C_v\times C}</span><script type="math/tex">W_m'\in R^{C_v\times C}</script></span>固定为单位矩阵时，所提出的注意力模块将退化为可变形卷积，可变形卷积是为单尺度输入设计的，每个注意力头只集中在一个采样点上。然而，我们的多尺度可变形注意力会查看来自多尺度输入的多个采样点，所提出的（多尺度）可变形注意力模块也可以视为Transformer注意力机制的有效变体，其中可变形采样定位引入了预滤波器机制（pre-filtering），也就是只在采样点上做滤波操作（即加权求和操作），当采样点遍历所有可能的位置时，所提出的可变形注意力等同于Transformer注意力。</p>
<blockquote>
<p>这里可变形卷积是为单尺度输入设计的是啥意思？再看看可变形卷积那块；</p>
</blockquote>
<h3 id="tf">可变形的TF编码器<a class="headerlink" href="#tf" title="Permanent link">&para;</a></h3>
<p>&emsp;&emsp;作者利用多尺度可变形注意力模块替换了DETR中的TF编码器，编码器的输入和输入具有相同分辨率的多尺度特征，在编码器中，我们从ResNet中C3到C5阶段输出的特征图提取多尺度特征图<span class="arithmatex"><span class="MathJax_Preview">\{x^l\}^{L-1}_{l=1}(L=4)</span><script type="math/tex">\{x^l\}^{L-1}_{l=1}(L=4)</script></span>（其中ResNet输出的特征会首先经过一层<span class="arithmatex"><span class="MathJax_Preview">1\times1</span><script type="math/tex">1\times1</script></span>的卷积层，用于统一特征图的通道数，统一成256），其中<span class="arithmatex"><span class="MathJax_Preview">C_l</span><script type="math/tex">C_l</script></span>的分辨率是输入图像的<span class="arithmatex"><span class="MathJax_Preview">\frac{1}{2^l}</span><script type="math/tex">\frac{1}{2^l}</script></span>倍，注意，分辨率最小的特征图<span class="arithmatex"><span class="MathJax_Preview">x^L</span><script type="math/tex">x^L</script></span>是由C5的输出经过一层卷积核为<span class="arithmatex"><span class="MathJax_Preview">3\times3</span><script type="math/tex">3\times3</script></span>，并且步长为2的卷积层得到，定义为C6，所有的特征图通道数均为256。注意，作者并没有用到FPN中自顶向下的结构，因为所提出的多<strong>尺度可变形注意力模块本身就可以在多尺度特征映射之间进行信息交换，TF序列间的建模能力实现了这一点</strong>。（论文的附录中验证了，引入FPN结构不会提高模型最终的性能）</p>
<p>&emsp;&emsp;在编码器中应用多尺度可变形注意力模块，输出是与输入分辨率相同的多尺度特征图，键和查询元素都是来自多尺度特征图的像素，对于每个查询向量的像素，参考点是其本身，为了识别每个查询像素所处的特征级别，除了嵌入位置编码以外，作者还在特征表示中添加了一个<strong>尺度编码，表示为<span class="arithmatex"><span class="MathJax_Preview">\{e_l\}^L_{l=1}</span><script type="math/tex">\{e_l\}^L_{l=1}</script></span></strong>，与位置编码不同（位置编码是固定的），尺度编码是随机初始化的，并且与网络共同训练。</p>
<p><strong>可变形的TF解码器</strong></p>
<p>&emsp;&emsp;解码器中有交叉注意力模块和自注意力模块，这两种注意力模块的查询元素（即q值）都是物体查询向量<span class="arithmatex"><span class="MathJax_Preview">Q</span><script type="math/tex">Q</script></span>，在交叉注意力中，物体查询向量从特征图中提取特征，键（k）为从编码器输出的特征图；在自注意力模块中，物体查询相互交互，键（k）为物体的查询向量。由于提出的可变形注意力模块是为了处理卷积特征映射作为键（k）值元素，因此作者只将每个交叉注意力模块替换为多尺度可变形注意力模块，保持自注意力模块结构不变。对于每个物体查询向量，2D参考点<span class="arithmatex"><span class="MathJax_Preview">\hat p_q</span><script type="math/tex">\hat p_q</script></span>归一化后的坐标通过可学习的线性投影和一个sigmoid函数从其对象查询嵌入中预测。</p>
<p>&emsp;&emsp;由于多尺度可变形注意力模块<strong>提取参考点周围的图像特征</strong>，因此我们<strong>让检测头预测的边界框作为相对于参考点的相对偏移量</strong>，从而进一步降低优化难度，参考点<strong>以框中心作为初始化数据</strong>。这样，学习到的解码器注意力与预测的边界框具有很强的相关性，进一步加快了网络的收敛。</p>
<p><strong>Deformable DETR的提升</strong></p>
<p><strong>迭代边界框的细化：</strong>受到光流估计中开发迭代细化的启发，为了提高目标检性能，作者建立了一种简单有效的迭代边界框细化机制，在这里，<strong>每个解码器层基于前一层的预测来细化边界框</strong>。</p>
<p><strong>二阶段Deformable DETR：</strong>在原始的DETR中，解码器中的物体查询向量<span class="arithmatex"><span class="MathJax_Preview">Q</span><script type="math/tex">Q</script></span>与当前图像无关，受二阶段目标检测器的启发，作者探索了一种Deformable DETR的变体，即二阶段Deformable DETR目标检测器，<strong>第一阶段检测到的边界框当做区域建议</strong>（proposals），之后进一步传入第二阶段中，充当物体查询向量，用于细化所预测的边界框位置。</p>
<p>注：在<strong>第一阶段</strong>，为了实现高召回率的提议，这里的查询向量<span class="arithmatex"><span class="MathJax_Preview">Q</span><script type="math/tex">Q</script></span>是以图像特征的形式输入到解码器中，和一阶段的不一样，一阶段的<span class="arithmatex"><span class="MathJax_Preview">Q</span><script type="math/tex">Q</script></span>是一组预设好形状、可学习的参数。这里多尺度特征中的每个特征像素都将作为物体查询向量，然而，这么做会带来非常大的计算量，计算复杂度随着查询数量（即图像尺寸）的增加而呈二次增长。为了避免这个问题，作者在第一阶段中去掉了解码器，形成了一个只有编码器的Deformable DETR来生成区域建议，其中<strong>每个像素点直接用来预测一个边界框，选取得分最高的边界框作为区域建议</strong>，在像第二阶段提供区域建议之前，不应用NMS。</p>
<h2 id="_6">源码实现<a class="headerlink" href="#_6" title="Permanent link">&para;</a></h2>
<h3 id="_7">流程<a class="headerlink" href="#_7" title="Permanent link">&para;</a></h3>
<p><strong>backbone模块</strong></p>
<ul>
<li>图像先经过backbone（一般由CNN组成），得到多个层级的特征图，根据特征图尺寸预设位置编码（这里的位置编码是固定的数据，x、y分别与sin、cos运算有关）；</li>
<li>不同层级特征图通道数不一样，不能直接传入TF编码器，因此像FPN一样，先统一通道数，通道数统一成256；</li>
</ul>
<p><strong>TF模块</strong></p>
<ul>
<li>根据不同层级，预设多组特征层编码（这里特征层编码为可学习的参数，尺寸为[层数，256]），先将图像特征拉直，变为序列特征，并且将不同层级的序列特征合并，合并为一个总的序列特征；</li>
<li>并且将图像的位置编码与特征层编码相加，用于表示图像每个图像特征的层级和位置信息，简称图像的信息编码；</li>
</ul>
<p><strong>编码模块</strong></p>
<ul>
<li>生成参考点坐标数据：对于每个层级特征，将其视为一个网格，网格上的点就是参考点（每个坐标点对应一个特征点），坐标数据从左上到右下依次增大，并且特征层越深，特征图越小，相邻参考点的数值跨度就越大，默认每个特征点生成四个参考点；</li>
<li>q为图像编码特征与信息编码相加后的数据、v为单纯的图像编码特征。将v传入线性映射，得到计算注意力前所用的v；模型利用q预测参考点在x、y上的偏移量、以及各个参考点的权重（解释：每个注意力点到底在哪，并且注意力的侧重力度有多大，只跟查询q有关，因为注意力和核心目的就是要得到查询q对应的&rsquo;v&rsquo;值）；</li>
<li>参考坐标点与预测的偏移量相加，得到采样点坐标；</li>
<li>将v、采样坐标点、注意力权重传入可变形注意力计算模块，计算注意力数据；</li>
<li>之后计算TF模块中剩余的部分（残差映射、LN、FFN等等）；</li>
</ul>
<p>注：可变形注意力模块降低计算量的本质，就是减少q在计算注意力时所参考的点，传统的多头注意力，对于q中每个元素，都要逐一与k做一次注意力运算，得到权重，再与所有的v值加权求和，而可变形注意力模块就限定了参考点的个数，这里默认限定为4个，即q中每个元素，只与k中4个元素作注意力运算，得到的权重，在与v中对应的4个元素作加权求和，其中采样点坐标就是为了定位4个参考元素。</p>
<p><strong>解码模块</strong></p>
<ul>
<li>预设一组物体查询向量<span class="arithmatex"><span class="MathJax_Preview">Q</span><script type="math/tex">Q</script></span>、初始的解码特征tgt（二者类似，数据均为可学习的参数，尺寸均为[查询个数、特征维度]），将查询向量传入线性映射层，映射为2个数，表示边界框参考点坐标，参考点尺寸为[查询个数,2]（后续再复制4倍，每个物体查询采样4个点），这里计算参考点也是为了后续在解码过程中，引入可变形注意力运算；</li>
<li>先对查询向量、解码特征算一次自注意力（self-attention），其中q、k为解码特征tgt与查询向量<span class="arithmatex"><span class="MathJax_Preview">Q</span><script type="math/tex">Q</script></span>相加，v为解码特征tgt，后面再经过残差映射、LN运算；</li>
<li>计算交叉注意力（可变形注意力运算），其中q为解码特征tgt与查询向量<span class="arithmatex"><span class="MathJax_Preview">Q</span><script type="math/tex">Q</script></span>相加，尺寸为[查询个数,特征维度]，k为边界框参考点坐标，尺寸为[查询个数,4,2]，v为编码特征src，尺寸为[特征序列数,特征维数]。q先经过两次线性映射，得到参考点的偏移量和注意力权重，偏移量与参考点坐标相加，得到采样点，之后将v、采样点、注意力权重传入可变形注意力模块，计算注意力，最后再经过残差映射、LN、FFN；</li>
</ul>
<p>注：</p>
<ul>
<li>解码特征是随着解码的过程不断变化的，而查询向量<span class="arithmatex"><span class="MathJax_Preview">Q</span><script type="math/tex">Q</script></span>在解码过程中是不变的，因此在每个解码模块中，q是不一样的，类似迭代优化表示；</li>
<li>论文中的两大改进点“迭代边界框的细化”和“二阶段Deformable DETR”，都是对物体的参考点坐标做操作，迭代边界框的细化是在每次解码模块过程中，都改进一次物体参考点坐标，类似迭代优化表示（原始方法，每个解码模块用的参考点坐标都一样）；二阶段的DeDETR，会在编码之后，先将编码特征传入一次解码器（额外设置的），解码得到的特征用于初始化物体参考点坐标（原始方法，参考点坐标的初始化由查询向量做一次线性映射得到）。</li>
</ul>
<p><strong>预测模块</strong></p>
<ul>
<li>根据得到的解码特征，预测边界框和类别，以类别为例，输出的数据尺寸为[查询个数、类别数]；</li>
</ul>
<h3 id="transformer">Transformer模块<a class="headerlink" href="#transformer" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">DeformableTransformer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">nhead</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
                 <span class="n">num_encoder_layers</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">num_decoder_layers</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">dim_feedforward</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                 <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">return_intermediate_dec</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">num_feature_levels</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">dec_n_points</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>  <span class="n">enc_n_points</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                 <span class="n">two_stage</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">two_stage_num_proposals</span><span class="o">=</span><span class="mi">300</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nhead</span> <span class="o">=</span> <span class="n">nhead</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">two_stage</span> <span class="o">=</span> <span class="n">two_stage</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">two_stage_num_proposals</span> <span class="o">=</span> <span class="n">two_stage_num_proposals</span>

        <span class="n">encoder_layer</span> <span class="o">=</span> <span class="n">DeformableTransformerEncoderLayer</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">dim_feedforward</span><span class="p">,</span>
                                                          <span class="n">dropout</span><span class="p">,</span> <span class="n">activation</span><span class="p">,</span>
                                                          <span class="n">num_feature_levels</span><span class="p">,</span> <span class="n">nhead</span><span class="p">,</span> <span class="n">enc_n_points</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">DeformableTransformerEncoder</span><span class="p">(</span><span class="n">encoder_layer</span><span class="p">,</span> <span class="n">num_encoder_layers</span><span class="p">)</span>

        <span class="n">decoder_layer</span> <span class="o">=</span> <span class="n">DeformableTransformerDecoderLayer</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">dim_feedforward</span><span class="p">,</span>
                                                          <span class="n">dropout</span><span class="p">,</span> <span class="n">activation</span><span class="p">,</span>
                                                          <span class="n">num_feature_levels</span><span class="p">,</span> <span class="n">nhead</span><span class="p">,</span> <span class="n">dec_n_points</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">DeformableTransformerDecoder</span><span class="p">(</span><span class="n">decoder_layer</span><span class="p">,</span> <span class="n">num_decoder_layers</span><span class="p">,</span> <span class="n">return_intermediate_dec</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">level_embed</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">num_feature_levels</span><span class="p">,</span> <span class="n">d_model</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">two_stage</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">enc_output</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">enc_output_norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pos_trans</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">d_model</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pos_trans_norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reference_points</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_reset_parameters</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_reset_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">MSDeformAttn</span><span class="p">):</span>
                <span class="n">m</span><span class="o">.</span><span class="n">_reset_parameters</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">two_stage</span><span class="p">:</span>
            <span class="n">xavier_uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reference_points</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">gain</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
            <span class="n">constant_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reference_points</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mf">0.</span><span class="p">)</span>
        <span class="n">normal_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">level_embed</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_proposal_pos_embed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">proposals</span><span class="p">):</span>
        <span class="n">num_pos_feats</span> <span class="o">=</span> <span class="mi">128</span>
        <span class="n">temperature</span> <span class="o">=</span> <span class="mi">10000</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span>

        <span class="n">dim_t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_pos_feats</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">proposals</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">dim_t</span> <span class="o">=</span> <span class="n">temperature</span> <span class="o">**</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">dim_t</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">num_pos_feats</span><span class="p">)</span>
        <span class="c1"># N, L, 4</span>
        <span class="n">proposals</span> <span class="o">=</span> <span class="n">proposals</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span> <span class="o">*</span> <span class="n">scale</span>
        <span class="c1"># N, L, 4, 128</span>
        <span class="n">pos</span> <span class="o">=</span> <span class="n">proposals</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">/</span> <span class="n">dim_t</span>
        <span class="c1"># N, L, 4, 64, 2</span>
        <span class="n">pos</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">pos</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">sin</span><span class="p">(),</span> <span class="n">pos</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">cos</span><span class="p">()),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">pos</span>

    <span class="k">def</span> <span class="nf">gen_encoder_output_proposals</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">memory</span><span class="p">,</span> <span class="n">memory_padding_mask</span><span class="p">,</span> <span class="n">spatial_shapes</span><span class="p">):</span>
        <span class="n">N_</span><span class="p">,</span> <span class="n">S_</span><span class="p">,</span> <span class="n">C_</span> <span class="o">=</span> <span class="n">memory</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">base_scale</span> <span class="o">=</span> <span class="mf">4.0</span>
        <span class="n">proposals</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">_cur</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">lvl</span><span class="p">,</span> <span class="p">(</span><span class="n">H_</span><span class="p">,</span> <span class="n">W_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">spatial_shapes</span><span class="p">):</span>
            <span class="n">mask_flatten_</span> <span class="o">=</span> <span class="n">memory_padding_mask</span><span class="p">[:,</span> <span class="n">_cur</span><span class="p">:(</span><span class="n">_cur</span> <span class="o">+</span> <span class="n">H_</span> <span class="o">*</span> <span class="n">W_</span><span class="p">)]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">N_</span><span class="p">,</span> <span class="n">H_</span><span class="p">,</span> <span class="n">W_</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">valid_H</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">~</span><span class="n">mask_flatten_</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">valid_W</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">~</span><span class="n">mask_flatten_</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>

            <span class="n">grid_y</span><span class="p">,</span> <span class="n">grid_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">H_</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">H_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">memory</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
                                            <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">W_</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">W_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">memory</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
            <span class="n">grid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">grid_x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">grid_y</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

            <span class="n">scale</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">valid_W</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">valid_H</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)],</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">N_</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">grid</span> <span class="o">=</span> <span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">N_</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">/</span> <span class="n">scale</span>
            <span class="n">wh</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">grid</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.05</span> <span class="o">*</span> <span class="p">(</span><span class="mf">2.0</span> <span class="o">**</span> <span class="n">lvl</span><span class="p">)</span>
            <span class="n">proposal</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">grid</span><span class="p">,</span> <span class="n">wh</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">N_</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
            <span class="n">proposals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">proposal</span><span class="p">)</span>
            <span class="n">_cur</span> <span class="o">+=</span> <span class="p">(</span><span class="n">H_</span> <span class="o">*</span> <span class="n">W_</span><span class="p">)</span>
        <span class="n">output_proposals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">proposals</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">output_proposals_valid</span> <span class="o">=</span> <span class="p">((</span><span class="n">output_proposals</span> <span class="o">&gt;</span> <span class="mf">0.01</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">output_proposals</span> <span class="o">&lt;</span> <span class="mf">0.99</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">output_proposals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">output_proposals</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">output_proposals</span><span class="p">))</span>
        <span class="n">output_proposals</span> <span class="o">=</span> <span class="n">output_proposals</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">memory_padding_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">))</span>
        <span class="n">output_proposals</span> <span class="o">=</span> <span class="n">output_proposals</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="o">~</span><span class="n">output_proposals_valid</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">))</span>

        <span class="n">output_memory</span> <span class="o">=</span> <span class="n">memory</span>
        <span class="n">output_memory</span> <span class="o">=</span> <span class="n">output_memory</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">memory_padding_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="nb">float</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
        <span class="n">output_memory</span> <span class="o">=</span> <span class="n">output_memory</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="o">~</span><span class="n">output_proposals_valid</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
        <span class="n">output_memory</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc_output_norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enc_output</span><span class="p">(</span><span class="n">output_memory</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">output_memory</span><span class="p">,</span> <span class="n">output_proposals</span>

    <span class="k">def</span> <span class="nf">get_valid_ratio</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">valid_H</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">~</span><span class="n">mask</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">valid_W</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">~</span><span class="n">mask</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:],</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">valid_ratio_h</span> <span class="o">=</span> <span class="n">valid_H</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">/</span> <span class="n">H</span>
        <span class="n">valid_ratio_w</span> <span class="o">=</span> <span class="n">valid_W</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">/</span> <span class="n">W</span>
        <span class="n">valid_ratio</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">valid_ratio_w</span><span class="p">,</span> <span class="n">valid_ratio_h</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">valid_ratio</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">srcs</span><span class="p">,</span> <span class="n">masks</span><span class="p">,</span> <span class="n">pos_embeds</span><span class="p">,</span> <span class="n">query_embed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">two_stage</span> <span class="ow">or</span> <span class="n">query_embed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

        <span class="c1"># prepare input for encoder</span>
        <span class="n">src_flatten</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">mask_flatten</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">lvl_pos_embed_flatten</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">spatial_shapes</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># 将图像特征拉直，变为序列特征，并且将图像的位置编码与特征层编码相加，赋予特征层信息，用于区分不同特征层的图像特征</span>
        <span class="k">for</span> <span class="n">lvl</span><span class="p">,</span> <span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">pos_embed</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">srcs</span><span class="p">,</span> <span class="n">masks</span><span class="p">,</span> <span class="n">pos_embeds</span><span class="p">)):</span>
            <span class="n">bs</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">src</span><span class="o">.</span><span class="n">shape</span>
            <span class="n">spatial_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
            <span class="n">spatial_shapes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">spatial_shape</span><span class="p">)</span>
            <span class="n">src</span> <span class="o">=</span> <span class="n">src</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">pos_embed</span> <span class="o">=</span> <span class="n">pos_embed</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
            <span class="c1"># 位置编码 + 特征层编码，得到图像的信息编码，用于区分不同区域的特征</span>
            <span class="n">lvl_pos_embed</span> <span class="o">=</span> <span class="n">pos_embed</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">level_embed</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">lvl_pos_embed_flatten</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">lvl_pos_embed</span><span class="p">)</span>
            <span class="n">src_flatten</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">src</span><span class="p">)</span>
            <span class="n">mask_flatten</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
        <span class="c1"># 不同特征层的特征沿层方向合并，合并为一个大的特征序列</span>
        <span class="n">src_flatten</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">src_flatten</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">mask_flatten</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">mask_flatten</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">lvl_pos_embed_flatten</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">lvl_pos_embed_flatten</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">spatial_shapes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">spatial_shapes</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">src_flatten</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">level_start_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">spatial_shapes</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="p">)),</span> <span class="n">spatial_shapes</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="mi">0</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
        <span class="n">valid_ratios</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">get_valid_ratio</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">masks</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># encoder 利用可变形注意力模块做编码</span>
        <span class="c1"># src_flatten表示图像编码特征、spatial_shapes表示每个特征层级的尺寸、level_start_index表示特征序列的层级索引</span>
        <span class="c1"># valid_ratios表示预设参考点坐标时x、y的比率，默认(1,1)，即不做变化</span>
        <span class="n">memory</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">src_flatten</span><span class="p">,</span> <span class="n">spatial_shapes</span><span class="p">,</span> <span class="n">level_start_index</span><span class="p">,</span> <span class="n">valid_ratios</span><span class="p">,</span> <span class="n">lvl_pos_embed_flatten</span><span class="p">,</span> <span class="n">mask_flatten</span><span class="p">)</span>

        <span class="c1"># prepare input for decoder</span>
        <span class="n">bs</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">memory</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">two_stage</span><span class="p">:</span>
            <span class="n">output_memory</span><span class="p">,</span> <span class="n">output_proposals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gen_encoder_output_proposals</span><span class="p">(</span><span class="n">memory</span><span class="p">,</span> <span class="n">mask_flatten</span><span class="p">,</span> <span class="n">spatial_shapes</span><span class="p">)</span>

            <span class="c1"># hack implementation for two-stage Deformable DETR</span>
            <span class="n">enc_outputs_class</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">class_embed</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">num_layers</span><span class="p">](</span><span class="n">output_memory</span><span class="p">)</span>
            <span class="n">enc_outputs_coord_unact</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">bbox_embed</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">num_layers</span><span class="p">](</span><span class="n">output_memory</span><span class="p">)</span> <span class="o">+</span> <span class="n">output_proposals</span>

            <span class="n">topk</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">two_stage_num_proposals</span>
            <span class="n">topk_proposals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">enc_outputs_class</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">topk</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">topk_coords_unact</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">enc_outputs_coord_unact</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">topk_proposals</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
            <span class="n">topk_coords_unact</span> <span class="o">=</span> <span class="n">topk_coords_unact</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
            <span class="n">reference_points</span> <span class="o">=</span> <span class="n">topk_coords_unact</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span>
            <span class="n">init_reference_out</span> <span class="o">=</span> <span class="n">reference_points</span>
            <span class="n">pos_trans_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_trans_norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pos_trans</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_proposal_pos_embed</span><span class="p">(</span><span class="n">topk_coords_unact</span><span class="p">)))</span>
            <span class="n">query_embed</span><span class="p">,</span> <span class="n">tgt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">pos_trans_out</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">query_embed</span><span class="p">,</span> <span class="n">tgt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">query_embed</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">query_embed</span> <span class="o">=</span> <span class="n">query_embed</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">tgt</span> <span class="o">=</span> <span class="n">tgt</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">reference_points</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reference_points</span><span class="p">(</span><span class="n">query_embed</span><span class="p">)</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span>
            <span class="n">init_reference_out</span> <span class="o">=</span> <span class="n">reference_points</span>

        <span class="c1"># decoder</span>
        <span class="c1"># 得到解码特征，还有每层的inter_references，用于iterative bounding box refinement，即迭代边界框的细化，属于DeDETR的提升任务</span>
        <span class="n">hs</span><span class="p">,</span> <span class="n">inter_references</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">tgt</span><span class="p">,</span> <span class="n">reference_points</span><span class="p">,</span> <span class="n">memory</span><span class="p">,</span>
                                            <span class="n">spatial_shapes</span><span class="p">,</span> <span class="n">level_start_index</span><span class="p">,</span> <span class="n">valid_ratios</span><span class="p">,</span> <span class="n">query_embed</span><span class="p">,</span> <span class="n">mask_flatten</span><span class="p">)</span>

        <span class="n">inter_references_out</span> <span class="o">=</span> <span class="n">inter_references</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">two_stage</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">hs</span><span class="p">,</span> <span class="n">init_reference_out</span><span class="p">,</span> <span class="n">inter_references_out</span><span class="p">,</span> <span class="n">enc_outputs_class</span><span class="p">,</span> <span class="n">enc_outputs_coord_unact</span>
        <span class="k">return</span> <span class="n">hs</span><span class="p">,</span> <span class="n">init_reference_out</span><span class="p">,</span> <span class="n">inter_references_out</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
</code></pre></div>
<h4 id="_8">编码器<a class="headerlink" href="#_8" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">DeformableTransformerEncoderLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">d_model</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">d_ffn</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
                 <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span>
                 <span class="n">n_levels</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">n_points</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># self attention</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span> <span class="o">=</span> <span class="n">MSDeformAttn</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">n_levels</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">,</span> <span class="n">n_points</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>

        <span class="c1"># ffn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_ffn</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">_get_activation_fn</span><span class="p">(</span><span class="n">activation</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_ffn</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">with_pos_embed</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">pos</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">tensor</span> <span class="k">if</span> <span class="n">pos</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">tensor</span> <span class="o">+</span> <span class="n">pos</span>

    <span class="k">def</span> <span class="nf">forward_ffn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">):</span>
        <span class="n">src2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear1</span><span class="p">(</span><span class="n">src</span><span class="p">))))</span>
        <span class="n">src</span> <span class="o">=</span> <span class="n">src</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout3</span><span class="p">(</span><span class="n">src2</span><span class="p">)</span>
        <span class="n">src</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="p">(</span><span class="n">src</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">src</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">reference_points</span><span class="p">,</span> <span class="n">spatial_shapes</span><span class="p">,</span> <span class="n">level_start_index</span><span class="p">,</span> <span class="n">padding_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># self attention</span>
        <span class="c1"># 图像编码特征与信息编码相加后的数据，充当查询q。单纯的图像编码特征src充当值v</span>
        <span class="c1"># reference_points表示参考点，用于计算采样点</span>
        <span class="c1"># spatial_shapes为每层特征图的尺寸，level_start_index为特征序列层级的索引（level_start_index[0]到level_start_index[1]表示第一级的索引，浅层特征）</span>
        <span class="n">src2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">with_pos_embed</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">pos</span><span class="p">),</span> <span class="n">reference_points</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">spatial_shapes</span><span class="p">,</span> <span class="n">level_start_index</span><span class="p">,</span> <span class="n">padding_mask</span><span class="p">)</span>
        <span class="n">src</span> <span class="o">=</span> <span class="n">src</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span><span class="p">(</span><span class="n">src2</span><span class="p">)</span>
        <span class="n">src</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">src</span><span class="p">)</span>

        <span class="c1"># ffn</span>
        <span class="n">src</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_ffn</span><span class="p">(</span><span class="n">src</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">src</span>
<span class="k">class</span> <span class="nc">DeformableTransformerEncoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder_layer</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">_get_clones</span><span class="p">(</span><span class="n">encoder_layer</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">get_reference_points</span><span class="p">(</span><span class="n">spatial_shapes</span><span class="p">,</span> <span class="n">valid_ratios</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
        <span class="n">reference_points_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">lvl</span><span class="p">,</span> <span class="p">(</span><span class="n">H_</span><span class="p">,</span> <span class="n">W_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">spatial_shapes</span><span class="p">):</span>

            <span class="n">ref_y</span><span class="p">,</span> <span class="n">ref_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">H_</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">H_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
                                          <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">W_</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">W_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>
            <span class="n">ref_y</span> <span class="o">=</span> <span class="n">ref_y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)[</span><span class="kc">None</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="n">valid_ratios</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">lvl</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">H_</span><span class="p">)</span>
            <span class="n">ref_x</span> <span class="o">=</span> <span class="n">ref_x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)[</span><span class="kc">None</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="n">valid_ratios</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">lvl</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">W_</span><span class="p">)</span>
            <span class="n">ref</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">ref_x</span><span class="p">,</span> <span class="n">ref_y</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">reference_points_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ref</span><span class="p">)</span>
        <span class="n">reference_points</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">reference_points_list</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">reference_points</span> <span class="o">=</span> <span class="n">reference_points</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">valid_ratios</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">reference_points</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">spatial_shapes</span><span class="p">,</span> <span class="n">level_start_index</span><span class="p">,</span> <span class="n">valid_ratios</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">src</span>
        <span class="c1"># 在每个像素点上预生成多个参考点，并且对于每个层级特征，将其视为一个网格，网格上的点就是参考点，坐标从左上到右下依次增大（从0增为1）</span>
        <span class="c1"># 因此特征层越深，特征图越小，相邻参考点数值的跨度就越大（步幅大）</span>
        <span class="c1"># valid_ratios为不同参考点的比例，默认都是1,1，生成4个参考点，对于每个点，生成4个一样的参考点</span>
        <span class="n">reference_points</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_reference_points</span><span class="p">(</span><span class="n">spatial_shapes</span><span class="p">,</span> <span class="n">valid_ratios</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">src</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">):</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">reference_points</span><span class="p">,</span> <span class="n">spatial_shapes</span><span class="p">,</span> <span class="n">level_start_index</span><span class="p">,</span> <span class="n">padding_mask</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">output</span>
</code></pre></div>
<h4 id="_9">可变注意力模块<a class="headerlink" href="#_9" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">MSDeformAttn</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">n_levels</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">n_points</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Multi-Scale Deformable Attention Module</span>
<span class="sd">        :param d_model      hidden dimension</span>
<span class="sd">        :param n_levels     number of feature levels</span>
<span class="sd">        :param n_heads      number of attention heads</span>
<span class="sd">        :param n_points     number of sampling points per attention head per feature level</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">d_model</span> <span class="o">%</span> <span class="n">n_heads</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;d_model must be divisible by n_heads, but got </span><span class="si">{}</span><span class="s1"> and </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">))</span>
        <span class="n">_d_per_head</span> <span class="o">=</span> <span class="n">d_model</span> <span class="o">//</span> <span class="n">n_heads</span>
        <span class="c1"># you&#39;d better set _d_per_head to a power of 2 which is more efficient in our CUDA implementation</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">_is_power_of_2</span><span class="p">(</span><span class="n">_d_per_head</span><span class="p">):</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;You&#39;d better set d_model in MSDeformAttn to make the dimension of each attention head a power of 2 &quot;</span>
                          <span class="s2">&quot;which is more efficient in our CUDA implementation.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">im2col_step</span> <span class="o">=</span> <span class="mi">64</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_levels</span> <span class="o">=</span> <span class="n">n_levels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span> <span class="o">=</span> <span class="n">n_heads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_points</span> <span class="o">=</span> <span class="n">n_points</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">sampling_offsets</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">n_heads</span> <span class="o">*</span> <span class="n">n_levels</span> <span class="o">*</span> <span class="n">n_points</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention_weights</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">n_heads</span> <span class="o">*</span> <span class="n">n_levels</span> <span class="o">*</span> <span class="n">n_points</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_reset_parameters</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_reset_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">constant_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sampling_offsets</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mf">0.</span><span class="p">)</span>
        <span class="n">thetas</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mf">2.0</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">)</span>
        <span class="n">grid_init</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">thetas</span><span class="o">.</span><span class="n">cos</span><span class="p">(),</span> <span class="n">thetas</span><span class="o">.</span><span class="n">sin</span><span class="p">()],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">grid_init</span> <span class="o">=</span> <span class="p">(</span><span class="n">grid_init</span> <span class="o">/</span> <span class="n">grid_init</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_levels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_points</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_points</span><span class="p">):</span>
            <span class="n">grid_init</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">*=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sampling_offsets</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">grid_init</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">constant_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attention_weights</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mf">0.</span><span class="p">)</span>
        <span class="n">constant_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attention_weights</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mf">0.</span><span class="p">)</span>
        <span class="n">xavier_uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">value_proj</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="n">constant_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">value_proj</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mf">0.</span><span class="p">)</span>
        <span class="n">xavier_uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_proj</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="n">constant_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_proj</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mf">0.</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">reference_points</span><span class="p">,</span> <span class="n">input_flatten</span><span class="p">,</span> <span class="n">input_spatial_shapes</span><span class="p">,</span> <span class="n">input_level_start_index</span><span class="p">,</span> <span class="n">input_padding_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param query                       (N, Length_{query}, C)，编码特征与信息编码相加后的数据，充当查询q</span>
<span class="sd">        :param reference_points            (N, Length_{query}, n_levels, 2), range in [0, 1], top-left (0,0), bottom-right (1, 1), including padding area</span>
<span class="sd">                                        or (N, Length_{query}, n_levels, 4), add additional (w, h) to form reference boxes</span>
<span class="sd">        :param input_flatten               (N, \sum_{l=0}^{L-1} H_l \cdot W_l, C)，编码特征，充当值v</span>
<span class="sd">        :param input_spatial_shapes        (n_levels, 2), [(H_0, W_0), (H_1, W_1), ..., (H_{L-1}, W_{L-1})]</span>
<span class="sd">        :param input_level_start_index     (n_levels, ), [0, H_0*W_0, H_0*W_0+H_1*W_1, H_0*W_0+H_1*W_1+H_2*W_2, ..., H_0*W_0+H_1*W_1+...+H_{L-1}*W_{L-1}]</span>
<span class="sd">        :param input_padding_mask          (N, \sum_{l=0}^{L-1} H_l \cdot W_l), True for padding elements, False for non-padding elements</span>

<span class="sd">        :return output                     (N, Length_{query}, C)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">N</span><span class="p">,</span> <span class="n">Len_q</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">N</span><span class="p">,</span> <span class="n">Len_in</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">input_flatten</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">assert</span> <span class="p">(</span><span class="n">input_spatial_shapes</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">input_spatial_shapes</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">==</span> <span class="n">Len_in</span>
        <span class="c1"># v经过一次线性映射，得到用于计算可变形注意力的v</span>
        <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">value_proj</span><span class="p">(</span><span class="n">input_flatten</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">input_padding_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">input_padding_mask</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="nb">float</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
        <span class="c1"># 分成不同的头，引入多头注意的概念</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">Len_in</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">)</span>
        <span class="c1"># 利用查询向量预测偏移量（到底往哪偏，与哪个元素建立联系，需要因查询向量q而异，因为注意力本身就是要计算q对应的&#39;v&#39;值）</span>
        <span class="c1"># 注意，这里把所有层的特征序列都混到一块了，所以每个特征序列都会预测四组偏移量，分别表示对应的层级</span>
        <span class="c1"># 后面会根据层级特征序列的索引input_level_start_index，来进行筛选</span>
        <span class="n">sampling_offsets</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampling_offsets</span><span class="p">(</span><span class="n">query</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">Len_q</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_levels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_points</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="c1"># 根据查询来计算注意力权重，同样权重只跟查询q有关。注意：偏移量与x、y两个数有关，因此偏移数据量是注意力权重数据量的两倍</span>
        <span class="n">attention_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_weights</span><span class="p">(</span><span class="n">query</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">Len_q</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_levels</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_points</span><span class="p">)</span>
        <span class="c1"># 权重经过一次softmax，做归一化操作</span>
        <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">attention_weights</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">Len_q</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_levels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_points</span><span class="p">)</span>
        <span class="c1"># N, Len_q, n_heads, n_levels, n_points, 2</span>
        <span class="c1"># 参考点与偏移量做加法，得到采样点。跟上面分析的一样，无论哪个层级，每个序列特征都会与不同层上的偏移量做相加，后面会再根据input_level_start_index筛选出来</span>
        <span class="k">if</span> <span class="n">reference_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">offset_normalizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">input_spatial_shapes</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">input_spatial_shapes</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">sampling_locations</span> <span class="o">=</span> <span class="n">reference_points</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> \
                                 <span class="o">+</span> <span class="n">sampling_offsets</span> <span class="o">/</span> <span class="n">offset_normalizer</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
        <span class="k">elif</span> <span class="n">reference_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
            <span class="n">sampling_locations</span> <span class="o">=</span> <span class="n">reference_points</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span> \
                                 <span class="o">+</span> <span class="n">sampling_offsets</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_points</span> <span class="o">*</span> <span class="n">reference_points</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">2</span><span class="p">:]</span> <span class="o">*</span> <span class="mf">0.5</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s1">&#39;Last dim of reference_points must be 2 or 4, but get </span><span class="si">{}</span><span class="s1"> instead.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">reference_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
        <span class="c1"># 直接诶调用库，计算可变形注意力机制</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">MSDeformAttnFunction</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
            <span class="n">value</span><span class="p">,</span> <span class="n">input_spatial_shapes</span><span class="p">,</span> <span class="n">input_level_start_index</span><span class="p">,</span> <span class="n">sampling_locations</span><span class="p">,</span> <span class="n">attention_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">im2col_step</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_proj</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>
</code></pre></div>
<h4 id="_10">解码器<a class="headerlink" href="#_10" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">DeformableTransformerDecoderLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">d_ffn</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
                 <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span>
                 <span class="n">n_levels</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">n_points</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># cross attention</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cross_attn</span> <span class="o">=</span> <span class="n">MSDeformAttn</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">n_levels</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">,</span> <span class="n">n_points</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>

        <span class="c1"># self attention</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MultiheadAttention</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>

        <span class="c1"># ffn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_ffn</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">_get_activation_fn</span><span class="p">(</span><span class="n">activation</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_ffn</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout4</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">with_pos_embed</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">pos</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">tensor</span> <span class="k">if</span> <span class="n">pos</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">tensor</span> <span class="o">+</span> <span class="n">pos</span>

    <span class="k">def</span> <span class="nf">forward_ffn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tgt</span><span class="p">):</span>
        <span class="n">tgt2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout3</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear1</span><span class="p">(</span><span class="n">tgt</span><span class="p">))))</span>
        <span class="n">tgt</span> <span class="o">=</span> <span class="n">tgt</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout4</span><span class="p">(</span><span class="n">tgt2</span><span class="p">)</span>
        <span class="n">tgt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm3</span><span class="p">(</span><span class="n">tgt</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tgt</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tgt</span><span class="p">,</span> <span class="n">query_pos</span><span class="p">,</span> <span class="n">reference_points</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">src_spatial_shapes</span><span class="p">,</span> <span class="n">level_start_index</span><span class="p">,</span> <span class="n">src_padding_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># self attention # 解码特征和查询向量q做自注意力运算，自注意力运算直接用多头注意力模块，不做可变形注意力操作</span>
        <span class="n">q</span> <span class="o">=</span> <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_pos_embed</span><span class="p">(</span><span class="n">tgt</span><span class="p">,</span> <span class="n">query_pos</span><span class="p">)</span>
        <span class="n">tgt2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span><span class="p">(</span><span class="n">q</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">k</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">tgt</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">tgt</span> <span class="o">=</span> <span class="n">tgt</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span><span class="p">(</span><span class="n">tgt2</span><span class="p">)</span>
        <span class="n">tgt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="p">(</span><span class="n">tgt</span><span class="p">)</span>

        <span class="c1"># cross attention # 交叉注意力</span>
        <span class="n">tgt2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cross_attn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">with_pos_embed</span><span class="p">(</span><span class="n">tgt</span><span class="p">,</span> <span class="n">query_pos</span><span class="p">),</span>
                               <span class="n">reference_points</span><span class="p">,</span>
                               <span class="n">src</span><span class="p">,</span> <span class="n">src_spatial_shapes</span><span class="p">,</span> <span class="n">level_start_index</span><span class="p">,</span> <span class="n">src_padding_mask</span><span class="p">)</span>
        <span class="n">tgt</span> <span class="o">=</span> <span class="n">tgt</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span><span class="p">(</span><span class="n">tgt2</span><span class="p">)</span>
        <span class="n">tgt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">tgt</span><span class="p">)</span>

        <span class="c1"># ffn</span>
        <span class="n">tgt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_ffn</span><span class="p">(</span><span class="n">tgt</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">tgt</span>


<span class="k">class</span> <span class="nc">DeformableTransformerDecoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">decoder_layer</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">return_intermediate</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">_get_clones</span><span class="p">(</span><span class="n">decoder_layer</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_intermediate</span> <span class="o">=</span> <span class="n">return_intermediate</span>
        <span class="c1"># hack implementation for iterative bounding box refinement and two-stage Deformable DETR</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bbox_embed</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">class_embed</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="c1"># tgt表示图像解码特征，是随着for循环（解码运算）的进行不断变化的，尺寸与预设的查询向量q一样，都是(300,256)</span>
    <span class="c1"># src表示图像编码特征，在解码过程中始终不变</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tgt</span><span class="p">,</span> <span class="n">reference_points</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">src_spatial_shapes</span><span class="p">,</span> <span class="n">src_level_start_index</span><span class="p">,</span> <span class="n">src_valid_ratios</span><span class="p">,</span>
                <span class="n">query_pos</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">src_padding_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">tgt</span>

        <span class="n">intermediate</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">intermediate_reference_points</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">lid</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">reference_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
                <span class="n">reference_points_input</span> <span class="o">=</span> <span class="n">reference_points</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">]</span> \
                                         <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">src_valid_ratios</span><span class="p">,</span> <span class="n">src_valid_ratios</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">assert</span> <span class="n">reference_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span>
                <span class="n">reference_points_input</span> <span class="o">=</span> <span class="n">reference_points</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">src_valid_ratios</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">query_pos</span><span class="p">,</span> <span class="n">reference_points_input</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">src_spatial_shapes</span><span class="p">,</span> <span class="n">src_level_start_index</span><span class="p">,</span> <span class="n">src_padding_mask</span><span class="p">)</span>

            <span class="c1"># hack implementation for iterative bounding box refinement</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bbox_embed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># if True:</span>
            <span class="c1">#     每次得到的图像解码特征都用于细化参考点，之后细化边界框</span>
                <span class="n">tmp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bbox_embed</span><span class="p">[</span><span class="n">lid</span><span class="p">](</span><span class="n">output</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">reference_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
                    <span class="n">new_reference_points</span> <span class="o">=</span> <span class="n">tmp</span> <span class="o">+</span> <span class="n">inverse_sigmoid</span><span class="p">(</span><span class="n">reference_points</span><span class="p">)</span>
                    <span class="n">new_reference_points</span> <span class="o">=</span> <span class="n">new_reference_points</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">assert</span> <span class="n">reference_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span>
                    <span class="n">new_reference_points</span> <span class="o">=</span> <span class="n">tmp</span>
                    <span class="n">new_reference_points</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="n">inverse_sigmoid</span><span class="p">(</span><span class="n">reference_points</span><span class="p">)</span>
                    <span class="n">new_reference_points</span> <span class="o">=</span> <span class="n">new_reference_points</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span>
                <span class="n">reference_points</span> <span class="o">=</span> <span class="n">new_reference_points</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_intermediate</span><span class="p">:</span>
                <span class="n">intermediate</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
                <span class="n">intermediate_reference_points</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reference_points</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_intermediate</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">intermediate</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">intermediate_reference_points</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">reference_points</span>
</code></pre></div>
<blockquote>
<p>注：以上仅是笔者个人见解，若有问题，欢迎指正。</p>
</blockquote>
<p>初步完稿于：2023年8月</p>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": [], "search": "../../assets/javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.cd18aaf1.min.js"></script>
      
        <script src="../../mathjax-config.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
      
        <script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
      
    
  </body>
</html>