{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\u7b80\u4ecb","text":"<p>\u672c\u4eba\u7814\u7a76\u65b9\u5411\u4e3a\u8ba1\u7b97\u673a\u89c6\u89c9</p> <p>\u8fd9\u662f\u6211\u7684\u4e2a\u4eba\u535a\u5ba2\uff0c\u7528\u6765\u8bb0\u5f55\u5e73\u65f6\u7684\u5b66\u4e60\u7b14\u8bb0</p> <p>\u521a\u5f00\u59cb\u63a5\u89e6\u79d1\u7814\uff0c\u6c34\u5e73\u6bd4\u8f83\u6709\u9650\uff0c\u5982\u679c\u6587\u4e2d\u6709\u9519\u8bef\u7684\u5730\u65b9\u6b22\u8fce\u6279\u8bc4\u6307\u6b63</p> <p>\u8054\u7cfb\u65b9\u5f0f\uff1a</p> <p>QQ\uff1a1045283851</p> <p>Email\uff1affuxiang2021@163.com</p>"},{"location":"fined_domain/","title":"\u7ec6\u7c92\u5ea6/\u57df\u9002\u5e94\u7b14\u8bb0","text":"<ul> <li> <p>\u7ec6\u7c92\u5ea6\u8bba\u6587\u7b14\u8bb0\u5df2\u79fb\u6b65\u81f3CSDN\u4e13\u680f\u300a\u7ec6\u7c92\u5ea6\u5206\u7c7b\u7ecf\u5178\u8bba\u6587\u53ca\u6e90\u7801\u7b14\u8bb0\u300b\uff1ahttps://blog.csdn.net/qq_50001789/category_12357788.html\uff08fine-grained/sum_fine\uff09</p> </li> <li> <p>\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u8bba\u6587\u7b14\u8bb0\u5df2\u79fb\u6b65\u81f3CSDN\u4e13\u680f\u300a\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u8bba\u6587\u4ee5\u53ca\u6e90\u7801\u7b14\u8bb0\u300b\uff1ahttps://blog.csdn.net/qq_50001789/category_12358377.html\uff08domain_adaptive/sum_domain\u3001domain_adaptive/question\uff09</p> </li> </ul>"},{"location":"resume/","title":"\u4e2a\u4eba\u7b80\u5386","text":""},{"location":"resume/#_2","title":"\u672c\u79d1\u6210\u679c","text":""},{"location":"resume/#_3","title":"\u5956\u5b66\u91d1","text":"<ul> <li>2023\u5e74\u7b2c\u516b\u5c4a\u9f50\u9c81\u5de5\u4e1a\u5927\u5b66\u6821\u957f\u5956\u5b66\u91d1</li> <li>2022\u5e74\u672c\u4e13\u79d1\u751f\u56fd\u5bb6\u5956\u5b66\u91d1</li> <li>\u5b66\u4e60\u6210\u7ee9\u4f18\u79c0\u5956\u5b66\u91d1\uff08\u4e00\u7b49\u5956\u5b66\u91d1\uff09</li> </ul>"},{"location":"resume/#_4","title":"\u79d1\u7814\u6210\u679c","text":"<p>\u5b66\u672f\u8bba\u6587</p> <ul> <li>Feng F, Dong H, Zhang Y, et al. MS-ALN: Multiscale Attention Learning Network for Pest Recognition[J]. IEEE Access, 2022, 10: 40888-40898.</li> <li>Feng F, Zhang Y, Zhang W, et al. Progressive dense feature fusion network for single image deraining[J]. Pattern Recognition Letters, 2023.</li> </ul> <p>\u53d1\u660e\u4e13\u5229</p> <ul> <li>\u57fa\u4e8e\u9010\u6b65\u5bc6\u96c6\u7279\u5f81\u878d\u5408\u53bb\u96e8\u7f51\u7edc\u7684\u56fe\u50cf\u53bb\u96e8\u65b9\u6cd5\u53ca\u7cfb\u7edf\uff0c\u5df2\u6388\u6743</li> <li>\u57fa\u4e8e\u5bf9\u6297\u5b66\u4e60\u7684\u5355\u5e45\u56fe\u50cf\u53bb\u96e8\u65b9\u6cd5\u53ca\u7cfb\u7edf\uff0c\u5b9e\u5ba1\u9636\u6bb5</li> <li>\u4e00\u79cd\u57fa\u4e8e\u591a\u5c3a\u5ea6\u6ce8\u610f\u529b\u5b66\u4e60\u7f51\u7edc\u7684\u5bb3\u866b\u8bc6\u522b\u65b9\u6cd5\u53ca\u7cfb\u7edf\uff0c\u5b9e\u5ba1\u9636\u6bb5</li> <li>\u57fa\u4e8e\u7279\u5f81\u9009\u62e9\u6a21\u5757\u7684\u6797\u4e1a\u5bb3\u866b\u8bc6\u522b\u65b9\u6cd5\u53ca\u7cfb\u7edf\uff0c\u5b9e\u5ba1\u9636\u6bb5</li> </ul> <p>\u6ce8\uff1a\u53d1\u660e\u4e13\u5229\u5747\u662f\u5bfc\u5e08\u4e00\u4f5c\uff0c\u672c\u4eba\u4e8c\u4f5c</p> <p>\u8f6f\u4ef6\u8457\u4f5c\u6743</p> <ul> <li>\u4e91\u7075\u519c\u4e1a\u5bb3\u866b\u8bc6\u522b\u7cfb\u7edfV1.0\uff08\u4e00\u4f5c\uff09</li> <li>\u4e91\u7075\u53e3\u7f69\u68c0\u6d4b\u7cfb\u7edfV1.0</li> </ul> <p>\u5927\u5b66\u751f\u521b\u65b0\u521b\u4e1a\u8bad\u7ec3\u8ba1\u5212</p> <ul> <li>\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u6797\u4e1a\u5bb3\u866b\u8bc6\u522b\u7cfb\u7edf\uff08\u56fd\u5bb6\u7ea7\u7acb\u9879\uff0c\u62c5\u4efb\u9879\u76ee\u8d1f\u8d23\u4eba\uff09</li> </ul>"},{"location":"resume/#_5","title":"\u7ade\u8d5b\u83b7\u5956","text":"<p>\u56fd\u5bb6\u7ea7\u5956\u9879</p> <ul> <li>2021\u5e74\u7b2c\u5341\u4e09\u5c4a\u5168\u56fd\u5927\u5b66\u751f\u6570\u5b66\u7ade\u8d5b\uff08\u975e\u6570\u5b66\u7c7b\uff09\u4e00\u7b49\u5956</li> <li>2020\u5e74\u4e2d\u56fd\u673a\u5668\u4eba\u5927\u8d5b\u4e00\u7b49\u5956</li> </ul> <p>\u7701\u7ea7\u5956\u9879</p> <ul> <li>2023\u5e74\u7b2c\u4e09\u5c4a\u5c71\u4e1c\u7701\u673a\u5668\u4eba\u53ca\u4eba\u5de5\u667a\u80fd\u5927\u8d5b\u4e09\u7b49\u5956</li> <li>2021\u5e74\u7b2c\u5341\u4e8c\u5c4a\u5c71\u4e1c\u7701\u5927\u5b66\u751f\u6570\u5b66\u7ade\u8d5b\uff08\u975e\u6570\u5b66\u7ec4\uff09\u4e00\u7b49\u5956</li> <li>2021\u5e74\u5168\u56fd\u5927\u5b66\u751f\u6570\u5b66\u5efa\u6a21\u7ade\u8d5b\u5c71\u4e1c\u8d5b\u533a\u4e00\u7b49\u5956</li> <li>2021\u5e74\u7b2c\u5341\u4e8c\u5c4a\u201c\u84dd\u6865\u676f\u201d\u5927\u8d5bPython\u7ec4\u5c71\u4e1c\u8d5b\u533a\u4e8c\u7b49\u5956</li> <li>2020\u5e74\u7b2c\u4e09\u5c4a\u5c71\u4e1c\u7701\u5927\u5b66\u751f\u4eba\u5de5\u667a\u80fd\u5927\u8d5b\u4e8c\u7b49\u5956</li> </ul>"},{"location":"resume/#_6","title":"\u5176\u4ed6\u5956\u9879","text":"<ul> <li>2023\u5c4a\u5c71\u4e1c\u7701\u4f18\u79c0\u6bd5\u4e1a\u751f\uff08\u672c\u79d1\u751f\uff09</li> <li>2023\u5c4a\u9f50\u9c81\u5de5\u4e1a\u5927\u5b66\u4f18\u79c0\u6bd5\u4e1a\u8bbe\u8ba1\uff08\u8bba\u6587\uff09</li> </ul> <p>\u4fee\u6539\u4e8e\uff1a2023\u5e745\u670821\u65e5</p>"},{"location":"LaTeX/symbol/","title":"LaTeX\u5b66\u4e60\u7b14\u8bb0\uff1a\u7279\u6b8a\u7b26\u53f7","text":"<p>\u53c2\u8003\u94fe\u63a5\uff1a</p> <ul> <li>https://www.zybuluo.com/codeep/note/163962</li> </ul>"},{"location":"LaTeX/symbol/#_1","title":"\u5e0c\u814a\u5b57\u6bcd","text":"<p>\u4ece\u5de6\u5230\u53f3\u4f9d\u6b21\u4e3a\uff1a\u5927\u5199\u5f62\u5f0f\uff08\u7b2c\u4e00\u4e2a\u5b57\u6bcd\u5927\u5199\uff09\u3001\u5c0f\u5199\u5f62\u5f0f\uff08\u7b2c\u4e00\u4e2a\u5b57\u6bcd\u5c0f\u5199\uff09\u3001\u5411\u91cf\u5f62\u5f0f\uff08\u4ee5var\u5f00\u5934\uff0c\u90e8\u5206\u5b57\u6bcd\u6709\uff09</p> LaTeX\u6e90\u7801 \u5b57\u6bcd LaTeX\u6e90\u7801 \u5b57\u6bcd \\Alpha\u3001\\alpha \\mathrm A\u3001\\alpha \\Beta\u3001\\beta \\mathrm B\u3001\\beta \\Gamma\u3001\\gamma\u3001\\digamma \\Gamma\u3001\\gamma\u3001\\digamma \\Delta\u3001\\dalta \\Delta\u3001\\delta \\Epsilon\u3001\\epsilon\u3001\\varepsilon \\mathrm E\u3001\\epsilon\u3001\\varepsilon \\Zeta\u3001\\zeta \\mathrm Z\u3001\\zeta \\Eta\u3001\\eta \\mathrm H\u3001\\eta \\Theta\u3001\\theta\u3001\\vartheta \\Theta\u3001\\theta\u3001\\vartheta \\Iota\u3001\\iota \\mathrm I\u3001\\iota \\Kappa\u3001\\kappa\u3001\\varkappa \\mathrm K\u3001\\kappa\u3001\\varkappa \\Lambda\u3001\\lambda \\Lambda\u3001\\lambda \\Mu\u3001\\mu \\mathrm M\u3001\\mu \\Nu\u3001\\nu \\mathrm N\u3001\\nu \\Xi\u3001\\xi \\Xi\u3001\\xi \\Omicron\u3001\\omicron \\mathrm O\u3001\\omicron \\Pi\u3001\\pi\u3001\\varpi \\Pi\u3001\\pi\u3001\\varpi \\Rho\u3001\\rho\u3001\\varrho \\mathrm P\u3001\\rho\u3001\\varrho \\Sigma\u3001\\sigma\u3001\\varsigma \\Sigma\u3001\\sigma\u3001\\varsigma \\Tau\u3001\\tau \\mathrm T\u3001\\tau \\Upsilon\u3001\\upsilon \\Upsilon\u3001\\upsilon \\Phi\u3001\\phi\u3001\\varphi \\Phi\u3001\\phi\u3001\\varphi \\Chi\u3001\\chi \\mathrm X\u3001\\chi \\Psi\u3001\\psi \\Psi\u3001\\psi \\Omega\u3001\\omega \\Omega\u3001\\omega"},{"location":"LaTeX/symbol/#_2","title":"\u5b57\u4f53","text":"<p>\u4ee5\u4e0b\u56db\u79cd\u4ec5\u652f\u6301\u5927\u5199\u5b57\u6bcd</p> <p>\u9ed1\u677f\u62a5\u7c97\u4f53</p> LaTeX\u6e90\u7801 \u5b57\u4f53\u6548\u679c LaTeX\u6e90\u7801 \u5b57\u4f53\u6548\u679c \\mathbb{ABCDEFGHI} \\mathbb{ABCDEFGHI} \\mathbb{JKLMNOPQR} \\mathbb{JKLMNOPQR} \\mathbb{STUVWXYZ} \\mathbb{STUVWXYZ} <p>\u82b1\u4f53</p> LaTeX\u6e90\u7801 \u5b57\u4f53\u6548\u679c LaTeX\u6e90\u7801 \u5b57\u4f53\u6548\u679c \\mathcal{ABCDEFGHI} \\mathcal{ABCDEFGHI} \\mathcal{JKLMNOPQR} \\mathcal{JKLMNOPQR} \\mathcal{STUVWXYZ} \\mathcal{STUVWXYZ} <p>\u624b\u5199\u4f53</p> LaTeX\u6e90\u7801 \u5b57\u4f53\u6548\u679c LaTeX\u6e90\u7801 \u5b57\u4f53\u6548\u679c \\scr{ABCDEFGHI} \\scr{ABCDEFGHI} \\scr{JKLMNOPQR} \\scr{JKLMNOPQR} \\scr{STUVWXYZ} \\scr{STUVWXYZ} <p>\u6570\u5b66\u659c\u4f53</p> LaTeX\u6e90\u7801 \u5b57\u4f53\u6548\u679c LaTeX\u6e90\u7801 \u5b57\u4f53\u6548\u679c \\mit{ABCDEFGHI} \\mit{ABCDEFGHI} \\mit{JKLMNOPQR} \\mit{JKLMNOPQR} \\mit{STUVWXYZ} \\mit{STUVWXYZ} <p>\u4ee5\u4e0b\u652f\u6301\u5168\u90e8\u5b57\u6bcd</p> <p>\u7f57\u9a6c\u4f53</p> LaTeX\u6e90\u7801 \u5b57\u4f53\u6548\u679c LaTeX\u6e90\u7801 \u5b57\u4f53\u6548\u679c \\rm{ABCDEFGHI} \\rm{ABCDEFGHI} \\rm{JKLMNOPQR} \\rm{JKLMNOPQR} \\rm{STUVWXYZ} \\rm{STUVWXYZ} \\rm{abcdefghi} \\rm{abcdefghi} \\rm{jklmnopqr} \\rm{jklmnopqr} \\rm{stuvwxyz} \\rm{stuvwxyz} <p>\u659c\u4f53</p> LaTeX\u6e90\u7801 \u5b57\u4f53\u6548\u679c LaTeX\u6e90\u7801 \u5b57\u4f53\u6548\u679c \\it{ABCDEFGHI} \\it{ABCDEFGHI} \\it{JKLMNOPQR} \\it{JKLMNOPQR} \\it{STUVWXYZ} \\it{STUVWXYZ} \\it{abcdefghi} \\it{abcdefghi} \\it{jklmnopqr} \\it{jklmnopqr} \\it{stuvwxyz} \\it{stuvwxyz} <p>\u7c97\u4f53</p> LaTeX\u6e90\u7801 \u5b57\u4f53\u6548\u679c LaTeX\u6e90\u7801 \u5b57\u4f53\u6548\u679c \\bf{ABCDEFGHI} \\bf{ABCDEFGHI} \\bf{JKLMNOPQR} \\bf{JKLMNOPQR} \\bf{STUVWXYZ} \\bf{STUVWXYZ} \\bf{abcdefghi} \\bf{abcdefghi} \\bf{jklmnopqr} \\bf{jklmnopqr} \\bf{stuvwxyz} \\bf{stuvwxyz} <p>\u7b49\u7ebf\u4f53</p> LaTeX\u6e90\u7801 \u5b57\u4f53\u6548\u679c LaTeX\u6e90\u7801 \u5b57\u4f53\u6548\u679c \\sf{ABCDEFGHI} \\sf{ABCDEFGHI} \\sf{JKLMNOPQR} \\sf{JKLMNOPQR} \\sf{STUVWXYZ} \\sf{STUVWXYZ} \\sf{abcdefghi} \\sf{abcdefghi} \\sf{jklmnopqr} \\sf{jklmnopqr} \\sf{stuvwxyz} \\sf{stuvwxyz} <p>\u6253\u5b57\u673a\u4f53</p> LaTeX\u6e90\u7801 \u5b57\u4f53\u6548\u679c LaTeX\u6e90\u7801 \u5b57\u4f53\u6548\u679c \\tt{ABCDEFGHI} \\tt{ABCDEFGHI} \\tt{JKLMNOPQR} \\tt{JKLMNOPQR} \\tt{STUVWXYZ} \\tt{STUVWXYZ} \\tt{abcdefghi} \\tt{abcdefghi} \\tt{jklmnopqr} \\rm{jklmnopqr} \\tt{stuvwxyz} \\tt{stuvwxyz} <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e742\u670819\u65e5</p>"},{"location":"Linux/Matterport3DSimulator%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/","title":"Matterport3DSimulator\u73af\u5883\u914d\u7f6e","text":"<p>github\u5b98\u65b9\u6559\u7a0b\uff1ahttps://github.com/peteanderson80/Matterport3DSimulator</p>"},{"location":"Linux/Matterport3DSimulator%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/#_1","title":"\u524d\u63d0\u51c6\u5907","text":"<ul> <li>\u4e0b\u8f7dMatterport3D Dataset\u6570\u636e\u96c6</li> <li>\u4e0b\u8f7d<code>docker</code>\uff1ahttps://blog.csdn.net/zzh516451964zzh/article/details/126019663\uff0c\u6b65\u9aa4\uff1a\u6dfb\u52a0\u5b98\u65b9\u5bc6\u94a5\u2192\u66f4\u65b0apt\u2192\u5728\u7ebf\u5b89\u88c5\uff0cdocker\u4ecb\u7ecd\uff1ahttps://www.bilibili.com/video/BV1ai421S7zj\u3001https://ruanyifeng.com/blog/2018/02/docker-tutorial.html</li> <li>\u5b89\u88c5<code>nvidia-docker</code>\uff0c\u53ef\u4ee5\u53c2\u8003\uff1ahttps://blog.csdn.net/BigData_Mining/article/details/99681168\uff0c\u5982\u679c<code>docker</code>\u7248\u672c\u5927\u4e8e19\uff0c\u5219\u53ef\u4ee5\u4e0d\u7528\u5b89\u88c5<code>nvidia-docker</code>\uff0c\u5177\u4f53\u539f\u56e0\u53ef\u89c1\u540e\u6587\uff1b</li> </ul> <p>\u6ce8\uff1a</p> <ul> <li>\u5982\u679c\u56e0\u4e3a\u7f51\u7edc\u95ee\u9898\uff0c\u65e0\u6cd5\u4e0b\u8f7d\u5bc6\u94a5\uff0c\u5219\u53ef\u4ee5\u4e0b\u8f7d\u5230\u672c\u5730\uff0c\u4e4b\u540e\u5728\u672c\u5730\u6dfb\u52a0\uff0c\u6559\u7a0b\uff1ahttps://blog.csdn.net/sunchaoyiA/article/details/81231000</li> <li>\u5982\u679c\u5728\u5b89\u88c5<code>docker-ce</code>\u8fc7\u7a0b\u62a5\u9519Package \u2018docker-ce\u2018 has no installation candidate\uff0c\u5219\u8bf4\u660eapt\u7684\u6e90\u8bbe\u7f6e\u7684\u4e0d\u5bf9\uff0c\u9700\u8981\u6362\u6e90\uff08\u53ef\u4ee5\u6362\u963f\u91cc\uff0c\u53c2\u8003\uff1ahttps://blog.csdn.net/gmaaa123/article/details/139682260\uff09</li> </ul>"},{"location":"Linux/Matterport3DSimulator%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/#dockermatterport3dsimulator","title":"\u6784\u5efa\u57fa\u4e8edocker\u7684Matterport3DSimulator\u73af\u5883","text":"<p>1\u3001\u5148\u514b\u9686Matterport3DSimulator\u4ed3\u5e93</p> <pre><code># Make sure to clone with --recursive\ngit clone --recursive https://github.com/peteanderson80/Matterport3DSimulator.git\n</code></pre> <p>\u5982\u679c\u4f60\u6ca1\u6709\u4f7f\u7528<code>\u2014\u2014recursive</code>\u514b\u9686\uff0c\u90a3\u4e48\u4f60\u9700\u8981\u4ece\u6839\u76ee\u5f55\u4e2d\u624b\u52a8\u514b\u9686pybind\u5b50\u6a21\u5757:</p> <pre><code>git submodule update --init --recursive\n</code></pre> <p>2\u3001\u6784\u5efadocker</p> <pre><code>cd Matterport3DSimulator\ndocker build -t mattersim:9.2-devel-ubuntu18.04 .\n</code></pre> <p>\u6307\u4ee4\u89e3\u91ca\uff1a\u8be5\u547d\u4ee4\u7528\u4e8e\u6784\u5efa\u4e00\u4e2a\u57fa\u4e8eDockerfile\u7684Docker\u955c\u50cf\uff0c\u5e76\u5c06\u5176\u547d\u540d\u4e3a <code>mattersim:9.2-devel-ubuntu18.04</code></p> <ul> <li> <p><code>docker build</code>\uff1a\u8fd9\u662f Docker \u6784\u5efa\u547d\u4ee4\uff0c\u7528\u4e8e\u6839\u636e\u5f53\u524d\u76ee\u5f55\u4e2d\u7684 <code>Dockerfile</code> \u6784\u5efa\u4e00\u4e2a Docker \u955c\u50cf\u3002<code>Dockerfile</code> \u5b9a\u4e49\u4e86\u955c\u50cf\u7684\u6784\u5efa\u6b65\u9aa4\u548c\u5185\u5bb9\uff1b</p> </li> <li> <p><code>-t mattersim:9.2-devel-ubuntu18.04</code>\uff1a<code>-t</code> \u662f <code>--tag</code> \u7684\u7f29\u5199\uff0c\u8868\u793a\u4e3a\u751f\u6210\u7684 Docker \u955c\u50cf\u6253\u6807\u7b7e\uff1b<code>mattersim:9.2-devel-ubuntu18.04</code> \u662f\u955c\u50cf\u7684\u540d\u79f0\u548c\u6807\u7b7e\uff08\u5176\u4e2d<code>mattersim</code> \u662f\u955c\u50cf\u7684\u540d\u79f0\uff1b<code>9.2-devel-ubuntu18.04</code> \u662f\u8be5\u955c\u50cf\u7684\u6807\u7b7e\uff08tag\uff09\uff0c\u7528\u4e8e\u6807\u8bc6\u8fd9\u4e2a\u955c\u50cf\u7684\u5177\u4f53\u7248\u672c\uff0c\u901a\u5e38\u6807\u7b7e\u4f1a\u6307\u793a\u8fd9\u4e2a\u955c\u50cf\u7684\u7528\u9014\u6216\u57fa\u7840\u73af\u5883\uff0c\u4f8b\u5982 <code>CUDA 9.2</code> \u548c `Ubuntu 18.04\uff09\uff1b</p> </li> <li><code>.</code>\uff1a\u8fd9\u4e2a\u70b9 (<code>.</code>) \u6307\u7684\u662f\u5f53\u524d\u76ee\u5f55\uff0c\u8868\u793a Docker \u5e94\u8be5\u5728\u5f53\u524d\u76ee\u5f55\u4e2d\u67e5\u627e <code>Dockerfile</code> \u6765\u6784\u5efa\u955c\u50cf\u3002\u5f53\u524d\u76ee\u5f55\u5305\u542b\u4e86\u6784\u5efa Docker \u955c\u50cf\u6240\u9700\u7684\u6587\u4ef6\u3001\u4ee3\u7801\u3001\u4f9d\u8d56\u7b49\u3002</li> </ul> <p>\u53ef\u80fd\u7684\u62a5\u9519\uff1a</p> <ul> <li>\u5728\u521b\u5efa\u955c\u50cf\u8fc7\u7a0b\u4e2d\uff0c\u5982\u679c\u62a5\u9519\u201cCannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?\u201d\uff0c\u5219\u9700\u8981\u6dfb\u52a0\u5b88\u62a4\u8fdb\u7a0b\uff0c\u53c2\u8003https://zhuanlan.zhihu.com/p/659684412</li> <li>connect: connection refused\uff1a\u65e0\u6cd5\u83b7\u53d6docker\uff0c\u5e38\u89c1\u7684\u65b9\u6cd5\u662f\u5207\u6362\u955c\u50cf\u6e90\uff08\u4f8b\u5982\u963f\u91cc\u3001\u7f51\u6613\uff09\uff0c\u65b9\u6cd5\u53ef\u4ee5\u53c2\u8003https://cloud.tencent.com/developer/article/2429585\uff0c\u5982\u679c\u6362\u4e86\u56fd\u5185\u5e38\u89c1\u7684\u955c\u50cf\u6e90\u8fd8\u662f\u4e0d\u884c\uff0c\u5219\u53ef\u4ee5\u53c2\u8003https://www.cnblogs.com/lxzcloud/p/18354640</li> </ul> <p>\u68c0\u67e5\u6784\u5efa\u7ed3\u679c\uff1a</p> <ul> <li>\u53ef\u4ee5\u4f7f\u7528docker images\u6307\u4ee4\u6765\u67e5\u770bdocker\u662f\u5426\u6784\u5efa\u6210\u529f\uff0c\u6b63\u5e38\u6765\u8bf4\u4f1a\u8f93\u51fa\u5982\u4e0b\u5185\u5bb9\uff0c<code>mattersim</code>\u5c31\u662f\u6240\u6784\u5efa\u7684docker</li> </ul> <pre><code>REPOSITORY      TAG                     IMAGE ID       CREATED         SIZE\nmattersim       9.2-devel-ubuntu18.04   c4e3d9dfa099   19 hours ago    6.61GB\n</code></pre> <p>3\u3001\u51c6\u5907\u6570\u636e\u96c6</p> <p>\u2003\u2003\u4e0b\u8f7d\u89e3\u538b\u6240\u4e0b\u8f7d\u7684\u6570\u636e\u96c6\uff0c\u5e76\u4e14\u8bbe\u7f6e\u4e00\u4e2a\u73af\u5883\u53d8\u91cf\uff0c\u7528\u4e8e\u8868\u793a\u6570\u636e\u96c6\u7684\u4f4d\u7f6e\uff08\u540e\u7eed\u542f\u52a8docker\u7684\u65f6\u5019\u9700\u8981\u7528\u5230\u8fd9\u4e2a\u53d8\u91cf\uff0c\u8fd9\u91cc\u8981\u586b\u7edd\u5bf9\u8def\u5f84\uff09</p> <pre><code>sudo vim ~/.bashrc\n</code></pre> <p>\u6dfb\u52a0\u5982\u4e0b\u5185\u5bb9</p> <pre><code>export MATTERPORT_DATA_DIR=&lt;PATH&gt;\n</code></pre> <p>\u4e4b\u540e\u6fc0\u6d3b\u73af\u5883</p> <pre><code>source ~./bashrc\n</code></pre> <p>4\u3001\u542f\u52a8docker</p> <p>\u2003\u2003\u5728\u542f\u52a8\u4e4b\u524d\uff0c\u8981\u4fdd\u8bc1\u547d\u4ee4\u884c\u6240\u5728\u7684\u8def\u5f84\u662f\u521a\u624d\u514b\u9686\u7684<code>Matterport3DSimulator</code>\u4ed3\u5e93\u76ee\u5f55\uff0c\u4e4b\u540e\uff0c\u6267\u884c\u8be5\u6307\u4ee4\u8fdb\u5165docker\u5bb9\u5668</p> <pre><code>nvidia-docker run -it --mount type=bind,source=$MATTERPORT_DATA_DIR,target=/root/mount/Matterport3DSimulator/data/v1/scans --volume `pwd`:/root/mount/Matterport3DSimulator mattersim:9.2-devel-ubuntu18.04\n</code></pre> <p>\u5982\u679cdocker\u7684\u5b89\u88c5\u7248\u672c\u8d85\u8fc719\uff0c\u5219\u53ef\u4ee5\u901a\u8fc7\u5982\u4e0b\u6307\u4ee4\u6765\u8fdb\u5165docker\u5bb9\u5668</p> <pre><code>docker run -it --gpus all --mount type=bind,source=$MATTERPORT_DATA_DIR,target=/root/mount/Matterport3DSimulator/data/v1/scans --volume `pwd`:/root/mount/Matterport3DSimulator mattersim:9.2-devel-ubuntu18.04\n</code></pre> <p>\u89e3\u91ca\uff1a\u6211\u4eec\u4f7f\u7528<code>nvidia-docker</code>\u6307\u4ee4\u542f\u52a8docker\u7684\u76ee\u7684\u5c31\u662f\u4e3a\u4e86\u53ef\u4ee5\u5728docker\u4e2d\u76f4\u63a5\u4f7f\u7528\u672c\u673a\u7684GPU\u8d44\u6e90\uff0c\u800c\u5728docker19.03\u4e2d\uff0c\u589e\u52a0\u4e86<code>--gpus</code>\u9009\u9879\uff0c\u5728\u542f\u52a8\u8fc7\u7a0b\u4e2d\u5982\u679c\u4f7f\u7528\u4e86\u8be5\u9009\u9879\uff0c\u5219\u53ef\u4ee5\u5728docker\u4e2d\u76f4\u63a5\u8c03\u7528GPU\uff0c\u4e0d\u5fc5\u518d\u4f7f\u7528<code>nvidia-docker</code>\u76f8\u5173\u7684\u6307\u4ee4\u4e86\uff0c\u5176\u4e2d<code>--gpus all</code>\u8868\u793a\u4f7f\u7528\u672c\u673a\u4e0a\u7684\u6240\u6709GPU\u8d44\u6e90\u3002\u5728\u542f\u52a8\u7684docker\u91cc\u9762\u8f93\u5165<code>nvidia-smi</code>\u6307\u4ee4\uff0c\u5982\u679c\u53ef\u4ee5\u6b63\u5e38\u8f93\u51fa\u663e\u5361\u53c2\u6570\uff0c\u5219\u8bf4\u660e\u8be5docker\u53ef\u4ee5\u8c03\u7528\u672c\u673a\u4e0a\u7684GPU\u8d44\u6e90\u3002\u53c2\u8003\u94fe\u63a5\uff1ahttps://www.jianshu.com/p/32ad4f448fe5</p> <p>5\u3001\u7f16\u8bd1\u73af\u5883</p> <p>\u2003\u2003\u5728docker\u4e2d\u8fdb\u5165Matterport3DSimulator\u76ee\u5f55\uff08\u6b65\u9aa44\u4e2d\u8fdb\u5165Matterport3DSimulator\u76ee\u5f55\u662f\u542f\u52a8\u524d\u8fdb\u5165\uff0c\u8fd9\u91cc\u8fdb\u5165\u662fdocker\u542f\u52a8\u540e\u8fdb\u5165\uff09</p> <pre><code>cd /root/mount/Matterport3DSimulator\nmkdir build &amp;&amp; cd build\ncmake -DEGL_RENDERING=ON ..\nmake\n</code></pre> <p>\u8fd9\u4e00\u6b65\u662f\u4e3a\u4e86\u5b89\u88c5<code>MatterSim</code>\u5e93\uff0c\u5b89\u88c5\u5230\u7cfb\u7edf\u9ed8\u8ba4\u7684python\u73af\u5883\u4e0b\u9762\u3002\u8fd9\u91cc\u4e5f\u53ef\u4ee5\u5229\u7528<code>conda</code>\u65b0\u5efa\u4e00\u4e2a\u73af\u5883\uff0c\u4e4b\u540e\u5728\u65b0\u5efa\u7684\u73af\u5883\u5185\u90e8\u7f16\u8bd1\u5b89\u88c5<code>MatterSim</code>\u5e93\uff0c\u9700\u8981\u6267\u884c\u5982\u4e0b\u6307\u4ee4\u8fdb\u884c\u73af\u5883\u7f16\u8bd1\uff1a</p> <pre><code>cmake -D PYTHON_EXECUTABLE=[python\u89e3\u91ca\u5668\u7684\u8def\u5f84] -DEGL_RENDERING=ON ..\n# \u4f8b\u5982\uff1acmake -D PYTHON_EXECUTABLE=/root/miniconda3/envs/mattersim/bin/python -DEGL_RENDERING=ON ..\nmake\n</code></pre> <p>6\u3001\u6d4b\u8bd5API</p> <ul> <li>\u5728docker\u4e2d\u8fdb\u5165python3\u73af\u5883\uff0c\u4f7f\u7528<code>python</code>\u6307\u4ee4\u4f1a\u9ed8\u8ba4\u8fdb\u5165python2\u73af\u5883</li> </ul> <pre><code>python3\n</code></pre> <ul> <li>\u6d4b\u8bd5<code>MatterSim</code>\u5e93\uff0c\u5982\u679c\u4e0d\u62a5\u9519\uff0c\u8bf4\u660e\u73af\u5883\u914d\u7f6e\u6210\u529f</li> </ul> <pre><code>import MatterSim\n</code></pre> <p>\u5982\u679c\u63d0\u793a\u627e\u4e0d\u5230\uff0c\u5219\u53ef\u4ee5\u5c06build\u6587\u4ef6\u4e2d\u7684<code>MatterSim.cpython-39m-x86_64-linux-gnu.so</code>\uff08\u540d\u5b57\u8ddfPython\u7248\u672c\u53f7\u6709\u5173\uff09\u548c<code>libMatterSim.so</code>\u6587\u4ef6\u590d\u5236\u5230\u81ea\u5df1Python\u7684<code>site-packages</code>\u8def\u5f84\u4e0b\u9762\uff0c\u67e5\u770b\u5f53\u524d\u89e3\u91ca\u5668\u7684<code>site-packages</code>\u8def\u5f84\uff0c\u8def\u5f84\u4e00\u822c\u4e3a<code>anaconda3/envs/[\u73af\u5883\u540d]/lib/[python\u89e3\u91ca\u5668\u7248\u672c]/site-packages</code></p> <pre><code># \u67e5\u770bsite-packages\u8def\u5f84\npython3 # \u8fdb\u5165python\u73af\u5883\nimport site\nsite.getsitepackages()\n</code></pre> <p>\u590d\u5236\u8fc7\u53bb</p> <pre><code>cp MatterSim.cpython-39-x86_64-linux-gnu.so [site-packages\u8def\u5f84]\ncp libMatterSim.so [site-packages\u8def\u5f84]\n</code></pre> <p>\u5982\u679c\u5f15\u7528<code>MatterSim</code>\u4e0d\u62a5\u9519\uff0c\u5219\u8bf4\u660e\u73af\u5883\u914d\u7f6e\u6210\u529f\u3002</p>"},{"location":"Linux/Ubuntu%E5%AE%89%E8%A3%85Docker%E6%95%99%E7%A8%8B/","title":"Docker\u5b66\u4e60\u7b14\u8bb0\u2014\u2014Ubuntu\u4e0a\u7684\u5b89\u88c5\u6559\u7a0b\u4e0e\u5e38\u89c1\u6307\u4ee4","text":"<p>docker\u4ecb\u7ecd\uff1ahttps://ruanyifeng.com/blog/2018/02/docker-tutorial.html</p>"},{"location":"Linux/Ubuntu%E5%AE%89%E8%A3%85Docker%E6%95%99%E7%A8%8B/#_1","title":"\u5b89\u88c5\u6559\u7a0b","text":"<p>\u5b98\u65b9\u5b89\u88c5\u6559\u7a0b\uff1ahttps://docs.docker.com/engine/install/ubuntu/</p> <p>\u6b65\u9aa4\uff1a\u6dfb\u52a0\u5b98\u65b9\u5bc6\u94a5\u2192\u66f4\u65b0apt\u2192\u5728\u7ebf\u5b89\u88c5</p> <ul> <li>\u5b89\u88c5\u4f9d\u8d56\u5e93</li> </ul> <pre><code>sudo apt-get install ca-certificates curl\n</code></pre> <ul> <li>\u6dfb\u52a0\u5b98\u65b9\u5bc6\u94a5\uff1a</li> </ul> <pre><code>curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add -\n</code></pre> <p>\u9a8c\u8bc1\u662f\u5426\u62e5\u6709\u5e26\u6307\u7eb9\u7684\u5bc6\u94a5</p> <pre><code>sudo apt-key fingerprint 0EBFCD88\n</code></pre> <p>\u8f93\u51fa\u5982\u4e0b\u5185\u5bb9\uff0c\u5373\u4e3a\u6dfb\u52a0\u6210\u529f\uff1a</p> <pre><code>pub   rsa4096 2017-02-22 [SCEA]\n      9DC8 5822 9FC7 DD38 854A  E2D8 8D81 803C 0EBF CD88\nuid           [ unknown] Docker Release (CE deb) &lt;docker@docker.com&gt;\nsub   rsa4096 2017-02-22 [S]\n</code></pre> <ul> <li>\u8865\u5145\uff1a\u8bbe\u7f6e\u7a33\u5b9a\u7248\u4ed3\u5e93</li> </ul> <pre><code>add-apt-repository \"deb [arch=amd64] https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu/ $(lsb_release -cs) \\ stable\"\n</code></pre> <p>\u53c2\u8003\uff1ahttps://blog.csdn.net/zzh516451964zzh/article/details/126019663</p> <ul> <li>\u5b89\u88c5<code>docker</code>\u76f8\u5173\u7684\u5305</li> </ul> <p>\u66f4\u65b0<code>apt</code></p> <pre><code>apt-get update\n</code></pre> <p>\u5b89\u88c5\u6700\u65b0\u7248\u672c\u7684Docker Engine-Community</p> <pre><code>sudo apt-get install docker-ce docker-ce-cli containerd.io\n</code></pre> <ul> <li>\u5982\u679c\u5728\u5b89\u88c5<code>docker-ce</code>\u8fc7\u7a0b\u62a5\u9519Package \u2018docker-ce\u2018 has no installation candidate\uff0c\u5219\u8bf4\u660eapt\u7684\u6e90\u8bbe\u7f6e\u7684\u4e0d\u5bf9\uff0c\u9700\u8981\u6362\u6e90\uff08\u53ef\u4ee5\u6362\u963f\u91cc\uff0c\u53c2\u8003\uff1ahttps://blog.csdn.net/gmaaa123/article/details/139682260</li> </ul> <p>\u6d4b\u8bd5docker\u662f\u5426\u5b89\u88c5\u6210\u529f</p> <pre><code>docker version\n</code></pre> <p>\u8f93\u51fa</p> <pre><code>Client: Docker Engine - Community\n Version:           24.0.2\n API version:       1.43\n Go version:        go1.20.4\n Git commit:        cb74dfc\n Built:             Thu May 25 21:52:13 2023\n OS/Arch:           linux/amd64\n Context:           default\n</code></pre> <p>\u8bc1\u660e\u5b89\u88c5\u7684docker\u7248\u672c\u662f24.0.2</p> <ul> <li>\u5982\u679c\u62a5\u9519\u201cCannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?\u201d\uff0c\u5219\u9700\u8981\u6dfb\u52a0\u5b88\u62a4\u8fdb\u7a0b\uff0c\u53c2\u8003https://zhuanlan.zhihu.com/p/659684412</li> </ul>"},{"location":"Linux/Ubuntu%E5%AE%89%E8%A3%85Docker%E6%95%99%E7%A8%8B/#_2","title":"\u4e3a\u7528\u6237\u6dfb\u52a0\u6267\u884c\u6743\u9650","text":"<p>\u4e00\u822c\u6765\u8bf4\uff0cdocker\u6307\u4ee4\u7684\u6267\u884c\u9700\u8981<code>sudo</code>\u6743\u9650\uff0c\u4e0d\u52a0<code>sudo</code>\u4f1a\u62a5\u5982\u4e0b\u9519\u8bef\uff1a</p> <pre><code>/var/run/docker.sock: connect: permission denied\n</code></pre> <ul> <li>\u5c06\u666e\u901a\u7528\u6237username\u52a0\u5165\u5230docker\u7ec4</li> </ul> <pre><code>sudo gpasswd -a username docker\n</code></pre> <ul> <li>\u66f4\u65b0docker\u7ec4</li> </ul> <pre><code>newgrp docker\n</code></pre> <ul> <li>\u91cd\u542f<code>docker</code></li> </ul> <pre><code>sudo service docker restart\n</code></pre>"},{"location":"Linux/Ubuntu%E5%AE%89%E8%A3%85Docker%E6%95%99%E7%A8%8B/#_3","title":"\u5e38\u7528\u6307\u4ee4","text":"<ul> <li>\u5217\u51fa\u672c\u5730\u6240\u6709<code>docker</code></li> </ul> <pre><code>docker images\n</code></pre> <ul> <li>\u67e5\u770b\u6b63\u5728\u8fd0\u884c\u7684<code>docker</code></li> </ul> <pre><code>docker ps\n</code></pre> <p>\u5982\u679c\u52a0\u4e0a\u53c2\u6570<code>-a</code>\u5219\u4f1a\u540c\u6837\u8f93\u51fa\u672a\u8fd0\u884c\u7684\u5bb9\u5668</p> <ul> <li>\u521b\u5efa/\u8fd0\u884c<code>docker</code></li> </ul> <pre><code>docker run\n</code></pre> <ul> <li>\u5173\u95ed<code>docker</code></li> </ul> <pre><code>docker stop docker\u540d\u5b57/ID\n</code></pre> <ul> <li>\u6253\u5f00<code>docker</code></li> </ul> <pre><code>docker start docker\u540d\u5b57/ID\n</code></pre> <ul> <li>\u5220\u9664<code>docker</code></li> </ul> <pre><code>docker rm docker\u540d\u5b57/ID\n</code></pre> <ul> <li>\u67e5\u770b<code>docker</code>\u6240\u6709\u4fe1\u606f</li> </ul> <pre><code>docker inspect docker\u540d\u5b57/ID\n</code></pre>"},{"location":"Linux/docker_run/","title":"\u3010docker\u6307\u4ee4\u3011run\u6307\u4ee4\u2014\u2014\u542f\u52a8\u5bb9\u5668","text":"<p>\u529f\u80fd\uff1a\u542f\u52a8\u4e00\u4e2a\u5bb9\u5668</p>"},{"location":"Linux/docker_run/#_1","title":"\u521b\u5efa\u65b9\u5f0f","text":"<p>\u200b   \u4e3b\u8981\u6709\u4e24\u79cd\u521b\u5efa\u7b56\u7565\uff0c</p>"},{"location":"Linux/docker_run/#_2","title":"\u76ee\u5f55\u6302\u8f7d","text":"<p>\u200b   \u4e3b\u8981\u4f7f\u7528<code>--mount</code>\u53c2\u6570\u6765\u5c06\u4e3b\u673a\u4e0a\u7684\u5b58\u50a8\u6302\u8f7d\u5230docker\u4e2d\uff0c\u6302\u8f7d\u7c7b\u578b\u5305\u62ec\u4e09\u7c7b\uff1a<code>bind</code>\u3001<code>volumes</code>\u548c<code>tmpfs</code>\uff0c\u5e38\u7528\u7684\u683c\u5f0f\u4e3a\uff1a</p> <pre><code>docker run --mount type=&lt;\u7c7b\u578b&gt;,source=&lt;\u4e3b\u673a\u8def\u5f84&gt;,target=&lt;\u5bb9\u5668\u8def\u5f84&gt; &lt;docker_name&gt;\n</code></pre> <ul> <li><code>bind</code>\u6302\u8f7d\u7b56\u7565\uff1a\u5c06\u4e3b\u673a\u6587\u4ef6\u7cfb\u7edf\u4e2d\u7684\u4e00\u4e2a\u5177\u4f53\u76ee\u5f55\u6302\u8f7d\u5230\u5bb9\u5668\u4e2d\uff0c\u9002\u7528\u4e8e\u9700\u8981\u5c06\u4e3b\u673a\u4e0a\u7684\u7279\u5b9a\u6587\u4ef6\u6216\u76ee\u5f55\u5171\u4eab\u5230\u5bb9\u5668\u7684\u573a\u666f\u3002\u6302\u8f7d\u7684\u76ee\u5f55\u4e0e\u4e3b\u673a\u4e0a\u7684\u5b9e\u9645\u4f4d\u7f6e\u76f4\u63a5\u5173\u8054\uff0c\u4efb\u4f55\u5728\u5bb9\u5668\u5185\u7684\u4fee\u6539\u90fd\u4f1a\u7acb\u5373\u53cd\u6620\u5728\u4e3b\u673a\u4e0a\uff0c\u53cd\u4e4b\u4ea6\u7136\uff0c\u8def\u5f84\u4e2d\u7684\u6570\u636e\u5177\u6709\u4e00\u81f4\u6027\uff1b</li> </ul> <p>\u6ce8\u610f\uff1a\u5728\u591a\u4e2a\u5bb9\u5668\u5171\u4eab\u4e3b\u673a\u7684\u540c\u4e00\u76ee\u5f55\u65f6\uff0c\u6587\u4ef6\u7684\u8bfb\u5199\u6743\u9650\u53d6\u51b3\u4e8e\u4e3b\u673a\u4e0a\u7684\u6743\u9650\u8bbe\u7f6e\uff0c\u5982\u679c\u67d0\u4e2a\u5bb9\u5668\u4ee5\u7279\u5b9a\u7528\u6237\u8eab\u4efd\u8fd0\u884c\uff0c\u800c\u8be5\u7528\u6237\u6ca1\u6709\u5bf9\u4e3b\u673a\u76ee\u5f55\u7684\u8bbf\u95ee\u6743\u9650\uff0c\u90a3\u4e48\u5728\u5bb9\u5668\u4e2d\u6267\u884c\u6570\u636e\u8bfb\u5199\u65f6\uff0c\u53ef\u80fd\u4f1a\u5bfc\u81f4\u6743\u9650\u95ee\u9898\u3002</p> <ul> <li><code>volumes</code>\u6302\u8f7d\u7b56\u7565\uff1a</li> <li><code>tmpfs</code>\u6302\u8f7d\u7b56\u7565\uff1a</li> <li></li> </ul>"},{"location":"Linux/docker_run/#_3","title":"\u7aef\u53e3\u6620\u5c04","text":""},{"location":"Linux/docker_run/#_4","title":"\u8d44\u6e90\u5206\u914d","text":""},{"location":"Linux/%E8%BF%9C%E7%A8%8B%E8%AE%BF%E9%97%AEdocker%E7%8E%AF%E5%A2%83/","title":"ssh\u8fdc\u7a0b\u8bbf\u95eedocker\u73af\u5883","text":"<p>\u521b\u5efadocker\u7684\u65f6\u5019\uff0c\u9700\u8981\u52a0\u7aef\u53e3\u6620\u5c04</p> <p>\u4e3adocker\u955c\u50cf\u914d\u7f6essh-server</p> <ul> <li>\u5b89\u88c5ssh\u670d\u52a1</li> </ul> <pre><code>apt install openssh-server\n</code></pre> <ul> <li>\u4fee\u6539<code>/etc/ssh/sshd_config</code>\u6587\u4ef6\u91cc\u7684\u914d\u7f6e</li> </ul> <pre><code>vim /etc/ssh/sshd_config\n</code></pre> <p>\u5c06<code>#PermitRootLogin prohibit-password</code>\u4fee\u6539\u4e3a<code>PermitRootLogin yes</code></p> <ul> <li>\u8bbe\u7f6e\u5bc6\u7801passwd</li> </ul> <pre><code>passwd\n</code></pre> <ul> <li>\u91cd\u542fssh\u670d\u52a1</li> </ul> <pre><code>/etc/init.d/ssh restart\n% \u6216\u8005\nservice ssh start\n</code></pre> <p>\u51fa\u73b0\u5982\u4e0b\u5b57\u6837\uff0c\u8bf4\u660essh\u542f\u52a8\u6210\u529f</p> <pre><code>* Restarting OpenBSD Secure Shell server sshd\n</code></pre>"},{"location":"Linux/error/gpg_no_valid/","title":"\u3010Linux\u3011\u62a5\u9519\uff1a\u6dfb\u52a0\u5bc6\u94a5\u5931\u8d25\u2014\u2014gpg: no valid OpenPGP data found.","text":"<p>\u2003\u2003\u5728\u6dfb\u52a0GPG\u5b98\u65b9\u5bc6\u94a5\u65f6\uff0c\u6709\u65f6\u5019\u53ef\u80fd\u4f1a\u56e0\u4e3a\u7f51\u7edc\u95ee\u9898\uff0c\u65e0\u6cd5\u5728\u670d\u52a1\u5668\u7aef\u4e0b\u8f7d\u5bc6\u94a5\u6587\u4ef6\uff0c\u4f8b\u5982\uff1a</p> <pre><code># \u8fd9\u91cc\u62c9\u53d6docker-ce\u6240\u9700\u8981\u7684gpg\u5bc6\u94a5\nroot@ubuntu:~$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add -\ncurl: (22) The requested URL returned error: 404\ngpg: no valid OpenPGP data found.\n</code></pre> <p>\u6216\u8005</p> <pre><code># \u540c\u4e0a\nroot@ubuntu:~$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add -\ncurl: (35) Recv failure: Connection reset by peer\ngpg: no valid OpenPGP data found\n</code></pre> <p>\u5bf9\u6b64\uff0c\u6211\u4eec\u53ef\u4ee5\u5c06GPG key\u4e0b\u8f7d\u5230\u672c\u5730\u7535\u8111\uff0c\u7136\u540e\u4e0a\u4f20\u5230\u8fdc\u7a0b\u670d\u52a1\u5668\uff0c\u5728Windows\u7cfb\u7edf\u4e2d\uff0c\u76f4\u63a5\u6253\u5f00\u94fe\u63a5\u5c31\u53ef\u4ee5\u4e0b\u8f7d</p> <pre><code>https://download.docker.com/linux/ubuntu/gpg\n</code></pre> <p>\u4e4b\u540e\u4f20\u5230\u8fdc\u7a0b\u670d\u52a1\u5668\uff0c\u6267\u884c\u5982\u4e0b\u547d\u4ee4\uff0c\u53ef\u4ee5\u5c06GPG \u516c\u94a5\u6dfb\u52a0\u5230<code>apt</code>\u7684\u53d7\u4fe1\u4efb\u5bc6\u94a5\u5217\u8868\u4e2d\uff1a</p> <pre><code>sudo apt-key add [gpg\u8def\u5f84]\n</code></pre>"},{"location":"Linux/error/linux1/","title":"[Linux]\u62a5\u9519\uff1aFailed CC version check. Bailing out!","text":"<p>\u539f\u56e0\uff1agcc\u7248\u672c\u4e0d\u517c\u5bb9</p>"},{"location":"Linux/error/linux1/#_1","title":"\u89e3\u51b3\u65b9\u6cd5","text":"<p>1\u3001\u6267\u884c<code>cat /proc/version</code>\u67e5\u770b\u76ee\u524d\u7cfb\u7edf\u7248\u672c\u4e0b\u7684gcc\u9ed8\u8ba4\u7248\u672c</p> <p> <p></p> <p></p> <p>2\u3001\u6267\u884c<code>gcc --version</code>\u67e5\u770bgcc\u7248\u672c</p> <p> <p></p> <p></p> <p>\u8fd9\u91cc\u6211\u5df2\u7ecf\u6539\u597d\u4e86\uff0c\u4fee\u6539\u4e4b\u524d\u663e\u793a\u7248\u672c\u4e3a9.0\uff0c\u548c\u7cfb\u7edf\u9ed8\u8ba4\u7684\u7248\u672c\u4e0d\u5339\u914d</p> <p>3\u3001\u6267\u884c<code>ls /usr/bin/gcc*</code>\u67e5\u770b\u7cfb\u7edf\u4e2d\u76ee\u524d\u6240\u6709\u7684gcc\u7248\u672c</p> <p> <p></p> <p></p> <p>\u5982\u679c\u6709\u548c\u7cfb\u7edf\u76f8\u5339\u914d\u7684\u7248\u672c\uff0c\u5982\u8fd9\u91cc\u7684gcc-7\uff0c\u5219\u6267\u884c\u5982\u4e0b\u6307\u4ee4\u4fee\u6539\u4f18\u5148\u7ea7</p> <pre><code>update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-7 100\n</code></pre> <p>\u5982\u679c\u6ca1\u6709\u548c\u7cfb\u7edf\u76f8\u5339\u914d\u7684\u7248\u672c\uff0c\u5219\u9700\u8981\u5148\u5b89\u88c5\u6307\u5b9a\u7248\u672c\u7684gcc\uff0c\u518d\u6267\u884c\u4e0a\u8ff0\u6307\u4ee4</p> <p>4\u3001\u518d\u6b21\u6267\u884c<code>gcc --version</code>\u67e5\u770b\u7248\u672c\u4fe1\u606f</p> <p> <p></p> <p></p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e744\u67084\u65e5</p>"},{"location":"Linux/error/sum_error/","title":"\u62a5\u9519\u6c47\u603b","text":""},{"location":"Linux/error/sum_error/#linux","title":"Linux","text":"<ul> <li>[Linux]\u62a5\u9519\uff1aFailed CC version check. Bailing out!</li> </ul>"},{"location":"Linux/error/sum_error/#_2","title":"\u9a71\u52a8","text":"<ul> <li>ubuntu18\u65e0\u6cd5\u4e0a\u7f51\uff0c\u6ca1\u6709\u7f51\u7edc\u8fde\u63a5\u56fe\u6807\uff0c\u6709\u53ef\u80fd\u662fubuntu\u81ea\u5e26\u7684\u7f51\u5361\u9a71\u52a8\u68c0\u6d4b\u4e0d\u5230\u7f51\u5361\uff0c\u53c2\u8003\uff1ahttps://blog.csdn.net/weixin_44359479/article/details/123019056</li> </ul>"},{"location":"Linux/error/sum_error/#nvidia","title":"NVIDIA","text":"<ul> <li> <p>[NVIDIA]\u9a71\u52a8\u62a5\u9519\uff1aNVIDIA-SMI has failed because it couldn\u2018t communicate with the NVIDIA driver</p> </li> <li> <p>[Nvidia]\u9a71\u52a8\u62a5\u9519\uff1aFailed to initialize NVML Driver/library version mismatch\uff0c\u53c2\u8003\uff1ahttps://blog.csdn.net/zywvvd/article/details/115500412</p> </li> <li>[Nvidia]\u9a71\u52a8\u5b89\u88c5\u62a5\u9519\uff1aAn NVIDIA kernel module \u2018nvidia-xxx\u2019 appears to already be loaded in your kernel</li> </ul>"},{"location":"Linux/error/sum_error/#docker","title":"docker\u76f8\u5173","text":"<ul> <li>Matterport3D\u6a21\u62df\u5668\u5b89\u88c5\uff0c\u62a5\u9519read: connection reset by peer\uff0c\u6362\u5e38\u89c1\u7684\u56fd\u5185\u6e90\u65e0\u6548\uff0c\u53ef\u4ee5\u5c1d\u8bd5\u6362\u4e00\u4e0b\u56fd\u5185\u5176\u4ed6\u7684\u6e90\uff1ahttps://www.cnblogs.com/lxzcloud/p/18354640</li> </ul> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u4e8e\uff1a2022\u5e744\u670820\u65e5</p>"},{"location":"Linux/error/nvidia/nvidia1/","title":"[NVIDIA]\u9a71\u52a8\u62a5\u9519\uff1aNVIDIA-SMI has failed because it couldn\u2018t communicate with the NVIDIA driver","text":"<p>\u6267\u884c\u6307\u4ee4<code>nvidia-smi</code>\u62a5\u9519\u5982\u4e0b\uff1a</p> <p> <p></p> <p></p> <p>\u9010\u6b65\u6392\u67e5</p> <p>1\u3001\u6267\u884c<code>nvcc -V</code>\u6307\u4ee4\u68c0\u67e5\u9a71\u52a8\u548ccuda</p> <p> <p></p> <p></p> <p>\u53d1\u73b0\u9a71\u52a8\u548ccuda\u5747\u5b58\u5728</p> <p>2\u3001\u67e5\u770b\u5df2\u5b89\u88c5\u7684\u9a71\u52a8</p> <pre><code>ls /usr/src | grep nvidia\n</code></pre> <p> <p></p> <p></p> <p>\u53d1\u73b0\u9a71\u52a8\u7248\u672c\u5b58\u5728</p> <p>\u539f\u56e0</p> <p>\u2003\u2003\u5982\u679c\u8be5\u73b0\u8c61\u5b58\u5728\u4e8eubuntu\u7cfb\u7edf\u4e2d\uff0c\u5219\u591a\u534a\u662f\u7531\u4e8e\u7cfb\u7edf\u5347\u7ea7\u4e86\u5185\u6838\uff0c\u5bfc\u81f4\u65b0\u7248\u672c\u7684\u5185\u6838\u548c\u539f\u6765\u7684\u663e\u5361\u9a71\u52a8\u4e0d\u5339\u914d\u3002</p>"},{"location":"Linux/error/nvidia/nvidia1/#_1","title":"\u89e3\u51b3\u65b9\u6cd5","text":"<p>1\u3001\u67e5\u770bnvidia\u7248\u672c\u53f7</p> <pre><code>ll /usr/src\n</code></pre> <p> <p></p> <p></p> <p>2\u3001\u5b89\u88c5dkms</p> <pre><code>sudo apt-get install dkms\n</code></pre> <p>3\u3001\u6267\u884c\u6307\u4ee4</p> <pre><code>sudo dkms install -m nvidia -v 455.45.01\n</code></pre> <p>\u7b49\u5f85\u5b89\u88c5\u5b8c\u6210\u4e4b\u540e\u518d\u6b21\u8f93\u5165\u6307\u4ee4<code>nvidia-smi</code>\uff0c\u67e5\u770bGPU\u60c5\u51b5</p> <p>\u6ce8\uff1a\u5982\u679c\u5b89\u88c5\u4e0d\u4e86\uff0c\u62a5\u9519<code>Failed CC version check. Bailing out!</code>\uff0c\u53ef\u53c2\u8003\uff1a[Linux]\u62a5\u9519\uff1aFailed CC version check. Bailing out!</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e744\u67084\u65e5</p>"},{"location":"Linux/error/nvidia/nvidia2/","title":"[Nvidia]\u9a71\u52a8\u5b89\u88c5\u62a5\u9519\uff1aAn NVIDIA kernel module \u2018nvidia-xxx\u2019 appears to already be loaded in your kernel","text":"<p>\u5b89\u88c5NVIDIA\u8fc7\u7a0b\u4e2d\u62a5\u9519</p> <p> <p></p> <p></p> <p>\u539f\u56e0\uff1a\u4ecd\u6709\u8fdb\u7a0b\u4f7f\u7528nvidia\u76f8\u5173\u7684\u7ec4\u4ef6\uff0c\u5bfc\u81f4nvidia\u7ec4\u4ef6\u672a\u5220\u5e72\u51c0\uff0c\u8fd9\u91ccxxx\u53ef\u4ee5\u8868\u793a\u6210uvm\u3001modeset\uff0cdrm\u7b49\u3002</p>"},{"location":"Linux/error/nvidia/nvidia2/#_1","title":"\u89e3\u51b3\u65b9\u6cd5","text":"<p>1\u3001\u6267\u884c\u4e0b\u8ff0\u547d\u4ee4\uff0c\u67e5\u770b\u7cfb\u7edf\u4e2dnvidia\u76f8\u5173\u7684\u6a21\u5757</p> <pre><code>lsmod | grep nvidia\n</code></pre> <p> <p></p> <p></p> <p>\u8fd9\u91cc\u53ef\u4ee5\u53d1\u73b0\u7cfb\u7edf\u4e2d\u4ecd\u6709nvidia_uvm\u6a21\u5757</p> <p>2\u3001\u6267\u884c\u4e0b\u8ff0\u547d\u4ee4\uff0c\u67e5\u770b\u6709\u54ea\u4e9b\u8fdb\u7a0b\u4f7f\u7528nvidia*</p> <pre><code>sudo lsof -n -w /dev/nvidia*\n</code></pre> <p> <p></p> <p></p> <p>3\u3001\u6267\u884ckill\u6307\u4ee4\u6740\u6b7b\u8fdb\u7a0b\uff0c\u76f4\u5230\u6267\u884c\u547d\u4ee4\u2461\u65f6\u4ec0\u4e48\u90fd\u4e0d\u663e\u793a</p> <pre><code>sudo kill 211380\n</code></pre> <p>4\u3001\u5220\u9664nvidia\u76f8\u5173\u7684\u7ec4\u4ef6</p> <pre><code>sudo rmmod nvidia_uvm\nsudo rmmod nvidia\n</code></pre> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e744\u67084\u65e5</p>"},{"location":"Linux/instruct/PID/","title":"Linux\u6839\u636e\u8fdb\u7a0bPID\u67e5\u770b\u8fdb\u7a0b\u4fe1\u606f","text":""},{"location":"Linux/instruct/PID/#ps","title":"ps\u6307\u4ee4","text":"<p>\u2003\u2003\u5728Ubuntu\uff08\u4ee5\u53ca\u5176\u4ed6\u7c7bUnix\u7cfb\u7edf\uff09\u4e2d\uff0c<code>ps</code>\uff08Process Status\uff09\u662f\u4e00\u4e2a\u7528\u4e8e\u663e\u793a\u5f53\u524d\u8fd0\u884c\u8fdb\u7a0b\u4fe1\u606f\u7684\u547d\u4ee4\u3002</p> <ul> <li><code>-e</code>\uff1a\u663e\u793a\u6240\u6709\u8fdb\u7a0b\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u5f53\u524d\u7528\u6237\u7684\u8fdb\u7a0b\uff1b</li> <li><code>-f</code>\uff1a\u663e\u793a\u5b8c\u6574\u7684\u8fdb\u7a0b\u4fe1\u606f\uff0c\u5305\u62ec\uff1aUID\uff08\u8fdb\u7a0b\u6240\u6709\u8005\u7684\u7528\u6237ID\uff09\u3001PID\uff08\u8fdb\u7a0bID\uff09\u3001PPID\uff08\u7236\u8fdb\u7a0bID\uff0c\u8868\u793a\u542f\u52a8\u8be5\u8fdb\u7a0b\u7684\u7236\u8fdb\u7a0bID\uff09\u3001C\uff08CPU\u4f7f\u7528\u7684\u767e\u5206\u6bd4\uff09\u3001STIME\uff08\u8fdb\u7a0b\u542f\u52a8\u7684\u65f6\u95f4\uff08\u8d77\u59cb\u65f6\u95f4\uff09\uff09\u3001TTY\uff08\u8fdb\u7a0b\u5173\u8054\u7684\u7ec8\u7aef\u7c7b\u578b\uff09\u3001TIME\uff08\u8fdb\u7a0b\u5360\u7528CPU\u7684\u603b\u65f6\u95f4\uff09\u3001CMD\uff08\u542f\u52a8\u8fdb\u7a0b\u65f6\u4f7f\u7528\u7684\u547d\u4ee4\uff09\uff1b</li> <li><code>-u</code>\uff1a\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u683c\u5f0f\u663e\u793a\u8fdb\u7a0b\u4fe1\u606f\uff0c\u53ef\u4ee5\u7528\u4e8e\u6307\u5b9a\u663e\u793a\u54ea\u4e2a\u7528\u6237\uff1b</li> <li><code>-l</code>\uff1a\u663e\u793a\u957f\u683c\u5f0f\u7684\u8f93\u51fa\uff0c\u5305\u62ec\u66f4\u591a\u7684\u5217\uff0c\u5982F\uff08\u8fdb\u7a0b\u6807\u8bb0\uff09\u3001S\uff08\u72b6\u6001\uff09\u3001PRI\uff08\u4f18\u5148\u7ea7\uff09\u3001NI\uff08Nice\u503c\uff09\u3001RSS\uff08\u5b9e\u9645\u5185\u5b58\u5927\u5c0f\uff09\u7b49;</li> <li><code>-o</code>\uff1a\u4ee5\u81ea\u5b9a\u4e49\u683c\u5f0f\u663e\u793a\u8fdb\u7a0b\u4fe1\u606f\uff1b</li> <li><code>--forest</code>\uff1a\u4ee5\u6811\u72b6\u7ed3\u6784\u663e\u793a\u8fdb\u7a0b\uff1b</li> </ul> <p>\u4e0d\u540c\u65b9\u6cd5\u53ef\u4ee5\u5b9e\u73b0\u7ec4\u5408\uff0c\u4f8b\u5982</p> <pre><code># \u663e\u793a\u6240\u6709\u8fdb\u7a0b\u7684\u8be6\u7ec6\u4fe1\u606f\nps -ef\n# \u4ee5\u6811\u72b6\u7ed3\u6784\u663e\u793aroot\u7528\u6237\u7684\u6240\u6709\u8fdb\u7a0b\u4fe1\u606f\nps -u root -f --forest\n# \u4ee5\u6307\u5b9a\u8f93\u51fa\u683c\u5f0f\u663e\u793aroot\u7528\u6237\u6240\u6709\u8fdb\u7a0b\u4fe1\u606f\uff0c\u5305\u62ecPID\u3001\u7528\u6237\u3001\u547d\u4ee4\u3001CPU\u4f7f\u7528\u7387\u548c\u5185\u5b58\u4f7f\u7528\u7387\nps -u root -o pid,user,cmd,%cpu,%mem\n</code></pre> <p>\u6ce8\uff1a</p> <ul> <li>\u53ef\u4ee5\u4f7f\u7528<code>grep</code>\u6765\u7b5b\u9009\u51fa\u5305\u542b\u7279\u5b9a\u8fdb\u7a0b\u540d\u79f0\u7684\u8fdb\u7a0b\u4fe1\u606f\uff0c\u4f8b\u5982\uff1a</li> </ul> <pre><code>ps -ef | grep \u8fdb\u7a0bID\n</code></pre> <p>\u8fd9\u884c\u6307\u4ee4\u7684\u4f5c\u7528\u76f8\u5f53\u4e8e\uff1a\u5f97\u5230\u6240\u6709\u8fdb\u7a0b\u7684\u8be6\u7ec6\u4fe1\u606f\uff08\u901a\u8fc7<code>-ef</code>\u5b9e\u73b0\uff09\uff0c\u5e76\u4e14\u7b5b\u9009\u51fa\u5305\u542b\u7279\u5b9a\u8fdb\u7a0bID\u7684\u8fdb\u7a0b\u4fe1\u606f\uff08\u901a\u8fc7<code>grep</code>\u5b9e\u73b0\uff09\uff0c\u6700\u7ec8\u663e\u793a\u5230\u7ec8\u7aef\u3002</p>"},{"location":"Linux/instruct/PID/#proc","title":"proc\u6587\u4ef6\u5939","text":"<p> <code>/proc</code> \u6587\u4ef6\u7cfb\u7edf\u662f\u4e00\u4e2a\u865a\u62df\u7684\u6587\u4ef6\u7cfb\u7edf\uff0c\u63d0\u4f9b\u4e86\u5173\u4e8e\u7cfb\u7edf\u5185\u6838\u3001\u8fdb\u7a0b\u548c\u786c\u4ef6\u8bbe\u5907\u7684\u4fe1\u606f\u3002\u5728Linux\u7cfb\u7edf\u4e2d\uff0c<code>/proc</code> \u76ee\u5f55\u662f\u4e00\u4e2a\u91cd\u8981\u7684\u7cfb\u7edf\u76ee\u5f55\uff0c\u5b83\u5141\u8bb8\u7528\u6237\u548c\u7cfb\u7edf\u7ba1\u7406\u5458\u901a\u8fc7\u67e5\u770b\u548c\u64cd\u4f5c\u6587\u4ef6\u6765\u83b7\u53d6\u5173\u4e8e\u7cfb\u7edf\u72b6\u6001\u548c\u5185\u6838\u53c2\u6570\u7684\u5b9e\u65f6\u4fe1\u606f\u3002</p> <ul> <li>\u5229\u7528<code>ll</code>\u65b9\u6cd5\u53ef\u4ee5\u67e5\u770b\u6587\u4ef6\u4fe1\u606f\uff0c\u5176\u4e2d<code>cwd</code>\u6307\u5411\u811a\u672c\u5730\u5740\uff0c<code>exe</code>\u6307\u5411\u53ef\u6267\u884c\u6587\u4ef6\u7684\u5730\u5740\uff0c\u5728\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u8bad\u7ec3\u6a21\u578b\u4e2d\uff0c<code>cwd</code>\u6307\u5411\u4ee3\u7801\u5730\u5740\u3001<code>exe</code>\u6307\u5411\u73af\u5883\u5730\u5740\uff1b</li> <li><code>/proc/[PID]/cmdline</code>\uff1a\u5305\u542b\u542f\u52a8\u8fdb\u7a0b\u7684\u5b8c\u6574\u547d\u547d\u4ee4\u884c</li> </ul> <pre><code>cat /proc/[PID]/cmdline\n</code></pre> <ul> <li><code>/proc/[PID]/status</code>\uff1a\u5305\u542b\u6709\u5173\u8fdb\u7a0b\u7684\u8be6\u7ec6\u72b6\u6001\u4fe1\u606f\uff0c\u5982\u8fdb\u7a0bID\u3001\u7236\u8fdb\u7a0bID\u3001\u7528\u6237ID\u3001\u8fdb\u7a0b\u72b6\u6001\u3001\u5185\u5b58\u4f7f\u7528\u7b49\u7b49</li> </ul> <pre><code>cat /proc/[PID]/status\n</code></pre> <ul> <li><code>/proc/[PID]/environ</code>\uff1a\u5305\u542b\u8fdb\u7a0b\u73af\u5883\u53d8\u91cf\u7684\u503c\uff0c\u4ee5 null \u5b57\u7b26\u4e32\uff08\\0\uff09\u5206\u9694</li> </ul> <pre><code>cat /proc/[PID]/environ\n</code></pre>"},{"location":"Linux/instruct/apt/","title":"apt\u547d\u4ee4","text":"<p>\u529f\u80fd\uff1aUbuntu\u3001Debian\u7cfb\u7edf\u4e2d\u67e5\u627e\u3001\u5b89\u88c5\u3001\u5347\u7ea7\u3001\u5220\u9664\u67d0\u4e2a\u4ee5\u53ca\u4e00\u7ec4\u8f6f\u4ef6\u5305\uff0c\u6267\u884capt\u547d\u4ee4\u9700\u8981\u8d85\u7ea7\u7ba1\u7406\u5458\u6743\u9650(root)</p> <p>\u8bed\u6cd5\uff1a</p> <pre><code>apt [options] [command] [package]\n</code></pre> <ul> <li><code>options</code>\uff1a\u5e38\u7528\u53ef\u9009\u9879\uff0c\u5982<code>-h</code>\uff08\u5e2e\u52a9\u6587\u6863\uff09\u3001<code>-y</code>\uff08\u5b89\u88c5\u8fc7\u7a0b\u4e2d\u63d0\u793a\u7684\u9009\u62e9\u5168\u90e8\u201dyes\u201d\uff09\u3001<code>-q</code>\uff08\u4e0d\u663e\u793a\u5b89\u88c5\u8fc7\u7a0b\uff09\u7b49\u7b49\uff1b</li> <li><code>command</code>\uff1a\u6267\u884c\u7684\u64cd\u4f5c\uff1b</li> <li><code>package</code>\uff1a\u8f6f\u4ef6\u5305\u540d\u79f0\u3002</li> </ul>"},{"location":"Linux/instruct/apt/#_1","title":"\u5e38\u7528\u7684\u547d\u4ee4\u64cd\u4f5c","text":"<ul> <li><code>install</code>\uff1a\u5b89\u88c5\u6307\u5b9a\u7684\u8f6f\u4ef6\u5305\uff0c\u5982\u679c\u5df2\u7ecf\u5b89\u88c5\uff0c\u5219\u4f1a\u8fdb\u4e00\u6b65\u68c0\u67e5\u8be5\u8f6f\u4ef6\u5305\u662f\u5426\u8981\u5347\u7ea7\uff08\u6b64\u65f6\u8be5\u6307\u4ee4\u4f5c\u7528\u4e0e<code>upgrade</code>\u76f8\u540c\uff09</li> </ul> <pre><code># \u5b89\u88c5\u5355\u4e2a\u8f6f\u4ef6\u5305\nsudo apt install &lt;package_name&gt;\n# \u5b89\u88c5\u591a\u4e2a\u8f6f\u4ef6\u5305\uff0c\u4e2d\u95f4\u4ee5\u7a7a\u683c\u9694\u5f00\nsudo apt install &lt;package_name1&gt; &lt;package_name2&gt; &lt;package_name3&gt; ...\n# \u5b89\u88c5\u6307\u5b9a\u7248\u672c\u7684\u8f6f\u4ef6\nsudo apt install &lt;package_name&gt;=&lt;version_number&gt;\n# \u5b89\u88c5\u6307\u5b9a\u7684\u8f6f\u4ef6\u5305\uff0c\u5982\u679c\u5df2\u7ecf\u5b89\u88c5\uff0c\u5219\u4e0d\u5347\u7ea7\u5b83\nsudo apt install &lt;package_name&gt; --no-upgrade\n# \u53ea\u5347\u7ea7\u6307\u5b9a\u7684\u8f6f\u4ef6\u5305\uff0c\u5982\u679c\u8be5\u8f6f\u4ef6\u5305\u4e0d\u5b58\u5728\uff0c\u5219\u4e0d\u9700\u8981\u5b89\u88c5\u5b83\nsudo apt install &lt;package_name&gt; --only-upgrade\n</code></pre> <ul> <li><code>remove</code>\uff1a\u79fb\u9664\u6307\u5b9a\u7684\u8f6f\u4ef6\u5305</li> </ul> <pre><code>sudo apt remove &lt;package_name&gt;\n</code></pre> <ul> <li><code>purge</code>\uff1a\u79fb\u9664\u8f6f\u4ef6\u5305\u53ca\u914d\u7f6e\u6587\u4ef6</li> </ul> <pre><code>sudo apt purge &lt;package_name&gt;\n</code></pre> <ul> <li><code>update</code>\uff1a\u68c0\u67e5\u6240\u6709\u5b89\u88c5\u7684\u8f6f\u4ef6\u5305\u662f\u5426\u6709\u53ef\u7528\u7684\u66f4\u65b0\uff0c\u6ce8\u610f\u8fd9\u91cc\u53ea\u68c0\u67e5\uff0c\u4e0d\u66f4\u65b0</li> </ul> <pre><code>sudo apt update\n</code></pre> <ul> <li> <p><code>list</code>\uff1a\u5217\u51fa\u5305\u542b\u6307\u5b9a\u6761\u4ef6\u7684\u8f6f\u4ef6\u5305</p> </li> <li> <p><code>shell   # \u5217\u51fa\u6240\u6709\u53ef\u5347\u7ea7\u7684\u8f6f\u4ef6\u5305   apt list --upgradeable   # \u5217\u51fa\u6240\u6709\u5df2\u5b89\u88c5\u7684\u8f6f\u4ef6\u5305   apt list --installed   # \u5217\u51fa\u6240\u6709\u5df2\u5b89\u88c5\u8f6f\u4ef6\u7684\u7248\u672c\u4fe1\u606f   apt list --all-versions</code></p> </li> <li> <p><code>upgrade</code>\uff1a\u66f4\u65b0\u6307\u5b9a\u7684\u8f6f\u4ef6\u5305\uff0c\u6267\u884c<code>upgrade</code>\u4e4b\u524d\uff0c\u6700\u597d\u5148\u6267\u884c<code>update</code>\u68c0\u67e5\u4e00\u904d</p> </li> </ul> <pre><code>sudo apt upgrade &lt;package_name&gt;\n</code></pre> <ul> <li><code>dist-upgrade</code>\uff1a\u66f4\u65b0\u6307\u5b9a\u7684\u8f6f\u4ef6\u5305\uff0c\u540c\u65f6\u667a\u80fd\u5904\u7406\u8f6f\u4ef6\u5305\u7684\u4f9d\u8d56\uff0c\u540c<code>upgrade</code>\u4e00\u6837\uff0c\u6267\u884c\u4e4b\u524d\u6700\u597d\u6267\u884c\u4e00\u904d<code>update</code>\u68c0\u67e5\u4e00\u4e0b\u53ef\u7528\u7684\u66f4\u65b0</li> </ul> <pre><code>sudo apt dist-upgrade &lt;package_name&gt;\n</code></pre> <ul> <li><code>search</code>\uff1a\u67e5\u627e\u5173\u952e\u5b57\u4e3a&lt;keyword&gt;\u7684\u76f8\u5173\u8f6f\u4ef6\u5305\uff0c\u53ef\u4ee5\u67e5\u672a\u5b89\u88c5\u7684\u8f6f\u4ef6\u5305</li> </ul> <pre><code>sudo apt search &lt;keyword&gt;\n</code></pre> <ul> <li><code>show</code>\uff1a\u663e\u793a\u6307\u5b9a\u8f6f\u4ef6\u5305\u7684\u76f8\u5173\u4fe1\u606f\uff0c\u540c<code>search</code>\u4e00\u6837\uff0c\u4e5f\u53ef\u4ee5\u663e\u793a\u7cfb\u7edf\u672a\u5b89\u88c5\u7684\u8f6f\u4ef6\u5305\u4fe1\u606f</li> </ul> <pre><code>sudo apt show &lt;package_name&gt;\n</code></pre> <p>\u6700\u540e\u4fee\u6539\u4e8e\uff1a2022\u5e744\u67087\u65e5</p>"},{"location":"Linux/instruct/bypy/","title":"Linux\u5229\u7528\u767e\u5ea6\u7f51\u76d8\u4e0a\u4f20/\u4e0b\u8f7d\u6570\u636e\u2014\u2014bypy\u6307\u4ee4","text":"<p>\u5b89\u88c5bypy</p> <pre><code>pip install bypy\n</code></pre> <p>\u6388\u6743\u767e\u5ea6\u7f51\u76d8\u8d26\u6237\u4fe1\u606f</p> <pre><code>bypy info\n</code></pre> <p>\u8f93\u51fa</p> <pre><code>Please visit:\nhttps://openapi.baidu.com/oauth/2.0/authorize?client_id=q8WE4EpCsau1oS0MplgMKNBn&amp;response_type=code&amp;redirect_uri=oob&amp;scope=basic+netdisk\nAnd authorize this app\nPaste the Authorization Code here within 10 minutes.\nPress [Enter] when you are done\n</code></pre> <p>\u70b9\u5f00\u5730\u5740\uff0c\u4e4b\u540e\u5c06\u6388\u6743\u7801\u8f93\u5165\u5230\u7ec8\u7aef\u7a97\u53e3\uff0c\u4e4b\u540e\u6309\u56de\u8f66\u5373\u53ef\u5b8c\u6210\u6388\u6743\uff0c\u6388\u6743\u6210\u529f\u540e\uff0c\u518d\u6b21\u8f93\u5165<code>bypy info</code>\u53ef\u4ee5\u663e\u793a\u767e\u5ea6\u7f51\u76d8\u5b58\u50a8\u5360\u7528\u91cf\uff0c\u4f8b\u5982\uff1a</p> <pre><code>Quota: 12.293TB\nUsed: 3.398TB\n</code></pre>"},{"location":"Linux/instruct/bypy/#_1","title":"\u5e38\u7528\u6307\u4ee4","text":"<p>\u67e5\u770b\u6587\u4ef6\u5217\u8868</p> <pre><code>bypy list\n</code></pre> <p>\u8be5\u547d\u4ee4\u4f1a\u67e5\u770b\u767e\u5ea6\u7f51\u76d8\u4e2d\uff0c\u201c\u6211\u7684\u5e94\u7528\u6570\u636e\u201d\u6587\u4ef6\u5939\u5185\u7684\u6240\u6709\u6587\u4ef6\uff0c\u4f8b\u5982\u5728\u8fd9\u91cc\u6211\u6709\u4e24\u4e2a\u6587\u4ef6\u5939\u201cCOCO2014\u201d\u548c\u201cBDD100K\u201d\uff1a</p> <pre><code>/apps/bypy ($t $f $s $m $d):\nD BDD100K 0 2024-01-22, 19:58:40\nD COCO2014 0 2024-01-22, 19:46:28\n</code></pre> <p>\u4e0b\u8f7d\u6587\u4ef6</p> <p>\u4ece\u767e\u5ea6\u7f51\u76d8\u4e0b\u8f7d\u5355\u4e2a\u6587\u4ef6</p> <pre><code>bypy downfile &lt;remotefile&gt; [localpath]\n</code></pre> <p>\u4ece\u767e\u5ea6\u7f51\u76d8\u4e0b\u8f7d\u6574\u4e2a\u6587\u4ef6</p> <pre><code>bypy downdir &lt;remotefile&gt; [localpath]\n</code></pre> <p>\u6ce8\uff1a\u4e0b\u8f7d\u6587\u4ef6\u65f6\uff0c\u53ef\u4ee5\u4f7f\u7528\u7b2c\u4e09\u65b9\u5de5\u5177aria2\u6765\u52a0\u901f\u4e0b\u8f7d\uff0c\u5e38\u7528\u6307\u4ee4\uff1a</p> <pre><code># \u5b89\u88c5aria2\nsudo apt-get install aria2\n# \u7528\u53c2\u6570'--downloader aria2'\u6765\u8ba9bypy\u8c03\u7528aria2\u5de5\u5177\u6765\u52a0\u901f\u4e0b\u8f7d\nbypy --downloader aria2 download [remotepath] [localpath]\n</code></pre> <p>\u4e0a\u4f20\u6587\u4ef6</p> <pre><code>bypy upload &lt;localpath&gt; [remotepath] [ondup]\n</code></pre> <p><code>[ondup]</code>\u8868\u793a\u5982\u679c\u8fdc\u7a0b\u76ee\u5f55\u6709\u91cd\u547d\u6587\u4ef6\uff0c\u8be5\u5982\u4f55\u64cd\u4f5c\uff0c\u53ef\u9009<code>overwrite</code>\uff08\u8986\u76d6\u3001\u9ed8\u8ba4\u9009\u9879\uff09\u548c<code>newcopy</code>\uff08\u521b\u5efa\u4e00\u4e2a\u65b0\u7684\u6587\u4ef6\u540d\uff09\u3002\u6216</p> <pre><code>bypy syncup &lt;localdir&gt; [remotedir] [deleteremote]\n</code></pre> <p><code>[deleteremote]</code>\u8868\u793a\u662f\u5426\u5220\u9664\u4e0d\u5728\u672c\u5730\u76ee\u5f55\u5185\u7684\u8fdc\u7a0b\u6587\u4ef6\uff08\u5373\u767e\u5ea6\u7f51\u76d8\u4e2d\u7684\u6587\u4ef6\uff09\uff0c\u9ed8\u8ba4<code>False</code></p> <p>\u67e5\u8be2\u6587\u6863</p> <p>\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528\u547d\u4ee4<code>bypy help &lt;command&gt;</code>\u6765\u67e5\u8be2\u4e00\u4e2a\u547d\u4ee4\u7684\u4f7f\u7528\u65b9\u5f0f\u4ee5\u53ca\u53c2\u6570\u89e3\u91ca\uff0c\u4f8b\u5982</p> <pre><code>bypy help upload\n</code></pre> <p>\u4f7f\u7528<code>bypy help</code>\u6216<code>bypy -h</code>\u53ef\u4ee5\u67e5\u8be2\u6240\u6709\u547d\u4ee4</p> <p>\u9000\u51fa\u767b\u5f55</p> <pre><code>bypy -c\n</code></pre> <p>\u5229\u7528Python\u5b9e\u73b0\u5229\u7528bypy\u4e0a\u4f20/\u4e0b\u8f7d\u6587\u4ef6</p> <pre><code># \u5bfc\u5165\u5e93\nfrom bypy import ByPy\n# \u5b9e\u4f8b\u5316bypy\u5bf9\u8c61\nbp = ByPy()\n# \u767e\u5ea6\u7f51\u76d8\u521b\u5efa\u8fdc\u7a0b\u6587\u4ef6\u5939\nbp.mkdir(remotepath = '')\n# \u4e0a\u4f20\u6587\u4ef6\nbp.upload(localpath = '', remotepath = '', ondup = \"overwrite\")\n# \u4e0b\u8f7d\u6587\u4ef6\nbp.download(remotepath = '/', localpath = '')\n</code></pre> <p>\u53c2\u8003\u94fe\u63a5</p> <p>https://tsukkomi.org/post/download-baidu-pan-with-bypy</p> <p>https://www.cnblogs.com/nulige/articles/10950613.html</p>"},{"location":"Linux/instruct/conda_pip/","title":"\u73af\u5883\u914d\u7f6e\u76f8\u5173","text":""},{"location":"Linux/instruct/conda_pip/#_2","title":"\u5e38\u7528\u6307\u4ee4","text":""},{"location":"Linux/instruct/conda_pip/#conda","title":"conda","text":"<ul> <li>\u67e5\u770b\u73b0\u6709\u7684\u865a\u62df\u73af\u5883\uff1a</li> </ul> <pre><code>conda env list\n</code></pre> <ul> <li>\u521b\u5efa\u865a\u62df\u73af\u5883\uff1a</li> </ul> <pre><code>conda create -n \u73af\u5883\u540d (python\u7248\u672c)\n# \u4f8b\u5982conda create -n torch python=3.9\n</code></pre> <ul> <li>\u590d\u5236\u865a\u62df\u73af\u5883</li> </ul> <p>```# \u590d\u5236\u865a\u62df\u73af\u5883 conda create -n traget_env_name \u2013clone source_env_name <pre><code>- \u6fc0\u6d3b\u865a\u62df\u73af\u5883\uff1a\n\n```shell\nconda activate \u73af\u5883\u540d\n</code></pre></p> <ul> <li>\u5220\u9664\u865a\u62df\u73af\u5883\uff1a</li> </ul> <pre><code>conda remove -n \u73af\u5883\u540d --all\n</code></pre> <ul> <li>\u5b89\u88c5\u5305\uff1a</li> </ul> <pre><code>conda install \u5305\u540d\n# \u5b89\u88c5\u6307\u5b9a\u7248\u672c\nconda install \u5305\u540d=\u7248\u672c\u53f7 \n</code></pre> <ul> <li>\u5347\u7ea7\u5305\uff08\u5347\u5230\u6700\u65b0\u7248\u672c\uff09\uff1a</li> </ul> <pre><code>conda update \u5305\u540d\n</code></pre> <ul> <li>\u5378\u8f7d\u5305\uff1a</li> </ul> <pre><code>conda remove \u5305\u540d\n</code></pre> <ul> <li>\u641c\u7d22\u5305\uff1a</li> </ul> <pre><code>conda search \u5173\u952e\u8bcd\n</code></pre> <ul> <li>\u5bfc\u51fa\u3001\u5b89\u88c5\u73af\u5883\uff08\u6587\u4ef6\u4f1a\u5bfc\u51fa\u5230\u6267\u884c\u5f53\u524d\u547d\u4ee4\u65f6\u6240\u5728\u7684\u76ee\u5f55\uff09\uff1a</li> </ul> <pre><code># \u5bfc\u51fa\u5f53\u524d\u73af\u5883\u7684\u6240\u6709\u5305\u53ca\u5176\u4f9d\u8d56\u9879\nconda env export &gt; environment.yaml\n# \u6839\u636eyaml\u6587\u4ef6\u91cc\u5305\u7684\u4fe1\u606f\u6765\u521b\u5efa\u73af\u5883\nconda env create -f environment.yaml\n</code></pre> <ul> <li>\u66f4\u65b0conda</li> </ul> <pre><code># \u5c06conda\u672c\u8eab\u5347\u7ea7\u5230\u6700\u65b0\u7248\u672c\nconda update conda\n</code></pre>"},{"location":"Linux/instruct/conda_pip/#pip","title":"pip","text":"<ul> <li>\u5b89\u88c5\u5e93\uff1a</li> </ul> <pre><code>pip install \u5e93\u540d\n# \u5b89\u88c5\u6307\u5b9a\u7248\u672c\u7684\u5e93\npip install \u5e93\u540d==\u7248\u672c\u53f7\n</code></pre> <ul> <li>\u5347\u7ea7\u5e93\uff08\u5347\u5230\u6700\u65b0\u7248\u672c\uff09\uff1a</li> </ul> <pre><code>pip install --upgrade \u5e93\u540d\n</code></pre> <ul> <li>\u5378\u8f7d\u5e93\uff1a</li> </ul> <pre><code>pip uninstall \u5e93\u540d\n</code></pre> <ul> <li>\u5217\u51fa\u5df2\u5b89\u88c5\u7684\u5e93\uff1a</li> </ul> <pre><code>pip list\n</code></pre> <ul> <li>\u67e5\u770b\u5df2\u5b89\u88c5\u5e93\u7684\u8be6\u7ec6\u4fe1\u606f\uff1a</li> </ul> <pre><code>pip show \u5e93\u540d\n</code></pre> <ul> <li>\u5bfc\u51fa\u672c\u73af\u5883\u4e0b\u6240\u6709\u7684\u5e93\uff08\u6587\u4ef6\u4f1a\u5bfc\u51fa\u5230\u6267\u884c\u5f53\u524d\u547d\u4ee4\u65f6\u6240\u5728\u7684\u76ee\u5f55\uff09\uff1a</li> </ul> <pre><code># \u5bfc\u51fa\u5e93\u540d\u4ee5\u53ca\u7248\u672c\u53f7\npip freeze &gt; requirements.txt\n</code></pre> <ul> <li>\u6279\u91cf\u5b89\u88c5\u5e93</li> </ul> <pre><code># \u5b89\u88c5txt\u6587\u4ef6\u4e2d\u6240\u5217\u4e3e\u7684\u5e93\npip install -r requirements.txt\n</code></pre>"},{"location":"Linux/instruct/conda_pip/#_3","title":"\u6362\u6e90","text":"<pre><code># \u6e05\u534e\u5927\u5b66\nhttps://pypi.tuna.tsinghua.edu.cn/simple\n# \u7f51\u6613\nhttp://mirrors.163.com/\n# \u963f\u91cc\u4e91\nhttp://mirrors.aliyun.com/pypi/simple/\n# \u8c46\u74e3\nhttp://pypi.doubanio.com/simple/\n</code></pre> <p>\u6ce8\uff1a</p> <pre><code>pip install \u5b89\u88c5\u5305 -i \u955c\u50cf\u6e90\u5730\u5740\n</code></pre>"},{"location":"Linux/instruct/conda_pip/#_4","title":"\u5e38\u7528\u94fe\u63a5","text":"<ul> <li>CUDA\u4e0b\u8f7d\u5730\u5740\uff1ahttps://developer.nvidia.com/CUDA-TOOLKIT-ARCHIVE</li> </ul>"},{"location":"Linux/instruct/fuser/","title":"Linux\uff1afuser\u6307\u4ee4","text":"<p>\u529f\u80fd\uff1a\u7528\u4e8e\u663e\u793a\u54ea\u4e2a\u8fdb\u7a0b\u6b63\u5728\u4f7f\u7528\u7279\u5b9a\u7684\u6587\u4ef6\u3001\u76ee\u5f55\u6216\u5957\u63a5\u5b57</p>"},{"location":"Linux/instruct/screen/","title":"Linux\uff1ascreen\u547d\u4ee4","text":"<p>\u529f\u80fd\uff1a\u7ba1\u7406\u547d\u4ee4\u884c\u7ec8\u7aef\u5207\u6362\u7684\u8f6f\u4ef6\uff0c\u5e38\u7528\u4e8e\u8fdc\u7a0b\u8fde\u63a5Linux\u8fc7\u7a0b\u4e2d\uff0c\u540c\u65f6\u4f7f\u7528\u591a\u4e2a\u547d\u4ee4\u884c\u7a97\u53e3\u3002\u5728\u7a97\u53e3\u8fd0\u884c\u4e2d\u7684\u7a0b\u5e8f\uff0c\u5373\u4f7f\u65ad\u5f00ssh\u8fde\u63a5\uff0c\u7a0b\u5e8f\u4e5f\u53ef\u4ee5\u7ee7\u7eed\u8fd0\u884c\u3002</p> <p>1\u3001\u5b89\u88c5screen</p> <pre><code>sudo apt-get install screen\n</code></pre> <p>2\u3001\u521b\u5efascreen\u7a97\u53e3\uff0c\u53ef\u4ee5\u81ea\u53d6\u7a97\u53e3\u540d\u5b57\uff0c\u8fd9\u91cc\u7a97\u53e3\u88ab\u547d\u540d\u4e3ademo</p> <pre><code>screen -S demo\n</code></pre> <p>3\u3001\u521b\u5efa\u6210\u529f\u540e\uff0c\u53ef\u4ee5\u5728\u7a97\u53e3\u4e2d\u6267\u884c\u6307\u4ee4</p> <p> <p></p> <p></p> <p>4\u3001\u5982\u679c\u60f3\u8981\u9000\u51fa\u8be5\u7a97\u53e3\uff0c\u5219\u53ea\u9700\u6309<code>Ctrl-A D</code>\u952e\u5373\u53ef\uff0c\u9000\u51fa\u4e4b\u540e\u7a97\u53e3\u4e2d\u7684\u6307\u4ee4\u7a0b\u5e8f\u4ecd\u4f1a\u7ee7\u7eed\u6267\u884c</p> <p>5\u3001\u8f93\u5165\u4e00\u4e0b\u6307\u4ee4\u67e5\u770b\u7a97\u53e3\u5217\u8868</p> <pre><code>screen -ls\n</code></pre> <p> <p></p> <p></p> <p>\u8bb0\u4f4f\u7a97\u53e3\u540d\u5b57\u524d\u9762\u7684\u5e8f\u53f7\uff0c\u91cd\u65b0\u8fde\u63a5\u8be5\u7a97\u53e3\u65f6\u4f1a\u7528\u5230</p> <p>6\u3001\u91cd\u65b0\u8fde\u63a5\u7a97\u53e3</p> <pre><code>screen -r 568408\n</code></pre> <p>7\u3001\u5173\u95ed\uff08\u6740\u6b7b\uff09\u7a97\u53e3</p> <pre><code># \u5982\u679c\u5728\u7a97\u53e3\u4e2d\nexit\n# \u5982\u679c\u4e0d\u5728\u7a97\u53e3\u4e2d\uff08\u5373\u7a97\u53e3\u65e0\u6cd5\u8fde\u63a5\u4e86\uff09\nscreen -X -S id(\u7a97\u53e3id) quit\n</code></pre> <p>\u6ce8\uff1a</p> <ul> <li>\u5982\u679c\u5728<code>-ls</code>\u5c55\u793a\u65f6\uff0c\u7a97\u53e3\u63d0\u793aAttached\u72b6\u6001\uff08\u4f8b\u5982\u4e0a\u4e2a\u56fe\u4e2d\u7b2c\u4e09\u4e2a\u4f8b\u5b50\uff09\uff0c<code>-r</code>\u65e0\u6cd5\u76f4\u63a5\u8fde\u63a5\u7a97\u53e3\uff0c\u6b64\u65f6\u53ef\u4ee5\u4f7f\u7528<code>-d</code>\u65b9\u6cd5\u5206\u79bb\u5df2\u7ecf\u9644\u52a0\u7684\u4f1a\u8bdd\uff0c\u4e4b\u540e\u4f7f\u7528<code>-r</code>\u65b9\u6cd5\u53ef\u4ee5\u91cd\u65b0\u52a0\u8f7d\uff1a</li> </ul> <pre><code># \u5206\u79bb\u7a97\u53e3\nscreen -d ID\n# \u91cd\u65b0\u52a0\u8f7d\nscreen -r ID\n</code></pre>"},{"location":"PyTorch/question/","title":"PyTorch\u5e38\u89c1\u95ee\u9898","text":"<p>1\u3001cv2.resize()\u4e0etorchvision.transform.Resize()\u5bf9\u9f50\u4e0d\u4e00\u81f4\uff0c\u5bf9\u4e8e\u540c\u6837\u7684\u56fe\u50cf\u5904\u7406\u6d41\u7a0b\uff0c\u53ef\u80fd\u4f1a\u5f97\u5230\u4e0d\u540c\u7684\u7ed3\u679c\uff0c\u5176\u4e2dtorchvision\u4e2d\u7684\u5bf9\u9f50\u65b9\u6cd5\u4e0ePIL\u4e00\u81f4\uff0c\u8bad\u7ec3\u65f6\u6ce8\u610f\u4e00\u4e0b\u3002</p> <p>\u53c2\u8003\u94fe\u63a5\uff1a</p> <ul> <li>https://zhuanlan.zhihu.com/p/96544998</li> <li>https://blog.csdn.net/yangjinyi1314/article/details/127515519?spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EOPENSEARCH%7ERate-1-127515519-blog-112522370.pc_relevant_vip_default&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EOPENSEARCH%7ERate-1-127515519-blog-112522370.pc_relevant_vip_default&amp;utm_relevant_index=2</li> </ul>"},{"location":"PyTorch/sum_pytorch/","title":"PyTorch\u5b66\u4e60\u7b14\u8bb0\u6c47\u603b","text":"<p>PyTorch\u5b98\u65b9\u6587\u6863\uff1ahttps://pytorch.org/docs/stable/index.html</p>"},{"location":"PyTorch/sum_pytorch/#nn","title":"nn\u65b9\u6cd5","text":""},{"location":"PyTorch/sum_pytorch/#_1","title":"\u7f51\u7edc\u7ed3\u6784","text":"<ul> <li>nn.Linear\uff1a\u7ebf\u6027\u56de\u5f52</li> <li>nn.Conv2d\uff1a\u4e8c\u7ef4\u5377\u79ef</li> <li>nn.BatchNorm2d\uff1a\u6279\u91cf\u6807\u51c6\u5316</li> <li>nn.AvgPool2d\uff1a\u4e8c\u7ef4\u5e73\u5747\u6c60\u5316</li> <li>nn.AdaptiveAvgPool2d\uff1a\u4e8c\u7ef4\u81ea\u9002\u5e94\u5e73\u5747\u6c60\u5316</li> <li>nn.Dropout\uff1a\u968f\u673a\u4e22\u5f03</li> <li>nn.MultiheadAttention\uff1a\u591a\u5934\u6ce8\u610f\u529b</li> <li>nn.Embedding\u2014\u2014\u7f16\u7801\u6620\u5c04</li> </ul>"},{"location":"PyTorch/sum_pytorch/#_2","title":"\u6fc0\u6d3b\u51fd\u6570","text":"<ul> <li>nn.ReLU\uff1aReLU\u6fc0\u6d3b\u51fd\u6570</li> <li>nn.LeakyReLU\uff1aLeakyReLU\u6fc0\u6d3b\u51fd\u6570</li> <li>nn.PReLU\uff1aPReLU\u6fc0\u6d3b\u51fd\u6570</li> <li>nn.Sigmoid\uff1aSigmoid\u6fc0\u6d3b\u51fd\u6570</li> <li>nn.Tanh\uff1aTanh\u6fc0\u6d3b\u51fd\u6570</li> <li>nn.GELU\uff1aGELU\u6fc0\u6d3b\u51fd\u6570</li> </ul>"},{"location":"PyTorch/sum_pytorch/#_3","title":"\u635f\u5931\u51fd\u6570","text":"<ul> <li>nn.L1Loss\uff1aL1\u635f\u5931</li> <li>nn.MSELoss\uff1aMSE\u635f\u5931</li> <li>nn.CrossEntropyLoss\uff1a\u4ea4\u53c9\u71b5\u635f\u5931</li> <li>nn.KLDivLoss\uff1aKL\u6563\u5ea6\u635f\u5931</li> <li>nn.MarginRankingLoss\uff1a\u6392\u5e8f\u635f\u5931</li> <li>nn.SmoothL1Loss\uff1a\u5e73\u6ed1L1\u635f\u5931</li> <li>nn.TripletMarginLoss\uff1a\u4e09\u5143\u7ec4\u635f\u5931</li> </ul>"},{"location":"PyTorch/sum_pytorch/#nnfunctional","title":"nn.functional\u65b9\u6cd5","text":"<ul> <li>F.interpolate\uff1a\u6570\u7ec4\u91c7\u6837\u64cd\u4f5c</li> <li>F.normalize\uff1a\u6570\u7ec4\u5f52\u4e00\u5316\u64cd\u4f5c</li> </ul>"},{"location":"PyTorch/sum_pytorch/#utilsdata","title":"utils.data\u65b9\u6cd5","text":"<ul> <li>data.RandomSampler\uff1a\u968f\u673a\u91c7\u6837</li> <li>data.WeightedRandomSampler\uff1a\u6982\u7387\u91c7\u6837</li> <li>data.BatchSampler\uff1a\u5c01\u88c5batch</li> </ul>"},{"location":"PyTorch/sum_pytorch/#optim","title":"optim\u65b9\u6cd5","text":"<ul> <li>LambdaLR\uff1a\u81ea\u5b9a\u4e49\u5b66\u4e60\u7387\u53d8\u5316\u5668</li> </ul>"},{"location":"PyTorch/sum_pytorch/#torch","title":"torch\u65b9\u6cd5","text":"<ul> <li>torch.cat\u4e0etorch.stack\uff1a\u6570\u7ec4\u7684\u62fc\u63a5</li> <li>torch.chunk\uff1a\u6570\u7ec4\u7684\u62c6\u5206</li> <li>torch.clamp\uff1a\u6570\u7ec4\u7684\u5939\u7d27</li> <li>torch.div\uff1a\u6570\u7ec4\u7684\u2019\u70b9\u9664\u2019\u8fd0\u7b97</li> <li>torch.ge_gt_le_lt_ne_eq\uff1a\u9010\u5143\u7d20\u5bf9\u6bd4</li> <li>torch.from_numpy\uff1anumpy\u4e0etensor\u6570\u636e\u7c7b\u578b\u4e92\u6362</li> <li>torch.gather\uff1a\u6cbf\u7279\u5b9a\u7ef4\u5ea6\u6536\u96c6\u6570\u503c</li> <li>torch.index_select\uff1a\u6570\u7ec4\u7d22\u5f15</li> <li>torch.max\uff1a\u6570\u7ec4\u7684\u6700\u5927\u503c</li> <li>torch.mul\uff1a\u6570\u7ec4\u7684\u70b9\u4e58</li> <li>torch.nonzero\uff1a\u975e\u96f6\u5143\u7d20\u7684\u5b9a\u4f4d</li> <li>torch.repeat_interleave\u4e0etensor.repeat\uff1a\u6570\u7ec4\u7684\u91cd\u590d</li> <li>torch.squeeze\u4e0etorch.unsqueeze\uff1a\u6570\u7ec4\u7684\u538b\u7f29\u4e0e\u89e3\u538b</li> <li>torch.transpose\u4e0etensor.permute\uff1a\u4ea4\u6362\u6570\u7ec4\u7ef4\u5ea6</li> <li>torch.where\uff1a\u6570\u7ec4\u7684\u67e5\u8be2</li> </ul>"},{"location":"PyTorch/sum_pytorch/#_4","title":"\u5176\u4ed6\u65b9\u6cd5","text":"<ul> <li>hook\u6a21\u5757\uff1a\u63d0\u53d6\u4e2d\u95f4\u6570\u636e\uff0c\u5982\u7279\u5f81\u3001\u68af\u5ea6</li> <li>model.train() \u4e0emodel.eval()\uff1a\u5207\u6362\u6a21\u578b\u6a21\u5f0f\uff08\u5f71\u54cdBN\u3001Dropout\u8fd0\u7b97\uff09</li> <li>cuda\u65b9\u6cd5\uff1a\u83b7\u5f97\u663e\u5361\u4fe1\u606f</li> </ul> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2024\u5e742\u670821\u65e5</p>"},{"location":"PyTorch/data/data.BatchSampler/","title":"\u5c01\u88c5batch\u64cd\u4f5c","text":""},{"location":"PyTorch/data/data.BatchSampler/#_1","title":"\u6807\u51c6\u51fd\u6570","text":"<pre><code>torch.utils.data.BatchSampler(sampler, batch_size, drop_last)\n</code></pre> <p>\u529f\u80fd\uff1a\u5305\u88c5\u8f93\u5165\u7684\u91c7\u6837\u5668\uff0c\u4ece\u800c\u4ea7\u751f\u5c0f\u6279\u91cf\u6570\u636e(mini-batch)</p> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>sampler</code>\uff1a\u57fa\u7840\u7684\u91c7\u6837\u5668\uff0c\u53ef\u4ee5\u662f\u4efb\u4f55\u8fed\u4ee3\u5bf9\u8c61\uff0c\u6570\u636e\u7c7b\u578b\u4e3asampler \u6216\u8005iterable</li> <li><code>batch_size</code>\uff1abatch\u5927\u5c0f\uff0c\u6570\u636e\u7c7b\u578b\u4e3aint</li> <li><code>drop_last</code>\uff1a\u8bbe\u4e3a<code>True</code>\u65f6\uff0c\u5982\u679c\u8fed\u4ee3\u5230\u6700\u540e\u5269\u4f59\u7684\u6837\u672c\u6570\u4e0d\u8db3\u4ee5\u6784\u6210\u4e00\u4e2abatch\uff0c\u5219\u4f1a\u4e22\u5f03\u6700\u540e\u7684\u6570\u636e\uff0c\u5426\u5219\u4e0d\u4e22\u5f03\uff0c\u6570\u636e\u7c7b\u578b\u4e3abool</li> </ul>"},{"location":"PyTorch/data/data.BatchSampler/#_2","title":"\u4ee3\u7801\u6848\u4f8b","text":"<p>\u4e00\u822c\u7528\u6cd5</p> <pre><code>from torch.utils.data.sampler import BatchSampler\n\nbatch = BatchSampler(range(10), batch_size=3, drop_last=False)\nfor i in batch:\n    print(i)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code>[0, 1, 2]\n[3, 4, 5]\n[6, 7, 8]\n# \u5982\u679cdrop_last\u8bbe\u4e3aTrue\uff0c\u5219\u4e0d\u4f1a\u8f93\u51fa\u6700\u540e\u4e00\u4e2a9\n[9]\n</code></pre>"},{"location":"PyTorch/data/data.BatchSampler/#batchsampler","title":"\u81ea\u5b9a\u4e49BatchSampler","text":"<p>\u2003\u2003\u5982\u679c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5bf9\u5c01\u88c5\u7684batch\u6709\u989d\u5916\u7684\u9700\u6c42\u65f6\uff08\u5982Faster RCNN\uff0c\u5728\u91c7\u6837\u65f6\u56fe\u50cf\u9ad8\u5bbd\u6bd4\u4f8b\u4f4d\u4e8e\u540c\u4e00\u533a\u95f4\u7684\u9700\u8981\u88ab\u5c01\u88c5\u5230\u4e00\u4e2abatch\u91cc\uff09\uff0c\u53ef\u4ee5\u901a\u8fc7\u5b9a\u4e49\u4e00\u4e2a\u65b0\u7c7b\u5b9e\u73b0\uff0c\u8be5\u7c7b\u9700\u8981\u7ee7\u627fBatchSampler\uff0c\u4e3b\u8981\u901a\u8fc7\u4fee\u6539\u8fed\u4ee3\u65b9\u6cd5__iter__(self)\u6765\u5b9e\u73b0\u3002</p>"},{"location":"PyTorch/data/data.BatchSampler/#_3","title":"\u4ee3\u7801\u6848\u4f8b","text":"<p>\u2003\u2003\u5047\u8bbe\u73b0\u6709\u5341\u4e2a\u6570\u636e\uff0c\u5e76\u4e14\u6bcf\u4e2a\u6570\u636e\u90fd\u5bf9\u5e94\u4e00\u4e2a\u5c5e\u6027<code>data</code>\uff0c\u73b0\u5728\u8981\u6c42\u5c5e\u6027\u662f\u5426\u53ef\u4ee5\u6574\u96642\u6765\u5c01\u88c5batch\uff0c\u5373\u5bf9\u5e94\u5c5e\u6027\u53ef\u4ee5\u6574\u96642\u7684\u6570\u636e\u88ab\u5206\u5230\u4e00\u4e2abatch\u91cc\uff0c\u5bf9\u5e94\u5c5e\u6027\u4e0d\u80fd\u6574\u96642\u7684\u6570\u636e\u88ab\u5206\u5230\u53e6\u4e00\u4e2abatch\u91cc\uff0c\u9996\u5148\u81ea\u5b9a\u4e49\u7c7b\uff1a</p> <pre><code>from torch.utils.data.sampler import BatchSampler\n\nclass GroupedBatchSampler(BatchSampler):\n    def __init__(self, sampler, batch_size, data):\n        # \u4e4b\u524d\u5b9a\u4e49\u7684\u91c7\u6837\u5668\n        self.sampler = sampler\n        # batch size\n        self.batch_size = batch_size\n        # data\u53ef\u4ee5\u8868\u793a\u6570\u636e\u5bf9\u5e94\u7684\u5c5e\u6027\n        self.data = data\n    def __iter__(self):\n        # \u7528\u4e8e\u50a8\u5b58\u53ef\u4ee5\u6574\u96642\u7684\u6570\u636e\u7d22\u5f15\n        group_div = []\n        # \u7528\u4e8e\u50a8\u5b58\u4e0d\u80fd\u6574\u96642\u7684\u6570\u636e\u7d22\u5f15\n        group = []\n        # \u6309\u91c7\u6837\u5668\uff0c\u904d\u5386\u6570\u636e\uff0c\u76f8\u5f53\u4e8e\u505a\u4e00\u4e2a\u91c7\u6837\n        for idx in self.sampler:\n            # \u5f97\u5230\u88ab\u91c7\u6837\u7684\u6570\u636e\u5c5e\u6027\n            data = self.data[idx]\n            # \u5982\u679c\u5f53\u524d\u7d22\u5f15\u5bf9\u5e94\u6570\u636e\u7684\u5c5e\u6027\u53ef\u4ee5\u6574\u96642\uff0c\u5219\u5728group_div\u4e2d\u6dfb\u52a0\u8be5\u7d22\u5f15\n            if data % 2 == 0:\n                group_div.append(idx)\n            # \u5426\u5219\u5728group\u4e2d\u6dfb\u52a0\u8be5\u7d22\u5f15\n            else:\n                group.append(idx)\n            # \u5982\u679c\u904d\u5386\u7ed3\u679c\u6ee1\u8db3\u4e00\u4e2abatch\u4e86\n            # \u5219\u5229\u7528yield\u5c01\u88c5\u6210\u4e00\u4e2a\u8fed\u4ee3\u5bf9\u8c61\n            # \u5e76\u4e14\u8fd4\u56de\u8be5\u5bf9\u8c61\uff0c\u6267\u884c\u4e00\u7cfb\u5217\u64cd\u4f5c\n            if len(group_div) == self.batch_size:\n                yield group_div\n                # \u6267\u884c\u5b8c\u4e4b\u540e\u518d\u56de\u5230\u8be5for\u5faa\u73af\uff0c\u6b64\u65f6\u521d\u59cb\u5316\u7d22\u5f15\u96c6\u5408group_div\n                group_div = []\n            # \u8fd9\u91cc\u540c\u7406\n            elif len(group) == self.batch_size:\n                yield group\n                group = []\n</code></pre> <p>\u6ce8\u610f\uff1a</p> <ul> <li>\u5728\u904d\u5386\u91c7\u6837\u5668<code>sampler</code>\u7684\u8fc7\u7a0b\u4e2d\uff0c\u5982\u679c\u6240\u5b58\u50a8\u7684\u6570\u636e\u7d22\u5f15\u91cf\u5df2\u7ecf\u6ee1\u8db3\u4e00\u4e2abatch\uff0c\u5219\u9700\u8981\u5229\u7528<code>yield</code>\u65b9\u6cd5\u5c06\u5176\u5c01\u88c5\u6210\u4e00\u4e2a\u8fed\u4ee3\u5bf9\u8c61</li> <li>\u4e00\u822c\u8be5\u65b9\u6cd5\u4f1a\u4e0e<code>for</code>\u5faa\u73af\u76f8\u7ed3\u5408\uff0c\u901a\u8fc7<code>for</code>\u5faa\u73af\u6307\u4ee4\u7684\u9a71\u52a8\u6765\u6267\u884c\u91c7\u6837\u3001\u5c01\u88c5batch\u7684\u64cd\u4f5c\u3002\u56e0\u6b64\u5f53\u8be5\u7c7b\u5c01\u88c5\u5b8c\u4e00\u4e2a\u8fed\u4ee3\u5bf9\u8c61\u65f6\uff0c\u7a0b\u5e8f\u4f1a\u6682\u65f6\u505c\u6b62\u91c7\u6837\uff0c\u5373\u505c\u6b62\u5bf9<code>self.sampler</code>\u7684\u904d\u5386\uff0c\u6267\u884c\u4e3b\u7a0b\u5e8f\u4e2d\u5bf9\u8fed\u4ee3\u5bf9\u8c61\u7684\u64cd\u4f5c\uff0c\u6267\u884c\u5b8c\u4e4b\u540e\u518d\u56de\u6765\u7ee7\u7eed\u91c7\u6837\u904d\u5386\u3002\u6bd4\u5982\uff1a\u5728\u904d\u5386\u6570\u636e\u96c6\u7684\u65f6\u5019\uff0c\u5f53\u91c7\u6837\u5f97\u5230\u7684\u6570\u636e\u6ee1\u8db3\u4e00\u4e2abatch\u540e\uff0c\u7a0b\u5e8f\u4f1a\u6682\u505c\u91c7\u6837\uff0c\u4e4b\u540e\u5c06\u8be5\u6279\u6b21\u6570\u636e\u6253\u5305\uff0c\u6267\u884c\u540e\u7eed\u7684\u4e00\u7cfb\u5217\u64cd\u4f5c\uff0c\u5982\uff1a\u8bad\u7ec3\u3001\u6d4b\u8bd5\u3001\u4ea6\u6216\u8005\u662f\u4e0b\u9762\u7684<code>print(i)</code>\uff0c\u6267\u884c\u5b8c\u4e4b\u540e\u518d\u56de\u6765\u7ee7\u7eed\u91c7\u6837\u904d\u5386\uff0c\u76f4\u5230\u904d\u5386\u7ed3\u675f\u3002</li> </ul> <p>\u904d\u5386\u91c7\u6837\u5668\u64cd\u4f5c</p> <pre><code>`from torch.utils.data.sampler import RandomSampler\n\n# \u5b9a\u4e49\u968f\u673a\u91c7\u6837\u5668\nsampler = RandomSampler(range(80))\n# \u5b9a\u4e49\u6570\u636e\u5bf9\u5e94\u7684\u5c5e\u6027\uff0c\u5c5e\u6027\u4e0e\u7d22\u5f15\u503c\u4e00\u81f4\n# \u8fd9\u91cc\u5c5e\u6027\u662f\u968f\u4fbf\u5b9a\u4e49\u7684\uff0c\u5177\u4f53\u53ef\u4ee5\u6839\u636e\u4efb\u52a1\u8981\u6c42\u6765\u5b9a\u4e49\u7684\ndata = [i for i in range(80)]\n# \u5c06\u5f97\u5230\u6279\u91cf\u91c7\u6837\u5668\uff0c\u6309\u7279\u5b9a\u7684\u529f\u80fd\u8fdb\u884c\u91c7\u6837\nbatch_sampler = GroupedBatchSampler(sampler, 8, data)\n\n# \u5faa\u73af\u904d\u5386\uff0c\u76f8\u5f53\u4e8e\u8bad\u7ec3\u6570\u636e\u96c6\u65f6\u904d\u5386\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\nfor i in batch_sampler:\n    print(i)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code>[70, 6, 22, 36, 12, 40, 42, 64]\n[7, 77, 47, 9, 57, 49, 61, 35]\n[53, 31, 67, 45, 21, 37, 59, 63]\n[76, 4, 18, 72, 44, 58, 32, 14]\n[11, 79, 55, 15, 75, 25, 23, 71]\n[8, 74, 34, 38, 20, 52, 30, 24]\n[29, 19, 39, 5, 17, 41, 69, 1]\n[50, 60, 56, 78, 10, 28, 2, 16]\n[13, 27, 43, 3, 73, 33, 65, 51]\n[0, 48, 68, 66, 26, 54, 46, 62]\n</code></pre>"},{"location":"PyTorch/data/data.BatchSampler/#_4","title":"\u5b98\u65b9\u6587\u6863","text":"<p>data.BatchSampler\uff1ahttps://pytorch.org/docs/stable/data.html#torch.utils.data.BatchSampler</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e742\u670819\u65e5</p>"},{"location":"PyTorch/data/data.RandomSampler/","title":"\u6570\u636e\u968f\u673a\u91c7\u6837","text":"<pre><code>torch.utils.data.RandomSampler(data_source, replacement=False, num_samples=None, generator=None)\n</code></pre> <p>\u529f\u80fd\uff1a\u968f\u5373\u5bf9\u6837\u672c\u8fdb\u884c\u91c7\u6837</p> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>data_source</code>\uff1a\u88ab\u91c7\u6837\u7684\u6570\u636e\u96c6\u5408</li> <li><code>replacement</code>\uff1a\u91c7\u6837\u7b56\u7565\uff0c\u5982\u679c\u4e3a<code>True</code>\uff0c\u5219\u4ee3\u8868\u4f7f\u7528\u66ff\u6362\u91c7\u6837\u7b56\u7565\uff0c\u5373\u53ef\u91cd\u590d\u5bf9\u4e00\u4e2a\u6837\u672c\u8fdb\u884c\u91c7\u6837\uff1b\u5982\u679c\u4e3a<code>False</code>\uff0c\u5219\u8868\u793a\u4e0d\u7528\u66ff\u6362\u91c7\u6837\u7b56\u7565\uff0c\u5373\u4e00\u4e2a\u6837\u672c\u6700\u591a\u53ea\u80fd\u88ab\u91c7\u4e00\u6b21</li> <li><code>num_samples</code>\uff1a\u6240\u91c7\u6837\u672c\u7684\u6570\u91cf\uff0c\u9ed8\u8ba4\u91c7\u5168\u90e8\u6837\u672c\uff1b\u5f53<code>replacement</code>\u89c4\u5b9a\u4e3a<code>True</code>\u65f6\uff0c\u53ef\u6307\u5b9a\u91c7\u6837\u6570\u91cf\uff0c\u5373\u4fee\u6539<code>num_samples</code>\u7684\u5927\u5c0f\uff1b\u5982\u679c<code>replacement</code>\u8bbe\u7f6e\u4e3a<code>False</code>\uff0c\u5219\u8be5\u53c2\u6570\u4e0d\u53ef\u505a\u4fee\u6539</li> <li><code>generator</code>\uff1a\u91c7\u6837\u8fc7\u7a0b\u4e2d\u7684\u751f\u6210\u5668</li> </ul>"},{"location":"PyTorch/data/data.RandomSampler/#_2","title":"\u4ee3\u7801\u6848\u4f8b","text":"<p>\u4e00\u822c\u7528\u6cd5</p> <pre><code>from torch.utils.data import RandomSampler\n\nsampler = RandomSampler(range(20))\nprint([i for i in sampler])\n</code></pre> <p>\u8f93\u51fa</p> <p>\u8fd9\u91cc\u76f8\u5f53\u4e8e\u5bf9\u539f\u6570\u636e\u505a\u4e86\u6253\u4e71\u64cd\u4f5c</p> <pre><code>[7, 17, 8, 1, 13, 9, 6, 4, 12, 18, 19, 14, 10, 3, 2, 16, 5, 15, 0, 11]\n</code></pre> <p><code>replacement</code>\u8bbe\u4e3a<code>True</code>\u4e0e<code>False</code>\u7684\u533a\u522b</p> <pre><code>from torch.utils.data import RandomSampler\n\nsampler_t = RandomSampler(range(20), replacement=True)\nsampler_f = RandomSampler(range(20), replacement=False)\nsampler_t_8 = RandomSampler(range(20), replacement=True, num_samples=8)\nprint('sampler_t:', [i for i in sampler_t])\nprint('sampler_f:', [i for i in sampler_f])\nprint('sampler_t_8:', [i for i in sampler_t_8])\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># replacement\u8bbe\u4e3aTrue\u65f6\uff0c\u4f1a\u5bf9\u540c\u4e00\u6837\u672c\u591a\u6b21\u91c7\u6837\nsampler_t: [7, 3, 13, 17, 4, 5, 8, 18, 15, 8, 1, 3, 17, 4, 13, 13, 16, 14, 15, 11]\n# \u5426\u5219\u4e00\u4e2a\u6837\u672c\u53ea\u91c7\u6837\u4e00\u6b21\nsampler_f: [3, 5, 19, 10, 6, 7, 13, 16, 15, 9, 14, 0, 4, 18, 12, 2, 11, 17, 1, 8]\n# replacement\u8bbe\u4e3aTrue\u65f6\uff0c\u53ef\u4ee5\u89c4\u5b9a\u91c7\u6837\u6570\u91cf\uff0c\u5982\u8fd9\u91cc\u53ea\u91c78\u4e2a\nsampler_t_8: [1, 9, 4, 5, 11, 18, 18, 4]\n</code></pre>"},{"location":"PyTorch/data/data.RandomSampler/#_3","title":"\u5b98\u65b9\u6587\u6863","text":"<p>torch.utils.data.RandomSampler\uff1ahttps://pytorch.org/docs/stable/data.html?highlight=randomsampler#torch.utils.data.RandomSampler</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e742\u670822\u65e5</p>"},{"location":"PyTorch/data/data.WeightedRandomSampler/","title":"\u6570\u636e\u6743\u91cd\u6982\u7387\u91c7\u6837","text":"<pre><code>torch.utils.data.WeightedRandomSampler(weights, num_samples, replacement=True, generator=None)\n</code></pre> <p>\u529f\u80fd\uff1a\u6309\u7ed9\u5b9a\u7684\u6743\u91cd(\u6982\u7387)[p_0,p_1,\\dots,p_{n-1}]\u5bf9\u6837\u672c\u7d22\u5f15[0,1,\\dots,n-1]\u91c7\u6837</p> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>weights</code>\uff1a\u91c7\u6837\u6743\u91cd\uff0c\u6743\u91cd\u4e4b\u548c\u4e0d\u8981\u6c42\u4e3a1\uff0c\u8be5\u6743\u91cd\u9700\u8981\u4e0e\u6bcf\u4e2a\u6837\u672c\u5bf9\u5e94\u8d77\u6765\uff0c\u5373\u6743\u91cd\u6570\u91cf\u7b49\u4e8e\u6837\u672c\u6570\u91cf</li> <li><code>num_samples</code>\uff1a\u6240\u91c7\u6837\u672c\u7684\u6570\u91cf\uff0c\u53ef\u4ee5\u5c0f\u4e8e<code>weights</code>\u7684\u6570\u91cf</li> <li><code>replacement</code>\uff1a\u91c7\u6837\u7b56\u7565\uff0c\u5982\u679c\u4e3a<code>True</code>\uff0c\u5219\u4ee3\u8868\u4f7f\u7528\u66ff\u6362\u91c7\u6837\u7b56\u7565\uff0c\u5373\u53ef\u91cd\u590d\u5bf9\u4e00\u4e2a\u6837\u672c\u8fdb\u884c\u91c7\u6837\uff1b\u5982\u679c\u4e3a<code>False</code>\uff0c\u5219\u8868\u793a\u4e0d\u7528\u66ff\u6362\u91c7\u6837\u7b56\u7565\uff0c\u5373\u4e00\u4e2a\u6837\u672c\u6700\u591a\u53ea\u80fd\u88ab\u91c7\u4e00\u6b21</li> <li><code>generator</code>\uff1a\u91c7\u6837\u8fc7\u7a0b\u4e2d\u7684\u751f\u6210\u5668</li> </ul>"},{"location":"PyTorch/data/data.WeightedRandomSampler/#_2","title":"\u4ee3\u7801\u6848\u4f8b","text":"<p>\u4e00\u822c\u7528\u6cd5</p> <pre><code>from torch.utils.data import WeightedRandomSampler\n\nsampler = WeightedRandomSampler([0.1, 0.6, 1.2, 2.9, 0.8, 0.4, 0.8, 1.0, 0.9], 8)\nprint([i for i in sampler])\n</code></pre> <p>\u8f93\u51fa</p> <p>\u8fd9\u91cc\u91c7\u6837\u5f97\u5230\u7684\u90fd\u662f\u6837\u672c\u7684\u7d22\u5f15</p> <pre><code>[5, 4, 6, 7, 0, 4, 4, 6]\n</code></pre> <p><code>replacement</code>\u8bbe\u4e3a<code>True</code>\u4e0e<code>False</code>\u7684\u533a\u522b</p> <pre><code>from torch.utils.data import WeightedRandomSampler\n\nsampler_t = WeightedRandomSampler([0.1, 0.6, 1.2, 2.9, 0.8, 0.4, 0.8, 1.0, 0.9], 8, replacement=True)\nsampler_f = WeightedRandomSampler([0.1, 0.6, 1.2, 2.9, 0.8, 0.4, 0.8, 1.0, 0.9], 8, replacement=False)\nprint('sampler_t:', [i for i in sampler_t])\nprint('sampler_f:', [i for i in sampler_f])\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># replacement\u8bbe\u4e3aTrue\u65f6\uff0c\u4f1a\u5bf9\u540c\u4e00\u6837\u672c\u591a\u6b21\u91c7\u6837\nsampler_t: [6, 1, 6, 6, 3, 3, 8, 4]\n# \u5426\u5219\u6bcf\u4e2a\u6837\u672c\u53ea\u91c7\u6837\u4e00\u6b21\nsampler_f: [7, 0, 2, 4, 1, 3, 8, 5]\n</code></pre>"},{"location":"PyTorch/data/data.WeightedRandomSampler/#_3","title":"\u5b98\u65b9\u6587\u6863","text":"<p>torch.utils.data.WeightedRandomSampler\uff1ahttps://pytorch.org/docs/stable/data.html?highlight=sampler#torch.utils.data.WeightedRandomSampler</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e742\u670822\u65e5</p>"},{"location":"PyTorch/nn/F/F.interpolate/","title":"\u6570\u7ec4\u91c7\u6837\u8fd0\u7b97","text":"<pre><code>torch.nn.functional.interpolate(input, size=None, scale_factor=None, mode='nearest', align_corners=None, recompute_scale_factor=None)\n</code></pre> <p>\u529f\u80fd\uff1a\u5229\u7528\u63d2\u503c\u65b9\u6cd5\uff0c\u5bf9\u8f93\u5165\u7684\u5f20\u91cf\u6570\u7ec4\u8fdb\u884c\u4e0a\\\u4e0b\u91c7\u6837\u64cd\u4f5c\uff0c\u6362\u53e5\u8bdd\u8bf4\u5c31\u662f\u79d1\u5b66\u5408\u7406\u5730\u6539\u53d8\u6570\u7ec4\u7684\u5c3a\u5bf8\u5927\u5c0f\uff0c\u5c3d\u91cf\u4fdd\u6301\u6570\u636e\u5b8c\u6574\u3002</p> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>input</code>(Tensor)\uff1a\u9700\u8981\u8fdb\u884c\u91c7\u6837\u5904\u7406\u7684\u6570\u7ec4\u3002</li> <li><code>size</code>(int\u6216\u5e8f\u5217)\uff1a\u8f93\u51fa\u7a7a\u95f4\u7684\u5927\u5c0f</li> <li><code>scale_factor</code>(float\u6216\u5e8f\u5217)\uff1a\u7a7a\u95f4\u5927\u5c0f\u7684\u4e58\u6570</li> <li><code>mode</code>(str)\uff1a\u7528\u4e8e\u91c7\u6837\u7684\u7b97\u6cd5\u3002<code>'nearest'</code>| <code>'linear'</code>| <code>'bilinear'</code>| <code>'bicubic'</code>| <code>'trilinear'</code>| <code>'area'</code>\u3002\u9ed8\u8ba4\uff1a<code>'nearest'</code></li> <li><code>align_corners</code>(bool)\uff1a\u5728\u51e0\u4f55\u4e0a\uff0c\u6211\u4eec\u5c06\u8f93\u5165\u548c\u8f93\u51fa\u7684\u50cf\u7d20\u89c6\u4e3a\u6b63\u65b9\u5f62\u800c\u4e0d\u662f\u70b9\u3002\u5982\u679c\u8bbe\u7f6e\u4e3a<code>True</code>\uff0c\u5219\u8f93\u5165\u548c\u8f93\u51fa\u5f20\u91cf\u6309\u5176\u89d2\u50cf\u7d20\u7684\u4e2d\u5fc3\u70b9\u5bf9\u9f50\uff0c\u4fdd\u7559\u89d2\u50cf\u7d20\u5904\u7684\u503c\u3002\u5982\u679c\u8bbe\u7f6e\u4e3a<code>False</code>\uff0c\u5219\u8f93\u5165\u548c\u8f93\u51fa\u5f20\u91cf\u901a\u8fc7\u5176\u89d2\u50cf\u7d20\u7684\u89d2\u70b9\u5bf9\u9f50\uff0c\u5e76\u4e14\u63d2\u503c\u4f7f\u7528\u8fb9\u7f18\u503c\u586b\u5145\u7528\u4e8e\u8fb9\u754c\u5916\u503c\uff0c\u4f7f\u6b64\u64cd\u4f5c\u5728\u4fdd\u6301\u4e0d\u53d8\u65f6\u72ec\u7acb\u4e8e\u8f93\u5165\u5927\u5c0f<code>scale_factor</code>\u3002</li> <li><code>recompute_scale_facto</code>(bool)\uff1a\u91cd\u65b0\u8ba1\u7b97\u7528\u4e8e\u63d2\u503c\u8ba1\u7b97\u7684 scale_factor\u3002\u5f53scale_factor\u4f5c\u4e3a\u53c2\u6570\u4f20\u9012\u65f6\uff0c\u5b83\u7528\u4e8e\u8ba1\u7b97output_size\u3002\u5982\u679crecompute_scale_factor\u7684<code>False</code>\u6216\u6ca1\u6709\u6307\u5b9a\uff0c\u4f20\u5165\u7684scale_factor\u5c06\u5728\u63d2\u503c\u8ba1\u7b97\u4e2d\u4f7f\u7528\u3002\u5426\u5219\uff0c\u5c06\u6839\u636e\u7528\u4e8e\u63d2\u503c\u8ba1\u7b97\u7684\u8f93\u51fa\u548c\u8f93\u5165\u5927\u5c0f\u8ba1\u7b97\u65b0\u7684scale_factor\uff08\u5373\uff0c\u5982\u679c\u8ba1\u7b97\u7684output_size\u663e\u5f0f\u4f20\u5165\uff0c\u5219\u8ba1\u7b97\u5c06\u76f8\u540c \uff09\u3002\u6ce8\u610f\u5f53scale_factor \u662f\u6d6e\u70b9\u6570\uff0c\u7531\u4e8e\u820d\u5165\u548c\u7cbe\u5ea6\u95ee\u9898\uff0c\u91cd\u65b0\u8ba1\u7b97\u7684 scale_factor \u53ef\u80fd\u4e0e\u4f20\u5165\u7684\u4e0d\u540c\u3002</li> </ul> <p>\u6ce8\u610f\uff1a</p> <ul> <li>\u8f93\u5165\u7684\u5f20\u91cf\u6570\u7ec4\u91cc\u9762\u7684\u6570\u636e\u7c7b\u578b\u5fc5\u987b\u662f<code>float</code>\u3002</li> <li>\u8f93\u5165\u7684\u6570\u7ec4\u7ef4\u6570\u53ea\u80fd\u662f3\u30014\u62165\uff0c\u5206\u522b\u5bf9\u5e94\u4e8e\u65f6\u95f4\u3001\u7a7a\u95f4\u3001\u4f53\u79ef\u91c7\u6837\u3002</li> <li>\u4e0d\u5bf9\u8f93\u5165\u6570\u7ec4\u7684\u524d\u4e24\u4e2a\u7ef4\u5ea6(\u6279\u6b21\u548c\u901a\u9053)\u91c7\u6837\uff0c\u4ece\u7b2c\u4e09\u4e2a\u7ef4\u5ea6\u5f80\u540e\u5f00\u59cb\u91c7\u6837\u5904\u7406\u3002</li> <li>\u8f93\u5165\u7684\u7ef4\u5ea6\u5f62\u5f0f\u4e3a\uff1a\u6279\u91cf(batch_size)\u00d7\u901a\u9053(channel)\u00d7[\u53ef\u9009\u6df1\u5ea6]\u00d7[\u53ef\u9009\u9ad8\u5ea6]\u00d7\u5bbd\u5ea6(\u524d\u4e24\u4e2a\u7ef4\u5ea6\u5177\u6709\u7279\u6b8a\u7684\u542b\u4e49\uff0c\u4e0d\u8fdb\u884c\u91c7\u6837\u5904\u7406)</li> <li><code>size</code>\u4e0e<code>scale_factor</code>\u4e24\u4e2a\u53c2\u6570\u53ea\u80fd\u5b9a\u4e49\u4e00\u4e2a\uff0c\u5373\u4e24\u79cd\u91c7\u6837\u6a21\u5f0f\u53ea\u80fd\u7528\u4e00\u4e2a\u3002\u8981\u4e48\u8ba9\u6570\u7ec4\u653e\u5927\u6210\u7279\u5b9a\u5927\u5c0f\u3001\u8981\u4e48\u7ed9\u5b9a\u7279\u5b9a\u7cfb\u6570\uff0c\u6765\u7b49\u6bd4\u653e\u5927\u6570\u7ec4\u3002</li> <li>\u5982\u679c<code>size</code>\u6216\u8005<code>scale_factor</code>\u8f93\u5165\u5e8f\u5217\uff0c\u5219\u5fc5\u987b\u5339\u914d\u8f93\u5165\u7684\u5927\u5c0f\u3002\u5982\u679c\u8f93\u5165\u56db\u7ef4\uff0c\u5219\u5b83\u4eec\u7684\u5e8f\u5217\u957f\u5ea6\u5fc5\u987b\u662f2\uff0c\u5982\u679c\u8f93\u5165\u662f\u4e94\u7ef4\uff0c\u5219\u5b83\u4eec\u7684\u5e8f\u5217\u957f\u5ea6\u5fc5\u987b\u662f3\u3002</li> <li>\u5982\u679c<code>size</code>\u8f93\u5165\u6574\u6570x\uff0c\u5219\u76f8\u5f53\u4e8e\u628a3\u30014\u7ef4\u5ea6\u653e\u5927\u6210(x,x)\u5927\u5c0f(\u8f93\u5165\u4ee5\u56db\u7ef4\u4e3a\u4f8b\uff0c\u4e0b\u9762\u540c\u7406)\u3002</li> <li>\u5982\u679c<code>scale_factor</code>\u8f93\u5165\u6574\u6570x\uff0c\u5219\u76f8\u5f53\u4e8e\u628a3\u30014\u7ef4\u5ea6\u90fd\u7b49\u6bd4\u653e\u5927x\u500d\u3002</li> <li><code>mode</code>\u662f\u2019linear\u2019\u65f6\u8f93\u5165\u5fc5\u987b\u662f3\u7ef4\u7684\uff1b\u662f\u2019bicubic\u2019\u65f6\u8f93\u5165\u5fc5\u987b\u662f4\u7ef4\u7684\uff1b\u662f\u2019trilinear\u2019\u65f6\u8f93\u5165\u5fc5\u987b\u662f5\u7ef4\u7684</li> <li>\u5982\u679c<code>align_corners</code>\u88ab\u8d4b\u503c\uff0c\u5219<code>mode</code>\u5fc5\u987b\u662f<code>'linear'</code>\uff0c<code>'bilinear'</code>\uff0c<code>'bicubic'</code>\u6216<code>'trilinear'</code>\u4e2d\u7684\u4e00\u4e2a\u3002</li> <li>\u63d2\u503c\u65b9\u6cd5\u4e0d\u540c\uff0c\u7ed3\u679c\u5c31\u4e0d\u4e00\u6837\uff0c\u9700\u8981\u7ed3\u5408\u5177\u4f53\u4efb\u52a1\uff0c\u9009\u62e9\u5408\u9002\u7684\u63d2\u503c\u65b9\u6cd5\u3002</li> </ul> <p>\u8865\u5145\uff1a</p> <p>\u4e00\u56fe\u770b\u61c2align_corners=True\u4e0eFalse\u7684\u533a\u522b\uff0c\u4ece4\u00d74\u4e0a\u91c7\u6837\u62108\u00d78\u3002\u4e00\u4e2a\u662f\u6309\u56db\u89d2\u7684\u50cf\u7d20\u70b9\u4e2d\u5fc3\u5bf9\u9f50\uff0c\u53e6\u4e00\u4e2a\u662f\u6309\u56db\u89d2\u7684\u50cf\u7d20\u89d2\u70b9\u5bf9\u9f50\u3002</p> <p> <p></p> <p></p> <p>\u56fe\u7247\u8f6c\u81ea\uff1ahttps://discuss.pytorch.org/t/what-we-should-use-align-corners-false/22663/9</p>"},{"location":"PyTorch/nn/F/F.interpolate/#_2","title":"\u4ee3\u7801\u6848\u4f8b","text":""},{"location":"PyTorch/nn/F/F.interpolate/#_3","title":"\u4e00\u822c\u7528\u6cd5","text":"<pre><code>import torch.nn.functional as F\nimport torch\n\na=torch.arange(12,dtype=torch.float32).reshape(1,2,2,3)\nb=F.interpolate(a,size=(4,4),mode='bilinear')\n# \u8fd9\u91cc\u7684(4,4)\u6307\u7684\u662f\u5c06\u540e\u4e24\u4e2a\u7ef4\u5ea6\u653e\u7f29\u62104*4\u7684\u5927\u5c0f\nprint(a)\nprint(b)\nprint('\u539f\u6570\u7ec4\u5c3a\u5bf8:',a.shape)\nprint('size\u91c7\u6837\u5c3a\u5bf8:',b.shape)\n</code></pre> <p>\u8f93\u51fa\u7ed3\u679c\uff0c\u4e00\u4e8c\u7ef4\u5ea6\u5927\u5c0f\u4e0d\u4f1a\u53d1\u751f\u53d8\u5316</p> <pre><code># \u539f\u6570\u7ec4\ntensor([[[[ 0.,  1.,  2.],\n          [ 3.,  4.,  5.]],\n\n         [[ 6.,  7.,  8.],\n          [ 9., 10., 11.]]]])\n# \u91c7\u6837\u540e\u7684\u6570\u7ec4\ntensor([[[[ 0.0000,  0.6250,  1.3750,  2.0000],\n          [ 0.7500,  1.3750,  2.1250,  2.7500],\n          [ 2.2500,  2.8750,  3.6250,  4.2500],\n          [ 3.0000,  3.6250,  4.3750,  5.0000]],\n\n         [[ 6.0000,  6.6250,  7.3750,  8.0000],\n          [ 6.7500,  7.3750,  8.1250,  8.7500],\n          [ 8.2500,  8.8750,  9.6250, 10.2500],\n          [ 9.0000,  9.6250, 10.3750, 11.0000]]]])\n\u539f\u6570\u7ec4\u5c3a\u5bf8: torch.Size([1, 2, 2, 3])\nsize\u91c7\u6837\u5c3a\u5bf8: torch.Size([1, 2, 4, 4])\n# \u89c4\u5b9a\u4e09\u56db\u7ef4\u5ea6\u653e\u7f29\u62104*4\u5927\u5c0f\n</code></pre> <p><code>size</code>\u4e0e<code>scale_factor</code>\u7684\u533a\u522b\uff1a\u8f93\u5165\u5e8f\u5217\u65f6</p> <pre><code>import torch.nn.functional as F\nimport torch\n\na=torch.arange(4*512*14*14,dtype=torch.float32).reshape(4,512,14,14)\nb=F.interpolate(a,size=(28,56),mode='bilinear')\nc=F.interpolate(a,scale_factor=(4,8),mode='bilinear')\nprint('\u539f\u6570\u7ec4\u5c3a\u5bf8:',a.shape)\nprint('size\u91c7\u6837\u5c3a\u5bf8:',b.shape)\nprint('scale_factor\u91c7\u6837\u5c3a\u5bf8:',c.shape)\n</code></pre> <p>\u8f93\u51fa\u7ed3\u679c</p> <pre><code>\u539f\u6570\u7ec4\u5c3a\u5bf8: torch.Size([4, 512, 14, 14])\nsize\u91c7\u6837\u5c3a\u5bf8: torch.Size([4, 512, 28, 56])\n# \u7b2c\u4e09\u7ef4\u5ea6\u653e\u5927\u621028\uff0c\u7b2c\u56db\u7ef4\u5ea6\u653e\u5927\u621056\nscale_factor\u91c7\u6837\u5c3a\u5bf8: torch.Size([4, 512, 56, 112])\n# \u7b2c\u4e09\u7ef4\u5ea6\u653e\u59274\u500d\uff0c\u7b2c\u56db\u7ef4\u5ea6\u653e8\u500d\n</code></pre> <p><code>size</code>\u4e0e<code>scale_factor</code>\u7684\u533a\u522b\uff1a\u8f93\u5165\u6574\u6570\u65f6</p> <pre><code>import torch.nn.functional as F\nimport torch\n\na=torch.arange(4*512*14*14,dtype=torch.float32).reshape(4,512,14,14)\nb=F.interpolate(a,size=28,mode='bilinear')\nc=F.interpolate(a,scale_factor=4,mode='bilinear')\nprint('\u539f\u6570\u7ec4\u5c3a\u5bf8:',a.shape)\nprint('size\u91c7\u6837\u5c3a\u5bf8:',b.shape)\nprint('scale_factor\u91c7\u6837\u5c3a\u5bf8:',c.shape)\n</code></pre> <p>\u8f93\u51fa\u7ed3\u679c</p> <pre><code>\u539f\u6570\u7ec4\u5c3a\u5bf8: torch.Size([4, 512, 14, 14])\nsize\u91c7\u6837\u5c3a\u5bf8: torch.Size([4, 512, 28, 28])\n# \u4e09\u56db\u7ef4\u5ea6\u6570\u7ec4\u88ab\u653e\u5927\u621028*28\nscale_factor\u91c7\u6837\u5c3a\u5bf8: torch.Size([4, 512, 56, 56])\n# \u4e09\u56db\u7ef4\u5ea6\u6570\u7ec4\u88ab\u653e\u5927\u4e864\u500d\n</code></pre> <p><code>align_corners</code>=True\u4e0eFalse\u7684\u533a\u522b</p> <pre><code>import torch.nn.functional as F\nimport torch\n\na=torch.arange(18,dtype=torch.float32).reshape(1,2,3,3)\nb=F.interpolate(a,size=(4,4),mode='bicubic',align_corners=True)\nc=F.interpolate(a,size=(4,4),mode='bicubic',align_corners=False)\n\nprint(a)\nprint(b)\nprint(c)\n</code></pre> <p>\u8f93\u51fa\u7ed3\u679c\uff0c\u5177\u4f53\u6548\u679c\u4f1a\u56e0mode\u63d2\u503c\u65b9\u6cd5\u800c\u5f02</p> <pre><code>tensor([[[[ 0.,  1.,  2.],\n          [ 3.,  4.,  5.],\n          [ 6.,  7.,  8.]],\n\n         [[ 9., 10., 11.],\n          [12., 13., 14.],\n          [15., 16., 17.]]]])\n# align_corners=True\ntensor([[[[ 0.0000,  0.5741,  1.4259,  2.0000],\n          [ 1.7222,  2.2963,  3.1481,  3.7222],\n          [ 4.2778,  4.8519,  5.7037,  6.2778],\n          [ 6.0000,  6.5741,  7.4259,  8.0000]],\n\n         [[ 9.0000,  9.5741, 10.4259, 11.0000],\n          [10.7222, 11.2963, 12.1481, 12.7222],\n          [13.2778, 13.8519, 14.7037, 15.2778],\n          [15.0000, 15.5741, 16.4259, 17.0000]]]])\n# align_corners=False\ntensor([[[[-0.2871,  0.3145,  1.2549,  1.8564],\n          [ 1.5176,  2.1191,  3.0596,  3.6611],\n          [ 4.3389,  4.9404,  5.8809,  6.4824],\n          [ 6.1436,  6.7451,  7.6855,  8.2871]],\n\n         [[ 8.7129,  9.3145, 10.2549, 10.8564],\n          [10.5176, 11.1191, 12.0596, 12.6611],\n          [13.3389, 13.9404, 14.8809, 15.4824],\n          [15.1436, 15.7451, 16.6855, 17.2871]]]])\n</code></pre>"},{"location":"PyTorch/nn/F/F.interpolate/#_4","title":"\u6269\u5c55","text":"<p>\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\uff0c<code>interpolate</code>\u51fd\u6570\u5e38\u7528\u4e8e\u56fe\u50cf\u7684\u653e\u5927(\u5373\u4e0a\u91c7\u6837\u64cd\u4f5c)\u3002\u6bd4\u5982\u5728\u7ec6\u7c92\u5ea6\u8bc6\u522b\u9886\u57df\u4e2d\uff0c\u6ce8\u610f\u529b\u56fe\u6709\u65f6\u5019\u4f1a\u5bf9\u7279\u5f81\u56fe\u8fdb\u884c\u88c1\u526a\u64cd\u4f5c\uff0c\u5c06\u6709\u7528\u7684\u90e8\u5206\u88c1\u526a\u51fa\u6765\uff0c\u88c1\u526a\u540e\u7684\u56fe\u50cf\u5f80\u5f80\u5c3a\u5bf8\u5c0f\u4e8e\u539f\u59cb\u7279\u5f81\u56fe\uff0c\u8fd9\u65f6\u5019\u5982\u679c\u5f3a\u5236\u8f6c\u6362\u6210\u539f\u59cb\u56fe\u50cf\u5927\u5c0f\uff0c\u5f80\u5f80\u662f\u65e0\u6548\u7684\uff0c\u4f1a\u4e22\u6389\u90e8\u5206\u6709\u7528\u7684\u4fe1\u606f\u3002\u6240\u4ee5\u8fd9\u65f6\u5019\u5c31\u9700\u8981\u7528\u5230<code>interpolate</code>\u51fd\u6570\u5bf9\u5176\u8fdb\u884c\u4e0a\u91c7\u6837\u64cd\u4f5c\uff0c\u5728\u4fdd\u8bc1\u56fe\u50cf\u4fe1\u606f\u4e0d\u4e22\u5931\u7684\u60c5\u51b5\u4e0b\uff0c\u653e\u5927\u56fe\u50cf\uff0c\u4ece\u800c\u653e\u5927\u56fe\u50cf\u7684\u7ec6\u8282\uff0c\u6709\u5229\u4e8e\u8fdb\u4e00\u6b65\u7684\u7279\u5f81\u63d0\u53d6\u5de5\u4f5c\u3002</p>"},{"location":"PyTorch/nn/F/F.interpolate/#_5","title":"\u5b98\u65b9\u6587\u6863","text":"<p>torch.nn.functional.interpolate\uff1ahttps://pytorch.org/docs/stable/generated/torch.nn.functional.interpolate.html?highlight=interpolate#torch.nn.functional.interpolate</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e749\u670814\u65e5</p>"},{"location":"PyTorch/nn/F/F.normalize/","title":"\u6570\u7ec4\u5f52\u4e00\u5316\u8fd0\u7b97","text":"<pre><code>torch.nn.functional.normalize(input, p=2.0, dim=1, eps=1e-12, out=None)\n</code></pre> <p>\u529f\u80fd\uff1a\u5229\u7528L_p\u8303\u6570\u5bf9\u8f93\u5165\u7684\u6570\u7ec4\u6cbf\u7279\u5b9a\u7684\u7ef4\u5ea6\u8fdb\u884c\u5f52\u4e00\u5316</p> <p>\u2003\u2003\u5bf9\u4e8e\u5c3a\u5bf8\u4e3a(n_0,\\dots,n_{dim},\\dots,n_k)\u7684\u8f93\u5165\u6570\u7ec4<code>input</code>\uff0c\u6bcf\u4e2an_{dim}\u4e0a\u7684\u5143\u7d20\u5411\u91cfv\u6cbf\u7740\u7ef4\u5ea6<code>dim</code>\u8fdb\u884c\u8f6c\u6362\uff0c\u8f6c\u6362\u516c\u5f0f\u4e3a\uff1a $$ v=\\frac{v}{\\max(||v||_p,\\epsilon)} $$ \u8303\u6570\u8ba1\u7b97\u516c\u5f0f</p> <p>\u5bf9\u4e8e\u6570\u636ex=[x_1,x_2,\\dots,x_n]^T\uff1a</p> <ul> <li>L_p\u8303\u6570\uff1a||x||_p=(|x_1|^p+|x_2|^p+\\dots+|x_n|^p)^{\\frac1p}</li> <li>L_1\u8303\u6570\uff1a||x||_1=|x_1|+|x_2|+\\dots+|x_n|</li> <li>L_2\u8303\u6570\uff1a||x||_2=(|x_1|^2+|x_2|^2+\\dots+|x_n|^2)^{\\frac12}</li> </ul> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>input</code>\uff1a\u8f93\u5165\u7684\u6570\u7ec4\uff0c\u6570\u7ec4\u6570\u636e\u7c7b\u578b\u4e3a<code>float</code></li> <li><code>p</code>\uff1a\u6307\u5b9a\u4f7f\u7528\u7684\u8303\u6570\uff0c\u6570\u636e\u7c7b\u578b\u4e3a<code>float</code>\uff0c\u9ed8\u8ba42.0</li> <li><code>dim</code>\uff1a\u6307\u5b9a\u7684\u7ef4\u5ea6\uff0c\u6570\u636e\u7c7b\u578b\u4e3a<code>int</code>\uff0c\u9ed8\u8ba41</li> <li><code>eps</code>\uff1a\u8fb9\u754c\u503c\uff0c\u9632\u6b62\u5206\u6bcd\u4e3a0\uff0c\u9ed8\u8ba41e-12</li> </ul>"},{"location":"PyTorch/nn/F/F.normalize/#_2","title":"\u4ee3\u7801\u6848\u4f8b","text":"<p>\u4e00\u822c\u7528\u6cd5</p> <pre><code>import torch.nn.functional as F\nimport torch\n\na = torch.arange(20, dtype=torch.float).reshape(4,5)\nb = F.normalize(a, dim=0)\nc = F.normalize(a, dim=1)\nprint(a)\nprint(b)\nprint(c)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u8f93\u5165\u7684\u6570\u7ec4\ntensor([[ 0.,  1.,  2.,  3.,  4.],\n        [ 5.,  6.,  7.,  8.,  9.],\n        [10., 11., 12., 13., 14.],\n        [15., 16., 17., 18., 19.]])\n# dim=0\u65f6\uff0c\u5373\u6cbf\u7b2c\u4e00\u7ef4\u5ea6(\u5217)\u505a\u5f52\u4e00\u5316\ntensor([[0.0000, 0.0491, 0.0907, 0.1261, 0.1564],\n        [0.2673, 0.2949, 0.3175, 0.3363, 0.3519],\n        [0.5345, 0.5406, 0.5443, 0.5464, 0.5474],\n        [0.8018, 0.7864, 0.7711, 0.7566, 0.7430]])\n# dim=1\u65f6\uff0c\u5373\u6cbf\u7b2c\u4e8c\u7ef4\u5ea6(\u884c)\u505a\u5f52\u4e00\u5316\n# \u7ef4\u5ea6\u8bb0\u5fc6\u6280\u5de7:\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\u59cb\u7ec8\u662f\u884c\uff0c\u4ece\u540e\u5411\u524d\u63a8:\u884c\u3001\u5217\u3001\u901a\u9053\ntensor([[0.0000, 0.1826, 0.3651, 0.5477, 0.7303],\n        [0.3131, 0.3757, 0.4384, 0.5010, 0.5636],\n        [0.3701, 0.4071, 0.4441, 0.4812, 0.5182],\n        [0.3932, 0.4195, 0.4457, 0.4719, 0.4981]])\n</code></pre>"},{"location":"PyTorch/nn/F/F.normalize/#_3","title":"\u5b98\u65b9\u6587\u6863","text":"<p>torch.nn.functional.normalize\uff1ahttps://pytorch.org/docs/stable/generated/torch.nn.functional.normalize.html#torch.nn.functional.normalize</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e742\u67086\u65e5</p>"},{"location":"PyTorch/nn/F/F.pad/","title":"PyTorch\u5b66\u4e60\u7b14\u8bb0\uff1aF.pad\u2014\u2014\u5f20\u91cf\u586b\u5145\u64cd\u4f5c","text":"<pre><code>torch.nn.functional.pad(input, pad, mode='constant', value=None)\n</code></pre> <p>\u529f\u80fd\uff1a\u5bf9\u5f20\u91cf\u6570\u636e\u6267\u884c\u586b\u5145\u64cd\u4f5c</p> <p>\u8f93\u5165\uff1a</p> <ul> <li> <p><code>input</code>\uff1a\u5f85\u586b\u5145\u7684n\u7ef4\u5f20\u91cf\uff1b</p> </li> <li> <p><code>pad</code>\uff1a\u6bcf\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u586b\u5145\u5927\u5c0f\uff0c\u8f93\u5165\u662f\u5927\u5c0f\u4e3a<code>m</code>\u7684\u5143\u7ec4\u6570\u636e\uff0c\u5e76\u4e14\\frac m2\\le n\uff1b</p> </li> <li> <p><code>mode</code>\uff1a\u586b\u5145\u65b9\u5f0f\uff0c\u53ef\u9009\u62e94\u79cd\u2014\u2014<code>constant</code>\u3001<code>reflect</code>\u3001<code>replicate</code>\u3001<code>circular</code>\uff1b</p> </li> </ul> <p><code>constant</code>\uff1a\u56fa\u5b9a\u586b\u5145\uff0c\u586b\u5145\u56fa\u5b9a\u7684\u6570\u503c\uff0c\u6570\u503c\u5927\u5c0f\u7531<code>value</code>\u786e\u5b9a\uff1b</p> <p><code>reflect</code>\uff1a\u955c\u50cf\u586b\u5145\uff0c\u4ee5\u77e9\u9635\u8fb9\u7f18\u4e3a\u5bf9\u79f0\u8f74\uff0c\u5c06\u53cd\u65b9\u5411\u7684\u5bf9\u79f0\u5143\u7d20\u586b\u5145\u5230\u6700\u5916\u56f4\uff1b</p> <p><code>replicate</code>\uff1a\u590d\u5236\u586b\u5145\uff0c\u4f7f\u7528\u8f93\u5165\u8fb9\u754c\u7684\u590d\u5236\u503c\u586b\u5145\u5f20\u91cf\uff1b</p> <p><code>circular</code>\uff1a\u5faa\u73af\u586b\u5145\uff0c\u91cd\u590d\u77e9\u9635\u8fb9\u754c\u53e6\u4e00\u4fa7\u7684\u5143\u7d20\uff1b</p> <ul> <li><code>value</code>\uff1a\u586b\u5145\u7684\u6570\u503c\uff0c\u5982\u679c\u6307\u5b9a\u6a21\u5f0f\u4e3a<code>constant</code>\uff0c\u5219\u9700\u8981\u8bbe\u7f6e\u8fd9\u4e2a\u6570\u636e\uff0c\u9ed8\u8ba4\u4e3a<code>0</code>\uff1b</li> </ul> <p>\u6ce8\u610f\uff1a<code>pad</code>\u53c2\u6570\u76f8\u5f53\u4e8e\u89c4\u5b9a\u4e86\u586b\u5145\u7684\u7ef4\u5ea6\uff0c\u4ece\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\u5f00\u59cb\u586b\u5145\uff0c\u4e4b\u540e\u5411\u524d\u79fb\u52a8\u3002</p> <ul> <li>\u5982\u679c\u53ea\u586b\u5145\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\uff0c\u90a3\u4e48<code>pad</code>\u7684\u5f62\u5f0f\u5e94\u8be5\u662f</li> </ul>  (padding_{left}, padding_{right})  <ul> <li>\u5982\u679c\u9700\u8981\u586b\u5145\u540e\u4e24\u4e2a\u7ef4\u5ea6\uff0c\u5219<code>pad</code>\u7684\u5f62\u5f0f\u5e94\u8be5\u662f\uff1a</li> </ul>  (padding_{left}, padding_{right}, padding_{top},padding_{bottom})  <ul> <li>\u5982\u679c\u9700\u8981\u586b\u5145\u540e\u4e09\u4e2a\u7ef4\u5ea6\uff0c\u5219<code>pad</code>\u7684\u5f62\u5f0f\u5e94\u8be5\u662f\uff1a</li> </ul>  (padding_{left}, padding_{right}, padding_{top},padding_{bottom}, padding_{front}, padding_{back})  <p>\u586b\u5145\u7ef4\u5ea6\u9075\u5faa\u4ece\u540e\u5f80\u524d\u7684\u987a\u5e8f\uff0c\u5bf9\u4e8e\u6bcf\u4e2a\u7ef4\u5ea6\uff0c\u5219\u5148\u586b\u5145\u5de6\u4fa7\\\u4e0a\u4fa7\\\u524d\u4fa7\uff08\u5f53\u524d\u7ef4\u5ea6\u7684\u5934\u90e8\uff09\uff0c\u518d\u586b\u5145\u53f3\u4fa7\\\u4e0b\u4fa7\\\u540e\u4fa7\uff08\u5f53\u524d\u7ef4\u5ea6\u7684\u5c3e\u90e8\uff09\u3002</p>"},{"location":"PyTorch/nn/F/F.pad/#_1","title":"\u4ee3\u7801\u6848\u4f8b","text":"<p>\u586b\u5145\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6</p> <pre><code>import torch\nimport torch.nn.functional as F\n\ndata = torch.rand((4, 5))\ndata_pad = F.pad(data, (1, 1), mode='constant', value=0)\nprint(data_pad.shape)\nprint(data_pad)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code>torch.Size([4, 7])\ntensor([[0.0000, 0.9078, 0.7661, 0.9528, 0.5150, 0.7477, 0.0000],\n        [0.0000, 0.7557, 0.8106, 0.3553, 0.6389, 0.3530, 0.0000],\n        [0.0000, 0.2252, 0.1503, 0.1594, 0.0670, 0.6921, 0.0000],\n        [0.0000, 0.9031, 0.4881, 0.4229, 0.6172, 0.8499, 0.0000]])\n</code></pre> <p>\u586b\u5145\u5012\u6570\u7b2c\u4e8c\u4e2a\u7ef4\u5ea6</p> <pre><code>import torch\nimport torch.nn.functional as F\n\ndata = torch.rand((4, 5))\ndata_pad = F.pad(data, (0, 0, 1, 1), mode='constant', value=0)\nprint(data_pad.shape)\nprint(data_pad)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code>torch.Size([6, 5])\ntensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.9654, 0.2884, 0.7230, 0.0726, 0.1494],\n        [0.7932, 0.3762, 0.0208, 0.5714, 0.4117],\n        [0.0561, 0.3267, 0.8760, 0.7788, 0.5641],\n        [0.2164, 0.1843, 0.5578, 0.4320, 0.7201],\n        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])\n</code></pre> <p>\u586b\u5145\u4e00\u5708</p> <pre><code>import torch\nimport torch.nn.functional as F\n\ndata = torch.rand((4, 5))\ndata_pad = F.pad(data, (1, 1, 1, 1), mode='constant', value=0)\nprint(data_pad.shape)\nprint(data_pad)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code>torch.Size([6, 7])\ntensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.0000, 0.8213, 0.4184, 0.0156, 0.2825, 0.0275, 0.0000],\n        [0.0000, 0.2093, 0.4823, 0.3615, 0.5399, 0.4086, 0.0000],\n        [0.0000, 0.2813, 0.9294, 0.6584, 0.0308, 0.3365, 0.0000],\n        [0.0000, 0.9582, 0.1243, 0.2762, 0.1795, 0.3596, 0.0000],\n        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])\n</code></pre> <p>\u586b\u5145\u65b9\u5f0f\u7684\u533a\u522b\u53ef\u53c2\u8003\uff1a\u300aPyTorch\u5b66\u4e60\u7b14\u8bb0\uff1ann.Conv2d\u2014\u2014\u4e8c\u7ef4\u5377\u79ef\u8fd0\u7b97\u89e3\u8bfb\u300b</p>"},{"location":"PyTorch/nn/F/F.pad/#_2","title":"\u5b98\u65b9\u6587\u6863","text":"<p>F.pad\uff1ahttps://pytorch.org/docs/stable/generated/torch.nn.functional.pad.html#torch.nn.functional.pad</p>"},{"location":"PyTorch/nn/activations/nn.GELU/","title":"nn.GELU","text":""},{"location":"PyTorch/nn/activations/nn.GELU/#_1","title":"\u4ecb\u7ecd","text":"<p>\u51fa\u81ea\u8bba\u6587\u300aGAUSSIAN ERROR LINEAR UNITS (GELUS)\u300b</p> <p>\u529f\u80fd\uff1a</p> <p>\u2003\u2003\u9010\u5143\u7d20\u5bf9\u6570\u636e\u5e94\u7528\u5982\u4e0b\u51fd\u6570\u516c\u5f0f\u8fdb\u884c\u6fc0\u6d3b $$ GELU(x)=x*\\Phi(x) $$  \u5176\u4e2d\\Phi(x)\u662f\u6807\u51c6\u6b63\u6001\u5206\u5e03\u7684\u79ef\u7d2f\u5206\u5e03\u51fd\u6570\uff1a $$ \\Phi(x)=\\int^x_{-\\infty}\\frac{e^{-t^2/2}}{\\sqrt{2\\pi}}dt=\\frac12[1+erf(\\frac x{\\sqrt2})] $$  \u5176\u4e2derf(\u00b7)\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ erf(x)=\\frac2{\\sqrt\\pi}\\int^x_0e^{-t^2}dt $$  \u5bf9GELU\u6c42\u5bfc\uff0c\u53ef\u5f97\u5230\u5bfc\u51fd\u6570\uff1a $$ GELU'(x)=\\frac12(1+erf(\\frac x{\\sqrt2}))+\\frac{x}{\\sqrt{2\\pi}}e^{-\\frac{x^2}{2}} $$  \u6ce8\uff1a</p> <ul> <li>\u8f93\u51fa\u6570\u636e\u5c3a\u5bf8\u4e0e\u8f93\u5165\u6570\u636e\u5c3a\u5bf8\u76f8\u540c\uff1b</li> </ul> <p>\u4f18\u70b9</p> <ul> <li>\u76f8\u6bd4\u4e8eReLU\uff0cGELU\u51fd\u6570\u5728\u4e34\u8fd1\u539f\u70b9\u65f6\u68af\u5ea6\u4e0d\u4e3a\u96f6\uff0c\u51cf\u5c11\u4e86\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u68af\u5ea6\u6d88\u5931\u7684\u95ee\u9898\uff1b</li> <li>\u5bfc\u51fd\u6570\u6bd4\u8f83\u5149\u6ed1\uff0c\u65e0\u95f4\u65ad\u60c5\u51b5\uff0c\u5bb9\u6613\u505a\u53cd\u5411\u4f20\u64ad\uff1b</li> <li>RELU\u8ba1\u7b97\u590d\u6742\u5ea6\u8f83\u4f4e\uff0c\u540c\u65f6\u5177\u6709\u826f\u597d\u7684\u6027\u80fd\uff0c\u5e38\u7528\u4e8e\u5927\u89c4\u6a21\u8bad\u7ec3\u7684\u4efb\u52a1\uff0c\u4f8b\u5982BERT\u3001GPT\u7b49\u7b49\u3002</li> </ul> <p>\u51fd\u6570\u56fe\u50cf</p> <p>\u2003\u2003\u4e0b\u56fe\u5de6\u4fa7\u4e3aGELU\u6fc0\u6d3b\u51fd\u6570\u56fe\u50cf\uff0c\u53f3\u4fa7\u4e3a\u5bfc\u51fd\u6570\u56fe\u50cf\uff1a</p> <p> <p></p> <p></p>"},{"location":"PyTorch/nn/activations/nn.GELU/#_2","title":"\u4ee3\u7801\u6848\u4f8b","text":"<pre><code>import torch.nn as nn\nimport torch\n\nGELU = nn.GELU()\nx = torch.rand(10)\nvalue = GELU(x)\nprint(x)\nprint(value)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code>tensor([0.7163, 0.9452, 0.6216, 0.5953, 0.5593, 0.1129, 0.9343, 0.4854, 0.3826,\n        0.2847])\ntensor([0.5466, 0.7823, 0.4555, 0.4311, 0.3982, 0.0615, 0.7708, 0.3331, 0.2483,\n        0.1742])\n</code></pre> <p>\u6ce8\uff1a\u7ed8\u56fe\u7a0b\u5e8f</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.special import erf\n\n\ndef gelu(x):\n    return 0.5 * x * (1 + erf(x / np.sqrt(2)))\n\n\ndef gelu_activation(x):\n    return 0.5 * (1 + erf(x / np.sqrt(2))) + x / np.sqrt(2 * np.pi) * np.exp(-x ** 2 / 2)\n\n\n# \u751f\u6210x\u8f74\u6570\u636e\nx = np.linspace(-5, 5, 100)\n\n# \u8ba1\u7b97GeLU\u51fd\u6570\u548c\u5176\u5bfc\u6570\ny_gelu = gelu(x)\ny_gelu_activation = gelu_activation(x)\n\n# \u521b\u5efa\u56fe\u5f62\u548c\u5b50\u56fe\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n\n# \u7ed8\u5236GeLU\u51fd\u6570\u56fe\u50cf\nax1.plot(x, y_gelu, color='blue')\nax1.set_title('GeLU Function')\nax1.set_xlabel('x')\nax1.set_ylabel('GeLU(x)')\nax1.grid(True)\n\n# \u7ed8\u5236GeLU\u51fd\u6570\u5bfc\u6570\u56fe\u50cf\nax2.plot(x, y_gelu_activation, color='red')\nax2.set_title('GeLU Activation Function')\nax2.set_xlabel('x')\nax2.set_ylabel('GeLU\\'(x)')\nax2.grid(True)\n\n# \u663e\u793a\u56fe\u5f62\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"PyTorch/nn/activations/nn.GELU/#_3","title":"\u5b98\u65b9\u6587\u6863","text":"<p>nn.GELU\uff1ahttps://pytorch.org/docs/1.9.1/generated/torch.nn.GELU.html</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2024\u5e742\u670818\u65e5</p>"},{"location":"PyTorch/nn/activations/nn.LeakyReLU/","title":"LeakyReLU\u6fc0\u6d3b\u51fd\u6570","text":"<p>\u529f\u80fd\uff1a\u9010\u5143\u7d20\u5bf9\u6570\u636e\u5e94\u7528\u5982\u4e0b\u51fd\u6570\u516c\u5f0f\u8fdb\u884c\u6fc0\u6d3b $$ \\text{LeakyReLU}(x)=\\max(0,x)+\\alpha*\\min(0,x) $$  \u6216\u8005 $$ \\begin{aligned} \\text{LeakyReLU}(x)= \\left\\{ \\begin{matrix}  x,\\quad &amp;if\\quad x\u22650 \\\\ \\alpha\\times x,\\quad &amp;\\text{otherwise} \\end{matrix}  \\right. \\end{aligned} $$  \u8be5\u51fd\u6570\u76f8\u6bd4\u4e8eReLU\uff0c\u4fdd\u7559\u4e86\u4e00\u4e9b\u8d1f\u8f74\u7684\u503c\uff0c\u7f13\u89e3\u4e86\u6fc0\u6d3b\u503c\u8fc7\u5c0f\u800c\u5bfc\u81f4\u795e\u7ecf\u5143\u53c2\u6570\u65e0\u6cd5\u66f4\u65b0\u7684\u95ee\u9898\uff0c\u5176\u4e2d\\alpha\u9ed8\u8ba40.01\u3002</p> <p>\u51fd\u6570\u56fe\u50cf\uff1a</p> <p> <p></p> <p></p> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>negative_slope</code>\uff1a\u63a7\u5236\u8d1f\u6fc0\u6d3b\u503c\u7684\u659c\u7387\uff0c\u9ed8\u8ba41e-2</li> <li><code>inplace</code>\uff1a\u662f\u5426\u6539\u53d8\u8f93\u5165\u6570\u636e\uff0c\u5982\u679c\u8bbe\u7f6e\u4e3a<code>True</code>\uff0c\u5219\u4f1a\u76f4\u63a5\u4fee\u6539\u8f93\u5165\u6570\u636e\uff1b\u5982\u679c\u8bbe\u7f6e\u4e3a<code>False</code>\uff0c\u5219\u4e0d\u5bf9\u8f93\u5165\u6570\u636e\u505a\u4fee\u6539</li> </ul> <p>\u6ce8\u610f\uff1a</p> <ul> <li>\u8f93\u51fa\u6570\u636e\u4e0e\u8f93\u5165\u6570\u636e\u5c3a\u5bf8\u76f8\u540c</li> </ul>"},{"location":"PyTorch/nn/activations/nn.LeakyReLU/#_1","title":"\u4ee3\u7801\u6848\u4f8b","text":"<p>\u4e0eReLU\u505a\u6bd4\u8f83</p> <pre><code>import torch.nn as nn\nimport torch\n\nLeakyReLU = nn.LeakyReLU(negative_slope=5e-2)\nReLU = nn.ReLU()\nx = torch.randn(10)\nvalue = ReLU(x)\nvalue_l = LeakyReLU(x)\nprint(x)\nprint(value)\nprint(value_l)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u8f93\u5165\ntensor([ 0.1820, -0.4248, -0.9135,  0.1136, -1.0147, -0.5044,  0.1361,  0.0744,\n         1.3379, -1.1290])\n# ReLU\ntensor([0.1820, 0.0000, 0.0000, 0.1136, 0.0000, 0.0000, 0.1361, 0.0744, 1.3379,\n        0.0000])\n# LeakyReLU\ntensor([ 0.1820, -0.0212, -0.0457,  0.1136, -0.0507, -0.0252,  0.1361,  0.0744,\n         1.3379, -0.0564])\n</code></pre> <p>\u6ce8\uff1a\u7ed8\u56fe\u7a0b\u5e8f</p> <pre><code>import torch.nn as nn\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nLeakyReLU = nn.LeakyReLU(negative_slope=5e-2)\nx = torch.from_numpy(np.linspace(-3,3,100))\nvalue = LeakyReLU(x)\nplt.plot(x, value)\nplt.savefig('LeakyReLU.jpg')\n</code></pre>"},{"location":"PyTorch/nn/activations/nn.LeakyReLU/#_2","title":"\u5b98\u65b9\u6587\u6863","text":"<p>nn.LeakyReLU\uff1ahttps://pytorch.org/docs/stable/generated/torch.nn.LeakyReLU.html#torch.nn.LeakyReLU</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e742\u670816\u65e5</p>"},{"location":"PyTorch/nn/activations/nn.PReLU/","title":"PReLU\u6fc0\u6d3b\u51fd\u6570","text":"<pre><code>torch.nn.PReLU(num_parameters=1, init=0.25, device=None, dtype=None)\n</code></pre> <p>\u529f\u80fd\uff1a\u9010\u5143\u7d20\u5bf9\u6570\u636e\u5e94\u7528\u5982\u4e0b\u51fd\u6570\u516c\u5f0f\u8fdb\u884c\u6fc0\u6d3b $$ \\text{PReLU}(x)=\\max(0,x)+a*\\min(0,x) $$  \u6216\u8005 $$ \\begin{aligned} \\text{PReLU}(x)=\\left\\{ \\begin{matrix}  x,\\quad &amp;if\\quad x \u22650\\\\ ax,&amp;\\text{otherwise} \\end{matrix}  \\right. \\end{aligned} $$  \u6b64\u6fc0\u6d3b\u51fd\u6570\u4e0eLeakyReLU\u6fc0\u6d3b\u51fd\u6570\u975e\u5e38\u76f8\u4f3c\uff0c\u90fd\u53ef\u4ee5\u4fdd\u7559\u8d1f\u6fc0\u6d3b\u6570\u636e\uff0c\u4f46\u4e0eLeakyReLU\u6700\u5927\u7684\u4e0d\u540c\u5728\u4e8ePReLU\u4e2d\u7684\u53c2\u6570a\u662f\u53ef\u5b66\u4e60\u7684\uff0c\u800cLeakyReLU\u4e2d\u7684a\u662f\u4e00\u4e2a\u5b9a\u503c\u3002</p> <p>\u51fd\u6570\u56fe\u50cf\uff1a</p> <p> <p></p> <p></p> <p>\u8fd9\u91cc\u4e0eLeakyReLU\u56fe\u50cf\u975e\u5e38\u76f8\u4f3c\u3002</p> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>num_parameters</code>(\u6574\u6570)\uff1a\u53ef\u5b66\u4e60\u53c2\u6570a\u7684\u6570\u91cf\uff0c\u53ea\u6709\u4e24\u79cd\u9009\u62e9\uff0c\u8981\u4e48\u5b9a\u4e49\u62101\uff0c\u8868\u793a\u5728\u6240\u6709\u901a\u9053\u4e0a\u5e94\u7528\u76f8\u540c\u7684a\u8fdb\u884c\u6fc0\u6d3b\uff0c\u8981\u4e48\u5b9a\u4e49\u6210\u8f93\u5165\u6570\u636e\u7684\u901a\u9053\u6570\uff0c\u8868\u793a\u5728\u6240\u6709\u901a\u9053\u4e0a\u5e94\u7528\u4e0d\u540c\u7684a\u8fdb\u884c\u6fc0\u6d3b\uff0c\u9ed8\u8ba41\u3002</li> <li><code>init</code>(float)\uff1aa\u7684\u521d\u59cb\u503c</li> </ul> <p>\u6ce8\u610f\uff1a</p> <ul> <li>\u8f93\u5165\u6570\u636e\u7684\u7b2c\u4e8c\u7ef4\u5ea6\u8868\u793a\u4e3a\u901a\u9053\u7ef4\u5ea6\uff0c\u5f53\u8f93\u5165\u7ef4\u5ea6\u5c0f\u4e8e2\u65f6\uff0c\u4e0d\u5b58\u5728\u901a\u9053\u7ef4\u5ea6\uff0c\u6b64\u65f6\u9ed8\u8ba4\u901a\u9053\u6570\u4e3a1</li> <li>\u53ef\u4ee5\u901a\u8fc7\u8c03\u7528<code>.weight</code>\u65b9\u6cd5\u6765\u53d6\u51fa\u53c2\u6570a</li> <li>\u5373\u4f7f\u6709\u591a\u4e2aa\uff0c<code>init</code>\u4e5f\u8fd8\u662f\u53ea\u80fd\u8f93\u5165\u4e00\u4e2a<code>float</code>\u7c7b\u578b\u7684\u6570</li> </ul>"},{"location":"PyTorch/nn/activations/nn.PReLU/#_1","title":"\u4ee3\u7801\u6848\u4f8b","text":"<p>\u4e00\u822c\u7528\u6cd5</p> <pre><code>import torch.nn as nn\nimport torch\n\nPReLU = nn.PReLU()\nx = torch.randn(10)\nvalue = PReLU(x)\nprint(x)\nprint(value)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u8f93\u5165\ntensor([ 0.2399, -0.3208, -0.7234,  1.6305,  0.5196, -0.7686,  0.1195, -0.2320,\n         1.2424, -0.7216])\n# \u6fc0\u6d3b\u503c\ntensor([ 0.2399, -0.0802, -0.1809,  1.6305,  0.5196, -0.1922,  0.1195, -0.0580,\n         1.2424, -0.1804], grad_fn=&lt;PreluBackward&gt;)\n</code></pre> <p>\u6709\u591a\u4e2aa\u65f6</p> <pre><code>import torch.nn as nn\nimport torch\n\nPReLU = nn.PReLU(num_parameters=3, init=0.1)\nx = torch.randn(12).reshape(4,3)\nvalue = PReLU(x)\nprint(x)\nprint(value)\nprint(PReLU.weight)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u8f93\u5165\ntensor([[-0.5554,  0.2285,  1.0417],\n        [ 0.0180,  0.1619,  2.1579],\n        [ 0.1636, -1.1147, -1.9901],\n        [-0.4662,  1.5423,  0.0380]])\n# \u8f93\u51fa\ntensor([[-0.0555,  0.2285,  1.0417],\n        [ 0.0180,  0.1619,  2.1579],\n        [ 0.1636, -0.1115, -0.1990],\n        [-0.0466,  1.5423,  0.0380]], grad_fn=&lt;PreluBackward&gt;)\n# \u53c2\u6570a\nParameter containing:\ntensor([0.1000, 0.1000, 0.1000], requires_grad=True)\n</code></pre> <p>\u6ce8\uff1a\u7ed8\u56fe\u4ee3\u7801</p> <pre><code>import torch.nn as nn\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nPReLU = nn.PReLU()\nx = torch.tensor(np.linspace(-5,5,100), dtype=torch.float32)\nvalue = PReLU(x)\nplt.plot(x, value.detach().numpy())\nplt.savefig('PReLU.jpg')\n</code></pre>"},{"location":"PyTorch/nn/activations/nn.PReLU/#_2","title":"\u5b98\u65b9\u6587\u6863","text":"<p>nn.PReLU\uff1ahttps://pytorch.org/docs/stable/generated/torch.nn.PReLU.html#torch.nn.PReLU</p>"},{"location":"PyTorch/nn/activations/nn.ReLU/","title":"ReLU\u6fc0\u6d3b\u51fd\u6570","text":"<pre><code>torch.nn.ReLU(inplace=False)\n</code></pre> <p>\u529f\u80fd\uff1a\u9010\u5143\u7d20\u5e94\u7528ReLU\u51fd\u6570\u5bf9\u6570\u636e\u8fdb\u884c\u6fc0\u6d3b</p> <p>\u51fd\u6570\u65b9\u7a0b\uff1a $$ ReLU(x)=(x)^+=\\max(0,x) $$ </p> <p> <p></p> <p></p> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>inplace</code>\uff1a\u662f\u5426\u6539\u53d8\u8f93\u5165\u6570\u636e\uff0c\u5982\u679c\u8bbe\u7f6e\u4e3a<code>True</code>\uff0c\u5219\u4f1a\u76f4\u63a5\u4fee\u6539\u8f93\u5165\u6570\u636e\uff1b\u5982\u679c\u8bbe\u7f6e\u4e3a<code>False</code>\uff0c\u5219\u4e0d\u5bf9\u8f93\u5165\u6570\u636e\u505a\u4fee\u6539</li> </ul> <p>\u6ce8\u610f\uff1a</p> <ul> <li>\u8f93\u5165\u53ef\u4ee5\u662f\u4efb\u610f\u5c3a\u5bf8\u7684\u6570\u636e\uff0c\u8f93\u51fa\u5c3a\u5bf8\u4e0e\u8f93\u5165\u5c3a\u5bf8\u76f8\u540c</li> </ul>"},{"location":"PyTorch/nn/activations/nn.ReLU/#_1","title":"\u4ee3\u7801\u6848\u4f8b","text":"<p>\u4e00\u822c\u7528\u6cd5</p> <pre><code>import torch.nn as nn\nimport torch\na = torch.randn(10)\nrelu = nn.ReLU()\nb = relu(a)\nprint(a)\nprint(b)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u7ecf\u8fc7relu\u4e4b\u524d\ntensor([ 1.4481, -1.6880,  1.1357,  2.2152, -1.9795, -1.3784, -0.5270, -0.5725, 1.5533, -1.7112])\n# \u7ecf\u8fc7relu\u4e4b\u540e\ntensor([1.4481, 0.0000, 1.1357, 2.2152, 0.0000, 0.0000, 0.0000, 0.0000, 1.5533, 0.0000])\n</code></pre>"},{"location":"PyTorch/nn/activations/nn.ReLU/#_2","title":"\u5b98\u65b9\u6587\u6863","text":"<p>nn.ReLU()\uff1ahttps://pytorch.org/docs/stable/generated/torch.nn.ReLU.html?highlight=relu#torch.nn.ReLU</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e741\u670828\u65e5</p>"},{"location":"PyTorch/nn/activations/nn.Sigmoid/","title":"Sigmoid\u6fc0\u6d3b\u51fd\u6570","text":"<pre><code>torch.nn.Sigmoid()\n</code></pre> <p>\u529f\u80fd\uff1a\u9010\u5143\u7d20\u5e94\u7528Sigmoid\u51fd\u6570\u5bf9\u6570\u636e\u8fdb\u884c\u6fc0\u6d3b\uff0c\u5c06\u5143\u7d20\u5f52\u4e00\u5316\u5230\u533a\u95f4(0,1)\u5185</p> <p>\u51fd\u6570\u65b9\u7a0b\uff1a $$ Sigmoid(x)=\\sigma(x)=\\frac1{1+e^{-x}} $$ </p> <p> <p></p> <p></p> <p>\u4e0a\u56fe\u6765\u6e90\u4e8ePyTorch\u5b98\u65b9\u6587\u6863</p> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>inplace</code>\uff1a\u662f\u5426\u6539\u53d8\u8f93\u5165\u6570\u636e\uff0c\u5982\u679c\u8bbe\u7f6e\u4e3a<code>True</code>\uff0c\u5219\u4f1a\u76f4\u63a5\u4fee\u6539\u8f93\u5165\u6570\u636e\uff1b\u5982\u679c\u8bbe\u7f6e\u4e3a<code>False</code>\uff0c\u5219\u4e0d\u5bf9\u8f93\u5165\u6570\u636e\u505a\u4fee\u6539</li> </ul> <p>\u6ce8\u610f\uff1a</p> <ul> <li>\u8f93\u5165\u53ef\u4ee5\u662f\u4efb\u610f\u5c3a\u5bf8\u7684\u6570\u636e\uff0c\u8f93\u51fa\u5c3a\u5bf8\u4e0e\u8f93\u5165\u5c3a\u5bf8\u76f8\u540c</li> </ul>"},{"location":"PyTorch/nn/activations/nn.Sigmoid/#_1","title":"\u4ee3\u7801\u6848\u4f8b","text":"<p>\u4e00\u822c\u7528\u6cd5</p> <pre><code>import torch.nn as nn\nimport torch\na = torch.randn(10)\nsigmoid = nn.Sigmoid()\nb = sigmoid(a)\nprint(a)\nprint(b)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u6570\u636e\u7ecf\u8fc7sigmoid\u4e4b\u524d\ntensor([-0.0175, -0.3315, -1.4424, -2.1318,  1.8448, -0.6835, -1.9436,  1.3432, 0.2550,  1.1898])\n# \u6570\u636e\u7ecf\u8fc7sigmoid\u4e4b\u540e\ntensor([0.4956, 0.4179, 0.1912, 0.1060, 0.8635, 0.3355, 0.1252, 0.7930, 0.5634, 0.7667])\n</code></pre>"},{"location":"PyTorch/nn/activations/nn.Sigmoid/#_2","title":"\u5b98\u65b9\u6587\u6863","text":"<p>nn.Sigmoid()\uff1ahttps://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html#torch.nn.Sigmoid</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e741\u670829\u65e5</p>"},{"location":"PyTorch/nn/activations/nn.Tanh/","title":"Tanh\u6fc0\u6d3b\u51fd\u6570","text":"<pre><code>torch.nn.Tanh()\n</code></pre> <p>\u529f\u80fd\uff1a\u9010\u5143\u7d20\u5e94\u7528Tanh\u51fd\u6570\uff08\u53cc\u66f2\u6b63\u5207\uff09\u5bf9\u6570\u636e\u8fdb\u884c\u6fc0\u6d3b\uff0c\u5c06\u5143\u7d20\u8c03\u6574\u5230\u533a\u95f4(-1,1)\u5185</p> <p>\u51fd\u6570\u65b9\u7a0b\uff1a $$ \\text{Tanh}(x)=\\text{tanh}(x)=\\frac{e^x-e^{-x}}{e^x+e^{-x}} $$ </p> <p> <p></p> <p></p> <p>\u6ce8\u610f\uff1a</p> <ul> <li>\u8f93\u5165\u53ef\u4ee5\u662f\u4efb\u610f\u5c3a\u5bf8\u7684\u6570\u636e\uff0c\u8f93\u51fa\u5c3a\u5bf8\u4e0e\u8f93\u5165\u5c3a\u5bf8\u76f8\u540c</li> <li>\u8be5\u6fc0\u6d3b\u51fd\u6570\u5b9a\u4e49\u65f6\u65e0\u8f93\u5165</li> </ul>"},{"location":"PyTorch/nn/activations/nn.Tanh/#_1","title":"\u4ee3\u7801\u6848\u4f8b","text":"<p>\u4e00\u822c\u7528\u6cd5</p> <pre><code>import torch.nn as nn\nimport torch\n\nTanh = nn.Tanh()\nx = torch.randn(10)\nvalue = Tanh(x)\nprint(x)\nprint(value)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u8f93\u5165\ntensor([-0.7827, -0.3373,  0.2476, -0.5910, -1.2637,  1.0676,  1.1027, -0.8984,\n        -0.0252, -0.1457])\n# \u6570\u636e\u7ecf\u8fc7Tanh\u6fc0\u6d3b\u51fd\u6570\u4e4b\u540e\ntensor([-0.6542, -0.3251,  0.2426, -0.5306, -0.8521,  0.7885,  0.8015, -0.7155,\n        -0.0252, -0.1447])\n</code></pre> <p>\u6ce8\uff1a\u7ed8\u56fe\u7a0b\u5e8f</p> <pre><code>import torch.nn as nn\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nTanh = nn.Tanh()\nx = torch.from_numpy(np.linspace(-5,5,100))\nvalue = Tanh(x)\nplt.plot(x, value)\nplt.savefig('Tanh.jpg')\n</code></pre>"},{"location":"PyTorch/nn/activations/nn.Tanh/#_2","title":"\u5b98\u65b9\u6587\u6863","text":"<p>nn.Tanh()\uff1ahttps://pytorch.org/docs/stable/generated/torch.nn.Tanh.html#torch.nn.Tanh</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e742\u670816\u65e5</p>"},{"location":"PyTorch/nn/layers/nn.AdaptiveAvgPool2d/","title":"\u4e8c\u7ef4\u81ea\u9002\u5e94\u5e73\u5747\u6c60\u5316","text":"<pre><code>torch.nn.AdaptiveAvgPool2d(output_size)\n</code></pre> <p>\u529f\u80fd\uff1a\u8be5\u51fd\u6570\u4e0e\u4e8c\u7ef4\u5e73\u5747\u6c60\u5316\u8fd0\u7b97\u7c7b\u4f3c\uff0c\u533a\u522b\u4e3b\u8981\u4f53\u73b0\u5728\u81ea\u9002\u5e94\u4e0a\uff0c\u5bf9\u4e8e\u4efb\u4f55\u8f93\u5165\u5927\u5c0f\uff0c\u8f93\u51fa\u5927\u5c0f\u5747\u4e3a\u6307\u5b9a\u7684H\u00d7W\u5927\u5c0f\u3002</p> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>output_size</code>\uff1a\u6307\u5b9a\u7684\u8f93\u51fa\u5927\u5c0f\uff0c\u53ef\u4ee5\u662f\u5143\u7ec4(H\uff0cW)\uff0c\u6216\u8005\u662f\u5355\u4e2a\u7684\u6570\uff0c\u5982\u679c\u662f\u5355\u4e2a\u7684\u6570\uff0c\u5219\u8868\u793a\u8f93\u51fa\u7684\u9ad8\u548c\u5bbd\u5c3a\u5bf8\u4e00\u6837\uff0c<code>output_size</code>\u5927\u5c0f\u53ef\u4ee5\u5927\u4e8e\u8f93\u5165\u7684\u56fe\u7247\u5c3a\u5bf8\u5927\u5c0f\u3002</li> </ul>"},{"location":"PyTorch/nn/layers/nn.AdaptiveAvgPool2d/#_2","title":"\u4ee3\u7801\u6848\u4f8b","text":"<p>\u4e00\u822c\u7528\u6cd5</p> <pre><code>import torch\nfrom torch import nn\nimg=torch.arange(24,dtype=torch.float).reshape(1,1,4,6)\npool_1=nn.AdaptiveAvgPool2d((2,3))\npool_2=nn.AdaptiveAvgPool2d(2)\nimg_1=pool_1(img)\nimg_2=pool_2(img)\nprint(img)\nprint(img_1)\nprint(img_2)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u539f\u56fe\ntensor([[[[ 0.,  1.,  2.,  3.,  4.,  5.],\n          [ 6.,  7.,  8.,  9., 10., 11.],\n          [12., 13., 14., 15., 16., 17.],\n          [18., 19., 20., 21., 22., 23.]]]])\n# \u8f93\u51fa\u5927\u5c0f\u6307\u5b9a\u4e3a(2,3)\ntensor([[[[ 3.5000,  5.5000,  7.5000],\n          [15.5000, 17.5000, 19.5000]]]])\n# \u8f93\u51fa\u5927\u5c0f\u6307\u5b9a\u4e3a(2,2)\ntensor([[[[ 4.,  7.],\n          [16., 19.]]]])\n</code></pre> <p>\u5f53<code>output_size</code>\u6307\u5b9a\u4e3a1\u65f6\uff0c\u76f8\u5f53\u4e8e\u5168\u5c40\u5e73\u5747\u6c60\u5316</p> <pre><code>import torch\nfrom torch import nn\nimg=torch.arange(48,dtype=torch.float).reshape(1,2,4,6)\npool=nn.AdaptiveAvgPool2d(1)\nimg_1=pool(img)\nprint(img_1)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u4e0d\u540c\u901a\u9053\u5206\u522b\u505a\u6c60\u5316\u8fd0\u7b97\ntensor([[[[11.5000]],\n\n         [[35.5000]]]])\n</code></pre>"},{"location":"PyTorch/nn/layers/nn.AdaptiveAvgPool2d/#_3","title":"\u5b98\u65b9\u6587\u6863","text":"<p>nn.AdaptiveAvgPool2d()\uff1ahttps://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool2d.html?highlight=avgpool2d#torch.nn.AdaptiveAvgPool2d</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e749\u670828\u65e5</p>"},{"location":"PyTorch/nn/layers/nn.AvgPool2d/","title":"\u4e8c\u7ef4\u5e73\u5747\u6c60\u5316","text":"<pre><code>torch.nn.AvgPool2d( kernel_size , stride=None , padding=0 , ceil_mode=False , count_include_pad=True , divisor_override=None )\n</code></pre> <p>\u529f\u80fd\uff1a\u5728\u7531\u591a\u4e2a\u5e73\u9762\u7ec4\u6210\u7684\u8f93\u5165\u4fe1\u53f7\u4e0a\u5e94\u75282D\u5e73\u5747\u6c60\u5316\u64cd\u4f5c\uff0c\u5177\u4f53\u8ba1\u7b97\u516c\u5f0f\u5982\u4e0b\uff1a $$ out(N_i,C_i,h,w)=\\frac{1}{kH*kW}\\sum^{kH-1}_{m=0}\\sum^{kH-1}_{m=0}input(N_i,C_i,stride[0]\\times h+m,stride[1]\\times w+n)\\\\ \u5047\u8bbe\u8f93\u5165\u5c3a\u5bf8\u662f(N,C,H,W),\u8f93\u51fa\u5c3a\u5bf8\u662f(N,C,H_{out},W_{out}),\u6c60\u5316\u6838\u5c3a\u5bf8\u662f(kH,kW) $$  \u5982\u679c<code>padding</code>\u975e\u96f6\uff0c\u5219\u4f1a\u5728\u8f93\u5165\u56fe\u50cf\u7684\u56db\u5468\u9690\u5f0f\u5730\u586b\u51450\uff0c\u53ef\u4ee5\u901a\u8fc7\u6307\u5b9a\u53c2\u6570<code>count_include_pad</code>\u6765\u786e\u5b9a\u662f\u5426\u5c06\u8be50\u7eb3\u5165\u6c60\u5316\u8ba1\u7b97\u8fc7\u7a0b\u3002</p> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>kernel_size</code>\uff1a\u6c60\u5316\u6838\u7684\u5c3a\u5bf8\u5927\u5c0f</li> <li><code>stride</code>\uff1a\u7a97\u53e3\u7684\u79fb\u52a8\u6b65\u5e45\uff0c\u9ed8\u8ba4\u4e0e<code>kernel_size</code>\u5927\u5c0f\u4e00\u81f4</li> <li><code>padding</code>\uff1a\u5728\u4e24\u4fa7\u7684\u96f6\u586b\u5145\u5bbd\u5ea6\u5927\u5c0f</li> <li><code>ceil_mode</code>\uff1a\u8bbe\u4e3a<code>True</code>\u65f6\uff0c\u5728\u8ba1\u7b97\u8f93\u51fa\u5f62\u72b6\u7684\u8fc7\u7a0b\u4e2d\u91c7\u7528\u5411\u4e0a\u53d6\u6574\u7684\u64cd\u4f5c\uff0c\u5426\u5219\uff0c\u91c7\u7528\u5411\u4e0b\u53d6\u6574</li> <li><code>count_include_pad</code>\uff1a\u5e03\u5c14\u7c7b\u578b\uff0c\u5f53\u4e3a<code>True</code>\u65f6\uff0c\u5c06\u5728\u5e73\u5747\u6c60\u5316\u8ba1\u7b97\u4e2d\u5305\u62ec\u96f6\u586b\u5145\uff0c\u5426\u5219\uff0c\u4e0d\u5305\u62ec\u96f6\u586b\u5145</li> <li><code>divisor_override</code>\uff1a\u5982\u679c\u88ab\u6307\u5b9a\uff0c\u5219\u9664\u6570\u4f1a\u88ab\u4ee3\u66ff\u6210<code>divisor_override</code>\u3002\u6362\u53e5\u8bdd\u8bf4\uff0c\u5982\u679c\u4e0d\u6307\u5b9a\u8be5\u53d8\u91cf\uff0c\u5219\u5e73\u5747\u6c60\u5316\u7684\u8ba1\u7b97\u8fc7\u7a0b\u5176\u5b9e\u662f\u5728\u4e00\u4e2a\u6c60\u5316\u6838\u5185\uff0c\u5c06\u5143\u7d20\u76f8\u52a0\u518d\u9664\u4ee5\u6c60\u5316\u6838\u7684\u5927\u5c0f\uff0c\u4e5f\u5c31\u662f<code>divisor_override</code>\u9ed8\u8ba4\u4e3a\u6c60\u5316\u6838\u7684\u9ad8\u00d7\u5bbd\uff1b\u5982\u679c\u8be5\u53d8\u91cf\u88ab\u6307\u5b9a\uff0c\u5219\u6c60\u5316\u8fc7\u7a0b\u4e3a\u5c06\u6c60\u5316\u6838\u5185\u5143\u7d20\u76f8\u52a0\u518d\u9664\u4ee5<code>divisor_override</code>\u3002</li> </ul> <p>\u6ce8\u610f\uff1a</p> <ul> <li> <p>\u53c2\u6570\u7684<code>kernel_size</code>\u3001<code>stride</code>\u3001<code>padding</code>\u53ef\u4ee5\u662f\uff1a</p> </li> <li> <p>\u6574\u6570\uff0c\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u9ad8\u548c\u5bbd\u5c3a\u5bf8\u76f8\u540c</p> </li> <li> <p>\u5143\u7ec4\uff0c\u5305\u542b\u4e24\u4e2a\u6574\u6570\uff0c\u7b2c\u4e00\u4e2a\u7528\u4e8e\u9ad8\u5ea6\u7ef4\u5ea6\uff0c\u7b2c\u4e8c\u4e2a\u7528\u4e8e\u5bbd\u5ea6\u7ef4\u5ea6</p> </li> <li> <p>\u8f93\u51fa\u5f62\u72b6\u7684\u8ba1\u7b97\u516c\u5f0f\u4e3a\uff1a   $$   H_{out}=\\lfloor{\\frac{H_{in}+2\\times padding[0]-kernel\\_size[0]}{stride[0]}+1}\\rfloor\\\\   W_{out}=\\lfloor{\\frac{W_{in}+2\\times padding[1]-kernel\\_size[1]}{stride[1]}+1}\\rfloor\\\\   \u5176\u4e2d\uff0cH_{in}\u548cW_{in}\u4e3a\u8f93\u5165\u7684\u9ad8\u548c\u5bbd\uff0c\u9ed8\u8ba4\u5411\u4e0b\u53d6\u6574(\u53ef\u6307\u5b9a\u53c2\u6570\u6765\u4fee\u6539\u53d6\u6574\u89c4\u5219)   $$ </p> </li> <li> <p><code>padding</code>\u5927\u5c0f\u8981\u5c0f\u4e8e\u6c60\u5316\u6838\u7684\u5c3a\u5bf8\u5927\u5c0f</p> </li> </ul>"},{"location":"PyTorch/nn/layers/nn.AvgPool2d/#_2","title":"\u4ee3\u7801\u6848\u4f8b","text":"<p>\u4e00\u822c\u7528\u6cd5</p> <pre><code>import torch\nfrom torch import nn\nimg=torch.arange(16).reshape(1,1,4,4)\n# \u6c60\u5316\u6838\u548c\u6c60\u5316\u6b65\u957f\u5747\u4e3a2\npool=nn.AvgPool2d(2,stride=2)\nimg_2=pool(img)\nprint(img)\nprint(img_2)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u539f\u56fe\u50cf\ntensor([[[[ 0,  1,  2,  3],\n          [ 4,  5,  6,  7],\n          [ 8,  9, 10, 11],\n          [12, 13, 14, 15]]]])\n# \u6c60\u5316\u540e\u56fe\u50cf\uff0c\u957f\u5bbd\u5747\u4e3a\u539f\u6765\u7684\u4e00\u534a\ntensor([[[[ 2,  4],\n          [10, 12]]]])\n</code></pre> <p>ceil_mode\u8bbe\u4e3aTrue\u4e0eFasle\u7684\u533a\u522b</p> <pre><code>import torch\nfrom torch import nn\nimg=torch.arange(20,dtype=torch.float).reshape(1,1,4,5)\npool_f=nn.AvgPool2d(2,stride=2,padding=0,ceil_mode=False)\npool_t=nn.AvgPool2d(2,stride=2,padding=0,ceil_mode=True)\nimg_2=pool_f(img)\nimg_3=pool_t(img)\nprint(img)\nprint(img_2)\nprint(img_3)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u539f\u56fe\u50cf\ntensor([[[[ 0.,  1.,  2.,  3.,  4.],\n          [ 5.,  6.,  7.,  8.,  9.],\n          [10., 11., 12., 13., 14.],\n          [15., 16., 17., 18., 19.]]]])\n# \u9ed8\u8ba4\u60c5\u51b5\uff0cceil_mode\u4e3aFalse\ntensor([[[[ 3.,  5.],\n          [13., 15.]]]])\n# ceil_mode\u4e3aTrue\ntensor([[[[ 3.0000,  5.0000,  6.5000],\n          [13.0000, 15.0000, 16.5000]]]])\n# \u7531\u4e8e5\u4e0d\u80fd\u88ab2\u6574\u9664\uff0c\u6240\u4ee5\u4e00\u4e2a\u4e0b\u53d6\u6574\uff0c\u4e00\u4e2a\u4e0a\u53d6\u6574\n</code></pre> <p>padding\u8bbe\u4e0e\u4e0d\u8bbe\u7684\u533a\u522b</p> <pre><code>import torch\nfrom torch import nn\nimg=torch.arange(16,dtype=torch.float).reshape(1,1,4,4)\npool_t=nn.AvgPool2d(2,stride=2,padding=1)\npool_f=nn.AvgPool2d(2,stride=2)\nimg_2=pool_t(img)\nimg_3=pool_f(img)\nprint(img)\nprint(img_2)\nprint(img_3)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u539f\u56fe\ntensor([[[[ 0.,  1.,  2.,  3.],\n          [ 4.,  5.,  6.,  7.],\n          [ 8.,  9., 10., 11.],\n          [12., 13., 14., 15.]]]])\n# \u586b\u5145\u5bbd\u5ea6\u4e3a1\uff0c\u9ed8\u8ba4\u586b\u5145\u76840\u4f1a\u88ab\u7528\u4e8e\u6c60\u5316\u8ba1\u7b97\ntensor([[[[0.0000, 0.7500, 0.7500],\n          [3.0000, 7.5000, 4.5000],\n          [3.0000, 6.7500, 3.7500]]]])\n# \u672a\u586b\u5145\u7ed3\u679c\ntensor([[[[ 2.5000,  4.5000],\n          [10.5000, 12.5000]]]])\n# \u586b\u5145\u540e\u7684\u56fe\u50cf\u7ecf\u8fc7\u6c60\u5316\u8fd0\u7b97\u5f97\u5230\u7684\u56fe\u50cf\u5c3a\u5bf8\u53ef\u4ee5\u7528\u4e0a\u9762\u7684\u516c\u5f0f\u8ba1\u7b97\u51fa\u6765\n</code></pre> <p>count_include_pad\u8bbe\u4e3aTrue\u4e0eFalse\u7684\u533a\u522b</p> <pre><code>import torch\nfrom torch import nn\nimg=torch.arange(16,dtype=torch.float).reshape(1,1,4,4)\npool_t=nn.AvgPool2d(2,stride=2,padding=1,count_include_pad=True)\npool_f=nn.AvgPool2d(2,stride=2,padding=1,count_include_pad=False)\nimg_2=pool_t(img)\nimg_3=pool_f(img)\nprint(img)\nprint(img_2)\nprint(img_3)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u539f\u56fe\ntensor([[[[ 0.,  1.,  2.,  3.],\n          [ 4.,  5.,  6.,  7.],\n          [ 8.,  9., 10., 11.],\n          [12., 13., 14., 15.]]]])\n# \u586b\u5145\u5bbd\u5ea6\u4e3a1\uff0ccount_include_pad\u4e3aTrue(\u9ed8\u8ba4\u60c5\u51b5)\n# \u586b\u5145\u76840\u88ab\u7528\u4e8e\u6c60\u5316\u8ba1\u7b97\ntensor([[[[0.0000, 0.7500, 0.7500],\n          [3.0000, 7.5000, 4.5000],\n          [3.0000, 6.7500, 3.7500]]]])\n# \u586b\u5145\u76840\u672a\u88ab\u7528\u4e8e\u6c60\u5316\u8ba1\u7b97\ntensor([[[[ 0.0000,  1.5000,  3.0000],\n          [ 6.0000,  7.5000,  9.0000],\n          [12.0000, 13.5000, 15.0000]]]])\n</code></pre> <p>divisor_override\u8bbe\u4e0e\u672a\u8bbe\u7684\u533a\u522b</p> <pre><code>import torch\nfrom torch import nn\nimg=torch.arange(16,dtype=torch.float).reshape(1,1,4,4)\npool_1=nn.AvgPool2d(2,stride=2)\npool_d1=nn.AvgPool2d(2,stride=2,divisor_override=2)\npool_d2=nn.AvgPool2d(2,stride=2,divisor_override=3)\nimg_1=pool_1(img)\nimg_2=pool_d1(img)\nimg_3=pool_d2(img)\nprint(img)\nprint(img_1)\nprint(img_2)\nprint(img_3)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u539f\u56fe\u50cf\ntensor([[[[ 0.,  1.,  2.,  3.],\n          [ 4.,  5.,  6.,  7.],\n          [ 8.,  9., 10., 11.],\n          [12., 13., 14., 15.]]]])\n# \u672a\u8bbe\u7f6edivisor_override\uff0c\u6b64\u65f6\u662f\u666e\u901a\u7684\u5e73\u5747\u6c60\u5316\u64cd\u4f5c\ntensor([[[[ 2.5000,  4.5000],\n          [10.5000, 12.5000]]]])\n# divisor_override\u8bbe\u7f6e\u4e3a2\uff0c\u4ee5\u5de6\u4e0a\u89d2\u56db\u4e2a\u5143\u7d20\u4e3a\u4f8b\n# \u6c60\u5316\u540e\u7b2c\u4e00\u4e2a\u5143\u7d20\u4e3a\u539f\u56fe\u5de6\u4e0a\u89d2\u56db\u4e2a\u5143\u7d20\u76f8\u52a0\u9664\u4ee52\ntensor([[[[ 5.,  9.],\n          [21., 25.]]]])\n# divisor_override\u8bbe\u7f6e\u4e3a3,\n# \u5373\u56db\u4e2a\u5143\u7d20\u76f8\u52a0\u9664\u4ee53\ntensor([[[[ 3.3333,  6.0000],\n          [14.0000, 16.6667]]]])\n</code></pre>"},{"location":"PyTorch/nn/layers/nn.AvgPool2d/#_3","title":"\u5b98\u65b9\u6587\u6863","text":"<p>torch.nn.AvgPool2d()\uff1ahttps://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html?highlight=avgpool2d#torch.nn.AvgPool2d</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e749\u670828\u65e5</p>"},{"location":"PyTorch/nn/layers/nn.BatchNorm2d/","title":"\u6279\u91cf\u6807\u51c6\u5316\u5c42","text":"<pre><code>torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None)\n</code></pre> <p>\u529f\u80fd\uff1a\u5bf9\u8f93\u5165\u7684\u56db\u7ef4\u6570\u7ec4\u8fdb\u884c\u6279\u91cf\u6807\u51c6\u5316\u5904\u7406\uff0c\u5177\u4f53\u8ba1\u7b97\u516c\u5f0f\u5982\u4e0b\uff1a $$ y=\\frac{x-mean[x]}{\\sqrt{Var[x]+eps}}*gamma+beta $$ </p> <p>\u2003\u2003\u5bf9\u4e8e\u6240\u6709\u7684batch\u4e2d\u7684\u540c\u4e00\u4e2achannel\u7684\u6570\u636e\u5143\u7d20\u8fdb\u884c\u6807\u51c6\u5316\u5904\u7406\uff0c\u5373\u5982\u679c\u6709C\u4e2a\u901a\u9053\uff0c\u65e0\u8bba\u6709\u591a\u5c11\u4e2abatch\uff0c\u90fd\u4f1a\u5728\u901a\u9053\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u6807\u51c6\u5316\u5904\u7406\uff0c\u4e00\u5171\u8fdb\u884cC\u6b21\u3002</p> <p>\u2003\u2003\u8bad\u7ec3\u9636\u6bb5\u7684\u5747\u503c\u548c\u65b9\u5dee\u8ba1\u7b97\u65b9\u6cd5\u76f8\u540c\uff0c\u5c06\u540c\u4e00\u4e0bbatch\u901a\u9053\u76f8\u540c\u7684\u503c\u53d6\u51fa\u6765\uff0c\u4e00\u5757\u8ba1\u7b97\u5747\u503c\u548c\u65b9\u5dee\uff0c\u5373\u8ba1\u7b97\u5f53\u524d\u89c2\u6d4b\u503c\u7684\u5747\u503c\u548c\u65b9\u5dee\u3002</p> <p>\u2003\u2003\u6d4b\u8bd5\u9636\u6bb5\u7684\u5747\u503c\u548c\u65b9\u5dee\u6709\u4e24\u79cd\u8ba1\u7b97\u65b9\u6cd5\uff1a \u2003\u2003\u2460\u4f30\u8ba1\u6240\u6709\u56fe\u7247\u7684\u5747\u503c\u548c\u65b9\u5dee\uff0c\u5373\u505a\u5168\u5c40\u8ba1\u7b97\uff0c\u5177\u4f53\u8ba1\u7b97\u65b9\u6cd5\u5982\u4e0b\uff1a \u2003\u2003\u6a21\u578b\u5206\u522b\u50a8\u5b58\u5404\u4e2a\u901a\u9053(\u901a\u9053\u6570\u9700\u8981\u9884\u5148\u5b9a\u4e49)\u7684\u5747\u503c\u548c\u65b9\u5dee\u6570\u636e(\u521d\u59cb\u4e3a0\u548c1)\uff0c\u5728\u6bcf\u6b21\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6bcf\u6807\u51c6\u5316\u4e00\u7ec4\u6570\u636e\uff0c\u90fd\u5229\u7528\u8ba1\u7b97\u5f97\u5230\u7684\u5c40\u90e8\u89c2\u6d4b\u503c\u7684\u5747\u503c\u548c\u65b9\u5dee\u5bf9\u50a8\u5b58\u7684\u6570\u636e\u505a\u66f4\u65b0\uff0c\u6d4b\u8bd5\u9636\u6bb5\u5229\u7528\u6a21\u578b\u5b58\u50a8\u7684\u4e24\u4e2a\u6570\u636e\u505a\u6807\u51c6\u5316\u5904\u7406\uff0c\u66f4\u65b0\u516c\u5f0f\u5982\u4e0b\uff1a $$ X_{new}=(1-momentum)\\times X_{old} + momentum\\times X_t\\\\ \u5176\u4e2d\uff0cX_{new}\u662f\u6a21\u578b\u7684\u65b0\u53c2\u6570\uff0cX_{old}\u662f\u6a21\u578b\u539f\u6765\u7684\u53c2\u6570\uff0cX_t\u662f\u5f53\u524d\u89c2\u6d4b\u503c\u7684\u53c2\u6570 $$  \u2003\u2003\u2461\u91c7\u7528\u548c\u8bad\u7ec3\u9636\u6bb5\u76f8\u540c\u7684\u8ba1\u7b97\u65b9\u6cd5\uff0c\u5373\u53ea\u8ba1\u7b97\u5f53\u524d\u8f93\u5165\u6570\u636e\u7684\u5747\u503c\u548c\u65b9\u5dee</p> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>num_features</code>\uff1a\u8f93\u5165\u56fe\u50cf\u7684\u901a\u9053\u6570\u91cf\u3002</li> <li><code>eps</code>\uff1a\u7a33\u5b9a\u7cfb\u6570\uff0c\u9632\u6b62\u5206\u6bcd\u51fa\u73b00\u3002</li> <li><code>momentum</code>\uff1a\u6a21\u578b\u5747\u503c\u548c\u65b9\u5dee\u66f4\u65b0\u65f6\u7684\u53c2\u6570\uff0c\u89c1\u4e0a\u8ff0\u516c\u5f0f\u3002</li> <li><code>affine</code>\uff1a\u4ee3\u8868gamma\uff0cbeta\u662f\u5426\u53ef\u5b66\u3002\u5982\u679c\u8bbe\u4e3a<code>True</code>\uff0c\u4ee3\u8868\u4e24\u4e2a\u53c2\u6570\u662f\u901a\u8fc7\u5b66\u4e60\u5f97\u5230\u7684\uff1b\u5982\u679c\u8bbe\u4e3a<code>False</code>\uff0c\u4ee3\u8868\u4e24\u4e2a\u53c2\u6570\u662f\u56fa\u5b9a\u503c\uff0c\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0cgamma\u662f1\uff0cbeta\u662f0\u3002</li> <li><code>track_running_stats</code>\uff1a\u4ee3\u8868\u8bad\u7ec3\u9636\u6bb5\u662f\u5426\u66f4\u65b0\u6a21\u578b\u5b58\u50a8\u7684\u5747\u503c\u548c\u65b9\u5dee\uff0c\u5373\u6d4b\u8bd5\u9636\u6bb5\u7684\u5747\u503c\u4e0e\u65b9\u5dee\u7684\u8ba1\u7b97\u65b9\u6cd5\u91c7\u7528\u7b2c\u4e00\u79cd\u65b9\u6cd5\u8fd8\u662f\u7b2c\u4e8c\u79cd\u65b9\u6cd5\u3002\u5982\u679c\u8bbe\u4e3a<code>True</code>\uff0c\u5219\u4ee3\u8868\u8bad\u7ec3\u9636\u6bb5\u6bcf\u6b21\u8fed\u4ee3\u90fd\u4f1a\u66f4\u65b0\u6a21\u578b\u5b58\u50a8\u7684\u5747\u503c\u548c\u65b9\u5dee(\u8ba1\u7b97\u5168\u5c40\u6570\u636e)\uff0c\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\u5229\u7528\u5b58\u50a8\u7684\u5747\u503c\u548c\u65b9\u5dee\u5bf9\u5404\u4e2a\u901a\u9053\u8fdb\u884c\u6807\u51c6\u5316\u5904\u7406\uff1b\u5982\u679c\u8bbe\u4e3a<code>False</code>\uff0c\u5219\u6a21\u578b\u4e0d\u4f1a\u5b58\u50a8\u5747\u503c\u548c\u65b9\u5dee\uff0c\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4e5f\u4e0d\u4f1a\u66f4\u65b0\u5747\u503c\u548c\u65b9\u5dee\u7684\u6570\u636e\uff0c\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\u53ea\u8ba1\u7b97\u5f53\u524d\u8f93\u5165\u56fe\u50cf\u7684\u5747\u503c\u548c\u65b9\u5dee\u6570\u636e(\u5c40\u90e8\u6570\u636e)\u3002\u5177\u4f53\u533a\u522b\u89c1\u4ee3\u7801\u6848\u4f8b\u3002</li> </ul> <p>\u6ce8\u610f\uff1a</p> <ul> <li>\u8bad\u7ec3\u9636\u6bb5\u7684\u6807\u51c6\u5316\u8fc7\u7a0b\u4e2d\uff0c\u5747\u503c\u548c\u65b9\u5dee\u6765\u6e90\u9014\u5f84\u53ea\u6709\u4e00\u79cd\u65b9\u5f0f\uff0c\u5373\u5229\u7528\u5f53\u524d\u8f93\u5165\u7684\u6570\u636e\u8fdb\u884c\u8ba1\u7b97\uff1b</li> <li>\u6d4b\u8bd5\u9636\u6bb5\u7684\u6807\u51c6\u5316\u8fc7\u7a0b\u4e2d\uff0c\u5747\u503c\u548c\u65b9\u5dee\u6765\u6e90\u9014\u5f84\u6709\u4e24\u79cd\u65b9\u5f0f\uff0c\u4e00\u662f\u6765\u6e90\u4e8e\u5168\u5c40\u7684\u6570\u636e\uff0c\u5373\u6a21\u578b\u672c\u8eab\u5b58\u50a8\u4e00\u7ec4\u5747\u503c\u548c\u65b9\u5dee\u6570\u636e\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u4e0d\u65ad\u66f4\u65b0\u5b83\u4eec\uff0c\u4f7f\u5176\u5177\u6709\u63cf\u8ff0\u5168\u5c40\u6570\u636e\u7684\u7edf\u8ba1\u7279\u6027\uff1b\u4e8c\u662f\u6765\u6e90\u4e8e\u5f53\u524d\u7684\u8f93\u5165\u6570\u636e\uff0c\u5373\u548c\u8bad\u7ec3\u9636\u6bb5\u8ba1\u7b97\u65b9\u6cd5\u4e00\u6837\uff0c\u4f46\u8fd9\u6837\u4f1a\u5728\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\u5e26\u6765\u7edf\u8ba1\u7279\u6027\u504f\u79fb\u7684\u5f0a\u7aef\uff0c\u4e00\u822c<code>track_running_stats</code>\u8bbe\u7f6e\u4e3a<code>True</code>\uff0c\u5373\u91c7\u7528\u7b2c\u4e00\u79cd\u6765\u6e90\u9014\u5f84\uff1b</li> <li>\u91c7\u7528\u7b2c\u4e00\u79cd\u9014\u5f84\u65f6\uff0c\u53ea\u8981\u6709\u6570\u636e\u4f20\u5165BN\u5c42\uff0c\u5373\u505a\u4e86\u524d\u5411\u4f20\u64ad\uff0c\u5219BN\u5c42\u4e2d\u5b58\u50a8\u7684\u5168\u5c40\u5747\u503c\u548c\u65b9\u5dee\u5c31\u4f1a\u505a\u76f8\u5e94\u7684\u66f4\u65b0\uff0c\u65e0\u9700\u505a\u53cd\u5411\u4f20\u64ad\uff0c\u8fd9\u4e5f\u662f\u4e3a\u4ec0\u4e48\u6709\u7684\u6a21\u578b\u5373\u4f7f\u53ea\u505a\u524d\u5411\u4f20\u64ad\uff0c\u53c2\u6570\u4e5f\u4f1a\u53d1\u751f\u53d8\u5316\uff08\u4e00\u822c\u6307BN\u5c42\u4e2d\u7684\u53c2\u6570\uff09\uff1b</li> <li>\u6362\u53e5\u8bdd\u8bf4\uff0c\u5c31\u662f\u8bad\u7ec3\u9636\u6bb5\u548c\u6d4b\u8bd5\u9636\u6bb5\u6240\u627f\u8f7d\u7684\u4efb\u52a1\u4e0d\u540c\uff0c\u8bad\u7ec3\u9636\u6bb5\u4e3b\u8981\u662f\u901a\u8fc7\u5df2\u77e5\u7684\u6570\u636e\u53bb\u4f18\u5316\u6a21\u578b\uff0c\u800c\u6d4b\u8bd5\u9636\u6bb5\u4e3b\u8981\u662f\u5229\u7528\u5df2\u77e5\u7684\u6a21\u578b\u53bb\u9884\u6d4b\u672a\u77e5\u7684\u6570\u636e\u3002</li> </ul> <p>\u7528\u9014\uff1a</p> <ul> <li>\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u9047\u5230\u6536\u655b\u901f\u5ea6\u5f88\u6162\u7684\u95ee\u9898\u65f6\uff0c\u53ef\u4ee5\u901a\u8fc7\u5f15\u5165BN\u5c42\u6765\u52a0\u5feb\u7f51\u7edc\u6a21\u578b\u7684\u6536\u655b\u901f\u5ea6</li> <li>\u9047\u5230\u68af\u5ea6\u6d88\u5931\u6216\u8005\u68af\u5ea6\u7206\u70b8\u7684\u95ee\u9898\u65f6\uff0c\u53ef\u4ee5\u8003\u8651\u5f15\u5165BN\u5c42\u6765\u89e3\u51b3</li> <li>\u4e00\u822c\u60c5\u51b5\u4e0b\uff0c\u8fd8\u53ef\u4ee5\u901a\u8fc7\u5f15\u5165BN\u5c42\u6765\u52a0\u5feb\u7f51\u7edc\u7684\u8bad\u7ec3\u901f\u5ea6</li> </ul> <p>\u6279\u91cf\u6807\u51c6\u5316\u7684\u5177\u4f53\u539f\u7406\u8bf7\u53c2\u8003\u8bba\u6587\uff1aBatch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</p>"},{"location":"PyTorch/nn/layers/nn.BatchNorm2d/#_2","title":"\u4ee3\u7801\u6848\u4f8b","text":"<p>\u4e00\u822c\u7528\u6cd5</p> <pre><code>import torch\nfrom torch import nn\n# \u5728(0-1)\u8303\u56f4\u5185\u968f\u673a\u751f\u6210\u6570\u636e\nimg=torch.rand(2,2,2,3)\nbn=nn.BatchNorm2d(2)\nimg_2=bn(img)\nprint(img)\nprint(img_2)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u6807\u51c6\u5316\u524d\ntensor([[[[0.5330, 0.7753, 0.6192],\n          [0.9190, 0.1657, 0.5841]],\n\n         [[0.7766, 0.7864, 0.2004],\n          [0.9379, 0.3253, 0.1964]]],\n\n\n        [[[0.7448, 0.9222, 0.1860],\n          [0.3829, 0.8812, 0.2508]],\n\n         [[0.0130, 0.0405, 0.2205],\n          [0.8997, 0.5143, 0.9414]]]])\n# \u6807\u51c6\u5316\u540e\ntensor([[[[-0.1764,  0.7257,  0.1446],\n          [ 1.2605, -1.5434,  0.0140]],\n\n         [[ 0.8332,  0.8615, -0.8287],\n          [ 1.2987, -0.4685, -0.8403]]],\n\n\n        [[[ 0.6121,  1.2726, -1.4678],\n          [-0.7350,  1.1199, -1.2269]],\n\n         [[-1.3693, -1.2899, -0.7707],\n          [ 1.1883,  0.0769,  1.3088]]]], grad_fn=&lt;NativeBatchNormBackward&gt;)\n</code></pre> <p>\u6807\u51c6\u5316\u8fc7\u7a0b\u662f\u4ee5\u901a\u9053\u4e3a\u7ef4\u5ea6\u8ba1\u7b97\u7684\uff0c\u5373\u6240\u6709batch\u4e0b\uff0c\u76f8\u540c\u901a\u9053(channel)\u4e0b\u7684\u6570\u636e\u5408\u5e76\u5230\u4e00\u5757\uff0c\u505a\u6807\u51c6\u5316\u5904\u7406\u3002\u82e5\u6709C\u4e2a\u901a\u9053\uff0c\u65e0\u8bbabatch\u662f\u591a\u5c11\uff0c\u90fd\u4f1a\u6709C\u6b21\u6807\u51c6\u5316\u3002</p> <pre><code>import torch\nfrom torch import nn\nimg=torch.rand(2,2,2,3)\n# \u53d6\u51fa\u4e24\u4e2abatch\u4e0b\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u7684\u6570\u636e\na=torch.cat((img[0,0,:,:],img[1,0,:,:]),dim=0)\n# \u8f6c\u5316\u4e3anumpy\u683c\u5f0f\uff0c\u4fbf\u4e8e\u8ba1\u7b97\u5747\u503c\u65b9\u5dee\nb=a.numpy()\nimport numpy as np\nmean=np.mean(b)\nstd=np.std(b)+1e-5\n# \u624b\u52a8\u6807\u51c6\u5316\nimg_2=(b-mean)/std\nbn=nn.BatchNorm2d(2)\n# \u5229\u7528BatchNorm2d\u6807\u51c6\u5316\nimg_3=bn(img)\nprint(img_2)\nprint(img_3)\n</code></pre> <p>\u8f93\u51fa</p> <p>\u624b\u52a8\u6807\u51c6\u5316\u5f97\u5230\u7684\u6570\u636e\uff0c\u524d\u4e24\u884c\u4ee3\u8868\u7b2c\u4e00\u4e2abatch\u4e0b\u7b2c\u4e00\u4e2a\u901a\u9053\u6807\u51c6\u5316\u540e\u7684\u6570\u636e\uff0c\u4e0e\u5229\u7528BatchNorm2d\u7684\u524d\u4e24\u884c\u6570\u636e\u76f8\u7b49\uff1b\u540e\u4e24\u884c\u4ee3\u8868\u7b2c\u4e8c\u4e2abatch\u4e0b\u7b2c\u4e00\u4e2a\u901a\u9053\u6807\u51c6\u5316\u540e\u7684\u6570\u636e\uff0c\u4e0e\u5229\u7528BatchNorm2d\u7684\u524d\u4e94\u516d\u884c\u6570\u636e\u76f8\u7b49\u3002</p> <pre><code># \u624b\u52a8\u6807\u51c6\u5316\n[[-0.8814389  -1.3535967   0.05035681]\n [-0.5180839  -1.396645    1.8198812 ]\n [ 0.9151892   0.9469903  -0.7903797 ]\n [ 0.35690263  1.135288   -0.28446582]]\n# \u5229\u7528BatchNorm2d\u6807\u51c6\u5316\ntensor([[[[-0.8814, -1.3535,  0.0504],\n          [-0.5181, -1.3966,  1.8198]],\n\n         [[-1.5779, -0.5996, -1.0233],\n          [-0.3919, -0.6692,  0.6693]]],\n\n\n        [[[ 0.9151,  0.9469, -0.7903],\n          [ 0.3569,  1.1352, -0.2844]],\n\n         [[ 0.5829, -0.7664,  1.1329],\n          [ 1.4469, -0.4100,  1.6063]]]], grad_fn=&lt;NativeBatchNormBackward&gt;)\n</code></pre> <p><code>track_running_stats</code>\u8bbe\u4e3a<code>True</code>\u4e0e<code>Fasle</code>\u7684\u533a\u522b</p> <p>\u8bad\u7ec3\u8fc7\u7a0b</p> <pre><code>import torch\nfrom torch import nn\nimg=torch.rand(2,2,2,3)\nbn_t=nn.BatchNorm2d(2,track_running_stats=True)\nbn_f=nn.BatchNorm2d(2,track_running_stats=False)\n# \u8f93\u51fa\u521d\u59cb\u7684\u6a21\u578b\u5b58\u50a8\u503c\nprint('bn_t,mean:',bn_t.running_mean,'var:',bn_t.running_var)\nprint('bn_f,mean:',bn_f.running_mean,'var:',bn_f.running_var)\n# \u8f6c\u5316\u4e3a\u8bad\u7ec3\u9636\u6bb5\nbn_t.train()\nbn_f.train()\nimg_t=bn_t(img)\nimg_f=bn_f(img)\nprint(img_t)\nprint(img_f)\nprint('\u4e00\u6b21\u8fed\u4ee3\u66f4\u65b0bn_t,mean:',bn_t.running_mean,'var:',bn_t.running_var)\nimg_t=bn_t(img)\nprint('\u4e24\u6b21\u8fed\u4ee3\u66f4\u65b0bn_t,mean:',bn_t.running_mean,'var:',bn_t.running_var)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u521d\u59cb\u8fc7\u7a0b\uff0ctrack_running_stats\u8bbe\u4e3aTrue\u65f6\uff0c\u6a21\u578b\u5b58\u50a8\u5168\u5c40\u5747\u503c\u4e0e\u65b9\u5dee\n# \u521d\u59cb\u5316\u4e3a0\u548c1,\u4e24\u4e2a\u503c\u5bf9\u5e94\u4e24\u4e2a\u901a\u9053\nbn_t,mean: tensor([0., 0.]) var: tensor([1., 1.])\n# track_running_stats\u8bbe\u4e3aFalse\u65f6\uff0c\u6a21\u578b\u4e0d\u5b58\u50a8\u5747\u503c\u4e0e\u65b9\u5dee\nbn_f,mean: None var: None\n# \u7531\u4e0b\u9762\u7684\u7ed3\u679c\u6613\u77e5\uff0ctrack_running_stats\u8bbe\u4e3aTrue\u4e0eFalse\uff0c\u5bf9\u8bad\u7ec3\u8fc7\u7a0b\u7684\u6807\u51c6\u5316\u7ed3\u679c\u65e0\u5f71\u54cd\ntensor([[[[-1.0599,  0.9532, -0.2647],\n          [ 0.8146,  0.2971, -1.7099]],\n\n         [[ 1.0554,  0.9239,  1.9331],\n          [ 0.0334, -1.3058, -0.0804]]],\n\n\n        [[[ 1.0146,  0.7528, -0.1986],\n          [ 1.3564, -1.6232, -0.3325]],\n\n         [[-1.6591, -0.7690, -0.3045],\n          [ 0.7691,  0.1344, -0.7306]]]], grad_fn=&lt;NativeBatchNormBackward&gt;)\ntensor([[[[-1.0599,  0.9532, -0.2647],\n          [ 0.8146,  0.2971, -1.7099]],\n\n         [[ 1.0554,  0.9239,  1.9331],\n          [ 0.0334, -1.3058, -0.0804]]],\n\n\n        [[[ 1.0146,  0.7528, -0.1986],\n          [ 1.3564, -1.6232, -0.3325]],\n\n         [[-1.6591, -0.7690, -0.3045],\n          [ 0.7691,  0.1344, -0.7306]]]], grad_fn=&lt;NativeBatchNormBackward&gt;)\n# track_running_stats\u8bbe\u4e3aTure\u65f6\uff0c\u6a21\u578b\u6bcf\u6807\u51c6\u5316\u4e00\u7ec4\u6570\u636e\uff0c\u90fd\u4f1a\u66f4\u65b0\u81ea\u5df1\u5b58\u50a8\u7684\u6570\u636e\u4e00\u6b21\n\u4e00\u6b21\u8fed\u4ee3\u66f4\u65b0bn_t,mean: tensor([0.0562, 0.0586]) var: tensor([0.9092, 0.9043])\n\u4e24\u6b21\u8fed\u4ee3\u66f4\u65b0bn_t,mean: tensor([0.1068, 0.1114]) var: tensor([0.8275, 0.8183])\n</code></pre> <p>\u6d4b\u8bd5\u8fc7\u7a0b</p> <pre><code>import torch\nfrom torch import nn\n# img\u548c\u4e0a\u4e2a\u8bad\u7ec3\u8fc7\u7a0b\u7684\u6570\u636e\u4e00\u6837\uff0c\u4e3a\u4e86\u4fbf\u4e8e\u505a\u6bd4\u8f83\nbn_t=nn.BatchNorm2d(2,track_running_stats=True)\nbn_f=nn.BatchNorm2d(2,track_running_stats=False)\n# \u8f93\u51fa\u521d\u59cb\u7684\u6a21\u578b\u5b58\u50a8\u503c,\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\uff0cbn_t\u5229\u7528\u8be5\u503c\u8fdb\u884c\u6807\u51c6\u5316\nprint('bn_t,mean:',bn_t.running_mean,'var:',bn_t.running_var)\n# \u8f6c\u5316\u4e3a\u6d4b\u8bd5\u8fc7\u7a0b\nbn_t.eval()\nbn_f.eval()\nimg_t=bn_t(img)\nimg_f=bn_f(img)\nprint(img)\nprint(img_t)\nprint(img_f)\nbn_t.train()\nimg_t=bn_t(img)\nbn_t.eval()\nimg_t=bn_t(img)\nprint('\u66f4\u65b0\u540ebn_t,mean:',bn_t.running_mean,'var:',bn_t.running_var)\nprint(img_t)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># track_running_stats\u8bbe\u4e3aTure\u65f6\n# \u5728\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\u5229\u7528running_mean\u548crunning_var\u505a\u6807\u51c6\u5316\u8ba1\u7b97\nbn_t,mean: tensor([0., 0.]) var: tensor([1., 1.])\n# \u5982\u679c\u4e0d\u8fdb\u884c\u8bad\u7ec3\uff0c\u5219\u9ed8\u8ba4\u521d\u59cb\u503c\u4e3a0\u548c1\uff0c\u7528\u8fd9\u4e24\u4e2a\u6570\u505a\u6807\u51c6\u5316\u65f6\u7684\u7ed3\u679c\u4e0e\u8f93\u5165\u76f8\u540c\n# \u8f93\u5165\u6570\u636e\ntensor([[[[0.2542, 0.8395, 0.4854],\n          [0.7992, 0.6488, 0.0652]],\n\n         [[0.7970, 0.7707, 0.9722],\n          [0.5929, 0.3256, 0.5702]]],\n\n\n        [[[0.8574, 0.7813, 0.5046],\n          [0.9568, 0.0904, 0.4657]],\n\n         [[0.2550, 0.4327, 0.5255],\n          [0.7398, 0.6131, 0.4404]]]])\n# track_running_stats\u8bbe\u4e3aTure\u65f6\uff0c\u62ff\u521d\u59cb\u5316\u6570\u636e\u8fdb\u884c\u6807\u51c6\u5316\u8ba1\u7b97\u7ed3\u679c\n# \u53ef\u89c1\u4e0e\u4e0a\u8ff0\u7ed3\u679c\u76f8\u540c\ntensor([[[[0.2542, 0.8395, 0.4854],\n          [0.7992, 0.6488, 0.0652]],\n\n         [[0.7970, 0.7707, 0.9722],\n          [0.5929, 0.3256, 0.5702]]],\n\n\n        [[[0.8574, 0.7813, 0.5046],\n          [0.9568, 0.0904, 0.4657]],\n\n         [[0.2550, 0.4327, 0.5255],\n          [0.7398, 0.6131, 0.4404]]]], grad_fn=&lt;NativeBatchNormBackward&gt;)\n# track_running_stats\u8bbe\u4e3aFasle\u65f6\uff0c\u6807\u51c6\u5316\u8ba1\u7b97\u7ed3\u679c\u548c\u8bad\u7ec3\u8fc7\u7a0b\u4e00\u6837\uff0c\u56e0\u6b64\u7ed3\u679c\u76f8\u540c\n# \u8fd9\u91cc\u7684\u8f93\u5165\u6570\u636e\u548c\u4e0a\u4e00\u4e2a\u6848\u4f8b\u4e00\u6837\uff0c\u53ef\u4ee5\u548c\u4e0a\u4e2a\u8fc7\u7a0b\u7684\u7ed3\u679c\u505a\u6bd4\u8f83\u3002\ntensor([[[[-1.0599,  0.9532, -0.2647],\n          [ 0.8146,  0.2971, -1.7099]],\n\n         [[ 1.0554,  0.9239,  1.9331],\n          [ 0.0334, -1.3058, -0.0804]]],\n\n\n        [[[ 1.0146,  0.7528, -0.1986],\n          [ 1.3564, -1.6232, -0.3325]],\n\n         [[-1.6591, -0.7690, -0.3045],\n          [ 0.7691,  0.1344, -0.7306]]]], grad_fn=&lt;NativeBatchNormBackward&gt;)\n# \u7ecf\u8fc7\u4e00\u6b21\u8bad\u7ec3\u8fc7\u7a0b\uff0crunning_mean\u4e0erunning_var\u90fd\u6709\u6240\u6539\u53d8\n\u66f4\u65b0\u540ebn_t,mean: tensor([0.0562, 0.0586]) var: tensor([0.9092, 0.9043])\n# \u518d\u8fdb\u884c\u6d4b\u8bd5\u65f6\uff0c\u7528\u65b0\u7684running_mean\u548crunning_var\u505a\u6807\u51c6\u5316\u8ba1\u7b97\ntensor([[[[0.2076, 0.8215, 0.4501],\n          [0.7792, 0.6214, 0.0094]],\n\n         [[0.7764, 0.7488, 0.9607],\n          [0.5619, 0.2807, 0.5380]]],\n\n\n        [[[0.8402, 0.7604, 0.4702],\n          [0.9444, 0.0358, 0.4294]],\n\n         [[0.2065, 0.3934, 0.4909],\n          [0.7163, 0.5831, 0.4015]]]], grad_fn=&lt;NativeBatchNormBackward&gt;)\n</code></pre>"},{"location":"PyTorch/nn/layers/nn.BatchNorm2d/#_3","title":"\u5b98\u65b9\u6587\u6863","text":"<p>nn.BatchNorm2d\uff1ahttps://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html?highlight=norm2d#torch.nn.BatchNorm2d</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e749\u670827\u65e5</p>"},{"location":"PyTorch/nn/layers/nn.Conv2d/","title":"\u4e8c\u7ef4\u5377\u79ef\u5c42","text":"<pre><code>torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n</code></pre> <p>\u529f\u80fd\uff1a\u5bf9\u591a\u4e2a\u8f93\u5165\u5e73\u9762\u7ec4\u6210\u7684\u8f93\u5165\u4fe1\u53f7\u5e94\u75282D\u5377\u79ef\u8fd0\u7b97\uff0c\u5e38\u7528\u4e8e\u56fe\u50cf\u5904\u7406\u3002</p> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>in_channels</code>\uff1a\u8f93\u5165\u56fe\u50cf\u4e2d\u7684\u901a\u9053\u6570</li> <li><code>out_channels</code>\uff1a\u7ecf\u8fc7\u5377\u79ef\u8fd0\u7b97\u4ea7\u751f\u7684\u901a\u9053\u6570</li> <li><code>kernel_size</code>\uff1a\u5377\u79ef\u6838\u5927\u5c0f\uff0c\u6574\u6570\u6216\u8005\u5143\u7ec4\u7c7b\u578b</li> <li><code>stride</code>\uff1a\u5377\u79ef\u8fd0\u7b97\u7684\u6b65\u5e45\uff0c\u6574\u6570\u6216\u8005\u5143\u7ec4\u7c7b\u578b\uff0c\u9ed8\u8ba41</li> <li><code>padding</code>\uff1a\u8fb9\u754c\u5904\u7684\u586b\u5145\u5927\u5c0f\uff0c\u6574\u6570\u6216\u8005\u5143\u7ec4\u7c7b\u578b\uff0c\u9ed8\u8ba40</li> <li><code>padding_mode</code>\uff1a\u586b\u5145\u65b9\u5f0f\uff0c<code>zeros</code>\u3001<code>reflect</code>\u3001<code>replicate</code>\u3001<code>circular</code>\uff0c\u9ed8\u8ba4\u662f<code>zeros</code> <code>zeros</code>\uff1a\u96f6\u586b\u5145\uff0c\u5728\u5f20\u91cf\u8fb9\u754c\u5168\u90e8\u586b\u51450   <code>reflect</code>\uff1a\u955c\u50cf\u586b\u5145\uff0c\u4ee5\u77e9\u9635\u8fb9\u7f18\u4e3a\u5bf9\u79f0\u8f74\uff0c\u5c06\u53cd\u65b9\u5411\u7684\u5bf9\u79f0\u5143\u7d20\u586b\u5145\u5230\u6700\u5916\u56f4\u3002   <code>replicate</code>\uff1a\u590d\u5236\u586b\u5145\uff0c\u4f7f\u7528\u8f93\u5165\u8fb9\u754c\u7684\u590d\u5236\u503c\u586b\u5145\u5f20\u91cf   <code>circular</code>\uff1a\u5faa\u73af\u586b\u5145\uff0c\u91cd\u590d\u77e9\u9635\u8fb9\u754c\u53e6\u4e00\u4fa7\u7684\u5143\u7d20   \u5177\u4f53\u533a\u522b\u8bf7\u89c1\u4ee3\u7801\u6848\u4f8b</li> <li><code>dilation</code>\uff1a\u63a7\u5236\u70b9\u4e4b\u95f4\u7684\u8ddd\u79bb\uff0c\u9ed8\u8ba4\u662f1\uff0c\u5982\u679c\u5927\u4e8e1\uff0c\u5219\u8be5\u8fd0\u7b97\u53c8\u79f0\u4e3a\u6269\u5f20\u5377\u79ef\u8fd0\u7b97\u3002   \u4e00\u56fe\u770b\u61c2\u6269\u5f20\u5377\u79ef\u8fd0\u7b97</li> </ul> <p> <p></p> <p></p> <p>\u56fe\u7247\u6765\u6e90\uff1ahttps://github.com/vdumoulin/conv_arithmetic</p> <ul> <li><code>groups</code>\uff1a\u63a7\u5236\u8f93\u5165\u548c\u8f93\u51fa\u4e4b\u95f4\u7684\u8fde\u63a5\uff0c\u9ed8\u8ba4\u662f1\u3002</li> <li>\u5728<code>groups</code>=1\u65f6\uff0c\u6240\u6709\u8f93\u5165\u90fd\u88ab\u5377\u79ef\u4e3a\u8f93\u51fa</li> <li>\u5728<code>groups</code>=2\u65f6\uff0c\u8be5\u64cd\u4f5c\u76f8\u5f53\u4e8e\u5148\u628a\u8f93\u5165\u901a\u9053\u5bf9\u534a\u5206\uff0c\u5206\u522b\u7ecf\u8fc7\u76f8\u540c\u7684conv\u8fd0\u7b97(\u56e0\u6b64\u5377\u79ef\u53c2\u6570\u4f1a\u51cf\u534a)\uff0c\u4ea7\u751f\u5bf9\u5e94\u7684\u8f93\u51fa\uff0c\u7136\u540e\u518d\u5c06\u4e24\u8005\u7684\u8f93\u51fa\u8fde\u63a5\u8d77\u6765\u3002<code>groups</code>&gt;2\u7684\u60c5\u51b5\u7c7b\u4f3c\uff0c\u6700\u5927\u4e0d\u80fd\u8d85\u8fc7\u8f93\u5165\u7684\u901a\u9053\u6570\u3002</li> <li><code>groups</code>\u5fc5\u987b\u53ef\u4ee5\u6574\u9664<code>in_channels</code>\u548c<code>out_channels</code></li> <li><code>bias</code>\uff1a\u662f\u5426\u6709\u504f\u7f6e\u9879\uff0c\u9ed8\u8ba4<code>True</code>\uff0c\u5373\u9ed8\u8ba4\u5b58\u5728\u504f\u7f6e\u9879\u3002</li> <li>\u8f93\u5165\u7684\u6570\u7ec4\u6570\u636e\u7c7b\u578b\u5fc5\u987b\u662f<code>TensorFloat32</code>\u7c7b\u578b</li> </ul> <p>\u6ce8\u610f\uff1a</p> <ul> <li><code>in_channels</code>\u3001 <code>out_channels</code>\u548c<code>kernel_size</code>\u662f\u5fc5\u987b\u6307\u5b9a\u7684\u53c2\u6570\uff0c\u5176\u4ed6\u53c2\u6570\u90fd\u6709\u9ed8\u8ba4\u503c\uff0c\u53ef\u4ee5\u4e0d\u6307\u5b9a\u3002</li> <li><code>kernel_size</code>\u3001<code>stride</code>\u3001<code>padding</code>\u548c<code>dilation</code>\u65e2\u53ef\u4ee5\u6307\u5b9a\u4e3a\u6574\u6570\u7c7b\u578b\uff0c\u4e5f\u53ef\u4ee5\u6307\u5b9a\u4e3a\u5143\u7ec4\u7c7b\u578b\u3002</li> <li>\u5982\u679c\u88ab\u6307\u5b9a\u4e3a\u6574\u6570\u65f6\uff0c\u5219\u9ad8\u5ea6\u548c\u5bbd\u5ea6\u5c3a\u5bf8\u4f7f\u7528\u76f8\u540c\u7684\u503c(\u6b63\u65b9\u5f62)</li> <li>\u5982\u679c\u88ab\u6307\u5b9a\u4e3a\u5143\u7ec4\u7c7b\u578b\u65f6\uff0c\u5143\u7ec4\u4e2d\u7b2c\u4e00\u4e2a\u503c\u7528\u4e8e\u9ad8\uff0c\u7b2c\u4e8c\u4e2a\u7ef4\u5ea6\u7528\u4e8e\u5bbd(\u957f\u65b9\u5f62)</li> </ul> <p>\u8865\u5145\uff1a</p> <ul> <li>\u8f93\u51fa\u56fe\u50cf\u7684\u9ad8\u3001\u5bbd\u8ba1\u7b97\u516c\u5f0f(\u516c\u5f0f\u8f6c\u81ea\u5b98\u65b9\u6587\u6863)\uff1a</li> </ul>  \u5047\u8bbe: \u8f93\u5165input:(N,C_{in},H_{in},W_{in}),\u8f93\u51faoutput:(N,C_{out},H_{out},W_{out})\\\\ \u5176\u4e2dN\u662fbatch\\_size\u3001C_i\u662f\u901a\u9053\uff0cH_i\u662f\u56fe\u50cf\u7684\u9ad8\u3001W_i\u662f\u56fe\u50cf\u7684\u5bbd   H_{out}=\\frac{H_{in}+2\\times padding[0]-dilation[0]\\times(kernel\\_size[0]-1)-1}{stride[0]}+1\\\\ W_{out}=\\frac{W_{in}+2\\times padding[1]-dilation[1]\\times(kernel\\_size[1]-1)-1}{stride[1]}+1\\\\  <ul> <li>\u5377\u79ef\u5c42\u7684\u6743\u91cd\u53ef\u901a\u8fc7\u65b9\u6cd5<code>Conv2d.weight</code>\u63d0\u53d6\uff0c\u8f93\u51fa\u7684\u6743\u91cd\u6570\u7ec4\u5c3a\u5bf8\u4e3a\uff1a $$ (out\\_channels,\\frac{in\\_channels}{groups},kernel\\_size[0],kernel\\_size[0]) $$ </li> </ul> <p>\u5e76\u4e14\u521d\u59cb\u5316\u6743\u91cd\u5206\u90e8\u670d\u4ece\u5747\u5300\u5206\u5e03\uff1a $$ u(-\\sqrt{k},\\sqrt{k}),\u5176\u4e2dk=\\frac{groups}{C_{in}\\times \\prod\\limits_{i=0}^1 kernel\\_size[i]} $$ </p> <ul> <li>\u5377\u79ef\u5c42\u7684\u504f\u7f6e\u53c2\u6570\u53ef\u4ee5\u901a\u8fc7\u65b9\u6cd5<code>Conv2d.bias</code>\u63d0\u53d6(\u524d\u63d0<code>bias=True</code>)\uff0c\u8f93\u51fa\u7684\u6570\u7ec4\u5c3a\u5bf8\u4e0e<code>out_channels</code>\u5927\u5c0f\u4e00\u6837\uff0c\u521d\u59cb\u5316\u5206\u90e8\u4e0e<code>weight</code>\u6743\u91cd\u5206\u90e8\u4e00\u6837\u3002</li> <li>\u5377\u79ef\u5c42\u53c2\u6570\u4e5f\u53ef\u4ee5\u901a\u8fc7<code>.parameters()</code>\u65b9\u6cd5\u83b7\u53d6</li> </ul>"},{"location":"PyTorch/nn/layers/nn.Conv2d/#_2","title":"\u4ee3\u7801\u6848\u4f8b","text":""},{"location":"PyTorch/nn/layers/nn.Conv2d/#_3","title":"\u4e00\u822c\u7528\u6cd5","text":"<pre><code>import torch.nn as nn\nimport torch\nimg=torch.arange(49,dtype=torch.float32).view(1,1,7,7)\nconv=nn.Conv2d(in_channels=1,out_channels=1,kernel_size=3)\nimg_2=conv(img)\nprint(img)\nprint(img_2)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u7ecf\u8fc7\u5377\u79ef\u8fd0\u7b97\u524d\ntensor([[[[ 0.,  1.,  2.,  3.,  4.,  5.,  6.],\n          [ 7.,  8.,  9., 10., 11., 12., 13.],\n          [14., 15., 16., 17., 18., 19., 20.],\n          [21., 22., 23., 24., 25., 26., 27.],\n          [28., 29., 30., 31., 32., 33., 34.],\n          [35., 36., 37., 38., 39., 40., 41.],\n          [42., 43., 44., 45., 46., 47., 48.]]]])\n# \u5377\u79ef\u8fd0\u7b97\u540e\ntensor([[[[4.7303, 4.8851, 5.0398, 5.1945, 5.3492],\n          [5.8134, 5.9681, 6.1228, 6.2775, 6.4323],\n          [6.8964, 7.0512, 7.2059, 7.3606, 7.5153],\n          [7.9795, 8.1342, 8.2889, 8.4436, 8.5984],\n          [9.0625, 9.2172, 9.3720, 9.5267, 9.6814]]]],\n       grad_fn=&lt;ThnnConv2DBackward&gt;)\n</code></pre> <p>\u56fe\u50cf\u5c3a\u5bf8\u7684\u53d8\u5316</p> <pre><code>import torch.nn as nn\nimport torch\nimg=torch.arange(4*64*28*28,dtype=torch.float32).view(4,64,28,28)\nconv=nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,padding=1)\nimg_2=conv(img)\nprint(img.shape)\nprint(img_2.shape)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u5377\u79ef\u524d\ntorch.Size([4, 64, 28, 28])\n# \u5377\u79ef\u540e\ntorch.Size([4, 128, 28, 28])\n</code></pre> <p>\u901a\u9053\u6570\u53d8\u4e3a\u4e86\u539f\u6765\u7684\u4e24\u500d\uff0c\u7531\u4e8e\u586b\u5145\u4e86\u4e00\u683c\uff0c\u6240\u4ee5\u5377\u79ef\u540e\u5c3a\u5bf8\u4e0d\u53d8</p>"},{"location":"PyTorch/nn/layers/nn.Conv2d/#_4","title":"\u8f93\u51fa\u5377\u79ef\u8fd0\u7b97\u7684\u53c2\u6570","text":"<p>\u5377\u79ef\u5c42\u6570\u503c</p> <pre><code>import torch.nn as nn\nimport torch\nconv=nn.Conv2d(in_channels=1,out_channels=1,kernel_size=3)\nprint(conv.weight)\nprint(conv.bias)\nprint(type(conv.weight))\n# \u5229\u7528.parameters()\u65b9\u6cd5\u8c03\u7528\u53c2\u6570\nfor i in conv.parameters():\n    print(i)\nprint(type(i))\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u5377\u79ef\u5c42\u6743\u91cd\u53c2\u6570\nParameter containing:\ntensor([[[[-0.1891, -0.2296,  0.0362],\n          [-0.1552, -0.0747,  0.2922],\n          [-0.1434,  0.0802, -0.0778]]]], requires_grad=True)\n# \u5377\u79ef\u5c42\u504f\u7f6e\u53c2\u6570\nParameter containing:\ntensor([0.1998], requires_grad=True)\n# \u53c2\u6570\u7684\u7c7b\u578b\uff0c\u5747\u4e3aParameter\u7c7b\n&lt;class 'torch.nn.parameter.Parameter'&gt;\n# \u4e0b\u9762\u662f\u901a\u8fc7.parameters()\u65b9\u6cd5\u8c03\u7528\u53c2\u6570\uff0c\u4e0e\u524d\u9762\u7684\u65b9\u6cd5\u7ed3\u679c\u4e00\u6837\nParameter containing:\ntensor([[[[-0.1891, -0.2296,  0.0362],\n          [-0.1552, -0.0747,  0.2922],\n          [-0.1434,  0.0802, -0.0778]]]], requires_grad=True)\nParameter containing:\ntensor([0.1998], requires_grad=True)\n# \u8fd4\u56de\u7684\u6570\u636e\u7c7b\u578b\u4e5f\u4e00\u6837\n&lt;class 'torch.nn.parameter.Parameter'&gt;\n</code></pre> <p>\u5377\u79ef\u5c42\u53c2\u6570\u5c3a\u5bf8</p> <pre><code>import torch.nn as nn\nimport torch\nconv=nn.Conv2d(in_channels=64,out_channels=128,kernel_size=[5,3],padding=2)\nprint(conv.weight.shape)\nprint(conv.bias.shape)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u6743\u91cd\u53c2\u6570\uff0c\u4ece\u7b2c\u4e00\u7ef4\u5230\u7b2c\u56db\u7ef4\u4f9d\u6b21\u4ee3\u8868\uff1a\n# \u8f93\u51fa\u901a\u9053\u6570\u3001\u8f93\u5165\u901a\u9053\u6570\u3001\u5377\u79ef\u6838\u7684\u9ad8\u3001\u5377\u79ef\u6838\u7684\u5bbd\ntorch.Size([128, 64, 5, 3])\n# \u504f\u7f6e\u9879\u53c2\u6570\uff0c\u5927\u5c0f\u548c\u8f93\u5165\u901a\u9053\u6570\u4e00\u6837\ntorch.Size([128])\n</code></pre>"},{"location":"PyTorch/nn/layers/nn.Conv2d/#_5","title":"\u586b\u5145\u65b9\u5f0f","text":"<p>\u4e3a\u4e86\u6d88\u9664\u5377\u79ef\u8fd0\u7b97\u5bf9\u539f\u56fe\u7684\u5f71\u54cd\uff0c\u6211\u4eec\u9996\u5148\u5c06\u5377\u79ef\u6838\u5927\u5c0f\u8bbe\u4e3a1\uff0c\u5e76\u4e14\u53c2\u6570\u4e5f\u8bbe\u4e3a1\uff0c\u4e0d\u8bbe\u7f6e\u504f\u7f6e\u9879\uff0c\u5e76\u4e14\u4e3a\u4e86\u51f8\u663e\u6269\u5145\u540e\u7684\u6548\u679c\uff0c\u6211\u4eec\u5c06<code>padding</code>\u8c03\u6574\u4e3a3\u3002</p> <p>\u521d\u59cb\u5316\u8fc7\u7a0b</p> <pre><code>import torch.nn as nn\nimport torch\nconv_1=nn.Conv2d(in_channels=1,out_channels=1,kernel_size=1,bias=False,padding=3,mode='zeros')\nconv_1.weight=nn.parameter(torch.ones((1,1,1,1)))\nconv_2=nn.Conv2d(in_channels=1,out_channels=1,kernel_size=1,bias=False,padding=3,mode='reflect')\nconv_2.weight=nn.parameter(torch.ones((1,1,1,1)))\nconv_3=nn.Conv2d(in_channels=1,out_channels=1,kernel_size=1,bias=False,padding=3,mode='replicate')\nconv_3.weight=nn.parameter(torch.ones((1,1,1,1)))\nconv_4=nn.Conv2d(in_channels=1,out_channels=1,kernel_size=1,bias=False,padding=3,mode='circular')\nconv_4.weight=nn.parameter(torch.ones((1,1,1,1)))\nimg=torch.arange(25,dtype=torch.float32).reshape(1,1,5,5)\n</code></pre> <p>\u96f6\u586b\u5145\uff1a</p> <pre><code>img_1=conv_1(img)\nprint(img)\nprint(img_1)\n</code></pre> <p>\u8f93\u51fa </p> <p>\u955c\u50cf\u586b\u5145\uff1a</p> <pre><code>img_2=conv_2(img)\nprint(img)\nprint(img_2)\n</code></pre> <p>\u8f93\u51fa</p> <p></p> <p>\u590d\u5236\u586b\u5145\uff1a</p> <pre><code>img_3=conv_3(img)\nprint(img)\nprint(img_3)\n</code></pre> <p>\u8f93\u51fa</p> <p></p> <p>\u5faa\u73af\u586b\u5145\uff1a</p> <pre><code>img_4=conv_4(img)\nprint(img)\nprint(img_4)\n</code></pre> <p>\u8f93\u51fa</p> <p></p>"},{"location":"PyTorch/nn/layers/nn.Conv2d/#_6","title":"\u5b98\u65b9\u6587\u6863","text":"<p>nn.Conv2d()\uff1ahttps://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html?highlight=conv2d#torch.nn.Conv2d</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e749\u670819\u65e5</p>"},{"location":"PyTorch/nn/layers/nn.Dropout/","title":"\u968f\u673a\u4e22\u5f03\u5c42","text":"<pre><code>torch.nn.Dropout(p=0.5, inplace=False)\n</code></pre> <p>\u529f\u80fd\uff1a\u5728\u8bad\u7ec3\u9636\u6bb5\u6309\u67d0\u79cd\u6982\u7387\u968f\u5373\u5c06\u8f93\u5165\u7684\u5f20\u91cf\u5143\u7d20\u968f\u673a\u5f52\u96f6\uff0c\u5e38\u7528\u7684\u6b63\u5219\u5316\u5668\uff0c\u7528\u4e8e\u9632\u6b62\u7f51\u7edc\u8fc7\u62df\u5408\u3002</p> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>p</code>\uff1a\u5143\u7d20\u5f52\u96f6\u7684\u6982\u7387</li> <li><code>inplace</code>\uff1a\u662f\u5426\u6539\u53d8\u8f93\u5165\u6570\u636e\uff0c\u5982\u679c\u8bbe\u7f6e\u4e3a<code>True</code>\uff0c\u5219\u4f1a\u76f4\u63a5\u4fee\u6539\u8f93\u5165\u6570\u636e\uff1b\u5982\u679c\u8bbe\u7f6e\u4e3a<code>False</code>\uff0c\u5219\u4e0d\u5bf9\u8f93\u5165\u6570\u636e\u505a\u4fee\u6539</li> </ul> <p>\u6ce8\u610f\uff1a</p> <ul> <li><code>Dropout</code>\u64cd\u4f5c\u53ea\u5728\u8bad\u7ec3\u9636\u6bb5\u6267\u884c\uff0c\u5373\u53ea\u5728\u8bad\u7ec3\u9636\u6bb5\u968f\u673a\u4e22\u5f03\u6570\u636e\uff0c\u800c\u5bf9\u6d4b\u8bd5\u9636\u6bb5\u7684\u6570\u636e\u4e0d\u505a\u53d8\u5316</li> <li>\u5982\u679c\u6309\u6982\u7387<code>p</code>\u968f\u673a\u4e22\u5f03\u5143\u7d20\uff0c\u5219\u8f93\u51fa\u7684\u5143\u7d20\u6570\u503c\u6574\u4f53\u4e0a\u4f1a\u6309\u6bd4\u4f8b\u7f29\u653e\u4e3a\u539f\u6765\u76841-p\uff0c\u56e0\u6b64\u9700\u8981\u76f8\u5e94\u5730\u5c06\u5143\u7d20\u653e\u5927\u4e3a\\frac1{1-p}\u500d\uff0c\u5373\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6570\u636e\u9996\u5148\u88ab\u653e\u5927\\frac1{1-p}\u500d\uff0c\u4e4b\u540e\u518d\u4ee5\u6982\u7387p\u6267\u884c\u5f52\u96f6\u64cd\u4f5c\uff0c\u800c\u6d4b\u8bd5\u9636\u6bb5\u4e0d\u505a\u53d8\u5316\u3002</li> </ul>"},{"location":"PyTorch/nn/layers/nn.Dropout/#_2","title":"\u4ee3\u7801\u6848\u4f8b","text":"<p>\u4e00\u822c\u7528\u6cd5</p> <pre><code>import torch.nn as nn\nimport torch\nx = torch.arange(10, dtype=torch.float)\n# \u8bad\u7ec3\u9636\u6bb5\u7684dropout\ndrop_train = nn.Dropout(0.2).train()\n# \u6d4b\u8bd5\u9636\u6bb5\u7684dropout\ndrop_eval = nn.Dropout(0.2).eval()\ny_train = drop_train(x)\ny_eval = drop_eval(x)\nprint('\u8f93\u5165:', x)\nprint('\u8bad\u7ec3\u9636\u6bb5\u7684\u8f93\u51fa:', y_train)\nprint('\u6d4b\u8bd5\u9636\u6bb5\u7684\u8f93\u51fa:', y_eval)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code>\u8f93\u5165: tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n# \u6570\u636e\u88ab\u653e\u5927\u4e3a\u539f\u6765\u76841.25\u500d\uff0c\u53731/0.8\u500d\uff0c\u4e4b\u540e\u518d\u968f\u673a\u5c06\u6570\u636e\u5f52\u96f6\n\u8bad\u7ec3\u9636\u6bb5\u7684\u8f93\u51fa: tensor([ 0.0000,  1.2500,  2.5000,  3.7500,  5.0000,  0.0000,  7.5000,  8.7500, 10.0000, 11.2500])\n# \u6d4b\u8bd5\u9636\u6bb5\u4e0d\u5bf9\u6570\u636e\u505a\u64cd\u4f5c\n\u6d4b\u8bd5\u9636\u6bb5\u7684\u8f93\u51fa: tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n</code></pre> <p><code>inplace</code>\u8bbe\u7f6e\u4e3a<code>True</code>\u65f6\uff0c\u6b64\u65f6\u76f8\u5f53\u4e8e\u5148\u5bf9\u8f93\u5165x\u505a\u968f\u673a\u5f52\u96f6\uff0c\u4e4b\u540e\u518d\u5c06\u8be5\u6570\u636e\u8d4b\u503c\u7ed9y\uff0c\u56e0\u6b64\u7ecf\u8fc7dropout\u4e4b\u540ex\u4e0ey\u6570\u503c\u76f8\u540c</p> <pre><code>import torch.nn as nn\nimport torch\nx = torch.arange(10, dtype=torch.float)\ndrop_true = nn.Dropout(0.5, inplace=True)\ny = drop_true(x)\nprint(x)\nprint(y)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># x\u53d8\u91cf\ntensor([ 0.,  2.,  4.,  0.,  0., 10.,  0.,  0.,  0., 18.])\n# y\u53d8\u91cf\ntensor([ 0.,  2.,  4.,  0.,  0., 10.,  0.,  0.,  0., 18.])\n</code></pre> <p><code>inplace</code>\u8bbe\u7f6e\u4e3a<code>False</code>\u65f6\uff0c\u7ecf\u8fc7dropout\u4e4b\u540e\u53d8\u91cfx\u4e0d\u53d8\uff0cx\u4e0ey\u6570\u503c\u4e0d\u540c</p> <pre><code>import torch.nn as nn\nimport torch\nx = torch.arange(10, dtype=torch.float)\ndrop_false = nn.Dropout(0.5, inplace=False)\ny = drop_false(x)\nprint(x)\nprint(y)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># x\u53d8\u91cf\ntensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n# y\u53d8\u91cf\ntensor([ 0.,  2.,  0.,  0.,  0., 10.,  0., 14., 16., 18.])\n</code></pre>"},{"location":"PyTorch/nn/layers/nn.Dropout/#_3","title":"\u5b98\u65b9\u6587\u6863","text":"<p>nn.Dropout()\uff1ahttps://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e741\u670828\u65e5</p>"},{"location":"PyTorch/nn/layers/nn.Embedding/","title":"PyTorch\u5b66\u4e60\u7b14\u8bb0\uff1ann.Embedding\u2014\u2014\u7f16\u7801\u6620\u5c04","text":"<pre><code>torch.nn.Embedding(num_embeddings, embedding_dim, padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False, _weight=None, _freeze=False, device=None, dtype=None)\n</code></pre> <p>\u529f\u80fd\uff1a\u505a\u7f16\u7801\u6620\u5c04\u3002\u5728NLP\u9886\u57df\u4e2d\uff0c\u5e38\u7528\u4e8e\u5c06\u4e00\u53e5\u8bdd\u6620\u5c04\u6210\u5411\u91cf\uff1b\u5728CV\u4e2d\uff0c\u5e38\u7528\u4e8e\u7f16\u7801\u64cd\u4f5c\uff0c\u5982ViLT\u4e2d\u7684\u6807\u5fd7\u4f4d\u7f16\u7801\u3002</p> <p>\u5b9a\u4e49\u53c2\u6570\uff1a</p> <ul> <li><code>num_embeddings</code>\uff1a\u8bcd\u5178\u7684\u5927\u5c0f\uff08\u7ef4\u6570\uff09\uff0c\u8bbe\u5b9a\u5927\u5c0f\u8ddf\u5177\u4f53\u4efb\u52a1\u76ee\u7684\u6709\u5173\uff0c\u5728NLP\u4e2d\uff0c\u901a\u5e38\u8981\u5927\u4e8e\u7b49\u4e8e\u5b57\u7b26\u79cd\u7c7b\u4e2a\u6570\u3002\uff08\u8fc7\u5927\u7684\u8bdd\u4f1a\u96be\u4ee5\u4f18\u5316\uff0c\u8fc7\u5c0f\u7684\u8bdd\u96be\u4ee5\u5efa\u6a21\u4e0d\u540c\u7684\u5b57\u7b26\uff09</li> <li><code>embedding_dim</code>\uff1a\u7f16\u7801\u540e\u7684\u5411\u91cf\u7ef4\u6570\uff0c\u4e5f\u5c31\u662f\u8bcd\u5411\u91cf\u7ef4\u5ea6\u5927\u5c0f</li> <li><code>padding_idx</code>\uff1a\u6307\u5b9a\u54ea\u4e9b\u4f4d\u7f6e\u662f\u586b\u5145\u4f4d\u7f6e\uff0c\u586b\u5145\u4f4d\u7f6e\u7684\u5d4c\u5165\u5411\u91cf\u4e0d\u53c2\u4e0e\u68af\u5ea6\u7684\u8ba1\u7b97\uff1b</li> <li><code>max_norm</code>\uff1a\u7528\u4e8e\u63a7\u5236\u6743\u91cd\u77e9\u9635\u7684\u8303\u6570\uff0c\u5373\u9650\u5236\u8bcd\u5d4c\u5165\u77e9\u9635\u7684\u6700\u5927\u8303\u6570\u3002\u5f53\u8bcd\u5d4c\u5165\u77e9\u9635\u7684\u8303\u6570\u8d85\u8fc7 <code>max_norm</code> \u65f6\uff0c\u8be5\u77e9\u9635\u5c06\u88ab\u91cd\u65b0\u7f29\u653e\u5230\u6307\u5b9a\u7684\u8303\u6570\u4e0b\uff0c\u7528\u4e8e\u9632\u6b62\u68af\u5ea6\u7206\u70b8\uff0c\u4f20\u5165<code>float</code>\u683c\u5f0f\u7684\u6570\u636e\uff1b</li> <li><code>norm_type</code>\uff1a\u6307\u5b9a\u5229\u7528\u4ec0\u4e48\u8303\u6570\u8ba1\u7b97\uff0c\u548c<code>max_norm</code>\u7ed3\u5408\u4f7f\u7528\uff1b</li> <li><code>scale_grad_by_freq</code>\uff1a\u5982\u679c\u8bbe\u4e3aTrue\uff0c\u5219\u4f1a\u6839\u636e\u5355\u8bcd\u51fa\u73b0\u7684\u9891\u7387\uff0c\u5bf9\u68af\u5ea6\u5b9e\u73b0\u653e\u7f29\uff1b</li> <li><code>sparse</code>\uff1a\u5982\u679c\u8bbe\u4e3aTrue\uff0c\u5219\u6743\u91cd\u77e9\u9635\u76f8\u5173\u7684\u68af\u5ea6\u4f1a\u53d8\u4e3a\u7a00\u758f\u5f20\u91cf\u3002</li> </ul> <p>\u524d\u5411\u4f20\u64ad\uff1a\u4f20\u5165\u5f85\u5d4c\u5165\u7684\u6570\u636e\uff0c\u5c3a\u5bf8\u5047\u8bbe\u4e3a(*)\uff0c\u8f93\u5165\u6570\u636e\u7684\u7c7b\u578b\u4e3a<code>IntTensor</code> \u6216\u8005 <code>LongTensor</code>\u3002</p> <p>\u8f93\u51fa\uff1a\u5c3a\u5bf8\u5728\u540e\u9762\u591a\u4e00\u4e2a\u7ef4\u5ea6(*,embedding\\_dim)\uff0c\u76f4\u63a5\u62fc\u63a5\u5230\u540e\u9762\uff0c\u76f8\u5f53\u4e8e\u4e3a\u6bcf\u4e2a\u5143\u7d20\u5206\u914d\u5c3a\u5bf8\u4e3aembedding\\_dim\u7684\u5411\u91cf\uff0c\u8f93\u51fa\u6d6e\u70b9\u6570\u683c\u5f0f\u7684\u6570\u636e\u3002</p> <p>\u6ce8\uff1a</p> <ul> <li>\u6743\u91cd\u53ef\u5b66\u4e60\uff0c\u5e76\u4e14\u53ef\u7531<code>.weight</code>\u63d0\u53d6\uff0c\u8f93\u51fa\u5f20\u91cf\u7684\u5c3a\u5bf8\u4e3a<code>(num_embeddings, embedding_dim)</code>\uff0c\u6743\u91cd\u6570\u636e\u7684\u521d\u59cb\u5316\u670d\u4ece\u6807\u51c6\u6b63\u6001\u5206\u5e03N(0,1)</li> <li><code>num_embeddings</code>\u7684\u8bbe\u5b9a\u901a\u5e38\u8ddf\u5177\u4f53\u4efb\u52a1\u6709\u5173\uff0c\u5728NLP\u4e2d\uff0c\u901a\u5e38\u8981\u5927\u4e8e\u7b49\u4e8e\u5b57\u7b26\u79cd\u7c7b\u4e2a\u6570\uff0c\u628a\u6bcf\u4e2a\u5b57\u7b26\u6620\u5c04\u6210\u5c3a\u5bf8\u4e3a<code>embedding_dim</code>\u7684\u5411\u91cf\uff1b\u5728CV\u7684\u7f16\u7801\u64cd\u4f5c\u4e2d\uff0c\u8ddf\u7f16\u7801\u79cd\u7c7b\u6709\u5173\uff0c\u5982ViLT\u4e2d\u8981\u5bf9\u662f\u56fe\u7247\u8fd8\u662f\u6587\u672c\u5411\u91cf\u505a\u7f16\u7801\uff0c\u5b9a\u4e49\u6807\u5fd7\u4f4d\uff0c\u56e0\u6b64\u5728\u751f\u6210\u5d4c\u5165\u5411\u91cf\u65f6\u8981\u4f20\u51652\uff1b</li> <li>\u76f8\u5f53\u4e8e\u5c06\u539f\u59cb\u7684\u6570\u636e\u4ece\u9ed8\u8ba4<code>num_embeddings</code>\u7684\u8303\u56f4\uff0c\u6620\u5c04\u6210\u5c3a\u5bf8\u4e3a<code>embedding_dim</code>\u7684\u5d4c\u5165\u5411\u91cf\u3002\uff08\u82e5\u4f7f\u7528one-hot\u89c4\u5219\u505a\u6620\u5c04\uff0c\u6bcf\u4e2a\u6570\u636e\u4f1a\u6620\u5c04\u6210\u5c3a\u5bf8\u4e3a<code>num_embeddings</code>\u7684\u5411\u91cf\uff09</li> <li>\u53ef\u53c2\u8003\uff1ahttps://blog.csdn.net/qq_41477675/article/details/114645012</li> </ul>"},{"location":"PyTorch/nn/layers/nn.Embedding/#_1","title":"\u4ee3\u7801\u6848\u4f8b","text":"<pre><code>import torch\nfrom torch import nn\n\nemb = nn.Embedding(3, 256)\ndata = torch.zeros((2, 56), dtype=torch.int)\nembeds = emb(data)\nprint(embeds.shape)\nprint(emb.weight.shape)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code>torch.Size([2, 56, 256])\ntorch.Size([3, 256])\n</code></pre>"},{"location":"PyTorch/nn/layers/nn.Embedding/#_2","title":"\u5b98\u65b9\u6587\u6863","text":"<p>torch.nn.Embedding\uff1ahttps://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding</p> <p>\u6ce8\uff1a\u521d\u6b65\u5b8c\u7a3f\u4e8e2023\u5e745\u67083\u65e5</p>"},{"location":"PyTorch/nn/layers/nn.Linear/","title":"\u7ebf\u6027\u56de\u5f52\u5c42","text":"<pre><code>torch.nn.Linear(in_features, out_features, bias=True, device=None, dtype=None)\n</code></pre> <p>\u529f\u80fd\uff1a\u5bf9\u8f93\u5165\u6570\u636e\u5e94\u7528\u7ebf\u6027\u53d8\u6362\u8fd0\u7b97\uff1ay=xA^T+b</p> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>in_features</code>\uff1a\u8f93\u5165\u6837\u672c\u7684\u5c3a\u5bf8\uff0c\u5373x\u7684\u957f\u5ea6</li> <li><code>out_features</code>\uff1a\u8f93\u51fa\u6837\u672c\u7684\u5c3a\u5bf8\uff0c\u5373y\u7684\u957f\u5ea6</li> <li><code>bias</code>\uff1a\u662f\u5426\u6dfb\u52a0\u504f\u7f6e\u9879\uff0c\u5982\u679c\u8bbe\u7f6e\u4e3a<code>False</code>\uff0c\u5219\u8be5\u5c42\u4e0d\u4f1a\u5b66\u4e60\u9644\u52a0\u7684\u504f\u7f6e\u9879\uff0c\u9ed8\u8ba4\u4e3a<code>True</code></li> </ul> <p>\u6ce8\u610f\uff1a</p> <ul> <li>\u7ebf\u6027\u5c42\u7684\u8f93\u5165\u53ef\u4ee5\u662f\u4efb\u610f\u7ef4\u5ea6\uff0c\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\u8868\u793ax\uff0c\u5e76\u4e14\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\u7684\u957f\u5ea6\u5fc5\u987b\u4e0e\u5b9a\u4e49\u7ebf\u6027\u56de\u5f52\u5c42\u4f7f\u7528\u7684\u53c2\u6570<code>in_features</code>\u5927\u5c0f\u4e00\u81f4</li> </ul> <p>\u8865\u5145\uff1a</p> <ul> <li> <p>\u7ebf\u6027\u56de\u5f52\u5c42\u7684\u6743\u91cd\u53c2\u6570\u53ef\u4ee5\u901a\u8fc7<code>.weight</code>\u65b9\u6cd5\u8c03\u53d6\uff0c\u504f\u7f6e\u53c2\u6570\u53ef\u4ee5\u901a\u8fc7<code>.bias</code>\u65b9\u6cd5\u8c03\u53d6</p> </li> <li> <p>\u7f51\u7edc\u53c2\u6570\u5c3a\u5bf8\u7531\u8f93\u5165\u6837\u672c\u5c3a\u5bf8\u548c\u8f93\u51fa\u6837\u672c\u5c3a\u5bf8\u51b3\u5b9a\uff1a\u6743\u91cd\u53c2\u6570\u4e3a2\u7ef4\u6570\u7ec4\uff0c\u5c3a\u5bf8\u4e3a[out_features, in_features]\uff1b\u504f\u7f6e\u53c2\u6570\u5c3a\u5bf8\u4e3a1\u7ef4\u6570\u7ec4\uff0c\u5c3a\u5bf8\u4e3a[out_features]</p> </li> <li> <p>\u521d\u59cb\u5316\u7684\u53c2\u6570\u670d\u4ece\u5747\u5300\u5206\u5e03\uff1a   $$   u(-\\sqrt{k},\\sqrt{k}),\u5176\u4e2dk=\\frac1{in\\_features}   $$ </p> </li> </ul>"},{"location":"PyTorch/nn/layers/nn.Linear/#_2","title":"\u4ee3\u7801\u6848\u4f8b","text":"<p>\u4e00\u822c\u7528\u6cd5</p> <pre><code>import torch.nn as nn\nimport torch\nx = torch.arange(10, dtype = torch.float32).view(1,10)\nlin = nn.Linear(in_features=10, out_features=5)\ny = lin(x)\nprint(x)\nprint(y)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u7ecf\u8fc7\u7ebf\u6027\u56de\u5f52\u5c42\u4e4b\u524d\ntensor([[0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]])\n# \u7ecf\u8fc7\u7ebf\u6027\u56de\u5f52\u5c42\u4e4b\u540e\ntensor([[-2.8759,  3.0576, -0.7961, -1.2897,  3.7157]],\n       grad_fn=&lt;AddmmBackward&gt;)\n</code></pre> <p>\u63d0\u53d6\u7f51\u7edc\u5c42\u7684\u53c2\u6570\u4fe1\u606f</p> <pre><code>print(lin.weight)\nprint(lin.weight.shape)\nprint(lin.bias)\nprint(lin.bias.shape)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u6743\u91cd\u53c2\u6570\nParameter containing:\ntensor([[-0.0099,  0.2451, -0.0532,  0.1081, -0.0393, -0.1213, -0.1463,  0.0669,\n         -0.1575, -0.0706],\n        [-0.1148, -0.0775,  0.2737, -0.3030, -0.1963,  0.0923,  0.2992,  0.1199,\n          0.2811, -0.1478],\n        [-0.0505,  0.2176,  0.0202,  0.0401,  0.1174, -0.2441, -0.3055, -0.1314,\n          0.2129,  0.0935],\n        [-0.0078, -0.2243,  0.1759,  0.3004, -0.1303, -0.2597, -0.2271,  0.3144,\n         -0.0914, -0.1003],\n        [ 0.1836,  0.1219,  0.2339, -0.2303,  0.2604, -0.0198,  0.2339, -0.2411,\n          0.2057,  0.1353]], requires_grad=True)\n# \u6743\u91cd\u53c2\u6570\u5c3a\u5bf8\ntorch.Size([5, 10])\n# \u504f\u7f6e\u53c2\u6570\nParameter containing:\ntensor([-0.2704,  0.2675, -0.2156,  0.2969,  0.2958], requires_grad=True)\n# \u504f\u7f6e\u53c2\u6570\u5c3a\u5bf8\ntorch.Size([5])\n</code></pre>"},{"location":"PyTorch/nn/layers/nn.Linear/#_3","title":"\u5b98\u65b9\u6587\u6863","text":"<p>nn.Linear()\uff1ahttps://pytorch.org/docs/stable/generated/torch.nn.Linear.html?highlight=linear#torch.nn.Linear</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e741\u670828\u65e5</p>"},{"location":"PyTorch/nn/layers/nn.MultiheadAttention/","title":"\u591a\u5934\u6ce8\u610f\u529b","text":"<pre><code>torch.nn.MultiheadAttention(embed_dim, num_heads, dropout=0.0, bias=True, add_bias_kv=False, add_zero_attn=False, kdim=None, vdim=None, batch_first=False, device=None, dtype=None)\n</code></pre> <p>\u529f\u80fd\uff1a\u521b\u5efa\u4e00\u4e2a\u591a\u5934\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u53c2\u8003\u8bba\u6587\u300atransformer\u300b</p> <p>\u591a\u5934\u6ce8\u610f\u529b\u516c\u5f0f\u4e3a\uff1a $$ MultiHead(Q,K,V)=Concat(head_1,\\dots,head_h)W^O $$  \u5176\u4e2dhead_i=Attention(QW^Q_i,KW_i^K,VW^V_i)\uff0c\u6d41\u7a0b\u56fe\u5982\u4e0b\uff1a</p> <p> <p></p> <p></p> <p>\u53c2\u6570\uff1a</p> <ul> <li><code>embed_dim</code>\uff1a\u8f93\u5165\u6570\u636e\u7684\u7ef4\u5ea6\uff0c\u4e5f\u5c31\u662f\u5411\u91cf\u7684\u957f\u5ea6\uff1b</li> <li> <p><code>num_heads</code>\uff1a\u8868\u793a\u5e76\u884c\u6ce8\u610f\u529b\u7684\u6570\u91cf\uff0c\u4e5f\u5c31\u662f\u201c\u5934\u201d\u7684\u6570\u91cf\uff1b</p> </li> <li> <p><code>dropout</code>\uff1a\u8868\u793a\u6ce8\u610f\u529b\u6743\u91cd\u7684\u4e22\u5f03\u6982\u7387\uff0c\u76f8\u5f53\u4e8e\u751f\u6210\u6ce8\u610f\u529b\u4e4b\u540e\uff0c\u518d\u5c06\u6ce8\u610f\u529b\u4f20\u5165\u4e00\u5c42Dropout\u5c42\uff0c\u9ed8\u8ba4\u4e3a0\uff1b</p> </li> <li><code>bias</code>\uff1a\u5728\u505a\u7ebf\u6027\u53d8\u6362Linear\u65f6\uff0c\u662f\u5426\u6dfb\u52a0\u504f\u7f6e\uff0c\u9ed8\u8ba4<code>True</code></li> <li><code>add_bias_kv</code>\uff1a<code>kv</code>\u505a\u7ebf\u6027\u53d8\u6362\u65f6\u662f\u5426\u52a0\u504f\u7f6e\uff0c\u82e5\u952e\u503c\u7ef4\u5ea6\u4e0e\u5d4c\u5165\u7ef4\u5ea6\u76f8\u540c\uff0c\u5219\u53ef\u4ee5\u5c06<code>add_bias_kv</code>\u8bbe\u4e3aFalse\uff0c\u9ed8\u8ba4<code>False</code></li> <li><code>add_zero_attn</code>\uff1a\u5c06\u4e00\u4e2a\u5168\u96f6\u6ce8\u610f\u529b\u5411\u91cf\u6dfb\u52a0\u5230\u6700\u7ec8\u7684\u8f93\u51fa\u4e2d\uff08\u53ea\u5f71\u54cd\u5f62\u72b6\uff0c\u4e0d\u6539\u53d8\u6570\u503c\uff09\uff0c\u5f3a\u5236\u4f7f\u8f93\u51fa\u5f20\u91cf\u7684\u5f62\u72b6\u4e0e\u8f93\u5165\u5f20\u91cf\u76f8\u540c</li> <li><code>kdim</code>\uff1akeys\u7684\u7279\u5f81\u6570\u636e\u7ef4\u5ea6\uff0c\u5373\u5411\u91cf\u957f\u5ea6\uff0c\u9ed8\u8ba4\u4e0e<code>embed_dim</code>\u76f8\u7b49</li> <li><code>vdim</code>\uff1avalues\u7684\u7279\u5f81\u6570\u636e\u7ef4\u5ea6\uff0c\u5373\u5411\u91cf\u957f\u5ea6\uff0c\u9ed8\u8ba4\u4e0e<code>embed_dim</code>\u76f8\u7b49</li> <li><code>batch_first</code>\uff1a\u5982\u679c\u8bbe\u4e3a<code>True</code>\uff0c\u5219\u8f93\u5165\u3001\u8f93\u51fa\u5f20\u91cf\u8868\u793a\u4e3a\uff08batch, seq, feature\uff09\uff0c\u5426\u5219\u5f20\u91cf\u8868\u793a\u4e3a\uff08seq, batch, feature\uff09\uff0c\u9ed8\u8ba4<code>False</code>\u3002</li> </ul> <p>\u6ce8\u610f\uff1a</p> <ul> <li><code>embed_dim</code>\u4f1a\u88ab\u5212\u5206\u6210<code>num_heads</code>\u4efd\uff0c\u5bf9\u5e94\u7684\u6570\u636e\u4e5f\u4f1a\u88ab\u5212\u5206\uff0c\u4f20\u5165\u4e0d\u540c\u7684\u201chead\u201d\u91cc\uff0c\u6bcf\u4e2a\u201chead\u201d\u7684\u7ef4\u5ea6\u662f<code>embed_dim // num_heads</code>\uff1b</li> </ul> <p>\u524d\u5411\u4f20\u64ad</p> <pre><code>forward(query, key, value, key_padding_mask=None, need_weights=True, attn_mask=None, average_attn_weights=True, is_causal=False)\n</code></pre> <p>\u53c2\u6570\uff1a</p> <ul> <li> <p><code>query, key, value</code>\uff1a\u8868\u793a\u4f20\u5165\u7684qkv\u6570\u636e\uff0c\u5f62\u5f0f\u56e0<code>batch_first</code>\u53d8\u91cf\u800c\u5f02\uff0c\u9ed8\u8ba4\uff08seq, batch, feature\uff09\uff0c\u5373\uff08\u5e8f\u5217\uff0cbatch\uff0c\u7279\u5f81\uff09\uff1b</p> </li> <li> <p><code>key_padding_mask</code>\uff1a\u7528\u4e8e\u6307\u5b9a\u54ea\u4e9b\u4f4d\u7f6e\u662f\u586b\u5145\u4f4d\u7f6e\uff0c\u4ee5\u4fbf\u5728\u8ba1\u7b97\u6ce8\u610f\u529b\u6743\u91cd\u65f6\u5c06\u5176\u5ffd\u7565\u3002\u5bf9\u4e8e<code>batch</code>\u6570\u636e\uff0c\u8f93\u5165\u5c3a\u5bf8\u5e94\u4e3a(N,S)\uff0c\u5176\u4e2dS\u4e3a\u5e8f\u5217\u957f\u5ea6\uff0c\u5bf9\u4e8e\u975e<code>batch</code>\u6570\u636e\uff0c\u8f93\u5165\u5c3a\u5bf8\u5e94\u4e3aS\uff0c\u91cc\u9762\u7684\u6570\u503c\u53ef\u4ee5\u662f\u5e03\u5c14\u3001\u4e5f\u53ef\u4ee5\u662f\u6d6e\u70b9\u6570\u3002\u5e38\u7528\u5e03\u5c14\u6570\u636e\uff0c<code>True</code>\u8868\u793a\u8be5\u4f4d\u7f6e\u4e3a\u586b\u5145\uff0c\u8ba1\u7b97\u6ce8\u610f\u529b\u7684\u65f6\u5019\u9700\u8981\u5ffd\u7565\u8be5\u4f4d\u7f6e\uff0c\u5982\u679c\u4f20\u5165\u6d6e\u70b9\u6570\uff0c\u5219\u4f1a\u5c06\u8be5\u6570\u4e0ekey\u76f8\u52a0\uff0c\u5e38\u52a0\u8d1f\u6570\uff0c\u7528\u4e8e\u6291\u5236\u8be5\u4f4d\u7f6e\uff08False\u4e0e\u8d1f\u65e0\u7a77\u6548\u679c\u4e00\u6837\uff09\uff1b</p> </li> <li><code>need_weights</code>\uff1a\u5982\u679c\u6307\u5b9a\u4e3a<code>True</code>\uff0c\u5219\u7f51\u7edc\u4f1a\u989d\u5916\u8f93\u51fa\u6ce8\u610f\u529b\u6743\u91cd\uff1b</li> <li><code>attn_mask</code>\uff1a\u5c3a\u5bf8\u4e3a(L,S)\u6216(N,num_heads,L,S)\uff0c\u5176\u4e2dL\u8868\u793a\u76ee\u6807\u5e8f\u5217\u957f\u5ea6\uff0c\u6570\u503c\u8868\u793a\u4f4d\u7f6e\uff0cS\u8868\u793a\u6e90\u5e8f\u5217\u957f\u5ea6\uff0c\u6570\u503c\u8868\u793a\u4f4d\u7f6e\uff0c\u5982\u679c attn_mask[b, :, i, j] \u4e3a True\uff0c\u5219\u8868\u793a\u7b2c b \u4e2a\u6837\u672c\u3001\u7b2c i \u4e2a\u76ee\u6807\u4f4d\u7f6e\u548c\u7b2c j \u4e2a\u6e90\u4f4d\u7f6e\u4e4b\u95f4\u9700\u8981\u8fdb\u884c\u6ce8\u610f\u529b\u8ba1\u7b97\uff1b</li> <li><code>average_attn_weights</code>\uff1a\u8868\u793a\u662f\u5426\u8981\u5bf9\u591a\u5934\u6ce8\u610f\u529b\u4e2d\u7684\u6743\u91cd\u6cbf\u201c\u5934\u201d\u65b9\u5411\u505a\u5e73\u5747\uff0c\u5c06\u591a\u7ec4\u6ce8\u610f\u529b\u77e9\u9635\u751f\u6210\u4e00\u7ec4\u77e9\u9635\uff0c\u8bbe\u4e3a<code>True</code>\u65f6\uff0c\u8868\u793a\u9700\u8981\u505a\u5e73\u5747\uff0c\u5373\u751f\u6210\u4e00\u4e2a\u6ce8\u610f\u529b\u77e9\u9635\uff0c\u9ed8\u8ba4True\uff0c\u5373\u751f\u6210\u6bcf\u4e2a\u5934\u7684\u6ce8\u610f\u529b\u77e9\u9635\u3002\u53ea\u6709\u5f53<code>need_weights</code>\u8bbe\u7f6e\u4e3aTrue\u65f6\uff0c\u8be5\u53c2\u6570\u624d\u6709\u610f\u4e49\uff1b</li> <li><code>is_causal</code>\uff1a\u5982\u679c is_causal \u4e3a True\uff0c\u8868\u660e\u76ee\u6807\u5e8f\u5217\u4e2d\u7684\u6bcf\u4e2a\u4f4d\u7f6e\u53ea\u80fd\u4f9d\u8d56\u4e8e\u5b83\u4e4b\u524d\u7684\u4f4d\u7f6e\uff0c\u8fd9\u4e2a\u64cd\u4f5c\u80fd\u591f\u5b9e\u73b0\u56e0\u679c\u6027\uff0c\u9ed8\u8ba4False\u3002\u8fd9\u4e2a\u53c2\u6570\u53ea\u4f5c\u4e3a\u4e00\u4e2a\u63d0\u793a\uff0c\u6700\u7ec8\u662f\u5426\u662f\u56e0\u679c\u7684\uff0c\u8fd8\u662f\u8981\u770b\u53c2\u6570attn_mask\u3002</li> </ul> <p>\u6ce8\uff1a</p> <ul> <li> <p>\u6743\u91cd\u7531\u8ba1\u7b97<code>k\u3001q</code>\u7684\u76f8\u4f3c\u5ea6\u5f97\u5230\uff0c\u5f97\u5230\u7684\u6743\u91cd\u518d\u4e0ev\u76f8\u4e58\uff0c\u505a\u52a0\u6743\u6c42\u548c\uff1b</p> </li> <li> <p>\u8ba1\u7b97\u8fc7\u7a0b\uff1a</p> </li> </ul> <p>\u5148\u8ba9kqv\u505a\u7ebf\u6027\u6620\u5c04\uff0c\u4e4b\u540e\u6cbf\u7279\u5f81\u5411\u91cf\u7684\u65b9\u5411\u62c6\u5206\u6210\u4e0d\u540c\u7684\u201c\u5934\u201d\uff0c\u4e4b\u540e\u5229\u7528\u62c6\u5206\u7684\u5411\u91cf\u505a\u8fd0\u7b97\u2192q\u548ck\u505a\u77e9\u9635\u4e58\u6cd5\uff0c\u5f97\u5230\u6ce8\u610f\u529b\u6743\u91cd\u2192\u6ce8\u610f\u529b\u6743\u91cd\u9664\u4ee5\u7f29\u653e\u56e0\u5b50\\sqrt{d_k}\uff0cd_k\u8868\u793a\u6bcf\u4e2a\u5934\u7684\u7ef4\u5ea6\uff0c\u518d\u505aSoftmax\u8fd0\u7b97\u2192\u7ecf\u8fc7\u4e00\u6b21Dropout\u8fd0\u7b97\uff08\u53ef\u9009\uff09\u2192\u6240\u5f97\u7684\u6743\u91cd\u4e0ev\u505a\u77e9\u9635\u4e58\u6cd5\u2192\u5408\u5e76\u6240\u6709\u201c\u5934\u201d\uff0c\u6700\u540e\u7ecf\u8fc7\u4e00\u6b21\u7ebf\u6027\u6620\u5c04\uff1b</p> <ul> <li>\u591a\u5934\u662f\u62c6\u7279\u5f81\uff0c\u4e0d\u662f\u62c6\u5e8f\u5217\uff1b</li> </ul> <p>\u591a\u5934\u6ce8\u610f\u529bK\u3001Q\u3001V\u89e3\u91ca\uff1a</p> <ul> <li>\u76ee\u524d\u6709\u591a\u7ec4\u952e\u503c\u5339\u914d\u5bf9k\u3001v\uff0c\u6bcf\u4e2ak\u5bf9\u5e94\u4e00\u4e2av\uff0c\u8ba1\u7b97q\u6240\u5bf9\u5e94\u7684\u503c\u3002\u601d\u8def\uff1a\u8ba1\u7b97q\u4e0e\u6bcf\u4e2ak\u7684\u76f8\u4f3c\u5ea6\uff0c\u5f97\u5230v\u7684\u6743\u91cd\uff0c\u4e4b\u540e\u5bf9v\u505a\u52a0\u6743\u6c42\u548c\uff0c\u5f97\u5230q\u5bf9\u5e94\u7684\u6570\u503c\u3002\u56e0\u6b64\u5728\u89e3\u7801\u8fc7\u7a0b\u4e2d\uff0c\u7b2c\u4e8c\u4e2a\u591a\u5934\u6ce8\u610f\u529b\u7684\u8f93\u5165\u4e2d\uff0ck\u3001v\u4f20\u5165\u7f16\u7801\u7279\u5f81\uff08\u662f\u5df2\u77e5\u7684\u7279\u5f81\u5339\u914d\u5bf9\uff09\uff0cq\u4f20\u5165\u89e3\u7801\u7279\u5f81\uff08\u53ef\u8fed\u4ee3\u4f20\u5165\uff09\uff0c\u6c42\u89e3\u7801\u5bf9\u5e94\u7684\u7279\u5f81\uff08\u6839\u636e\u7f16\u7801\u7279\u5f81\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6\u6c42\u89e3\u7801\u7684\u6ce8\u610f\u529b\u52a0\u6743\u7279\u5f81\uff09\u3002</li> </ul> <p>\u6ce8\uff1akqv\u7684\u5173\u7cfb\u7528\u4e00\u53e5\u8bdd\u6765\u8bf4\u5c31\u662f\u6839\u636ekv\u7684\u952e\u503c\u5339\u914d\u5173\u7cfb\uff0c\u9884\u6d4bq\u5bf9\u5e94\u7684\u6570\u503c\uff0c\u6839\u636ekq\u7684\u76f8\u4f3c\u5ea6\u5bf9v\u505a\u52a0\u6743\u6c42\u548c\u3002</p>"},{"location":"PyTorch/nn/layers/nn.MultiheadAttention/#_2","title":"\u5b9e\u73b0\u65b9\u6cd5","text":"<p>\u4ee3\u7801\u6765\u6e90\uff1ahttps://github.com/lucidrains/vit-pytorch/blob/main/vit_pytorch/vit.py</p> <pre><code>class Attention(nn.Module):\n    def __init__(self, dim, heads=8, dim_head=64, dropout=0.):\n        super().__init__()\n        inner_dim = dim_head * heads\n        project_out = not (heads == 1 and dim_head == dim)\n\n        self.heads = heads\n        self.scale = dim_head ** -0.5\n\n        self.attend = nn.Softmax(dim=-1)\n        self.dropout = nn.Dropout(dropout)\n\n        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n\n        self.to_out = nn.Sequential(\n            nn.Linear(inner_dim, dim),\n            nn.Dropout(dropout)\n        ) if project_out else nn.Identity()\n\n    def forward(self, x):\n        qkv = self.to_qkv(x).chunk(3, dim=-1)\n        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -&gt; b h n d', h=self.heads), qkv)\n\n        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n\n        attn = self.attend(dots)\n        attn = self.dropout(attn)\n\n        out = torch.matmul(attn, v)\n        out = rearrange(out, 'b h n d -&gt; b n (h d)')\n        return self.to_out(out)\n</code></pre>"},{"location":"PyTorch/nn/layers/nn.MultiheadAttention/#_3","title":"\u5b98\u65b9\u6587\u6863","text":"<p>nn.MultiheadAttention\uff1ahttps://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html?highlight=attention#torch.nn.MultiheadAttention</p> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u6307\u6b63</p> <p>\u521d\u6b65\u5b8c\u7a3f\u4e8e\uff1a2023\u5e744\u670829\u65e5</p>"},{"location":"PyTorch/nn/loss_functions/nn.CrossEntropyLoss/","title":"\u4ea4\u53c9\u71b5\u635f\u5931","text":"<pre><code>torch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean', label_smoothing=0.0)\n</code></pre> <p>\u529f\u80fd\uff1a\u521b\u5efa\u4e00\u4e2a\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff1a $$ l(x,y)=L=\\{l_1,\\dots,l_N\\}^T\uff0cl_n=-\\sum^C_{c=1}w_c\\log\\frac{e^{x_{n,c}}}{\\sum^C_{i=1}e^{x_{n,i}}}\u00b7 y_{n,c} $$  \u5176\u4e2dx\u662f\u8f93\u5165\uff0cy_{n,c}\u662f\u6807\u7b7e\u5411\u91cf\u5143\u7d20\uff08\u6765\u81ea\u7ecf\u8fc7\u72ec\u70ed\u7f16\u7801\u540e\u7684\u6807\u7b7e\u5411\u91cf\uff09\uff0cw\u662f\u7c7b\u522b\u6743\u91cd\uff0cC\u662f\u7c7b\u522b\u603b\u6570\uff0cN\u8868\u793abatch size\u3002</p> <p>\u8f93\u5165\uff1a</p> <ul> <li> <p><code>size_average</code>\u4e0e<code>reduce</code>\u5df2\u88ab\u5f03\u7528\uff0c\u5177\u4f53\u529f\u80fd\u7531\u53c2\u6570<code>reduction</code>\u4ee3\u66ff</p> </li> <li> <p><code>weight</code>\uff1a\u8d4b\u4e88\u6bcf\u4e2a\u7c7b\u7684\u6743\u91cd\uff0c\u6307\u5b9a\u7684\u6743\u91cd\u5fc5\u987b\u662f\u4e00\u7ef4\u5e76\u4e14\u957f\u5ea6\u4e3aC\u7684\u6570\u7ec4\uff0c\u6570\u636e\u7c7b\u578b\u5fc5\u987b\u4e3a<code>tensor</code>\u683c\u5f0f</p> </li> <li> <p><code>ignore_index</code>\uff1a\u6307\u5b9a\u4e00\u4e2a\u88ab\u5ffd\u7565\uff0c\u5e76\u4e14\u4e0d\u5f71\u54cd\u7f51\u7edc\u53c2\u6570\u66f4\u65b0\u7684\u76ee\u6807\u7c7b\u522b\uff0c\u6570\u636e\u7c7b\u578b\u5fc5\u987b\u662f\u6574\u6570\uff0c\u5373\u53ea\u80fd\u6307\u5b9a\u4e00\u4e2a\u7c7b\u522b</p> </li> <li> <p><code>reduction</code>\uff1a\u6307\u5b9a\u635f\u5931\u8f93\u51fa\u7684\u5f62\u5f0f\uff0c\u6709\u4e09\u79cd\u9009\u62e9\uff1a<code>none</code>|<code>mean</code>|<code>sum</code>\u3002<code>none</code>\uff1a\u635f\u5931\u4e0d\u505a\u4efb\u4f55\u5904\u7406\uff0c\u76f4\u63a5\u8f93\u51fa\u4e00\u4e2a\u6570\u7ec4\uff1b<code>mean</code>\uff1a\u5c06\u5f97\u5230\u7684\u635f\u5931\u6c42\u5e73\u5747\u503c\u518d\u8f93\u51fa\uff0c\u4f1a\u8f93\u51fa\u4e00\u4e2a\u6570\uff1b<code>sum</code>\uff1a\u5c06\u5f97\u5230\u7684\u635f\u5931\u6c42\u548c\u518d\u8f93\u51fa\uff0c\u4f1a\u8f93\u51fa\u4e00\u4e2a\u6570</p> </li> </ul> <p>\u6ce8\u610f\uff1a\u5982\u679c\u6307\u5b9a\u4e86ignore_index\uff0c\u5219\u9996\u5148\u5c06ignore_index\u4ee3\u8868\u7684\u7c7b\u522b\u635f\u5931\u5220\u53bb\uff0c\u5728\u5269\u4e0b\u7684\u635f\u5931\u6570\u636e\u91cc\u6c42\u5747\u503c\uff0c\u56e0\u6b64ignore_index\u6240\u4ee3\u8868\u7684\u7684\u7c7b\u522b\u5b8c\u5168\u4e0d\u4f1a\u5f71\u54cd\u7f51\u7edc\u53c2\u6570\u7684\u66f4\u65b0</p> <ul> <li><code>label_smoothing</code>\uff1a\u6307\u5b9a\u8ba1\u7b97\u635f\u5931\u65f6\u7684\u5e73\u6ed1\u91cf\uff0c\u5176\u4e2d0.0\u8868\u793a\u4e0d\u5e73\u6ed1\uff0c\u5173\u4e8e\u5e73\u6ed1\u91cf\u53ef\u53c2\u8003\u8bba\u6587\u300aRethinking the Inception Architecture for Computer Vision\u300b</li> </ul> <p>\u6ce8\u610f\uff1a</p> <ul> <li>\u8f93\u5165\u5e94\u8be5\u5305\u542b\u539f\u59cb\u3001\u672a\u7ecf\u8fc7\u6807\u51c6\u5316\u7684\u9884\u6d4b\u503c\uff0c<code>CrossEntropyLoss</code>\u51fd\u6570\u5df2\u7ecf\u5185\u7f6e<code>softmax</code>\u5904\u7406</li> <li>\u5bf9\u4e8e\u8f93\u5165\u5f20\u91cfx\uff0c\u5c3a\u5bf8\u5fc5\u987b\u4e3a(minibatch,C)\u6216\u8005(minibatch,C,d_1,\\dots,d_K)\uff0c\u540e\u8005\u5bf9\u4e8e\u8ba1\u7b97\u9ad8\u7ef4\u8f93\u5165\u65f6\u5f88\u6709\u7528\uff0c\u5982\u8ba1\u7b97\u4e8c\u7ef4\u56fe\u50cf\u4e2d\u6bcf\u4e2a\u50cf\u7d20\u70b9\u7684\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u6ce8\u610f\uff1aK\u22651</li> <li>\u8f93\u5165\u7684\u5f20\u91cfy\uff0c\u5c3a\u5bf8\u5fc5\u987b\u4e3a(minibatch)\u6216\u8005(minibatch,d_1,\\dots,d_K)\uff0c\u4e0ex\u7684\u5c3a\u5bf8\u76f8\u5bf9\u5e94\uff0c\u540e\u8005\u4e5f\u662f\u7528\u4e8e\u9ad8\u7ef4\u6570\u636e\u7684\u8ba1\u7b97</li> <li>\u6ce8\u610fx\u7684\u7b2c\u4e8c\u7ef4\u5ea6\u5c3a\u5bf8\u4e0e\u7c7b\u522b\u6570\u91cf\u4e00\u4e00\u5bf9\u5e94\uff0c\u5e76\u4e14y\u53ea\u9700\u8981\u8f93\u5165\u7269\u4f53\u7c7b\u522b\u5e8f\u53f7\u5373\u53ef\uff0c\u65e0\u9700\u8f93\u5165\u72ec\u70ed\u7f16\u7801\uff08\u8be5\u51fd\u6570\u4f1a\u81ea\u52a8\u5bf9y\u505a\u72ec\u70ed\u7f16\u7801\uff09\uff0cy\u91cc\u9762\u6570\u636e\u7684\u5927\u5c0f\u4e0d\u80fd\u8d85\u8fc7x\u7b2c\u4e8c\u7ef4\u5ea6\u5c3a\u5bf8\u7684\u5927\u5c0f\u51cf\u4e00(\u51cf\u4e00\u662f\u56e0\u4e3a\u6807\u7b7ey\u662f\u4ece0\u5f00\u59cb\u8ba1\u7b97)</li> </ul>"},{"location":"PyTorch/nn/loss_functions/nn.CrossEntropyLoss/#_2","title":"\u4ee3\u7801\u6848\u4f8b","text":""},{"location":"PyTorch/nn/loss_functions/nn.CrossEntropyLoss/#_3","title":"\u4e00\u822c\u7528\u6cd5","text":"<pre><code>import torch.nn as nn\nimport torch\n\nx = torch.randn((2, 8))\n# \u57280-7\u8303\u56f4\u5185\uff0c\u968f\u673a\u751f\u6210\u4e24\u4e2a\u6570\uff0c\u5f53\u505a\u6807\u7b7e\ny = torch.randint(0, 8, [2])\nce = nn.CrossEntropyLoss()\nout = ce(x, y)\nprint(x)\nprint(y)\nprint(out)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># x\ntensor([[ 1.3712,  0.4903, -1.3202,  0.1297, -1.6004, -0.1809, -2.8812, -0.3088],\n        [ 0.5855, -0.4926,  0.7647, -0.1717, -1.0418, -0.0381, -0.1307, -0.6390]])\n# y\ntensor([5, 0])\n# \u5f97\u5230\u7684\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u9ed8\u8ba4\u8fd4\u56de\u635f\u5931\u7684\u5e73\u5747\u503c\ntensor(1.9324)\n</code></pre>"},{"location":"PyTorch/nn/loss_functions/nn.CrossEntropyLoss/#weight","title":"\u53c2\u6570weight\u7684\u7528\u6cd5","text":"<pre><code>import torch.nn as nn\nimport torch\n\nx = torch.randn((2, 2))\ny = torch.tensor([0, 1])\n# \u4e0d\u6dfb\u52a0weight\nce = nn.CrossEntropyLoss(reduction='none')\n# \u6dfb\u52a0weight\nce_w = nn.CrossEntropyLoss(weight=torch.tensor([0.5, 1.5]), reduction='none')\nout = ce(x, y)\nout_w = ce_w(x, y)\nprint(x)\nprint(y)\nprint(out)\nprint(out_w)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># x\ntensor([[-1.1011,  0.6231],\n        [ 0.2384, -0.3223]])\n# y\ntensor([0, 1])\n# \u4e0d\u6dfb\u52a0weight\u65f6\u7684\u635f\u5931\u8f93\u51fa\ntensor([1.8883, 1.0123])\n# weight\u5b9a\u4e49\u4e3a[0.5, 1.5]\u65f6\u7684\u635f\u5931\n# \u7b2c\u4e00\u4e2a\u6570\u636e(batch\u4e2d\u7b2c\u4e00\u4e2a\u5143\u7d20)\u7531\u4e8e\u6807\u7b7e\u4e3a0\n# \u56e0\u6b64\u5bf9\u5e94\u7684\u635f\u5931\u4e58\u4ee5weight\u4e2d\u7b2c\u4e00\u4e2a\u6743\u91cd\n# \u7b2c\u4e8c\u4e2a\u6570\u636e\u7c7b\u4f3c\ntensor([0.9441, 1.5184])\n</code></pre>"},{"location":"PyTorch/nn/loss_functions/nn.CrossEntropyLoss/#ignore_index","title":"\u53c2\u6570ignore_index\u7684\u7528\u6cd5","text":"<pre><code>import torch.nn as nn\nimport torch\n\nx = torch.randn((2, 2))\ny = torch.tensor([0, 1])\n# \u4e0d\u6dfb\u52a0ignore_index\nce = nn.CrossEntropyLoss(reduction='none')\n# \u6dfb\u52a0ignore_index\nce_i = nn.CrossEntropyLoss(ignore_index = 0, reduction='none')\nout = ce(x, y)\nout_i = ce_i(x, y)\nprint(x)\nprint(y)\nprint(out)\nprint(out_i)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># x\ntensor([[-0.9390, -0.6169],\n        [-0.7700,  0.3602]])\n# y\ntensor([0, 1])\n# \u4e0d\u6dfb\u52a0ignore_index\u65f6\u7684\u635f\u5931\u8f93\u51fa\ntensor([0.8671, 0.2799])\n# ignore_index\u8bbe\u7f6e\u4e3a0\uff0c\u8868\u793a\u5ffd\u7565\u7c7b\u522b\u5e8f\u53f7\u4e3a0\u7684\u635f\u5931\n# \u8fd9\u91cc\u7b2c\u4e00\u4e2a\u6570\u636e\u6807\u7b7e\u8bbe\u7f6e\u4e3a0\uff0c\u56e0\u6b64\u7b2c\u4e00\u4e2a\u635f\u5931\u6e05\u96f6\ntensor([0.0000, 0.2799])\n</code></pre>"},{"location":"PyTorch/nn/loss_functions/nn.CrossEntropyLoss/#_4","title":"\u8f93\u5165\u9ad8\u7ef4\u6570\u636e\u65f6","text":"<p>\u8fd9\u91cc\u4ee5\u5bf9\u4e8c\u7ef4\u7684\u9884\u6d4b\u56fe\u505a\u635f\u5931\u4e3a\u4f8b</p> <pre><code>import torch.nn as nn\nimport torch\n# \u8fd9\u91cc\u8868\u793a\u968f\u673a\u751f\u6210batch\u4e3a1\uff0c\u56fe\u7247\u5c3a\u5bf8\u4e3a3*3\n# \u5e76\u4e14\u6bcf\u4e2a\u70b9\u6709\u4e24\u4e2a\u7c7b\u522b\u7684\u9884\u6d4b\u56fe\nx = torch.randn((1, 2, 3, 3))\n# \u8fd9\u91cc\u8868\u793a\u9884\u6d4b\u56fex\u5bf9\u5e94\u7684\u6807\u7b7ey\n# \u9884\u6d4b\u56fex\u6bcf\u4e2a\u4f4d\u7f6e\u90fd\u4f1a\u5bf9\u5e94\u4e00\u4e2a\u6807\u7b7e\u503c\n# x\u5220\u53bb\u7b2c\u4e8c\u7ef4\u5ea6\u540e\u7684\u5c3a\u5bf8\uff0c\u5c31\u662f\u6807\u7b7ey\u7684\u5c3a\u5bf8\ny = torch.randint(0, 2, [1, 3, 3])\nce = nn.CrossEntropyLoss(reduction='none')\nout = ce(x, y)\nprint(x)\nprint(y)\nprint(out)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u8f93\u5165\u7684\u9ad8\u7ef4\u6570\u636ex\ntensor([[[[ 0.8859, -2.0889, -0.6026],\n          [-1.6448,  0.7807,  0.9609],\n          [-0.0646,  0.2204, -0.7471]],\n\n         [[ 0.7075, -0.7013, -0.9280],\n          [-0.6913,  2.1507, -0.0758],\n          [ 0.2139,  0.8387,  0.3743]]]])\n# \u5bf9\u5e94\u7684\u6807\u7b7e\uff0c\u9884\u6d4b\u56fex\u957f\u5bbd\u4e3a\u591a\u5c11\uff0c\u6807\u7b7ey\u7684\u957f\u5bbd\u5c31\u4e3a\u591a\u5c11\ntensor([[[0, 0, 1],\n         [0, 0, 0],\n         [1, 0, 1]]])\n# \u8f93\u51fa\u7684\u635f\u5931\n# \u51fd\u6570\u4f1a\u4e3a\u9884\u6d4b\u56fex\u4e0a\u6bcf\u4e2a\u4f4d\u7f6e\u90fd\u751f\u6210\u4e00\u4e2a\u635f\u5931\uff0c\u8fd9\u91cc\u4e00\u5171\u751f\u62103*3\u4e2a\u635f\u5931(\u5bf9\u5e94\u957f\u4e58\u5bbd)\ntensor([[[0.6079, 1.6105, 0.8690],\n         [1.2794, 1.5964, 0.3035],\n         [0.5635, 1.0493, 0.2820]]])\n</code></pre>"},{"location":"PyTorch/nn/loss_functions/nn.CrossEntropyLoss/#_5","title":"\u5b98\u65b9\u6587\u6863","text":"<p>nn.CrossEntropyLoss\uff1ahttps://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e741\u670829\u65e5</p>"},{"location":"PyTorch/nn/loss_functions/nn.KLDivLoss/","title":"KL\u6563\u5ea6\u635f\u5931","text":"<pre><code>torch.nn.KLDivLoss(size_average=None, reduce=None, reduction='mean', log_target=False)\n</code></pre> <p>\u529f\u80fd\uff1a\u751f\u6210\u4e00\u4e2aKL\u6563\u5ea6\u635f\u5931\u51fd\u6570\uff0c\u5e38\u7528\u4e8e\u8861\u91cf\u4e24\u4e2a\u8fde\u7eed\u5206\u5e03\u7684\u8ddd\u79bb\uff1a $$ l(x,y)=L=\\{l_1,\\dots,l_N\\}\uff0cl_n=y_n(logy_n-x_n) $$  \u5176\u4e2d\uff0cN\u8868\u793abatch size\u3002</p> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>size_average</code>\u4e0e<code>reduce</code>\u5df2\u88ab\u5f03\u7528\uff0c\u5177\u4f53\u529f\u80fd\u7531\u53c2\u6570<code>reduction</code>\u4ee3\u66ff</li> <li><code>reduction</code>\uff1a\u6307\u5b9a\u635f\u5931\u8f93\u51fa\u7684\u5f62\u5f0f\uff0c\u6709\u56db\u79cd\u9009\u62e9\uff1a<code>none</code>|<code>mean</code>|<code>batchmean</code>|<code>sum</code>\u3002<code>none</code>\uff1a\u635f\u5931\u4e0d\u505a\u4efb\u4f55\u5904\u7406\uff0c\u76f4\u63a5\u8f93\u51fa\u4e00\u4e2a\u6570\u7ec4\uff1b<code>mean</code>\uff1a\u5c06\u5f97\u5230\u7684\u635f\u5931\u6c42\u5e73\u5747\u503c\u518d\u8f93\u51fa\uff0c\u4f1a\u8f93\u51fa\u4e00\u4e2a\u6570\uff1b<code>batchmean</code>\uff1a\u5c06\u8f93\u51fa\u7684\u603b\u548c\u9664\u4ee5batchsize\uff1b<code>sum</code>\uff1a\u5c06\u5f97\u5230\u7684\u635f\u5931\u6c42\u548c\u518d\u8f93\u51fa\uff0c\u4f1a\u8f93\u51fa\u4e00\u4e2a\u6570</li> <li><code>log_target</code>\uff1a\u6307\u5b9a\u662f\u5426\u5bf9\u8f93\u5165\u7684y\u4f7f\u7528log\u64cd\u4f5c</li> </ul> <p>\u6ce8\u610f\uff1a</p> <ul> <li>\u7ed9\u5b9a\u7684\u8f93\u5165x\u5e94\u8be5\u4e3a\u5bf9\u6570\u6982\u7387\u5f62\u5f0f\uff0c\u5373\u9996\u5148\u5bf9\u7f51\u7edc\u7684\u8f93\u51fa\u5e94\u7528<code>softmax</code>\uff0c\u4e4b\u540e\u518d\u53d6\u5bf9\u6570(\u53ef\u7531<code>F.log_softmax</code>\u51fd\u6570\u76f4\u63a5\u5b9e\u73b0)</li> <li><code>reduction</code>\u8bbe\u7f6e\u4e3a<code>mean</code>\u65f6\uff0c\u5e76\u4e0d\u4f1a\u8fd4\u56de\u771f\u6b63\u7684KL\u6563\u5ea6\u503c\uff0c\u5728\u5b9a\u4e49KL\u7684\u65f6\u5019\uff0c\u9700\u4f7f\u7528<code>batchmean</code>(\u4e0e\u6570\u5b66\u516c\u5f0f\u5bf9\u5e94\u8d77\u6765)</li> <li>\u7531\u4e8eKL\u6563\u5ea6\u5177\u6709\u4e0d\u5bf9\u79f0\u6027\uff0c\u5b58\u5728\u4e00\u4e2a\u6307\u5bfc\u548c\u88ab\u6307\u5bfc\u7684\u5173\u7cfb\uff0c\u5982\u679c\u60f3\u7528y\u53bb\u6307\u5bfcx\uff0c\u5219\u7b2c\u4e00\u4e2a\u53c2\u6570\u9700\u8981\u4f20x\uff0c\u7b2c\u4e8c\u4e2a\u53c2\u6570\u9700\u8981\u4f20y\uff0c\u56e0\u6b64\u8fd9\u91cc\u53c8\u79f0y\u4e3atarget\u3002\u5f15\u81ea\uff1ahttps://www.w3cschool.cn/article/84661764.html</li> </ul>"},{"location":"PyTorch/nn/loss_functions/nn.KLDivLoss/#_1","title":"\u4ee3\u7801\u6848\u4f8b","text":"<pre><code>import torch.nn as nn\nimport torch\nimport torch.nn.functional as F\n\nx = torch.randn((1, 8))\ny = torch.randn((1, 8))\n# \u5148\u8f6c\u5316\u4e3a\u6982\u7387\uff0c\u4e4b\u540e\u53d6\u5bf9\u6570\nx_log = F.log_softmax(x,dim=1)\n# \u53ea\u8f6c\u5316\u4e3a\u6982\u7387\ny = F.softmax(y,dim=1)\nkl = nn.KLDivLoss(reduction='batchmean')\nout = kl(x_log, y)\nprint(x)\nprint(y)\nprint(out)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u8f93\u5165x\ntensor([[-4.6294, -1.2088, -4.3072, -1.1917, -2.8688, -5.9614, -3.3626, -1.2710]])\n# \u8f93\u5165y\ntensor([[0.0045, 0.0434, 0.0118, 0.0118, 0.0921, 0.4020, 0.3631, 0.0712]])\n# \u8f93\u51fa\u7684\u635f\u5931\ntensor(2.7031)\n</code></pre>"},{"location":"PyTorch/nn/loss_functions/nn.KLDivLoss/#_2","title":"\u5b98\u65b9\u6587\u6863","text":"<p>nn.KLDivLoss\uff1ahttps://pytorch.org/docs/stable/generated/torch.nn.KLDivLoss.html#torch.nn.KLDivLoss</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e741\u670830\u65e5</p>"},{"location":"PyTorch/nn/loss_functions/nn.L1Loss/","title":"L1\u635f\u5931","text":"<pre><code>torch.nn.L1Loss(size_average=None, reduce=None, reduction='mean')\n</code></pre> <p>\u529f\u80fd\uff1a\u521b\u5efa\u4e00\u4e2a\u7edd\u5bf9\u503c\u8bef\u5dee\u635f\u5931\u51fd\u6570\uff0c\u5373L1\u635f\u5931\uff1a $$ l(x,y)=L=\\{l_1,\\dots,l_N\\}^T,l_n=|x_n-y_n| $$  \u5176\u4e2d\uff0cN\u8868\u793abatch size\u3002</p> <p>\u51fd\u6570\u56fe\u50cf\uff1a</p> <p> <p></p> <p></p> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>size_average</code>\u4e0e<code>reduce</code>\u5df2\u7ecf\u88ab\u5f03\u7528\uff0c\u5177\u4f53\u529f\u80fd\u53ef\u7531<code>reduction</code>\u66ff\u4ee3</li> <li><code>reduction</code>\uff1a\u6307\u5b9a\u635f\u5931\u8f93\u51fa\u7684\u5f62\u5f0f\uff0c\u6709\u4e09\u79cd\u9009\u62e9\uff1a<code>none</code>|<code>mean</code>|<code>sum</code>\u3002<code>none</code>\uff1a\u635f\u5931\u4e0d\u505a\u4efb\u4f55\u5904\u7406\uff0c\u76f4\u63a5\u8f93\u51fa\u4e00\u4e2a\u6570\u7ec4\uff1b<code>mean</code>\uff1a\u5c06\u5f97\u5230\u7684\u635f\u5931\u6c42\u5e73\u5747\u503c\u518d\u8f93\u51fa\uff0c\u4f1a\u8f93\u51fa\u4e00\u4e2a\u6570\uff1b<code>sum</code>\uff1a\u5c06\u5f97\u5230\u7684\u635f\u5931\u6c42\u548c\u518d\u8f93\u51fa\uff0c\u4f1a\u8f93\u51fa\u4e00\u4e2a\u6570</li> </ul> <p>\u6ce8\u610f\uff1a</p> <ul> <li>\u8f93\u5165\u7684x\u4e0ey\u53ef\u4ee5\u662f\u4efb\u610f\u7ef4\u6570\u7684\u6570\u7ec4\uff0c\u4f46\u662f\u4e8c\u8005\u5f62\u72b6\u5fc5\u987b\u4e00\u81f4</li> </ul>"},{"location":"PyTorch/nn/loss_functions/nn.L1Loss/#_1","title":"\u4ee3\u7801\u6848\u4f8b","text":"<p>\u5bf9\u6bd4<code>reduction</code>\u4e0d\u540c\u65f6\uff0c\u8f93\u51fa\u635f\u5931\u7684\u5dee\u5f02</p> <pre><code>import torch.nn as nn\nimport torch\n\nx = torch.rand(10, dtype=torch.float)\ny = torch.rand(10, dtype=torch.float)\nL1_none = nn.L1Loss(reduction='none')\nL1_mean = nn.L1Loss(reduction='mean')\nL1_sum = nn.L1Loss(reduction='sum')\nout_none = L1_none(x, y)\nout_mean = L1_mean(x, y)\nout_sum = L1_sum(x, y)\nprint(x)\nprint(y)\nprint(out_none)\nprint(out_mean)\nprint(out_sum)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u7528\u4e8e\u8f93\u5165\u7684x\ntensor([0.8597, 0.0679, 0.6531, 0.5442, 0.9690, 0.1412, 0.1161, 0.6927, 0.2017, 0.3142])\n# \u7528\u4e8e\u8f93\u5165\u7684y\ntensor([0.2538, 0.2823, 0.7768, 0.6710, 0.4303, 0.7249, 0.5897, 0.0048, 0.4121, 0.8169])\n# \u5f53reduction\u8bbe\u7f6e\u4e3anone\u65f6\uff0c\u8f93\u51fa\u4e00\u4e2a\u6570\u7ec4\n# \u8be5\u6570\u7ec4\u4e0a\u7684\u5143\u7d20\u4e3ax\uff0cy\u5bf9\u5e94\u6bcf\u4e2a\u5143\u7d20\u7684\u7edd\u5bf9\u503c\u635f\u5931\uff0c\u5373\u5bf9\u5e94\u5143\u7d20\u505a\u5dee\u6c42\u7edd\u5bf9\u503c\ntensor([0.6059, 0.2143, 0.1237, 0.1268, 0.5387, 0.5837, 0.4737, 0.6879, 0.2103, 0.5027])\n# \u5f53reduction\u8bbe\u7f6e\u4e3amean\u65f6\uff0c\u8f93\u51fa\u6240\u6709\u635f\u5931\u7684\u5e73\u5747\u503c\ntensor(0.4068)\n# \u5f53reduction\u8bbe\u7f6e\u4e3asum\u65f6\uff0c\u8f93\u51fa\u6240\u6709\u635f\u5931\u7684\u548c\ntensor(4.0677)\n</code></pre> <p>\u6ce8\uff1a\u7ed8\u56fe\u7a0b\u5e8f</p> <pre><code>import torch.nn as nn\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nloss = nn.L1Loss(reduction='none')\nx = torch.tensor([0]*100)\ny = torch.from_numpy(np.linspace(-3,3,100))\nloss_value = loss(x,y)\nplt.plot(y, loss_value)\nplt.savefig('L1Loss.jpg')\n</code></pre>"},{"location":"PyTorch/nn/loss_functions/nn.L1Loss/#_2","title":"\u5b98\u65b9\u6587\u6863","text":"<p>nn.L1Loss\uff1ahttps://pytorch.org/docs/stable/generated/torch.nn.L1Loss.html#torch.nn.L1Loss</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e741\u670829\u65e5</p>"},{"location":"PyTorch/nn/loss_functions/nn.MSELoss/","title":"MSE\u635f\u5931","text":"<pre><code>torch.nn.MSELoss(size_average = None\uff0creduce = None\uff0creduction = 'mean')\n</code></pre> <p>\u529f\u80fd\uff1a\u521b\u5efa\u4e00\u4e2a\u5e73\u65b9\u8bef\u5dee(MSE)\u635f\u5931\u51fd\u6570\uff0c\u53c8\u79f0\u4e3aL2\u635f\u5931\uff1a $$ l(x,y)=L=\\{l_1,\\dots,l_N\\}^T,l_n=(x_n-y_n)^2 $$  \u5176\u4e2d\uff0cN\u8868\u793abatch size\u3002</p> <p>\u51fd\u6570\u56fe\u50cf\uff1a</p> <p> <p></p> <p></p> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>size_average</code>\u4e0e<code>reduce</code>\u5df2\u7ecf\u88ab\u5f03\u7528\uff0c\u5177\u4f53\u529f\u80fd\u53ef\u7531<code>reduction</code>\u66ff\u4ee3</li> <li><code>reduction</code>\uff1a\u6307\u5b9a\u635f\u5931\u8f93\u51fa\u7684\u5f62\u5f0f\uff0c\u6709\u4e09\u79cd\u9009\u62e9\uff1a<code>none</code>|<code>mean</code>|<code>sum</code>\u3002<code>none</code>\uff1a\u635f\u5931\u4e0d\u505a\u4efb\u4f55\u5904\u7406\uff0c\u76f4\u63a5\u8f93\u51fa\u4e00\u4e2a\u6570\u7ec4\uff1b<code>mean</code>\uff1a\u5c06\u5f97\u5230\u7684\u635f\u5931\u6c42\u5e73\u5747\u503c\u518d\u8f93\u51fa\uff0c\u4f1a\u8f93\u51fa\u4e00\u4e2a\u6570\uff1b<code>sum</code>\uff1a\u5c06\u5f97\u5230\u7684\u635f\u5931\u6c42\u548c\u518d\u8f93\u51fa\uff0c\u4f1a\u8f93\u51fa\u4e00\u4e2a\u6570</li> </ul> <p>\u6ce8\u610f\uff1a</p> <ul> <li>\u8f93\u5165\u7684x\u4e0ey\u53ef\u4ee5\u662f\u4efb\u610f\u7ef4\u6570\u7684\u6570\u7ec4\uff0c\u4f46\u662f\u4e8c\u8005\u5f62\u72b6\u5fc5\u987b\u4e00\u81f4</li> </ul>"},{"location":"PyTorch/nn/loss_functions/nn.MSELoss/#_1","title":"\u4ee3\u7801\u6848\u4f8b","text":"<p>\u5bf9\u6bd4<code>reduction</code>\u4e0d\u540c\u65f6\uff0c\u8f93\u51fa\u635f\u5931\u7684\u5dee\u5f02</p> <pre><code>import torch.nn as nn\nimport torch\n\nx = torch.rand(10, dtype=torch.float)\ny = torch.rand(10, dtype=torch.float)\nmse_none = nn.MSELoss(reduction='none')\nmse_mean = nn.MSELoss(reduction='mean')\nmse_sum = nn.MSELoss(reduction='sum')\nout_none = mse_none(x, y)\nout_mean = mse_mean(x, y)\nout_sum = mse_sum(x, y)\nprint(x)\nprint(y)\nprint(out_none)\nprint(out_mean)\nprint(out_sum)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u7528\u4e8e\u8f93\u5165\u7684x\ntensor([0.4138, 0.1747, 0.9259, 0.2938, 0.5557, 0.9708, 0.0649, 0.6155, 0.3192, 0.1918])\n# \u7528\u4e8e\u8f93\u5165\u7684y\ntensor([0.1024, 0.9160, 0.8386, 0.0783, 0.1479, 0.9933, 0.8791, 0.4219, 0.7586, 0.2212])\n# \u5f53reduction\u8bbe\u7f6e\u4e3anone\u65f6\uff0c\u8f93\u51fa\u4e00\u4e2a\u6570\u7ec4\n# \u8be5\u6570\u7ec4\u4e0a\u7684\u5143\u7d20\u4e3ax\uff0cy\u5bf9\u5e94\u6bcf\u4e2a\u5143\u7d20\u7684\u5e73\u65b9\u8bef\u5dee\u635f\u5931\uff0c\u5373\u5bf9\u5e94\u5143\u7d20\u505a\u5dee\u6c42\u5e73\u65b9\ntensor([9.6983e-02, 5.4955e-01, 7.6214e-03, 4.6433e-02, 1.6630e-01, 5.0293e-04, 6.6287e-01, 3.7512e-02, 1.9310e-01, 8.6344e-04])\n# \u5f53reduction\u8bbe\u7f6e\u4e3amean\u65f6\uff0c\u8f93\u51fa\u6240\u6709\u635f\u5931\u7684\u5e73\u5747\u503c\ntensor(0.1762)\n# \u5f53reduction\u8bbe\u7f6e\u4e3asum\u65f6\uff0c\u8f93\u51fa\u6240\u6709\u635f\u5931\u7684\u548c\ntensor(1.7617)\n</code></pre> <p>\u6ce8\uff1a\u7ed8\u56fe\u7a0b\u5e8f</p> <pre><code>import torch.nn as nn\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nloss = nn.MSELoss(reduction='none')\nx = torch.tensor([0]*100)\ny = torch.from_numpy(np.linspace(-3,3,100))\nloss_value = loss(x,y)\nplt.plot(y, loss_value)\nplt.savefig('MSELoss.jpg')\n</code></pre>"},{"location":"PyTorch/nn/loss_functions/nn.MSELoss/#_2","title":"\u5b98\u65b9\u6587\u6863","text":"<p>nn.MSELoss\uff1ahttps://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e741\u670829\u65e5</p>"},{"location":"PyTorch/nn/loss_functions/nn.MarginRankingLoss/","title":"\u6392\u5e8f\u635f\u5931","text":"<pre><code>torch.nn.MarginRankingLoss(margin=0.0, size_average=None, reduce=None, reduction='mean')\n</code></pre> <p>\u529f\u80fd\uff1a\u521b\u5efa\u4e00\u4e2a\u6392\u5e8f\u635f\u5931\u51fd\u6570\uff0c\u7528\u4e8e\u8861\u91cf\u8f93\u5165x_1\u4e0ex_2\u4e4b\u95f4\u7684\u6392\u5e8f\u635f\u5931(Ranking Loss)\uff0c\u8f93\u5165\u7684\u7b2c\u4e09\u4e2a\u53c2\u6570y\u63a7\u5236\u987a\u5e8f\u8fd8\u662f\u9006\u5e8f\uff0c\u56e0\u6b64y\u7684\u53d6\u503c\u8303\u56f4\u4e3ay\\in\\{1,-1\\}\u3002</p> <p>\u635f\u5931\u51fd\u6570\uff1a $$ loss(x_1,x_2,y)=\\max(0,-y*(x_1-x_2)+\\text{margin}) $$ \u5f53\u671f\u671bx_1&gt;x_2\uff0c\u5373\u6392\u5e8f\u4e3a\u987a\u5e8f\u65f6\uff0c\u5e94\u8be5\u4f20\u5165y=1\uff1b\u5f53\u671f\u671bx_1&lt;x_2\uff0c\u5373\u6392\u5e8f\u4e3a\u9006\u5e8f\u65f6\uff0c\u5e94\u8be5\u4f20\u5165y=-1\u3002</p> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>margin</code>\uff1a\u5dee\u989d\u503c\uff0c\u5177\u4f53\u7528\u6cd5\u5982\u516c\u5f0f\u6240\u793a\uff0c\u5982\u679c\u8be5\u503c\u8d8a\u5927\uff0c\u5219\u8868\u793a\u671f\u671bx_1\u4e0ex_2\u8d8a\u8fdc\uff0c\u5373\u5dee\u989d\u8d8a\u5927\u3002\u8f93\u5165\u6570\u636e\u7c7b\u578b\u4e3a<code>float</code>\uff0c\u9ed8\u8ba4\u4e3a0\uff1b</li> <li><code>size_average</code>\u4e0e<code>reduce</code>\u5df2\u88ab\u5f03\u7528\uff0c\u5177\u4f53\u529f\u80fd\u7531<code>reduction</code>\u66ff\u4ee3</li> <li><code>reduction</code>\uff1a\u6307\u5b9a\u635f\u5931\u8f93\u51fa\u7684\u5f62\u5f0f\uff0c\u6709\u4e09\u79cd\u9009\u62e9\uff1a<code>none</code>|<code>mean</code>|<code>sum</code>\u3002<code>none</code>\uff1a\u635f\u5931\u4e0d\u505a\u4efb\u4f55\u5904\u7406\uff0c\u76f4\u63a5\u8f93\u51fa\u4e00\u4e2a\u6570\u7ec4\uff1b<code>mean</code>\uff1a\u5c06\u5f97\u5230\u7684\u635f\u5931\u6c42\u5e73\u5747\u503c\u518d\u8f93\u51fa\uff0c\u4f1a\u8f93\u51fa\u4e00\u4e2a\u6570\uff1b<code>sum</code>\uff1a\u5c06\u5f97\u5230\u7684\u635f\u5931\u6c42\u548c\u518d\u8f93\u51fa\uff0c\u4f1a\u8f93\u51fa\u4e00\u4e2a\u6570</li> </ul> <p>\u6ce8\u610f\uff1a</p> <ul> <li>\u8f93\u5165\u7684x_1\u3001x_2\u4e0ey\u5fc5\u987b\u662f\u4e00\u7ef4\u7684\u6570\u636e\uff0c\u5e76\u4e14\u4e09\u4e2a\u6570\u636e\u957f\u5ea6\u5fc5\u987b\u4e00\u81f4\uff0c\u6570\u636e\u957f\u5ea6\u8868\u793abatch\u5927\u5c0f</li> </ul>"},{"location":"PyTorch/nn/loss_functions/nn.MarginRankingLoss/#_2","title":"\u4ee3\u7801\u6848\u4f8b","text":"<p>\u4e00\u822c\u7528\u6cd5</p> <pre><code>import torch\nimport torch.nn as nn\n\n# reduction\u8bbe\u4e3anone\u4fbf\u4e8e\u67e5\u770b\u6bcf\u4e2a\u4f4d\u7f6e\u635f\u5931\u8ba1\u7b97\u7684\u7ed3\u679c\nrankloss = nn.MarginRankingLoss(reduction='none')\nx1 = torch.randn(10)\nx2 = torch.randn(10)\n# \u968f\u673a\u751f\u621010\u4e2a0,1\u6570\u636e\ny = torch.randint(0, 2, [10])\n# \u5c06y\u4e2d\u6570\u636e\u4e3a0\u7684\u4f4d\u7f6e\u8d4b\u503c\u4e3a-1\ny[y==0] = -1\nloss = rankloss(x1, x2, y)\nprint(x1)\nprint(x2)\nprint(y)\nprint(loss)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># x1\ntensor([-1.2248, -1.4788,  0.1703,  0.1072, -0.2147,  0.7527, -1.2443,  0.8361, 0.3679,  0.5935])\n# x2\ntensor([-0.3616, -0.0333,  0.8483,  0.9880,  0.6980, -0.5157,  0.1767,  0.2060, -0.4908,  1.1774])\n# y\ntensor([ 1, -1,  1, -1,  1, -1,  1, -1,  1, -1])\n# \u5bf9\u5e94\u4f4d\u7f6e\u7684\u635f\u5931\u8ba1\u7b97\u7ed3\u679c\ntensor([0.8631, 0.0000, 0.6780, 0.0000, 0.9127, 1.2684, 1.4210, 0.6301, 0.0000, 0.0000])\n</code></pre>"},{"location":"PyTorch/nn/loss_functions/nn.MarginRankingLoss/#_3","title":"\u5b98\u65b9\u6587\u6863","text":"<p>nn.MarginRankingLoss\uff1ahttps://pytorch.org/docs/stable/generated/torch.nn.MarginRankingLoss.html#torch.nn.MarginRankingLoss</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e742\u67086\u65e5</p>"},{"location":"PyTorch/nn/loss_functions/nn.SmoothL1Loss/","title":"\u5e73\u6ed1L1\u635f\u5931","text":"<pre><code>torch.nn.SmoothL1Loss(size_average=None, reduce=None, reduction='mean', beta=1.0)\n</code></pre> <p>\u529f\u80fd\uff1a\u521b\u5efa\u4e00\u4e2a\u5e73\u6ed1\u540e\u7684L_1\u635f\u5931\u51fd\u6570\uff0c\u5373Smooth L1\uff1a $$ l(x,y)=L=\\{l_1,\\dots,l_N\\}^T $$  \u5176\u4e2d\uff0c $$ \\begin{aligned} l_n=\\left\\{ \\begin{matrix}  &amp; \\frac{1}{2\\beta}(x_n,y_n)^2, \\quad |x_n-y_n|&lt;\\beta\\\\   &amp;|x_n-y_n|-\\frac12\\beta\uff0c\\quad \\text{otherwise} \\end{matrix} \\right. \\end{aligned} $$ </p> <p>\u2003\u2003\u5982\u679c\u7edd\u5bf9\u503c\u8bef\u5dee\u4f4e\u4e8e\\beta\uff0c\u5219\u521b\u5efa\u4e00\u4e2a\u5e73\u65b9\u9879\u7684\u635f\u5931(L_2)\uff0c\u5426\u5219\u4f7f\u7528\u7edd\u5bf9\u503c\u635f\u5931(L_1)\uff0c\u6b64\u635f\u5931\u5bf9\u5f02\u5e38\u503c\u7684\u654f\u611f\u6027\u4f4e\u4e8eL_2\u635f\u5931\uff0c\u5373\u5f53x\u4e0ey\u76f8\u5dee\u8fc7\u5927\u65f6\uff0c\u8be5\u635f\u5931\u6570\u503c\u8981\u5c0f\u4e8eL_2\u635f\u5931\u6570\u503c\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u8be5\u635f\u5931\u53ef\u4ee5\u9632\u6b62\u68af\u5ea6\u7206\u70b8\uff0c\u635f\u5931\u56fe\u5982\u4e0b\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>size_average</code>\u4e0e<code>reduce</code>\u5df2\u7ecf\u88ab\u5f03\u7528\uff0c\u5177\u4f53\u529f\u80fd\u53ef\u7531<code>reduction</code>\u66ff\u4ee3</li> <li><code>reduction</code>\uff1a\u6307\u5b9a\u635f\u5931\u8f93\u51fa\u7684\u5f62\u5f0f\uff0c\u6709\u4e09\u79cd\u9009\u62e9\uff1a<code>none</code>|<code>mean</code>|<code>sum</code>\u3002<code>none</code>\uff1a\u635f\u5931\u4e0d\u505a\u4efb\u4f55\u5904\u7406\uff0c\u76f4\u63a5\u8f93\u51fa\u4e00\u4e2a\u6570\u7ec4\uff1b<code>mean</code>\uff1a\u5c06\u5f97\u5230\u7684\u635f\u5931\u6c42\u5e73\u5747\u503c\u518d\u8f93\u51fa\uff0c\u4f1a\u8f93\u51fa\u4e00\u4e2a\u6570\uff1b<code>sum</code>\uff1a\u5c06\u5f97\u5230\u7684\u635f\u5931\u6c42\u548c\u518d\u8f93\u51fa\uff0c\u4f1a\u8f93\u51fa\u4e00\u4e2a\u6570</li> <li><code>beta</code>\uff1a\u6307\u5b9a\u8be5\u635f\u5931\u5728L_1\u4e0eL_2\u4e4b\u95f4\u53d8\u5316\u7684\u9608\u503c\uff0c\u9ed8\u8ba41.0</li> </ul> <p>\u6ce8\u610f\uff1a</p> <ul> <li>Smooth L1\u635f\u5931\u4e0eL_1\u635f\u5931\u7c7b\u4f3c\uff0c\u4f46\u662f\u968f\u7740|x-y|&lt;\\beta\uff0c\u5373\u968f\u7740x\u4e0ey\u7684\u9760\u8fd1\uff0c\u635f\u5931\u5f62\u5f0f\u9010\u6e10\u5411L_2\u635f\u5931\u7684\u5f62\u5f0f\u9760\u8fd1</li> </ul>"},{"location":"PyTorch/nn/loss_functions/nn.SmoothL1Loss/#_1","title":"\u4ee3\u7801\u6848\u4f8b","text":"<p>\u4e00\u822c\u7528\u6cd5</p> <pre><code>import torch.nn as nn\nimport torch\n\n# reduction\u8bbe\u4e3anone\u4fbf\u4e8e\u9010\u5143\u7d20\u5bf9\u6bd4\u635f\u5931\u503c\nloss = nn.SmoothL1Loss(reduction='none')\nx = torch.randn(10)\ny = torch.randn(10)\nloss_value = loss(x, y)\nprint(x)\nprint(y)\nprint(loss_value)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># x\ntensor([ 0.7584,  1.0724,  0.8966, -1.0947, -1.8141, -1.8305, -1.5329, -0.3077,\n         0.6814, -0.2394])\n# y\ntensor([ 0.5081, -0.1718,  0.7817, -0.8019, -0.6405, -1.4802,  2.3039,  1.4522,\n         1.1861, -0.2443])\n# loss\ntensor([3.1319e-02, 7.4427e-01, 6.6015e-03, 4.2872e-02, 6.7358e-01, 6.1354e-02,\n        3.3368e+00, 1.2598e+00, 1.2736e-01, 1.1723e-05])\n</code></pre> <p>\u6ce8\uff1a\u753b\u56fe\u7a0b\u5e8f</p> <pre><code>import torch.nn as nn\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nloss = nn.SmoothL1Loss(reduction='none')\nx = torch.tensor([0]*100)\ny = torch.from_numpy(np.linspace(-3,3,100))\nloss_value = loss(x,y)\nplt.plot(y, loss_value)\nplt.savefig('SmoothL1Loss.jpg')\n</code></pre>"},{"location":"PyTorch/nn/loss_functions/nn.SmoothL1Loss/#_2","title":"\u5b98\u65b9\u6587\u6863","text":"<p>nn.SmoothL1Loss\uff1ahttps://pytorch.org/docs/stable/generated/torch.nn.SmoothL1Loss.html#torch.nn.SmoothL1Loss</p>"},{"location":"PyTorch/nn/loss_functions/nn.TripletMarginLoss/","title":"\u4e09\u5143\u7ec4\u635f\u5931","text":"<pre><code>torch.nn.TripletMarginLoss(margin=1.0, p=2.0, eps=1e-06, swap=False, size_average=None, reduce=None, reduction='mean')\n</code></pre> <p>\u529f\u80fd\uff1a\u521b\u5efa\u4e00\u4e2a\u4e09\u5143\u7ec4\u635f\u5931\u51fd\u6570(triplet loss)\uff0c\u7528\u4e8e\u8861\u91cf\u8f93\u5165\u6570\u636ex_1,x_2,x_3\u4e4b\u95f4\u7684\u76f8\u5bf9\u76f8\u4f3c\u6027\uff0c\u5176\u4e2d\u8f93\u5165\u6837\u672c\u53c8\u5206\u522b\u79f0\u4e3a\u4e2d\u7acb\u6837\u672c\u3001\u6b63\u6837\u672c\u4ee5\u53ca\u8d1f\u6837\u672c\uff0c\u5177\u4f53\u4ecb\u7ecd\u53ef\u89c1\u8bba\u6587\u300aLearning shallow convolutional feature descriptors with triplet losses\u300b</p> <p>\u635f\u5931\u51fd\u6570\uff1a $$ L(x_1,x_2,x_3)=\\max\\{d(x_1,x_2)-d(x_1,x_3)+\\text{margin},0\\} $$  \u5176\u4e2d\uff1a $$ d(x_i,y_i)=||x_i-y_i||_p $$  \u8be5\u51fd\u6570\u7684\u4f5c\u7528\u5c31\u662f\u62c9\u8fdbx_1\u4e0ex_2\u7684\u8ddd\u79bb\uff0c\u4f7f\u5b83\u4eec\u66f4\u52a0\u76f8\u4f3c\uff0c\u540c\u65f6\u63a8\u79bbx_1\u4e0ex_3\u7684\u8ddd\u79bb\uff0c\u5373\u4f7f\u5b83\u4eec\u66f4\u52a0\u4e0d\u540c\u3002</p> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>margin</code>\uff1a\u8fb9\u754c\u8ddd\u79bb\uff0c\u5177\u4f53\u542b\u4e49\u5982\u516c\u5f0f\u6240\u793a\uff0c\u5982\u679c\u8be5\u503c\u8d8a\u5927\uff0c\u5219\u8868\u660ex_1\u4e0ex_2\u671f\u671b\u8ddd\u79bb\u8d8a\u8fd1\uff0cx_1\u4e0ex_3\u671f\u671b\u8ddd\u79bb\u8d8a\u8fdc\u3002\u8f93\u5165\u6570\u636e\u7c7b\u578b\u4e3a\u6d6e\u70b9\u6570(float)\uff0c\u9ed8\u8ba41.0\uff1b</li> <li><code>p</code>\uff1a\u7528\u4e8e\u8ba1\u7b97\u4e24\u4e2a\u5411\u91cf\u8ddd\u79bb\u7684\u8303\u6570\uff0c\u5177\u4f53\u542b\u4e49\u5982\u516c\u5f0f\u6240\u793a\u3002\u8f93\u5165\u6570\u636e\u7c7b\u578b\u4e3a\u6574\u6570(int)\uff0c\u9ed8\u8ba42\uff0c\u5373\u6b27\u6c0f\u8ddd\u79bb\uff1b</li> <li><code>swap</code>\uff1a\u662f\u5426\u4f7f\u7528\u8ddd\u79bb\u4ea4\u6362\uff0c\u5177\u4f53\u529f\u80fd\u53ef\u89c1\u8bba\u6587\u300aLearning shallow convolutional feature descriptors with triplet losses\u300b\uff1b</li> <li><code>size_average</code>\u4e0e<code>reduce</code>\u5df2\u88ab\u5f03\u7528\uff0c\u5177\u4f53\u529f\u80fd\u7531<code>reduction</code>\u66ff\u4ee3\uff1b</li> <li><code>reduction</code>\uff1a\u6307\u5b9a\u635f\u5931\u8f93\u51fa\u7684\u5f62\u5f0f\uff0c\u6709\u4e09\u79cd\u9009\u62e9\uff1a<code>none</code>|<code>mean</code>|<code>sum</code>\u3002<code>none</code>\uff1a\u635f\u5931\u4e0d\u505a\u4efb\u4f55\u5904\u7406\uff0c\u76f4\u63a5\u8f93\u51fa\u4e00\u4e2a\u6570\u7ec4\uff1b<code>mean</code>\uff1a\u5c06\u5f97\u5230\u7684\u635f\u5931\u6c42\u5e73\u5747\u503c\u518d\u8f93\u51fa\uff0c\u4f1a\u8f93\u51fa\u4e00\u4e2a\u6570\uff1b<code>sum</code>\uff1a\u5c06\u5f97\u5230\u7684\u635f\u5931\u6c42\u548c\u518d\u8f93\u51fa\uff0c\u4f1a\u8f93\u51fa\u4e00\u4e2a\u6570\u3002</li> </ul> <p>\u6ce8\u610f\uff1a</p> <ul> <li>\u8f93\u5165\u7684\u4e09\u4e2a\u6837\u672c\u6570\u636e\u7ef4\u6570\u5fc5\u987b\u4e3a\u4e8c\u7ef4(N,D)\uff0c\u5176\u4e2d\u7b2c\u4e8c\u4e2a\u7ef4\u5ea6D\u8868\u793a\u5411\u91cf\u957f\u5ea6\uff1b</li> <li>\u5982\u679c<code>reduction</code>\u8bbe\u7f6e\u4e3a<code>none</code>\uff0c\u5219\u8f93\u51fa\u7684\u6570\u7ec4\u7ef4\u6570\u4e3a1\uff0c\u5c3a\u5bf8\u4e3a(N)</li> </ul>"},{"location":"PyTorch/nn/loss_functions/nn.TripletMarginLoss/#_2","title":"\u4ee3\u7801\u6848\u4f8b","text":"<p>\u4e00\u822c\u7528\u6cd5</p> <pre><code>import torch\nimport torch.nn as nn\n\n# reduction\u8bbe\u4e3anone\u4fbf\u4e8e\u67e5\u770b\u635f\u5931\u8ba1\u7b97\u7684\u7ed3\u679c\ntriplet_loss = nn.TripletMarginLoss(reduction='none')\nx1 = torch.randn(20).reshape(2,10)\nx2 = torch.randn(20).reshape(2,10)\nx3 = torch.randn(20).reshape(2,10)\nloss = triplet_loss(x1, x2, x3)\nprint(x1)\nprint(x2)\nprint(x3)\nprint(loss)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code>tensor([[-0.1419,  0.0550, -0.2996, -1.7194,  0.5485, -0.9163, -0.6983,  0.0239,\n          1.2940, -0.4858],\n        [ 1.8544, -0.2349, -0.2523, -1.6167,  0.7861, -1.7627,  0.3139, -1.5112,\n         -0.3378,  0.0059]])\ntensor([[-1.5967,  0.4007,  0.1468, -1.0085, -1.4989,  1.7531,  0.0865, -0.9080,\n         -0.4046,  0.5229],\n        [-1.8673, -0.4958,  1.0122, -1.8696,  0.1974, -0.8017, -1.0562, -2.1461,\n          1.7112, -0.6001]])\ntensor([[-1.0008,  1.5316,  0.0078,  1.1405, -0.0629,  0.4934, -1.8050, -1.0302,\n          0.8676, -0.1988],\n        [ 1.3015, -0.2786,  0.4215, -0.6413, -0.0760, -0.8138,  0.2173,  1.5132,\n         -0.6389,  0.7173]])\ntensor([1.4133, 2.2473])\n</code></pre>"},{"location":"PyTorch/nn/loss_functions/nn.TripletMarginLoss/#_3","title":"\u5b98\u65b9\u6587\u6863","text":"<p>nn.TripletMarginLoss\uff1ahttps://pytorch.org/docs/stable/generated/torch.nn.TripletMarginLoss.html?highlight=tripletmarginloss#torch.nn.TripletMarginLoss</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e743\u670830\u65e5</p>"},{"location":"PyTorch/optim/LambdaLR/","title":"Pytorch\u5b66\u4e60\u7b14\u8bb0\u2014\u2014\u81ea\u5b9a\u4e49\u5b66\u4e60\u7387\u53d8\u5316\u5668LambdaLR","text":"<pre><code>torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda, last_epoch=-1, verbose='deprecated')\n</code></pre> <p>\u529f\u80fd\uff1a</p> <p>\u2003\u2003\u5c06\u6bcf\u4e2a\u53c2\u6570\u7684\u5b66\u4e60\u7387\u8bbe\u7f6e\u4e3a\u521d\u59cb\u7684<code>lr</code>\u4e58\u4ee5\u4e00\u4e2a\u6743\u91cd\u7cfb\u6570<code>factor</code>\uff0c\u7528\u4e8e\u8c03\u6574\u5b66\u4e60\u7387\u5927\u5c0f\uff0c\u5176\u4e2d\u6743\u91cd\u7cfb\u6570<code>factor</code>\u7531\u51fd\u6570<code>lr_lambda</code>\u5f97\u5230\uff0c\u8fd9\u91cc\u53ef\u4ee5\u4e3a\u6bcf\u4e2a\u5c42\u8bbe\u7f6e\u4e0d\u540c\u7684\u5b66\u4e60\u7387\u8c03\u6574\u7b56\u7565\u3002</p> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>optimizer</code>\uff1a\u4f18\u5316\u5668\uff1b</li> <li><code>lr_lambda</code>\uff1a\u7ed9\u5b9aepoch\u6216\u8005\uff0c\u4f20\u5165\u51fd\u6570\u6216<code>list</code>\u5217\u8868\uff1b</li> <li><code>last_epoch</code>\uff1a\u5f53\u524d\u7684epoch\uff0c\u9ed8\u8ba4-1\uff1b</li> <li><code>verbose</code>\uff1a\u5982\u679c\u8bbe\u4e3a<code>True</code>\uff0c\u5219\u6bcf\u6b21\u5b66\u4e60\u7387\u66f4\u65b0\u90fd\u4f1a\u8f93\u51fa\u4e00\u6761\u6d88\u606f\uff08\u5373\u5c06\u5f03\u7528\uff0c\u67e5\u770b\u5b66\u4e60\u7387\u53ef\u901a\u8fc7\u8c03\u7528<code>get_last_lr()</code>\u5b9e\u73b0\uff09\uff1b</li> </ul> <p>\u5e38\u7528\u65b9\u6cd5\uff1a</p> <ul> <li> <p><code>get_last_lr()</code>\uff1a\u8fd4\u56de\u5f53\u524d\u7684\u5b66\u4e60\u7387</p> </li> <li> <p><code>state_dict()</code>\uff1a\u63d0\u53d6<code>__dict__</code>\u4e2d\u7684\u6570\u636e\uff08\u4e0d\u5305\u62ec<code>optimizer</code>\uff09\uff0c\u5982\u679c<code>lr_lambda</code>\u662f\u4e00\u4e2a\u53ef\u8c03\u7528\u7684\u5bf9\u8c61\u65f6\uff0c\u53ef\u4ee5\u88ab\u63d0\u53d6\uff0c\u5982\u679c\u662f\u51fd\u6570\u6216\u8005<code>lambda</code>\u65f6\uff0c\u5219\u4e0d\u4f1a\u88ab\u63d0\u53d6\uff0c\u4f1a\u5f97\u5230<code>None</code>\uff1b</p> </li> <li><code>load_state_dict(state_dict)</code>\uff1a\u52a0\u8f7d\u53c2\u6570\uff1b</li> </ul>"},{"location":"PyTorch/optim/LambdaLR/#_1","title":"\u4ee3\u7801\u6848\u4f8b","text":"<p>\u2003\u2003\u5bf9\u6a21\u578b\u4e2d\u6240\u6709\u53c2\u6570\u90fd\u4f7f\u7528\u76f8\u540c\u7684\u5b66\u4e60\u7387\u8c03\u6574\u7b56\u7565\uff0c\u5b66\u4e60\u7387\u6743\u91cd\u56e0\u5b50\u8ba1\u7b97\u65b9\u6cd5\u5982\u4e0b\uff1a $$ lr=\\alpha^{epoch} * base\\_lr $$ </p> <pre><code>from torch.optim.lr_scheduler import LambdaLR\nfrom torch.optim import SGD\nfrom torchvision import models\n\n\ndef lambda_lr(epoch, alpha=0.99):\n    return alpha ** epoch\n\n\nmodel = models.resnet50()\noptimizer = SGD(model.parameters(), lr=1e-3)\nour_scheduler = LambdaLR(optimizer, lambda_lr)\nlast_lr = our_scheduler.get_last_lr()\n\nfor i in range(100):\n    our_scheduler.step()\n    last_lr = our_scheduler.get_last_lr()\n    print(last_lr)\n</code></pre> <p>\u2003\u2003\u5bf9\u4e0d\u540c\u7684\u53c2\u6570\u5c42\u4f7f\u7528\u4e0d\u540c\u7684\u5b66\u4e60\u7387\u8c03\u6574\u7b56\u7565\uff0c\u8fd9\u91cc\u5bf9resnet50\u7684\u7279\u5f81\u63d0\u53d6\u5c42\u548c\u5168\u8fde\u63a5\u5c42\u4f7f\u7528\u4e0d\u540c\u7684\u5b66\u4e60\u7387\u4e0b\u964d\u7b56\u7565\uff0c\u5176\u4e2d\u7279\u5f81\u63d0\u53d6\u5c42\u4e0b\u964d\u901f\u5ea6\u8981\u5feb\u4e8e\u5168\u8fde\u63a5\u5c42\u3002</p> <p>\u2003\u2003\u9996\u5148\u5728\u5b9a\u4e49\u4f18\u5316\u5668\u65f6\uff0c\u9700\u8981\u5c06\u4e24\u7ec4\u53c2\u6570\u4ee5\u4e0d\u540c\u7684\u952e\u503c\u5bf9\u4f20\u5165\u4f18\u5316\u5668\u4e2d\uff0c\u5728\u5b9a\u4e49<code>lr_lambda</code>\u65f6\u9700\u8981\u4f20\u5165\u4e24\u79cd\u53d8\u5316\u7b56\u7565\uff08\u4ee5\u5217\u8868\u683c\u5f0f\u4f20\u5165\uff09\uff0c\u6ce8\u610f\u987a\u5e8f\u662f\u4e00\u4e00\u5bf9\u5e94\u7684\u3002</p> <pre><code>from torch.optim.lr_scheduler import LambdaLR\nfrom torch.optim import SGD\nfrom torchvision import models\n\n\ndef fc_lambda_lr(epoch, alpha=0.99):\n    return alpha ** epoch\n\n\ndef feature_lambda_lr(epoch, alpha=0.88):\n    return alpha ** epoch\n\n\nmodel = models.resnet50()\nfeature_params = []\nfc_params = []\nfor name, param in model.named_parameters():\n    if 'fc' in name:\n        fc_params.append(param)\n    else:\n        feature_params.append(param)\n\noptimizer = SGD([\n    {'params': feature_params},\n    {'params': fc_params}\n], lr=1e-3)\n\nour_scheduler = LambdaLR(optimizer, lr_lambda=[feature_lambda_lr, fc_lambda_lr])\nlast_lr = our_scheduler.get_last_lr()\n\nfor i in range(100):\n    our_scheduler.step()\n    last_lr = our_scheduler.get_last_lr()\n    print(last_lr)\n</code></pre>"},{"location":"PyTorch/optim/LambdaLR/#_2","title":"\u5b98\u65b9\u6587\u6863","text":"<p>LambdaLR\uff1ahttps://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.LambdaLR.html#lambdalr</p>"},{"location":"PyTorch/other_method/cuda/","title":"PyTorch\u5b66\u4e60\u7b14\u8bb0\uff1acuda\u65b9\u6cd5\u2014\u2014\u83b7\u5f97\u663e\u5361\u4fe1\u606f","text":""},{"location":"PyTorch/other_method/cuda/#cuda","title":"cuda\u5e38\u7528\u65b9\u6cd5","text":"<ul> <li>\u67e5\u770bcuda\u662f\u5426\u53ef\u7528</li> </ul> <pre><code>torch.cuda.is_available()\n</code></pre> <ul> <li>\u67e5\u770b\u5f53\u524d\u8bbe\u5907cuda\u6570\u91cf</li> </ul> <pre><code>torch.cuda.device_count()\n</code></pre> <ul> <li>\u67e5\u770b\u5f53\u524d\u8bbe\u5907\u7b2ci\u4e2acuda\u540d\u79f0</li> </ul> <pre><code>torch.cuda.get_device_name(i)\n</code></pre> <ul> <li>\u8bbe\u7f6e\u9ed8\u8ba4\u4f7f\u7528\u7b2ci\u5757GPU</li> </ul> <pre><code># \u91cc\u9762\u8f93\u5165int\u7c7b\u578b\u7684\u6570\u5b57\ntorch.cuda.set_device(i)\n</code></pre> <ul> <li>\u8fd4\u56de\u5f53\u524d\u9ed8\u8ba4\u7684GPU\u8bbe\u5907\u7d22\u5f15</li> </ul> <pre><code>torch.cuda.current_device()\n</code></pre> <p>\u8865\u5145\uff1a</p> <ul> <li>\u67e5\u770b\u7cfb\u7edfCPU\u6570\u91cf</li> </ul> <pre><code>torch.cuda.os.cpu_count()\n</code></pre>"},{"location":"PyTorch/other_method/cuda/#get_device_properties","title":"get_device_properties\u51fd\u6570","text":"<p>\u2003\u2003\u7528\u4e8e\u83b7\u53d6\u6307\u5b9aGPU\u8bbe\u5907\u7684\u5404\u79cd\u5c5e\u6027\u4fe1\u606f\uff0c\u5305\u62ec\uff1a</p> <ul> <li><code>name</code>\uff1aGPU \u8bbe\u5907\u7684\u540d\u79f0\uff1b</li> <li><code>total_memory</code>\uff1a\u63d0\u53d6GPU\u603b\u663e\u5b58\u5927\u5c0f\uff0c\u4ee5\u5b57\u8282\u4e3a\u5355\u4f4d\uff1b</li> <li><code>major</code>\uff1aCUDA\u8ba1\u7b97\u80fd\u529b\u7684\u4e3b\u8981\u7248\u672c\u53f7\uff1b</li> <li><code>minor</code>\uff1aCUDA\u8ba1\u7b97\u80fd\u529b\u7684\u6b21\u8981\u7248\u672c\u53f7\uff1b</li> <li><code>multi_processor_count</code>\uff1aGPU\u8bbe\u5907\u7684\u591a\u5904\u7406\u5668\u6570\u91cf\uff1b</li> <li><code>is_integrated</code>\uff1aGPU\u662f\u5426\u662f\u96c6\u6210\u663e\u5361\uff0c\u5982\u679c\u8fd4\u56deTrue\uff08\u6216\u80051\uff09\uff0c\u5219\u8bf4\u660e\u8be5\u663e\u5361\u662f\u96c6\u6210\u663e\u5361\uff0c\u5426\u5219\u662f\u72ec\u7acb\u663e\u5361\uff1b</li> <li><code>is_multi_gpu_board</code>\uff1a\u8868\u793aGPU\u662f\u5426\u662f\u591aGPU\u677f\u5361\uff0c\u5982\u679c\u8fd4\u56deTrue\uff08\u6216\u80051\uff09\uff0c\u5219\u8bf4\u660e\u8be5\u663e\u5361\u662f\u4e00\u4e2a\u5177\u6709\u591aGPU\u82af\u7247\u7684\u663e\u5361\uff1b</li> </ul> <p>\u4ee3\u7801\u6848\u4f8b</p> <pre><code>import torch\n\ndevice_id = 0  # GPU \u8bbe\u5907\u7684 ID\nproperties = torch.cuda.get_device_properties(device_id)\n\nprint(\"Name: \", properties.name)\nprint(\"Total memory: \", properties.total_memory / (1024**2), \"MB\")  # \u8f6c\u6362\u4e3a MB \u5355\u4f4d\nprint(\"CUDA capability: \", properties.major, \".\", properties.minor)\nprint(\"Multiprocessor count: \", properties.multi_processor_count)\n</code></pre> <p>\u8f93\u51fa\uff08\u4ee5\u672c\u673a\u6267\u884c\u7ed3\u679c\u4e3a\u4f8b\uff09</p> <pre><code>Name:  NVIDIA GeForce RTX 3050\nTotal memory:  8191.5 MB\nCUDA capability:  8 . 6\nMultiprocessor count:  20\n</code></pre>"},{"location":"PyTorch/other_method/hook/","title":"Pytorch\uff1ahook\u6a21\u5757","text":""},{"location":"PyTorch/other_method/hook/#_1","title":"\u4ecb\u7ecd","text":"<p>\u529f\u80fd\uff1a\u4e3b\u8981\u7528\u4e8e\u63d0\u53d6\u4e2d\u95f4\u53d8\u91cf\uff0c\u540c\u65f6\u4e5f\u53ef\u4ee5\u505a\u4fee\u6539\u7b49\u64cd\u4f5c\u3002</p> <p>\u5e38\u7528\u7684\u76f8\u5173\u51fd\u6570\u65b9\u6cd5</p> <pre><code># \u63d0\u53d6\u6570\u636e\u7684\u68af\u5ea6\ntorch.Tensor.register_hook(hook)\n# \u63d0\u53d6\u6a21\u578b\u7684\u4e2d\u95f4\u7279\u5f81\u6570\u636e\ntorch.nn.Module.register_forward_hook(hook)\n# \u63d0\u53d6\u7f51\u7edc\u5c42\u4e2d\u7684\u68af\u5ea6\ntorch.nn.Module.register_full_backward_hook(hook)\n</code></pre> <p>\u2003\u2003PyTorch\u5728\u6bcf\u4e00\u6b21\u8fd0\u7b97\u7ed3\u675f\u540e\u90fd\u4f1a\u91ca\u653e\u4e2d\u95f4\u53d8\u91cf\uff0c\u4ece\u800c\u8282\u7701\u5185\u5b58\u7a7a\u95f4\uff0c\u4f8b\u5982\u91ca\u653e\u6a21\u578b\u4e2d\u95f4\u5f97\u5230\u7684\u7279\u5f81\u6570\u636e\u3001\u53cd\u5411\u4f20\u64ad\u8fc7\u7a0b\u4e2d\u7684\u68af\u5ea6\u7b49\u7b49\uff0c\u56e0\u6b64\u5c31\u6709\u4e86hook\u65b9\u6cd5\uff0c\u53ef\u4ee5\u64cd\u4f5c\u4e2d\u95f4\u53d8\u91cf\uff0c\u5982\u4fdd\u5b58\u68af\u5ea6\u3001\u4fdd\u5b58\u4e2d\u95f4\u7279\u5f81\u6570\u636e\uff0c\u4e5f\u53ef\u4ee5\u5bf9\u4e2d\u95f4\u53d8\u91cf\u505a\u4fee\u6539\uff0c\u5982\u589e\u5927\u68af\u5ea6\u3001\u9650\u5236\u68af\u5ea6\u8303\u56f4\u7b49\u7b49\uff0c\u6838\u5fc3\u5728\u4e8e<code>hook</code>\u51fd\u6570\u7684\u5b9a\u4e49\u3002</p> <p>\u5b9a\u4e49hook\uff1a</p> <pre><code># register_hook\nhook(grad) -&gt; Tensor or None\n# register_forward_hook\nhook(module, input, output) -&gt; None or modified output\n# register_full_backward_hook\n# \u4e00\u822c\u53ea\u5229\u7528grad_output\uff0c\u63d0\u53d6\u6a21\u5757\u8f93\u51fa\u5143\u7d20\u7684\u68af\u5ea6\nhook(module, grad_input, grad_output) -&gt; tuple(Tensor) or None\n</code></pre>"},{"location":"PyTorch/other_method/hook/#_2","title":"\u6570\u636e\u68af\u5ea6","text":"<p>\u2003\u2003\u5229\u7528<code>torch.Tensor.register_hook(hook)</code>\u65b9\u6cd5\u5b9e\u73b0\uff0c\u8ba1\u7b97\u6570\u636e\u5728\u505a\u53cd\u5411\u4f20\u64ad\u65f6\u7684\u68af\u5ea6</p>"},{"location":"PyTorch/other_method/hook/#_3","title":"\u4ee3\u7801\u6848\u4f8b","text":"<p>\u4ee5\u4e0b\u9762\u7684\u516c\u5f0f\u4e3a\u4f8b\uff1a $$ z=\\frac14\\sum_{i=1}^4y_i,\\quad y_i=x_i^2 $$ </p> <pre><code>import torch\n\n\ndef grad_hook_x(grad):\n    # \u53ea\u4f20\u5165\u68af\u5ea6\u8fd9\u4e00\u4e2a\u53d8\u91cf\n    x_grad.append(grad)\n\n\ndef grad_hook_y(grad):\n    y_grad.append(grad)\n\n\ntorch.manual_seed(0)\ny_grad = []\nx_grad = []\nx = torch.rand(4, requires_grad=True)\ny = torch.pow(x, 2)\nz = torch.mean(y)\ny.register_hook(grad_hook_y)\nx.register_hook(grad_hook_x)\nz.backward()\nprint(x)\nprint(\"x grad: \", x_grad[0])\nprint(\"y grad: \", y_grad[0])\n</code></pre> <p>\u8f93\u51fa\uff0c\u76f8\u5f53\u4e8e\u5bf9x\u548cy\u4e0a\u7684\u68af\u5ea6\u505a\u4e86\u4fdd\u5b58</p> <pre><code># \u8f93\u5165x\ntensor([0.4963, 0.7682, 0.0885, 0.1320], requires_grad=True)\n# x\u4e0a\u7684\u68af\u5ea6\nx grad:  tensor([0.2481, 0.3841, 0.0442, 0.0660])\n# y\u4e0a\u7684\u68af\u5ea6\ny grad:  tensor([0.2500, 0.2500, 0.2500, 0.2500])\n</code></pre> <p>\u6ce8\uff1a\u5c06<code>z.backward()</code>\u6539\u4e3a<code>z.backward(retain_graph=True)</code>\u4e5f\u53ef\u4ee5\u5b9e\u73b0\u50a8\u5b58\u68af\u5ea6\u7684\u529f\u80fd</p>"},{"location":"PyTorch/other_method/hook/#_4","title":"\u4fee\u6539\u68af\u5ea6","text":"<p>\u2003\u2003\u5982\u679c\u60f3\u8981\u4fee\u6539\u68af\u5ea6\uff0c\u5219\u53ea\u9700\u8981\u4fee\u6539hook\u51fd\u6570\uff0c\u5982\u4e0b\u9762\u6848\u4f8b\uff0c\u6b64\u65f6y\u4e0a\u7684\u68af\u5ea6\u662f\u539f\u6765\u7684\u4e24\u500d\uff0c\u5c06\u4f1a\u5f71\u54cdx\u7684\u53c2\u6570\u66f4\u65b0\uff08\u66f4\u65b0\u5e45\u5ea6\u53d8\u5927\uff09</p> <pre><code>def grad_hook_y(grad):\n    return grad * 2\n</code></pre>"},{"location":"PyTorch/other_method/hook/#_5","title":"\u7f51\u7edc\u4e2d\u95f4\u7279\u5f81","text":"<p>\u2003\u2003\u5229\u7528<code>torch.nn.Module.register_forward_hook(hook)</code>\u65b9\u6cd5\u5b9e\u73b0\uff0c\u5b9e\u73b0\u63d0\u53d6\u7279\u5f81\u6570\u636e\u7684\u529f\u80fd\u3002</p> <p>\u6ce8\uff1a\u5c3d\u91cf\u4e0d\u8981\u5728\u8fd9\u91cc\u4fee\u6539\u7279\u5f81\u6570\u636e\uff0c\u5bb9\u6613\u51fa\u95ee\u9898\uff0c\u6700\u597d\u76f4\u63a5\u53bb\u7f51\u7edc\u7ed3\u6784\u91cc\u9762\u6539\u3002</p>"},{"location":"PyTorch/other_method/hook/#_6","title":"\u4ee3\u7801\u6848\u4f8b","text":""},{"location":"PyTorch/other_method/hook/#_7","title":"\u7f51\u7edc\u7ed3\u6784","text":"<pre><code>import torch\nfrom torch import nn\n\n\nclass Net(nn.Module):\n    def __init__(self, input_size, out_size, middle_size=None):\n        super().__init__()\n        if not middle_size:\n            middle_size = input_size // 2\n        self.conv1 = nn.Conv2d(input_size, middle_size, 3)\n        self.conv2 = nn.Conv2d(middle_size, middle_size, 3)\n        self.pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(middle_size, out_size)\n        self.middle_size = middle_size\n\n    def forward(self, x):\n        x1 = self.conv1(x)\n        x2 = self.conv2(x1)\n        x3 = self.pool(x2).view(-1, self.middle_size)\n        x4 = self.fc(x3)\n        return x4\n</code></pre>"},{"location":"PyTorch/other_method/hook/#_8","title":"\u8c03\u7528\u65b9\u6cd5","text":"<pre><code>def forward_hook(module, inputs, outputs):\n    # \u4f20\u5165\u6a21\u5757\u3001\u6a21\u5757\u8f93\u5165\u3001\u6a21\u5757\u8f93\u51fa\u4e09\u79cd\u53c2\u6570\n    feature_map_inputs.append(inputs)\n    feature_map_outputs.append(outputs)\n\n\ntorch.manual_seed(0)\nfeature_map_inputs = []\nfeature_map_outputs = []\n\nnet = Net(4, 2, 3)\nnet.conv1.register_forward_hook(forward_hook)\ndata = torch.rand((1, 4, 6, 6), dtype=torch.float32)\n\nout = net(data)\nout1 = out[:, 0]\nnet.zero_grad()\nout1.backward(retain_graph=True)\n</code></pre> <p>\u8f93\u51fa</p> <p> <p></p> <p></p>"},{"location":"PyTorch/other_method/hook/#_9","title":"\u7f51\u7edc\u68af\u5ea6","text":"<p>\u2003\u2003\u5229\u7528<code>torch.nn.Module.register_full_backward_hook(hook)</code>\u65b9\u6cd5\u5b9e\u73b0\uff0c\u5b9e\u73b0\u63d0\u53d6\u7279\u5f81\u6570\u636e\u7684\u68af\u5ea6\u529f\u80fd\u3001\u4e5f\u53ef\u4ee5\u4fee\u6539\u68af\u5ea6\u3002</p> <p>\u6ce8\uff1a</p> <ul> <li>\u5728\u63d0\u53d6\u68af\u5ea6\u65f6\uff0c\u6700\u597d\u52a0\u4e00\u4e2a<code>.detach()</code>\u65b9\u6cd5\uff0c\u5207\u65ad\u68af\u5ea6\uff0c\u9632\u6b62\u540e\u7eed\u64cd\u4f5c\u5bf9\u7f51\u7edc\u53cd\u5411\u4f20\u64ad\u6709\u5f71\u54cd\uff1b</li> <li>\u6a21\u5757\u5b58\u5728\u591a\u4e2a\u8f93\u5165\u8f93\u51fa\u65f6\uff0c<code>backward_hook()</code>\u4e2d\u7684<code>inputs</code> \u548c<code>outputs</code>\u5747\u4e3a\u5143\u7ec4\u7c7b\u578b\u3002</li> </ul>"},{"location":"PyTorch/other_method/hook/#_10","title":"\u4ee3\u7801\u6848\u4f8b","text":""},{"location":"PyTorch/other_method/hook/#_11","title":"\u5377\u79ef\u6a21\u5757","text":"<p>\u7f51\u7edc\u7ed3\u6784\u8fd8\u662f\u4e4b\u524d\u5b9a\u4e49\u7684\u7ed3\u6784</p> <pre><code>import torch\nfrom torch import nn\n\n\ndef backward_hook(module, inputs, outputs):\n    # \u5143\u7ec4\u7c7b\u578b\uff0c\u5e38\u5229\u7528[0]\u63d0\u53d6\u68af\u5ea6\u6570\u636e\n    grad_inputs.append(inputs[0].detach())\n    grad_outputs.append(outputs[0].detach())\n\n\ntorch.manual_seed(0)\ngrad_inputs = []\ngrad_outputs = []\n\nnet = Net(4, 2, 3)\nnet.conv2.register_backward_hook(backward_hook)\ndata = torch.rand((1, 4, 6, 6), dtype=torch.float32)\n\nout = net(data)\nout1 = out[:, 0]\nnet.zero_grad()\n# retain_graph\u8bbe\u4e3aTrue\u8868\u660e\u5728\u53cd\u5411\u4f20\u64ad\u65f6\u4fdd\u5b58\u68af\u5ea6\nout1.backward(retain_graph=True)\n</code></pre> <p>\u8f93\u51fa</p> <p> <p></p> <p></p> <p>\u6ce8\uff1a</p> <ul> <li>grad_inputs\u8868\u793a\u6a21\u5757\u8f93\u5165\u53c2\u6570\u7684\u68af\u5ea6\uff0c\u68af\u5ea6\u5c3a\u5bf8\u548c\u8f93\u5165\u7279\u5f81\u56fe\u7684\u5c3a\u5bf8\u76f8\u540c\uff1b</li> <li>grad_outputs\u8868\u793a\u6a21\u5757\u8f93\u51fa\u53c2\u6570\u7684\u68af\u5ea6\uff0c\u540c\u4e0a\uff0c\u68af\u5ea6\u5c3a\u5bf8\u548c\u8f93\u51fa\u7279\u5f81\u56fe\u7684\u5c3a\u5bf8\u76f8\u540c\u3002</li> </ul>"},{"location":"PyTorch/other_method/hook/#_12","title":"\u5168\u8fde\u63a5\u6a21\u5757","text":"<pre><code>import torch\nfrom torch import nn\n\n\nclass Net(nn.Module):\n    def __init__(self, input_size, out_size, middle_size=None):\n        super().__init__()\n        if not middle_size:\n            middle_size = input_size // 2\n        self.fc1 = nn.Linear(input_size, middle_size)\n        self.fc2 = nn.Linear(middle_size, out_size)\n\n    def forward(self, x):\n        x1 = self.fc1(x)\n        x2 = self.fc2(x1)\n\n        return x2\n\n\ndef backward_hook(module, inputs, outputs):\n    grad_inputs.append(inputs[0].detach())\n    grad_outputs.append(outputs[0].detach())\n\n\ntorch.manual_seed(0)\ngrad_inputs = []\ngrad_outputs = []\nnet = Net(6, 2, 3)\nnet.fc2.register_backward_hook(backward_hook)\ndata = torch.rand((1, 6), dtype=torch.float32)\n\nout = net(data)\nout1 = out[:, 0]\nnet.zero_grad()\n# retain_graph\u8bbe\u4e3aTrue\uff0c\u76ee\u7684\u4fdd\u7559\u68af\u5ea6\nout1.backward(retain_graph=True)\nprint(grad_inputs, grad_outputs)\n</code></pre> <p>\u8f93\u51fa</p> <p> <p></p> <p></p> <p>\u6ce8\uff1a</p> <ul> <li>grad_inputs\u8868\u793a\u6a21\u5757\u8f93\u5165\u53c2\u6570\u7684\u68af\u5ea6\uff0c\u68af\u5ea6\u5c3a\u5bf8\u548c\u8f93\u5165\u7279\u5f81\u7684\u5c3a\u5bf8\u76f8\u540c\uff1b</li> <li>grad_outputs\u8868\u793a\u6a21\u5757\u8f93\u51fa\u53c2\u6570\u7684\u68af\u5ea6\uff0c\u68af\u5ea6\u5c3a\u5bf8\u548c\u8f93\u51fa\u7279\u5f81\u7684\u5c3a\u5bf8\u76f8\u540c\u3002</li> </ul>"},{"location":"PyTorch/other_method/hook/#_13","title":"\u5b98\u65b9\u6587\u6863","text":"<p>register_hook\uff1ahttps://pytorch.org/docs/1.2.0/tensors.html#torch.Tensor.register_hook</p> <p>register_forward_hook\uff1ahttps://pytorch.org/docs/1.2.0/nn.html#torch.nn.Module.register_forward_hook</p> <p>register_full_backward_hook\uff1ahttps://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=register_full_backward_hook#torch.nn.Module.register_full_backward_hook</p> <p>\u6ce8\uff1a\u4ee5\u4e0a\u5185\u5bb9\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u6307\u6b63</p> <p>\u521d\u6b65\u5b8c\u7a3f\u4e8e\uff1a2023\u5e742\u67083\u65e5</p>"},{"location":"PyTorch/other_method/train_eval/","title":"model.train()\u4e0emodel.eval()","text":"<p>\u529f\u80fd\uff1a\u7528\u4e8e\u5207\u6362\u6a21\u578b\u7684\u6a21\u5f0f\uff0c<code>model.train()</code>\u5c06\u6a21\u578b\u5207\u6362\u4e3a\u8bad\u7ec3\u6a21\u5f0f\uff0c<code>model.eval()</code>\u5c06\u6a21\u578b\u5207\u6362\u4e3a\u6d4b\u8bd5\u6a21\u5f0f\u3002</p>"},{"location":"PyTorch/other_method/train_eval/#_1","title":"\u4e3b\u8981\u533a\u522b","text":""},{"location":"PyTorch/other_method/train_eval/#bndropout","title":"BN\u4e0eDropOut\u8fd0\u7b97\u89c4\u5219\u4e0d\u540c","text":""},{"location":"PyTorch/other_method/train_eval/#bn","title":"BN\u5c42","text":"<p>\u2003\u2003\u5b9a\u4e49\uff1a\u5bf9\u4e8e\u6240\u6709\u7684batch\u4e2d\u7684\u540c\u4e00\u4e2achannel\u7684\u6570\u636e\u5143\u7d20\u8fdb\u884c\u6807\u51c6\u5316\u5904\u7406\uff0c\u5373\u5982\u679c\u6709C\u4e2a\u901a\u9053\uff0c\u65e0\u8bba\u6709\u591a\u5c11\u4e2abatch\uff0c\u90fd\u4f1a\u5728\u901a\u9053\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u6807\u51c6\u5316\u5904\u7406\uff0c\u4e00\u5171\u8fdb\u884cC\u6b21\uff0c\u8bad\u7ec3\u9636\u6bb5\u4e0e\u6d4b\u8bd5\u9636\u6bb5\u5747\u503c\u65b9\u5dee\u7684\u8ba1\u7b97\u4e0d\u540c\u3002</p> <p> \u8bad\u7ec3\u9636\u6bb5\uff1a\u5c06\u540c\u4e00\u4e0bbatch\u901a\u9053\u76f8\u540c\u7684\u503c\u53d6\u51fa\u6765\uff0c\u4e00\u5757\u8ba1\u7b97\u5747\u503c\u548c\u65b9\u5dee\uff0c\u5373\u8ba1\u7b97\u5f53\u524d\u89c2\u6d4b\u503c\u7684\u5747\u503c\u548c\u65b9\u5dee\uff0c\u5e76\u4e14\u5229\u7528\u5f53\u524d\u6570\u636e\u7684\u5747\u503c\u65b9\u5dee\u66f4\u65b0\u5168\u5c40\u7684\u5747\u503c\u65b9\u5dee\u3002</p> <p> \u6d4b\u8bd5\u9636\u6bb5\uff1a\u5229\u7528\u6a21\u578b\u5b58\u50a8\u7684\u5168\u5c40\u5747\u503c\u65b9\u5dee\u505a\u6807\u51c6\u5316\u8fd0\u7b97\uff0c\u5e76\u4e14\u4e0d\u6539\u53d8\u5168\u5c40\u5747\u503c\u65b9\u5dee\u7684\u6570\u503c\u3002</p> <p>\u6ce8\uff1a</p> <ul> <li>\u53ea\u8981\u6709\u6570\u636e\u4f20\u5165BN\u5c42\uff0c\u5373\u505a\u4e86\u524d\u5411\u4f20\u64ad\uff0c\u5219BN\u5c42\u4e2d\u5b58\u50a8\u7684\u5168\u5c40\u5747\u503c\u548c\u65b9\u5dee\u5c31\u4f1a\u505a\u76f8\u5e94\u7684\u66f4\u65b0\uff0c\u65e0\u9700\u505a\u53cd\u5411\u4f20\u64ad\uff1b</li> <li>\u5177\u4f53\u7ec6\u8282\u53ef\u89c1\u300ann.BatchNorm2d\u5b66\u4e60\u7b14\u8bb0\u300b\u3002</li> </ul>"},{"location":"PyTorch/other_method/train_eval/#dropout","title":"DropOut\u5c42","text":"<p>\u2003\u2003\u5b9a\u4e49\uff1a\u5728\u8bad\u7ec3\u9636\u6bb5\u6309\u67d0\u79cd\u6982\u7387\u968f\u5373\u5c06\u8f93\u5165\u7684\u5f20\u91cf\u5143\u7d20\u968f\u673a\u5f52\u96f6\uff0c\u5e38\u7528\u7684\u6b63\u5219\u5316\u5668\uff0c\u7528\u4e8e\u9632\u6b62\u7f51\u7edc\u8fc7\u62df\u5408\u3002</p> <p> \u8bad\u7ec3\u9636\u6bb5\uff1a\u6570\u636e\u9996\u5148\u88ab\u653e\u5927\\frac1{1-p}\u500d\uff0c\u4e4b\u540e\u518d\u4ee5\u6982\u7387p\u6267\u884c\u5f52\u96f6\u64cd\u4f5c\u3002</p> <p> \u6d4b\u8bd5\u9636\u6bb5\uff1a\u4e0d\u5bf9\u6570\u636e\u505a\u53d8\u5316\u3002</p> <p>\u6ce8\uff1a</p> <ul> <li>\u5177\u4f53\u7ec6\u8282\u53ef\u89c1\uff1a\u300ann.Dropout\u5b66\u4e60\u7b14\u8bb0\u300b\u3002</li> </ul>"},{"location":"PyTorch/other_method/train_eval/#_2","title":"\u8865\u5145","text":"<p>\u2003\u2003\u6d4b\u8bd5\u6a21\u5f0f\u4e0b\u4e5f\u53ef\u4ee5\u6c42\u89e3\u53c2\u6570\u68af\u5ea6\uff0c\u56e0\u6b64\u4e5f\u4f1a\u5360\u7528\u4e00\u5b9a\u7684\u663e\u5b58\u7a7a\u95f4\uff0c\u5982\u679c\u60f3\u8981\u4e22\u5f03\u68af\u5ea6\u7684\u8fd0\u7b97\uff0c\u8282\u7701GPU\u7b97\u529b\u548c\u663e\u5b58\uff0c\u5219\u53ef\u4ee5\u5f15\u5165<code>with torch.no_grad():</code>\u65b9\u6cd5\uff0c\u5982\u4e0b\u9762\uff1a</p> <pre><code>def test(model,dataloader):\n    model.eval()  # \u5207\u6362\u5230\u6d4b\u8bd5\u6a21\u5f0f\n    with torch.no_grad():  #with\u4e0b\u5185\u5bb9\u4e0d\u8fdb\u884cgrad\u8ba1\u7b97\n        ...\n</code></pre>"},{"location":"PyTorch/other_method/train_eval/#_3","title":"\u5b98\u65b9\u6587\u6863","text":"<p>model.train()\uff1ahttps://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=train#torch.nn.Module.train</p> <p>model.eval()\uff1ahttps://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=eval#torch.nn.Module.eval</p> <p>torch.no_grad\uff1ahttps://pytorch.org/docs/stable/generated/torch.no_grad.html?highlight=torch+no_grad#torch.no_grad</p> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u6307\u6b63</p> <p>\u521d\u6b65\u5b8c\u7a3f\u4e8e\uff1a2023\u5e742\u67084\u65e5</p>"},{"location":"PyTorch/torch/torch.cat_torch.stack/","title":"\u6570\u7ec4\u7684\u62fc\u63a5","text":""},{"location":"PyTorch/torch/torch.cat_torch.stack/#torchcat","title":"torch.cat()","text":"<pre><code>torch.cat(tensors, dim=0, *, out=None) \u2192 Tensor\n</code></pre> <p>\u5b98\u65b9\u89e3\u91ca\uff1a\u5229\u7528\u7ed9\u5b9a\u7684\u7ef4\u5ea6\u8fde\u63a5\u7ed9\u5b9a\u7684\u6570\u7ec4\u5e8f\u5217(cat\u4ee3\u8868concatenate)\uff0c\u6240\u6709\u6570\u7ec4\u5fc5\u987b\u5177\u6709\u76f8\u540c\u7684\u5f62\u72b6\uff08\u8fde\u63a5\u7ef4\u5ea6\u9664\u5916\uff09\u6216\u4e3a\u7a7a\u3002 \u76f8\u5f53\u4e8e\u6309\u6307\u5b9a\u7ef4\u5ea6\u5c06\u6570\u7ec4\u8fdb\u884c\u62fc\u63a5</p> <p>\u53c2\u6570\u89e3\u91ca\uff1a</p> <ul> <li><code>tensors</code>\uff1a\u8981\u8fde\u63a5\u7684\u6570\u7ec4\u5e8f\u5217(\u5143\u7ec4<code>tuple</code>\u6216\u8005\u5217\u8868<code>list</code>)</li> <li><code>dim</code>\uff1a\u6570\u7ec4\u8fde\u63a5\u7684\u7ef4\u5ea6</li> <li><code>out</code>\uff1a\u8f93\u51fa\u6570\u7ec4(\u4e00\u822c\u7528\u4e0d\u5230\uff0c\u5982\u679c\u6709\u8f93\u51fa\uff0c\u5219\u53ef\u4ee5\u76f4\u63a5\u8fdb\u884c\u8d4b\u503c\u64cd\u4f5c)</li> </ul> <p>\u6ce8\u610f\uff1a \u2460<code>tensors</code>\u8f93\u5165\u7684\u5fc5\u987b\u662f\u6570\u7ec4\u5e8f\u5217\uff0c\u4e0d\u80fd\u662f\u5355\u4e2a\u6570\u7ec4\uff1b \u2461\u8f93\u5165\u7684\u6570\u7ec4\u5e8f\u5217\u9664\u4e86<code>dim</code>\u7ef4\u5ea6\uff0c\u5176\u4ed6\u7ef4\u5ea6\u5fc5\u987b\u5f62\u72b6\u76f8\u540c\u3002</p> <p>\u4e3e\u4f8b\uff1a</p> <pre><code>import torch\na=torch.arange(6).reshape(2,3)\nb=torch.arange(12)\nc=torch.cat((a,b.reshape(4,3)),dim=0)\n# \u6cbf\u7b2c0\u7ef4\u5ea6\u8fdb\u884c\u62fc\u63a5\uff0c\u4e5f\u5c31\u662f\u6309\u884c\u62fc\u63a5(\u7ad6\u7740\u62fc)\nd=torch.cat((a,b.reshape(2,6)),dim=1)\n# \u6cbf\u7b2c1\u7ef4\u5ea6\u8fdb\u884c\u62fc\u63a5\uff0c\u4e5f\u5c31\u662f\u6309\u5217\u62fc\u63a5(\u6a2a\u7740\u62fc)\nprint(c)\nprint(c.shape)\nprint(d)\nprint(d.shape)\n</code></pre> <p>\u8f93\u51fa\uff1a</p> <pre><code>tensor([[ 0,  1,  2],\n        [ 3,  4,  5],\n        [ 0,  1,  2],\n        [ 3,  4,  5],\n        [ 6,  7,  8],\n        [ 9, 10, 11]])\ntorch.Size([6, 3])\ntensor([[ 0,  1,  2,  0,  1,  2,  3,  4,  5],\n        [ 3,  4,  5,  6,  7,  8,  9, 10, 11]])\ntorch.Size([2, 9])\n</code></pre> <p>\u5229\u7528<code>torch.cat()</code>\u6cbf<code>dim</code>\u62fc\u63a5\uff0c\u5728\u5f62\u72b6\u4e0a\u770b\u76f8\u5f53\u4e8e\u5bf9<code>dim</code>\u8fdb\u884c\u76f8\u52a0\uff0c\u5176\u4f59\u7ef4\u5ea6\u5927\u5c0f\u4e0d\u53d8\uff0c\u5229\u7528\u8fd9\u4e2a\u601d\u60f3\uff0c\u53ef\u4ee5\u5f88\u5bb9\u6613\u7406\u89e3\u9ad8\u7ef4\u6570\u7ec4\u7684\u62fc\u63a5</p> <p>\u9ad8\u7ef4\u4e3e\u4f8b\uff1a</p> <pre><code>import torch\na=torch.ones(4*256*56*56).reshape(4,256,56,56)\nb=torch.arange(4*128*56*56).reshape(4,128,56,56)\nc=torch.zeros(4*64*56*56).reshape(4,64,56,56)\nd=torch.cat((a,b,c),dim=1)\nprint(d.shape)\n</code></pre> <p>\u8f93\u51fa\uff1a</p> <pre><code>torch.Size([4, 448, 56, 56])\n</code></pre> <p>\u4e0a\u8ff0\u4f8b\u5b50\u5728\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u4e2d\u5e38\u7528\u4e8e\u7279\u5f81\u56fe\u7684\u5806\u53e0\u3002</p>"},{"location":"PyTorch/torch/torch.cat_torch.stack/#torchstack","title":"torch.stack()","text":"<pre><code>torch.stack(tensors, dim=0, *, out=None) \u2192 Tensor\n</code></pre> <p>\u5b98\u65b9\u89e3\u91ca\uff1a\u6cbf\u7740\u65b0\u7684\u7ef4\u5ea6\u8fde\u63a5\u4e00\u7cfb\u5217\u6570\u7ec4\uff0c\u6240\u6709\u7684\u6570\u7ec4\u90fd\u9700\u8981\u5177\u6709\u76f8\u540c\u7684\u5927\u5c0f\u3002 \u76f8\u5f53\u4e8e\u5148\u5c06\u591a\u4e2an\u7ef4\u6570\u7ec4\u8fdb\u884c\u6269\u7ef4\u64cd\u4f5c\uff0c\u7136\u540e\u518d\u62fc\u63a5\u4e3a\u4e00\u4e2an+1\u7ef4\u7684\u6570\u7ec4</p> <p>\u53c2\u6570\u89e3\u91ca\uff1a</p> <ul> <li><code>tensors</code>\uff1a\u8981\u8fde\u63a5\u7684\u6570\u7ec4\u5e8f\u5217(\u5143\u7ec4<code>tuple</code>\u6216\u8005\u5217\u8868<code>list</code>)</li> <li><code>dim</code>\uff1a\u8981\u63d2\u5165\u7684\u7ef4\u5ea6\uff0c\u5927\u5c0f\u5fc5\u987b\u4ecb\u4e8e0\u548c\u9700\u8981\u62fc\u63a5\u7684\u6570\u7ec4\u7ef4\u6570\u4e4b\u95f4(<code>dim</code>\u6700\u5927\u4e0d\u8d85\u8fc7\u6570\u7ec4\u7684\u7ef4\u6570)</li> <li><code>out</code>\uff1a\u8f93\u51fa\u6570\u7ec4(\u4e0e<code>cat()</code>\u7c7b\u4f3c\uff0c\u4e00\u822c\u7528\u4e0d\u5230)</li> </ul> <p>\u6ce8\u610f\uff1a \u2460\u4e0e<code>cat</code>\u7c7b\u4f3c\uff0c\u5fc5\u987b\u8f93\u5165\u6570\u7ec4\u5e8f\u5217\uff0c\u4e0d\u80fd\u662f\u5355\u4e2a\u6570\u7ec4\uff1b \u2461\u8f93\u5165\u7684\u6240\u6709\u6570\u7ec4\u5e8f\u5217\u5f62\u72b6(\u5c3a\u5bf8)\u5fc5\u987b\u4e00\u81f4(\u8fd9\u91cc\u4e0e<code>cat</code>\u6709\u533a\u522b)\u3002</p> <p>\u4e3e\u4f8b\uff1a</p> <pre><code>import torch\na=torch.arange(12).reshape(3,4)\nb=torch.ones(12).reshape(3,4)\nc=torch.stack((a,b),dim=0)\nd=torch.stack((a,b),dim=1)\ne=torch.stack((a,b),dim=2)\n# dim\u6700\u5927\u53ef\u5230\u8f93\u5165\u6570\u7ec4\u7684\u7ef4\u6570\uff0c\u5373a\u3001b\u7684\u7ef4\u6570\nprint(c)\nprint(c.shape)\nprint(d)\nprint(d.shape)\nprint(e)\nprint(e.shape)\n</code></pre> <p>\u8f93\u51fa\uff1a</p> <pre><code>tensor([[[ 0.,  1.,  2.,  3.],\n         [ 4.,  5.,  6.,  7.],\n         [ 8.,  9., 10., 11.]],\n\n        [[ 1.,  1.,  1.,  1.],\n         [ 1.,  1.,  1.,  1.],\n         [ 1.,  1.,  1.,  1.]]])\ntorch.Size([2, 3, 4])\ntensor([[[ 0.,  1.,  2.,  3.],\n         [ 1.,  1.,  1.,  1.]],\n\n        [[ 4.,  5.,  6.,  7.],\n         [ 1.,  1.,  1.,  1.]],\n\n        [[ 8.,  9., 10., 11.],\n         [ 1.,  1.,  1.,  1.]]])\ntorch.Size([3, 2, 4])\ntensor([[[ 0.,  1.],\n         [ 1.,  1.],\n         [ 2.,  1.],\n         [ 3.,  1.]],\n\n        [[ 4.,  1.],\n         [ 5.,  1.],\n         [ 6.,  1.],\n         [ 7.,  1.]],\n\n        [[ 8.,  1.],\n         [ 9.,  1.],\n         [10.,  1.],\n         [11.,  1.]]])\ntorch.Size([3, 4, 2])\n</code></pre> <p>\u4ed4\u7ec6\u89c2\u5bdf\u4e0a\u4e2a\u6848\u4f8b\u7ef4\u5ea6\u7684\u53d8\u5316\uff0c\u53ef\u4ee5\u53d1\u73b0\u5f53\u8f93\u5165\u4e3a\u4e24\u7ec4\u6570\u7ec4\u65f6\uff0c<code>dim</code>\u5b9a\u4e3a\u51e0\uff0c\u62fc\u63a5\u540e\u54ea\u4e2a\u7ef4\u5ea6\u5c31\u662f2(\u6709\u4e24\u4e2a\u8f93\u5165\u6570\u7ec4)\uff0c\u76f8\u5f53\u4e8e\u505a\u4e86\u4e00\u4e2a\u6269\u7ef4\u62fc\u63a5\u64cd\u4f5c\u3002\u9996\u5148\u6309<code>dim</code>\u589e\u52a0\u4e00\u4e2a\u7ef4\u5ea6\uff0c\u7136\u540e\u518d\u4ece\u8be5\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u62fc\u63a5\u64cd\u4f5c\u3002</p>"},{"location":"PyTorch/torch/torch.cat_torch.stack/#catstack","title":"cat\u4e0estack\u7684\u533a\u522b","text":"<p>torch.cat()\u662f\u76f4\u63a5\u5728\u539f\u6570\u7ec4\u6570\u636e\u4e0a\u8fdb\u884c\u62fc\u63a5\uff0c\u4e0d\u4f1a\u6539\u53d8\u7ef4\u6570\u5927\u5c0f\uff1btorch.stack\u9996\u5148\u8fdb\u884c\u6269\u7ef4\uff0c\u7136\u540e\u518d\u8fdb\u884c\u62fc\u63a5\uff0c\u4f1a\u5c06\u7ef4\u6570\u589e\u5927\u4e00\u4e2a\u5355\u4f4d\u3002</p>"},{"location":"PyTorch/torch/torch.cat_torch.stack/#_2","title":"\u5b98\u65b9\u6587\u6863","text":"<p>torch.cat():https://pytorch.org/docs/stable/generated/torch.cat.html torch.stack():https://pytorch.org/docs/stable/generated/torch.stack.html</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e749\u67088\u65e5</p>"},{"location":"PyTorch/torch/torch.chunk/","title":"\u6570\u7ec4\u7684\u62c6\u5206","text":"<pre><code>torch.chunk(input, chunks, dim=0) \u2192 List of Tensors\n</code></pre> <p>\u529f\u80fd\uff1a\u5c06\u6570\u7ec4\u62c6\u5206\u4e3a\u7279\u5b9a\u6570\u91cf\u7684\u5757</p> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>input</code>\uff1a\u5f85\u62c6\u5206\u7684\u6570\u7ec4</li> <li><code>chunks</code>\uff1a\u62c6\u5206\u7684\u5757\u6570\uff0c\u6307\u5b9a\u4e3a\u51e0\uff0c\u5c31\u62c6\u6210\u51e0</li> <li><code>dim</code>\uff1a\u62c6\u5206\u7684\u7ef4\u5ea6\uff0c\u9ed8\u8ba4\u6cbf\u7b2c1\u7ef4\u5ea6\u62c6\u5206</li> </ul> <p>\u6ce8\u610f\uff1a</p> <ul> <li> <p>\u51fd\u6570\u6700\u540e\u8fd4\u56de\u7684\u662f\u5143\u7ec4\u7c7b\u578b\uff0c\u5305\u542b\u62c6\u5206\u540e\u7684\u6570\u7ec4</p> </li> <li> <p>\u5982\u679c\u8f93\u5165\u7684\u6570\u7ec4\u5728\u6307\u5b9a\u7684\u7ef4\u5ea6\u4e0b\u4e0d\u80fd\u6574\u9664\uff0c\u5219\u62c6\u5206\u5f97\u5230\u7684\u6700\u540e\u4e00\u5757\u6570\u7ec4\u7684<code>dim</code>\u7ef4\u5ea6\u5927\u5c0f\u5c06\u5c0f\u4e8e\u524d\u9762\u6240\u6709\u7684\u6570\u7ec4<code>dim</code>\u7ef4\u5ea6\u5927\u5c0f</p> </li> <li> <p><code>chunks</code>\u6709\u6700\u5927\u503c\u9650\u5236\uff0c\u5982\u679c\u6307\u5b9a\u7684\u5757\u6570\u8d85\u8fc7\u6700\u5927\u503c\uff0c\u5219\u6700\u7ec8\u53ea\u80fd\u62c6\u5206\u6210\u6700\u5927\u503c\u6570\u91cf</p> </li> <li> <p><code>chunks</code>\u6700\u5927\u503c\u7684\u8ba1\u7b97,<code>input</code>\u6570\u7ec4\u5728<code>dim</code>\u7ef4\u5ea6\u4e0a\u5927\u5c0f\u4e3aa   $$   chunks_{max}=\\left \\{ \\begin{matrix} \\frac{a}{2} \\quad&amp;,if\\quad a\u4e3a\u5076\u6570 \\\\ \\frac{a+1}{2}\\quad&amp;,if \\quad a\u4e3a\u5947\u6570 \\end{matrix} \\right.   $$ </p> </li> </ul> <p>\u5177\u4f53\u89c1\u4ee3\u7801\u6848\u4f8b</p>"},{"location":"PyTorch/torch/torch.chunk/#_2","title":"\u4ee3\u7801\u6848\u4f8b","text":"<pre><code>import torch\na=torch.arange(20).view(4,5)\nb=torch.chunk(a,chunks=2,dim=0)\nc=torch.chunk(a,chunks=2,dim=1)\nprint(type(b))\nprint(a.shape)\nprint(len(b))\nprint(len(c))\nprint(a)\nfor i in range(len(b)):\n    print(b[i])\n    print(b[i].shape)\n    # \u8f93\u51fa\u62c6\u5206\u540e\u7684\u5f62\u72b6\nfor i in range(len(c)):\n    print(c[i])\n    print(c[i].shape)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u62c6\u5206\u540e\u8fd4\u56de\u7684\u662f\u5143\u7ec4\u7c7b\u578b\n&lt;class 'tuple'&gt;\n# \u62c6\u5206\u524d\u6570\u7ec4\u5f62\u72b6\ntorch.Size([4, 5])\n# chunks\u6307\u5b9a\u4e3a2\uff0c\u65e0\u8bba\u5728\u54ea\u4e2a\u7ef4\u5ea6\u62c6\u5206\uff0c\u90fd\u4f1a\u5f97\u52302\u4e2a\u6570\u7ec4\n2\n2\n# \u62c6\u5206\u524d\u6570\u7ec4\ntensor([[ 0,  1,  2,  3,  4],\n        [ 5,  6,  7,  8,  9],\n        [10, 11, 12, 13, 14],\n        [15, 16, 17, 18, 19]])\n# \u5f53dim=0\uff0c\u5373\u5728\u7b2c\u4e00\u7ef4\u5ea6\u62c6\u5206\u65f6\ntensor([[0, 1, 2, 3, 4],\n        [5, 6, 7, 8, 9]])\n# \u7b2c\u4e00\u7ef4\u5ea6\u76f8\u5f53\u4e8e\u505a\u4e86\u4e00\u4e2a\u9664\u6cd5\uff0c\u9664\u4ee5chunks\n# \u5728\u8fd9\u91cc4\u9664\u4ee52\u7b49\u4e8e2\uff0c\u6240\u4ee5\u62c6\u5206\u540e\uff0c\u6bcf\u4e2a\u6570\u7ec4\u7b2c\u4e00\u7ef4\u5ea6\u5927\u5c0f\u662f2\ntorch.Size([2, 5])\ntensor([[10, 11, 12, 13, 14],\n        [15, 16, 17, 18, 19]])\ntorch.Size([2, 5])\n# \u5f53dim=1\uff0c\u5373\u5728\u7b2c\u4e8c\u7ef4\u5ea6\u62c6\u5206\u65f6\ntensor([[ 0,  1,  2],\n        [ 5,  6,  7],\n        [10, 11, 12],\n        [15, 16, 17]])\n# \u5f53\u4e0d\u80fd\u6574\u9664\u7684\u65f6\u5019\uff0c\u6700\u540e\u4e00\u4e2a\u6570\u7ec4\u5728\u5bf9\u5e94\u7ef4\u5ea6\u7684\u5c3a\u5bf8\u5c06\u4f1a\u6bd4\u524d\u9762\u7684\u5c0f\u3002\ntensor([[ 3,  4],\n        [ 8,  9],\n        [13, 14],\n        [18, 19]])\n# \u8fd9\u91cc\u6700\u540e\u4e00\u4e2a\u6570\u7ec4\u7b2c\u4e8c\u7ef4\u5ea6\u662f2\uff0c\u524d\u9762\u7684\u6570\u7ec4\u7ef4\u5ea6\u662f3\n</code></pre> <p>\u5982\u679c<code>chunks</code>\u6307\u5b9a\u7684\u8fc7\u5927</p> <pre><code>import torch\na=torch.arange(18).view(2,9)\n# \u62c6\u5947\u6570\nb=torch.chunk(a,chunks=8,dim=1)\nc=torch.arange(16).view(2,8)\n# \u62c6\u5076\u6570\nd=torch.chunk(c,chunks=7,dim=1)\nfor i in range(len(b)):\n    print(b[i])\nfor i in range(len(d)):\n    print(d[i])\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># 9\u5206\u62108\u5757\uff0c\u6700\u591a\u5f97\u52305\u5757\n\ntensor([[ 0,  1],\n        [ 9, 10]])\ntensor([[ 2,  3],\n        [11, 12]])\ntensor([[ 4,  5],\n        [13, 14]])\ntensor([[ 6,  7],\n        [15, 16]])\ntensor([[ 8],\n        [17]])\n# 8\u5206\u62107\u5757\uff0c\u6700\u591a\u5f97\u52304\u5757\ntensor([[0, 1],\n        [8, 9]])\ntensor([[ 2,  3],\n        [10, 11]])\ntensor([[ 4,  5],\n        [12, 13]])\ntensor([[ 6,  7],\n        [14, 15]])\n</code></pre> <p>\u6362\u53e5\u8bdd\u8bf4\uff1a\u9664\u4e86\u6700\u540e\u4e00\u4e2a\u6570\u7ec4<code>dim</code>\u7ef4\u5ea6\u4e0a\u7684\u5927\u5c0f\u53ef\u4ee5\u4e3a1\uff0c\u524d\u9762\u7684\u6570\u7ec4<code>dim</code>\u7ef4\u5ea6\u4e0a\u7684\u5927\u5c0f\u81f3\u5c11\u662f2</p>"},{"location":"PyTorch/torch/torch.chunk/#_3","title":"\u5b98\u65b9\u6587\u6863","text":"<p>torch.chunk():https://pytorch.org/docs/stable/generated/torch.chunk.html#torch.chunk</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e749\u670817\u65e5</p>"},{"location":"PyTorch/torch/torch.clamp/","title":"\u6570\u7ec4\u7684\u5939\u7d27","text":"<pre><code>torch.clamp(input, min=None, max=None, *, out=None) \u2192 Tensor\n</code></pre> <p>\u529f\u80fd\uff1a\u5c06\u6570\u7ec4\u7684\u6240\u6709\u5143\u7d20\u5939\u7d27\u5230\u8303\u56f4[min,max]\u5185\uff0c\u76f8\u5f53\u4e8e\u7ecf\u8fc7\u4e86\u51fd\u6570 $$ f(x)=\\left \\{ \\begin{matrix} min,\\quad &amp;if\\quad x\u2264min \\\\ x,&amp;if\\quad min&lt;x&lt;max \\\\ max,\\quad &amp;if\\quad x\u2265max \\\\ \\end {matrix} \\right. $$  \u7684\u6620\u5c04\u3002</p> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>input</code>\uff1a\u8f93\u5165\u5f20\u91cf</li> <li><code>min</code>\uff1a\u8303\u56f4\u7684\u6700\u5c0f\u503c\uff0c\u5982\u679c\u4e0d\u6307\u5b9a\u7684\u8bdd\uff0c\u4f1a\u9ed8\u8ba4\u65e0\u4e0b\u754c</li> <li><code>max</code>\uff1a\u8303\u56f4\u7684\u6700\u5927\u503c\uff0c\u5982\u679c\u4e0d\u6307\u5b9a\u7684\u8bdd\uff0c\u4f1a\u9ed8\u8ba4\u65e0\u4e0a\u754c</li> </ul> <p>\u6ce8\u610f\uff1a</p> <ul> <li>\u8f93\u5165\u7684\u5f20\u91cf\u5bf9\u5f62\u72b6\u65e0\u8981\u6c42\uff0c\u53ef\u4ee5\u5939\u7d27\u4efb\u610f\u5f62\u72b6\u7684\u5f20\u91cf\u6570\u7ec4\u3002</li> <li>\u8f93\u5165\u7684<code>min</code>\u4e0e<code>max</code>\u5fc5\u987b\u662f\u5355\u4e2a\u503c\uff0c\u4e0d\u80fd\u662f\u5e8f\u5217</li> <li>torch.clamp()\u7684\u529f\u80fd\u4e5f\u53ef\u4ee5\u7528a.clamp()\u65b9\u6cd5\u5b9e\u73b0\uff0c\u540e\u8005\u9ed8\u8ba4\u5939\u7d27\u6570\u7ec4a</li> </ul>"},{"location":"PyTorch/torch/torch.clamp/#_2","title":"\u4ee3\u7801\u6848\u4f8b","text":"<pre><code>import torch\na=torch.arange(10).view(2,5)\nb=torch.clamp(a,3,6)\nprint(a)\nprint(b)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u539f\u59cb\u6570\u7ec4\ntensor([[0, 1, 2, 3, 4],\n        [5, 6, 7, 8, 9]])\n# \u6570\u636e\u89c4\u8303\u52303\u52306\u4e4b\u95f4\ntensor([[3, 3, 3, 3, 4],\n        [5, 6, 6, 6, 6]])\n</code></pre>"},{"location":"PyTorch/torch/torch.clamp/#_3","title":"\u5b98\u65b9\u6587\u6863","text":"<p>torch.clamp()\uff1ahttps://pytorch.org/docs/stable/generated/torch.clamp.html?highlight=torch%20clamp#torch.clamp</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e749\u670816\u65e5</p>"},{"location":"PyTorch/torch/torch.div/","title":"\u6570\u7ec4\u7684\u2019\u70b9\u9664\u2019\u8fd0\u7b97","text":"<pre><code>torch.div(input, other, *, rounding_mode=None, out=None) \u2192 Tensor\n</code></pre> <p>\u529f\u80fd\uff1a\u5c06\u6570\u7ec4<code>input</code>\u4e0e\u6570\u7ec4<code>other</code>\u5bf9\u5e94\u5143\u7d20\u505a\u9664\u6cd5\uff0c\u5177\u4f53\u8ba1\u7b97\u516c\u5f0f\u5982\u4e0b\uff1a $$ out_i=\\frac{input_i}{other_i} $$  \u8f93\u5165\uff1a</p> <ul> <li><code>input</code>\uff1a\u5143\u7d20\u7528\u4e8e\u88ab\u9664\u6570\u7684\u6570\u7ec4</li> <li><code>other</code>\uff1a\u5143\u7d20\u7528\u4e8e\u9664\u6570\u7684\u6570\u7ec4\u6216\u8005\u6570</li> <li><code>rounding_mode</code>\uff1a\u8f93\u5165\u4e3a\u5b57\u7b26\u4e32\u7c7b\u578b\uff0c\u7528\u4e8e\u5224\u65ad\u7ed3\u679c\u7684\u820d\u5165\u7c7b\u578b\uff0c\u6709\u4ee5\u4e0b\u4e09\u79cd\u60c5\u51b5\uff1a</li> <li><code>None</code>\uff1a\u9ed8\u8ba4\u884c\u4e3a\uff0c\u4e0d\u6267\u884c\u820d\u5165\u64cd\u4f5c\u3002</li> <li><code>trunc</code>\uff1a\u5c06\u9664\u6cd5\u7ed3\u679c\u5411\u96f6\u56db\u820d\u4e94\u5165\uff0c\u76f8\u5f53\u4e8eC\u8bed\u8a00\u98ce\u683c\u7684\u9664\u6cd5\u3002</li> <li><code>floor</code>\uff1a\u5c06\u9664\u6cd5\u7ed3\u679c\u56db\u820d\u4e94\u5165</li> </ul> <p>\u6ce8\u610f\uff1a</p> <ul> <li>\u8be5\u8fd0\u7b97\u652f\u6301\u5e7f\u64ad\u673a\u5236\uff0c\u5e76\u4e14\u8fd8\u652f\u6301\u6574\u6570\u3001\u6d6e\u70b9\u6570\u548c\u590d\u6742\u8f93\u5165\uff0c\u59cb\u7ec8\u5c06\u6574\u6570\u7c7b\u578b\u63d0\u5347\u4e3a\u9ed8\u8ba4\u6807\u91cf\u7c7b\u578b</li> <li><code>torch.div</code>\u53ef\u4ee5\u901a\u8fc7<code>a.div</code>\u5b9e\u73b0\uff0c\u540e\u8005\u9ed8\u8ba4<code>a</code>\u5f53\u505a\u88ab\u9664\u6570</li> </ul>"},{"location":"PyTorch/torch/torch.div/#_2","title":"\u4ee3\u7801\u6848\u4f8b","text":"<p>\u4e00\u822c\u7528\u6cd5</p> <pre><code>import torch\na=torch.arange(20).reshape(5,4)\nb=torch.arange(21,41).reshape(5,4)\nc=torch.div(a,b)\nprint(a)\nprint(b)\nprint(c)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u88ab\u9664\u6570\ntensor([[ 0,  1,  2,  3],\n        [ 4,  5,  6,  7],\n        [ 8,  9, 10, 11],\n        [12, 13, 14, 15],\n        [16, 17, 18, 19]])\n# \u9664\u6570\ntensor([[21, 22, 23, 24],\n        [25, 26, 27, 28],\n        [29, 30, 31, 32],\n        [33, 34, 35, 36],\n        [37, 38, 39, 40]])\n# div\u7ed3\u679c(\u4e0d\u8fdb\u884c\u820d\u5165\u64cd\u4f5c)\ntensor([[0.0000, 0.0455, 0.0870, 0.1250],\n        [0.1600, 0.1923, 0.2222, 0.2500],\n        [0.2759, 0.3000, 0.3226, 0.3438],\n        [0.3636, 0.3824, 0.4000, 0.4167],\n        [0.4324, 0.4474, 0.4615, 0.4750]])\n</code></pre> <p><code>rounding_mode</code>\u4e09\u79cd\u65b9\u5f0f\u7684\u533a\u522b</p> <pre><code>import torch\nimport numpy as np\na=torch.from_numpy(np.random.randn(2,5))\nb=torch.from_numpy(np.random.randn(2,5))\nc=torch.div(a,b)\nd=torch.div(a,b,rounding_mode='trunc')\ne=torch.div(a,b,rounding_mode='floor')\nprint(a)\nprint(b)\nprint(c)\nprint(d)\nprint(e)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u88ab\u9664\u6570\ntensor([[-0.1634,  1.6856, -0.0897, -0.7464,  1.3927],\n        [-0.9697,  0.2859,  0.2458,  0.3014,  0.0339]], dtype=torch.float64)\n# \u9664\u6570\ntensor([[ 0.2383,  0.8596, -0.0589, -1.5333,  0.6570],\n        [-0.3662,  0.1371, -0.1085, -0.0345,  0.2491]], dtype=torch.float64)\n# \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u4e0d\u8fdb\u884c\u820d\u5165\u64cd\u4f5c\ntensor([[-0.6858,  1.9609,  1.5221,  0.4868,  2.1197],\n        [ 2.6481,  2.0850, -2.2658, -8.7355,  0.1361]], dtype=torch.float64)\n# trunc\u65b9\u5f0f\u7684\u820d\u5165\ntensor([[-0.,  1.,  1.,  0.,  2.],\n        [ 2.,  2., -2., -8.,  0.]], dtype=torch.float64)\n# floor\u65b9\u5f0f\u7684\u820d\u5165\ntensor([[-1.,  1.,  1.,  0.,  2.],\n        [ 2.,  2., -3., -9.,  0.]], dtype=torch.float64)\n</code></pre> <p>trunc\u4e0efloor\u6700\u4e3b\u8981\u7684\u533a\u522b\u5c31\u662f\u8d1f\u6570\u7684\u56db\u820d\u4e94\u5165\u65b9\u6cd5\uff0ctrunc\u5411\u96f6\u56db\u820d\u820d\u5165\uff0cfloor\u666e\u901a\u7684\u56db\u820d\u4e94\u5165\uff0ctrunc\u5f97\u5230\u7684\u8d1f\u6570\u7ed3\u679c\u59cb\u7ec8\u6bd4floor\u5f97\u5230\u7684\u8d1f\u6570\u7ed3\u679c\u59271\u3002</p>"},{"location":"PyTorch/torch/torch.div/#_3","title":"\u5b98\u65b9\u6587\u6863","text":"<p>torch.div()\uff1ahttps://pytorch.org/docs/stable/generated/torch.div.html?highlight=div#torch.div</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e749\u670827\u65e5</p>"},{"location":"PyTorch/torch/torch.from_numpy/","title":"torch.from_numpy","text":"<p>\ufeff# numpy\u4e0etensor\u6570\u636e\u7c7b\u578b\u4e92\u6362</p> <p><code>numpy</code>\u8f6c\u6362\u4e3a<code>tensor</code></p> <pre><code>torch.from_numpy(ndarray) \u2192 Tensor\n</code></pre> <p><code>tensor</code>\u8f6c\u6362\u4e3a<code>numpy</code></p> <pre><code>Tensor.numpy() \u2192 numpy.ndarray\n</code></pre> <p>\u6ce8\u610f\uff1a</p> <ul> <li>\u65e0\u8bba\u662f<code>numpy</code>\u8f6c\u6362\u4e3a<code>tensor</code>\u8fd8\u662f<code>tensor</code>\u8f6c\u6362\u4e3a<code>numpy</code>\uff0c\u4e24\u8005\u7684\u53d8\u6362\u540e\u5f97\u5230\u7684\u6570\u636e\u4e0e\u53d8\u6362\u524d\u7684\u6570\u636e\u5171\u4eab\u5e95\u5c42\u5b58\u50a8\uff0c\u5373\u6539\u53d8\u4e00\u65b9\u7684\u6570\u636e\uff0c\u53e6\u4e00\u65b9\u7684\u6570\u636e\u4e5f\u4f1a\u76f8\u5e94\u6539\u53d8\u3002</li> </ul>"},{"location":"PyTorch/torch/torch.from_numpy/#_1","title":"\u4ee3\u7801\u6848\u4f8b","text":"<p>numpy\u8f6c\u6362\u4e3atensor</p> <pre><code>import torch\nimport numpy as np\na=np.arange(10).reshape(2,5)\nb=torch.from_numpy(a)\nprint(type(a))\nprint(type(b))\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u539f\u6570\u636e\u7c7b\u578b\n&lt;class 'numpy.ndarray'&gt;\n# \u8f6c\u5316\u540e\u6570\u636e\u7c7b\u578b\n&lt;class 'torch.Tensor'&gt;\n</code></pre> <p>tensor\u8f6c\u6362\u4e3anumpy</p> <pre><code>import torch\nimport numpy as np\na=torch.arange(10).view(2,5)\nb=a.numpy()\nprint(type(a))\nprint(type(b))\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u539f\u6570\u636e\u7c7b\u578b\n&lt;class 'torch.Tensor'&gt;\n# \u8f6c\u5316\u540e\u6570\u636e\u7c7b\u578b\n&lt;class 'numpy.ndarray'&gt;\n</code></pre>"},{"location":"PyTorch/torch/torch.from_numpy/#_2","title":"\u5171\u4eab\u5e95\u5c42\u5185\u5b58","text":"<pre><code>import torch\nimport numpy as np\na=torch.arange(10).view(2,5)\nb=a.numpy()\nprint(a)\nb[0,1]=99\nprint(a)\nprint(b)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u539f\u59cb\u7684a\ntensor([[0, 1, 2, 3, 4],\n        [5, 6, 7, 8, 9]])\n# \u8f6c\u5316\u540e\u7684\ntensor([[ 0, 99,  2,  3,  4],\n        [ 5,  6,  7,  8,  9]])\n[[ 0 99  2  3  4]\n [ 5  6  7  8  9]]\n</code></pre> <p>\u8f6c\u5316\u540e\u7684\u6570\u636e\u76f8\u5f53\u4e8e\u662f\u8f6c\u5316\u524d\u7684\u6570\u636e\u7684\u4e00\u4e2a\u89c6\u56fe\uff0c\u5e95\u5c42\u7684\u5b58\u50a8\u6570\u636e\u90fd\u662f\u4e00\u6837\u7684\uff0c\u53ea\u8981\u6539\u53d8\u4e00\u65b9\u7684\u6570\u636e\uff0c\u53e6\u4e00\u65b9\u4e5f\u4f1a\u968f\u7740\u6539\u53d8\u3002</p>"},{"location":"PyTorch/torch/torch.from_numpy/#_3","title":"\u5b98\u65b9\u6587\u6863","text":"<p>torch.from_numpy()\uff1ahttps://pytorch.org/docs/stable/generated/torch.from_numpy.html?highlight=torch%20from_numpy#torch.from_numpy</p> <p>Tensor.numpy()\uff1ahttps://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html?highlight=torch%20numpy#torch.Tensor.numpy</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e749\u670818\u65e5</p>"},{"location":"PyTorch/torch/torch.gather/","title":"\u6cbf\u7279\u5b9a\u7ef4\u5ea6\u6536\u96c6\u6570\u7ec4\u6570\u636e","text":"<pre><code>torch.gather(input, dim, index, *, sparse_grad=False, out=None) \u2192 Tensor\n</code></pre> <p>\u529f\u80fd\uff1a\u4ece\u8f93\u5165\u7684\u6570\u7ec4\u4e2d\uff0c\u6cbf\u6307\u5b9a\u7684<code>dim</code>\u7ef4\u5ea6\uff0c\u5229\u7528\u7d22\u5f15\u53d8\u91cf<code>index</code>\uff0c\u5c06\u6570\u636e\u7d22\u5f15\u51fa\u6765\uff0c\u5e76\u4e14\u5806\u53e0\u6210\u4e00\u4e2a\u6570\u7ec4\u3002\u76f4\u89c2\u53ef\u80fd\u4e0d\u597d\u7406\u89e3\uff0c\u5177\u4f53\u53ef\u4ee5\u89c1\u4ee3\u7801\u6848\u4f8b\u3002</p> <p>\u8f93\u5165\uff1a</p> <p><code>input</code>\uff1a\u8f93\u5165\u7684\u6570\u7ec4</p> <p><code>dim</code>\uff1a\u6307\u5b9a\u7684\u7ef4\u5ea6</p> <p><code>index</code>\uff1a\u7d22\u5f15\u53d8\u91cf\uff0c\u6570\u636e\u7c7b\u578b\u9700\u662f\u957f\u6574\u578b(int64)</p> <p>\u6ce8\u610f\uff1a</p> <ul> <li> <p><code>input</code>\u548c<code>index</code>\u5177\u6709\u76f8\u540c\u7684\u7ef4\u6570</p> </li> <li> <p><code>out</code>\u548c<code>index</code>\u5177\u6709\u76f8\u540c\u7684\u5f62\u72b6</p> </li> <li> <p>\u9664\u4e86<code>dim</code>\u7ef4\u5ea6\uff0c\u5728\u6bcf\u4e2a\u7ef4\u5ea6\u4e0a\uff0c\u7d22\u5f15\u5728\u8be5\u7ef4\u5ea6\u4e0a\u7684\u5927\u5c0f\u8981\u5c0f\u4e8e\u7b49\u4e8e\u8f93\u5165\u5728\u8be5\u7ef4\u5ea6\u4e0a\u7684\u5927\u5c0f\uff0c\u5373\uff1a   $$   index.size(d)\u2264input.size(d),\\quad d!=dim   $$ </p> </li> </ul>"},{"location":"PyTorch/torch/torch.gather/#_2","title":"\u4ee3\u7801\u6848\u4f8b","text":"<p>\u4e00\u822c\u7528\u6cd5\uff0c\u5f53\u5728\u4e00\u4e2a\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u7d22\u5f15\u65f6\uff0c\u4ee5\u7b2c\u4e00\u7ef4\u5ea6\u4e3a\u4f8b</p> <pre><code>import torch\na=torch.arange(20).reshape(4,5)\nindex=torch.tensor([[2,3,1,3]])\nb=torch.gather(a,dim=0,index=index)\nprint(a)\nprint(b)\n</code></pre> <p>\u8f93\u51fa</p> <p> <p></p> <p></p> <p>\u4ee5\u7b2c\u4e8c\u7ef4\u5ea6\u4e3a\u4f8b</p> <pre><code>import torch\na=torch.arange(20).reshape(4,5)\nindex=torch.tensor([[2],[3],[1],[3]])\nb=torch.gather(a,dim=1,index=index)\nprint(a)\nprint(b)\n</code></pre> <p>\u8f93\u51fa</p> <p> <p></p> <p></p> <p>\u5f53\u540c\u65f6\u5728\u4e24\u4e2a\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u7d22\u5f15\u65f6\uff0c\u4ee5\u7b2c\u4e00\u7ef4\u5ea6\u4e3a\u4f8b</p> <pre><code>import torch\na=torch.arange(20).reshape(4,5)\nindex=torch.tensor([[1,2,3],[2,3,0],[3,0,1]])\nb=torch.gather(a,dim=0,index=index)\nprint(a)\nprint(b)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code>tensor([[ 0,  1,  2,  3,  4],\n        [ 5,  6,  7,  8,  9],\n        [10, 11, 12, 13, 14],\n        [15, 16, 17, 18, 19]])\ntensor([[ 5, 11, 17],\n        [10, 16,  2],\n        [15,  1,  7]])\n</code></pre> <p>\u4ee5\u7b2c\u4e8c\u7ef4\u5ea6\u4e3a\u4f8b</p> <pre><code>import torch\na=torch.arange(20).reshape(4,5)\nindex=torch.tensor([[1,2],[2,3],[3,4]])\nb=torch.gather(a,dim=1,index=index)\nprint(a)\nprint(b)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code>tensor([[ 0,  1,  2,  3,  4],\n        [ 5,  6,  7,  8,  9],\n        [10, 11, 12, 13, 14],\n        [15, 16, 17, 18, 19]])\ntensor([[ 1,  2],\n        [ 7,  8],\n        [13, 14]])\n</code></pre>"},{"location":"PyTorch/torch/torch.gather/#_3","title":"\u5b98\u65b9\u6587\u6863","text":"<p>torch.gather:https://pytorch.org/docs/stable/generated/torch.gather.html?highlight=torch%20gather#torch.gather</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e7411\u67087\u65e5</p>"},{"location":"PyTorch/torch/torch.ge_gt_le_lt_ne_eq/","title":"\u9010\u5143\u7d20\u5bf9\u6bd4","text":""},{"location":"PyTorch/torch/torch.ge_gt_le_lt_ne_eq/#_2","title":"\u4ecb\u7ecd","text":"<pre><code>torch.ge(input, other, *, out=None) \u2192 Tensor\ntorch.gt(input, other, *, out=None) \u2192 Tensor\ntorch.le(input, other, *, out=None) \u2192 Tensor\ntorch.lt(input, other, *, out=None) \u2192 Tensor\ntorch.ne(input, other, *, out=None) \u2192 Tensor\ntorch.eq(input, other, *, out=None) \u2192 Tensor\n</code></pre> <p>\u529f\u80fd\uff1a\u9010\u5143\u7d20\u5bf9\u6bd4</p> <ul> <li>torch.ge\uff1a\u5b9e\u73b0\u5927\u4e8e\u7b49\u4e8e\uff08\\ge\uff09\u8fd0\u7b97</li> <li>torch.gt\uff1a\u5b9e\u73b0\u5927\u4e8e\uff08\\gt\uff09\u8fd0\u7b97</li> <li>torch.le\uff1a\u5b9e\u73b0\u5c0f\u4e8e\u7b49\u4e8e\uff08\\le\uff09\u8fd0\u7b97</li> <li>torch.lt\uff1a\u5b9e\u73b0\u5c0f\u4e8e\uff08\\lt\uff09\u8fd0\u7b97</li> <li>torch.ne\uff1a\u5b9e\u73b0\u4e0d\u7b49\u4e8e\uff08\\ne\uff09\u8fd0\u7b97</li> <li>torch.eq\uff1a\u5b9e\u73b0\u7b49\u4e8e\uff08=\uff09\u8fd0\u7b97</li> </ul> <p>\u524d\u4e94\u4e2a\u7ed3\u5408latex\u516c\u5f0f\u7b26\u53f7\u8bb0\u5fc6</p> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>input</code>\uff1a\u5f85\u6bd4\u8f83\u7684\u6570\u7ec4</li> <li><code>other</code>\uff1a\u6bd4\u8f83\u6570\u503c\uff0c\u53ef\u4ee5\u662f\u6570\u7ec4\uff0c\u4e5f\u53ef\u4ee5\u662f\u4e00\u4e2a\u6570\u3002<code>tensor</code>\u6216<code>float</code>\u683c\u5f0f</li> </ul> <p>\u8f93\u51fa\uff1a\u5e03\u5c14\u5f20\u91cf\uff0c\u5c3a\u5bf8\u548c<code>input</code>\u76f8\u540c\uff0c\u5f53<code>input</code>\u548c<code>other</code>\u5143\u7d20\u4e4b\u95f4\u7b26\u5408\u8fd0\u7b97\u65f6\uff0c\u5bf9\u5e94\u4f4d\u7f6e\u5143\u7d20\u4e3a<code>True</code>\uff0c\u5426\u5219\u4e3a<code>Flase</code>\u3002</p> <p>\u6ce8\uff1a</p> <ul> <li>\u7b2c\u4e8c\u4e2a\u53c2\u6570\u53ef\u4ee5\u662f\u4e00\u4e2a\u6570\u5b57\uff0c\u4e5f\u53ef\u4ee5\u662f\u4e00\u4e2a\u5f20\u91cf\u6570\u7ec4\uff0c\u53ea\u8981\u4e0e\u7b2c\u4e00\u4e2a\u53c2\u6570\u6ee1\u8db3\u5e7f\u64ad\u6761\u4ef6\u5373\u53ef\uff1b</li> <li>\u4e5f\u53ef\u4ee5\u901a\u8fc7<code>tensor</code>\u52a0\u540e\u7f00\u7684\u5f62\u5f0f\u5b9e\u73b0\uff0c\u5982<code>a.ge</code>\uff0c<code>a</code>\u76f8\u5f53\u4e8e<code>input</code>\uff0c\u5373\u5f85\u6bd4\u8f83\u7684\u6570\u7ec4\uff1b</li> <li>\u5982\u679c\u8f93\u5165\u7684\u662f\u6570\u7ec4\uff0c\u5219\u5fc5\u987b\u662f<code>tensor</code>\u7c7b\u578b</li> </ul>"},{"location":"PyTorch/torch/torch.ge_gt_le_lt_ne_eq/#_3","title":"\u4ee3\u7801\u6848\u4f8b","text":"<pre><code>import torch\na=torch.arange(5)\nb=torch.tensor(3)\nprint(a)\nprint(b)\nprint(torch.ge(a,b))\nprint(torch.gt(a,b))\nprint(torch.le(a,b))\nprint(torch.lt(a,b))\nprint(torch.ne(a,b))\nprint(torch.eq(a,b))\n</code></pre> <p>\u8f93\u51fa</p> <pre><code>tensor([0, 1, 2, 3, 4])\ntensor(3)\n# \u5927\u4e8e\u7b49\u4e8e\ntensor([False, False, False,  True,  True])\n# \u5927\u4e8e\ntensor([False, False, False, False,  True])\n# \u5c0f\u4e8e\u7b49\u4e8e\ntensor([ True,  True,  True,  True, False])\n# \u5c0f\u4e8e\ntensor([ True,  True,  True, False, False])\n# \u4e0d\u7b49\u4e8e\ntensor([ True,  True,  True, False,  True])\n# \u7b49\u4e8e\ntensor([False, False, False,  True, False])\n</code></pre>"},{"location":"PyTorch/torch/torch.ge_gt_le_lt_ne_eq/#_4","title":"\u6269\u5c55","text":"<p><code>torch.eq</code>\u5e38\u7528\u4e8e\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u5224\u65ad\u9884\u6d4b\u503c\u662f\u5426\u4e0e\u771f\u5b9e\u503c(\u6807\u7b7e\u503c)\u76f8\u7b49\uff0c\u7136\u540e\u518d\u914d\u5408<code>.sum()</code>\u65b9\u6cd5\uff0c\u5c06\u8fd4\u56de\u6570\u7ec4\u4e2d<code>True</code>\u7684\u4e2a\u6570\u6c42\u548c\uff0c\u4ece\u800c\u8ba1\u7b97\u6b63\u786e\u9884\u6d4b\u7684\u4e2a\u6570\uff0c\u6700\u7ec8\u5f97\u5230\u6b63\u786e\u7387\u3002</p>"},{"location":"PyTorch/torch/torch.ge_gt_le_lt_ne_eq/#_5","title":"\u4ee3\u7801\u6848\u4f8b","text":"<pre><code>import torch\nimport numpy as np\n# \u4ece0,1\u5185\u968f\u673a\u900950\u4e2a\u6570\uff0c\u4f5c\u4e3a\u6807\u7b7e\u548c\u9884\u6d4b\u503c\nlabels=torch.tensor(np.random.choice(2,50))\npre=torch.tensor(np.random.choice(2,50))\nprint(labels)\nprint(pre)\nright=torch.eq(pre,labels).sum().item()\n# .sum()\u662f\u6c42\u548c\u64cd\u4f5c\uff0c\u5c06\u6570\u7ec4\u4e2dTrue\u6570\u91cf\u6c42\u548c\n# .item()\u65b9\u6cd5\u662f\u4e3a\u4e86\u53d6\u51fa\u6570\u503c\nprint('\u6b63\u786e\u9884\u6d4b:',right,'\u4e2a')\nacc=right/len(labels)\nprint('\u51c6\u786e\u7387\u4e3a:',acc,'%')\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u6807\u7b7e\ntensor([1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n        0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0,\n        1, 1], dtype=torch.int32)\n# \u9884\u6d4b\u503c\ntensor([1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n        1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n        0, 1], dtype=torch.int32)\n\u6b63\u786e\u9884\u6d4b: 31 \u4e2a\n\u51c6\u786e\u7387\u4e3a: 0.62 %\n</code></pre>"},{"location":"PyTorch/torch/torch.ge_gt_le_lt_ne_eq/#_6","title":"\u5b98\u65b9\u6587\u6863","text":"<p>torch.ge()\uff1ahttps://pytorch.org/docs/stable/generated/torch.ge.html?highlight=torch+ge#torch.ge</p> <p>torch.gt()\uff1ahttps://pytorch.org/docs/stable/generated/torch.gt.html?highlight=torch+gt#torch.gt</p> <p>torch.le()\uff1ahttps://pytorch.org/docs/stable/generated/torch.le.html?highlight=torch+le#torch.le</p> <p>torch.lt()\uff1ahttps://pytorch.org/docs/stable/generated/torch.lt.html?highlight=torch+lt#torch.lt</p> <p>torch.ne()\uff1ahttps://pytorch.org/docs/stable/generated/torch.ne.html?highlight=torch+ne#torch.ne</p> <p>torch.eq()\uff1ahttps://pytorch.org/docs/stable/generated/torch.eq.html?highlight=torch+eq#torch.eq</p> <p>\u521d\u6b65\u5b8c\u7a3f\u4e8e\uff1a2023\u5e741\u670826\u65e5</p>"},{"location":"PyTorch/torch/torch.index_select/","title":"\u6309\u7d22\u5f15\u641c\u7d22\u6570\u7ec4","text":"<pre><code>torch.index_select(input, dim, index, *, out=None) \u2192 Tensor\n</code></pre> <p>\u529f\u80fd\uff1a\u9009\u62e9\u6839\u636e\u7ed9\u5b9a\u7684<code>index</code>\u548c<code>dim</code>\u5728<code>input</code>\u4e2d\u9009\u62e9\u5f20\u91cf\u6570\u636e\uff0c\u76f8\u5f53\u4e8e\u66f4\u9ad8\u7ea7\u7684\u7d22\u5f15\u529f\u80fd\u3002</p> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>input</code>\uff1a\u9700\u8981\u7d22\u5f15\u7684\u5f20\u91cf\u6570\u7ec4</li> <li><code>dim</code>\uff1a\u7d22\u5f15\u7ef4\u5ea6(\u6cbf<code>dim</code>\u7ef4\u5ea6\u8fdb\u884c\u7d22\u5f15)</li> <li><code>index</code>\uff1a\u7d22\u5f15\u503c\uff0c\u53ef\u4ee5\u662f\u5355\u4e2a\u6570\u5b57\u3001\u4e5f\u53ef\u4ee5\u662f\u4e00\u4e2a\u5e8f\u5217(\u4e00\u7ef4\u5e8f\u5217)</li> </ul> <p>\u6ce8\u610f\uff1a</p> <ul> <li>\u8fd4\u56de\u7684\u5f20\u91cf\u6570\u7ec4\u4e0e\u539f\u59cb\u7684\u5f20\u91cf\u6570\u7ec4\u5177\u6709\u76f8\u540c\u7684\u7ef4\u6570\uff0c\u8fd9\u91cc\u4e0e\u76f4\u63a5\u8fdb\u884c\u7d22\u5f15\u6709\u533a\u522b\uff0c\u5177\u4f53\u89c1\u6848\u4f8b\u4ee3\u7801\uff1b</li> <li><code>dim</code>\u7ef4\u5ea6\u7684\u5c3a\u5bf8\u5927\u5c0f\u4e0e<code>index</code>\u7684\u957f\u5ea6\u76f8\u540c\uff0c\u5176\u4ed6\u5c3a\u5bf8\u5927\u5c0f\u4e0e\u539f\u59cb\u5f20\u91cf\u4e2d\u7684\u5c3a\u5bf8\u76f8\u540c</li> <li><code>index</code>\uff1a\u7ef4\u6570\u5fc5\u987b\u5c0f\u4e8e\u7b49\u4e8e1</li> </ul>"},{"location":"PyTorch/torch/torch.index_select/#_2","title":"\u4ee3\u7801\u6848\u4f8b","text":""},{"location":"PyTorch/torch/torch.index_select/#index","title":"\u5f53index\u7d22\u5f15\u4e3a\u5355\u4e2a\u6570\u5b57\u65f6","text":"<pre><code>import torch\na=torch.arange(40).view(2,4,5)\nindex=torch.tensor([1])\nselect_1=torch.index_select(a,dim=0,index=index)\nselect_2=torch.index_select(a,dim=1,index=index)\nselect_3=torch.index_select(a,dim=2,index=index)\nprint(select_1)\nprint(select_2)\nprint(select_3)\nprint(a.shape)\nprint(select_1.shape)\nprint(select_2.shape)\nprint(select_3.shape)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># dim=0\ntensor([[[20, 21, 22, 23, 24],\n         [25, 26, 27, 28, 29],\n         [30, 31, 32, 33, 34],\n         [35, 36, 37, 38, 39]]])\n# dim=1\ntensor([[[ 5,  6,  7,  8,  9]],\n\n        [[25, 26, 27, 28, 29]]])\n# dim=2\ntensor([[[ 1],\n         [ 6],\n         [11],\n         [16]],\n\n        [[21],\n         [26],\n         [31],\n         [36]]])\n# \u7d22\u5f15\u540e\u7684\u6570\u7ec4\u5c3a\u5bf8\uff0c\u9664\u4e86dim\u90e8\u5206\uff0c\u5176\u4ed6\u548c\u539f\u6765\u5927\u5c0f\u4e00\u6837\n# \u539f\u59cb\ntorch.Size([2, 4, 5])\n# dim=0\ntorch.Size([1, 4, 5])\n# dim=1\ntorch.Size([2, 1, 5])\n# dim=2\ntorch.Size([2, 4, 1])\n</code></pre> <p> <p></p> <p></p>"},{"location":"PyTorch/torch/torch.index_select/#_3","title":"\u5f53\u7d22\u5f15\u4e3a\u5217\u8868\u65f6","text":"<pre><code>import torch\na=torch.arange(40).view(2,4,5)\nindex=torch.tensor([1,3])\nselect_1=torch.index_select(a,dim=1,index=index)\nselect_2=torch.index_select(a,dim=2,index=index)\nprint(select_1)\nprint(select_2)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># dim=1\ntensor([[[ 5,  6,  7,  8,  9],\n         [15, 16, 17, 18, 19]],\n\n        [[25, 26, 27, 28, 29],\n         [35, 36, 37, 38, 39]]])\n# dim=2\ntensor([[[ 1,  3],\n         [ 6,  8],\n         [11, 13],\n         [16, 18]],\n\n        [[21, 23],\n         [26, 28],\n         [31, 33],\n         [36, 38]]])\n</code></pre> <p> <p></p> <p></p>"},{"location":"PyTorch/torch/torch.index_select/#_4","title":"\u9ad8\u7ef4\u6570\u7ec4\u7684\u9009\u62e9","text":"<pre><code>import torch\na=torch.arange(4*512*28*28).view(4,512,28,28)\nindex=np.random.choice(32,5)# \u57280\u523031\u5185\u968f\u673a\u90095\u4e2a\u503c\nselect=torch.index_select(a,1,index=torch.tensor(index,dtype=int))\nprint(index)\nprint(a.shape)\nprint(select.shape)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u7d22\u5f15\u5e8f\u5217\n[ 1  4 28  3  3]\n# \u539f\u59cb\u6570\u7ec4\ntorch.Size([4, 512, 28, 28])\n# \u7d22\u5f15\u540e\u7684\u6570\u7ec4\ntorch.Size([4, 5, 28, 28])\n</code></pre> <p>dim=1\uff0c\u76f8\u5f53\u4e8e\u5728\u7b2c\u4e8c\u4e2a\u7ef4\u5ea6\u4e2d\u8fdb\u884c\u9009\u62e9</p>"},{"location":"PyTorch/torch/torch.index_select/#torchindex_select","title":"torch.index_select\u4e0e\u76f4\u63a5\u7d22\u5f15\u7684\u533a\u522b","text":"<pre><code>import torch\na=torch.arange(40).view(2,4,5)\nindex=torch.tensor([1])\nselect_1=torch.index_select(a,dim=0,index=index)\nselect_2=a[0,:,:]\nprint(select_1)\nprint(select_2)\nprint(select_1.shape)\nprint(select_2.shape)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u5229\u7528torch.index_select\uff0c\u7ed3\u679c\ntensor([[[20, 21, 22, 23, 24],\n         [25, 26, 27, 28, 29],\n         [30, 31, 32, 33, 34],\n         [35, 36, 37, 38, 39]]])\n# \u76f4\u63a5\u8fdb\u884c\u7d22\u5f15\uff0c\u7ed3\u679c\ntensor([[ 0,  1,  2,  3,  4],\n        [ 5,  6,  7,  8,  9],\n        [10, 11, 12, 13, 14],\n        [15, 16, 17, 18, 19]])\n# \u5229\u7528torch.index_select\uff0c\u5f62\u72b6\ntorch.Size([1, 4, 5])\n# \u76f4\u63a5\u8fdb\u884c\u7d22\u5f15\uff0c\u5f62\u72b6\ntorch.Size([4, 5])\n</code></pre> <p>\u5bb9\u6613\u53d1\u73b0\uff0c\u76f4\u63a5\u8fdb\u884c\u7d22\u5f15\u548c\u5229\u7528torch.index_select\u7d22\u5f15\u6700\u5927\u7684\u533a\u522b\u5c31\u5728\u4e8e\uff1a\u76f4\u63a5\u8fdb\u884c\u7d22\u5f15\u6570\u7ec4\u7ef4\u6570\u4f1a\u964d\u4f4e\uff0c\u5229\u7528torch.index_select\u7d22\u5f15\u6570\u7ec4\u7ef4\u6570\u4e0d\u53d8\uff0c\u4e0b\u9762\u7684\u6848\u4f8b\u66f4\u5bb9\u6613\u7406\u89e3\u533a\u522b</p> <pre><code>import torch\na=torch.arange(40).view(2,4,5)\nselect_1=a[0,:,:]\nselect_2=a[0,0,:]\nselect_3=a[0,0,0]\nprint(select_1)\nprint(select_2)\nprint(select_3)\nprint(select_1.shape)\nprint(select_2.shape)\nprint(select_3.shape)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code>tensor([[ 0,  1,  2,  3,  4],\n        [ 5,  6,  7,  8,  9],\n        [10, 11, 12, 13, 14],\n        [15, 16, 17, 18, 19]])\ntensor([0, 1, 2, 3, 4])\ntensor(0)\ntorch.Size([4, 5])\ntorch.Size([5])\ntorch.Size([])\n</code></pre> <p>\u76f4\u63a5\u7d22\u5f15\u5c31\u662f\u4e00\u4e2a\u9010\u6b65\u903c\u8fd1\u7684\u8fc7\u7a0b\uff0c\u968f\u7740\u7ed9\u5b9a\u7684\u6570\u5b57\u8d8a\u591a(\u4ece\u7ed91\u4e2a\u5230\u7ed93\u4e2a)\uff0c\u7ef4\u6570\u8d8a\u5c0f(\u7ed3\u679c\u4ece2\u7ef4\u52300\u7ef4)\uff0c\u7ed3\u679c\u8303\u56f4\u8d8a\u7cbe\u786e\u3002\u800ctorch.index_select\u53ea\u80fd\u6cbf\u7740\u4e00\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u641c\u7d22\u67e5\u627e\uff0c\u76f8\u5f53\u4e8e\u5bf9\u6574\u4e2a\u6570\u7ec4\u8fdb\u884c\u7d22\u5f15\u3002</p>"},{"location":"PyTorch/torch/torch.index_select/#_5","title":"\u5b98\u65b9\u6587\u6863","text":"<p>torch.index_select()\uff1ahttps://pytorch.org/docs/stable/generated/torch.index_select.html?highlight=index_select</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e749\u670815\u65e5</p>"},{"location":"PyTorch/torch/torch.max/","title":"\u6570\u7ec4\u7684\u6700\u5927\u503c","text":"<p>torch.max()\u6709\u4e24\u79cd\u5f62\u5f0f</p>"},{"location":"PyTorch/torch/torch.max/#i","title":"\u5f62\u5f0f\u2160","text":"<pre><code>torch.max(input) \u2192 Tensor\n</code></pre> <p>\u529f\u80fd\uff1a\u8f93\u51fa\u6570\u7ec4\u7684\u6700\u5927\u503c</p> <p>\u6ce8\u610f\uff1a </p> <ul> <li>\u53ea\u6709\u4e00\u4e2a\u8f93\u5165\uff0c\u53ea\u9700\u8981\u8f93\u5165\u4e00\u4e2a\u6570\u7ec4</li> <li>\u8be5\u65b9\u5f0f\u4e5f\u53ef\u4ee5\u901a\u8fc7<code>a.max()</code>\u5b9e\u73b0\uff0c\u540e\u8005\u662f\u6c42\u6570\u7ec4<code>a</code>\u7684\u6700\u5927\u503c</li> </ul>"},{"location":"PyTorch/torch/torch.max/#ii","title":"\u5f62\u5f0f\u2161","text":"<pre><code>torch.max(input, dim, keepdim=False, *, out=None) -&gt; (Tensor, LongTensor)\n</code></pre> <p>\u529f\u80fd\uff1a\u6309\u6307\u5b9a\u7ef4\u5ea6\u5224\u65ad\uff0c\u8fd4\u56de\u6570\u7ec4\u7684\u6700\u5927\u503c\u4ee5\u53ca\u6700\u5927\u503c\u5904\u7684\u7d22\u5f15</p> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>input</code>\uff1a\u5f85\u5224\u5b9a\u7684\u6570\u7ec4</li> <li><code>dim</code>\uff1a\u7ed9\u5b9a\u7684\u7ef4\u5ea6</li> <li><code>keepdim</code>\uff1a\u5982\u679c\u6307\u5b9a\u4e3a<code>True</code>\uff0c\u5219\u8f93\u51fa\u7684\u5f20\u91cf\u6570\u7ec4\u7ef4\u6570\u548c\u8f93\u5165\u4e00\u81f4\uff0c\u5e76\u4e14\u9664\u4e86<code>dim</code>\u7ef4\u5ea6\u662f1\uff0c\u5176\u4f59\u7684\u7ef4\u5ea6\u5927\u5c0f\u548c\u8f93\u5165\u6570\u7ec4\u7ef4\u5ea6\u5927\u5c0f\u4e00\u81f4\u3002\u5982\u679c\u6539\u4e3a<code>False</code>\uff0c\u5219\u76f8\u5f53\u4e8e\u5c06<code>True</code>\u7684\u7ed3\u679c\u538b\u7f29\u4e86(\u5220\u53bb\u4e86\u5927\u5c0f\u662f1\u7684<code>dim</code>\u7ef4\u5ea6)\u3002\u4e24\u8005\u7684\u5dee\u522b\u5c31\u5728\u4e8e\u662f\u5426\u4fdd\u7559<code>dim</code>\u7ef4\u5ea6\u3002</li> </ul> <p>\u6ce8\u610f\uff1a</p> <ul> <li>\u5982\u679c\u5728\u6307\u5b9a\u7684\u7ef4\u5ea6\u4e2d\uff0c\u6709\u591a\u4e2a\u91cd\u590d\u7684\u6700\u5927\u503c\uff0c\u5219\u8fd4\u56de\u7b2c\u4e00\u4e2a\u6700\u5927\u503c\u7684\u7d22\u5f15</li> <li>\u8be5\u51fd\u6570\u8fd4\u56de\u7531\u6700\u5927\u503c\u4ee5\u53ca\u6700\u5927\u503c\u5904\u7684\u7d22\u5f15\u7ec4\u6210\u5143\u7ec4<code>(max,max_indices)</code></li> <li>\u8be5\u51fd\u6570\u4e5f\u53ef\u4ee5\u901a\u8fc7<code>a.max()</code>\u5b9e\u73b0\uff0c\u540e\u8005\u662f\u6c42\u6570\u7ec4<code>a</code>\u7684\u6700\u5927\u503c\uff0c\u53ea\u9700\u8981\u518d\u6307\u660e<code>dim</code>\u4ee5\u53ca<code>keepdim</code>\u5373\u53ef</li> <li>\u8f93\u51fa\u7684\u7d22\u5f15\u662f\u5bf9\u5e94\u7684<code>dim</code>\u7ef4\u5ea6\u4e0a\u7684\u7d22\u5f15\uff0c\u6ce8\u610f\u542b\u4e49\u3002</li> </ul> <p>\u4e0a\u8ff0\u4e24\u79cd\u51fd\u6570\u5f62\u5f0f\u672c\u8d28\u533a\u522b\u5c31\u662f\u6709\u6ca1\u6709\u6307\u51fa<code>dim</code>\uff0c\u5982\u679c\u672a\u6307\u51fa<code>dim</code>\uff0c\u5219\u8fd4\u56de\u6574\u4e2a\u6570\u7ec4\u7684\u6700\u5927\u503c\uff0c\u4e0d\u8fd4\u56de\u7d22\u5f15\u3002\u5982\u679c\u6307\u51fa\u4e86<code>dim</code>\uff0c\u5219\u5728\u6307\u5b9a\u7684\u7ef4\u5ea6\u4e0a\u641c\u7d22\u6700\u5927\u503c\uff0c\u8fd4\u56de\u6700\u5927\u503c\u4ee5\u53ca\u7d22\u5f15\u3002</p>"},{"location":"PyTorch/torch/torch.max/#_2","title":"\u4ee3\u7801\u6848\u4f8b","text":"<p>\u4e00\u822c\u7528\u6cd5</p> <pre><code>import torch\na=torch.arange(10).reshape(2,5)\nb=torch.max(a)\nc=torch.max(a,0)\nprint(a)\nprint(b)\nprint(c)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u539f\u6570\u7ec4\ntensor([[0, 1, 2, 3, 4],\n        [5, 6, 7, 8, 9]])\n# \u4e0d\u8f93\u5165dim\u65f6\uff0c\u8fd4\u56de\u6570\u7ec4\u7684\u6700\u5927\u503c\ntensor(9)\n# \u8f93\u5165dim\u65f6\uff0c\u8fd4\u56de\u6307\u5b9a\u7ef4\u5ea6\u7684\u6700\u5927\u503c\u53ca\u7d22\u5f15\ntorch.return_types.max(\n# \u7b2c\u4e00\u4e2a\u662f\u503c\uff0c\u6309dim=0\u6bd4\u8f83\u5f97\u5230\u7684\nvalues=tensor([5, 6, 7, 8, 9]),\n# \u7b2c\u4e8c\u4e2a\u662f\u503c\u5bf9\u5e94\u7684\u7d22\u5f15\uff0c\u5bf9\u5e94\u7ef4\u5ea6dim=0\u4e0a\u7684\u7d22\u5f15\nindices=tensor([1, 1, 1, 1, 1]))\n</code></pre> <p><code>keepdim</code>\u5b9a\u4e3a<code>True</code>\u6216\u8005<code>Flase</code>\u7684\u533a\u522b</p> <pre><code>import torch\na=torch.arange(10).reshape(2,5)\nb=torch.max(a,0,True)\nc=torch.max(a,0)\nprint(a.shape)\n# \u8fd9\u91cc\u5b9a\u4e3a0\u548c1\u90fd\u4e00\u6837\uff0c\u503c\u4e0e\u7d22\u5f15\u5177\u6709\u540c\u6837\u7684\u5f62\u72b6\nprint(b[0].shape)\nprint(c[0].shape)\n</code></pre> <p>\u8f93\u51fa\uff0c\u53ea\u6709\u7ef4\u5ea6\u4e0d\u540c</p> <pre><code>torch.Size([2, 5])\ntorch.Size([1, 5])\ntorch.Size([5])\n</code></pre> <p>\u4e0d\u540c\u7684<code>dim</code>\u5bf9\u7ed3\u679c\u7684\u5f71\u54cd\uff0c\u8fd9\u91cc\u4ee5<code>input</code>\u7684\u7ef4\u6570\u662f3\u4e3a\u4f8b\uff0c\u7ef4\u6570\u66f4\u591a\u7684\u53ef\u4ee5\u7c7b\u63a8\uff0c\u9996\u5148\u5b9a\u4e49\u597d\u6570\u7ec4<code>input</code>\u3002</p> <pre><code>import torch\na=torch.arange(32).reshape(2,4,4)\nprint(a)\n</code></pre> <pre><code>tensor([[[ 0,  1,  2,  3],\n         [ 4,  5,  6,  7],\n         [ 8,  9, 10, 11],\n         [12, 13, 14, 15]],\n\n        [[16, 17, 18, 19],\n         [20, 21, 22, 23],\n         [24, 25, 26, 27],\n         [28, 29, 30, 31]]])\n</code></pre> <p><code>dim</code>\u4e3a0</p> <pre><code>b=torch.max(a,0)\nprint(b)\n</code></pre> <p> <p></p> <p></p> <p>\u8f93\u51fa\uff1a</p> <pre><code>torch.return_types.max(\nvalues=tensor([[16, 17, 18, 19],\n        [20, 21, 22, 23],\n        [24, 25, 26, 27],\n        [28, 29, 30, 31]]),\nindices=tensor([[1, 1, 1, 1],\n        [1, 1, 1, 1],\n        [1, 1, 1, 1],\n        [1, 1, 1, 1]]))\n</code></pre> <p><code>dim</code>\u4e3a1</p> <pre><code>c=torch.max(a,1)\nprint(c)\n</code></pre> <p> <p></p> <p></p> <p>\u8f93\u51fa</p> <pre><code>torch.return_types.max(\nvalues=tensor([[12, 13, 14, 15],\n        [28, 29, 30, 31]]),\nindices=tensor([[3, 3, 3, 3],\n        [3, 3, 3, 3]]))\n</code></pre> <p><code>dim</code>\u4e3a2</p> <pre><code>d=torch.max(a,2)\nprint(d)\n</code></pre> <p> <p></p> <p></p> <p>\u8f93\u51fa</p> <pre><code>torch.return_types.max(\nvalues=tensor([[ 3,  7, 11, 15],\n        [19, 23, 27, 31]]),\nindices=tensor([[3, 3, 3, 3],\n        [3, 3, 3, 3]]))\n</code></pre>"},{"location":"PyTorch/torch/torch.max/#_3","title":"\u6269\u5c55","text":"<p>\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u7ecf\u5e38\u7528\u5230\u8be5\u51fd\u6570\uff0c<code>softmax</code>\u51fd\u6570\u8f93\u51fa\u5f97\u5230\u7684\u6982\u7387\u518d\u7ecf\u8fc7<code>torch.max</code>\u51fd\u6570\u5f97\u5230\u6700\u7ec8\u7684\u9884\u6d4b\u7ed3\u679c(\u9884\u6d4b\u7ed3\u679c\u4e00\u822c\u548c\u7d22\u5f15\u503c\u4e00\u4e00\u5bf9\u5e94\uff0c\u56e0\u6b64\u53ef\u4ee5\u7528\u7d22\u5f15\u503c\u6765\u8868\u793a\u9884\u6d4b\u7ed3\u679c)\uff0c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u4e0e\u6807\u7b7e\u505a\u6bd4\u8f83\uff0c\u5f97\u5230\u51c6\u786e\u7387\u3002</p> <pre><code>import numpy as np\nimport torch\n# \u5047\u8bbebatch_size=16\uff0c\u6bcf\u6279\u6b21\u670920\u4e2a\u6982\u7387\u503c(\u537320\u5206\u7c7b)\n# \u7f51\u7edc\u7ed3\u6784\u4f1a\u5f97\u523016\u884c20\u5217\u7684\u6570\u7ec4\na = torch.tensor(np.random.rand(16, 20))\n# \u7d22\u5f15\u53f7\u4ee3\u8868\u9884\u6d4b\u7ed3\u679c\npre = torch.max(a,dim=1)[1]\nprint(pre)\nprint(pre.shape)\n</code></pre> <p>\u8f93\u51fa\uff0c\u5171\u670916\u4e2a\u7ed3\u679c(\u5bf9\u5e94batch_size=16)</p> <pre><code>tensor([11, 10,  1,  9, 19, 19, 15, 14,  5,  2, 17, 14, 13, 15, 15, 17])\ntorch.Size([16])\n</code></pre>"},{"location":"PyTorch/torch/torch.max/#_4","title":"\u5b98\u65b9\u6587\u6863","text":"<p>torch.max()\uff1ahttps://pytorch.org/docs/stable/generated/torch.max.html?highlight=torch%20max#torch.max</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e749\u670819\u65e5</p>"},{"location":"PyTorch/torch/torch.mul/","title":"\u6570\u7ec4\u7684\u70b9\u4e58","text":"<pre><code>torch.mul(input, other, *, out=None)\n</code></pre> <p>\u8f93\u5165\uff1a\u4e24\u4e2a\u5f20\u91cf\u77e9\u9635\uff1b\u8f93\u51fa\uff1a\u4ed6\u4eec\u7684\u70b9\u4e58\u8fd0\u7b97\u7ed3\u679c</p> <p>\u7528\u9014\uff1a</p> <p>\u2460\u5b9e\u73b0\u4e24\u4e2a\u5f20\u91cf\u77e9\u9635\u7684\u70b9\u4e58\u8fd0\u7b97\uff0c\u53ef\u4ee5\u5b9e\u73b0\u5e7f\u64ad\u529f\u80fd(\u5177\u4f53\u89c1\u6848\u4f8b\u4ee3\u7801)\u3002</p> <p>\u2461\u5b9e\u73b0\u77e9\u9635\u7684\u6570\u503c\u4e58\u6cd5(\u4e00\u4e2a\u5e38\u6570k\u4e0e\u77e9\u9635\u505a\u4e58\u6cd5\uff0c\u5bf9\u5e94\u4e8e\u5e7f\u64ad\u673a\u5236)</p> <p>\u6ce8\u610f\uff1a</p> <ul> <li>\u82e5\u8f93\u5165\u7684\u4e24\u4e2a\u77e9\u9635\u5f62\u72b6\u4e0d\u4e00\u81f4\uff0c\u5219\u4f1a\u901a\u8fc7\u5e7f\u64ad\u529f\u80fd\u8fdb\u884c\u6570\u636e\u6269\u5145\uff0c\u7136\u540e\u518d\u8fdb\u884c\u70b9\u4e58</li> <li>\u6574\u6570\u77e9\u9635\u4e0e\u6d6e\u70b9\u6570\u77e9\u9635\u505a\u70b9\u4e58\uff0c\u7ed3\u679c\u662f\u6d6e\u70b9\u6570\u77e9\u9635</li> </ul>"},{"location":"PyTorch/torch/torch.mul/#_2","title":"\u6848\u4f8b\u4ee3\u7801\uff1a","text":"<p>\u2460\u666e\u901a\u70b9\u4e58</p> <pre><code>import torch \na=torch.tensor([[1,2,3],[4,5,6]])\nb=torch.tensor([[2,3,4],[5,6,7]])\nc=torch.mul(a,b)\nprint('a:',a)\nprint('b:',b)\nprint('c:',c)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code>a: tensor([[1, 2, 3],\n        [4, 5, 6]])\nb: tensor([[2, 3, 4],\n        [5, 6, 7]])\nc: tensor([[ 2,  6, 12],# \u7b2c\u4e00\u884c\u5bf9\u5e94\u70b9\u76f8\u4e58\n        [20, 30, 42]])# \u7b2c\u4e8c\u884c\u5bf9\u5e94\u70b9\u76f8\u4e58\n</code></pre> <p>\u2461\u82e5\u77e9\u9635\u5927\u5c0f\u4e0d\u4e00\u81f4\uff0c\u5219\u4f1a\u901a\u8fc7\u5e7f\u64ad\u673a\u5236\u8fdb\u884c\u6269\u5145</p> <pre><code>import torch \na=torch.tensor([[1,2,3],[4,5,6]])\nb=torch.tensor([2,3,4])\nc=torch.mul(a,b)\nprint('a:',a)\nprint('b:',b)\nprint('c:',c)\n</code></pre> <p>\u8f93\u51fa:</p> <pre><code>a: tensor([[1, 2, 3],\n        [4, 5, 6]])\nb: tensor([2, 3, 4])\nc: tensor([[ 2,  6, 12],# b\u4e0a\u7684\u5143\u7d20\u540c\u65f6\u4e0ea\u91cc\u9762\u4e24\u4e2a\u5143\u7d20\u505a\u70b9\u4e58\n        [ 8, 15, 24]])\n</code></pre> <p>\u518d\u770b\u4e00\u4e2a\u4f8b\u5b50\uff1a</p> <pre><code>import torch\nmat_1=t.arange(8*512*14*14).reshape((8,512,14,14))\nmat_2=t.arange(14*14).reshape(14,14)\nmat_3=torch.mul(mat_1,mat_2)\nprint(mat_1.shape)\nprint(mat_2.shape)\nprint(mat_3)\nprint(mat_3.shape)\n</code></pre> <p>\u8f93\u51fa\uff1a</p> <pre><code>torch.Size([8, 512, 14, 14])\ntorch.Size([14, 14])\ntorch.Size([8, 512, 14, 14])\n</code></pre> <p>\u6ce8\uff1a\u5e7f\u64ad\u673a\u5236\u76f8\u5f53\u4e8e\u505a\u4e86\u4e00\u4e2a\u590d\u5236\u6269\u5145\u5904\u7406\uff0c\u5982\u4e0a\u4e2a\u6848\u4f8b\u4e2d\u7684mat_2\u4ece\u4e24\u7ef4\u6269\u5145\u5230\u4e86\u56db\u7ef4\uff0c\u5e76\u4e14\u5728\u7b2c\u4e00\u7ef4\u5ea6\u590d\u5236\u4e868\u6b21\uff0c\u7b2c\u4e8c\u7ef4\u5ea6\u590d\u5236\u4e86512\u6b21\uff0c\u7136\u540e\u518d\u4e0emat_1\u505a\u70b9\u4e58\u8fd0\u7b97\u3002</p>"},{"location":"PyTorch/torch/torch.mul/#_3","title":"\u5e7f\u64ad\u673a\u5236\u6761\u4ef6\uff1a","text":"<p>\u2460\u4e24\u4e2a\u6570\u7ec4\u7684\u7ef4\u6570\u4e0d\u76f8\u7b49\uff0c\u4f46\u662f\u5b83\u4eec\u7684\u540e\u7f18\u7ef4\u5ea6\u7684\u8f74\u957f\u76f8\u7b26(\u4ece\u672b\u5c3e\u5f00\u59cb\u7b97\u8d77\u7684\u7ef4\u5ea6)(\u5373\u4e0a\u4e2a\u6848\u4f8b) \u2461\u4e24\u4e2a\u77e9\u9635\u4e2d\u5bf9\u5e94\u7684(\u4ece\u540e\u5411\u524d\u5bf9\u5e94)\u7ef4\u5ea6\u7684\u5c3a\u5bf8\u5927\u5c0f\u76f8\u7b49(mat_1\u4e0emat_2\u5728\u540e\u4e24\u4e2a\u7ef4\u5ea6\u5927\u5c0f\u5747\u662f14)\uff0c\u82e5\u4e0d\u76f8\u7b49\uff0c\u5219\u5fc5\u987b\u6709\u4e00\u65b9\u5728\u8be5\u7ef4\u5ea6\u4e0a\u5c3a\u5bf8\u5927\u5c0f\u662f1\u3002(\u6bd4\u5982\u4e0a\u4e2a\u6848\u4f8b\u4e2d\uff0c\u82e5mat_2\u5c3a\u5bf8\u4e3a[1,14,14]\uff0c\u5219\u4ecd\u53ef\u4ee5\u901a\u8fc7\u5e7f\u64ad\u673a\u5236\u8fdb\u884c\u6269\u5145\u8fd0\u7b97\uff0c\u7ed3\u679c\u4e0e\u4e0a\u8ff0\u6848\u4f8b\u76f8\u540c)</p> <p>\u6848\u4f8b\uff1a <pre><code>import torch\nmat_1=t.arange(8*512*14*14).reshape((8,512,14,14))\nmat_2=t.arange(2*14*14).reshape(2,14,14)\nmat_3=torch.mul(mat_1,mat_2)\n</code></pre> \u62a5\u9519: RuntimeError: The size of tensor a (512) must match the size of tensor b (2) at non-singleton dimension 1</p> <p>\u539f\u56e0\uff1a2\u4e0e512\u5c3a\u5bf8\u5927\u5c0f\u4e0d\u540c\uff0c\u5e76\u4e14\u5c3a\u5bf8\u90fd\u4e0d\u662f1</p>"},{"location":"PyTorch/torch/torch.mul/#_4","title":"\u6269\u5c55","text":"<p>\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u9886\u57df\u4e2d\uff0ctorch.mul\u5e38\u7528\u4e8e\u7279\u5f81\u56fe\u4e0e\u6ce8\u610f\u529b\u56fe\u7684\u76f8\u4e58\uff0c\u7279\u5f81\u56fe\u76f8\u5f53\u4e8e\u4e0a\u8ff0\u6848\u4f8b\u7684mat_1(batch_size=4\uff0c512\u5f2014\u00d714\u7684\u7279\u5f81\u56fe)\uff0c\u6ce8\u610f\u529b\u56fe\u76f8\u5f53\u4e8e\u4e0a\u8ff0\u6848\u4f8b\u7684mat_2(14\u00d714)\u3002\u5148\u5c06\u6ce8\u610f\u529b\u56fe\u590d\u5236512\u6b21\uff0c\u548c\u539f\u6765\u6bcf\u4e2a\u6279\u6b21\u4e2d\u7279\u5f81\u56fe\u5c3a\u5bf8\u76f8\u5339\u914d\uff0c\u518d\u6574\u4f53\u590d\u52364\u6b21\uff0c\u5bf9\u5e944\u7ec4\u7279\u5f81\u56fe\uff0c\u6700\u540e\u505a\u70b9\u4e58\u8fd0\u7b97\u3002</p>"},{"location":"PyTorch/torch/torch.mul/#_5","title":"\u5b98\u65b9\u6587\u6863","text":"<p>torch.mul():https://pytorch.org/docs/stable/generated/torch.mul.html?highlight=mul#torch.mul</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e749\u670813\u65e5</p>"},{"location":"PyTorch/torch/torch.nonzero/","title":"\u6570\u7ec4\u7684\u975e\u96f6\u5143\u7d20\u5b9a\u4f4d","text":"<pre><code>torch.nonzero(input, *, out=None, as_tuple=False) \u2192 LongTensor or tuple of LongTensors\n</code></pre> <p>\u529f\u80fd\uff1a\u7528\u4e8e\u8f93\u51fa\u6570\u7ec4\u7684\u975e\u96f6\u503c\u7684\u7d22\u5f15\uff0c\u5373\u7528\u6765\u5b9a\u4f4d\u6570\u7ec4\u4e2d\u975e\u96f6\u7684\u5143\u7d20</p> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>input</code>\uff1a\u8f93\u5165\u7684\u6570\u7ec4</li> <li><code>as_tuple</code>\uff1a\u5982\u679c\u8bbe\u4e3a<code>False</code>\uff0c\u5219\u8fd4\u56de\u4e00\u4e2a\u4e8c\u7ef4\u5f20\u91cf\uff0c\u5176\u4e2d\u6bcf\u4e00\u884c\u90fd\u662f\u975e\u96f6\u503c\u7684\u7d22\u5f15\uff0c\u5982\u679c\u8f93\u5165\u7684\u6570\u7ec4\u6709n\u7ef4\uff0c\u5219\u8f93\u51fa\u7684\u5f20\u91cf\u7ef4\u5ea6\u5927\u5c0f\u4e3az\u00d7n\uff0c\u5176\u4e2dz\u4e3a<code>input</code>\u975e\u96f6\u5143\u7d20\u7684\u603b\u6570\uff1b\u5982\u679c\u8bbe\u4e3a<code>True</code>\uff0c\u5219\u8fd4\u56de\u4e00\u4e2a\u7531\u4e00\u7ef4\u5f20\u91cf\u7ec4\u6210\u7684\u5143\u7ec4\uff0c\u5982\u679c\u8f93\u5165\u6570\u7ec4\u4e3an\u7ef4\uff0c\u5219\u6709n\u4e2a\u4e00\u7ef4\u5f20\u91cf\uff0c\u6bcf\u4e2a\u4e00\u7ef4\u5f20\u91cf\u5bf9\u5e94\u975e\u96f6\u5143\u7d20\u7279\u5b9a\u7ef4\u5ea6\u7684\u7d22\u5f15(\u7b2c\u4e00\u4e2a\u5f20\u91cf\u6570\u7ec4\u50a8\u5b58\u7684\u662f\u6240\u6709\u975e\u96f6\u5143\u7d20\u7b2c\u4e00\u7ef4\u5ea6\u7684\u7d22\u5f15)\uff0c\u5e76\u4e14\u6bcf\u4e2a\u5f20\u91cf\u91cc\u9762\u6709z\u4e2a\u6570\uff0c\u5176\u4e2dz\u4e3a\u8f93\u5165\u6570\u7ec4\u975e\u96f6\u5143\u7d20\u7684\u4e2a\u6570\u3002</li> </ul> <p>\u6ce8\u610f\uff1a</p> <ul> <li><code>torch.nonzero</code>\u4e5f\u53ef\u4ee5\u901a\u8fc7<code>tensor.nonzero</code>\u7684\u65b9\u5f0f\u8c03\u7528</li> </ul> <p>\u5177\u4f53\u7528\u6cd5\u53ef\u89c1\u4e0b\u9762\u7684\u4ee3\u7801\u6848\u4f8b</p>"},{"location":"PyTorch/torch/torch.nonzero/#_2","title":"\u4ee3\u7801\u6848\u4f8b","text":"<p>\u4e00\u822c\u7528\u6cd5</p> <pre><code>import torch\nimport numpy as np\n# \u4ece0\uff0c1\u4e4b\u95f4\u968f\u673a\u900920\u4e2a\u6570\na=torch.from_numpy(np.random.choice(2,20)).reshape(4,5)\nb=torch.nonzero(a)\nprint(a)\nprint(b)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u539f\u6570\u7ec4\ntensor([[0, 0, 0, 0, 0],\n        [1, 0, 0, 0, 0],\n        [1, 0, 1, 0, 1],\n        [1, 0, 0, 0, 0]], dtype=torch.int32)\n# \u9ed8\u8ba4\u60c5\u51b5\u4e0bas_tuple\u4e3aFalse\uff0c\u4e8c\u7ef4\u5f20\u91cf\u6570\u7ec4\ntensor([[1, 0],\n        [2, 0],\n        [2, 2],\n        [2, 4],\n        [3, 0]])\n</code></pre> <p>as_tuple\u8bbe\u4e3aTrue\u4e0eFalse\u7684\u533a\u522b</p> <pre><code>import torch\nimport numpy as np\n# \u4ece0\uff0c1\u4e4b\u95f4\u968f\u673a\u900912\u4e2a\u6570\na=torch.from_numpy(np.random.choice(2,12)).reshape(2,2,3)\nb=torch.nonzero(a,as_tuple=False)\nc=torch.nonzero(a,as_tuple=True)\nprint(a)\nprint(b)\nprint(c)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u539f\u6570\u7ec4\ntensor([[[0, 0, 1],\n         [0, 0, 1]],\n\n        [[1, 1, 0],\n         [1, 0, 0]]], dtype=torch.int32)\n# as_tuple\u8bbe\u4e3aFalse\u65f6\uff0c\u8fd4\u56de\u4e00\u4e2a\u4e8c\u7ef4\u6570\u7ec4\n# \u884c\u4ee3\u8868\u4e0d\u540c\u7684\u975e\u96f6\u5143\u7d20\u70b9\uff0c\u5217\u4ee3\u8868\u5750\u6807\n# \u7531\u4e8e\u662f\u4e09\u7ef4\u6570\u7ec4\uff0c\u6240\u4ee5\u6709\u4e09\u5217\uff0c\u6bcf\u5217\u5bf9\u5e94\u4e09\u4e2a\u7ef4\u5ea6\ntensor([[0, 0, 2],\n        [0, 1, 2],\n        [1, 0, 0],\n        [1, 0, 1],\n        [1, 1, 0]])\n# as_tuple\u8bbe\u4e3aFalse\u65f6\uff0c\u8fd4\u56de\u4e00\u4e2a\u5143\u7ec4\n# \u8fd9\u91cc\u8f93\u5165\u6570\u7ec4\u662f\u4e09\u7ef4\uff0c\u6240\u4ee5\u5143\u7ec4\u91cc\u9762\u6709\u4e09\u4e2a\u4e00\u7ef4\u6570\u7ec4\n# \u7b2c\u4e00\u4e2a\u4e00\u7ef4\u6570\u7ec4\u4ee3\u8868\u539f\u6570\u7ec4\u7684\u7b2c\u4e00\u7ef4\u5ea6\uff0c\u540e\u9762\u4e00\u6b21\u7c7b\u63a8\n# \u7b2c\u4e00\u4e2a\u4e00\u7ef4\u6570\u7ec4\u7684\u7b2c\u4e00\u4e2a\u5143\u7d20\u4ee3\u8868\u7b2c\u4e00\u4e2a\u975e\u96f6\u5143\u7d20\u7684\u7b2c\u4e00\u7ef4\u5ea6\u5750\u6807\uff0c\u540e\u9762\u4f9d\u6b21\u7c7b\u63a8\n(tensor([0, 0, 1, 1, 1]), tensor([0, 1, 0, 0, 1]), tensor([2, 2, 0, 1, 0]))\n</code></pre> <p>\u5e38\u7528\u4e8e\u7279\u5b9a\u6570\u7ec4\u5143\u7d20\u7684\u5b9a\u4f4d\u64cd\u4f5c</p> <pre><code>import torch\na=torch.arange(20).reshape(4,5)\n# \u8f93\u51fa\u6570\u7ec4a\u4e2d\uff0c\u6570\u503c\u4e3a5\u7684\u5143\u7d20\u7d22\u5f15\nb=torch.nonzero(a==5)\nprint(a)\nprint(b)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u539f\u6570\u7ec4\ntensor([[ 0,  1,  2,  3,  4],\n        [ 5,  6,  7,  8,  9],\n        [10, 11, 12, 13, 14],\n        [15, 16, 17, 18, 19]])\n# \u6570\u503c\u4e3a5\u7684\u5143\u7d20\u7d22\u5f15\ntensor([[1, 0]])\n</code></pre>"},{"location":"PyTorch/torch/torch.nonzero/#_3","title":"\u5b98\u65b9\u6587\u6863","text":"<p>torch.nonzero\uff1ahttps://pytorch.org/docs/stable/generated/torch.nonzero.html?highlight=torch%20nonzero#torch.nonzero</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e7410\u67084\u65e5</p>"},{"location":"PyTorch/torch/torch.repeat_interleave_tensor.repeat/","title":"\u6570\u7ec4\u7684\u91cd\u590d","text":""},{"location":"PyTorch/torch/torch.repeat_interleave_tensor.repeat/#torchrepeat_interleave","title":"torch.repeat_interleave","text":"<pre><code>torch.repeat_interleave(input, repeats, dim=None) \u2192 Tensor\n</code></pre> <p>\u529f\u80fd\uff1a\u6cbf\u7740\u6307\u5b9a\u7684\u7ef4\u5ea6\u91cd\u590d\u6570\u7ec4\u7684\u5143\u7d20</p> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>input</code>\uff1a\u6307\u5b9a\u7684\u6570\u7ec4</li> <li><code>repeats</code>\uff1a\u6bcf\u4e2a\u5143\u7d20\u91cd\u590d\u7684\u6b21\u6570\uff0c\u53ef\u4ee5\u662f\u5f20\u91cf\u6216\u8005\u662f\u6570\u7ec4</li> <li><code>dim</code>\uff1a\u6307\u5b9a\u7684\u7ef4\u5ea6</li> </ul> <p>\u6ce8\u610f\uff1a</p> <ul> <li> <p>\u5982\u679c\u4e0d\u6307\u5b9a<code>dim</code>\uff0c\u5219\u9ed8\u8ba4\u5c06\u8f93\u5165\u6570\u7ec4\u6241\u5e73\u5316(\u7ef4\u6570\u662f1\uff0c\u56e0\u6b64\u8fd9\u65f6<code>repeats</code>\u5fc5\u987b\u662f\u4e00\u4e2a\u6570\uff0c\u4e0d\u80fd\u662f\u6570\u7ec4)\uff0c\u5e76\u4e14\u8fd4\u56de\u4e00\u4e2a\u6241\u5e73\u5316\u7684\u8f93\u51fa\u6570\u7ec4</p> </li> <li> <p>\u8fd4\u56de\u7684\u6570\u7ec4\u4e0e\u8f93\u5165\u6570\u7ec4\u7ef4\u6570\u76f8\u540c\uff0c\u5e76\u4e14\u9664\u4e86\u7ed9\u5b9a\u7684\u7ef4\u5ea6<code>dim</code>\uff0c\u5176\u4ed6\u7ef4\u5ea6\u5927\u5c0f\u4e0e\u8f93\u5165\u6570\u7ec4\u76f8\u5e94\u7ef4\u5ea6\u5927\u5c0f\u76f8\u540c</p> </li> <li> <p><code>repeats</code>\uff1a\u5982\u679c\u4f20\u5165\u6570\u7ec4\uff0c\u5219\u5fc5\u987b\u662f<code>tensor</code>\u683c\u5f0f\u3002\u5e76\u4e14\u53ea\u80fd\u662f\u4e00\u7ef4\u6570\u7ec4\uff0c\u6570\u7ec4\u957f\u5ea6\u4e0e\u8f93\u5165\u6570\u7ec4<code>input</code>\u7684<code>dim</code>\u7ef4\u5ea6\u5927\u5c0f\u76f8\u540c\uff0c\u8f93\u5165\u6570\u7ec4\u7684\u5177\u4f53\u610f\u4e49\u5982\u4e0b\uff1a   $$   \u5982\u679crepeats=[n_1,n_2,\\dots,n_m],\u5219\u8f93\u51fa[x_1,x_1,\\dots,x_1,x_2,x_2,\\dots,x_m]\\\\\u5176\u4e2d\uff0cx_1\u91cd\u590dn_1\u6b21\uff0cx_2\u91cd\u590dn_2\u6b21\uff0cx_m\u91cd\u590dn_m\u6b21   $$ </p> </li> </ul>"},{"location":"PyTorch/torch/torch.repeat_interleave_tensor.repeat/#_2","title":"\u6848\u4f8b\u4ee3\u7801","text":"<p>\u4e00\u822c\u7528\u6cd5</p> <pre><code>import torch\na=torch.arange(10).view(2,5)\nb=torch.repeat_interleave(a,3,dim=0)\nc=torch.repeat_interleave(a,3,dim=1)\nprint(a)\nprint(b)\nprint(c)\nprint(a.shape)\nprint(b.shape)\nprint(c.shape)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u539f\u6570\u7ec4\ntensor([[0, 1, 2, 3, 4],\n        [5, 6, 7, 8, 9]])\n# \u6cbf\u7b2c\u4e00\u7ef4\u5ea6\u91cd\u590d\u540e\u7684\u6570\u7ec4\ntensor([[0, 1, 2, 3, 4],\n        [0, 1, 2, 3, 4],\n        [0, 1, 2, 3, 4],\n        [5, 6, 7, 8, 9],\n        [5, 6, 7, 8, 9],\n        [5, 6, 7, 8, 9]])\n# \u6cbf\u7b2c\u4e8c\u7ef4\u5ea6\u91cd\u590d\u540e\u7684\u6570\u7ec4\ntensor([[0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4],\n        [5, 5, 5, 6, 6, 6, 7, 7, 7, 8, 8, 8, 9, 9, 9]])\n# \u539f\u6570\u7ec4\u5f62\u72b6\ntorch.Size([2, 5])\n# \u6cbf\u7b2c\u4e00\u7ef4\u5ea6\u91cd\u590d\u540e\u7684\u5f62\u72b6\ntorch.Size([6, 5])\n# \u6cbf\u7b2c\u4e8c\u7ef4\u5ea6\u91cd\u590d\u540e\u7684\u5f62\u72b6\ntorch.Size([2, 15])\n</code></pre> <p>\u5f53\u4e0d\u6307\u5b9a<code>dim</code>\u65f6</p> <pre><code>import torch\na=torch.arange(10).view(2,5)\nb=torch.repeat_interleave(a,2)\nprint(a)\nprint(b)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u539f\u6570\u7ec4\ntensor([[0, 1, 2, 3, 4],\n        [5, 6, 7, 8, 9]])\n# \u4e0d\u6307\u5b9adim\u65f6\u91cd\u590d\u4e24\u6b21\ntensor([0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9])\n</code></pre> <p>\u5f53<code>repeats</code>\u4e3a\u6570\u7ec4\u683c\u5f0f\u65f6</p> <pre><code>import torch\na=torch.arange(10).view(2,5)\nb=torch.repeat_interleave(a,torch.tensor([2,3]),dim=0)\nprint(a)\nprint(b)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u539f\u6570\u7ec4\ntensor([[0, 1, 2, 3, 4],\n        [5, 6, 7, 8, 9]])\n# \u7b2c\u4e00\u884c\u91cd\u590d\u4e24\u6b21\uff0c\u7b2c\u4e8c\u884c\u91cd\u590d\u4e09\u6b21\ntensor([[0, 1, 2, 3, 4],\n        [0, 1, 2, 3, 4],\n        [5, 6, 7, 8, 9],\n        [5, 6, 7, 8, 9],\n        [5, 6, 7, 8, 9]])\n</code></pre> <p>\u5982\u679c<code>repeats</code>\u4e3a\u6570\u7ec4\uff0c\u4f46\u662f\u5927\u5c0f\u548c\u8f93\u5165\u7684<code>dim</code>\u5927\u5c0f\u4e0d\u5339\u914d\uff0c\u5219\u4f1a\u62a5\u9519</p> <pre><code>import torch\na=torch.arange(10).view(2,5)\nb=torch.repeat_interleave(a,torch.tensor([2,3]),dim=1)\nprint(a)\nprint(b)\n</code></pre> <p>\u8f93\u51fa\u62a5\u9519\uff0cRuntimeError\uff1a</p> <pre><code>---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n&lt;ipython-input-18-c8f2c85e38df&gt; in &lt;module&gt;\n      1 import torch\n      2 a=torch.arange(10).view(2,5)\n----&gt; 3 b=torch.repeat_interleave(a,torch.tensor([2,3]),dim=1)\n      4 print(a)\n      5 print(b)\n\nRuntimeError: repeats must have the same size as input along dim\n</code></pre>"},{"location":"PyTorch/torch/torch.repeat_interleave_tensor.repeat/#torchtensorrepeat","title":"torch.Tensor.repeat","text":"<pre><code>Tensor.repeat(*sizes) \u2192 Tensor\n</code></pre> <p>\u529f\u80fd\uff1a\u6cbf\u6bcf\u4e2a\u7ef4\u5ea6\u91cd\u590d\u5f20\u91cf\u6570\u7ec4</p> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>sizes</code>\uff1a\u6cbf\u6bcf\u4e2a\u7ef4\u5ea6\u91cd\u590d\u6b64\u5f20\u91cf\u7684\u6b21\u6570</li> </ul> <p>\u6ce8\u610f\uff1a</p> <ul> <li><code>sizes</code>\u957f\u5ea6\u5fc5\u987b\u5927\u4e8e\u7b49\u4e8e\u88ab\u91cd\u590d\u6570\u7ec4<code>tensor</code>\u7684\u7ef4\u6570(\u5982\u679c<code>tensor</code>\u7684\u7ef4\u6570\u662f2\uff0c\u5219<code>sizes</code>\u5c31\u5fc5\u987b\u5927\u4e8e\u7b49\u4e8e2)</li> </ul>"},{"location":"PyTorch/torch/torch.repeat_interleave_tensor.repeat/#_3","title":"\u4ee3\u7801\u6848\u4f8b","text":"<pre><code>import torch\na=torch.arange(10).view(2,5)\nb=a.repeat(2,3,2)\nprint(a)\nprint(b)\nprint(a.shape)\nprint(b.shape)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u539f\u6570\u7ec4\ntensor([[0, 1, 2, 3, 4],\n        [5, 6, 7, 8, 9]])\n# \u91cd\u590d\u540e\u7684\u6570\u7ec4\ntensor([[[0, 1, 2, 3, 4, 0, 1, 2, 3, 4],\n         [5, 6, 7, 8, 9, 5, 6, 7, 8, 9],\n         [0, 1, 2, 3, 4, 0, 1, 2, 3, 4],\n         [5, 6, 7, 8, 9, 5, 6, 7, 8, 9],\n         [0, 1, 2, 3, 4, 0, 1, 2, 3, 4],\n         [5, 6, 7, 8, 9, 5, 6, 7, 8, 9]],\n\n        [[0, 1, 2, 3, 4, 0, 1, 2, 3, 4],\n         [5, 6, 7, 8, 9, 5, 6, 7, 8, 9],\n         [0, 1, 2, 3, 4, 0, 1, 2, 3, 4],\n         [5, 6, 7, 8, 9, 5, 6, 7, 8, 9],\n         [0, 1, 2, 3, 4, 0, 1, 2, 3, 4],\n         [5, 6, 7, 8, 9, 5, 6, 7, 8, 9]]])\n# \u539f\u6570\u7ec4\u5f62\u72b6\ntorch.Size([2, 5])\n# \u91cd\u590d\u540e\u7684\u6570\u7ec4\u5f62\u72b6\ntorch.Size([2, 6, 10])\n</code></pre> <p>\u5982\u679c<code>sizes</code>\u957f\u5ea6\u5c0f\u4e8e<code>tensor</code>\u7684\u7ef4\u6570\uff0c\u5219\u4f1a\u62a5\u9519</p> <pre><code>import torch\na=torch.arange(10).view(2,5)\nb=a.repeat(2)\n</code></pre> <p>\u8f93\u51fa\u62a5\u9519</p> <pre><code>---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n&lt;ipython-input-33-19a278098c7c&gt; in &lt;module&gt;\n      1 import torch\n      2 a=torch.arange(10).view(2,5)\n----&gt; 3 b=a.repeat(2)\n\nRuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor\n</code></pre>"},{"location":"PyTorch/torch/torch.repeat_interleave_tensor.repeat/#_4","title":"\u533a\u522b","text":"<p>\u4e24\u4e2a\u51fd\u6570\u65b9\u6cd5\u6700\u5927\u7684\u533a\u522b\u5c31\u662f<code>repeat_interleave</code>\u662f\u4e00\u4e2a\u5143\u7d20\u4e00\u4e2a\u5143\u7d20\u5730\u91cd\u590d\uff0c\u800c<code>repeat</code>\u662f\u4e00\u7ec4\u5143\u7d20\u4e00\u7ec4\u5143\u7d20\u5730\u91cd\u590d</p>"},{"location":"PyTorch/torch/torch.repeat_interleave_tensor.repeat/#_5","title":"\u5b98\u65b9\u6587\u6863","text":"<p>torch.repeat_interleave():https://pytorch.org/docs/stable/generated/torch.repeat_interleave.html#torch.repeat_interleave</p> <p>torch.tensor.repeat():https://pytorch.org/docs/stable/generated/torch.Tensor.repeat.html#torch.Tensor.repeat</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e749\u670820\u65e5</p>"},{"location":"PyTorch/torch/torch.squeeze_torch.unsqueeze/","title":"\u6570\u7ec4\u7684\u538b\u7f29\u4e0e\u89e3\u538b","text":""},{"location":"PyTorch/torch/torch.squeeze_torch.unsqueeze/#torchsqueeze","title":"torch.squeeze()","text":"<pre><code>torch.squeeze(input, dim=None, *, out=None) \u2192 Tensor\n</code></pre> <p>\u529f\u80fd\uff1a\u5c06\u5c3a\u5bf8\u5927\u5c0f\u4e3a1\u7684\u7ef4\u5ea6\u8fdb\u884c\u5220\u9664\u64cd\u4f5c\u3002</p> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>input</code>\uff1a\u9700\u8981\u5220\u9664\u7684\u5f20\u91cf\u6570\u7ec4</li> <li><code>dim</code>\uff1a\u5728\u6307\u5b9a\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u5220\u9664\u64cd\u4f5c</li> </ul> <p>\u6ce8\u610f\uff1a</p> <ul> <li>\u82e5\u4e0d\u6307\u5b9a<code>dim</code>\uff0c\u5219\u9ed8\u8ba4\u5c06\u6240\u6709\u5c3a\u5bf8\u5927\u5c0f\u4e3a1\u7684\u7ef4\u5ea6\u5220\u9664\uff1b\u82e5\u6307\u5b9a<code>dim</code>\uff0c\u5219\u53ea\u5728\u6307\u5b9a\u7684\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u5220\u9664\u64cd\u4f5c\u3002</li> <li>\u8fd4\u56de\u7684\u5f20\u91cf\u4e0e\u8f93\u5165\u7684\u5f20\u91cf\u5171\u4eab\u5b58\u50a8\uff0c\u56e0\u6b64\u66f4\u6539\u4e00\u4e2a\u6570\u7ec4\u7684\u6570\u636e\u5185\u5bb9\uff0c\u5c06\u4f1a\u66f4\u6539\u53e6\u4e00\u4e2a\u6570\u7ec4\u3002</li> <li>torch.squeeze\u4e0ea.squeeze\u4f7f\u7528\u6548\u679c\u4e00\u6837\uff0c\u53ea\u662f\u540e\u8005\u9ed8\u8ba4\u5728\u6570\u7ec4a\u4e0a\u8fdb\u884c\u64cd\u4f5c\u3002</li> </ul>"},{"location":"PyTorch/torch/torch.squeeze_torch.unsqueeze/#_2","title":"\u4ee3\u7801\u6848\u4f8b","text":"<pre><code>import torch\na=torch.arange(5).view(1,5,1)\nb=torch.squeeze(a)\nprint(a)\nprint(b)\nprint(a.shape)\nprint(b.shape)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u538b\u7f29\u524d\ntensor([[[0],\n         [1],\n         [2],\n         [3],\n         [4]]])\n# \u538b\u7f29\u540e\ntensor([0, 1, 2, 3, 4])\n# \u538b\u7f29\u524d\u5c3a\u5bf8\ntorch.Size([1, 5, 1])\n# \u538b\u7f29\u540e\u5c3a\u5bf8\ntorch.Size([5])\n</code></pre> <p>\u53ef\u89c1\uff0c\u82e5\u4e0d\u6307\u5b9a<code>dim</code>\uff0c\u5219\u4f1a\u5c06\u6240\u6709\u5c3a\u5bf8\u5927\u5c0f\u4e3a1\u7684\u7ef4\u5ea6\u5168\u90e8\u5220\u9664\u3002</p> <p>\u6307\u5b9a<code>dim</code>\u65f6\uff0c\u53ea\u4f1a\u5728\u8be5<code>dim</code>\u4e0a\u8fdb\u884c\u64cd\u4f5c\u3002</p> <pre><code>import torch\na=torch.arange(5).view(5,1)\nb=a.squeeze(dim=0)\nc=a.squeeze(dim=1)\nprint(a)\nprint(b)\nprint(c)\nprint(a.shape)\nprint(b.shape)\nprint(c.shape)\n# \u5b58\u50a8\u5171\u4eab\u6d4b\u8bd5\nc[0]=9\nprint(a)\nprint(c)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u539f\u6570\u7ec4\ntensor([[0],\n        [1],\n        [2],\n        [3],\n        [4]])\n# dim\u8bbe\u4e3a0\u65f6\ntensor([[0],\n        [1],\n        [2],\n        [3],\n        [4]])\n# dim\u8bbe\u4e3a1\u65f6\ntensor([0, 1, 2, 3, 4])\n# \u539f\u6570\u7ec4\u5c3a\u5bf8\ntorch.Size([5, 1])\n# dim\u8bbe\u4e3a0\u65f6\u5c3a\u5bf8\ntorch.Size([5, 1])\n# dim\u8bbe\u4e3a1\u65f6\u5c3a\u5bf8\ntorch.Size([5])\n\n# \u5f53c\u88ab\u4fee\u6539\u65f6\uff0ca\u76f8\u5e94\u4f4d\u7f6e\u7684\u6570\u636e\u4e5f\u4f1a\u88ab\u4fee\u6539\ntensor([[9],\n        [1],\n        [2],\n        [3],\n        [4]])\ntensor([9, 1, 2, 3, 4])\n</code></pre> <p>\u5982\u679c\u6307\u5b9a\u7684\u7ef4\u5ea6\u4e0a\u5c3a\u5bf8\u4e0d\u662f1\uff0c\u5219\u4e0d\u8fdb\u884c\u64cd\u4f5c\uff1b\u5982\u679c\u6307\u5b9a\u7684\u7ef4\u5ea6\u4e0a\u5c3a\u5bf8\u662f1\uff0c\u5219\u53ea\u5220\u9664\u8be5\u7ef4\u5ea6\u3002\u538b\u7f29\u540e\u7684\u6570\u636e\u5982\u679c\u4fee\u6539\u4e86\u67d0\u4e2a\u6570\u636e\uff0c\u5219\u4e5f\u4f1a\u5728\u539f\u6570\u7ec4\u76f8\u5e94\u4f4d\u7f6e\u8fdb\u884c\u4fee\u6539\u3002</p>"},{"location":"PyTorch/torch/torch.squeeze_torch.unsqueeze/#torchunsqueeze","title":"torch.unsqueeze()","text":"<pre><code>torch.unsqueeze(input, dim) \u2192 Tensor\n</code></pre> <p>\u529f\u80fd\uff1a\u5728\u6307\u5b9a\u7684\u7ef4\u5ea6\u4e0a\uff0c\u63d2\u5165\u5c3a\u5bf8\u5927\u5c0f\u4e3a1\u7684\u7ef4\u5ea6(\u76f8\u5f53\u4e8e\u662f<code>squeeze</code>\u7684\u9006\u8fd0\u7b97)</p> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>input</code>\uff1a\u8f93\u5165\u5f20\u91cf</li> <li><code>dim</code>\uff1a\u6307\u5b9a\u7684\u7ef4\u5ea6</li> </ul> <p>\u6ce8\u610f\uff1a</p> <ul> <li>\u4e0esqueeze\u7c7b\u4f3c\uff0c\u8fd4\u56de\u7684\u5f20\u91cf\u4e0e\u8f93\u5165\u7684\u5f20\u91cf\u5171\u4eab\u5b58\u50a8\uff0c\u56e0\u6b64\u66f4\u6539\u4e00\u4e2a\u6570\u7ec4\u7684\u6570\u636e\u5185\u5bb9\uff0c\u5c06\u4f1a\u66f4\u6539\u53e6\u4e00\u4e2a\u6570\u7ec4\u3002</li> <li>torch.unsqueeze\u4e0ea.unsqueeze\u4f7f\u7528\u6548\u679c\u4e00\u6837\uff0c\u53ea\u662f\u540e\u8005\u9ed8\u8ba4\u5728\u6570\u7ec4a\u4e0a\u8fdb\u884c\u64cd\u4f5c\u3002</li> <li>\u5fc5\u987b\u8981\u6307\u5b9a<code>dim</code>\uff0c\u8fd9\u91cc\u4e0esqueeze\u4e0d\u540c\u3002</li> </ul>"},{"location":"PyTorch/torch/torch.squeeze_torch.unsqueeze/#_3","title":"\u4ee3\u7801\u6848\u4f8b","text":"<pre><code>import torch\na=torch.arange(5).view(5)\nb=torch.unsqueeze(a,dim=0)\nc=torch.unsqueeze(a,dim=1)\nprint(a)\nprint(b)\nprint(c)\nprint(a.shape)\nprint(b.shape)\nprint(c.shape)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u539f\u6570\u7ec4\ntensor([0, 1, 2, 3, 4])\n# dim\u8bbe\u4e3a0\u65f6\ntensor([[0, 1, 2, 3, 4]])\n# dim\u8bbe\u4e3a1\u65f6\ntensor([[0],\n        [1],\n        [2],\n        [3],\n        [4]])\n# \u539f\u6570\u7ec4\u5c3a\u5bf8\ntorch.Size([5])\n# dim\u8bbe\u4e3a0\u65f6\u5c3a\u5bf8\ntorch.Size([1, 5])\n# dim\u8bbe\u4e3a1\u65f6\u5c3a\u5bf8\ntorch.Size([5, 1])\n</code></pre>"},{"location":"PyTorch/torch/torch.squeeze_torch.unsqueeze/#_4","title":"\u5b98\u65b9\u6587\u6863","text":"<p>torch.squeeze()\uff1ahttps://pytorch.org/docs/stable/generated/torch.squeeze.html?highlight=torch%20squeeze#torch.squeeze</p> <p>torch.unsqueeze()\uff1ahttps://pytorch.org/docs/stable/generated/torch.unsqueeze.html?highlight=torch%20unsqueeze#torch.unsqueeze</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e749\u670816\u65e5</p>"},{"location":"PyTorch/torch/torch.transpose_tensor.permute/","title":"\u6570\u7ec4\u7684\u7ef4\u5ea6\u4ea4\u6362","text":""},{"location":"PyTorch/torch/torch.transpose_tensor.permute/#torchtranspose","title":"torch.transpose\u2014\u2014\u4ea4\u6362\u4e24\u4e2a\u7ef4\u5ea6","text":"<pre><code>torch.transpose(input, dim0, dim1) \u2192 Tensor\n</code></pre> <p>\u529f\u80fd\uff1a\u5c06\u8f93\u5165\u6570\u7ec4\u7684<code>dim0</code>\u7ef4\u5ea6\u548c<code>dim1</code>\u7ef4\u5ea6\u4ea4\u6362</p> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>input</code>\uff1a\u9700\u8981\u505a\u7ef4\u5ea6\u4ea4\u6362\u7684\u6570\u7ec4</li> <li><code>dim0</code>\u3001<code>dim1</code>\uff1a\u4ea4\u6362\u7684\u7ef4\u5ea6</li> </ul> <p>\u6ce8\u610f\uff1a</p> <ul> <li>\u8fd4\u56de\u7684\u5f20\u91cf\u6570\u7ec4\u4e0e\u539f\u6765\u7684\u6570\u7ec4\u5171\u4eab\u5e95\u5c42\u5b58\u50a8\uff0c\u66f4\u6539\u4e00\u65b9\u7684\u6570\u636e\u5185\u5bb9\uff0c\u53e6\u4e00\u65b9\u7684\u6570\u636e\u4e5f\u4f1a\u88ab\u4fee\u6539</li> <li>\u53ea\u80fd\u540c\u65f6\u4ea4\u6362\u4e24\u4e2a\u7ef4\u5ea6\uff0c\u56e0\u6b64\u53ea\u80fd\u8f93\u5165\u4e24\u4e2a\u6570</li> <li><code>torch.transpose</code>\u4e5f\u53ef\u4ee5\u901a\u8fc7<code>a.transpose</code>\u5b9e\u73b0\uff0c\u540e\u8005\u9ed8\u8ba4\u8f6c\u6362\u6570\u7ec4<code>a</code></li> <li>\u7ecf\u8fc7\u4ea4\u6362\u540e\u7684\u5185\u5b58\u5730\u5740\u4e0d\u8fde\u7eed\uff0c\u5982\u679c\u7528<code>view</code>\u6539\u53d8\u89c6\u56fe\uff0c\u5219\u4f1a\u62a5\u9519</li> </ul>"},{"location":"PyTorch/torch/torch.transpose_tensor.permute/#_2","title":"\u4ee3\u7801\u6848\u4f8b","text":"<p>\u4e8c\u7ef4\u6570\u7ec4\u8f6c\u7f6e</p> <pre><code>import torch\na=torch.arange(20).reshape(4,5)\nb=torch.transpose(a,dim0=1,dim1=0)\nprint(a)\nprint(b)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u539f\u6570\u7ec4\ntensor([[ 0,  1,  2,  3,  4],\n        [ 5,  6,  7,  8,  9],\n        [10, 11, 12, 13, 14],\n        [15, 16, 17, 18, 19]])\n# \u8f6c\u7f6e\u540e\ntensor([[ 0,  5, 10, 15],\n        [ 1,  6, 11, 16],\n        [ 2,  7, 12, 17],\n        [ 3,  8, 13, 18],\n        [ 4,  9, 14, 19]])\n</code></pre> <p>\u9ad8\u7ef4\u6570\u7ec4\u8f6c\u7f6e</p> <pre><code>import torch\na=torch.arange(24).reshape(2,3,4)\nb=torch.transpose(a,dim0=0,dim1=1)\nc=torch.transpose(a,dim0=0,dim1=2)\nd=torch.transpose(a,dim0=1,dim1=2)\nprint(a)\nprint(a.shape)\nprint(b)\nprint(b.shape)\nprint(c)\nprint(c.shape)\nprint(d)\nprint(d.shape)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u539f\u6570\u7ec4\ntensor([[[ 0,  1,  2,  3],\n         [ 4,  5,  6,  7],\n         [ 8,  9, 10, 11]],\n\n        [[12, 13, 14, 15],\n         [16, 17, 18, 19],\n         [20, 21, 22, 23]]])\ntorch.Size([2, 3, 4])\n# 1\u30012\u7ef4\u5ea6\u4ea4\u6362\ntensor([[[ 0,  1,  2,  3],\n         [12, 13, 14, 15]],\n\n        [[ 4,  5,  6,  7],\n         [16, 17, 18, 19]],\n\n        [[ 8,  9, 10, 11],\n         [20, 21, 22, 23]]])\ntorch.Size([3, 2, 4])\n# 1\u30013\u7ef4\u5ea6\u4ea4\u6362\ntensor([[[ 0, 12],\n         [ 4, 16],\n         [ 8, 20]],\n\n        [[ 1, 13],\n         [ 5, 17],\n         [ 9, 21]],\n\n        [[ 2, 14],\n         [ 6, 18],\n         [10, 22]],\n\n        [[ 3, 15],\n         [ 7, 19],\n         [11, 23]]])\ntorch.Size([4, 3, 2])\n# 2\u30013\u7ef4\u5ea6\u4ea4\u6362\ntensor([[[ 0,  4,  8],\n         [ 1,  5,  9],\n         [ 2,  6, 10],\n         [ 3,  7, 11]],\n\n        [[12, 16, 20],\n         [13, 17, 21],\n         [14, 18, 22],\n         [15, 19, 23]]])\ntorch.Size([2, 4, 3])\n</code></pre> <p>\u5b58\u50a8\u5730\u5740\u4e0d\u8fde\u7eed</p> <pre><code>import torch\na=torch.arange(24).reshape(2,3,4)\nb=torch.transpose(a,dim0=0,dim1=1)\nc=b.view(2,3,4)\n</code></pre> <p>\u4f1a\u62a5\u9519\uff0c<code>RuntimeError</code></p> <pre><code>RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\n</code></pre> <p>\u6362\u6210<code>reshape</code>\u65b9\u6cd5\u6765\u6539\u53d8\u89c6\u56fe\u6216\u8005\u52a0\u4e00\u6b65<code>.contiguous()</code>\u64cd\u4f5c\uff0c\u8ba9\u5b58\u50a8\u5185\u5b58\u8fde\u7eed</p> <pre><code>import torch\na=torch.arange(24).reshape(2,3,4)\nb=torch.transpose(a,dim0=0,dim1=1)\nc=b.reshape(4,6)\n# \u8ba9b\u7684\u5b58\u50a8\u53d8\u8fde\u7eed\nb=b.contiguous()\nd=b.view(4,6)\nprint(c)\nprint(d)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u4e24\u79cd\u65b9\u5f0f\u7ed3\u679c\u4e00\u6837\ntensor([[ 0,  1,  2,  3, 12, 13],\n        [14, 15,  4,  5,  6,  7],\n        [16, 17, 18, 19,  8,  9],\n        [10, 11, 20, 21, 22, 23]])\ntensor([[ 0,  1,  2,  3, 12, 13],\n        [14, 15,  4,  5,  6,  7],\n        [16, 17, 18, 19,  8,  9],\n        [10, 11, 20, 21, 22, 23]])\n</code></pre>"},{"location":"PyTorch/torch/torch.transpose_tensor.permute/#tensorpermute","title":"tensor.permute\u2014\u2014\u4ea4\u6362\u591a\u4e2a\u7ef4\u5ea6","text":"<pre><code>tensor.permute(*dims) \u2192 Tensor\n</code></pre> <p>\u529f\u80fd\uff1a\u5c06\u6570\u7ec4<code>tensor</code>\u7684\u7ef4\u5ea6\u6309\u8f93\u5165<code>dims</code>\u7684\u987a\u5e8f\u8fdb\u884c\u4ea4\u6362</p> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>dims</code>\uff1a\u7ef4\u5ea6\u4ea4\u6362\u987a\u5e8f</li> </ul> <p>\u6ce8\u610f\uff1a</p> <ul> <li><code>permute</code>\u65b9\u6cd5\u53ea\u80fd\u901a\u8fc7<code>tensor.permute</code>\u5b9e\u73b0\uff0c\u4e0d\u80fd\u901a\u8fc7<code>torch.permute</code>\u5b9e\u73b0</li> <li>\u548c<code>transpose</code>\u7c7b\u4f3c\u7ecf\u8fc7\u4ea4\u6362\u540e\u7684\u5185\u5b58\u5730\u5740\u4e0d\u8fde\u7eed\uff0c\u5982\u679c\u7528<code>view</code>\u6539\u53d8\u89c6\u56fe\uff0c\u5219\u4f1a\u62a5\u9519</li> <li><code>tensor.permute</code>\u7684\u529f\u80fd\u4e0e<code>np.transpose</code>\u7c7b\u4f3c\uff0c\u5747\u53ef\u4ee5\u540c\u65f6\u5bf9\u4e00\u4e2a\u6570\u7ec4\u8fdb\u884c\u591a\u7ef4\u5ea6\u4ea4\u6362\u64cd\u4f5c</li> </ul>"},{"location":"PyTorch/torch/torch.transpose_tensor.permute/#_3","title":"\u4ee3\u7801\u6848\u4f8b","text":"<pre><code>import torch\na=torch.arange(24).reshape(2,3,4)\n# 0,1,2-&gt;1,2,0\nb=a.permute(1,2,0)\nprint(a)\nprint(a.shape)\nprint(b)\nprint(b.shape)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u539f\u6570\u7ec4\ntensor([[[ 0,  1,  2,  3],\n         [ 4,  5,  6,  7],\n         [ 8,  9, 10, 11]],\n\n        [[12, 13, 14, 15],\n         [16, 17, 18, 19],\n         [20, 21, 22, 23]]])\ntorch.Size([2, 3, 4])\n# \u4ea4\u6362\u7ef4\u5ea6\u540e\u6570\u7ec4\ntensor([[[ 0, 12],\n         [ 1, 13],\n         [ 2, 14],\n         [ 3, 15]],\n\n        [[ 4, 16],\n         [ 5, 17],\n         [ 6, 18],\n         [ 7, 19]],\n\n        [[ 8, 20],\n         [ 9, 21],\n         [10, 22],\n         [11, 23]]])\ntorch.Size([3, 4, 2])\n</code></pre>"},{"location":"PyTorch/torch/torch.transpose_tensor.permute/#_4","title":"\u533a\u522b","text":"<ul> <li><code>permute</code>\u4e00\u6b21\u53ef\u4ee5\u64cd\u4f5c\u591a\u4e2a\u7ef4\u5ea6\uff0c\u5e76\u4e14\u5fc5\u987b\u4f20\u5165\u6240\u6709\u7ef4\u5ea6\u6570\uff1b\u800c<code>transpose</code>\u53ea\u80fd\u540c\u65f6\u4ea4\u6362\u4e24\u4e2a\u7ef4\u5ea6\uff0c\u5e76\u4e14\u53ea\u80fd\u4f20\u5165\u4e24\u4e2a\u6570</li> <li><code>permute</code>\u53ef\u4ee5\u901a\u8fc7\u591a\u4e2a<code>transpose</code>\u5b9e\u73b0</li> <li><code>transpose</code>\u4f20\u5165\u7684<code>dim</code>\u65e0\u987a\u5e8f\u4e4b\u5206\uff0c\u4f20\u5165(1,0)\u548c(0,1)\u7ed3\u679c\u4e00\u6837\uff0c\u90fd\u662f\u7b2c\u4e00\u7ef4\u5ea6\u548c\u7b2c\u4e8c\u7ef4\u5ea6\u8fdb\u884c\u4ea4\u6362\uff1b<code>permute</code>\u4f20\u5165\u7684<code>dim</code>\u6709\u987a\u5e8f\u4e4b\u5206\uff0c\u4f20\u5165(0,1)\u4ee3\u8868\u4ea4\u6362\u540e\u539f\u7b2c\u4e00\u7ef4\u5ea6\u5728\u524d\u9762\uff0c\u539f\u7b2c\u4e8c\u7ef4\u5ea6\u5728\u540e\u9762\uff1b\u4f20\u5165(1,0)\u4ee3\u8868\u4ea4\u6362\u540e\u539f\u7b2c\u4e8c\u7ef4\u5ea6\u5728\u524d\u9762\uff0c\u539f\u7b2c\u4e00\u7ef4\u5ea6\u5728\u540e\u9762</li> </ul>"},{"location":"PyTorch/torch/torch.transpose_tensor.permute/#_5","title":"\u6269\u5c55","text":"<p>\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\uff0c\u7531\u4e8ecv2\u683c\u5f0f(numpy)\u8bfb\u53d6\u7684\u56fe\u7247\u4e3aH\u00d7W\u00d7C\uff0c\u901a\u9053\u6570\u5728\u6700\u540e\uff1b\u800ctorch\u4e2d\u7684\u56fe\u7247\u5e38\u4ee5C\u00d7H\u00d7W\u5b58\u5728\uff0c\u56e0\u6b64\uff0c\u5f53\u56fe\u7247\u5728tensor\u4e0enumpy\u4e4b\u95f4\u8f6c\u6362\u65f6\uff0c\u9700\u8981\u7528\u5230\u4ea4\u6362\u6570\u7ec4\u7ef4\u5ea6\u7684\u51fd\u6570\u6765\u5c06\u56fe\u7247\u5b58\u50a8\u683c\u5f0f\u8f6c\u5316</p>"},{"location":"PyTorch/torch/torch.transpose_tensor.permute/#_6","title":"\u5b98\u65b9\u6587\u6863","text":"<p>torch.transpose():https://pytorch.org/docs/stable/generated/torch.transpose.html?highlight=transpose#torch.transpose</p> <p>toch.permute():https://pytorch.org/docs/1.9.1/generated/torch.Tensor.permute.html?highlight=torch%20permute#</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e749\u670824\u65e5</p>"},{"location":"PyTorch/torch/torch.where/","title":"\u6570\u7ec4\u7684\u67e5\u8be2","text":"<pre><code>torch.where(condition, x, y)\n</code></pre> <p>\u529f\u80fd\uff1a\u6309\u7167\u67e5\u627e\u6761\u4ef6<code>condition</code>\u6765\u8fd4\u56de<code>x</code>\u4e2d\u7684\u5143\u7d20\u6216\u8005<code>y</code>\u4e2d\u7684\u5143\u7d20\uff1b\u5982\u679c\u6761\u4ef6\u6210\u7acb\uff0c\u5373<code>condition</code>\u91cc\u4e3a<code>True</code>\uff0c\u5219\u8fd4\u56de<code>x</code>\u4e2d\u7684\u5143\u7d20\uff0c\u5426\u5219\uff0c\u5219\u8fd4\u56de<code>y</code>\u4e2d\u7684\u5143\u7d20\uff1a $$ \\begin{aligned} out_i=\\left\\{  \\begin{matrix}  x_i&amp;\\quad if\\quad \\text{condition}_i \\\\ y_i&amp;\\quad \\text{otherwise} \\end{matrix}   \\right. \\end{aligned} $$  \u8f93\u5165\uff1a</p> <ul> <li><code>condition</code>\uff1a\u67e5\u8be2\u6761\u4ef6\uff0c\u8f93\u5165\u6570\u636e\u7c7b\u578b\u4e3a\u5e03\u5c14\u7c7b\u578b\u7684\u6570\u636e<code>BoolTensor</code></li> <li><code>x</code>\uff1a\u6761\u4ef6\u6b63\u786e\u7684\u8bdd\uff0c\u6240\u671f\u671b\u8fd4\u56de\u7684\u503c\uff0c\u8f93\u5165\u6570\u636e\u7c7b\u578b\u4e3a\u5f20\u91cf\u6216\u8005\u6807\u91cf</li> <li><code>y</code>\uff1a\u6761\u4ef6\u9519\u8bef\u7684\u8bdd\uff0c\u6240\u671f\u671b\u8fd4\u56de\u7684\u503c\uff0c\u8f93\u5165\u6570\u636e\u7c7b\u578b\u4e0e<code>x</code>\u4e00\u81f4</li> </ul> <p>\u6ce8\u610f\uff1a</p> <ul> <li>\u8fd9\u91cc\u6267\u884c\u9010\u5143\u7d20\u7684\u67e5\u627e\uff0c<code>condition</code>\u4e2d\u5e94\u8be5\u662f\u4e00\u7cfb\u5217\u5e03\u5c14\u6570\u636e\uff0c\u5bf9\u5e94\u4f4d\u7f6e\u4e3a<code>True</code>\u65f6\uff0c\u8fd4\u56de<code>x</code>\u76f8\u540c\u4f4d\u7f6e\u4e0b\u7684\u5143\u7d20\uff0c\u5426\u5219\u8fd4\u56de<code>y</code>\u76f8\u540c\u4f4d\u7f6e\u4e0b\u7684\u5143\u7d20</li> <li><code>condition</code>\u3001<code>x</code>\u4e0e<code>y</code>\u5fc5\u987b\u652f\u6301\u5e7f\u64ad\u673a\u5236\uff0c\u5e76\u4e14\u5b83\u4eec\u4e09\u8005\u4e4b\u95f4\u53ef\u4ee5\u901a\u8fc7\u5e7f\u64ad\u673a\u5236\u5339\u914d\u8d77\u6765</li> <li>\u5982\u679c\u53ea\u4f20\u5165<code>condition</code>\u7684\u8bdd\uff0c\u5219\u8be5\u65b9\u6cd5\u5c31\u7c7b\u4f3c\u4e8e<code>torch.nonzero()</code>\uff0c\u67e5\u8be2\u975e\u96f6\u5143\u7d20\uff0c\u5177\u4f53\u53ef\u89c1torch.nonzero\u2014\u2014\u975e\u96f6\u5143\u7d20\u7684\u5b9a\u4f4d</li> <li><code>torch.where()</code>\u7684\u529f\u80fd\u4e5f\u53ef\u4ee5\u7528<code>tensor.where()</code>\u65b9\u6cd5\u5b9e\u73b0\uff0c\u540e\u8005\u9ed8\u8ba4<code>x</code>\u7684\u6570\u636e\u4e3a\u524d\u7f00<code>tensor</code>\u3002</li> </ul>"},{"location":"PyTorch/torch/torch.where/#_2","title":"\u4ee3\u7801\u6848\u4f8b","text":"<p>\u4e00\u822c\u7528\u6cd5</p> <pre><code>import torch\n\nx = torch.randn(10)\ny = torch.randn(10)\nout = torch.where(x&gt;0, x, y)\nprint(x)\nprint(y)\nprint(out)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># x\ntensor([ 1.3281,  0.4091, -1.2311,  0.8708, -1.4650,  0.2836,  2.0987,  0.3480,\n         0.2158, -0.5170])\n# y\ntensor([ 2.4749, -1.5315, -0.1035,  1.4638,  0.9670,  1.3757, -0.8117,  0.5418,\n         0.1308,  0.0948])\n# \u7ed3\u679c\ntensor([ 1.3281,  0.4091, -0.1035,  0.8708,  0.9670,  0.2836,  2.0987,  0.3480,\n         0.2158,  0.0948])\n</code></pre>"},{"location":"PyTorch/torch/torch.where/#_3","title":"\u5e7f\u64ad\u673a\u5236","text":"<pre><code>import torch\n\nx = torch.randn(5).reshape(1, 1, 5)\ny = torch.randn(20).reshape(2, 2, 5)\nout = torch.where(x&gt;0, x, y)\nprint(x)\nprint(y)\nprint(out)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># x\ntensor([[[ 0.9804,  0.2512, -1.0319, -1.5594, -2.1296]]])\n# y\ntensor([[[ 0.3023,  0.0923, -0.2217, -0.1646,  1.3965],\n         [ 0.6029, -0.5472,  0.9264, -0.5085, -0.1423]],\n\n        [[ 0.9171, -0.2700, -0.4862,  0.4522,  0.4943],\n         [-2.5135, -1.1070,  0.4611,  0.9768, -0.0368]]])\n# \u9996\u5148\u5c06x\u6269\u5145\uff0c\u6269\u5230\u4e0ey\u5c3a\u5bf8\u4e00\u6837\u7684\u6570\u7ec4\uff0c\u4e4b\u540e\u518d\u9010\u5143\u7d20\u6bd4\u8f83\ntensor([[[ 0.9804,  0.2512, -0.2217, -0.1646,  1.3965],\n         [ 0.9804,  0.2512,  0.9264, -0.5085, -0.1423]],\n\n        [[ 0.9804,  0.2512, -0.4862,  0.4522,  0.4943],\n         [ 0.9804,  0.2512,  0.4611,  0.9768, -0.0368]]])\n</code></pre> <p>\u6ce8\u610f\uff0c\u5e7f\u64ad\u673a\u5236\u53ea\u5141\u8bb8\u4e00\u4e2a\u53d8\u91cf\u6269\u5145\uff0c\u5373\u6709\u4e00\u4e2a\u4e3a\u6807\u51c6\uff0c\u53e6\u4e00\u4e2a\u671d\u7740\u6807\u51c6\u53d8</p> <pre><code>import torch\n\nx = torch.randn(10).reshape(1, 1, 10)\ny = torch.randn(20).reshape(2, 2, 5)\nout = torch.where(x&gt;0, x, y)\nprint(a)\nprint(b)\nprint(c)\n</code></pre> <p>\u6b64\u65f6<code>x</code>\u9700\u8981\u5bf9\u524d\u4e24\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u590d\u5236\uff0c\u4ece\u800c\u548c<code>y</code>\u7684\u524d\u4e24\u4e2a\u7ef4\u5ea6\u5bf9\u5e94\u8d77\u6765\uff0c\u4f46\u662f<code>x</code>\u7684\u7b2c\u4e09\u7ef4\u5ea6\u8981\u5927\u4e8e<code>y</code>\u7684\u7b2c\u4e09\u7ef4\u5ea6\uff0c\u6b64\u65f6<code>y</code>\u4e0d\u80fd\u590d\u5236\u7b2c\u4e09\u7ef4\u5ea6\uff0c\u56e0\u6b64<code>x</code>\u4e0e<code>y</code>\u5c3a\u5bf8\u5339\u914d\u4e0d\u8d77\u6765\uff0c\u4f1a\u62a5\u9519\uff1a</p> <pre><code>---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n&lt;ipython-input-20-3760522cac5b&gt; in &lt;module&gt;\n      3 a = torch.randn(10).reshape(1, 1, 10)\n      4 b = torch.randn(20).reshape(2, 2, 5)\n----&gt; 5 c = torch.where(a&gt;0, a, b)\n      6 print(a)\n      7 print(b)\n\nRuntimeError: The size of tensor a (10) must match the size of tensor b (5) at non-singleton dimension 2\n</code></pre> <p>\u63d0\u793a\u7b2c\u4e09\u7ef4\u5ea6\u7684\u6570\u636e\u5c3a\u5bf8\u4e0d\u5339\u914d\uff0c\u5982\u679c\u60f3\u8fdb\u884c\u5339\u914d\u7684\u8bdd\uff0c\u5fc5\u987b\u53ea\u80fd\u4e00\u4e2a\u53d8\u91cf\u671d\u53e6\u4e00\u4e2a\u53d8\u91cf\u6269\u5145\u5339\u914d\uff0c\u4e8c\u8005\u4e0d\u80fd\u4e92\u76f8\u671d\u7740\u5bf9\u65b9\u6269\u5145\u3002</p>"},{"location":"PyTorch/torch/torch.where/#_4","title":"\u53ea\u4f20\u5165\u67e5\u8be2\u6761\u4ef6\u65f6","text":"<pre><code>import torch\n\nx = torch.randn(10)\nout = torch.where(x&gt;0)\nprint(x)\nprint(out)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># x\ntensor([ 0.1115,  1.7095, -0.6749,  0.1693,  1.3004,  0.7765,  1.0432, -0.0085,\n        -0.1694,  0.2330])\n# \u67e5\u8be2\u7b26\u5408\u6761\u4ef6x&gt;0\u7684\u5143\u7d20\u7d22\u5f15\uff0c\u8fd9\u91cc\u4e0enonzero\u65b9\u6cd5\u7c7b\u4f3c\n(tensor([0, 1, 3, 4, 5, 6, 9]),)\n</code></pre>"},{"location":"PyTorch/torch/torch.where/#_5","title":"\u5b98\u65b9\u6587\u6863","text":"<p>torch.where()\uff1ahttps://pytorch.org/docs/stable/generated/torch.where.html?highlight=where#torch.where</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e742\u670812\u65e5</p>"},{"location":"RL/AC/","title":"AC\u7b97\u6cd5\u2014\u2014\u6f14\u5458-\u8bc4\u8bba\u5458\u7b97\u6cd5","text":"<p>\u6e90\u7801\u4e0e\u56fe\u7247\u5f15\u81ea\uff1ahttps://github.com/datawhalechina/easy-rl</p>"},{"location":"RL/AC/#_1","title":"\u4ecb\u7ecd","text":"<p>\u2003\u2003\u6838\u5fc3\u601d\u60f3\uff1a\u76f4\u63a5\u8bad\u7ec3\u51b3\u7b56\u51fd\u6570V_\\pi(s)\uff08\u6f14\u5458-actor\uff0c\u6267\u884c\u52a8\u4f5c\uff09\uff0c\u5e76\u4e14\u8bad\u7ec3\u8bc4\u4ef7\u7f51\u7edc\u53bb\u4f30\u8ba1\u52a8\u4f5c\u6267\u884c\u7684\u597d\u574f\uff0c\u5bf9\u6bcf\u4e2a\u52a8\u4f5c\u635f\u5931\u8d77\u5230\u52a0\u6743\u7684\u4f5c\u7528\uff08\u8bc4\u8bba\u5458-critic\uff09\uff0c\u4f8b\u5982\u4ef7\u503c\u51fd\u6570V_\\theta(s)\uff08\u8861\u91cf\u72b6\u6001s\u7684\u4ef7\u503c\u91cf\uff0c\u7528\u4e8e\u8bc4\u4f30\u52a8\u4f5c\u7684\u597d\u574f\uff09\u3001\u52a8\u4f5c\u4ef7\u503c\u51fd\u6570Q(s,a)\uff08\u8861\u91cf\u5728\u72b6\u6001s\u53bb\u6267\u884c\u52a8\u4f5ca\u4f1a\u4ea7\u751f\u7684\u79ef\u7d2f\u4ef7\u503c\uff09\u3002</p> <p>\u2003\u2003\u6bcf\u4e2a\u52a8\u4f5c\u7684\u6743\u91cd\u53c8\u79f0\u4f18\u52bf\u51fd\u6570\uff0c\u8ba1\u7b97\u65b9\u6cd5\u4e3a\uff1a\u5f53\u524d\u52a8\u4f5c\u6240\u4ea7\u751f\u7684\u79ef\u7d2f\u4ef7\u503c\u51cf\u53bb\u5f53\u524d\u72b6\u6001\u7684\u4ef7\u503c\u91cf\uff08\u53c8\u53ef\u4ee5\u770b\u6210\u72b6\u6001s\u7684\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u6240\u6709\u52a8\u4f5c\u53ef\u4ee5\u4ea7\u751f\u7684\u5e73\u5747\u4ef7\u503c\uff09\uff0c\u5982\u679c\u4f18\u52bf\u51fd\u6570\u4e3a\u6b63\uff0c\u5219\u8bf4\u660e\u8be5\u52a8\u4f5c\u6240\u4ea7\u751f\u7684\u79ef\u7d2f\u4ef7\u503c\u5927\u4e8e\u5e73\u5747\u91cf\uff0c\u5c5e\u4e8e\u201d\u597d\u52a8\u4f5c\u201c\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u9f13\u52b1\u7f51\u7edc\u591a\u505a\u8fd9\u79cd\u52a8\u4f5c\uff0c\u4ea7\u751f\u6b63\u5411\u4f18\u5316\uff0c\u5426\u5219\u4ea7\u751f\u8d1f\u5411\u4f18\u5316\u3002</p> <p>\u2003\u2003AC\u7b97\u6cd5\uff1a\u7528Q_\\pi(s^n_t,a^n_t)\u6765\u4f30\u8ba1\u6267\u884c\u52a8\u4f5ca_t\u4e4b\u540e\u53ef\u83b7\u5f97\u7684\u79ef\u7d2f\u5956\u52b1\uff08\u5229\u7528SARSA\u7b97\u6cd5\u8bad\u7ec3\uff0c\u5c5e\u4e8e\u540c\u7b56\u7565\uff0c\u4e0d\u80fd\u7528\u7ecf\u9a8c\u56de\u653e\uff0c\u548cDQN\u4e2d\u7684Q\u5b66\u4e60\u7b97\u6cd5\u76f8\u533a\u5206\uff09\uff0c\u5e76\u4e14\u5229\u7528\u79ef\u7d2f\u5956\u52b1\u6765\u5bf9\u6bcf\u4e2a\u52a8\u4f5c\u6982\u7387\u505a\u52a0\u6743\uff0c\u5229\u7528\u68af\u5ea6\u4e0a\u5347\u7b56\u7565\u4f18\u5316\u53c2\u6570\uff1b</p> <p>\u2003\u2003A2C\u7b97\u6cd5\u505a\u51fa\u7684\u6539\u8fdb\uff1a\u76f8\u5bf9\u4e8eAC\u7b97\u6cd5\uff0c\u5f15\u5165\u4e86\u57fa\u7ebf\u7b56\u7565\uff0c\u5229\u7528V_\\theta(s_t^n)\u6765\u4f30\u8ba1\u5f53\u524d\u72b6\u6001\u7684\u4ef7\u503c\uff0c\u7528\u4e8e\u8ba1\u7b97\u52a8\u4f5c\u7684\u79ef\u7d2f\u4f30\u8ba1\u91cf\uff0c\u548cPPO\u7b97\u6cd5\u4e2d\u7684b\u505a\u597d\u533a\u5206\uff0c\u5c06\u79ef\u7d2f\u5956\u52b1\u4e0e\u57fa\u7ebf\u505a\u5dee\uff0c\u5f97\u5230\u4f18\u52bf\u51fd\u6570\uff0c\u518d\u5229\u7528\u505a\u5dee\u540e\u7684\u7ed3\u679c\u5bf9\u635f\u5931\u505a\u52a0\u6743\u3002\u4f46\u6b64\u65f6\u9700\u8981\u540c\u65f6\u4f18\u5316\u4e24\u4e2a\u7f51\u7edc\uff0c\u6a21\u578b\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7a33\u5b9a\u6027\u4e0d\u9ad8\uff0c\u56e0\u6b64\u672c\u7b97\u6cd5\u53c8\u5229\u7528r^n_t+V_\\theta(s_{t+1}^n)\u8fd1\u4f3c\u4ee3\u66ff\u52a8\u4f5ca_t\u7684\u79ef\u7d2f\u5956\u52b1Q_\\pi(s^n_t,a^n_t)\uff0c\u8fd9\u6837\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u53ea\u9700\u8981\u66f4\u65b0\u4e00\u7ec4\u53c2\u6570V_\\theta(s)\uff0c\u63d0\u5347\u4e86\u7a33\u5b9a\u6027\uff1b</p> <p>\u6ce8\uff1a\u4f18\u52bf\u51fd\u6570\u7ed3\u679c\u6709\u6b63\u8d1f\uff0c\u53ef\u4ee5\u533a\u5206\u52a8\u4f5c\u7684\u597d\u574f\uff0c\u5426\u5219\u6743\u91cd\u5168\u662f\u975e\u8d1f\u6570\uff0c\u6ca1\u6709\u5bf9\u4e0d\u597d\u52a8\u4f5c\u7684\u201c\u6291\u5236\u4f5c\u7528\u201d</p> <p>\u2003\u2003A3C\u7b97\u6cd5\u505a\u51fa\u7684\u6539\u8fdb\uff1a\u53c2\u8003\u591a\u7ebf\u7a0b\u6a21\u5f0f\uff0c\u8bbe\u7f6e\u591a\u4e2a\u5b50\u7f51\u7edc\u53bb\u4e0d\u540c\u7684\u73af\u5883\u4e2d\u5b66\u4e60\uff0c\u6240\u6709\u7684\u7f51\u7edc\u5e76\u884c\u63a2\u7d22\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u53c2\u6570\u7684\u8bad\u7ec3\u901f\u5ea6\u4ee5\u53ca\u8bad\u7ec3\u7684\u7a33\u5b9a\u6027\u3002</p> <p>\u4f18\u5316\u76ee\u6807\uff1a</p> <ul> <li>\u51b3\u7b56\u51fd\u6570V_\\pi(s)\u7684\u4f18\u5316\u76ee\u6807\uff1a</li> </ul>  L_{\\pi}=\\frac1 N\\sum^N_{n=1}\\sum^{T_n}_{t=1}(R-V_{\\theta}(s_t^n))\\log p_\\pi(a_t^n|s_t^n)  <p>\u5176\u4e2d\uff0cR=\\sum_{t'=t}^{T_n}\\gamma^{t'-t}r^n_{t'}+\\gamma^{T_n-t}V_\\theta(s^n_{t+1})\uff0c\u8868\u793a\u52a8\u4f5ca_t\u7684\u79ef\u7d2f\u6536\u76ca\uff0c\u4e0b\u9762\u7684R\u76f8\u540c\u3002</p> <p>\u6ce8\uff1aL_\\pi\u53ea\u7528\u4e8e\u66f4\u65b0\u51b3\u7b56\u51fd\u6570\uff0c\u4e24\u4e2a\u72b6\u6001\u4ef7\u503cV_\\theta(s_t)\u53ea\u7528\u4e8e\u5bf9\u52a8\u4f5c\u635f\u5931\u505a\u52a0\u6743\uff0c\u5b9e\u9645\u6267\u884c\u65f6\u4f1a\u5207\u65ad\u68af\u5ea6\uff0c\u53cd\u5411\u4f20\u64ad\u8fc7\u7a0b\u4e0d\u5bf9\u4ef7\u503c\u51fd\u6570\u4ea7\u751f\u5f71\u54cd\u3002</p> <ul> <li>\u4ef7\u503c\u51fd\u6570V_\\theta(s)\u7684\u4f18\u5316\u76ee\u6807\uff1a</li> </ul>  L_\\theta=\\frac1N\\sum^N_{n=1}\\sum^{T_n}_{t=1}\\frac12(R -V_\\theta(s_t^n))^2  <ul> <li>\u71b5\uff08\u7528\u4e8e\u8f85\u52a9\u8bad\u7ec3\uff09\uff1a</li> </ul>  L_{en}=-H(p_\\pi(a_t^n|s_t^n)*\\log{p_\\pi(a_t^n|s_t^n)})  <p>\u603b\u635f\u5931\u51fd\u6570\uff1a $$ L=-L_\\pi+\\alpha L_\\theta-\\beta L_{en} $$  \u6ce8\uff1a</p> <ul> <li>\u9ed8\u8ba4\u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u6cd5\u66f4\u65b0\u7f51\u7edc\u53c2\u6570\uff0c\u56e0\u6b64\uff0c\u635f\u5931\u4e2d\u7684\u8d1f\u53f7\u8868\u793a\u8981\u63d0\u5347\u8be5\u76ee\u6807\u503c\uff0c\u6b63\u53f7\u8868\u793a\u8981\u964d\u4f4e\u8be5\u76ee\u6807\u503c</li> <li>\u6bcf\u8d70T_n\u6b65\u518d\u66f4\u65b0\u7f51\u7edc\u53c2\u6570\uff0ct\u4e3a\u65f6\u95f4\u6b65\uff0c\u82e5T_n\u4e3a1\uff0c\u5219\u4e3a\u5355\u6b65\u66f4\u65b0\u4e00\u6b21</li> </ul> <p>A2C\u6b65\u9aa4\uff1a</p> <ul> <li>\u521d\u59cb\u5316\u51b3\u7b56\u7f51\u7edcV_\\pi(s)\u4ee5\u53ca\u52a8\u4f5c\u7f51\u7edcV_\\theta(s)\uff0c\u9762\u5bf9\u72b6\u6001\u7ef4\u6570\u8fc7\u5927\u7684\u60c5\u51b5\uff08\u5982\u56fe\u50cf\uff09\uff0c\u4e24\u4e2a\u7f51\u7edc\u53ef\u4ee5\u5171\u4eab\u7279\u5f81\u63d0\u53d6\u90e8\u5206\u7684\u53c2\u6570</li> <li>\u904d\u5386\u6bcf\u4e2aepisodes\uff0c\u5047\u8bbet\u4e3a\u5f53\u524d\u7684\u65f6\u95f4\u6b65</li> <li>\u5c06\u72b6\u6001s_t\u4f20\u5165\u4e24\u4e2a\u7f51\u7edc\uff0c\u5f97\u5230\u52a8\u4f5c\u6982\u7387\u5206\u6570V_\\pi(s_t)\u4ee5\u53ca\u72b6\u6001\u4ef7\u503cV_\\theta(s_t)\uff0c\u6309\u6982\u7387\u91c7\u6837\uff0c\u5f97\u5230\u5f53\u524d\u72b6\u6001\u4e0b\u6240\u6267\u884c\u7684\u52a8\u4f5ca_t</li> <li>\u52a8\u4f5c\u4e0e\u73af\u5883\u4ea4\u4e92\uff0c\u5f97\u5230\u5f53\u524d\u7684\u53cd\u9988r_t\u4ee5\u53ca\u4e0b\u4e00\u9636\u6bb5\u7684\u72b6\u6001s_{t+1}</li> <li>\u5c06\u540c\u4e00\u4e2aT_n\u5185\u7684(V_\\pi(s_t),V_\\theta(s_t),r_t)\u5b58\u8d77\u6765\uff0c\u8fed\u4ee3T_n\u4e4b\u540e\u8ba1\u7b97\u603b\u635f\u5931L\uff0c\u66f4\u65b0\u7f51\u7edc\u53c2\u6570</li> </ul> <p>A3C\u6b65\u9aa4\uff1a</p> <ul> <li>\u9996\u5148\u8981\u9884\u8bbe\u4e00\u4e2a\u5168\u5c40\u7f51\u7edc\uff0c\u4e4b\u540e\u5206\u6210n\u4e2a\u73af\u5883\uff08\u7c7b\u4f3c\u7ebf\u7a0b\uff09\u4ee5\u53can\u4e2a\u5b50\u7f51\u7edc\uff0c\u5b50\u7f51\u7edc\u7ed3\u6784\u4e0e\u5168\u5c40\u7f51\u7edc\u7ed3\u6784\u76f8\u540c</li> <li>\u5bf9\u4e8e\u6bcf\u4e2a\u5b50\u7f51\u7edc\u90fd\u8981\u5206\u914d\u4e00\u4e2a\u73af\u5883\uff0c\u5e76\u4e14\u5728\u6bcf\u8d70T_n\u6b65\u4e4b\u524d\u90fd\u52a0\u8f7d\u4e00\u6b21\u5168\u5c40\u7f51\u7edc\u7684\u53c2\u6570</li> <li>\u6bcf\u4e2a\u5b50\u7f51\u7edc\u90fd\u8981\u5728\u6240\u5206\u914d\u7684\u73af\u5883\u4e0b\u8d70T_n\u6b65\uff0c\u8ba1\u7b97\u635f\u5931\uff0c\u6b65\u9aa4\u4e0eA2C\u7684\u6b65\u9aa4\u76f8\u540c</li> <li>\u635f\u5931\u6240\u4ea7\u751f\u7684\u68af\u5ea6\u8d4b\u503c\u5230\u5168\u5c40\u7f51\u7edc\u4e0a\u9762\uff0c\u66f4\u65b0\u5168\u5c40\u7f51\u7edc\u7684\u53c2\u6570</li> </ul> <p>\u6ce8\uff1aA3C\u76f8\u5f53\u4e8e\u5b9e\u73b0\u4e86\u591a\u7ebf\u7a0b\u66f4\u65b0\u53c2\u6570\u7684\u76ee\u7684\u3002</p>"},{"location":"RL/AC/#_2","title":"\u8865\u5145","text":""},{"location":"RL/AC/#_3","title":"\u8def\u5f84\u884d\u751f\u7b56\u7565\u68af\u5ea6","text":"<p>\u2003\u2003\u5229\u7528\u52a8\u4f5c\u4ef7\u503c\u51fd\u6570Q(s,a)\u6765\u4f18\u5316\u51b3\u7b56\u7f51\u7edcV_\\pi(s)\u3002\u9996\u5148\u8ba9\u51b3\u7b56\u7f51\u7edc\u4e0e\u73af\u5883\u505a\u4e92\u52a8\uff0c\u5229\u7528Q\u5b66\u4e60\u7b97\u6cd5\u53bb\u4f18\u5316\u52a8\u4f5c\u4ef7\u503c\u51fd\u6570Q(s,a)\uff0c\u4e4b\u540e\u56fa\u5b9a\u4ef7\u503c\u51fd\u6570\u7684\u53c2\u6570\uff0c\u4ee5\u6700\u5927\u5316Q\u503c\u8f93\u51fa\u7684\u76ee\u7684\u53bb\u4f18\u5316\u51b3\u7b56\u7f51\u7edcV_\\pi(s)\u7684\u53c2\u6570\uff0c\u4e0e\u5bf9\u6297\u751f\u6210\u7f51\u7edc\u601d\u60f3\u5f88\u50cf\uff0c\u5177\u4f53\u6d41\u7a0b\u5982\u4e0b\uff1a</p> <p> <p></p> <p></p> <p>\u6b65\u9aa4\uff1a</p> <ul> <li>\u521d\u59cb\u5316Q\u7f51\u7edc\u3001\u76ee\u6807\\hat Q\u7f51\u7edc\uff0c\u4ee4\\hat Q=Q\uff0c\u5e76\u4e14\u521d\u59cb\u5316\u51b3\u7b56\u7f51\u7edcV_\\pi(s)\u3001\u76ee\u6807\u51b3\u7b56\u7f51\u7edcV_\\hat \\pi(s)\uff0c\u4ee4\\hat \\pi=\\pi</li> <li>\u904d\u5386\u6bcf\u4e2aepisodes\uff0c\u5047\u8bbet\u4e3a\u5f53\u524d\u7684\u65f6\u95f4\u6b65</li> <li>\u7ed9\u5b9a\u4e00\u4e2a\u72b6\u6001s_t\uff0c\u6839\u636e\u51b3\u7b56\u7f51\u7edc\u7684\u51b3\u7b56\u7ed3\u679c\u6267\u884c\u52a8\u4f5ca_t\uff0c\u5e76\u4e14\u4e0e\u73af\u5883\u505a\u4ea4\u4e92\uff0c\u5f97\u5230\u5956\u52b1r_t\u4ee5\u53ca\u4e0b\u4e00\u4e2a\u9636\u6bb5s_{t+1}\uff1b</li> <li> <p>\u5c06(s_t,a_t,r_t,s_{t+1})\u5b58\u5165\u7f13\u51b2\u533a\uff0c\u5e76\u4e14\u6309\u6279\u91cf\u5f62\u5f0f\u4ece\u7f13\u51b2\u533a\u91c7\u6837\uff08\u5177\u4f53\u7ec6\u8282\u53ef\u89c1DQN\u7b97\u6cd5\uff09\uff0c\u5f97\u5230(s_i,a_i,r_i,s_{i+1})</p> </li> <li> <p>\u8ba1\u7b97\u76ee\u6807\u503cy=r_i+\\hat Q(s_{i+1},V_{\\hat \\pi}(s_{i+1}))\uff0c\u66f4\u65b0Q\u7f51\u7edc\u7684\u53c2\u6570\uff0c\u4f7f\u5f97Q(s_i,a_i)\u5411\u76ee\u6807\u503cy\u9760\u8fd1</p> </li> <li>\u66f4\u65b0\u51b3\u7b56\u7f51\u7edcV_\\pi(s)\u7684\u53c2\u6570\uff0c\u4f7f\u5f97Q(s_i,V_{\\pi}(s_i))\u7684\u503c\u6700\u5927</li> <li>\u6bcf\u66f4\u65b0C\u6b21\u53c2\u6570\u5c31\u66f4\u65b0\u4e24\u4e2a\u76ee\u6807\u7f51\u7edc\u7684\u53c2\u6570\uff0c\u4ee4\\hat Q=Q\u3001\\hat \\pi=\\pi</li> </ul>"},{"location":"RL/AC/#a2c","title":"A2C\u6e90\u7801\u5b9e\u73b0","text":""},{"location":"RL/AC/#_4","title":"\u7f51\u7edc\u7ed3\u6784","text":"<pre><code>class ActorCritic(nn.Module):\n    \"\"\"\n    A2C\u7f51\u7edc\u6a21\u578b\uff0c\u5305\u542b\u4e00\u4e2aActor\u548cCritic\n    \"\"\"\n\n    def __init__(self, input_dim, output_dim, hidden_dim):\n        super(ActorCritic, self).__init__()\n        # \u4e24\u4e2a\u7f51\u7edc\u7684\u8f93\u5165\u7ef4\u5ea6\u5747\u4e3a\u72b6\u6001s\u7684\u6570\u636e\u7ef4\u5ea6\n        # \u8bc4\u4ef7\u7f51\u7edc\u7684\u8f93\u51fa\u4e3a1\uff0c\u8f93\u51fa\u5f53\u524d\u72b6\u6001\u7684\u4ef7\u503c\n        self.critic = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, 1)\n        )\n        # \u51b3\u7b56\u51fd\u6570\u7684\u8f93\u51fa\u7ef4\u5ea6\u4e3a\u52a8\u4f5c\u7a7a\u95f4\u7684\u7ef4\u5ea6\u5927\u5c0f\n        # \u8f93\u51fa\u6570\u636e\u8868\u793a\u5728\u5f53\u524d\u72b6\u6001\u4e0b\u6bcf\u4e2a\u52a8\u4f5c\u6240\u88ab\u9009\u53d6\u7684\u6982\u7387\n        self.actor = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, output_dim),\n            nn.Softmax(dim=1),\n        )\n\n    def forward(self, x):\n        value = self.critic(x)\n        probs = self.actor(x)\n        # \u5c06\u6982\u7387\u8f6c\u4e3a\u5206\u5e03\uff0c\u7528\u4e8e\u540e\u7eed\u7684\u91c7\u6837\uff0c\u5f97\u5230\u6240\u6267\u884c\u7684\u52a8\u4f5c\n        dist = Categorical(probs)\n        return dist, value\n</code></pre>"},{"location":"RL/AC/#_5","title":"\u8bad\u7ec3\u6d41\u7a0b","text":"<pre><code>def train(cfg, envs):\n    print('\u5f00\u59cb\u8bad\u7ec3!')\n    print(f'\u73af\u5883\uff1a{cfg.env_name}, \u7b97\u6cd5\uff1a{cfg.algo_name}, \u8bbe\u5907\uff1a{cfg.device}')\n    env = gym.make(cfg.env_name)  # a single env\n    env.seed(10)\n    state_dim = envs.observation_space.shape[0]\n    action_dim = envs.action_space.n\n    # \u5b9a\u4e49\u6a21\u578b\u4ee5\u53ca\u4f18\u5316\u5668\n    model = ActorCritic(state_dim, action_dim, cfg.hidden_dim).to(cfg.device)\n    optimizer = optim.Adam(model.parameters())\n    frame_idx = 0\n    test_rewards = []\n    test_ma_rewards = []\n    state = envs.reset()\n    while frame_idx &lt; cfg.max_frames:\n        log_probs = []\n        values = []\n        rewards = []\n        masks = []\n        entropy = 0\n        # rollout trajectory\n        # \u6309Tn\u904d\u5386\n        for _ in range(cfg.n_steps):\n            state = torch.FloatTensor(state).to(cfg.device)\n            # \u6839\u636e\u72b6\u6001\u6765\u8bc4\u4f30\u52a8\u4f5c\u6982\u7387\u4ee5\u53ca\u72b6\u6001\u4ef7\u503c\n            dist, value = model(state)\n            # \u5bf9\u5206\u5e03\u505a\u91c7\u6837\uff0c\u5f97\u5230\u6267\u884c\u52a8\u4f5c\u7684\u5e8f\u53f7\n            action = dist.sample()\n            # \u4e0e\u73af\u5883\u505a\u4ea4\u4e92\uff0c\u5f97\u5230\u4e0b\u4e00\u4e2a\u72b6\u6001\u3001\u5956\u52b1\u503c\u3001\u5f53\u524d\u52a8\u4f5c\u662f\u5426\u5b8c\u6210\n            next_state, reward, done, _ = envs.step(action.cpu().numpy())\n            # \u8ba1\u7b97\u5bf9\u6570\u6982\u7387\n            log_prob = dist.log_prob(action)\n            # \u8ba1\u7b97\u71b5\n            entropy += dist.entropy().mean()\n            # \u50a8\u5b58\u540c\u4e00\u4e2aTn\u4e2d\u7684\u6570\u636e\n            log_probs.append(log_prob)\n            values.append(value)\n            rewards.append(torch.FloatTensor(reward).unsqueeze(1).to(cfg.device))\n            masks.append(torch.FloatTensor(1 - done).unsqueeze(1).to(cfg.device))\n            state = next_state\n            frame_idx += 1\n            if frame_idx % 100 == 0:\n                test_reward = np.mean([test_env(env, model) for _ in range(10)])\n                print(f\"frame_idx:{frame_idx}, test_reward:{test_reward}\")\n                test_rewards.append(test_reward)\n                if test_ma_rewards:\n                    test_ma_rewards.append(0.9 * test_ma_rewards[-1] + 0.1 * test_reward)\n                else:\n                    test_ma_rewards.append(test_reward)\n                    # plot(frame_idx, test_rewards)\n        next_state = torch.FloatTensor(next_state).to(cfg.device)\n        _, next_value = model(next_state)\n        # returns\u91cc\u5171\u6709n_steps\u4e2a\u5143\u7d20\uff0c\u8868\u793a\u6bcf\u4e2a\u65f6\u95f4\u6b65\u7684\u8fd1\u4f3c\u52a8\u4f5c\u4ef7\u503c\u91cf\uff0c\u5373\u635f\u5931\u516c\u5f0f\u4e2d\u7684R\n        returns = compute_returns(next_value, rewards, masks)\n        log_probs = torch.cat(log_probs)\n        returns = torch.cat(returns).detach()\n        values = torch.cat(values)\n        # \u8fd1\u4f3c\u52a8\u4f5c\u4ef7\u503c\u91cfR\u51cf\u53bb\u72b6\u6001\u4ef7\u503c\uff0c\u5f97\u5230\u4f18\u52bf\u51fd\u6570\n        advantage = returns - values\n        # \u51b3\u7b56\u51fd\u6570\u635f\u5931\n        actor_loss = (log_probs * advantage.detach()).mean()\n        # \u4ef7\u503c\u51fd\u6570\u635f\u5931\n        critic_loss = advantage.pow(2).mean()\n        # \u603b\u635f\u5931\n        loss = -actor_loss + 0.5 * critic_loss - 0.001 * entropy\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    print('\u5b8c\u6210\u8bad\u7ec3\uff01')\n    return test_rewards, test_ma_rewards\n</code></pre> <p>\u8fed\u4ee3\u8ba1\u7b97\u8fd1\u4f3c\u52a8\u4f5c\u4ef7\u503c\u91cfR</p> <pre><code>def compute_returns(next_value, rewards, masks, gamma=0.99):\n    R = next_value\n    returns = []\n    for step in reversed(range(len(rewards))):\n        R = rewards[step] + gamma * R * masks[step]\n        returns.insert(0, R)\n    return returns\n</code></pre> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u6307\u6b63</p> <p>\u521d\u6b65\u5b8c\u7a3f\u4e8e\uff1a2023\u5e745\u670815\u65e5</p>"},{"location":"RL/DDPG/","title":"DDPG\u2014\u2014\u6df1\u5ea6\u786e\u5b9a\u6027\u7b56\u7565\u68af\u5ea6","text":"<p>\u672c\u6587\u56fe\u7247\u4e0e\u6e90\u7801\u5747\u6765\u81ea\uff1ahttps://github.com/datawhalechina/easy-rl</p>"},{"location":"RL/DDPG/#_1","title":"\u4ecb\u7ecd","text":"<p>\u2003\u2003\u6df1\u5ea6\u786e\u5b9a\u6027\u7b56\u7565\u68af\u5ea6\uff08DDPG\uff09\u5e38\u5e38\u7528\u4e8e\u8fde\u7eed\u63a7\u5236\u7684\u9886\u57df\uff0c\u7531\u51b3\u7b56\u7f51\u7edc\u548c\u4ef7\u503c\u7f51\u7edc\u6784\u6210\uff0c\u51b3\u7b56\u7f51\u7edc\u63a7\u5236\u667a\u80fd\u4f53\u505a\u8fd0\u52a8\uff0c\u9762\u5bf9\u4e00\u4e2a\u72b6\u6001s\u8f93\u51fa\u4e00\u4e2a\u52a8\u4f5c\uff0c\u4ef7\u503c\u7f51\u7edc\u4e0d\u63a7\u5236\u667a\u80fd\u4f53\uff0c\u53ea\u662f\u57fa\u4e8e\u72b6\u6001s\u6765\u5bf9\u8f93\u51fa\u7684\u52a8\u4f5c\u6253\u5206\uff0c\u4ece\u800c\u6307\u5bfc\u51b3\u7b56\u7f51\u7edc\u7684\u8bad\u7ec3\u3002</p> <p>\u786e\u5b9a\u6027\u7b56\u7565\u4e0e\u4e0d\u786e\u5b9a\u6027\u7b56\u7565\u7684\u533a\u522b</p> <ul> <li> <p>\u4e0d\u786e\u5b9a\u6027\u7b56\u7565\uff1a\u5bf9\u4e8e\u79bb\u6563\u7684\u52a8\u4f5c\u7a7a\u95f4\uff0c\u51b3\u7b56\u51fd\u6570\u5f80\u5f80\u4f1a\u5bf9\u6bcf\u4e2a\u52a8\u4f5c\u8f93\u51fa\u4e00\u4e2a\u6982\u7387\u503c\uff0c\u667a\u80fd\u4f53\u6839\u636e\u6240\u5f97\u7684\u6982\u7387\u5206\u5e03\u968f\u673a\u4ece\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u9009\u53d6\u4e00\u4e2a\u52a8\u4f5c\u6765\u6267\u884c\u3002\u5373\u4f7f\u67d0\u4e00\u52a8\u4f5c\u7684\u6982\u7387\u503c\u6700\u5927\uff0c\u6700\u540e\u4e5f\u4e0d\u4e00\u5b9a\u80fd\u9009\u5230\u90a3\u4e2a\u52a8\u4f5c\uff0c\u56e0\u6b64\u8be5\u7b56\u7565\u79f0\u4e3a\u4e0d\u786e\u5b9a\u6027\u7b56\u7565</p> </li> <li> <p>\u786e\u5b9a\u6027\u7b56\u7565\uff1a\u9762\u5bf9\u4e00\u4e2a\u72b6\u6001s\uff0c\u51b3\u7b56\u7f51\u7edc\u8f93\u51fa\u7684\u52a8\u4f5c\u662f\u786e\u5b9a\u7684\uff0c\u5e38\u5e38\u7528\u4e8e\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4\u7684\u5e94\u7528\u3002\u5728\u8f6c\u5411\u65f6\u65e0\u8bba\u8f6c\u591a\u5c11\u5ea6\uff0c\u90fd\u4f1a\u505a\u8f6c\u5411\u8fd9\u4e2a\u52a8\u4f5c\uff0c\u56e0\u6b64\u8be5\u7b56\u7565\u79f0\u4e3a\u786e\u5b9a\u6027\u7b56\u7565</p> </li> </ul>"},{"location":"RL/DDPG/#_2","title":"\u8bad\u7ec3\u6d41\u7a0b","text":"<p>\u2003\u2003\u8be5\u7b97\u6cd5\u4e3b\u8981\u6709\u4e24\u4e2a\u7f51\u7edc\u2014\u2014\u51b3\u7b56\u7f51\u7edcV_\\pi(s)\u548c\u52a8\u4f5c\u4ef7\u503c\u7f51\u7edcQ_w(s,a)\uff0c\u51b3\u7b56\u7f51\u7edc\u5145\u5f53\u6f14\u5458\u7684\u4f5c\u7528\uff0c\u6839\u636e\u5f53\u524d\u7684\u72b6\u6001\u6765\u505a\u51fa\u52a8\u4f5c\uff0c \u52a8\u4f5c\u4ef7\u503c\u7f51\u7edc\u5145\u5f53\u8bc4\u8bba\u5458\u7684\u4f5c\u7528\uff0c\u6839\u636e\u667a\u80fd\u4f53\u6240\u505a\u51fa\u7684\u52a8\u4f5c\u4ee5\u53ca\u5f53\u524d\u7684\u73af\u5883\u6765\u6253\u5206\u3002\u5047\u8bbe\u73af\u5883\u53ef\u4ee5\u770b\u6210\u89c2\u4f17\uff0c\u5219\u8bc4\u8bba\u5458\u8981\u6839\u636e\u89c2\u4f17\u7684\u53cd\u9988\u6765\u8c03\u6574\u81ea\u5df1\u7684\u6253\u5206\u7b56\u7565\uff0c\u6f14\u5458\u8981\u6839\u636e\u8bc4\u8bba\u5458\u7684\u8bc4\u4ef7\u8c03\u6574\u81ea\u5df1\u7684\u52a8\u4f5c\u51b3\u7b56\uff0c\u56e0\u6b64\uff0c\u52a8\u4f5c\u4ef7\u503c\u7f51\u7edcQ_w(s,a)\u901a\u8fc7\u4e0e\u73af\u5883\u505a\u4ea4\u4e92\u6765\u4f18\u5316\u81ea\u5df1\uff0c\u51b3\u7b56\u7f51\u7edcV_\\pi(s)\u901a\u8fc7\u4e0eQ_w(s,a)\u505a\u4ea4\u4e92\u6765\u4f18\u5316\u81ea\u5df1\u3002</p> <p> Q\u7f51\u7edc\u7684\u8bad\u7ec3\u8fc7\u7a0b\u4e0e\u524d\u9762DQN\u7b97\u6cd5\u5f88\u76f8\u4f3c\uff0c\u56e0\u6b64\u8fd9\u91cc\u4e5f\u91c7\u7528\u76ee\u6807\u7f51\u7edc\u4e0e\u7ecf\u9a8c\u56de\u653e\u4e24\u4e2a\u7b56\u7565\uff0c\u6d41\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u6ce8\uff1aDDPG\u4e5f\u662f\u4e00\u4e2a\u5f02\u7b56\u7565\u7684\u7b97\u6cd5\u3002</p> <p>\u8bad\u7ec3\u6b65\u9aa4\uff1a</p> <ul> <li>\u521d\u59cb\u5316\u51b3\u7b56\u7f51\u7edcV_\\pi(s)\u3001\u52a8\u4f5c\u4ef7\u503c\u7f51\u7edcQ_w(s,a)\uff0c\u4ee5\u53ca\u5bf9\u5e94\u7684\u76ee\u6807\u7f51\u7edcV_{\\pi'}(s)\u548cQ_{w'}(s,a)\uff0c\u5e76\u4e14\u4ee4\u5176\u53c2\u6570\u76f8\u7b49\uff0c\u540c\u65f6\u521d\u59cb\u5316\u52a8\u4f5c\u63a2\u7d22\u7684\u968f\u673a\u8fc7\u7a0b\uff0c\u5373\u566a\u58f0N</li> <li>\u8fed\u4ee3\u91c7\u6837\uff0c\u5bf9\u4e8es_t\u6839\u636e\u5f53\u524d\u7684\u7b56\u7565\u548c\u566a\u58f0\u6765\u9009\u62e9\u52a8\u4f5ca_t=V_\\pi(s)+N\uff0ca_t\u4e0e\u73af\u5883\u505a\u4ea4\u4e92\u5f97\u5230s_{t+1}\uff0c\u5c06(s_t,a_t,r_t,s_{t+1})\u5b58\u5165\u7ecf\u9a8c\u7f13\u51b2\u533a\uff0c\u89c4\u5219\u4e0eDQN\u7b97\u6cd5\u4e00\u81f4\uff0c\u91c7\u6837\u8fc7\u7a0b\u4e0d\u6539\u53d8\u7f51\u7edc\u53c2\u6570</li> <li>\u4ece\u7ecf\u9a8c\u7f13\u51b2\u533a\u4e2d\u6309batch\u62bd\u53d6\u4e00\u4e2a\u56db\u5143\u7ec4(s_i,a_i,r_i,s_{i+1})\uff0c\u4ece\u7f13\u51b2\u533a\u62bd\u53d6\u7684\u6570\u636e\u76f8\u5f53\u4e8e\u65e7\u53c2\u6570\u6240\u91c7\u5f97\u7684\u6837\u672c\uff0c\u5373\u65e7\u53c2\u6570\u7684\u9884\u6d4b\u7ed3\u679c</li> <li>\u5c06s_i\u4f20\u5165\u51b3\u7b56\u7f51\u7edc\u5f97\u5230\u52a8\u4f5c\\hat a_i\uff0c\u4e4b\u540e\u5c06(s_i\u3001\\hat a_i)\u4f20\u5165\u4ef7\u503c\u7f51\u7edc\uff0c\u5f97\u5230\u52a8\u4f5c\u5206\u6570\\hat Q_i\uff0c\u4ee5\u6700\u5927\u5316\\hat Q_i\u4e3a\u76ee\u7684\u6765\u4f18\u5316\u51b3\u7b56\u7f51\u7edc\u7684\u53c2\u6570\uff08\u76f4\u63a5\u4ee5\\hat Q_i\u5206\u6570\u5f53\u505a\u4f18\u5316\u76ee\u6807\uff09</li> <li>\u5c06s_{i+1}\u4f20\u5165\u76ee\u6807\u51b3\u7b56\u7f51\u7edc\u5f97\u5230\u52a8\u4f5c\\hat a_{i+1}\uff0c\u518d\u5c06(s_{i+1},\\hat a_{i+1})\u4f20\u5165\u76ee\u6807\u4ef7\u503c\u7f51\u7edc\uff0c\u5229\u7528\u6240\u5f97\u7684\u52a8\u4f5c\u5206\u6570\u6765\u8ba1\u7b97\u5b9e\u9645\u7684Q\u503cy_i=r_i+\\gamma Q_{w'}(s_{i+1},V_{\\pi'}(s_{i+1}))\uff1b\u5c06s_i\u4e0ea_i\u4f20\u5165\u4ef7\u503c\u7f51\u7edc\uff0c\u5f97\u5230\u4f30\u8ba1\u7684Q\u503cQ_i\uff0c\u4ee5\u62c9\u8fdby_i\u4e0eQ_i\u4e4b\u95f4\u7684\u8ddd\u79bb\u6765\u4f18\u5316\u4ef7\u503c\u7f51\u7edc\u7684\u53c2\u6570\u3002\u76ee\u6807\u7f51\u7edc\u53ea\u7528\u4e8e\u8ba1\u7b97\u5b9e\u9645\u503cy_i\uff0c\u56e0\u6b64\u8fd9\u4e2a\u635f\u5931\u53ea\u4f18\u5316\u4ef7\u503c\u7f51\u7edc\u7684\u53c2\u6570\uff0c\u4e0d\u4f18\u5316\u76ee\u6807\u4ef7\u503c\u7f51\u7edc\u7684\u53c2\u6570</li> <li>\u8f6f\u66f4\u65b0\u4e24\u4e2a\u76ee\u6807\u7f51\u7edc\\pi'\\leftarrow\\tau\\pi+(1-\\tau)\\pi'\u3001w'\\leftarrow\\tau w+(1-\\tau)w'</li> </ul>"},{"location":"RL/DDPG/#td3","title":"TD3","text":"<p>\u200b       \u4e0eDQN\u7b97\u6cd5\u7c7b\u4f3c\uff0c\u5728Q\u7f51\u7edc\u7684\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u540c\u6837\u4e5f\u4f1a\u5b58\u5728Q\u5206\u6570\u7684\u9ad8\u4f30\u95ee\u9898\uff0c\u5373Q\u51fd\u6570\u4f1a\u663e\u8457\u5730\u9ad8\u4f30\u5b9e\u9645\u7684Q\u503c\uff0c\u5bf9\u6b64\u5728TQ3\u7b97\u6cd5\u4e2d\u5f15\u5165\u4e86\u4e09\u4e2a\u6539\u8fdb\u63aa\u65bd\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff1a</p> <ul> <li>\u622a\u65ad\u7684\u53ccQ\u5b66\u4e60\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u5747\u65b9\u8bef\u5dee\u6765\u540c\u65f6\u5b66\u4e60\u4e24\u4e2aQ\u51fd\u6570Q_{w_1}\u548cQ_{w_2}\uff0c\u4e24\u4e2aQ\u51fd\u6570\u90fd\u4f7f\u7528\u540c\u4e00\u4e2a\u76ee\u6807\uff0c\u6700\u7ec8\u5b9e\u9645\u7684Q\u503c\u8ba1\u7b97\u65b9\u6cd5\u4e3a\uff1a</li> </ul>  y_i=r_i+\\gamma \\min_{j=1,2}Q_{w_j}(s_{i+1},V_{\\pi'}(s_{i+1}))  <p>\u6ce8\uff1a\u6b64\u65f6\u6709\u4e24\u4e2a\u4ef7\u503c\u7f51\u7edc\u548c\u4e00\u4e2a\u51b3\u7b56\u7f51\u7edc\uff0c\u5e76\u4e14\u90fd\u5bf9\u5e94\u6709\u4e00\u4e2a\u76ee\u6807\u7f51\u7edc\uff0c\u56e0\u6b64\u4e00\u5171\u6709\u516d\u4e2a\u7f51\u7edc</p> <ul> <li>\u5ef6\u8fdf\u7684\u7b56\u7565\u66f4\u65b0\u3002\u540c\u65f6\u66f4\u65b0\u51b3\u7b56\u7f51\u7edc\u548c\u4ef7\u503c\u7f51\u7edc\u4f1a\u5bfc\u81f4\u4e0d\u7a33\u5b9a\uff0c\u56e0\u6b64TD3\u7b97\u6cd5\u4ee5\u8f83\u4f4e\u7684\u9891\u7387\u66f4\u65b0\u51b3\u7b56\u7f51\u7edc\uff0c\u4ee5\u8f83\u9ad8\u7684\u9891\u7387\u66f4\u65b0\u4ef7\u503c\u7f51\u7edc\uff08\u5b9e\u9a8c\u8bc1\u660e\u8fd9\u6837\u6548\u679c\u597d\uff09\uff0c\u901a\u5e38\u6bcf\u66f4\u65b0\u4e24\u6b21\u4ef7\u503c\u7f51\u7edc\u5c31\u66f4\u65b0\u4e00\u6b21\u51b3\u7b56\u7f51\u7edc</li> <li>\u76ee\u6807\u51b3\u7b56\u5e73\u6ed1\uff0cTD3\u7b97\u6cd5\u5728\u76ee\u6807\u51b3\u7b56\u7f51\u7edc\u4e2d\u52a0\u5165\u566a\u58f0\uff0c\u5e73\u6ed1Q\u6cbf\u52a8\u4f5c\u7684\u53d8\u5316\uff0c\u4f7f\u51b3\u7b56\u7f51\u7edc\u66f4\u96be\u5229\u7528Q\u51fd\u6570\u7684\u8bef\u5dee\uff1a</li> </ul>  V'_{\\pi'}(s_{i+1})=clip\\left(V_{\\pi'}(s_{i+1})+clip(\\epsilon,-c,c),a_{low},a_{high} \\right)  <p>\u5176\u4e2d\uff0c\\epsilon\\in N(0,\\sigma)\u3002</p>"},{"location":"RL/DDPG/#ddpg_1","title":"DDPG\u6e90\u7801\u5b9e\u73b0","text":""},{"location":"RL/DDPG/#_3","title":"\u7f51\u7edc\u7ed3\u6784","text":"<p>\u2003\u2003\u51b3\u7b56\u7f51\u7edc\u7684\u8f93\u5165\u7ef4\u5ea6\u4e3a\u72b6\u6001\u6570\u636e\u7684\u7ef4\u5ea6\uff0c\u8f93\u51fa\u7ef4\u5ea6\u4e3a\u52a8\u4f5c\u7684\u4e2a\u6570\uff08\u8868\u793a\u8981\u505a\u51e0\u4e2a\u52a8\u4f5c\uff09\uff0c\u8fd9\u91cc\u6bcf\u4e2a\u6570\u636e\u5747\u8868\u793a\u4e00\u4e2a\u8fde\u7eed\u7684\u503c</p> <p>\u2003\u2003\u4ef7\u503c\u7f51\u7edc\u7684\u8f93\u5165\u7ef4\u5ea6\u4e3a\u72b6\u6001\u6570\u636e\u7684\u7ef4\u5ea6\u52a0\u4e0a\u52a8\u4f5c\u7684\u4e2a\u6570\uff0c\u8f93\u51fa\u7ef4\u5ea6\u4e3a1</p> <pre><code>class Actor(nn.Module):\n    def __init__(self, state_dim, action_dim, hidden_dim, init_w=3e-3):\n        super(Actor, self).__init__()  \n        self.linear1 = nn.Linear(state_dim, hidden_dim)\n        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n        self.linear3 = nn.Linear(hidden_dim, action_dim)\n\n        self.linear3.weight.data.uniform_(-init_w, init_w)\n        self.linear3.bias.data.uniform_(-init_w, init_w)\n\n    def forward(self, x):\n        x = F.relu(self.linear1(x))\n        x = F.relu(self.linear2(x))\n        x = torch.tanh(self.linear3(x))\n        return x\n\nclass Critic(nn.Module):\n    def __init__(self, state_dim, action_dim, hidden_dim, init_w=3e-3):\n        super(Critic, self).__init__()\n\n        self.linear1 = nn.Linear(state_dim + action_dim, hidden_dim)\n        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n        self.linear3 = nn.Linear(hidden_dim, 1)\n        # \u968f\u673a\u521d\u59cb\u5316\u4e3a\u8f83\u5c0f\u7684\u503c\n        self.linear3.weight.data.uniform_(-init_w, init_w)\n        self.linear3.bias.data.uniform_(-init_w, init_w)\n\n    def forward(self, state, action):\n        # \u6309\u7ef4\u65701\u62fc\u63a5\n        x = torch.cat([state, action], 1)\n        x = F.relu(self.linear1(x))\n        x = F.relu(self.linear2(x))\n        x = self.linear3(x)\n        return x\n</code></pre>"},{"location":"RL/DDPG/#_4","title":"\u8bad\u7ec3\u6d41\u7a0b","text":"<pre><code>def train(cfg, env, agent):\n    print('\u5f00\u59cb\u8bad\u7ec3\uff01')\n    print(f'\u73af\u5883\uff1a{cfg.env_name}\uff0c\u7b97\u6cd5\uff1a{cfg.algo_name}\uff0c\u8bbe\u5907\uff1a{cfg.device}')\n    ou_noise = OUNoise(env.action_space)  # \u52a8\u4f5c\u566a\u58f0\n    rewards = []  # \u8bb0\u5f55\u6240\u6709\u56de\u5408\u7684\u5956\u52b1\n    ma_rewards = []  # \u8bb0\u5f55\u6240\u6709\u56de\u5408\u7684\u6ed1\u52a8\u5e73\u5747\u5956\u52b1\n    for i_ep in range(cfg.train_eps):\n        state = env.reset()\n        ou_noise.reset()\n        done = False\n        ep_reward = 0\n        i_step = 0\n        while not done:\n            i_step += 1\n            action = agent.choose_action(state)\n            action = ou_noise.get_action(action, i_step)\n            next_state, reward, done, _ = env.step(action)\n            ep_reward += reward\n            # \u5c06\u6bcf\u4e2a\u9636\u6bb5\u7684\u91c7\u6837\u6570\u636e\u5b58\u5165\u7f13\u51b2\u533a\n            agent.memory.push(state, action, reward, next_state, done)\n            agent.update()\n            state = next_state\n        if (i_ep + 1) % 10 == 0:\n            print('\u56de\u5408\uff1a{}/{}\uff0c\u5956\u52b1\uff1a{:.2f}'.format(i_ep + 1, cfg.train_eps, ep_reward))\n        rewards.append(ep_reward)\n        if ma_rewards:\n            ma_rewards.append(0.9 * ma_rewards[-1] + 0.1 * ep_reward)\n        else:\n            ma_rewards.append(ep_reward)\n    print('\u5b8c\u6210\u8bad\u7ec3\uff01')\n    return rewards, ma_rewards\n</code></pre>"},{"location":"RL/DDPG/#_5","title":"\u66f4\u65b0\u9636\u6bb5","text":"<pre><code>def update(self):\n    if len(self.memory) &lt; self.batch_size: # \u5f53 memory \u4e2d\u4e0d\u6ee1\u8db3\u4e00\u4e2a\u6279\u91cf\u65f6\uff0c\u4e0d\u66f4\u65b0\u7b56\u7565\n        return\n        # \u4ece\u7ecf\u9a8c\u56de\u653e\u4e2d(replay memory)\u4e2d\u968f\u673a\u91c7\u6837\u4e00\u4e2a\u6279\u91cf\u7684\u8f6c\u79fb(transition)\n    state, action, reward, next_state, done = self.memory.sample(self.batch_size)\n    # \u8f6c\u53d8\u4e3a\u5f20\u91cf\n    state = torch.FloatTensor(state).to(self.device)\n    next_state = torch.FloatTensor(next_state).to(self.device)\n    action = torch.FloatTensor(action).to(self.device)\n    reward = torch.FloatTensor(reward).unsqueeze(1).to(self.device)\n    done = torch.FloatTensor(np.float32(done)).unsqueeze(1).to(self.device)\n    # \u8ba1\u7b97\u51b3\u7b56\u7f51\u7edc\u635f\u5931\uff0c\u76f4\u63a5\u4ee5Q\u5206\u6570\u5f53\u505a\u4f18\u5316\u76ee\u6807\n    policy_loss = self.critic(state, self.actor(state))\n    policy_loss = -policy_loss.mean()\n    # \u8ba1\u7b97\u4ef7\u503c\u7f51\u7edc\u635f\u5931\n    next_action = self.target_actor(next_state)\n    target_value = self.target_critic(next_state, next_action.detach())\n    expected_value = reward + (1.0 - done) * self.gamma * target_value\n    expected_value = torch.clamp(expected_value, -np.inf, np.inf)\n\n    value = self.critic(state, action)\n    value_loss = nn.MSELoss()(value, expected_value.detach())\n\n    self.actor_optimizer.zero_grad()\n    policy_loss.backward()\n    self.actor_optimizer.step()\n    self.critic_optimizer.zero_grad()\n    value_loss.backward()\n    self.critic_optimizer.step()\n    # \u8f6f\u66f4\u65b0\n    for target_param, param in zip(self.target_critic.parameters(), self.critic.parameters()):\n        target_param.data.copy_(\n            target_param.data * (1.0 - self.soft_tau) +\n            param.data * self.soft_tau\n        )\n    for target_param, param in zip(self.target_actor.parameters(), self.actor.parameters()):\n        target_param.data.copy_(\n            target_param.data * (1.0 - self.soft_tau) +\n            param.data * self.soft_tau\n        )\n</code></pre> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u6307\u6b63</p> <p>\u521d\u6b65\u5b8c\u7a3f\u4e8e\uff1a2023\u5e745\u670817\u65e5</p>"},{"location":"RL/DQN/","title":"DQN\u7b97\u6cd5\u2014\u2014\u6df1\u5ea6Q\u7f51\u7edc\u7b97\u6cd5","text":"<p>\u672c\u6587\u56fe\u7247\u4e0e\u6e90\u7801\u5747\u6765\u81ea\uff1ahttps://github.com/datawhalechina/easy-rl</p>"},{"location":"RL/DQN/#_1","title":"\u4ecb\u7ecd","text":"<p>\u2003\u2003\u6838\u5fc3\u601d\u60f3\uff1a\u8bad\u7ec3\u52a8\u4f5c\u4ef7\u503c\u51fd\u6570Q_\\theta(s,a)\uff0c\u7528\u4e8e\u4f30\u8ba1\u5f53\u524d\u72b6\u6001s\u4e0b\u9009\u53d6\u5404\u4e2a\u52a8\u4f5ca\u6240\u4ea7\u751f\u7684\u79ef\u7d2f\u6536\u76ca\uff0c\u4e4b\u540e\u9009\u62e9\u79ef\u7d2f\u6536\u76ca\u6700\u5927\u7684\u52a8\u4f5ca\uff0c\u5176\u4e2da\u7684\u8303\u56f4\u5305\u62ec\u6574\u4e2a\u52a8\u4f5c\u7a7a\u95f4\u3002</p> <p>\u4f18\u5316\u76ee\u6807\uff1a $$ Q_\\theta(s_t,a_t)= r(s_t,a_t)+\\gamma\\max_{a}Q_{\\theta}(s_{t+1},a) $$ </p> <p>\u6ce8\uff1a\u5f53\u524d\u52a8\u4f5c\u7684\u79ef\u7d2f\u6536\u76ca\u53ef\u4ee5\u770b\u6210\u5f53\u524d\u52a8\u4f5c\u7684\u4e34\u65f6\u6536\u76ca\u548c\u4e0b\u4e00\u4e2a\u52a8\u4f5c\u7684\u6700\u5927\u79ef\u7d2f\u6536\u76ca\u7684\u548c\uff0c\u56e0\u6b64\u4e3a\u4e86\u4f18\u5316Q\u7f51\u7edc\uff0c\u6211\u4eec\u53ef\u4ee5\u8ba9\u4e0a\u9762\u4e24\u90e8\u5206\u8d8a\u63a5\u8fd1\u8d8a\u597d\uff0c\u53ef\u7528\u8ddd\u79bb\u635f\u5931\u5b9e\u73b0\u3002</p>"},{"location":"RL/DQN/#_2","title":"\u5e38\u7528\u6280\u5de7","text":"<p>\u76ee\u6807\u7f51\u7edc</p> <p>\u2003\u2003\u7531\u4e8e\u635f\u5931\u51fd\u6570\u5305\u62ecQ_\\theta(s,a)\u7f51\u7edc\u8f93\u51fa\u7684\u4e24\u4e2aQ\u5206\u6570\uff0c\u7f51\u7edc\u4f1a\u4ece\u4e24\u4e2a\u65b9\u5411\u53bb\u4f18\u5316\u7f51\u7edc\u53c2\u6570\uff0c\u4e0d\u7a33\u5b9a\u6027\u56e0\u7d20\u8f83\u9ad8\u3002\u4ee5y=r(s,a)+\\gamma\\max_{a'}Q_{\\theta}(s',a')\u4f5c\u4e3a\u4f18\u5316\u76ee\u6807\u4e3a\u4f8b\uff0c\u53c2\u6570\\theta\u4f1a\u968f\u7740\u8bad\u7ec3\u7684\u8fdb\u884c\u4e0d\u65ad\u53d8\u5316\uff0c\u56e0\u6b64y\u7684\u503c\u4f1a\u4e0d\u65ad\u6539\u53d8\uff0c\u7f51\u7edc\u9700\u8981\u62df\u5408\u4e00\u4e2a\u4e0d\u65ad\u53d8\u52a8\u7684\u76ee\u6807\uff0c\u4e0d\u592a\u597d\u8bad\u7ec3\u3002</p> <p>\u2003\u2003\u5bf9\u6b64\uff0c\u5e38\u5e38\u4f1a\u56fa\u5b9a\u4f4f\u4e00\u4e2aQ\u5206\u6570\u7684\u8f93\u51fa\u89c4\u5219\uff0c\u4f7f\u5176\u6210\u4e3a\u4f18\u5316\u76ee\u6807\uff0c\u8ba9\u53e6\u4e00\u4e2aQ\u5206\u6570\u4e0d\u65ad\u671d\u5176\u63a8\u8fdb\u9760\u62e2\u3002\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u5e38\u5e38\u4ee5y=r(s,a)+\\gamma\\max_{a'}Q_{\\theta}(s',a')\u4f5c\u4e3a\u4f18\u5316\u76ee\u6807\uff0c\u9884\u8bbe\u4e00\u4e2a\u76ee\u6807Q_{\\hat \\theta}(s,a)\u7f51\u7edc\uff0c\u5e76\u4e14\u56fa\u5b9a\u4f4f\u4ed6\u7684\u53c2\u6570\uff0cQ\u7f51\u7edc\u6bcf\u66f4\u65b0\u6307\u5b9a\u6b21\u53c2\u6570(C\u6b21)\uff0c\u5c31\u66f4\u65b0\u4e00\u6b21\u76ee\u6807Q_{\\hat \\theta}(s,a)\u7f51\u7edc\u7684\u53c2\u6570\uff0c\u4f7f\\hat \\theta=\\theta\uff0c\u5177\u4f53\u6d41\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u63a2\u7d22\u673a\u5236</p> <p>\u2003\u2003\u5982\u679c\u52a8\u4f5c\u53ea\u5229\u7528Q\u51fd\u6570\u7684\u4f30\u8ba1\u503c\u53bb\u9009\u62e9\uff0c\u90a3\u4e48\u52a8\u4f5c\u7684\u9009\u53d6\u53ef\u80fd\u4f1a\u5177\u6709\u5355\u4e00\u6027\uff0c\u5373\u6ca1\u89c1\u8fc7\u7684\u52a8\u4f5c-\u72b6\u6001\u5bf9\u4f30\u8ba1\u4e0d\u51fa\u4ef7\u503c\u6765\uff0c\u4e0d\u4f1a\u53bb\u63a2\u7d22\u65b0\u7684\u52a8\u4f5c\uff0c\u5bb9\u6613\u9677\u5165\u5230\u4e00\u4e2a\u5c40\u90e8\u6700\u4f18\u89e3\u91cc\uff0c\u7c7b\u4f3c\u8fc7\u62df\u5408\u4e86\uff0c\u6a21\u578b\u53ea\u8ba4\u51c6\u67d0\u4e9b\u52a8\u4f5c\uff0c\u5bf9\u6b64\uff0c\u5e38\u5e38\u4f7f\u7528\\varepsilon-\u8d2a\u5fc3\u65b9\u6cd5\u3001\u73bb\u5c14\u5179\u66fc\u63a2\u7d22\u65b9\u6cd5\u6765\u89e3\u51b3\u8be5\u95ee\u9898\u3002</p> <ul> <li>\\varepsilon-\u8d2a\u5fc3\uff1a</li> </ul>  a=\\left\\{\\begin{matrix} \\arg\\max_a Q(s,a),&amp;p=1-\\varepsilon  \\\\ \u968f\u673a\u52a8\u4f5c,&amp;p=\\varepsilon \\end{matrix}\\right.  <p>\u8bbe\u7f6e\u4e00\u4e2a\u8d85\u53c2\u6570\\varepsilon\uff0c\u6709\u51e0\u7387\u968f\u673a\u9009\u62e9\u52a8\u4f5c\u6765\u6267\u884c\u3002</p> <ul> <li>\u73bb\u5c14\u5179\u66fc\u63a2\u7d22\uff1a</li> </ul>  \\pi(a|s)=\\frac{e^{Q(s,a)/T}}{\\sum_{a'\\in A}e^{Q(s,a')/T}}  <p>\u5176\u4e2d\uff0cA\u8868\u793a\u52a8\u4f5c\u7a7a\u95f4\uff0cT&gt;0\u79f0\u4e3a\u6e29\u5ea6\u7cfb\u6570\uff0c\u5982\u679cT\u5f88\u5927\uff0c\u5219\u6240\u6709\u7684\u52a8\u4f5c\u51e0\u4e4e\u7b49\u6982\u7387\u9009\u62e9\uff08\u63a2\u7d22\uff09\uff1b\u5982\u679cT\u5f88\u5c0f\uff0c\u90a3\u4e48Q\u5206\u6570\u5927\u7684\u52a8\u4f5c\u66f4\u5bb9\u6613\u88ab\u9009\u4e2d\uff1b\u5982\u679cT\u8d8b\u4e8e0\uff0c\u5219\u53ea\u9009\u62e9\u6700\u4f18\u52a8\u4f5c\u3002</p> <p>\u7ecf\u9a8c\u56de\u653e</p> <p>\u2003\u2003\u5728\u5229\u7528DQN\u7b97\u6cd5\u53bb\u8bad\u7ec3\u7f51\u7edc\u65f6\uff0c\u6a21\u578b\u4e0e\u73af\u5883\u505a\u4ea4\u4e92\u5f80\u5f80\u4f1a\u5f88\u82b1\u8d39\u65f6\u95f4\uff0c\u5e76\u4e14\u5728\u505a\u53c2\u6570\u66f4\u65b0\u65f6\uff0c\u7ecf\u9a8c\u4e0d\u9700\u8981\u901a\u901a\u6765\u81ea\u67d0\u4e00\u4e2a\u7b56\u7565\uff0c\u4e5f\u53ef\u4ee5\u5229\u7528\u8fc7\u53bb\u7684\u7b56\u7565\u6765\u5b66\u4e60\u7ecf\u9a8c\uff0c\u56e0\u6b64\uff0c\u6211\u4eec\u53ef\u4ee5\u8bbe\u7f6e\u4e00\u7ec4\u7f13\u51b2\u533a\uff0c\u5c06\u4ea4\u4e92\u6240\u5f97\u7684\u6837\u672c\u653e\u5165\u7f13\u51b2\u533a\u4e2d\uff0c\u4e4b\u540e\u5bf9\u7f13\u51b2\u533a\u91cc\u7684\u6570\u636e\u505a\u91c7\u6837\uff0c\u66f4\u65b0\u53c2\u6570\uff0c\u5177\u4f53\u6d41\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u6ce8\uff1a\u5982\u679c\u7f13\u51b2\u533a\u5df2\u6ee1\uff0c\u5219\u5229\u7528\u65b0\u6837\u672c\u66ff\u4ee3\u65e7\u6837\u672c\uff0c\u653e\u5f03\u65e7\u7684\u7ecf\u9a8c\u3002\u5229\u7528\u7ecf\u9a8c\u56de\u653e\u8fd8\u6709\u4e00\u4e2a\u597d\u5904\uff0c\u5c31\u662f\u53ef\u4ee5\u6253\u7834\u5e8f\u5217\u7684\u76f8\u5173\u6027\u3002</p>"},{"location":"RL/DQN/#_3","title":"\u7b97\u6cd5\u6b65\u9aa4","text":"<ul> <li>\u521d\u59cb\u5316Q\u7f51\u7edc\u3001\u76ee\u6807\\hat{Q}\u7f51\u7edc\uff0c\u5e76\u4e14\u4ee4\\hat Q=Q</li> <li>\u904d\u5386\u6bcf\u4e2aepisodes\uff0c\u5047\u8bbet\u4e3a\u5f53\u524d\u7684\u65f6\u95f4\u6b65</li> <li>\u7ed9\u5b9a\u4e00\u4e2a\u72b6\u6001s_t\uff0c\u5c06\u5176\u4f20\u5165Q\u7f51\u7edc\uff0c\u8ba1\u7b97\u6bcf\u4e2a\u52a8\u4f5c\u4f1a\u4ea7\u751f\u7684Q\u5206\u6570\uff08\u89c6\u4e3aQ(s_t,a_t)\uff09\uff0c\u6982\u7387\u9009\u62e9\u662f\u6309Q\u5206\u6570\u9009\u62e9\u52a8\u4f5c\u8fd8\u662f\u968f\u673a\u9009\u62e9\u52a8\u4f5c\u3002\u5982\u679c\u662f\u6309Q\u5206\u6570\u9009\u62e9\uff0c\u5219\u53d6\u51fa\u53ef\u4ee5\u4f7fQ\u5206\u6570\u6700\u5927\u7684\u52a8\u4f5ca_t\uff0c\u5373\u5f53\u524d\u72b6\u6001\u4e0b\u53d6\u52a8\u4f5ca_t\u65f6\uff0c\u672a\u6765\u7684\u79ef\u7d2f\u6536\u76ca\u4f1a\u6700\u5927</li> <li>\u83b7\u5f97\u53cd\u9988r_t\u4ee5\u53ca\u4e0b\u4e00\u9636\u6bb5\u7684\u72b6\u6001s_{t+1}</li> <li>\u5c06(s_t,a_t,r_t,s_{t+1})\u5b58\u5165\u7f13\u51b2\u533a\uff0c\u5f53\u505a\u4e00\u4e2a\u66f4\u65b0\u6837\u672c\uff08\u5f53\u7f13\u51b2\u533a\u5b58\u6ee1\u6570\u636e\u4ee5\u540e\uff0c\u624d\u505a\u540e\u7eed\u91c7\u6837\u66f4\u65b0\uff0c\u5e76\u4e14\u5b58\u6ee1\u4ee5\u540e\uff0c\u518d\u6b21\u83b7\u5f97\u66f4\u65b0\u6837\u672c\u65f6\u4f1a\u4ece\u524d\u5f80\u540e\u8986\u76d6\u6570\u636e\uff09</li> <li>\u6309\u6279\u91cf\u5f62\u5f0f\u4ece\u7f13\u51b2\u533a\u91c7\u6837\uff0c\u91c7\u53d6batch\u4e2a\u66f4\u65b0\u6837\u672c(s_i,a_i,r_i,s_{i+1})</li> <li>\u5c06s_{i+1}\u4f20\u5165\u76ee\u6807\\hat Q\u7f51\u7edc\u4e2d\uff0c\u5f97\u5230\u4e0b\u4e00\u9636\u6bb5\u6bcf\u4e2a\u52a8\u4f5c\u7684\u79ef\u7d2f\u6536\u76ca\uff0c\u5e76\u4e14\u9009\u53d6\u6700\u5927\u7684\u6536\u76ca\\max_a \\hat{Q}(s_{i+1},a_{i+1})</li> <li>\u8ba1\u7b97\u76ee\u6807\u503cy=r_i+\\gamma \\max_a \\hat{Q}(s_{i+1},a_{i+1})\uff0c\u5176\u4e2d\\gamma\u8868\u793a\u6298\u6263\u56e0\u5b50\uff0c\u5229\u7528y\u6765\u4f18\u5316Q\u7f51\u7edc\u7684\u53c2\u6570\uff0c\u4f7f\u5f97Q(s_i,a_i)\u5411y\u4e0d\u65ad\u9760\u8fd1\uff08\u6ce8\u610f\uff0c\u6b64\u65f6\u53ea\u66f4\u65b0Q\u7f51\u7edc\u7684\u53c2\u6570\uff0c\u4e0d\u66f4\u65b0\\hat Q\u7f51\u7edc\u7684\u53c2\u6570\uff09</li> <li>Q\u7f51\u7edc\u6bcf\u66f4\u65b0C\u6b21\u53c2\u6570\uff0c\u5c31\u91cd\u7f6e\u4e00\u6b21\u76ee\u6807\\hat Q\u7f51\u7edc\u7684\u53c2\u6570\\hat Q=Q</li> </ul> <p>\u6ce8\uff1aQ\u7f51\u7edc\u7684\u8f93\u5165\u4ec5\u4e3as_t\uff0c\u8f93\u51fa\u6570\u636e\u7684\u7ef4\u5ea6\u4e3a\u52a8\u4f5c\u7a7a\u95f4\u7684\u7ef4\u5ea6n\uff0c\u5373\u8868\u793a\u5728\u72b6\u6001s_t\u4e0b\u6267\u884c\u52a8\u4f5ca_i\u65f6\u4f1a\u4ea7\u751f\u7684\u79ef\u7d2f\u6536\u76ca\uff0c\u5176\u4e2di\\le n\uff0c\u56e0\u6b64\uff0c\u4f20\u52a8\u7684DQN\u7b97\u6cd5\u53ea\u9002\u7528\u4e8e\u52a8\u4f5c\u7a7a\u95f4\u79bb\u6563\u5206\u5e03\u7684\u60c5\u51b5\uff0c\u4e0d\u9002\u7528\u4e8e\u8fde\u7eed\u5206\u5e03\u7684\u60c5\u51b5\u3002</p>"},{"location":"RL/DQN/#dqn","title":"DQN\u6e90\u7801\u5b9e\u73b0","text":""},{"location":"RL/DQN/#_4","title":"\u7f51\u7edc\u7ed3\u6784","text":"<pre><code>class DQN:\n    def __init__(self, state_dim, action_dim, cfg):\n\n        self.action_dim = action_dim  # \u603b\u7684\u52a8\u4f5c\u4e2a\u6570\n        self.device = cfg.device  # \u8bbe\u5907\uff0ccpu\u6216gpu\u7b49\n        self.gamma = cfg.gamma  # \u5956\u52b1\u7684\u6298\u6263\u56e0\u5b50\n        # e-greedy\u7b56\u7565\u76f8\u5173\u53c2\u6570\n        self.frame_idx = 0  # \u7528\u4e8eepsilon\u7684\u8870\u51cf\u8ba1\u6570\n        self.epsilon = lambda frame_idx: cfg.epsilon_end + \\\n                                         (cfg.epsilon_start - cfg.epsilon_end) * \\\n                                         math.exp(-1. * frame_idx / cfg.epsilon_decay)\n        self.batch_size = cfg.batch_size\n        self.policy_net = MLP(state_dim, action_dim, hidden_dim=cfg.hidden_dim).to(self.device)\n        self.target_net = MLP(state_dim, action_dim, hidden_dim=cfg.hidden_dim).to(self.device)\n        for target_param, param in zip(self.target_net.parameters(),\n                                       self.policy_net.parameters()):  # \u590d\u5236\u53c2\u6570\u5230\u76ee\u6807\u7f51\u8deftarge_net\n            target_param.data.copy_(param.data)\n        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=cfg.lr)  # \u4f18\u5316\u5668\n        self.memory = ReplayBuffer(cfg.memory_capacity)  # \u7ecf\u9a8c\u56de\u653e\n\n    def choose_action(self, state):\n        \"\"\"\n        \u9009\u62e9\u52a8\u4f5c\n        \"\"\"\n        self.frame_idx += 1\n        # \u5f15\u5165\u63a2\u7d22\u673a\u5236\uff0c\u6982\u7387\u9009\u62e9\u662f\u6309Q\u5206\u6570\u9009\u62e9\u52a8\u4f5c\u8fd8\u662f\u968f\u673a\u9009\u62e9\u52a8\u4f5c\n        if random.random() &gt; self.epsilon(self.frame_idx):\n            with torch.no_grad():\n                state = torch.tensor([state], device=self.device, dtype=torch.float32)\n                q_values = self.policy_net(state)\n                action = q_values.max(1)[1].item()  # \u9009\u62e9Q\u503c\u6700\u5927\u7684\u52a8\u4f5c\n        else:\n            action = random.randrange(self.action_dim)\n        return action\n\n    def update(self):\n        # \u7ecf\u9a8c\u56de\u653e\u673a\u5236\n        # \u5f53memory\u4e2d\u4e0d\u6ee1\u8db3\u4e00\u4e2a\u6279\u91cf\u65f6\uff0c\u4e0d\u66f4\u65b0\u7b56\u7565\n        if len(self.memory) &lt; self.batch_size:\n            return\n        # \u4ece\u7ecf\u9a8c\u56de\u653e\u4e2d(replay memory)\u4e2d\u968f\u673a\u91c7\u6837\u4e00\u4e2a\u6279\u91cf\u7684\u8f6c\u79fb(transition)\n        state_batch, action_batch, reward_batch, next_state_batch, done_batch = self.memory.sample(\n            self.batch_size)\n        # \u8f6c\u4e3a\u5f20\u91cf\n        state_batch = torch.tensor(state_batch, device=self.device, dtype=torch.float)\n        action_batch = torch.tensor(action_batch, device=self.device).unsqueeze(1)\n        reward_batch = torch.tensor(reward_batch, device=self.device, dtype=torch.float)\n        next_state_batch = torch.tensor(next_state_batch, device=self.device, dtype=torch.float)\n        done_batch = torch.tensor(np.float32(done_batch), device=self.device)\n        # \u8ba1\u7b97\u5f53\u524d\u72b6\u6001(s_t,a)\u5bf9\u5e94\u7684Q(s_t, a)\uff0c\u63d0\u53d6\u5f53\u65f6\u6267\u884c\u52a8\u4f5ca\u65f6\u6240\u4ea7\u751f\u7684Q\u5206\u6570\n        q_values = self.policy_net(state_batch).gather(dim=1, index=action_batch)\n        # \u8ba1\u7b97\u4e0b\u4e00\u65f6\u523b\u7684\u72b6\u6001(s_t_,a)\u5bf9\u5e94\u7684Q\u503c\uff0c\u63d0\u53d6\u6700\u5927\u7684Q\u5206\u6570\n        next_q_values = self.target_net(next_state_batch).max(1)[0].detach()\n        # \u8ba1\u7b97\u671f\u671b\u7684Q\u503c\uff0c\u5bf9\u4e8e\u7ec8\u6b62\u72b6\u6001\uff0c\u6b64\u65f6done_batch[0]=1, \u5bf9\u5e94\u7684expected_q_value\u7b49\u4e8ereward\n        expected_q_values = reward_batch + self.gamma * next_q_values * (1 - done_batch)\n        # \u8ba1\u7b97\u5747\u65b9\u6839\u635f\u5931\uff0c\u8ba9t\u72b6\u6001\u6267\u884c\u52a8\u4f5ca\u65f6\u4ea7\u751f\u7684\u79ef\u7d2f\u4ef7\u503c\u91cf\u5411\u6700\u9ad8\u7684\u79ef\u7d2f\u4ef7\u503c\u91cf\u9760\u62e2\n        loss = nn.MSELoss()(q_values, expected_q_values.unsqueeze(1))\n        # \u4f18\u5316\u66f4\u65b0\u6a21\u578b\n        self.optimizer.zero_grad()\n        loss.backward()\n        for param in self.policy_net.parameters():  # clip\u9632\u6b62\u68af\u5ea6\u7206\u70b8\n            param.grad.data.clamp_(-1, 1)\n        self.optimizer.step()\n\n    def save(self, path):\n        torch.save(self.target_net.state_dict(), path + 'dqn_checkpoint.pth')\n\n    def load(self, path):\n        self.target_net.load_state_dict(torch.load(path + 'dqn_checkpoint.pth'))\n        for target_param, param in zip(self.target_net.parameters(), self.policy_net.parameters()):\n            param.data.copy_(target_param.data)\n</code></pre>"},{"location":"RL/DQN/#_5","title":"\u8bad\u7ec3\u7b56\u7565","text":"<pre><code>def train(cfg, env, agent):\n    ''' \u8bad\u7ec3\n    '''\n    print('\u5f00\u59cb\u8bad\u7ec3!')\n    print(f'\u73af\u5883\uff1a{cfg.env_name}, \u7b97\u6cd5\uff1a{cfg.algo_name}, \u8bbe\u5907\uff1a{cfg.device}')\n    rewards = []  # \u8bb0\u5f55\u6240\u6709\u56de\u5408\u7684\u5956\u52b1\n    ma_rewards = []  # \u8bb0\u5f55\u6240\u6709\u56de\u5408\u7684\u6ed1\u52a8\u5e73\u5747\u5956\u52b1\n    for i_ep in range(cfg.train_eps):\n        ep_reward = 0  # \u8bb0\u5f55\u4e00\u56de\u5408\u5185\u7684\u5956\u52b1\n        state = env.reset()  # \u91cd\u7f6e\u73af\u5883\uff0c\u8fd4\u56de\u521d\u59cb\u72b6\u6001\n        while True:\n            # \u5c06\u72b6\u6001\u4f20\u5165Q\u7f51\u7edc\uff0c\u9009\u53d6\u53ef\u4ee5\u4f7fQ\u5206\u6570\u6700\u5927\u7684\u52a8\u4f5c\n            action = agent.choose_action(state)  # \u9009\u62e9\u52a8\u4f5c\n            next_state, reward, done, _ = env.step(action)  # \u66f4\u65b0\u73af\u5883\uff0c\u8fd4\u56detransition\n            agent.memory.push(state, action, reward,\n                              next_state, done)  # \u4fdd\u5b58transition\n            state = next_state  # \u66f4\u65b0\u4e0b\u4e00\u4e2a\u72b6\u6001\n            agent.update()  # \u66f4\u65b0\u667a\u80fd\u4f53\n            ep_reward += reward  # \u7d2f\u52a0\u5956\u52b1\n            if done:\n                break\n        # \u6bcf\u66f4\u65b0C\u6b21\u53c2\u6570\uff0c\u5c31\u66f4\u65b0\u4e00\u6b21\u76ee\u6807Q\u7f51\u7edc\uff0c\u5c06Q\u7f51\u7edc\u7684\u53c2\u6570\u8d4b\u503c\u7ed9\u76ee\u6807Q\u7f51\u7edc\n        if (i_ep + 1) % cfg.target_update == 0:\n            agent.target_net.load_state_dict(agent.policy_net.state_dict())\n        rewards.append(ep_reward)\n        if ma_rewards:\n            ma_rewards.append(0.9 * ma_rewards[-1] + 0.1 * ep_reward)\n        else:\n            ma_rewards.append(ep_reward)\n        if (i_ep + 1) % 10 == 0:\n            print('\u56de\u5408\uff1a{}/{}, \u5956\u52b1\uff1a{}'.format(i_ep + 1, cfg.train_eps, ep_reward))\n    print('\u5b8c\u6210\u8bad\u7ec3\uff01')\n    env.close()\n    return rewards, ma_rewards\n</code></pre>"},{"location":"RL/DQN/#dqn_1","title":"DQN\u7b97\u6cd5\u8fdb\u9636","text":""},{"location":"RL/DQN/#qdouble_dqn","title":"\u53cc\u6df1\u5ea6Q\u7f51\u7edc\uff08Double DQN\uff09","text":"<p>\u2003\u2003\u7531\u4e8e\u5728\u8bad\u7ec3\u65f6\uff0c\u7b49\u5f0f\u53f3\u4fa7\u59cb\u7ec8\u4ee5\u6700\u5927\u7684Q\u5206\u6570\u5f53\u505a\u4f18\u5316\u76ee\u6807\uff0c\u56e0\u6b64\u76ee\u6807\u503c\u5f88\u5bb9\u6613\u88ab\u8bbe\u7684\u592a\u9ad8\uff0c\u6240\u8bad\u7ec3\u7684Q\u7f51\u7edc\u5728\u5e94\u7528\u65f6\u5f88\u5bb9\u6613\u975e\u5747\u5300\u5730\u9ad8\u4f30\u5b9e\u9645\u7684Q\u503c\uff0c\u4e0d\u5229\u4e8e\u51c6\u786e\u5730\u6839\u636e\u4ef7\u503c\u6765\u51b3\u7b56\u3002\u5bf9\u6b64\uff0c\u53ef\u4ee5\u7528\u4e24\u4e2aQ\u7f51\u7edc\u53bb\u4f30\u8ba1\u4f18\u5316\u76ee\u6807\u4e2d\u7684Q\u5206\u6570\uff0c\u4f18\u5316\u76ee\u6807\u5982\u4e0b\uff1a $$ Q(s_t,a_t)\\leftrightarrow r_t+Q'(s_{t+1},\\arg\\max_a Q(s_{t+1},a)) $$  \u5728\u5b9e\u73b0\u8fc7\u7a0b\u4e2d\uff0c\u6211\u4eec\u4f1a\u7528\u4f1a\u66f4\u65b0\u53c2\u6570\u7684Q\u7f51\u7edc\u53bb\u9009\u52a8\u4f5c\uff0c\u7528\u76ee\u6807Q\u7f51\u7edc\u53bb\u8ba1\u7b97\u503c\uff0c\u6838\u5fc3\u6e90\u7801\u5982\u4e0b\uff1a</p> <pre><code># \u5b9e\u9645\u7684Q\u503c\nq_value_batch = self.policy_net(state_batch).gather(dim=1, index=action_batch) \n# \u4e0b\u4e00\u4e2a\u72b6\u6001\u5bf9\u5e94\u7684\u5b9e\u9645\u7b56\u7565\u7f51\u7edcQ\u503c\nnext_q_value_batch = self.policy_net(next_state_batch) \n# \u4e0b\u4e00\u4e2a\u72b6\u6001\u5bf9\u5e94\u7684\u76ee\u6807\u7f51\u7edcQ\u503c\nnext_target_value_batch = self.target_net(next_state_batch)\n# \u5c06\u7b56\u7565\u7f51\u7edcQ\u503c\u6700\u5927\u7684\u52a8\u4f5c\u5bf9\u5e94\u7684\u76ee\u6807\u7f51\u7edcQ\u503c\u4f5c\u4e3a\u671f\u671b\u7684Q\u503c\nnext_target_q_value_batch = next_target_value_batch.gather(1, torch.max(next_q_value_batch, 1)[1].unsqueeze(1))\n# \u671f\u671b\u7684Q\u503c\nexpected_q_value_batch = reward_batch + self.gamma * next_target_q_value_batch* (1-done_batch) \n# \u8ba1\u7b97\u635f\u5931\nloss = nn.MSELoss()(q_value_batch, expected_q_value_batch)\n</code></pre>"},{"location":"RL/DQN/#qdueling_dqn","title":"\u7ade\u4e89\u6df1\u5ea6Q\u7f51\u7edc\uff08Dueling DQN\uff09","text":"<p>\u2003\u2003\u539f\u59cb\u7684Q\u7f51\u7edc\u53ea\u6cbf\u7740\u4e00\u4e2a\u5206\u652f\u53bb\u4f18\u5316\uff0c\u8f93\u51fa\u4e00\u7ec4Q\u5206\u6570\uff0c\u5728Dueling DQN\u4e2d\uff0c\u4f1a\u5728\u7f51\u7edc\u540e\u7aef\u5f15\u51fa\u4e24\u4e2a\u5b50\u7f51\u7edc\u7ed3\u6784\uff0c\u5206\u522b\u5bf9\u5e94\u5230\u4ef7\u503c\u51fd\u6570V(s)\u548c\u4f18\u52bf\u51fd\u6570A(s,a)\uff0c\u6700\u7ec8Q\u7f51\u7edc\u7684\u8f93\u51fa\u7531\u4ef7\u503c\u51fd\u6570\u8f93\u51fa\u548c\u4f18\u52bf\u51fd\u6570\u8f93\u51fa\u7684\u7ebf\u6027\u7ec4\u5408\u5f97\u5230\uff0c\u533a\u522b\u5982\u4e0b\uff1a</p> <ul> <li> <p>\u4f20\u7edf\u7684DQN\u7b97\u6cd5\u4e00\u822c\u5229\u7528\u6837\u672c\u66f4\u65b0\u53c2\u6570\u65f6\uff0c\u53ea\u4f1a\u66f4\u65b0\u5f53\u524d\u72b6\u6001\u4e0b\u67d0\u4e00\u4e2a\u52a8\u4f5c\u7684Q\u5206\u6570</p> </li> <li> <p>\u591a\u5f15\u5165\u4e00\u4e2a\u4ef7\u503c\u51fd\u6570V(s)\u76f8\u5f53\u4e8e\u5728\u7f51\u7edc\u7684\u8f93\u51fa\u4e2d\u6dfb\u52a0\u4e00\u4e2a\u504f\u7f6e\u9879\uff0c\u5728\u7ebf\u6027\u8fd0\u7b97\u4e2d\uff0c\u504f\u7f6e\u9879\u6539\u53d8\u4e00\u6b21\u4f1a\u76f4\u63a5\u5f71\u54cd\u6240\u6709\u4f4d\u7f6e\u7684\u8f93\u51fa\u7ed3\u679c\uff0c\u56e0\u6b64\u5728Q\u7f51\u7edc\u4e2d\uff0c\u5f15\u5165V(s)\u4e4b\u540e\uff0c\u6bcf\u4e00\u4e2a\u6837\u672c\u90fd\u53ef\u4ee5\u901a\u8fc7\u66f4\u65b0V(s)\u6765\u5f71\u54cd\u5f53\u524d\u72b6\u6001\u4e0b\u6240\u6709\u52a8\u4f5c\u7684Q\u5206\u6570\u3002</p> </li> </ul> <p> <p></p> <p></p> <p>\u2003\u2003\u540c\u65f6\uff0c\u4e3a\u4e86\u8ba9\u7f51\u7edc\u53ef\u4ee5\u8fa8\u8bc6V(s)\u548cA(s,a)\u7684\u4f5c\u7528\uff0c\u8ba9\u5176\u771f\u6b63\u610f\u8bc6\u5230\u5f15\u5165V(s)\u7684\u76ee\u7684\uff0c\u6211\u4eec\u4f1a\u989d\u5916\u5bf9A(s,a)\u505a\u4e00\u4e2a\u7ea6\u675f\uff0c\u8ba9\u5176\u66f4\u65b0\u6bd4\u8f83\u201c\u9ebb\u70e6\u201d\uff0c\u9632\u6b62\u7f51\u7edc\u8bad\u7ec3\u51fa\u6765\u7684V(s)=0\uff0cA(s,a)=Q(s,a)\uff0c\u4f8b\u5982\u8ba9A(s,a)\u7684\u6bcf\u4e00\u5217\u6570\u636e\u548c\u4e3a0\uff0c\u5b9e\u73b0\u8d77\u6765\u5c31\u662f\u8ba9A(s,a)\u51cf\u53bb\u5747\u503c\uff0c\u6539\u8fdb\u540e\u7684Q\u51fd\u6570\u8868\u8fbe\u5f0f\u4e3a\uff1a $$ Q(s, a)=V(s)+\\left(A(s, a)-\\frac{1}{\\mathcal{A}} \\sum_{a^{\\prime} \\in \\mathcal{A}} A\\left(s, a\\right)\\right) $$ </p> <p>\u6ce8\uff1a\u5982\u679c\u4ee5\u76f8\u540c\u7684\u89c4\u5219\u53bb\u66f4\u65b0V(s)\u548cA(s,a)\u7684\u8bdd\uff0c\u5bb9\u6613\u5bfc\u81f4\u7f51\u7edc\u5177\u6709\u4e0d\u552f\u4e00\u6027\uff0c\u4e0d\u540c\u7684A(s,a)\u3001V(s)\u7ec4\u5408\u6709\u53ef\u80fd\u4f1a\u5f97\u5230\u540c\u4e00\u4e2aQ\u5206\u6570\u3002</p> <p>\u7f51\u7edc\u7ed3\u6784\u6e90\u7801\u5982\u4e0b</p> <pre><code>class DuelingNet(nn.Module):\n    def __init__(self, n_states, n_actions,hidden_dim=128):\n        super(DuelingNet, self).__init__()\n\n        # hidden layer\n        self.hidden_layer = nn.Sequential(\n            nn.Linear(n_states, hidden_dim),\n            nn.ReLU()\n        )\n\n        #  advantage\n        self.advantage_layer = nn.Sequential(\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, n_actions)\n        )\n\n        # value\n        self.value_layer = nn.Sequential(\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, 1)\n        )\n\n    def forward(self, state):\n        x = self.hidden_layer(state)\n        advantage = self.advantage_layer(x)\n        value     = self.value_layer(x)\n        return value + advantage - advantage.mean()\n</code></pre>"},{"location":"RL/DQN/#per","title":"\u4f18\u5148\u7ea7\u7ecf\u9a8c\u56de\u653e\uff08PER\uff09","text":"<p>\u2003\u2003\u5728\u6700\u521d\u7684\u7ecf\u9a8c\u56de\u653e\u7b56\u7565\u4e2d\uff0c\u4f1a\u5747\u5300\u5730\u4ece\u7f13\u51b2\u533a\u91cc\u91c7\u6837\u6570\u636e\uff0c\u4f46\u5b9e\u9645\u60c5\u51b5\u4e2d\uff0c\u8fd9\u4e9b\u6837\u672c\u4e0d\u4e00\u5b9a\u662f\u6700\u597d\u7684\uff0c\u6709\u7684\u6570\u636e\u53ef\u80fd\u4f1a\u6bd4\u8f83\u91cd\u8981\uff0c\u56e0\u6b64\u6211\u4eec\u53ef\u4ee5\u7ed9\u6bcf\u4e2a\u6837\u672c\u8d4b\u4e00\u4e2a\u91c7\u6837\u6743\u91cd\uff0c\u5bf9\u4e8e\u8f93\u51fa\u503c\u4e0e\u76ee\u6807\u503c\u5dee\u8ddd\u6bd4\u8f83\u5927\u3001\u6bd4\u8f83\u4e0d\u597d\u8bad\u7ec3\u7684\u6837\u672c\uff0c\u8d4b\u7ed9\u5176\u5927\u7684\u91c7\u6837\u6743\u91cd\uff0c\u8ba9\u5176\u66f4\u5bb9\u6613\u88ab\u91c7\u5230\uff0c\u5177\u4f53\u5730\u6765\u8bf4\uff0c\u91c7\u6837\u6743\u91cd\u53ef\u4ee5\u901a\u8fc7\u8ba1\u7b97Q(s_t,a_t)-[r_t+\\gamma\\max_a Q(s_{t+1},a)]\u6765\u5f97\u5230\u3002</p> <p>\u2003\u2003\u540c\u65f6\uff0c\u5982\u679c\u505a\u975e\u5747\u5300\u91c7\u6837\u7684\u8bdd\uff0c\u6bcf\u4e2a\u6837\u672c\u7684\u5728\u66f4\u65b0\u53c2\u6570\u65f6\u6240\u7528\u7684\u5b66\u4e60\u7387\u5e94\u8be5\u968f\u7740\u91c7\u6837\u6743\u91cd\u800c\u8c03\u6574\uff0c\u9632\u6b62\u67d0\u4e9b\u6837\u672c\u4e3b\u5bfc\u8bad\u7ec3\u7684\u8fc7\u7a0b\uff0c\u5982\u679c\u4e00\u4e2a\u6837\u672c\u88ab\u62bd\u6837\u7684\u6982\u7387\u6bd4\u8f83\u5927\uff0c\u90a3\u4e48\u4ed6\u7684\u5b66\u4e60\u7387\u5c31\u5e94\u5f53\u6bd4\u8f83\u5c0f\uff0c\u53ef\u4ee5\u901a\u8fc7\u4e0b\u9762\u7684\u516c\u5f0f\u6765\u8ba1\u7b97\u6bcf\u4e2a\u6837\u672ci\u7684\u5b66\u4e60\u7387\uff1a $$ \\alpha_i=\\frac{\\alpha}{(b\\cdot p_i)^{\\beta}} $$  \u5176\u4e2d\uff0cb\u662f\u6837\u672c\u603b\u6570\uff0c\\alpha\u662f\u9ed8\u8ba4\u7684\u5b66\u4e60\u7387\uff0cp_i\u662f\u6837\u672c\u7684\u91c7\u6837\u6743\u91cd\uff0c\\beta\\in(0,1)\u4e3a\u8d85\u53c2\u6570\uff08\u53ef\u4ee5\u4e00\u5f00\u59cb\u8bbe\u7f6e\u7684\u6bd4\u8f83\u5c0f\uff0c\u7136\u540e\u6162\u6162\u589e\u957f\u52301\uff09\u3002</p> <p>\u6ce8\uff1a</p> <ul> <li>\u5927\u62bd\u6837\u6982\u7387\u4e0e\u5c0f\u5b66\u4e60\u7387\u4e4b\u95f4\u5e76\u4e0d\u77db\u76fe\uff0c\u4ee5\u5c0f\u6b65\u5e45\u53bb\u66f4\u65b0\u591a\u6b21\uff0c\u53ef\u4ee5\u66f4\u597d\u5730\u5229\u7528\u6837\u672c\uff0c\u4f46\u662f\u4f1a\u5e26\u6765\u8ba1\u7b97\u91cf\u5927\u7684\u95ee\u9898\uff0c\u56e0\u6b64\u8be5\u7b56\u7565\u53ea\u88ab\u7528\u4e8e\u91cd\u8981\u7684\u6837\u672c</li> <li>\u4ece\u7ecf\u9a8c\u56de\u653e\u4e2d\u62bd\u53d6\u6837\u672c\u53bb\u66f4\u65b0\u53c2\u6570\u65f6\uff0c\u53ef\u4ee5\u5229\u7528\u66f4\u65b0\u540e\u7684\u6a21\u578b\u53c2\u6570\u518d\u8ba1\u7b97\u4e00\u6b21\u91c7\u6837\u6743\u91cd\uff0c\u66ff\u6362\u6389\u7f13\u51b2\u533a\u4e2d\u7684\u65e7\u53c2\u6570</li> </ul>"},{"location":"RL/DQN/#noisy","title":"\u566a\u58f0\u7f51\u7edc\uff08noisy\uff09","text":"<p>\u2003\u2003\u5bf9\u4e8e\u539f\u6765\u7684\u63a2\u7d22\u673a\u5236\uff0c\\varepsilon-\u8d2a\u5fc3\u7b56\u7565\u4e3a\u4e86\u8ba9\u7f51\u7edc\u53ef\u4ee5\u5c1d\u8bd5\u672a\u77e5\u7684\u52a8\u4f5c\uff0c\u6309\u6982\u7387\u968f\u673a\u51b3\u5b9a\u662f\u5426\u6267\u884cQ\u51fd\u6570\u6240\u5224\u65ad\u7684\u52a8\u4f5c\uff0c\u5373\u4f7f\u662f\u9762\u5bf9\u540c\u4e00\u4e2a\u72b6\u6001\uff0c\u667a\u80fd\u4f53\u6240\u91c7\u53d6\u7684\u52a8\u4f5c\u4e5f\u53ef\u80fd\u662f\u4e0d\u540c\u7684\uff0c\u4f46\u4e00\u4e2a\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u7b56\u7565\u5e76\u4e0d\u662f\u8fd9\u6837\u7684\uff0c\u9762\u5bf9\u540c\u4e00\u4e2a\u72b6\u6001\u5e94\u8be5\u4ee5\u76f8\u540c\u7684\u89c4\u5219\u505a\u51fa\u56de\u5e94\uff0c\u800c\u4e0d\u662f\u6709\u65f6\u5019\u4ee5\u89c4\u5219A\u6267\u884c\uff0c\u6709\u65f6\u5019\u4ee5\u89c4\u5219B\u6267\u884c\uff0c\u56e0\u6b64\\varepsilon-\u8d2a\u5fc3\u7b56\u7565\u5728\u5f15\u5165\u63a2\u7d22\u673a\u5236\u7684\u540c\u65f6\uff0c\u7834\u574f\u4e86\u539f\u6709\u7684\u52a8\u4f5c\u6267\u884c\u89c4\u5219\u3002</p> <p>\u2003\u2003\u5bf9\u6b64\uff0c\u6211\u4eec\u53ef\u4ee5\u5f15\u5165\u566a\u58f0\u7f51\u7edc\u8fd9\u4e00\u6982\u5ff5\uff0c\u5728\u539f\u6709Q\u7f51\u7edc\u7684\u53c2\u6570\u7a7a\u95f4\u4e0a\u52a0\u4e0a\u566a\u58f0\uff0c\u566a\u58f0\u7684\u5f15\u5165\u4f1a\u5e26\u6765\u4e00\u5b9a\u7684\u968f\u673a\u6027\uff0c\u56e0\u6b64\u540c\u6837\u4e5f\u4f1a\u8d77\u5230\u63a2\u7d22\u673a\u5236\u7684\u4f5c\u7528\uff0c\u4f46\u5728\u5e94\u7528\u7684\u8fc7\u7a0b\u4e2d\u4e0d\u4f1a\u50cf\\varepsilon-\u8d2a\u5fc3\u4e00\u6837\u4ea7\u751f\u5206\u6d41\uff0c\u5373\u59cb\u7ec8\u6309\u7167\u4e00\u4e2a\u89c4\u5219\u8d70\uff0c\u9762\u5bf9\u76f8\u540c\u6216\u8005\u7c7b\u4f3c\u7684\u72b6\u6001\u4f1a\u91c7\u53d6\u76f8\u540c\u7684\u52a8\u4f5c\u3002\u8fd9\u53c8\u88ab\u79f0\u4e3a\u4f9d\u8d56\u72b6\u6001\u7684\u63a2\u7d22\uff0c\u867d\u7136\u4e5f\u4f1a\u53bb\u505a\u63a2\u7d22\u8fd9\u4ef6\u4e8b\uff0c\u4f46\u662f\u63a2\u7d22\u7684\u7ed3\u679c\u4f1a\u4e0e\u72b6\u6001\u6709\u5173\uff0c\u770b\u5230\u540c\u6837\u7684\u72b6\u6001\u4f1a\u9009\u62e9\u76f8\u540c\u7684\u63a2\u7d22\u65b9\u5f0f\u3002</p> <p>\u2003\u2003\u6700\u7b80\u5355\u7684\u5b9e\u73b0\u65b9\u6cd5\u5c31\u662f\u5f15\u5165\u9ad8\u65af\u566a\u58f0\uff0c\u5c06\u539f\u59cb\u7f51\u7edc\u4e2d\u7684\u53c2\u6570w\u66ff\u6362\u4e3a\\mu+\\sigma \\cdot\\xi\uff0c\\mu\u548c\\sigma\u5206\u522b\u8868\u793a\u5747\u503c\u548c\u65b9\u5dee\uff0c\u662f\u7f51\u7edc\u4e2d\u53ef\u5b66\u4e60\u7684\u53c2\u6570\uff0c\\xi\u662f\u968f\u673a\u566a\u58f0\uff0c\u4e3a\u968f\u673a\u751f\u6210\u7684\u53c2\u6570\uff0c\u66ff\u6362\u4ee5\u540e\u76f8\u5f53\u4e8ew\u7684\u6bcf\u4e2a\u5143\u7d20\u4ece\u5747\u503c\u4e3a\\mu\uff0c\u6807\u51c6\u5dee\u4e3a\\sigma\u7684\u6b63\u6001\u5206\u5e03\u4e2d\u62bd\u53d6\uff0c\u5e76\u4e0d\u662f\u4e00\u4e2a\u56fa\u5b9a\u7684\u6570\u503c\u3002</p> <p>\u6ce8\uff1a</p> <ul> <li>\u566a\u58f0\u53ea\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5f15\u5165\uff0c\u5728\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\u4e0d\u5f15\u5165\u566a\u58f0\uff0c\u6b64\u65f6\u53ef\u4ee5\u628a\\sigma\u8bbe\u4e3a0</li> <li>\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5f15\u5165\u566a\u58f0\uff0c\u4e0d\u4ec5\u6709\u5229\u4e8e\u6a21\u578b\u505a\u63a2\u7d22\uff0c\u8fd8\u53ef\u4ee5\u589e\u5f3a\u6a21\u578b\u7684\u9c81\u68d2\u6027\uff0c\u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\uff0c\u5373\u63d0\u5347\u6a21\u578b\u5e94\u5bf9\u4e0d\u7a33\u5b9a\u6027\u56e0\u7d20\u7684\u80fd\u529b\uff0c\u6a21\u578b\u4e0d\u4f1a\u56e0\u4e3a\u73af\u5883\u7684\u4e00\u4e9b\u7ec6\u5fae\u53d8\u5316\u800c\u4ea7\u751f\u201c\u5931\u4e4b\u6beb\u5398\u8c2c\u4ee5\u5343\u91cc\u201d\u7684\u51b3\u7b56\u5224\u65ad</li> </ul> <p>\u53c2\u8003\u4ee3\u7801\uff1a</p> <pre><code>import math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nclass NoisyLinear(nn.Module):\n    def __init__(self, input_dim, output_dim, std_init=0.4):\n        super(NoisyLinear, self).__init__()\n\n        self.input_dim  = input_dim\n        self.output_dim = output_dim\n        self.std_init     = std_init\n        # weight_mu\u548cweight_sigma\u90fd\u662f\u53ef\u5b66\u4e60\u7684\n        self.weight_mu    = nn.Parameter(torch.FloatTensor(output_dim, input_dim))\n        self.weight_sigma = nn.Parameter(torch.FloatTensor(output_dim, input_dim))\n        self.register_buffer('weight_epsilon', torch.FloatTensor(output_dim, input_dim))\n\n        self.bias_mu    = nn.Parameter(torch.FloatTensor(output_dim))\n        self.bias_sigma = nn.Parameter(torch.FloatTensor(output_dim))\n        self.register_buffer('bias_epsilon', torch.FloatTensor(output_dim))\n\n        self.reset_parameters()\n        self.reset_noise()\n\n    def forward(self, x):\n        if self.training: \n            # self.weight_epsilon\u548cself.bias_epsilon\u662f\u4e0d\u53ef\u5b66\u4e60\u7684\u53c2\u6570\n            # \u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5145\u5f53\u566a\u58f0\u6765\u6e90\n            weight = self.weight_mu + self.weight_sigma.mul(torch.tensor(self.weight_epsilon))\n            bias   = self.bias_mu   + self.bias_sigma.mul(torch.tensor(self.bias_epsilon))\n        else:\n            weight = self.weight_mu\n            bias   = self.bias_mu\n\n        return F.linear(x, weight, bias)\n\n    def reset_parameters(self):\n        mu_range = 1 / math.sqrt(self.weight_mu.size(1))\n\n        self.weight_mu.data.uniform_(-mu_range, mu_range)\n        self.weight_sigma.data.fill_(self.std_init / math.sqrt(self.weight_sigma.size(1)))\n\n        self.bias_mu.data.uniform_(-mu_range, mu_range)\n        self.bias_sigma.data.fill_(self.std_init / math.sqrt(self.bias_sigma.size(0)))\n\n    def reset_noise(self):\n        epsilon_in  = self._scale_noise(self.input_dim)\n        epsilon_out = self._scale_noise(self.output_dim)\n\n        self.weight_epsilon.copy_(epsilon_out.ger(epsilon_in))\n        self.bias_epsilon.copy_(self._scale_noise(self.output_dim))\n\n    def _scale_noise(self, size):\n        x = torch.randn(size)\n        x = x.sign().mul(x.abs().sqrt())\n        return x\n\nclass NoisyMLP(nn.Module):\n    def __init__(self, input_dim,output_dim,hidden_dim=128):\n        super(NoisyMLP, self).__init__()\n        self.fc1 =  nn.Linear(input_dim, hidden_dim)\n        self.noisy_fc2 = NoisyLinear(hidden_dim, hidden_dim)\n        self.noisy_fc3 = NoisyLinear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.noisy_fc2(x))\n        x = self.noisy_fc3(x)\n        return x\n\n    def reset_noise(self):\n        self.noisy_fc2.reset_noise()\n        self.noisy_fc3.reset_noise()\n</code></pre> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u6307\u6b63</p> <p>\u521d\u6b65\u5b8c\u7a3f\u4e8e\uff1a2023\u5e745\u670816\u65e5</p>"},{"location":"RL/PPO/","title":"PPO\u7b97\u6cd5","text":"<p>\u6e90\u7801\u5f15\u81ea\uff1ahttps://github.com/datawhalechina/easy-rl</p>"},{"location":"RL/PPO/#_1","title":"\u4ecb\u7ecd","text":"<p>\u2003\u2003\u6838\u5fc3\u601d\u60f3\uff1aPPO\u7b97\u6cd5\u662f\u4e00\u79cd\u7b56\u7565\u5b66\u4e60\u7b97\u6cd5\uff0c\u8bad\u7ec3\u7b56\u7565\u51fd\u6570V_\\pi(s)\u6765\u51b3\u7b56\u4f7f\u7528\u54ea\u79cd\u52a8\u4f5c\uff0c\u540c\u65f6\u8bad\u7ec3\u4ef7\u503c\u51fd\u6570V_\\theta(s)\u6765\u4f30\u8ba1\u4f18\u52bf\u6743\u91cdA(s,a)\uff0c\u964d\u4f4e\u68af\u5ea6\u7684\u65b9\u5dee\uff0c\u5e76\u4e14\u901a\u8fc7\u5bf9\u7b56\u7565\u66f4\u65b0\u7684\u5e45\u5ea6\u8fdb\u884c\u9650\u5236\uff0c\u5b9e\u73b0\u7a33\u5b9a\u4e14\u9ad8\u6548\u7684\u7b56\u7565\u4f18\u5316\u3002</p> <p>PPO\u4f18\u5316\u76ee\u6807\uff1a $$ \\begin{aligned} J_{\\text{PPO}}(\\pi)=\\sum_{\\left(s_{t}, a_{t}\\right)} \\frac{p_{\\pi}\\left(a_{t} \\mid s_{t}\\right)}{p_{\\pi^{k}}\\left(a_{t} \\mid s_{t}\\right)} A^{\\pi^{k}}\\left(s_{t}, a_{t}\\right)-\\beta \\text{KL}\\left(\\pi, \\pi^{k}\\right) \\\\ \\end{aligned} $$ </p> <p>PPO2\u4f18\u5316\u76ee\u6807\uff1a $$ \\begin{aligned}         J_{\\mathrm{PPO2}}(\\pi) \\approx \\sum_{\\left(s_{t}, a_{t}\\right)} \\min &amp;\\left(\\frac{p_{\\pi}\\left(a_{t} | s_{t}\\right)}{p_{\\pi^{k}}\\left(a_{t} | s_{t}\\right)} A^{\\pi^{k}}\\left(s_{t}, a_{t}\\right),\\right.\\\\         &amp;\\left.\\operatorname{clip}\\left(\\frac{p_{\\pi}\\left(a_{t} | s_{t}\\right)}{p_{\\pi^{k}}\\left(a_{t} | s_{t}\\right)}, 1-\\varepsilon, 1+\\varepsilon\\right) A^{\\pi^{k}}\\left(s_{t}, a_{t}\\right)\\right)         \\end{aligned} $$  \u5176\u4e2dA^{\\pi^{k}}\\left(s_{t}, a_{t}\\right)=\\sum_{t'=t}^{T_n}\\gamma^{t'-t}r^k_{t'}-V_\\theta(s_t)\uff0c\u4e0a\u6807k\u8868\u793a\u5229\u7528\u65e7\u53c2\u6570\u6240\u91c7\u7684\u6837\u672c\uff08\u5373\u5229\u7528\u76ee\u6807\u7f51\u7edc\u91c7\u5f97\u7684\u6837\u672c\uff09\u3002</p> <p>\u4ef7\u503c\u51fd\u6570V_\\theta(s)\u7684\u4f18\u5316\u76ee\u6807\uff1a $$ L(\\theta)=\\sum^{T_n}_{t=1}\\frac12(\\sum_{t'=t}^{T_n}\\gamma^{t'-t}r^n_{t'}-V_\\theta(s))^2 $$  \u66f4\u65b0\u6b65\u9aa4\uff1a</p> <ul> <li>\u521d\u59cb\u5316\u51b3\u7b56\u7f51\u7edcV_\\pi(s)\u4ee5\u53ca\u52a8\u4f5c\u7f51\u7edcV_\\theta(s)\uff0c\u9762\u5bf9\u72b6\u6001\u7ef4\u6570\u8fc7\u5927\u7684\u60c5\u51b5\uff08\u5982\u56fe\u50cf\uff09\uff0c\u4e24\u4e2a\u7f51\u7edc\u53ef\u4ee5\u5171\u4eab\u7279\u5f81\u63d0\u53d6\u90e8\u5206\u7684\u53c2\u6570</li> <li>\u904d\u5386\u6bcf\u4e2aepisodes\uff0c\u5047\u8bbet\u4e3a\u5f53\u524d\u7684\u65f6\u95f4\u6b65</li> <li>\u5c06\u72b6\u6001s_t\u4f20\u5165\u51b3\u7b56\u51fd\u6570\uff0c\u5f97\u5230\u52a8\u4f5c\u6982\u7387\u5206\u6570p_{\\pi^{k}}\\left(a_{t}|s_{t}\\right)</li> <li>\u5c06\\left(s_t,a_t,p_{\\pi^{k}}\\left(a_{t}|s_{t}\\right)\\right)\u5b58\u8d77\u6765\uff0c\u5f53\u6210\u5229\u7528\u65e7\u53c2\u6570\u6240\u91c7\u7684\u6837\u672c\uff0c\u7528\u4e8e\u8ba1\u7b97\u4e0a\u8ff0\u516c\u5f0f\u4e2d\u5e26\u4e0a\u6807k\u7684\u53d8\u91cf</li> <li>\u6240\u91c7\u7684\u6837\u672c\u6570\u91cf\u5230\u8fbe\u4e00\u5b9a\u7a0b\u5ea6\u4e4b\u540e\uff0c\u8f6c\u5165\u66f4\u65b0\u6b65\u9aa4\uff0c\u63d0\u53d6\u4e4b\u524d\u91c7\u5f97\u7684\u6837\u672c\uff0c\u91cd\u65b0\u5c06s_t\u4f20\u5165\u4e24\u4e2a\u7f51\u7edc\uff0c\u5f97\u5230\u65b0\u7684\u52a8\u4f5c\u6982\u7387\u5206\u6570p_{\\pi}\\left(a_{t} | s_{t}\\right)\u548c\u72b6\u6001\u5206\u6570V_\\theta(s)\uff0c\u8ba1\u7b97\u635f\u5931\uff0c\u4f18\u5316\u7f51\u7edc\uff0c\u8fd9\u4e00\u6b65\u9aa4\u91cd\u590dK\u6b21</li> </ul> <p>\u6ce8\uff1aPPO\u548cA2C\u7b97\u6cd5\u4e2d\u7684\u4f18\u52bf\u51fd\u6570\u8ba1\u7b97\u65b9\u6cd5\u7c7b\u4f3c\uff0c\u4f46\u662f\u4ef7\u503c\u51fd\u6570\u6240\u8868\u793a\u7684\u610f\u4e49\u4e0d\u540c\uff0cPPO\u4e2d\u7684\u4ef7\u503c\u51fd\u6570\u7528\u4e8e\u4f30\u8ba1\u5f53\u524d\u72b6\u6001\u7684\u57fa\u672c\u4ef7\u503c\uff08baseline\uff09\uff0c\u4e3a\u4e86\u51cf\u5c0f\u635f\u5931\u65b9\u5dee\uff0c\u800cA2C\u4e2d\u7684\u4ef7\u503c\u51fd\u6570\u7528\u4e8e\u8861\u91cf\u52a8\u4f5c\u7684\u79ef\u7d2f\u4ef7\u503c\u91cf\uff0c\u56e0\u6b64\u5728\u8ba1\u7b97\u8fc7\u7a0b\u4e2d\u6709\u70b9\u5dee\u5f02\uff0c\u4e0d\u662f\u5b8c\u5168\u76f8\u540c\u7684\u3002</p>"},{"location":"RL/PPO/#_2","title":"\u6e90\u7801\u5b9e\u73b0","text":""},{"location":"RL/PPO/#_3","title":"\u8bad\u7ec3\u6d41\u7a0b","text":"<pre><code>memory = Memory()\n    ppo = PPO(state_dim, action_dim, n_latent_var, lr, betas, gamma, K_epochs, eps_clip)\n    # print(lr,betas)\n\n    # logging variables\n    running_reward = 0\n    avg_length = 0\n    timestep = 0\n\n    # training loop\n    for i_episode in range(1, max_episodes + 1):\n        state = env.reset()  # \u521d\u59cb\u5316\uff08\u91cd\u65b0\u73a9\uff09\n        for t in range(max_timesteps):\n            timestep += 1\n            # Running policy_old:\n            # \u5229\u7528\u65e7\u53c2\u6570\u6267\u884c\u91c7\u6837\uff0c\u5e76\u4e14\u5c06\u6837\u672c\u5b58\u5165memory\u4e2d\n            action = ppo.policy_old.act(state, memory)\n            state, reward, done, _ = env.step(action)  # \u5f97\u5230\uff08\u65b0\u7684\u72b6\u6001\uff0c\u5956\u52b1\uff0c\u662f\u5426\u7ec8\u6b62\uff0c\u989d\u5916\u7684\u8c03\u8bd5\u4fe1\u606f\uff09\n            # data = env.step(action)\n            # Saving reward and is_terminal:\n            memory.rewards.append(reward)\n            memory.is_terminals.append(done)\n\n            # \u91c7\u5230\u6307\u5b9a\u6570\u91cf\u7684\u6837\u672c\uff0c\u8f6c\u5165\u66f4\u65b0\u9636\u6bb5\n            if timestep % update_timestep == 0:\n                ppo.update(memory)\n                memory.clear_memory()\n                timestep = 0\n\n            running_reward += reward\n            if render:\n                env.render()\n            if done:\n                break\n\n        avg_length += t\n\n        # stop training if avg_reward &gt; solved_reward\n        if running_reward &gt; (log_interval * solved_reward):\n            print(\"########## Solved! ##########\")\n            torch.save(ppo.policy.state_dict(), './PPO_{}.pth'.format(env_name))\n            break\n\n        # logging\n        if i_episode % log_interval == 0:\n            avg_length = int(avg_length / log_interval)\n            running_reward = int((running_reward / log_interval))\n\n            print('Episode {} \\t avg length: {} \\t reward: {}'.format(i_episode, avg_length, running_reward))\n            running_reward = 0\n            avg_length = 0\n</code></pre>"},{"location":"RL/PPO/#_4","title":"\u66f4\u65b0\u9636\u6bb5","text":"<pre><code>def update(self, memory):\n    # Monte Carlo estimate of state rewards:\n    rewards = []\n    discounted_reward = 0\n    # \u8ba1\u7b97\u6bcf\u4e2a\u72b6\u6001\u7684\u79ef\u7d2f\u4ef7\u503c\u91cf\uff08\u5229\u7528\u65e7\u53c2\u6570\u6240\u91c7\u7684\u6837\u672c\u8ba1\u7b97\uff09\uff0c\u7528\u4e8e\u540e\u7eed\u8ba1\u7b97\u4f18\u52bf\u51fd\u6570\n    for reward, is_terminal in zip(reversed(memory.rewards), reversed(memory.is_terminals)):\n        if is_terminal:\n            discounted_reward = 0\n        discounted_reward = reward + (self.gamma * discounted_reward) # \u4ece\u540e\u5f80\u524d\u8865\u5145\n        rewards.insert(0, discounted_reward)\n\n    # Normalizing the rewards:  # \u5956\u52b1\u505a\u6807\u51c6\u5316\n    rewards = torch.tensor(rewards, dtype=torch.float32).to(device)\n    rewards = (rewards - rewards.mean()) / (rewards.std() + 1e-5)\n\n    # convert list to tensor \u63d0\u53d6\u65e7\u53c2\u6570\u6240\u91c7\u5f97\u7684\u6837\u672c\n    old_states = torch.stack(memory.states).to(device).detach()\n    old_actions = torch.stack(memory.actions).to(device).detach()\n    old_logprobs = torch.stack(memory.logprobs).to(device).detach()\n\n    # Optimize policy for K epochs:\n    for _ in range(self.K_epochs):\n        # Evaluating old actions and values :\n        # \u5c06\u72b6\u6001\u4f20\u5165\u7f51\u7edc\uff0c\u5f97\u5230\u65b0\u7684\u52a8\u4f5c\u6982\u7387\u5206\u6570\u548c\u72b6\u6001\u5206\u6570\n        logprobs, state_values, dist_entropy = self.policy.evaluate(old_states, old_actions)\n        # \u8ba1\u7b97\u635f\u5931\n        # Finding the ratio (pi_theta / pi_theta__old):\n        ratios = torch.exp(logprobs - old_logprobs.detach())\n\n        # Finding Surrogate Loss:\n        advantages = rewards - state_values.detach()\n        surr1 = ratios * advantages\n        surr2 = torch.clamp(ratios, 1 - self.eps_clip, 1 + self.eps_clip) * advantages\n        loss = -torch.min(surr1, surr2) + 0.5 * self.MseLoss(state_values, rewards) - 0.01 * dist_entropy\n\n        # take gradient step\n        self.optimizer.zero_grad()\n        loss.mean().backward()\n        self.optimizer.step()\n\n    # Copy new weights into old policy:\n    self.policy_old.load_state_dict(self.policy.state_dict())\n</code></pre> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u6307\u6b63</p> <p>\u521d\u6b65\u5b8c\u7a3f\u4e8e2023\u5e745\u670817\u65e5</p>"},{"location":"RL/landing_guide/","title":"\u8bfb\u4e66\u7b14\u8bb0\u2014\u2014\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u843d\u5730\u6307\u5357","text":"<p>\u300a\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u843d\u5730\u6307\u5357\u300b\uff0c\u9b4f\u5b81\uff0c\u7535\u5b50\u5de5\u4e1a\u51fa\u7248\u793e</p> <p>\u77e5\u4e4e\u4e13\u680f\uff1a\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u843d\u5730\u65b9\u6cd5\u8bba</p> <p>\u6ce8\uff1a\u672c\u6587\u5927\u90e8\u5206\u5185\u5bb9\u57fa\u4e8e\u4e66\u7c4d\u300a\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u843d\u5730\u6307\u5357\u300b\u6240\u5199\uff0c\u7528\u4e8e\u540e\u7eed\u4e2a\u4eba\u590d\u4e60\u3002</p>"},{"location":"RL/landing_guide/#_2","title":"\u52a8\u4f5c\u7a7a\u95f4\u7684\u8bbe\u8ba1","text":"<p>\u2003\u2003\u52a8\u4f5c\u7a7a\u95f4\u7684\u7c7b\u578b\u5e38\u88ab\u5206\u4e3a\u8fde\u7eed\u52a8\u4f5c\u4e0e\u79bb\u6563\u52a8\u4f5c\uff0c\u5728\u8bbe\u8ba1\u52a8\u4f5c\u7a7a\u95f4\u65f6\u8981\u6ee1\u8db3\u4e09\u4e2a\u57fa\u672c\u539f\u5219\uff1a\u5b8c\u5907\u6027\u3001\u9ad8\u6548\u6027\u4ee5\u53ca\u5408\u6cd5\u6027</p>"},{"location":"RL/landing_guide/#_3","title":"\u5b8c\u5907\u6027","text":"<p>\u529f\u80fd\u5b8c\u5907</p> <p>\u2003\u2003\u9996\u5148\u8981\u505a\u5230\u529f\u80fd\u5b8c\u5907\uff0c\u786e\u4fdd\u667a\u80fd\u4f53\u5177\u6709\u5b8c\u6210\u76ee\u6807\u4efb\u52a1\u6240\u9700\u8981\u7684\u5168\u90e8\u80fd\u529b\uff0c\u4e0d\u80fd\u5b58\u5728\u65e0\u6cd5\u89e6\u53ca\u7684\u201c\u72b6\u6001\u76f2\u533a\u201d\uff0c\u5c24\u5176\u662f\u5728\u8fde\u7eed\u63a7\u5236\u53d8\u91cf\u8f6c\u4e3a\u6709\u9650\u6570\u91cf\u7684\u79bb\u6563\u52a8\u4f5c\u65f6\uff0c\u5fc5\u987b\u8981\u4fdd\u8bc1\u79bb\u6563\u53d8\u91cf\u5177\u5907\u8db3\u591f\u7684\u63a7\u5236\u7cbe\u5ea6\u3002\u540c\u65f6\uff0c\u5728\u67d0\u4e9b\u5f00\u653e\u6027\u4efb\u52a1\u4e2d\uff0c\u7531\u4e8e\u7f3a\u4e4f\u660e\u786e\u7684\u6307\u5bfc\u6846\u67b6\uff0c\u8981\u786e\u4fdd\u529f\u80fd\u5b8c\u5907\u9700\u8981\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\u3002\u4ee5\u4efb\u52a1\u9a71\u52a8\u578b\u804a\u5929\u673a\u5668\u4eba\u4e3a\u4f8b\uff0c\u667a\u80fd\u4f53\u9700\u8981\u4ece\u4e00\u4e9b\u5e38\u7528\u95ee\u53e5\u4e2d\u9002\u65f6\u9009\u62e9\uff0c\u5f15\u5bfc\u5ba2\u6237\u5b8c\u6210\u591a\u8f6e\u5bf9\u8bdd\u5e76\u6536\u96c6\u4efb\u52a1\u6240\u9700\u7684\u5b8c\u6574\u4fe1\u606f\u3002\u6bd4\u5982\u8be2\u95ee\uff1a\u2460\u54ea\u4e2a\u57ce\u5e02\uff1f\u2461\u4ec0\u4e48\u4ef7\u4f4d\u7b49\u7b49\u3002\u7531\u8fd9\u4e9b\u95ee\u53e5\u6784\u6210\u7684\u52a8\u4f5c\u7a7a\u95f4\u53ef\u4ee5\u5b8c\u6210\u7edd\u5927\u90e8\u5206\u9152\u5e97\u7684\u9884\u8ba2\u4efb\u52a1\u3002</p> <p>\u2003\u2003\u5bf9\u4e8e\u52a8\u4f5c\u7a7a\u95f4\u7684\u529f\u80fd\u5b8c\u5907\u6027\uff0c\u6709\u4e00\u70b9\u9700\u8981\u6ce8\u610f\uff0c\u5e94\u5f53\u907f\u514d\u8d4b\u4e88\u667a\u80fd\u4f53\u7be1\u6539\u56de\u62a5\u51fd\u6570\u7684\u80fd\u529b\u3002\u5728\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\u4e2d\uff0c\u56de\u62a5\u51fd\u6570\u7684\u8bbe\u8ba1\u901a\u5e38\u90fd\u57fa\u4e8e\u5bf9\u73af\u5883\u4fe1\u606f\u7684\u611f\u77e5\u548c\u52a0\u5de5\uff0c\u5982\u679c\u667a\u80fd\u4f53\u7684\u52a8\u4f5c\u7a7a\u95f4\u5f3a\u5927\u5230\u8db3\u4ee5\u5f71\u54cd\u611f\u77e5\u548c\u52a0\u5de5\u7684\u8fc7\u7a0b\uff0c\u90a3\u4e48\u4ed6\u5c31\u53ef\u80fd\u5229\u7528\u8be5\u80fd\u529b\u5b66\u4f1a\u67d0\u79cd\u6295\u673a\u7b56\u7565\uff0c\u901a\u8fc7\u64cd\u7eb5\u56de\u62a5\u51fd\u6570\u6765\u6301\u7eed\u83b7\u5f97\u9ad8\u56de\u62a5\u3002\u4f8b\u5982\uff0c\u5728\u8dd1\u6b65\u6bd4\u8d5b\u4e2d\uff0c\u53ea\u6709\u667a\u80fd\u4f53\u4e0d\u65ad\u8d70\u5411\u7ec8\u70b9\uff0c\u624d\u80fd\u51ed\u501f\u201c\u79bb\u7ec8\u70b9\u8d8a\u6765\u8d8a\u8fd1\u201d\u8fd9\u4e00\u73b0\u8c61\u83b7\u5f97\u6b63\u5411\u6536\u76ca\u3002\u5728\u6bd4\u8d5b\u8fd9\u9879\u4efb\u52a1\u4e2d\uff0c\u7ec8\u70b9\u5c5e\u4e8e\u73af\u5883\uff0c\u667a\u80fd\u4f53\u4e0d\u80fd\u4fee\u6539\u7ec8\u70b9\u7684\u4f4d\u7f6e\uff0c\u5982\u679c\u6b64\u65f6\u667a\u80fd\u4f53\u7684\u52a8\u4f5c\u53ef\u4ee5\u5f71\u54cd\u5230\u7ec8\u70b9\uff0c\u90a3\u4e48\u4ed6\u4e3a\u4e86\u83b7\u5f97\u9ad8\u989d\u7684\u6b63\u5411\u6536\u76ca\uff0c\u53ef\u4ee5\u4ece\u4e2d\u201c\u53d6\u5de7\u201d\uff0c\u8ba9\u7ec8\u70b9\u8d70\u5411\u667a\u80fd\u4f53\uff0c\u7136\u800c\u8fd9\u7834\u574f\u4e86\u8dd1\u6b65\u6bd4\u8d5b\u7684\u6e38\u620f\u89c4\u5219\uff0c\u5373\u7834\u574f\u4e86\u73b0\u5b9e\u7684\u89c4\u5219\uff0c\u5e94\u5f53\u907f\u514d\u8fd9\u4e00\u73b0\u8c61\u3002\uff08\u8fd9\u4e00\u73b0\u8c61\u88ab\u79f0\u4e3aWireheading\uff09</p> <p>\u65f6\u6548\u5b8c\u5907</p> <p>\u2003\u2003\u5bf9\u4e8e\u52a8\u4f5c\u7a7a\u95f4\u7684\u8bbe\u8ba1\uff0c\u8fd8\u8981\u4e3a\u6bcf\u4e2a\u52a8\u4f5c\u9009\u62e9\u5408\u7406\u7684\u51b3\u7b56\u5468\u671f\uff0c\u540c\u6837\u7684\u52a8\u4f5c\u5728\u4e0d\u540c\u65f6\u95f4\u5206\u8fa8\u7387\u4e0b\u7684\u6267\u884c\u6548\u679c\u53ef\u80fd\u5b58\u5728\u5929\u58e4\u4e4b\u522b\uff0c\u5982\u679c\u52a8\u4f5c\u6307\u4ee4\u7684\u54cd\u5e94\u901f\u5ea6\u8fc7\u6162\u6216\u8005\u66f4\u65b0\u5468\u671f\u8fc7\u957f\uff0c\u90fd\u4f1a\u4e25\u91cd\u5f71\u54cd\u5b9e\u9645\u7684\u51b3\u7b56\u6548\u679c\uff0c\u56e0\u6b64\u5728\u4fdd\u8bc1\u8db3\u591f\u5feb\u7684\u6307\u4ee4\u54cd\u5e94\u901f\u5ea6\u4e4b\u5916\uff0c\u6211\u4eec\u5e94\u5f53\u5728\u7b97\u529b\u5141\u8bb8\u7684\u8303\u56f4\u5185\u9002\u5f53\u7f29\u77ed\u51b3\u7b56\u5468\u671f\u3002\u52a8\u4f5c\u7a7a\u95f4\u7684\u51b3\u7b56\u5468\u671f\u5e94\u8be5\u6ee1\u8db3\u5b8c\u6210\u7279\u5b9a\u4efb\u52a1\u6240\u9700\u7684\u6700\u4f4e\u65f6\u95f4\u5206\u8fa8\u7387\uff0c\u4ece\u800c\u4fdd\u8bc1\u52a8\u4f5c\u7a7a\u95f4\u7684\u65f6\u6548\u5b8c\u5907\u6027\uff0c\u4e00\u822c\u800c\u8a00\uff0c\u8f83\u77ed\u7684\u51b3\u7b56\u5468\u671f\u80fd\u591f\u63d0\u5347\u667a\u80fd\u4f53\u7684\u7075\u6d3b\u6027\u548c\u673a\u52a8\u6027\u3002\u73b0\u5b9e\u4e2d\uff0c\u6700\u4f4e\u7684\u65f6\u95f4\u5206\u8fa8\u7387\u4e0e\u7406\u8bba\u6700\u9ad8\u7684\u5206\u8fa8\u7387\u4e4b\u95f4\u5b58\u5728\u4e00\u4e2a\u65f6\u6548\u5b8c\u5907\u533a\u95f4\uff0c\u5728\u8fd9\u4e2a\u533a\u95f4\u5185\u7075\u6d3b\u9009\u62e9\u51b3\u7b56\u5468\u671f\u3002</p>"},{"location":"RL/landing_guide/#_4","title":"\u9ad8\u6548\u6027","text":"<p>\u2003\u2003\u52a8\u4f5c\u7a7a\u95f4\u7684\u8bbe\u8ba1\u4e0d\u4ec5\u5728\u4e8e\u4fdd\u8bc1\u667a\u80fd\u4f53\u6709\u5b8c\u6574\u7684\u63a2\u7d22\u7a7a\u95f4\uff0c\u540c\u65f6\u4e5f\u5728\u4e8e\u5e2e\u52a9\u6539\u5584\u667a\u80fd\u4f53\u5728\u73af\u5883\u4e2d\u7684\u63a2\u7d22\u6548\u7387\uff0c\u4ece\u800c\u52a0\u901f\u7b97\u6cd5\u7684\u6536\u655b\uff0c\u5e76\u4e14\u63d0\u5347\u7b97\u6cd5\u6027\u80fd\uff0c\u4e3b\u8981\u6709\u4e24\u4e2a\u63aa\u65bd\uff1a\u5316\u6574\u4e3a\u96f6\u548c\u6709\u673a\u7ec4\u5408\u3002</p> <p>\u5316\u6574\u4e3a\u96f6</p> <p>\u2003\u2003\u5c06\u8fde\u7eed\u9ad8\u7ef4\u7684\u52a8\u4f5c\u79bb\u6563\u5316\uff0c\u901a\u8fc7\u727a\u7272\u4e00\u90e8\u5206\u63a7\u5236\u7cbe\u5ea6\u6362\u53d6\u89e3\u7a7a\u95f4\u7ef4\u5ea6\u7684\u5927\u5e45\u5ea6\u538b\u7f29\u4ee5\u53ca\u63a2\u7d22\u6548\u7387\u7684\u663e\u8457\u63d0\u5347\uff08\u4ee5\u7cbe\u5ea6\u6362\u53d6\u6548\u7387\uff09\uff0c\u5728\u79bb\u6563\u5316\u8fc7\u7a0b\u4e2d\u8981\u6ce8\u610f\u79bb\u6563\u5316\u7684\u7c92\u5ea6\u8981\u9002\u4e2d\uff0c\u7c92\u5ea6\u4e0d\u80fd\u8fc7\u5927\uff0c\u5426\u5219\u4f1a\u964d\u4f4e\u63a7\u5236\u7cbe\u5ea6\uff0c\u7c92\u5ea6\u4e5f\u4e0d\u80fd\u8fc7\u5c0f\uff0c\u5426\u5219\u4f1a\u964d\u4f4e\u63a2\u7d22\u6548\u7387\uff0c\u4ece\u800c\u5f71\u54cd\u667a\u80fd\u4f53\u7684\u7075\u6d3b\u6027\u3002\u52a8\u4f5c\u7a7a\u95f4\u79bb\u6563\u5316\u7684\u8fc7\u7a0b\u4e5f\u540c\u6837\u5b58\u5728\u4e00\u4e2a\u529f\u80fd\u5b8c\u5907\u533a\uff0c\u5176\u7c92\u5ea6\u4e0a\u9650\u662f\u539f\u6709\u8fde\u7eed\u52a8\u4f5c\u533a\u95f4\u6216\u4e0d\u505a\u4efb\u4f55\u989d\u5916\u79bb\u6563\u5316\u7684\u60c5\u5f62\uff0c\u5176\u7c92\u5ea6\u4e0b\u9650\u5219\u5bf9\u5e94\u7ef4\u6301\u529f\u80fd\u5b8c\u5907\u6027\u6240\u9700\u7684\u6700\u4f4e\u63a7\u5236\u7cbe\u5ea6\u3002</p> <p>\u2003\u2003\u4e8b\u5b9e\u4e0a\uff0c\u5728\u5e7f\u4e49\u52a8\u4f5c\u7a7a\u95f4\u7684\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u4e5f\u5b58\u5728\u4e00\u79cd\u7279\u6b8a\u7684\u79bb\u6563\u5316\u64cd\u4f5c\u2014\u2014\u8df3\u5e27\uff08Frame Skipping\uff09\u3002\u8fc7\u77ed\u7684\u51b3\u7b56\u5468\u671f\u4f1a\u663e\u8457\u589e\u52a0Episode\u7684\u957f\u5ea6\uff0c\u8feb\u4f7f\u667a\u80fd\u4f53\u4e0d\u5f97\u4e0d\u5411\u524d\u8003\u8651\u66f4\u591a\u7684\u6b65\u9aa4\uff0c\u5373\u5728\u76f8\u540c\u7684\u65f6\u95f4\u5185\u4f1a\u6267\u884c\u66f4\u591a\u7684\u6b65\u9aa4\uff0c\u9700\u8981\u5236\u5b9a\u66f4\u591a\u7684\u51b3\u7b56\uff0c\u8fd9\u4e0d\u5229\u4e8e\u667a\u80fd\u4f53\u5728\u957f\u65f6\u95f4\u8de8\u5ea6\u4e0b\u5efa\u7acb\u51b3\u7b56\u76f8\u5173\u6027\uff0c\u7b97\u6cd5\u8bad\u7ec3\u7684\u96be\u5ea6\u4e5f\u6bd4\u8f83\u9ad8\u3002\u8df3\u5e27\u64cd\u4f5c\u5c31\u662f\u5728\u65f6\u6548\u5b8c\u5907\u533a\u95f4\u5185\u523b\u610f\u964d\u4f4e\u51b3\u7b56\u9891\u7387\uff0c\u5e76\u4e14\u5728\u76f8\u90bb\u4e24\u6b21\u51b3\u7b56\u4e4b\u95f4\u7b80\u5355\u91cd\u590d\u4e0a\u4e00\u6b21\u7684\u52a8\u4f5c\uff0c\u4ece\u800c\u7f29\u77edEpisode\u7684\u957f\u5ea6\u3002\u6362\u4e2a\u89d2\u5ea6\u6765\u770b\uff0c\u5373\u4f7f\u7b56\u7565\u4e0d\u9700\u8981\u6839\u636e\u4e2d\u95f4\u72b6\u6001\u505a\u51fa\u51b3\u7b56\uff0c\u4f46\u662f\u4e2d\u95f4\u72b6\u6001\u7684\u53d8\u5316\u5374\u53ef\u80fd\u5f71\u54cd\u7b56\u7565\u7684\u8f93\u51fa\uff0c\u56e0\u6b64\u60f3\u8981\u8fde\u7eed\u82e5\u5e72\u6b65\u90fd\u7ef4\u6301\u76f8\u540c\u7684\u8f93\u51fa\u52a8\u4f5c\u672c\u8eab\u5c31\u662f\u4e00\u79cd\u8f83\u96be\u5b66\u4e60\u7684\u80fd\u529b\uff0c\u5bf9\u4e8e\u65f6\u95f4\u8de8\u5ea6\u8f83\u5927\uff0c\u5e76\u4e14\u5728\u65f6\u5e8f\u4e0a\u53c8\u5b58\u5728\u5927\u91cf\u5197\u4f59\u7684\u4efb\u52a1\uff08\u4e00\u6bb5\u65f6\u95f4\u5185\u4f1a\u505a\u51fa\u5f88\u591a\u91cd\u590d\u7684\u52a8\u4f5c\uff09\uff0c\u8df3\u5e27\u64cd\u4f5c\u53ef\u4ee5\u6709\u6548\u5730\u63d0\u5347\u667a\u80fd\u4f53\u5728\u73af\u5883\u4e2d\u7684\u63a2\u7d22\u6548\u7387\u3002</p> <p>\u2003\u2003\u4f20\u7edf\u7684\u8df3\u5e27\u64cd\u4f5c\u662f\u6309\u6307\u5b9a\u7684\u6b65\u957f\u505a\u91cd\u590d\uff0c\u5176\u5b9e\u8fd8\u53ef\u4ee5\u4fee\u6539\u4e00\u4e0b\uff0c\u91c7\u7528\u81ea\u9002\u5e94\u8df3\u5e27\u6b65\u957f\uff0c\u5373\u5728\u4e0d\u540c\u72b6\u6001\u4e0b\u91c7\u53d6\u4e0d\u540c\u6b65\u6570\u7684\u52a8\u4f5c\u91cd\u590d\u7b56\u7565\uff0c\u5b9e\u73b0\u201c\u53ea\u5728\u9700\u8981\u65f6\u505a\u51b3\u7b56\u201d\u7684\u6548\u679c\u3002\u5177\u4f53\u7684\u5b9e\u73b0\u65b9\u6cd5\u662f\u5728\u539f\u52a8\u4f5c\u7a7a\u95f4\u7684\u57fa\u7840\u4e0a\u589e\u52a0\u4e00\u4e2a\u989d\u5916\u7684\u79bb\u6563\u96c6\u5408W=\\{w_1,w_2,\\dots,w_{|W|}\\}\uff0c\u7528\u4e8e\u8868\u793a\u6240\u6709\u53ef\u9009\u62e9\u7684\u52a8\u4f5c\u91cd\u590d\u6b65\u6570\uff0c\u5e76\u4e14\u4e0e\u5e38\u89c4\u52a8\u4f5c\u5171\u540c\u7ec4\u5408\u6210\u5b9e\u9645\u7684\u7b56\u7565\u8f93\u51fa(\\pi_{\\theta_{\\alpha}}(\\cdot|s),\\pi_{\\theta_{x}}(\\cdot|s))\uff0c\u5176\u4e2d\\theta_{\\alpha}\u548c\\theta_{x}\u5206\u522b\u4ee3\u8868\u8d1f\u8d23\u8f93\u51fa\u5e38\u89c4\u52a8\u4f5c\u548c\u52a8\u4f5c\u91cd\u590d\u6b65\u6570\u7684\u4e24\u4e2a\u7f51\u7edc\u53c2\u6570\uff0c\u76f8\u5f53\u4e8e\u51b3\u7b56\u7f51\u7edc\u6709\u4e24\u4e2a\u5206\u652f\uff0c\u4e00\u4e2a\u8f93\u51fa\u52a8\u4f5c\u7684\u6982\u7387\u5206\u5e03\uff0c\u53e6\u4e00\u4e2a\u8f93\u51fa\u52a8\u4f5c\u7684\u91cd\u590d\u6b65\u6570\u3002</p> <p>\u6709\u673a\u7ec4\u5408</p> <p>\u2003\u2003\u9664\u4e86\u5316\u6574\u4e3a\u96f6\uff0c\u8bbe\u8ba1\u9ad8\u6548\u52a8\u4f5c\u7a7a\u95f4\u7684\u53e6\u4e00\u79cd\u65b9\u5f0f\u662f\u5bf9\u57fa\u672c\u63a7\u5236\u624b\u6bb5\u7684\u6709\u673a\u7ec4\u5408\uff0c\u5c06\u4e00\u4e9b\u57fa\u7840\u7684\u96f6\u4ef6\u8fd0\u52a8\u7ec4\u5408\u6210\u4e00\u4e9b\u57fa\u672c\u7684\u52a8\u4f5c\uff0c\u6bd4\u5982\u5c06\u817f\u90e8\u808c\u8089\u7684\u8fd0\u52a8\u7ec4\u5408\u6210\u8d70\u6216\u8005\u8dd1\u7684\u52a8\u4f5c\uff0c\u7ec4\u5408\u52a8\u4f5c\u53c8\u79f0\u4e3a\u5b8f\u52a8\u4f5c\uff0c\u5728\u8bbe\u8ba1\u52a8\u4f5c\u7a7a\u95f4\u65f6\u76f4\u63a5\u5c06\u8fd9\u4e9b\u9ad8\u7ea7\u6280\u80fd\u4f5c\u4e3a\u5e38\u5907\u9009\u9879\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u63d0\u5347\u7b97\u6cd5\u7684\u6536\u655b\u901f\u5ea6\u548c\u6700\u7ec8\u6027\u80fd\u3002</p> <p>\u2003\u2003\u7406\u60f3\u7684\u52a8\u4f5c\u7a7a\u95f4\u5e94\u8be5\u7531\u90a3\u4e9b\u57fa\u7840\u7684\u3001\u4e0d\u53ef\u518d\u5206\u7684\u201c\u5143\u52a8\u4f5c\u201d\uff0c\u4ee5\u53ca\u90a3\u4e9b\u5341\u5206\u6709\u7528\u4f46\u4e0d\u5bb9\u6613\u638c\u63e1\u6216\u8005\u6ca1\u5fc5\u8981\u638c\u63e1\u7684\u5b8f\u52a8\u4f5c\u5171\u540c\u7ec4\u6210\u3002\u5b8f\u52a8\u4f5c\u672a\u5fc5\u662f\u201c\u5143\u52a8\u4f5c\u201d\u7684\u673a\u68b0\u7ec4\u5408\uff0c\u53ef\u4ee5\u662f\u4e00\u4e2a\u51fd\u6570\u3001\u4e00\u5957\u89c4\u5219\u751a\u81f3\u4e00\u79cd\u7b97\u6cd5\u3002\u9664\u4e86\u624b\u5de5\u8bbe\u8ba1\uff0c\u5b8f\u52a8\u4f5c\u4e5f\u53ef\u4ee5\u7531\u7b97\u6cd5\u81ea\u4e3b\u5b66\u4e60\u5f97\u5230\uff0c\u5c42\u7ea7\u5f3a\u5316\u5b66\u4e60\uff08HRL\uff09\u5c31\u662f\u4e13\u95e8\u7814\u7a76\u8fd9\u4e00\u95ee\u9898\u7684\u5b66\u672f\u65b9\u5411\uff0c\u5728HRL\u4e2d\uff0c\u901a\u5e38\u5305\u542b\u9ad8\u5c42\u7ea7\u548c\u4f4e\u5c42\u7ea7\u4e24\u79cd\u5b66\u4e60\u5668\uff0c\u524d\u8005\u53d1\u73b0\u548c\u5207\u6362\u5b8f\u52a8\u4f5c\uff0c\u540e\u8005\u8d1f\u8d23\u5177\u4f53\u6267\u884c\u5b8f\u52a8\u4f5c\u3002</p> <p>\u2003\u2003\u4ece\u672c\u8d28\u4e0a\u770b\uff0c\u6709\u673a\u7ec4\u5408\u4e0e\u5316\u6574\u4e3a\u96f6\u4e00\u6837\uff0c\u90fd\u662f\u901a\u8fc7\u538b\u7f29\u7a7a\u95f4\u7ef4\u5ea6\u8d77\u4f5c\u7528\u7684\u3002\u5316\u6574\u4e3a\u96f6\u53ef\u4ee5\u88ab\u770b\u4f5c\u662f\u4e00\u79cd\u673a\u68b0\u7684\u6709\u673a\u7ec4\u5408\uff0c\u6709\u673a\u7ec4\u5408\u76f8\u5f53\u4e8e\u7cbe\u7ec6\u7684\u5316\u6574\u4e3a\u96f6\uff0c\u4f8b\u5982\u8df3\u5e27\u6280\u5de7\u4e0b\u7684\u91cd\u590d\u52a8\u4f5c\u5c31\u5c5e\u4e8e\u4e00\u79cd\u7279\u6b8a\u7684\u5b8f\u52a8\u4f5c\u3002</p>"},{"location":"RL/landing_guide/#_5","title":"\u5408\u6cd5\u6027","text":"<p>\u2003\u2003\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u5e76\u4e0d\u662f\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u6240\u6709\u7684\u52a8\u4f5c\u5728\u4efb\u4f55\u72b6\u6001\u4e0b\u90fd\u662f\u6709\u6548\u6216\u8005\u5408\u6cd5\u7684\uff0c\u667a\u80fd\u4f53\u9700\u8981\u5728\u9075\u5b88\u6bcf\u4e2a\u5b9e\u9645\u4efb\u52a1\u89c4\u5219\u7684\u524d\u63d0\u4e0b\u53bb\u5bfb\u627e\u6700\u4f18\u7b56\u7565\uff0c\u4f8b\u5982\u5728\u6e38\u620f\u4e2d\u6709\u76f8\u5e94\u7684\u6e38\u620f\u89c4\u5219\u3001\u73b0\u5b9e\u4e2d\u6709\u6cd5\u5f8b\u89c4\u5219\u4ee5\u53ca\u9053\u5fb7\u7684\u7ea6\u675f\uff0c\u667a\u80fd\u4f53\u5728\u505a\u51b3\u7b56\u65f6\u51b3\u4e0d\u80fd\u89e6\u78b0\u89c4\u5219\u5e95\u7ebf\u3002\u540c\u65f6\uff0c\u5bf9\u4e8e\u5b9e\u9645\u786c\u4ef6\u7684\u51b3\u7b56\u63a7\u5236\u4e5f\u5b58\u5728\u4e00\u4e9b\u6765\u81ea\u7269\u7406\u89c4\u5219\u7684\u9650\u5236\uff0c\u4f8b\u5982\uff0c\u5de5\u4e1a\u673a\u5668\u4eba\u6bcf\u4e2a\u5173\u8282\u90fd\u6709\u5404\u81ea\u7684\u6d3b\u52a8\u8303\u56f4\u3002\u5728\u4efb\u4f55\u72b6\u6001\u4e0b\u9009\u62e9\u52a8\u4f5c\u90fd\u4e0d\u80fd\u8fdd\u80cc\u9884\u8bbe\u7684\u89c4\u5219\u9650\u5236\u3002</p> <p>\u975e\u6cd5\u52a8\u4f5c\u5c4f\u853d\u673a\u5236</p> <p>\u2003\u2003\u5e38\u7528\u7684\u505a\u6cd5\u5c31\u662f\u5c06\u7279\u5b9a\u72b6\u6001\u4e0b\u89c4\u5219\u4e0d\u5141\u8bb8\u51fa\u73b0\u6216\u8005\u4f1a\u5f15\u53d1\u4e25\u91cd\u540e\u679c\u7684\u52a8\u4f5c\u76f4\u63a5\u5c4f\u853d\u6389\uff0c\u4f8b\u5982\u5728\u79bb\u6563\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u53ef\u4ee5\u5ffd\u7565\u6389\u975e\u6cd5\u52a8\u4f5c\uff0c\u5e76\u4e14\u5c06\u5269\u4f59\u5408\u6cd5\u52a8\u4f5c\u7684Q\u503c\u6216\u8005\u7b56\u7565\u54cd\u5e94\u91cd\u65b0\u5f52\u4e00\u5316\uff0c\u518d\u6309\u7167\u6b63\u5e38\u7684\u65b9\u6cd5\u8fdb\u884c\u91c7\u6837\uff1b\u5728\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4\u4e2d\uff0c\u5219\u8bbe\u7f6e\u5404\u4e2a\u52a8\u4f5c\u7ef4\u5ea6\u7684\u5408\u6cd5\u53d6\u503c\u533a\u95f4\uff0c\u5bf9\u7b56\u7565\u8f93\u51fa\u505a\u622a\u65ad\u5904\u7406\u3002</p> <p>\u667a\u80fd\u4f53\u7684\u77e5\u60c5\u6743</p> <p>\u2003\u2003\u867d\u7136\u901a\u8fc7\u5f3a\u5236\u5c4f\u853d\u7684\u624b\u6bb5\u53ef\u4ee5\u786e\u4fddDRL\u7b97\u6cd5\u4e0d\u4f1a\u8f93\u51fa\u975e\u6cd5\u52a8\u4f5c\uff0c\u4f46\u662f\u76f8\u5173\u89c4\u5219\u672c\u8eab\u662f\u73af\u5883\u52a8\u6001\u4e0d\u53ef\u6216\u7f3a\u4e5f\u65e0\u6cd5\u5ffd\u7565\u7684\u4e00\u90e8\u5206\uff0c\u622a\u65ad\u5f0f\u7684\u5c4f\u853d\u67d0\u79cd\u52a8\u4f5c\u4e0d\u4f1a\u8ba9\u667a\u80fd\u4f53\u5b66\u5230\u8fd9\u4e9b\u89c4\u5219\uff0c\u7c7b\u4f3c\u4e00\u6761\u8def\u4e2d\u6709\u4e00\u9053\u9690\u5f62\u7684\u5899\uff0c\u6211\u4eec\u5f3a\u5236\u8ba9\u667a\u80fd\u4f53\u7ed5\u884c\uff0c\u4f46\u662f\u667a\u80fd\u4f53\u5e76\u4e0d\u77e5\u9053\u4e3a\u4ec0\u4e48\u8981\u7ed5\u884c\uff0c\u7531\u4e8e\u770b\u4e0d\u5230\u8fd9\u9762\u5899\uff0c\u5728\u4ed6\u7684\u51b3\u7b56\u5224\u65ad\u4e2d\u76f4\u7ebf\u884c\u9a76\u662f\u6700\u4f18\u7b56\u7565\u3002\u56e0\u6b64\u6211\u4eec\u5e94\u8be5\u8bbe\u8ba1\u7b97\u6cd5\uff0c\u8ba9\u667a\u80fd\u4f53\u4e3b\u52a8\u53bb\u8bc6\u522b\u548c\u9075\u5b88\u89c4\u5219\uff0c\u4f7f\u5176\u5728\u7edd\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u5373\u4f7f\u4e0d\u4f9d\u8d56\u5916\u754c\u5c4f\u853d\u4e5f\u80fd\u8f93\u51fa\u5408\u6cd5\u52a8\u4f5c\uff0c\u5728\u672c\u6848\u4f8b\u4e2d\u5c31\u662f\u8ba9\u667a\u80fd\u4f53\u77e5\u9053\u4e3a\u4ec0\u4e48\u4e0d\u80fd\u76f4\u884c\u800c\u9009\u62e9\u7ed5\u884c\u3002</p> <p>\u8865\uff1a\u201c\u4e0d\u80fd\u9009\u975e\u6cd5\u52a8\u4f5c\u201d\u662f\u5ba2\u89c2\u8981\u6c42\uff0c\u201c\u77e5\u9053\u4e0d\u80fd\u9009\u5e76\u4e14\u4e0d\u4f1a\u9009\u201d\u624d\u662f\u771f\u6b63\u7684\u76ee\u7684</p> <p>\u2003\u2003\u5bf9\u6b64\uff0c\u6211\u4eec\u53ef\u4ee5\u8ba9\u667a\u80fd\u4f53\u4fdd\u6301\u77e5\u60c5\u6743\uff0c\u544a\u8bc9\u667a\u80fd\u4f53\u5b9e\u9645\u4e2d\u7684\u89c4\u5219\u3002\u5b9e\u65bd\u8fc7\u7a0b\u4e2d\uff0c\u901a\u5e38\u53ef\u4ee5\u5c06\u7279\u6b8a\u89c4\u5219\u4ee5\u9002\u5f53\u5730\u65b9\u5f0f\u52a0\u5165\u72b6\u6001\u4fe1\u606f\u4e2d\uff0c\u8ba9\u72b6\u6001\u7a7a\u95f4\u4e2d\u7684\u6570\u636e\u53ef\u4ee5\u4f53\u73b0\u89c4\u5219\u4fe1\u606f\uff0c\u5e76\u4e14\u8bbe\u8ba1\u7279\u5b9a\u7684\u56de\u62a5\u51fd\u6570\u4e0e\u4e4b\u505a\u914d\u5408\uff0c\u8ba9\u667a\u80fd\u4f53\u901a\u8fc7\u5927\u91cf\u7684\u63a2\u7d22\u5efa\u7acb\u201c\u5404\u79cd\u72b6\u6001\u4e0b\u9009\u62e9\u5408\u6cd5\u52a8\u4f5c\u548c\u89c4\u907f\u975e\u6cd5\u52a8\u4f5c\u201d\u4e0e\u201c\u5bf9\u5e94\u7cfb\u7edf\u52a8\u6001\u53d8\u5316\u201d\u4e4b\u95f4\u7684\u76f8\u5173\u6027\uff0c\u4ece\u800c\u5b66\u4f1a\u5728\u8f93\u5165\u72b6\u6001\u4e2d\u8bc6\u522b\u89c4\u5219\uff0c\u5e76\u4e14\u5728\u8be5\u89c4\u5219\u7684\u9650\u5236\u4e0b\u91c7\u53d6\u6700\u4f18\u7b56\u7565\u3002</p> <p>\u2003\u2003\u6b64\u5916\uff0c\u667a\u80fd\u4f53\u65e0\u6cd5\u53bb\u8bc6\u522b\u89c4\u5219\uff0c\u8fd8\u6709\u4e00\u4e2a\u539f\u56e0\u5c31\u662f\u201c\u622a\u65ad\u5f0f\u5730\u8ba9\u667a\u80fd\u4f53\u53bb\u505a\u67d0\u79cd\u52a8\u4f5c\u201d\u8fd9\u4e00\u8fc7\u7a0b\u4e0d\u662f\u8fde\u7eed\u7684\uff0c\u662f\u79bb\u6563\u95f4\u65ad\u7684\uff0c\u65e0\u6cd5\u901a\u8fc7\u6c42\u5bfc\u6765\u53cd\u5411\u4f20\u64ad\u505a\u4f18\u5316\u3002\u5bf9\u6b64\uff0c\u6211\u4eec\u53ef\u4ee5\u8ba9\u8fd9\u4e00\u8fc7\u7a0b\u8fde\u7eed\u5316\uff0c\u53ef\u4ee5\u6839\u636e\u5b9e\u9645\u60c5\u51b5\u5728\u56de\u62a5\u51fd\u6570\u4e2d\u589e\u52a0\u9488\u5bf9\u975e\u6cd5\u52a8\u4f5c\u7684\u60e9\u7f5a\u9879\uff0c\u4ece\u800c\u66f4\u76f4\u89c2\u5730\u6355\u6349\u5230\u975e\u6cd5\u52a8\u4f5c\u4e0e\u4f18\u5316\u76ee\u6807\u4e4b\u95f4\u7684\u8d1f\u76f8\u5173\u6027\u3002</p> <p>\u2003\u2003\u540c\u65f6\uff0c\u6211\u4eec\u8fd8\u53ef\u4ee5\u5229\u7528LSTM\u548cGRU\u7b49\u62e5\u6709\u201c\u8bb0\u5fc6\u201d\u529f\u80fd\u7684RNN\u7ed3\u6784\uff0c\u5c06\u540c\u4e00\u6bb5Episode\u5185\u7684\u5386\u53f2\u51b3\u7b56\u548c\u5bf9\u5e94\u7684\u56de\u62a5\u4f9d\u6b21\u8f93\u5165\u8fdb\u6765\uff0c\u7531\u795e\u7ecf\u7f51\u7edc\u81ea\u52a8\u53d1\u73b0\u975e\u6cd5\u52a8\u4f5c\u548c\u53ca\u65f6\u8d1f\u53cd\u9988\uff0c\u4ee5\u53ca\u5b83\u4eec\u4e0e\u76f8\u5e94\u72b6\u6001\u7684\u8054\u7cfb\uff0c\u4ece\u800c\u907f\u514d\u5728\u63a5\u4e0b\u6765\u7684\u51b3\u7b56\u4e2d\u8f93\u51fa\u975e\u6cd5\u52a8\u4f5c\u3002\u8fd9\u79cd\u65b9\u6848\u501f\u9274\u4e86\u5143\u5f3a\u5316\u5b66\u4e60\u7684\u601d\u8def\uff0c\u540e\u8005\u81f4\u529b\u4e8e\u5b66\u4e60\u4e00\u7c7b\u76f8\u4f3c\u4efb\u52a1\u7684\u901a\u7528\u77e5\u8bc6\uff0c\u5e76\u5728\u540c\u5206\u5e03\u5185\u7684\u964c\u751f\u4efb\u52a1\u4e2d\u901a\u8fc7\u5c11\u91cf\u73af\u5883\u4ea4\u4e92\u5373\u53ef\u5feb\u901f\u9002\u5e94\u3002</p>"},{"location":"RL/landing_guide/#_6","title":"\u72b6\u6001\u7a7a\u95f4\u7684\u8bbe\u8ba1","text":"<p>\u2003\u2003\u72b6\u6001\u4fe1\u606f\u4ee3\u8868\u4e86\u667a\u80fd\u4f53\u6240\u611f\u77e5\u5230\u7684\u73af\u5883\u4fe1\u606f\u4ee5\u53ca\u5176\u52a8\u6001\u53d8\u5316\uff0c\u72b6\u6001\u7a7a\u95f4\u8bbe\u8ba1\u7684\u8d28\u91cf\u76f4\u63a5\u51b3\u5b9a\u4e86DRL\u7b97\u6cd5\u80fd\u5426\u6536\u655b\u3001\u6536\u655b\u901f\u5ea6\u4ee5\u53ca\u6700\u7ec8\u7684\u6027\u80fd\uff0c\u5728\u8bbe\u8ba1\u72b6\u6001\u7a7a\u95f4\u65f6\u4e0d\u80fd\u8fc7\u5206\u4f9d\u8d56\u7aef\u5230\u7aef\u7684\u7279\u5f81\u5b66\u4e60\u4ee5\u53ca\u6781\u81f4\u7684\u7279\u5f81\u5de5\u7a0b\uff0c\u4e5f\u5c31\u662f\u4e0d\u80fd\u5ffd\u7565\u4eba\u5de5\u63d0\u53d6\u7279\u5f81\u4e5f\u4e0d\u80fd\u8fc7\u6e21\u5229\u7528\u4eba\u5de5\u63d0\u53d6\u7684\u7279\u5f81</p>"},{"location":"RL/landing_guide/#_7","title":"\u534f\u540c\u8bbe\u8ba1","text":"<p>\u2003\u2003\u72b6\u6001\u7a7a\u95f4\u7684\u8bbe\u8ba1\u4e0e\u53e6\u5916\u4e24\u4e2a\u8981\u7d20\u2014\u2014\u52a8\u4f5c\u7a7a\u95f4\u548c\u56de\u62a5\u51fd\u6570\u7684\u8bbe\u8ba1\u5e76\u4e0d\u662f\u76f8\u4e92\u5272\u88c2\u7684\uff0c\u5728\u5b9e\u9a8c\u4e2d\u4e09\u8005\u5f80\u5f80\u9700\u8981\u4e00\u5b9a\u7684\u534f\u540c\u8bbe\u8ba1\u3002\u72b6\u6001\u7a7a\u95f4\u7684\u8bbe\u8ba1\u5728\u903b\u8f91\u4e0a\u4ece\u5c5e\u4e8e\u52a8\u4f5c\u7a7a\u95f4\u548c\u56de\u62a5\u51fd\u6570\u7684\u8bbe\u8ba1\uff0c\u5728\u5b8f\u89c2\u65f6\u95f4\u8f74\u4e0a\u53ef\u4ee5\u8ba4\u4e3a\u5148\u6709\u52a8\u4f5c\u7a7a\u95f4\u548c\u56de\u62a5\u51fd\u6570\uff0c\u540e\u6709\u9488\u5bf9\u6027\u8bbe\u8ba1\u7684\u72b6\u6001\u7a7a\u95f4\u3002\u5177\u4f53\u5730\u6765\u8bf4\uff0c\u72b6\u6001\u7a7a\u95f4\u5e94\u8be5\u4e0e\u52a8\u4f5c\u7a7a\u95f4\u5728\u5c3a\u5ea6\u4e0a\u4fdd\u6301\u4e00\u81f4\uff0c\u5e76\u4e14\u4ee5\u56de\u62a5\u51fd\u6570\u4e3a\u6838\u5fc3\uff0c\u670d\u52a1\u4e8e\u5bf9\u957f\u671f\u79ef\u7d2f\u56de\u62a5\u7684\u9884\u6d4b\u548c\u51b3\u7b56\u76f8\u5173\u6027\u7684\u5efa\u7acb\u3002</p> <p>\u4e0e\u52a8\u4f5c\u7a7a\u95f4\u5c3a\u5ea6\u4e00\u81f4</p> <p>\u2003\u2003\u667a\u80fd\u4f53\u5728\u73af\u5883\u4e2d\u91c7\u53d6\u7684\u52a8\u4f5c\u4f1a\u53cd\u8fc7\u6765\u5f71\u54cd\u73af\u5883\u7684\u72b6\u6001\u4fe1\u606f\uff0c\u5e76\u4e14\u72b6\u6001\u4fe1\u606f\u5e94\u8be5\u80fd\u591f\u51c6\u786e\u53cd\u6620\u8fd9\u79cd\u72b6\u6001\u53d8\u5316\uff0c\u8fd9\u5c31\u8981\u6c42\u72b6\u6001\u5728\u7a7a\u95f4\u548c\u65f6\u95f4\u5c3a\u5ea6\u4e0a\u4e0e\u8be5\u52a8\u4f5c\u5f15\u8d77\u7684\u53d8\u5316\u4fdd\u6301\u4e00\u81f4\uff0c\u72b6\u6001\u7684\u53d8\u5316\u53ef\u4ee5\u53ca\u65f6\u3001\u51c6\u786e\u5730\u53cd\u6620\u52a8\u4f5c\u7684\u53d8\u5316\uff08\u53cd\u6620\u4e00\u4e2a\u52a8\u4f5c\u662f\u4e0d\u662f\u5408\u7406\u7684\u52a8\u4f5c\uff0c\u8981\u6c42\u72b6\u6001\u548c\u52a8\u4f5c\u7684\u7075\u654f\u5ea6\u548c\u7c92\u5ea6\u4fdd\u6301\u4e00\u81f4\uff09\u3002\u5047\u8bbe\u52a8\u4f5c\u7a7a\u95f4\u4ee5\u5398\u7c73\u4e3a\u6700\u5c0f\u79fb\u52a8\u5355\u4f4d\uff0c\u800c\u72b6\u6001\u7a7a\u95f4\u4ee5\u7c73\u4e3a\u6700\u5c0f\u611f\u77e5\u5355\u4f4d\uff0c\u90a3\u4e48\u8fd9\u79cd\u6267\u884c-\u53cd\u9988\u5206\u8fa8\u7387\u7684\u9519\u4f4d\u5c06\u5bfc\u81f4DRL\u7b97\u6cd5\u96be\u4ee5\u6536\u655b\u3002</p> <p>\u4ee5\u56de\u62a5\u51fd\u6570\u4e3a\u4e2d\u5fc3</p> <p>\u2003\u2003\u6bcf\u4e00\u4e2a\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\u90fd\u6709\u5404\u81ea\u7684\u5b66\u4e60\u76ee\u6807\uff0c\u800c\u8be5\u76ee\u6807\u53c8\u5b8c\u5168\u662f\u901a\u8fc7\u56de\u62a5\u51fd\u6570\u6765\u4f20\u9012\u7684\uff0c\u56e0\u6b64\u72b6\u6001\u7a7a\u95f4\u7684\u8bbe\u8ba1\u5fc5\u987b\u7d27\u5bc6\u56f4\u7ed5\u56de\u62a5\u51fd\u6570\u8fdb\u884c\uff0c\u4e8c\u8005\u5f80\u5f80\u5f7c\u6b64\u4ea4\u7ec7\u8fdb\u884c\u3002\u901a\u8fc7\u523b\u610f\u589e\u5f3a\u72b6\u6001\u4fe1\u606f\u4e0e\u56de\u62a5\u51fd\u6570\u4e4b\u95f4\u7684\u76f8\u5173\u6027\uff0c\u5c06\u4e24\u8005\u4e4b\u95f4\u7684\u6620\u5c04\u5173\u7cfb\u5177\u4f53\u5316\uff0c\u4ece\u800c\u4e3a\u503c\u4f30\u8ba1\u548c\u51b3\u7b56\u751f\u6210\u63d0\u4f9b\u5145\u5206\u7684\u53ef\u8fa8\u8bc6\u4f9d\u636e\u3002</p>"},{"location":"RL/landing_guide/#_8","title":"\u8bbe\u8ba1\u6b65\u9aa4","text":""},{"location":"RL/landing_guide/#_9","title":"\u4efb\u52a1\u5206\u6790","text":"<p>\u2003\u2003\u5148\u5c06\u539f\u59cb\u4efb\u52a1\u62c6\u89e3\u6210\u4e0d\u540c\u7684\u5b50\u76ee\u6807\uff0c\u8fd9\u4e9b\u5b50\u76ee\u6807\u5305\u62ec\u60f3\u8ba9\u667a\u80fd\u4f53\u505a\u7684\u548c\u4e0d\u60f3\u8ba9\u667a\u80fd\u4f53\u505a\u7684\uff0c\u9488\u5bf9\u8fd9\u4e9b\u5b50\u76ee\u6807\u9010\u4e00\u8bbe\u8ba1\u56de\u62a5\u51fd\u6570\uff0c\u901a\u8fc7\u56de\u62a5\u51fd\u6570\u6765\u7ea6\u675f\u667a\u80fd\u4f53\u7684\u51b3\u7b56\uff0c\u867d\u7136\u6b64\u65f6\u7684\u56de\u62a5\u51fd\u6570\u53ef\u80fd\u4e0d\u662f\u6700\u597d\u7684\uff0c\u4f46\u53ea\u8981\u80fd\u4fdd\u8bc1\u667a\u80fd\u4f53\u5b66\u4f1a\u57fa\u672c\u7684\u76ee\u6807\u6280\u80fd\u5c31\u53ef\u4ee5\uff0c\u5728\u6b64\u57fa\u7840\u4e0a\u8fdb\u5165\u4e0b\u4e00\u4e2a\u73af\u8282\u2014\u2014\u76f8\u5173\u4fe1\u606f\u7b5b\u9009\uff0c\u627e\u51fa\u4e0e\u56de\u62a5\u51fd\u6570\u5404\u6210\u5206\u76f4\u63a5\u6216\u95f4\u63a5\u76f8\u5173\u7684\u72b6\u6001\u4fe1\u606f\u3002</p>"},{"location":"RL/landing_guide/#_10","title":"\u76f8\u5173\u4fe1\u606f\u7b5b\u9009","text":"<p>\u2003\u2003\u968f\u7740DRL\u7b97\u6cd5\u8bad\u7ec3\u7684\u8fdb\u884c\uff0c\u795e\u7ecf\u7f51\u7edc\u4f1a\u9010\u6e10\u5b66\u4f1a\u4ece\u8f93\u5165\u7684\u72b6\u6001\u4fe1\u606f\u4e2d\u63d0\u70bc\u51fa\u4e0e\u957f\u671f\u7d2f\u8ba1\u56de\u62a5\u9ad8\u5ea6\u5173\u8054\u7684\u7279\u5f81\uff0c\u5e76\u4e14\u8fdb\u4e00\u6b65\u7528\u4e8e\u751f\u6210\u51b3\u7b56\u3002\u5728\u7279\u5b9a\u7684\u56de\u62a5\u51fd\u6570\u4e0b\uff0c\u67d0\u4e2a\u72b6\u6001\u4fe1\u606f\u53d8\u5316\u5f97\u5230\u7684\u53cd\u9988\u8d8a\u53ca\u65f6\uff0c\u795e\u7ecf\u7f51\u7edc\u5c31\u4f1a\u8d8a\u5bb9\u6613\u5b66\u4f1a\u5982\u4f55\u5bf9\u5176\u8fdb\u884c\u52a0\u5de5\u5e76\u4e14\u5efa\u7acb\u8d77\u51b3\u7b56\u76f8\u5173\u6027\uff1b\u53cd\u4e4b\uff0c\u72b6\u6001\u4fe1\u606f\u53d8\u5316\u5f97\u5230\u7684\u53cd\u9988\u8d8a\u6ede\u540e\uff0c\u51b3\u7b56\u76f8\u5173\u6027\u5c31\u8d8a\u4e0d\u5bb9\u6613\u5efa\u7acb\uff0c\u76f8\u5e94\u7684\u5b66\u4e60\u96be\u5ea6\u4e5f\u8d8a\u9ad8\u3002\u6839\u636e\u8fd9\u79cd\u53cd\u9988\u65f6\u95f4\u7684\u957f\u77ed\uff0c\u53ef\u4ee5\u7c97\u7565\u5730\u5c06\u72b6\u6001\u4fe1\u606f\u5206\u4e3a\u76f4\u63a5\u76f8\u5173\u4fe1\u606f\u548c\u95f4\u63a5\u76f8\u5173\u4fe1\u606f\u3002</p> <p>\u2003\u2003\u6bd4\u5982\u5bf9\u4e8e\u201c\u667a\u80fd\u4f53\u4e0d\u80fd\u649e\u5899\u201d\u8fd9\u4e00\u9700\u6c42\uff0c\u6709\u5982\u4e0b\u4e24\u79cd\u56de\u62a5\u51fd\u6570\u7684\u8bbe\u8ba1\uff1a\u2460\u649e\u5230\u5899\u540e\u7ed9\u4e88\u4e00\u4e2a\u8d1f\u53cd\u9988\uff08\u4e0e\u5899\u4e4b\u95f4\u7684\u8ddd\u79bb\u4e3a0\u65f6\uff09\uff1b\u2461\u7ed9\u5b9a\u4e00\u4e2a\u9608\u503c\uff0c\u4e0e\u5899\u4e4b\u95f4\u7684\u8ddd\u79bb\u5c0f\u4e8e\u9608\u503c\u65f6\u6b63\u53cd\u9988\u964d\u4f4e\uff0c\u5e76\u4e14\u968f\u7740\u8ddd\u79bb\u7684\u51cf\u5c0f\u505a\u6301\u7eed\u5730\u60e9\u7f5a\u3002\u7b2c\u4e00\u4e2a\u53cd\u9988\u6ede\u540e\u6027\u8f83\u9ad8\uff0c\u667a\u80fd\u4f53\u53ea\u6709\u649e\u5230\u4e86\u5899\u624d\u4f1a\u53d1\u73b0\u201c\u8fd9\u4e48\u505a\u4e0d\u5bf9\u201d\uff0c\u53cd\u4e4b\u7b2c\u4e8c\u4e2a\u53cd\u9988\u7075\u654f\u5ea6\u8f83\u9ad8\uff0c\u9760\u8fd1\u5899\u65f6\u667a\u80fd\u4f53\u5c31\u4f1a\u610f\u8bc6\u5230\u201c\u8fd9\u4e48\u505a\u5e94\u8be5\u4e0d\u592a\u5bf9\u201d\uff0c\u7b97\u6cd5\u4e3a\u4e86\u8ba9\u667a\u80fd\u4f53\u4e0d\u4f1a\u79bb\u5899\u592a\u8fd1\uff0c\u4ece\u800c\u907f\u514d\u649e\u5899\uff0c\u5f88\u5bb9\u6613\u80fd\u591f\u5bf9\u8def\u5f84\u505a\u51fa\u6b63\u786e\u7684\u89c4\u5212\u3002</p> <p>\u76f4\u63a5\u76f8\u5173\u4fe1\u606f</p> <p>\u2003\u2003\u76f4\u63a5\u76f8\u5173\u4fe1\u606f\u5c31\u662f\u6307\u4e0e\u56de\u62a5\u51fd\u6570\u4e2d\u67d0\u4e2a\u5956\u52b1\u6216\u60e9\u7f5a\u9879\u5373\u65f6\u8054\u52a8\u7684\u4fe1\u606f\uff0c\u5728\u6848\u4f8b\u2461\u4e2d\uff0c\u4e0e\u5899\u4e4b\u95f4\u7684\u8ddd\u79bb\u4e3a\u5bf9\u5e94\u56de\u62a5\u51fd\u6570\u7684\u76f4\u63a5\u76f8\u5173\u4fe1\u606f\u3002\u76f4\u63a5\u76f8\u5173\u4fe1\u606f\u6240\u5bf9\u5e94\u7684\u56de\u62a5\u51fd\u6570\u6210\u5206\u9ed8\u8ba4\u662f\u7a20\u5bc6\u7684\uff0c\u5728\u5b9e\u8df5\u4e2d\uff0c\u4e3a\u4e86\u5b9e\u73b0\u67d0\u79cd\u76ee\u7684\uff0c\u5728\u56de\u62a5\u51fd\u6570\u4e2d\u8bbe\u7f6e\u4e00\u4e2a\u5956\u52b1/\u60e9\u7f5a\u9879\uff0c\u5e76\u4e14\u987a\u624b\u5728\u72b6\u6001\u7a7a\u95f4\u4e2d\u76f8\u5e94\u589e\u52a0\u4e00\u4e2a\u6216\u591a\u4e2a\u76f4\u63a5\u76f8\u5173\u4fe1\u606f\uff08\u4f8b\u5982\u4e0a\u9762\u6848\u4f8b\u4e2d\u7684\u201c\u667a\u80fd\u4f53\u4e0e\u5899\u4e4b\u95f4\u7684\u8ddd\u79bb\u201d\uff0c\u5956\u52b1/\u60e9\u7f5a\u9879\u8981\u4e0e\u6240\u589e\u52a0\u7684\u76f4\u63a5\u76f8\u5173\u4fe1\u606f\u5177\u6709\u5f3a\u76f8\u5173\u6027\uff09\uff0c\u6216\u8005\u987a\u5e8f\u53cd\u8fc7\u6765\uff0c\u5148\u589e\u52a0\u72b6\u6001\u4fe1\u606f\uff0c\u518d\u8bbe\u7f6e\u5bf9\u5e94\u7684\u5956\u52b1/\u60e9\u7f5a\u9879\uff0c\u8fd9\u662f\u72b6\u6001\u7a7a\u95f4\u4e0e\u56de\u62a5\u51fd\u6570\u534f\u540c\u8bbe\u8ba1\u7684\u5e38\u89c1\u6a21\u5f0f\u3002</p> <p>\u6ce8\uff1a\u8bbe\u7acb\u76f4\u63a5\u76f8\u5173\u4fe1\u606f\u76f8\u5f53\u4e8e\u7ed9\u667a\u80fd\u4f53\u8bbe\u7acb\u4e86\u4e00\u4e2a\u4e2d\u95f4\u671f\u671b\uff0c\u667a\u80fd\u4f53\u53ef\u4ee5\u901a\u8fc7\u89c2\u5bdf\u4e2d\u95f4\u671f\u671b\u6765\u5224\u65ad\u662f\u5426\u80fd\u591f\u5b8c\u6210\u6700\u7ec8\u7684\u76ee\u7684\u3002</p> <p>\u95f4\u63a5\u76f8\u5173\u4fe1\u606f</p> <p>\u2003\u2003\u95f4\u63a5\u76f8\u5173\u4fe1\u606f\u6307\u7684\u662f\u56de\u62a5\u51fd\u6570\u4e2d\u6ca1\u6709\u53ca\u65f6\u8054\u52a8\u7684\u72b6\u6001\u4fe1\u606f\uff0c\u95f4\u63a5\u76f8\u5173\u4fe1\u606f\u7684\u53d8\u5316\u9700\u8981\u4e00\u6bb5\u65f6\u95f4\u540e\u624d\u4f1a\u5f97\u5230\u56de\u62a5\u51fd\u6570\u7684\u53cd\u9988\uff0c\u5177\u6709\u6ede\u540e\u6027\uff0c\u5728\u6848\u4f8b\u2460\u4e2d\uff0c\u4e0e\u5899\u4e4b\u95f4\u7684\u8ddd\u79bb\u4e3a\u5bf9\u5e94\u56de\u62a5\u51fd\u6570\u7684\u95f4\u63a5\u76f8\u5173\u4fe1\u606f\u3002\u95f4\u63a5\u76f8\u5173\u4fe1\u606f\u4e0e\u957f\u671f\u56de\u62a5\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u8f83\u5f31\uff0c\u7b97\u6cd5\u4e0d\u5bb9\u6613\u4ece\u4e2d\u53d1\u73b0\u89c4\u5f8b\uff0c\u4e0d\u5bb9\u6613\u5f97\u5230\u4f18\u5316\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u4fee\u6539\u56de\u62a5\u51fd\u6570\uff0c\u6765\u8ba9\u90e8\u5206\u72b6\u6001\u4fe1\u606f\u53d8\u4e3a\u76f4\u63a5\u72b6\u6001\u4fe1\u606f\uff0c\u4f7f\u7f51\u7edc\u66f4\u5bb9\u6613\u5f97\u5230\u4f18\u5316\u3002\u4f8b\u5982\uff1a\u5bf9\u4e8e\u201c\u8ba9\u667a\u80fd\u4f53\u8d70\u5411A\u70b9\u201d\u8fd9\u4e00\u9700\u6c42\uff0c\u2460\u5230\u8fbeA\u4e4b\u540e\u7ed9\u4e00\u4e2a\u6b63\u53cd\u9988\uff1b\u2461\u667a\u80fd\u4f53\u79bbA\u8d8a\u6765\u8d8a\u8fd1\uff0c\u9010\u6b65\u7ed9\u4e88\u6b63\u53cd\u9988\uff08\u53ef\u4ee5\u901a\u8fc7\u5206\u6790\u76f8\u90bb\u7684\u4e24\u4e2a\u72b6\u6001\u5f97\u5230\uff09\uff0c\u4ece\u2460\u6539\u4e3a\u2461\u4e5f\u662f\u4e00\u79cd\u57fa\u4e8e\u76f8\u5173\u4fe1\u606f\u7b5b\u9009\u7684\u6b63\u5411\u4f18\u5316\u3002</p> <p>\u6ce8\uff1a\u76f4\u63a5\u76f8\u5173\u6027\u4e0e\u95f4\u63a5\u76f8\u5173\u6027\u4e4b\u95f4\u7684\u533a\u522b\u548c\u8fde\u7eed\u4e0e\u79bb\u6563\u7684\u533a\u522b\u5f88\u7c7b\u4f3c\uff0c\u76f4\u63a5\u76f8\u5173\u4fe1\u606f\u53ef\u4ee5\u8fde\u7eed\u3001\u9010\u6b65\u5730\u53cd\u6620\u52a8\u4f5c\u597d\u574f\uff1b</p> <p>Oracle\u4fe1\u606f</p> <p>\u2003\u2003\u5728\u8bbe\u8ba1\u72b6\u6001\u7a7a\u95f4\u65f6\uff0c\u8fd8\u6709\u4e00\u7c7bOracle\u4fe1\u606f\u503c\u5f97\u5173\u6ce8\uff0c\u4ed6\u4eec\u663e\u5f0f\u5730\u8868\u8fbe\u4e86\u672c\u5e94\u7531DRL\u7b97\u6cd5\u81ea\u884c\u5b66\u4e60\u548c\u63a8\u7406\u7684\u9690\u85cf\u4fe1\u606f\uff0c\u4ece\u800c\u964d\u4f4e\u4e86\u4efb\u52a1\u5b66\u4e60\u7684\u96be\u5ea6\uff0c\u8d77\u5230\u4e86\u52a0\u901f\u7b97\u6cd5\u6536\u655b\u7684\u4f5c\u7528\u3002\u4f8b\u5982\u5728\u4e8c\u7ef4\u5e73\u9762\u5bfc\u822a\u4efb\u52a1\u4e2d\uff0c\u5145\u7535\u6869\u4f4d\u7f6e\u5c5e\u4e8e\u73af\u5883\u7684\u4e00\u90e8\u5206\uff0c\u5728\u73af\u5883\u4e2d\u7684\u4f4d\u7f6e\u662f\u4e0d\u53d1\u751f\u53d8\u5316\u7684\uff0c\u5982\u679c\u544a\u8bc9\u7b97\u6cd5\u8fd9\u4e9b\u4f4d\u7f6e\u5728\u54ea\u91cc\uff0c\u90a3\u4e48\u66f4\u5bb9\u6613\u8ba9\u7b97\u6cd5\u6839\u636e\u5145\u7535\u6869\u7684\u4f4d\u7f6e\u505a\u8def\u5f84\u89c4\u5212\u3002\u4f46\u7531\u4e8e\u4ed6\u4eec\u662f\u56fa\u5b9a\u4e0d\u53d8\u7684\uff0c\u56e0\u6b64\u7b97\u6cd5\u603b\u80fd\u901a\u8fc7\u5927\u91cf\u63a2\u7d22\u6765\u9690\u5f0f\u5730\u5b66\u4f1a\u5e76\u4e14\u201c\u8bb0\u4f4f\u201d\u8fd9\u4e9b\u4f4d\u7f6e\uff0c\u56e0\u6b64\u5148\u9a8c\u4fe1\u606fOracle\u5e76\u975e\u4e0d\u53ef\u6216\u7f3a\uff0c\u4f46\u662f\u63d0\u4f9bOracle\u53ef\u4ee5\u52a0\u901f\u7b97\u6cd5\u7684\u6536\u655b\u3002\u4e00\u65e6\u5728\u72b6\u6001\u7a7a\u95f4\u4e2d\u63d0\u4f9b\u4e86Oracle\u4fe1\u606f\uff0c\u90a3\u4e48DRL\u7b97\u6cd5\u5c31\u80fd\u591f\u901a\u8fc7\u5728\u539f\u59cb\u6570\u636e\u6216\u7279\u5f81\u5c42\u9762\u4e0e\u4e4b\u8fdb\u884c\u67d0\u79cd\u6bd4\u8f83\uff0c\u4ece\u800c\u66f4\u52a0\u9ad8\u6548\u5730\u5efa\u7acb\u8d77\u72b6\u6001\u4e0e\u56de\u62a5\u51fd\u6570\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u3002</p> <p>\u6ce8\uff1a\u5728\u5b66\u672f\u754c\u901a\u5e38\u5c06Oracle\u7b56\u7565\u4f5c\u4e3a\u67d0\u4efb\u52a1\u7684\u6027\u80fd\u4e0a\u9650\u3002</p>"},{"location":"RL/landing_guide/#_11","title":"\u6cdb\u5316\u6027\u8003\u91cf","text":"<p>\u2003\u2003\u73b0\u5b9e\u4e16\u754c\u4e2d\uff0c\u4efb\u52a1\u5f80\u5f80\u5177\u6709\u4e00\u5b9a\u7684\u53ef\u53d8\u56e0\u7d20\uff0c\u4f8b\u5982\u5bfc\u822a\u4efb\u52a1\u4e2d\u5730\u56fe\u7684\u5c3a\u5bf8\u3001\u969c\u788d\u7269\u7684\u5206\u5e03\u7b49\u7b49\uff0c\u6211\u4eec\u5e0c\u671b\u6240\u8bbe\u8ba1\u7684\u7b97\u6cd5\u5e94\u5f53\u5177\u5907\u4e00\u5b9a\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u53ef\u4ee5\u4ece\u5bb9\u5730\u5e94\u5bf9\u73af\u5883\u7684\u53d8\u5316\uff0c\u8fd9\u5c31\u8981\u6c42\u6240\u8bbe\u8ba1\u7684\u72b6\u6001\u7a7a\u95f4\u5728\u8de8\u4efb\u52a1\u573a\u666f\u4e0b\u5c3d\u53ef\u80fd\u4fdd\u6301\u4e00\u81f4\uff0c\u4e3a\u4e86\u5b9e\u73b0\u8be5\u76ee\u7684\uff0c\u4e3b\u8981\u53ef\u4ee5\u91c7\u53d6\u4e24\u4e2a\u624b\u6bb5\uff1a\u72b6\u6001\u4fe1\u606f\u7684\u62bd\u8c61\u5316\u9884\u5904\u7406\u548c\u4fe1\u606f\u7ec4\u7ec7\u5f62\u5f0f\u7684\u7edf\u4e00\u5316\u3002</p> <p>\u62bd\u8c61\u5316\u9884\u5904\u7406</p> <p>\u2003\u2003\u5728\u673a\u5668\u5b66\u4e60\u9886\u57df\uff0c\u5f80\u5f80\u6a21\u578b\u7684\u8f93\u5165\u4fe1\u606f\u8d8a\u591a\u5c31\u4f1a\u8d8a\u5bb9\u6613\u5bfc\u81f4\u5176\u8fc7\u62df\u5408\uff0c\u7b97\u6cd5\u53ef\u80fd\u4f1a\u5728\u65e0\u7528\u7684\u7279\u5f81\u4fe1\u606f\u4e0e\u6a21\u578b\u8f93\u51fa\u4e4b\u95f4\u5efa\u7acb\u865a\u5047\u7684\u76f8\u5173\u6027\uff0c\u8fd9\u4e00\u73b0\u8c61\u540c\u6837\u4e5f\u9002\u7528\u4e8eDRL\uff0c\u5bf9\u4e8eDRL\u7b97\u6cd5\u7684\u8f93\u5165\u72b6\u6001\u800c\u8a00\uff0c\u4fe1\u606f\u8d8a\u62bd\u8c61\uff0c\u5176\u6240\u5305\u542b\u7684\u5171\u6027\u6210\u5206\u8d8a\u591a\u3001\u5e72\u6270\u6210\u5206\u8d8a\u5c11\uff0c\u7b56\u7565\u4e5f\u5c31\u8d8a\u5bb9\u6613\u5728\u76f8\u4f3c\u4efb\u52a1\u95f4\u8fdb\u884c\u8fc1\u79fb\u3002</p> <p>\u2003\u2003\u57fa\u4e8e\u9886\u57df\u77e5\u8bc6\u548c\u5bf9\u4efb\u52a1\u903b\u8f91\u7684\u7406\u89e3\u5bf9\u539f\u59cb\u72b6\u6001\u4fe1\u606f\u505a\u4e8c\u6b21\u52a0\u5de5\uff0c\u5e76\u4ece\u4e2d\u63d0\u70bc\u51fa\u66f4\u52a0\u7b80\u6d01\u3001\u9ad8\u6548\uff0c\u5e76\u4e14\u4e0e\u56de\u62a5\u51fd\u6570\u76f8\u5173\u6027\u66f4\u5f3a\u7684\u4fe1\u606f\u6210\u5206\u6216\u8868\u8fbe\u5f0f\uff0c\u4ece\u800c\u4f7fDRL\u7b97\u6cd5\u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u6027\u80fd\u3002\u4f8b\u5982AlphaGo\u5728\u72b6\u6001\u7a7a\u95f4\u8bbe\u8ba1\u4e2d\u5bf9\u68cb\u76d8\u7684\u62bd\u8c61\u5316\uff0c\u4f7f\u7b56\u7565\u7f51\u7edc\u53ef\u4ee5\u76f4\u63a5\u8fc1\u79fb\u5230\u4efb\u4f55\u5c5e\u6027\u7684\u56f4\u68cb\u68cb\u76d8\u4e0a\u3002</p> <p>\u2003\u2003\u5728\u4e8c\u7ef4\u5e73\u9762\u7684\u5bfc\u822a\u4efb\u52a1\u4e2d\uff0c\u5047\u8bbep\u8868\u793a\u667a\u80fd\u4f53\u5f53\u524d\u7684\u4f4d\u7f6e\uff0cg\u8868\u793a\u671f\u671b\u667a\u80fd\u4f53\u6240\u5230\u8fbe\u7684\u4f4d\u7f6e\uff0c\u5982\u679c\u4ee5\u7edd\u5bf9\u5750\u6807\u53bb\u8868\u793ap\u548cg\u7684\u4f4d\u7f6e\uff0c\u5219\u8be5\u72b6\u6001\u4fe1\u606f\u4f1a\u8bf1\u4f7f\u795e\u7ecf\u7f51\u7edc\u201c\u8bb0\u4f4f\u201d\u5730\u56fe\u4e2d\u6bcf\u4e2a\u4f4d\u7f6e\u7684\u7279\u5f81\uff0c\u6240\u8bad\u7ec3\u7684\u7b97\u6cd5\u5728\u5f53\u524d\u5730\u56fe\u4e0b\u53ef\u4ee5\u5b9e\u73b0\u826f\u597d\u7684\u5bfc\u822a\u76ee\u7684\uff0c\u4f46\u662f\u4e0d\u5229\u4e8e\u6cdb\u5316\u5230\u5176\u4ed6\u5730\u56fe\u4e0a\u53bb\u3002\u4e00\u79cd\u6bd4\u8f83\u6709\u6548\u7684\u6539\u8fdb\u7b56\u7565\u5c31\u662f\u5efa\u7acb\u4ee5\u667a\u80fd\u4f53\u4e3a\u4e2d\u5fc3\u7684\u5750\u6807\u7cfb\uff0c\u5c06\u76ee\u6807\u4f4d\u7f6eg\u6539\u4e3a\u76f8\u5bf9\u4e8e\u667a\u80fd\u4f53\u7684\u5750\u6807g-p\uff0c\u8ba9\u667a\u80fd\u4f53\u7ad9\u5728\u5730\u56fe\u4e2d\u5fc3\u53bb\u51b3\u7b56\u5bfc\u822a\uff0c\u4ece\u800c\u4f7f\u7b97\u6cd5\u53ef\u4ee5\u5b66\u4e60\u5230\u667a\u80fd\u4f53\u89c6\u89d2\u4e0b\u66f4\u4e3a\u901a\u7528\u7684\u5bfc\u822a\u77e5\u8bc6\uff0c\u5e76\u4e14\u5c3d\u53ef\u80fd\u51cf\u5c11\u5bf9\u7279\u5b9a\u5730\u56fe\u7684\u8fc7\u62df\u5408\u3002</p> <p>\u2003\u2003\u5728\u5269\u4f59\u7535\u91cfe_{left}\u4e0e\u5145\u7535\u9884\u8b66E\u7684\u6848\u4f8b\u4e2d\uff0c\u5728\u56de\u62a5\u51fd\u6570r=-w\\cdot1[e_{left}&lt;E]\u7684\u9a71\u52a8\u4e0b\uff0cDRL\u7b97\u6cd5\u53ef\u4ee5\u901a\u8fc7\u5927\u91cf\u7684\u63a2\u7d22\u5b66\u4f1a\u6839\u636e\u5f53\u524d\u5269\u4f59\u7535\u91cfe_{left}\u4e0e\u5145\u7535\u9884\u8b66\u7535\u91cfE\u7684\u76f8\u5bf9\u5173\u7cfb\uff0c\u9002\u65f6\u89c4\u5212\u5145\u7535\u7684\u65f6\u673a\u548c\u8def\u5f84\uff0c\u4ece\u800c\u5c3d\u53ef\u80fd\u907f\u514d\u5269\u4f59\u7535\u91cf\u5c0f\u4e8e\u9884\u8b66\u7535\u91cf\u7684\u60c5\u51b5\u3002\u7136\u800c\uff0c\u5ba2\u6237\u53ef\u80fd\u540e\u7eed\u6839\u636e\u5b9e\u9645\u60c5\u51b5\u8981\u6c42\u964d\u4f4e\u6216\u63d0\u5347\u5145\u7535\u9884\u8b66\u7535\u91cfE\uff0c\u4e00\u65e6\u6539\u53d8\u9884\u8b66\u7535\u91cf\uff0c\u5728\u56de\u62a5\u51fd\u6570\u4e2d\u53d7\u5230\u60e9\u7f5a\u7684\u6761\u4ef6\u5c31\u53d8\u4e86\uff0c\u56e0\u6b64\u8fd9\u65f6\u5019\u6240\u8bad\u7ec3\u7684\u7b97\u6cd5\u5c31\u4e0d\u9002\u7528\u4e86\uff0c\u9700\u8981\u53e6\u5916\u518d\u6b21\u8bad\u7ec3DRL\u6a21\u578b\u3002\u5bf9\u6b64\uff0c\u53ef\u4ee5\u5c06\u7edd\u5bf9\u7535\u91cfe_{left}\u6539\u4e3a\u76f8\u5bf9\u7535\u91cf\\frac{e_{left}}{E}\uff0c\u76f4\u63a5\u53cd\u6620\u5269\u4f59\u7535\u91cf\u4e0e\u5145\u7535\u9884\u8b66\u7535\u91cf\u4e4b\u95f4\u7684\u6bd4\u503c\u5173\u7cfb\uff0c\u8fd9\u6837\u5373\u4f7f\u5145\u7535\u7535\u91cf\u6539\u53d8\u4e5f\u4e0d\u4f1a\u5f71\u54cd\u539f\u6709\u7b56\u7565\u7684\u4f7f\u7528\u3002</p> <p>\u6ce8\uff1a\u8bf4\u767d\u4e86\uff0c\u8fd8\u662f\u79bb\u6563\u4e0e\u8fde\u7eed\u7684\u95ee\u9898\uff0c\u5c06\u79bb\u6563\u7684\u4f5c\u7528\u4f18\u5316\u65b9\u5f0f\u4e3a\u8fde\u7eed\u7684\u4f18\u5316\u65b9\u5f0f\u3002</p> <p>\u2003\u2003\u7531\u4e8e\u5f3a\u5316\u5b66\u4e60\u7f3a\u4e4f\u8db3\u591f\u9ad8\u6548\u7684\u76d1\u7763\u4fe1\u53f7\uff0c\u5373\u4f7f\u539f\u59cb\u72b6\u6001\u4fe1\u606f\u5df2\u7ecf\u5305\u542b\u4efb\u52a1\u5b66\u4e60\u6240\u9700\u7684\u5168\u90e8\u4fe1\u606f\uff0c\u795e\u7ecf\u7f51\u7edc\u4e5f\u96be\u4ee5\u9ad8\u6548\u5730\u5b66\u4f1a\u4ece\u4e2d\u63d0\u70bc\u51fa\u6709\u6548\u5730\u7279\u5f81\uff0c\u5373\u5bb9\u6613\u88ab\u65e0\u5173\u4fe1\u606f\u6240\u5e72\u6270\u3002\u72b6\u6001\u4fe1\u606f\u7684\u62bd\u8c61\u5316\u9884\u5904\u7406\u964d\u4f4e\u4e86\u795e\u7ecf\u7f51\u7edc\u4ece\u539f\u59cb\u72b6\u6001\u4fe1\u606f\u4e2d\u63d0\u53d6\u6709\u6548\u7279\u5f81\u3001\u5e76\u5efa\u7acb\u957f\u671f\u51b3\u7b56\u76f8\u5173\u6027\u7684\u96be\u5ea6\uff0c\u4e0d\u4ec5\u80fd\u591f\u6539\u5584\u7b56\u7565\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u540c\u65f6\u8fd8\u53ef\u4ee5\u63d0\u5347DRL\u7b97\u6cd5\u7684\u5b66\u4e60\u6548\u7387\u4ee5\u53ca\u6700\u7ec8\u6027\u80fd\u3002</p> <p>\u5f62\u5f0f\u7edf\u4e00</p> <p>\u2003\u2003\u5f53\u6240\u6709\u72b6\u6001\u4fe1\u606f\u90fd\u5df2\u7ecf\u7b5b\u9009\u548c\u8bbe\u8ba1\u5b8c\u6bd5\u4e4b\u540e\uff0c\u6700\u76f4\u63a5\u7684\u7ec4\u7ec7\u65b9\u5f0f\u5c31\u662f\u5c06\u4ed6\u4eec\u62fc\u63a5\u6210\u4e00\u4e2a\u4e00\u7ef4\u7684\u5411\u91cf\uff0c\u4e4b\u540e\u8f93\u5165\u5230\u7f51\u7edc\u4e2d\u505a\u51b3\u7b56\u3002\u4f46\u662f\u8fd9\u6837\u4f1a\u5e26\u6765\u4e24\u4e2a\u95ee\u9898\uff1a\u2460\u5bb9\u6613\u5c06\u7b56\u7565\u9650\u5236\u4e8e\u7279\u5b9a\u573a\u666f\u4e0b\uff0c\u5047\u5982\u5145\u7535\u6869\u6570\u91cf\u589e\u52a0\u6216\u8005\u51cf\u5c11\uff0c\u72b6\u6001\u5411\u91cf\u7684\u7ef4\u5ea6\u548c\u7f51\u7edc\u7ed3\u6784\u4e5f\u8981\u968f\u4e4b\u53d1\u751f\u53d8\u5316\uff0c\u5bfc\u81f4\u539f\u6709\u7684\u7b56\u7565\u7f51\u7edc\u5f7b\u5e95\u5931\u6548\uff1b\u2461\u72b6\u6001\u7684\u8868\u8fbe\u80fd\u529b\u6709\u9650\uff0c\u7531\u4e8e\u73af\u5883\u4e2d\u969c\u788d\u7269\u7684\u5927\u5c0f\u3001\u5f62\u72b6\u3001\u6570\u91cf\u548c\u4f4d\u7f6e\u5206\u5e03\u5404\u5f02\uff0c\u96be\u4ee5\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\u51c6\u786e\u8868\u793a\u51fa\u6765\u3002</p> <p>\u2003\u2003\u4e3a\u4e86\u514b\u670d\u4ee5\u4e0a\u7684\u7f3a\u70b9\uff0c\u72b6\u6001\u7a7a\u95f4\u5b9c\u91c7\u7528\u201c\u7559\u767d\u5f0f\u201d\u4fe1\u606f\u7ec4\u7ec7\u5f62\u5f0f\u3002\u9996\u5148\u5145\u5206\u8003\u8651\u6240\u6709\u7684\u53ef\u80fd\u6027\u5e76\u4e14\u8bbe\u8ba1\u4e00\u5957\u5197\u4f59\u7684\u6a21\u677f\uff0c\u4f7f\u5176\u6bcf\u4e2a\u4f4d\u7f6e\u90fd\u6709\u56fa\u5b9a\u7684\u3001\u72ec\u4e00\u65e0\u4e8c\u7684\u542b\u4e49\uff0c\u7136\u540e\u5c06\u5f53\u524d\u53ef\u7528\u7684\u72b6\u6001\u4fe1\u606f\u586b\u5230\u76f8\u5e94\u7684\u4f4d\u7f6e\uff0c\u7a7a\u767d\u4f4d\u7f6e\u5219\u4ee5\u5e38\u6570\u586b\u5145\uff08\u4f8b\u59820\uff09\uff0c\u5982\u6b64\u4e00\u6765\uff0c\u5c31\u53ef\u4ee5\u7528\u7edf\u4e00\u7ef4\u5ea6\u7684\u72b6\u6001\u4fe1\u606f\u5e94\u5bf9\u5404\u79cd\u53ef\u80fd\u7684\u72b6\u6001\u53d8\u5316\u3002\u5197\u4f59\u6a21\u677f\u7684\u8bbe\u8ba1\u53ef\u4ee5\u91c7\u7528\u5411\u91cf\u7f16\u7801\u5f62\u5f0f\u3001\u7a7a\u95f4\u7f16\u7801\u5f62\u5f0f\u6216\u8005\u4e24\u8005\u7684\u7ec4\u5408\uff0c\u6709\u65f6\u4e3a\u4e86\u66f4\u52a0\u4fbf\u4e8e\u6355\u6349\u72b6\u6001\u4fe1\u606f\u5728\u65f6\u5e8f\u4e0a\u7684\u53d8\u5316\u7279\u5f81\uff0c\u8fd8\u53ef\u4ee5\u5c06\u4e00\u5b9a\u65f6\u95f4\u8de8\u5ea6\u5185\u7684\u72b6\u6001\u4fe1\u606f\u6309\u5148\u540e\u987a\u5e8f\u5806\u780c\u5230\u4e00\u8d77\uff0c\u5e76\u5f62\u6210\u6700\u7ec8\u7684\u72b6\u6001\u7a7a\u95f4\u3002</p> <p>\u2003\u2003\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\u4e2d\u667a\u80fd\u4f53\u5728\u505a\u51b3\u7b56\u65f6\u8981\u540c\u65f6\u8003\u8651\u5f53\u524d\u7684\u72b6\u6001\u4ee5\u53ca\u52a8\u4f5c\u7a7a\u95f4\uff0c\u667a\u80fd\u4f53\u89e3\u7a7a\u95f4\u7684\u7ef4\u5ea6\u7531\u72b6\u6001\u7a7a\u95f4\u7ef4\u5ea6\u548c\u52a8\u4f5c\u7a7a\u95f4\u7ef4\u5ea6\u5171\u540c\u51b3\u5b9a\uff0c\u56e0\u6b64\u53ef\u4ee5\u901a\u8fc7\u5bf9\u72b6\u6001\u7a7a\u95f4\u8fdb\u884c\u9002\u5ea6\u79bb\u6563\u5316\u6765\u8fbe\u5230\u538b\u7f29\u89e3\u7a7a\u95f4\u7684\u76ee\u7684\u3002\u4ee5\u7a7a\u95f4\u7f16\u7801\u4e3a\u4f8b\uff0c\u5e38\u89c4\u505a\u6cd5\u5c31\u662f\u5c06\u539f\u59cb\u72b6\u6001\u4fe1\u606f\u4e0b\u91c7\u6837\uff0c\u5f97\u5230\u4e00\u7ec4\u7f51\u683c\u70b9\uff0c\u867d\u7136\u4f1a\u635f\u5931\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u7684\u611f\u77e5\u7cbe\u5ea6\uff0c\u4f46\u662f\u53ea\u8981\u628a\u63e1\u597d\u79bb\u6563\u7684\u7c92\u5ea6\uff0c\u4e0d\u4e22\u5931\u5173\u952e\u4fe1\u606f\uff0c\u5e76\u4e14\u4e0e\u52a8\u4f5c\u7a7a\u95f4\u4fdd\u6301\u5c3a\u5ea6\u4e00\u81f4\uff0c\u6240\u5e26\u6765\u7684\u6536\u76ca\u4e5f\u662f\u4f1a\u5f25\u8865\u635f\u5931\u7684\u3002</p>"},{"location":"RL/landing_guide/#_12","title":"\u6548\u679c\u9a8c\u8bc1","text":"<p>\u2003\u2003\u5e38\u7528\u4e8e\u72b6\u6001\u7a7a\u95f4\u9a8c\u8bc1\u7684\u65b9\u5f0f\u4e3b\u8981\u5305\u62ec\uff1a\u76f4\u63a5\u9a8c\u8bc1\u3001\u7f3a\u7701\u9a8c\u8bc1\u4ee5\u53ca\u6a21\u4eff\u5b66\u4e60\u9a8c\u8bc1\u3002</p> <p>\u76f4\u63a5\u9a8c\u8bc1</p> <p>\u2003\u2003\u76f4\u63a5\u5206\u6790\u7b97\u6cd5\u7684\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u53ef\u4ee5\u901a\u8fc7\u6bd4\u8f83\u4e2d\u9014\u67d0\u4e2a\u8282\u70b9\uff08\u6709\u98ce\u9669\uff0c\u8fed\u4ee3\u7684\u5feb\u4e0d\u4e00\u5b9a\u4ee3\u8868\u6700\u7ec8\u6548\u679c\u597d\uff09\u6216\u8005\u5b8c\u5168\u6536\u655b\u540e\u7684\u6027\u80fd\u3002</p> <p>\u7f3a\u7701\u9a8c\u8bc1</p> <p>\u2003\u2003\u5b9e\u8df5\u4e2dDRL\u7b97\u6cd5\u7684\u8bad\u7ec3\u5468\u671f\u53ef\u80fd\u4f1a\u5f88\u957f\uff0c\u76f4\u63a5\u505a\u5b9e\u9a8c\u6765\u9a8c\u8bc1\u72b6\u6001\u7a7a\u95f4\u4e2d\u6bcf\u4e2a\u4fe1\u606f\u7684\u6709\u6548\u6027\u4e0d\u5408\u9002\uff0c\u6210\u672c\u6bd4\u8f83\u5927\u3002\u5bf9\u6b64\uff0c\u53ef\u4ee5\u5229\u7528\u8bad\u7ec3\u597d\u7684\u7b56\u7565\uff0c\u901a\u8fc7\u51bb\u7ed3\u8f93\u5165\u72b6\u6001\u4e2d\u7684\u67d0\u4e2a\u4fe1\u606f\uff0c\u6bd4\u5982\u5c06\u5176\u56fa\u5b9a\u4e3a\u5408\u7406\u533a\u95f4\u5185\u7684\u67d0\u4e2a\u6570\u503c\uff0c\u4e4b\u540e\u89c2\u5bdf\u5176\u6027\u80fd\u76f8\u5bf9\u4e8e\u57fa\u7ebf\u7b56\u7565\u7684\u635f\u5931\uff0c\u6027\u80fd\u635f\u5931\u8d8a\u5927\uff0c\u8bf4\u660e\u76f8\u5e94\u72b6\u6001\u4fe1\u606f\u5728\u751f\u6210\u51b3\u7b56\u7684\u8fc7\u7a0b\u4e2d\u4f5c\u7528\u8d8a\u5173\u952e\uff0c\u53cd\u4e4b\u8bf4\u660e\u4f5c\u7528\u8d8a\u8fb9\u7f18\u5316\uff0c\u5982\u679c\u6027\u80fd\u4e0d\u964d\u53cd\u5347\uff0c\u8bf4\u660e\u88ab\u51bb\u4f4f\u7684\u72b6\u6001\u4fe1\u606f\u5bf9\u51b3\u7b56\u6709\u5e72\u6270\u4f5c\u7528\uff0c\u6709\u53ef\u80fd\u5f15\u5165\u7684\u8be5\u4fe1\u606f\u566a\u58f0\u8fc7\u5927\u6216\u8005\u53d1\u751f\u5f02\u5e38\u3002\u7f3a\u7701\u9a8c\u8bc1\u53ea\u9002\u7528\u4e8e\u5df2\u7ecf\u6210\u529f\u6536\u655b\u7684DRL\u6a21\u578b\uff0c\u5176\u610f\u4e49\u7528\u4e8e\u5254\u9664\u72b6\u6001\u7a7a\u95f4\u4e2d\u90a3\u4e9b\u4e0d\u8d77\u4f5c\u7528\u6216\u8005\u8d77\u8d1f\u4f5c\u7528\u7684\u72b6\u6001\u4fe1\u606f\uff0c\u5e76\u4e3a\u8fdb\u4e00\u6b65\u4f18\u5316\u5173\u952e\u72b6\u6001\u4fe1\u606f\u548c\u5f31\u4f5c\u7528\u72b6\u6001\u4fe1\u606f\u63d0\u4f9b\u6307\u5bfc\u3002</p> <p>\u6a21\u4eff\u5b66\u4e60\u9a8c\u8bc1</p> <p>\u2003\u2003\u5982\u679c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u63d0\u4f9b\u4e00\u4e2a\u201c\u4e13\u5bb6\u7b56\u7565\u201d\uff0c\u5373\u5bf9\u4e8e\u667a\u80fd\u4f53\u6765\u8bf4\u4e13\u5bb6\u7b56\u7565\u5728\u5f53\u524d\u72b6\u6001\u4e0b\u91c7\u53d6\u7684\u52a8\u4f5c\u662f\u7edd\u5bf9\u6b63\u786e\u7684\uff0c\u5e76\u4e14\u72b6\u6001\u7a7a\u95f4\u4e2d\u5305\u542b\u4e86\u4e13\u5bb6\u51b3\u7b56\u6240\u9700\u8981\u7684\u5168\u90e8\u4fe1\u606f\uff0c\u90a3\u4e48\u7ecf\u8fc7\u5145\u5206\u8bad\u7ec3\u540e\u6a21\u578b\u5e94\u8be5\u80fd\u591f\u7cbe\u786e\u6a21\u4eff\u4e13\u5bb6\u7b56\u7565\u5e76\u4e14\u8fbe\u5230\u540e\u8005\u7684\u6027\u80fd\uff0c\u800c\u6a21\u578b\u8f93\u51fa\u4e0e\u4e13\u5bb6\u7b56\u7565\u7684\u5dee\u5f02\u53ef\u4ee5\u4f5c\u4e3a\u8861\u91cf\u72b6\u6001\u7a7a\u95f4\u8bbe\u8ba1\u8d28\u91cf\u7684\u4e00\u79cd\u53c2\u8003\u6807\u51c6\u3002</p>"},{"location":"RL/landing_guide/#_13","title":"\u56de\u62a5\u51fd\u6570\u7684\u8bbe\u8ba1","text":"<p>\u2003\u2003\u5728\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\u4e2d\uff0c\u667a\u80fd\u4f53\u6839\u636e\u63a2\u7d22\u8fc7\u7a0b\u4e2d\u6765\u81ea\u73af\u5883\u7684\u53cd\u9988\u4fe1\u53f7\u6301\u7eed\u6539\u8fdb\u7b56\u7565\uff0c\u8fd9\u4e9b\u53cd\u9988\u4fe1\u53f7\u88ab\u79f0\u4e3a\u56de\u62a5\u3002\u4f5c\u4e3a\u4efb\u52a1\u76ee\u6807\u7684\u5177\u4f53\u5316\u548c\u6570\u503c\u5316\uff0c\u56de\u62a5\u4fe1\u53f7\u8d77\u5230\u4e86\u4eba\u4e0e\u7b97\u6cd5\u6c9f\u901a\u7684\u6865\u6881\u4f5c\u7528\uff0c\u60f3\u8981\u667a\u80fd\u4f53\u5b9e\u73b0\u4ec0\u4e48\u6837\u7684\u76ee\u7684\uff0c\u5c31\u5e94\u5f53\u6709\u4ec0\u4e48\u6837\u7684\u56de\u62a5\u4fe1\u53f7\u53bb\u5f15\u5bfc\u4ed6\u5b66\u4e60\uff0c\u56de\u62a5\u4fe1\u53f7\u7531\u56de\u62a5\u51fd\u6570\u751f\u6210\uff0c\u56e0\u6b64\u6211\u4eec\u9700\u8981\u505a\u7684\u5c31\u662f\u5c06\u4efb\u52a1\u7684\u671f\u671b\u548c\u76ee\u6807\u201c\u7ffb\u8bd1\u201d\u6210\u56de\u62a5\u51fd\u6570\uff0c\u5e76\u4e14\u7531\u56de\u62a5\u51fd\u6570\u53bb\u5f15\u5bfc\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u7684\u8bad\u7ec3\u3002\u5f3a\u5316\u5b66\u4e60\u7684\u672c\u8d28\u5c31\u662f\u56de\u62a5\u51fd\u6570\u5f15\u5bfc\u4e0b\u7684\u795e\u7ecf\u7f51\u7edc\u5bf9\u8f93\u5165\u72b6\u6001\u4fe1\u606f\u7684\u7279\u5f81\u6df1\u52a0\u5de5\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u6df1\u5c42\u7279\u5f81\u4e0e\u503c\u4f30\u8ba1\u548c\u51b3\u7b56\u76f8\u5173\u6027\u7684\u5efa\u7acb\u8fc7\u7a0b\u3002</p>"},{"location":"RL/landing_guide/#_14","title":"\u7a00\u758f\u56de\u62a5\u95ee\u9898","text":"<p>\u2003\u2003\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\u7684\u76ee\u6807\u901a\u5e38\u53ef\u4ee5\u5206\u4e3a\u4e24\u7c7b\uff1a\u4e00\u7c7b\u662f\u5b9a\u6027\u76ee\u6807\u7684\u8fbe\u6210\uff0c\u6bd4\u5982\u4e8c\u7ef4\u5e73\u9762\u5bfc\u822a\u4efb\u52a1\u4e2d\u667a\u80fd\u4f53\u62b5\u8fbe\u7ec8\u70b9\u3001\u4e0b\u68cb\u83b7\u80dc\u7b49\u7b49\uff1b\u53e6\u4e00\u7c7b\u662f\u5b9a\u91cf\u76ee\u6807\u7684\u6781\u503c\u5316\uff0c\u6bd4\u5982\u6700\u5927\u5316\u6295\u8d44\u6536\u76ca\u3001\u6700\u5c0f\u5316\u7535\u80fd\u635f\u8017\u7b49\u7b49\u3002\u672c\u6587\u5c06\u4e0a\u8ff0\u76ee\u6807\u7684\u6539\u5584\u7edf\u79f0\u4e3a\u4efb\u52a1\u7684\u4e3b\u7ebf\u4e8b\u4ef6\uff0c\u5bf9\u5e94\u4f1a\u6709\u4e3b\u7ebf\u56de\u62a5\u3002\u4e3b\u7ebf\u4e8b\u4ef6\u6240\u5bf9\u5e94\u7684\u6837\u672c\u901a\u5e38\u88ab\u79f0\u4e3a\u6b63\u6837\u672c\uff0c\u5bf9\u5e94\u4f1a\u5f97\u5230\u6b63\u5411\u56de\u62a5\uff0c\u5176\u4f59\u7684\u5219\u88ab\u79f0\u4e3a\u8d1f\u6837\u672c\uff0c\u5bf9\u5e94\u4f1a\u5f97\u5230\u8d1f\u5411\u56de\u62a5\u3002\u5bf9\u4e8e\u8bb8\u591a\u4efb\u52a1\u6765\u8bf4\uff0c\u667a\u80fd\u4f53\u5728\u73af\u5883\u4e2d\u8fdb\u884c\u968f\u673a\u63a2\u7d22\u5c31\u80fd\u4ee5\u4e00\u5b9a\u6982\u7387\u9047\u5230\u4e3b\u7ebf\u4e8b\u4ef6\uff0c\u4ece\u800c\u83b7\u5f97\u6b63\u5411\u6536\u76ca\uff0c\u4f46\u662f\u968f\u7740\u4efb\u52a1\u590d\u6742\u5ea6\u7684\u63d0\u5347\uff0c\u901a\u8fc7\u968f\u673a\u65b9\u5f0f\u53bb\u63a2\u7d22\u5230\u4e3b\u7ebf\u4e8b\u4ef6\u7684\u6982\u7387\u4f1a\u53d8\u5f97\u5f88\u5c0f\uff0c\u91c7\u5f97\u7684\u6837\u672c\u4f1a\u6709\u4e25\u91cd\u7684\u6b63\u8d1f\u6bd4\u4f8b\u4e0d\u5747\u8861\u95ee\u9898\uff0c\u5373\u8d1f\u6837\u672c\u8fdc\u5927\u4e8e\u6b63\u6837\u672c\uff0c\u7a00\u7f3a\u7684\u53cd\u9988\u4fe1\u53f7\u65e0\u6cd5\u4e3a\u667a\u80fd\u4f53\u6307\u660e\u6b63\u786e\u7684\u63a2\u7d22\u65b9\u5411\uff0c\u4f1a\u5bfc\u81f4\u7b97\u6cd5\u6536\u655b\u5f88\u6162\uff0c\u751a\u81f3\u4e0d\u6536\u655b\u3002\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u8fd9\u79cd\u56e0\u7f3a\u4e4f\u53cd\u9988\u4fe1\u53f7\u9020\u6210\u5b66\u4e60\u56f0\u96be\u7684\u73b0\u8c61\u88ab\u79f0\u4e3a\u7a00\u758f\u56de\u62a5\u95ee\u9898\u3002</p> <p>\u7a00\u758f\u56de\u62a5\u95ee\u9898\u7684\u672c\u8d28</p> <p>\u2003\u2003\u4e3e\u4f8b\u6765\u8bf4\uff0c\u5047\u8bbe\u73b0\u5728\u6709\u4e00\u4e2a\u4efb\u52a1\uff0c\u60f3\u8981\u8ba9\u5de6\u4fa7\u7684\u667a\u80fd\u4f53\u8d70\u5230\u6700\u53f3\u4fa7\uff0c\u5e76\u4e14\u667a\u80fd\u4f53\u53ea\u80fd\u9009\u62e9\u5411\u5de6\u3001\u5411\u53f3\u6216\u8005\u505c\u7559\u539f\u5730\u8fd9\u4e09\u4e2a\u52a8\u4f5c\uff0c\u8d70\u5230\u6700\u53f3\u4fa7\u540e\u83b7\u5f97\u6b63\u5411\u56de\u62a5\uff0c\u6ca1\u6709\u5176\u4f59\u4efb\u4f55\u53cd\u9988\uff0c\u5982\u679c\u6b64\u65f6\u5de6\u53f3\u76f8\u8ddd\u5f88\u8fdc\u7684\u8bdd\uff0c\u4f9d\u9760\u7b49\u6982\u7387\u53bb\u63a2\u7d22\u83b7\u53d6\u6b63\u6837\u672c\u7684\u96be\u5ea6\u5f88\u9ad8\uff0c\u540c\u65f6\u4e2d\u95f4\u72b6\u6001\u4e0b\u53cd\u9988\u4fe1\u53f7\u7684\u7f3a\u5931\u4f7f\u667a\u80fd\u4f53\u96be\u4ee5\u201c\u53d1\u73b0\u201d\u53f3\u79fb\u76f8\u5bf9\u4e8e\u5de6\u79fb\u548c\u539f\u5730\u4e0d\u52a8\u7684\u4f18\u52bf\uff0c\u4e5f\u5c31\u65e0\u6cd5\u901a\u8fc7\u4e3b\u52a8\u589e\u52a0\u53f3\u79fb\u52a8\u4f5c\u6765\u89e6\u53d1\u66f4\u591a\u7684\u4e3b\u7ebf\u4e8b\u4ef6\u3002</p> <p>\u6ce8\uff1a\u6362\u53e5\u8bdd\u8bf4\uff0c\u6211\u4eec\u6240\u8bbe\u8ba1\u7684\u7b97\u6cd5\u5e94\u5f53\u5bf9\u4e2d\u95f4\u72b6\u6001\u90fd\u505a\u597d\u53cd\u9988\uff0c\u4ece\u800c\u5f15\u5bfc\u667a\u80fd\u4f53\u53bb\u89e6\u53d1\u4e3b\u7ebf\u4e8b\u4ef6\uff0c\u8fd9\u4e5f\u662f\u8f85\u52a9\u56de\u62a5\u7684\u601d\u60f3\u3002</p> <p>\u2003\u2003\u5f3a\u5316\u5b66\u4e60\u662f\u63a2\u7d22\u548c\u5229\u7528\u7684\u5e73\u8861\u8fc7\u7a0b\uff0c\u667a\u80fd\u4f53\u901a\u8fc7\u63a2\u7d22\u83b7\u5f97\u5173\u4e8e\u73af\u5883\u548c\u4efb\u52a1\u7684\u5c40\u90e8\u77e5\u8bc6\uff0c\u4e5f\u5c31\u662f\u5c11\u91cf\u6b65\u5e45\u5185\u7684\u77e5\u8bc6\uff0c\u540c\u65f6\u5229\u7528\u8fd9\u4e9b\u77e5\u8bc6\u8fdb\u884c\u66f4\u6709\u9488\u5bf9\u6027\u7684\u63a2\u7d22\u3002\u4ece\u8fd9\u4e2a\u89d2\u5ea6\u5206\u6790\uff0c\u8fc7\u4e8e\u7a00\u758f\u7684\u73af\u5883\u53cd\u9988\u4fe1\u53f7\u4e0d\u5229\u4e8e\u5f62\u6210\u5c40\u90e8\u77e5\u8bc6\u5e76\u4e3a\u63a2\u7d22\u65b9\u5411\u63d0\u4f9b\u6307\u5bfc\uff0c\u800c\u76f2\u76ee\u7684\u63a2\u7d22\u5bfc\u81f4\u6b63\u6837\u672c\u65e0\u6cd5\u51fa\u73b0\u6216\u8005\u6570\u91cf\u6781\u5c11\uff0c\u63a2\u7d22\u548c\u5229\u7528\u7684\u4e25\u91cd\u5931\u8861\u9020\u6210\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u6536\u655b\u56f0\u96be\u3002</p>"},{"location":"RL/landing_guide/#_15","title":"\u8f85\u52a9\u56de\u62a5","text":"<p>\u2003\u2003\u4e3a\u4e86\u514b\u670d\u7a00\u758f\u56de\u62a5\u95ee\u9898\uff0c\u9700\u8981\u5728\u4e3b\u7ebf\u56de\u62a5\u7684\u57fa\u7840\u4e0a\u589e\u52a0\u5176\u4ed6\u5956\u52b1\u9879\u6216\u60e9\u7f5a\u9879\uff0c\u4f7f\u56de\u62a5\u51fd\u6570\u53d8\u5f97\u7a20\u5bc6\u7684\u540c\u65f6\u5f15\u5bfc\u667a\u80fd\u4f53\u5728\u73af\u5883\u4e2d\u66f4\u52a0\u9ad8\u6548\u5730\u63a2\u7d22\uff0c\u4ece\u800c\u52a0\u5febDRL\u7b97\u6cd5\u7684\u6536\u655b\u901f\u5ea6\u5e76\u63d0\u5347\u7b97\u6cd5\u6027\u80fd\uff0c\u8fd9\u4e9b\u4e3b\u7ebf\u56de\u62a5\u4ee5\u5916\u7684\u989d\u5916\u56de\u62a5\u88ab\u79f0\u4e3a\u8f85\u52a9\u56de\u62a5\u3002\u5728\u5b9e\u8df5\u4e2d\u5e38\u7528\u7684\u8f85\u52a9\u56de\u62a5\u5305\u62ec\u4e09\u7c7b\uff1a\u5b50\u76ee\u6807\u56de\u62a5\u3001\u5851\u5f62\u56de\u62a5\u548c\u5185\u9a71\u56de\u62a5\u3002</p>"},{"location":"RL/landing_guide/#_16","title":"\u5b50\u76ee\u6807\u56de\u62a5","text":"<p>\u8d21\u732e\u5ea6\u5206\u914d</p> <p>\u2003\u2003\u5b50\u76ee\u6807\u56de\u62a5\u662f\u8f85\u52a9\u56de\u62a5\u7684\u4e3b\u8981\u5f62\u5f0f\uff0c\u4e3b\u8981\u7b56\u7565\u5c31\u662f\u5c06\u4efb\u52a1\u76ee\u6807\u8fdb\u4e00\u6b65\u5206\u89e3\u4e3a\u5b50\u76ee\u6807\uff0c\u4e4b\u540e\u6309\u7167\u5404\u81ea\u5728\u4fc3\u8fdb\u4e3b\u7ebf\u4e8b\u4ef6\u5b9e\u73b0\u8fc7\u7a0b\u4e2d\u7684\u8d21\u732e\u5927\u5c0f\u548c\u4f5c\u7528\u65b9\u5411\u5206\u522b\u7ed9\u4e88\u6070\u5f53\u7684\u5956\u52b1\u6216\u60e9\u7f5a\uff0c\u8fd9\u88ab\u79f0\u4e3a\u8d21\u732e\u5ea6\u5206\u914d\u3002\u5728\u7406\u60f3\u60c5\u51b5\u4e0b\uff0c\u8d21\u732e\u5ea6\u5206\u914d\u5e94\u8be5\u7531DRL\u7b97\u6cd5\u5728\u4e3b\u7ebf\u56de\u62a5\u7684\u5f15\u5bfc\u4e0b\u81ea\u52a8\u5b8c\u6210\uff0c\u5728\u4e0a\u4e2a\u4ece\u5de6\u5f80\u53f3\u8d70\u7684\u6848\u4f8b\u4e2d\uff0c\u7406\u60f3\u60c5\u51b5\u4e0b\u7b97\u6cd5\u662f\u53ef\u4ee5\u53ea\u901a\u8fc7\u4e3b\u7ebf\u56de\u62a5\u53bb\u5b66\u5230\u5411\u53f3\u8d70\u8fd9\u4e00\u7b56\u7565\u8981\u6bd4\u5411\u5de6\u8d70\u548c\u505c\u7559\u539f\u5730\u4e0d\u540c\u66f4\u6709\u4f18\u52bf\uff0c\u4f46\u7531\u4e8e\u7a00\u758f\u56de\u62a5\u95ee\u9898\u7684\u5b58\u5728\uff0c\u8fd9\u4e00\u5c40\u90e8\u76f8\u5173\u6027\u96be\u4ee5\u5efa\u7acb\u3002\u5b50\u76ee\u6807\u56de\u62a5\u8bbe\u8ba1\u76f8\u5f53\u4e8e\u7528\u4eba\u5de5\u4ee3\u66ff\u7b97\u6cd5\u53bb\u5b9e\u73b0\u8d21\u732e\u5ea6\u5206\u914d\u8fd9\u4e00\u8fc7\u7a0b\uff0c\u4ece\u800c\u514b\u670d\u7a00\u758f\u56de\u62a5\u95ee\u9898\uff0cDRL\u7b97\u6cd5\u5229\u7528\u8f85\u52a9\u56de\u62a5\u9996\u5148\u5b66\u4f1a\u5b8c\u6210\u5b50\u76ee\u6807\uff0c\u7136\u540e\u5728\u6b64\u57fa\u7840\u4e0a\u5c31\u80fd\u4ee5\u66f4\u5927\u7684\u6982\u7387\u63a2\u7d22\u5230\u4e3b\u7ebf\u4e8b\u4ef6\uff0c\u6700\u540e\u5728\u4e3b\u7ebf\u56de\u62a5\u548c\u8f85\u52a9\u56de\u62a5\u7684\u5171\u540c\u5f15\u5bfc\u4e0b\u5b66\u4f1a\u671f\u671b\u7684\u6280\u80fd\u3002</p> <p>\u2003\u2003\u8d21\u732e\u5ea6\u5206\u914d\u548c\u5b50\u76ee\u6807\u56de\u62a5\u90fd\u5efa\u7acb\u5728\u5bf9\u4efb\u52a1\u903b\u8f91\u7684\u6df1\u5165\u5206\u6790\u548c\u7406\u89e3\u4e4b\u4e0a\uff0c\u6bcf\u4e2a\u5177\u4f53\u4efb\u52a1\u90fd\u5b58\u5728\u5404\u79cd\u7ec6\u8282\uff0c\u4ed6\u4eec\u53ef\u80fd\u5bf9\u6700\u7ec8\u76ee\u6807\u7684\u5b9e\u73b0\u4ea7\u751f\u6b63\u5411\u6216\u8005\u8d1f\u5411\u7684\u5f71\u54cd\u3002\u4ece\u4efb\u52a1\u76ee\u6807\u51fa\u53d1\u53cd\u5411\u56de\u6eaf\uff0c\u5e76\u6316\u6398\u51fa\u6784\u6210\u76ee\u6807\u8fbe\u6210\u7684\u5145\u5206\u6216\u5fc5\u8981\u6761\u4ef6\u7684\u5173\u952e\u56e0\u7d20\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u56e0\u7d20\u662f\u5426\u8fd8\u6709\u5404\u81ea\u7684\u5145\u5206\u6216\u5fc5\u8981\u6761\u4ef6\uff0c\u8fd9\u4e9b\u4e2d\u95f4\u8282\u70b9\u90fd\u53ef\u4ee5\u4f5c\u4e3a\u5b50\u76ee\u6807\uff0c\u5e76\u4e3a\u4e4b\u8bbe\u8ba1\u5bf9\u5e94\u7684\u8f85\u52a9\u56de\u62a5\u3002</p> <p>\u76ee\u6807\u5206\u89e3\u5b9e\u4f8b</p> <p>\u2003\u2003\u603b\u4f53\u4e0a\uff0c\u5b50\u76ee\u6807\u5206\u4e3a\u9f13\u52b1\u548c\u89c4\u907f\u4e24\u5927\u7c7b\uff0c\u5206\u522b\u4ee3\u8868\u201c\u5e94\u8be5\u505a\u4ec0\u4e48\u201d\u548c\u201c\u4e0d\u5e94\u8be5\u505a\u4ec0\u4e48\u201d\uff0c\u56de\u5230\u4e8c\u7ef4\u5e73\u9762\u5bfc\u822a\u4efb\u52a1\u4e2d\uff0c\u4e3a\u4e86\u5b8c\u6210\u4efb\u52a1\u76ee\u6807\uff0c\u667a\u80fd\u4f53\u9700\u8981\u5b9e\u73b0\u4e09\u4e2a\u663e\u800c\u6613\u89c1\u7684\u5b50\u76ee\u6807\uff0c\u5373\u62b5\u8fbe\u7ec8\u70b9\u3001\u89c4\u907f\u78b0\u649e\u548c\u9632\u6b62\u7535\u91cf\u8fc7\u4f4e\uff0c\u5176\u4e2d\u7b2c\u4e00\u4e2a\u662f\u9f13\u52b1\u7c7b\u5b50\u76ee\u6807\u3001\u540e\u4e24\u4e2a\u5c5e\u4e8e\u89c4\u907f\u7c7b\u5b50\u76ee\u6807\u3002</p> <p>\u2003\u2003\u56f4\u7ed5\u62b5\u8fbe\u7ec8\u70b9\u8fd9\u4e00\u5b50\u76ee\u6807\u8fd8\u53ef\u4ee5\u8fdb\u4e00\u6b65\u8bbe\u8ba1\u5176\u4ed6\u6b21\u4e00\u7ea7\u7684\u5b50\u76ee\u6807\u3002\u4f8b\u5982\u9f13\u52b1\u5b50\u76ee\u6807\u201c\u5f53\u524d\u65f6\u523b\u4f4d\u7f6e\u5e94\u8be5\u6bd4\u4e0a\u4e00\u65f6\u523b\u66f4\u9760\u8fd1\u7ec8\u70b9\u201d\u548c\u89c4\u907f\u7c7b\u5b50\u76ee\u6807\u201c\u51cf\u5c11\u8f6c\u5f2f\u201d\uff0c\u524d\u8005\u4fc3\u8fdb\u667a\u80fd\u4f53\u5b66\u4f1a\u4e3b\u52a8\u9760\u8fd1\u7ec8\u70b9\uff0c\u8fd9\u6709\u52a9\u4e8e\u5728\u540e\u7eed\u63a2\u7d22\u4e2d\u4ee5\u66f4\u5927\u7684\u6982\u7387\u9047\u5230\u4e3b\u7ebf\u4e8b\u4ef6\u548c\u6b63\u6837\u672c\uff1b\u540e\u8005\u6293\u4f4f\u7ed5\u8def\u884c\u4e3a\u7684\u5178\u578b\u8868\u73b0\u2014\u2014\u8f6c\u5f2f\u591a\uff0c\u901a\u8fc7\u60e9\u7f5a\u8f6c\u5f2f\u884c\u4e3a\u4ece\u800c\u8d77\u5230\u51cf\u5c11\u7ed5\u8def\u7684\u6548\u679c\uff0c\u4ece\u800c\u8fbe\u5230\u9ad8\u6548\u5730\u62b5\u8fbe\u7ec8\u70b9\u7684\u76ee\u6807\u3002</p> <p>\u6ce8\uff1a\u5373\u4f7f\u9762\u5bf9\u4e00\u4e2a\u9f13\u52b1\u7c7b\u76ee\u6807\uff0c\u4e5f\u53ef\u4ee5\u5c06\u5176\u518d\u7ec6\u5206\u4e3a\u9f13\u52b1\u7c7b\u548c\u89c4\u907f\u7c7b\u5b50\u76ee\u6807\uff0c\u6838\u5fc3\u59cb\u7ec8\u56f4\u7ed5\u7740\u7236\u7c7b\u76ee\u6807\u800c\u8bbe\u5b9a\u3002</p> <p>\u2003\u2003\u5bf9\u4e8e\u907f\u514d\u78b0\u649e\u548c\u9632\u6b62\u7535\u91cf\u8fc7\u4f4e\u8fd9\u4e24\u4e2a\u89c4\u907f\u7c7b\u5b50\u76ee\u6807\uff0c\u5e94\u8be5\u5bf9\u76f8\u5173\u72b6\u6001\uff08\u78b0\u649e\u548c\u4f4e\u7535\u91cf\uff09\u8fdb\u884c\u60e9\u7f5a\uff0c\u4e3a\u4e86\u964d\u4f4e\u5b66\u4e60\u96be\u5ea6\uff0c\u4ee5\u4e0a\u4e24\u4e2a\u5b50\u76ee\u6807\u8fd8\u53ef\u4ee5\u7ee7\u7eed\u5206\u89e3\uff1a\u907f\u514d\u78b0\u649e\u7684\u6700\u597d\u65b9\u5f0f\u5c31\u662f\u4e0e\u969c\u788d\u7269\u4fdd\u6301\u4e00\u5b9a\u7684\u5b89\u5168\u8ddd\u79bb\uff0c\u5f53\u667a\u80fd\u4f53\u4e0e\u6700\u8fd1\u969c\u788d\u7269\u7684\u95f4\u8ddd\u5c0f\u4e8e\u8be5\u8ddd\u79bb\u65f6\u5c31\u65bd\u52a0\u60e9\u7f5a\u9879\uff1b\u540c\u7406\uff0c\u5728\u5f53\u524d\u7535\u91cf\u4e0b\u964d\u81f3\u5145\u7535\u9884\u8b66\u7535\u91cf\u6216\u66f4\u4f4e\u65f6\u4e5f\u5e94\u5f53\u57fa\u4e8e\u60e9\u7f5a\u3002</p> <p>\u2003\u2003\u8fde\u7eed\u60e9\u7f5a/\u5956\u52b1\u7684\u6548\u679c\u901a\u5e38\u8981\u4f18\u4e8e\u4e00\u6b21\u6027\u60e9\u7f5a/\u5956\u52b1\u7684\u6548\u679c\uff0c\u56e0\u4e3a\u8fde\u7eed\u60e9\u7f5a/\u5956\u52b1\u662f\u4e00\u79cd\u53ca\u65f6\u53cd\u9988\u7b56\u7565\uff0c\u4e0e\u72b6\u6001\u4fe1\u606f\u76f4\u63a5\u76f8\u5173\uff0c\u6709\u5229\u4e8e\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u5bf9\u6709\u6548\u7279\u5f81\u7684\u63d0\u53d6\uff0c\u5f15\u5bfc\u4f5c\u7528\u66f4\u5f3a\uff1b\u800c\u4e00\u6b21\u6027\u7684\u60e9\u7f5a/\u5956\u52b1\u5177\u6709\u6ede\u540e\u6548\u5e94\uff0c\u53ea\u80fd\u505a\u5230\u95f4\u63a5\u76f8\u5173\uff0c\u5f15\u5bfc\u4f5c\u7528\u8f83\u5dee\u3002\u5728\u5b9e\u8df5\u4e2d\uff0c\u5982\u679c\u89c4\u907f/\u9f13\u52b1\u72b6\u6001\u6301\u7eed\u5b58\u5728\uff08\u5982\u4f4e\u7535\u91cf\uff09\uff0c\u5219\u6bcf\u4e00\u6b65\u7ed9\u4e88\u4e00\u6b21\u53cd\u9988\u5373\u53ef\uff1b\u82e5\u89c4\u907f/\u9f13\u52b1\u72b6\u6001\u53ea\u5728\u77ac\u95f4\u53d1\u751f\uff0c\u4ee5\u89c4\u907f\u4e3a\u4f8b\uff08\u5982\u78b0\u649e\uff09\uff0c\u5219\u53ef\u4ee5\u7ad9\u5728\u9884\u9632\u89d2\u5ea6\u5b9a\u4e49\u5b89\u5168\u8fb9\u754c\uff0c\u5e76\u5728\u667a\u80fd\u4f53\u8d8a\u754c\u540e\u5f00\u59cb\u8fde\u7eed\u60e9\u7f5a\uff0c\u9f13\u52b1\u72b6\u6001\u540c\u7406\u3002</p> <p>\u4e0e\u72b6\u6001\u7a7a\u95f4\u7684\u534f\u540c\u8bbe\u8ba1</p> <p>\u2003\u2003\u72b6\u6001\u7a7a\u95f4\u4e0e\u56de\u62a5\u51fd\u6570\u4e4b\u95f4\u7684\u8bbe\u8ba1\u662f\u7d27\u5bc6\u8054\u7cfb\u7684\uff0c\u53ef\u4ee5\u4ece\u8ba4\u77e5\u548c\u5b9e\u8df5\u5c42\u9762\u533a\u5206\u4e24\u4e2a\u6982\u5ff5\uff0c\u5c06\u4efb\u52a1\u76ee\u6807\u5206\u89e3\u4e3a\u5b50\u76ee\u6807\u7684\u540c\u65f6\uff0c\u968f\u65f6\u601d\u8003\u8fbe\u6210\u6bcf\u4e2a\u5b50\u76ee\u6807\u90fd\u9700\u8981\u54ea\u4e9b\u4fe1\u606f\u4f5c\u4e3a\u4f9d\u636e\uff0c\u4ee5\u53ca\u54ea\u4e9b\u4fe1\u606f\u80fd\u591f\u53cd\u6620\u5b50\u76ee\u6807\u8fbe\u6210\u524d\u540e\u7684\u53d8\u5316\u3002</p> <p>\u2003\u2003\u5728\u4e8c\u7ef4\u5e73\u9762\u6848\u4f8b\u4e2d\uff0c\u60f3\u8981\u9632\u6b62\u7535\u91cf\u8fc7\u4f4e\uff0c\u5c31\u9700\u8981\u77e5\u9053\u5f53\u524d\u5269\u4f59\u7535\u91cf\u662f\u591a\u5c11\uff0c\u4e3a\u4e86\u907f\u514d\u78b0\u649e\uff0c\u5c31\u5fc5\u987b\u77e5\u9053\u5f53\u524d\u4f4d\u7f6e\u548c\u5468\u56f4\u969c\u788d\u7269\u7684\u5206\u5e03\u60c5\u51b5\uff1b\u5982\u679c\u667a\u80fd\u4f53\u8f6c\u4e86\u5f2f\uff0c\u5c31\u5e94\u8be5\u4f53\u73b0\u5728\u5176\u671d\u5411\u7684\u53d8\u5316\u4e0a\u3002\u4ed6\u4eec\u4f5c\u4e3a\u4e0e\u8f85\u52a9\u56de\u62a5\u76f4\u63a5\u6216\u95f4\u63a5\u76f8\u5173\u7684\u4fe1\u606f\uff0c\u975e\u5e38\u9002\u5408\u52a0\u5165\u72b6\u6001\u7a7a\u95f4\u3002\u4e8b\u5b9e\u4e0a\uff0c\u6bcf\u65b0\u589e\u4e00\u9879\u8f85\u52a9\u56de\u62a5\u90fd\u5e94\u8be5\u9a6c\u4e0a\u68c0\u67e5\u72b6\u6001\u7a7a\u95f4\u4e2d\u662f\u5426\u5df2\u7ecf\u5305\u542b\u4e86\u4e0e\u5176\u76f4\u63a5\u6216\u95f4\u63a5\u76f8\u5173\u7684\u4fe1\u606f\uff0c\u4ee5\u53ca\u8be5\u4fe1\u606f\u662f\u5426\u8db3\u591f\u9ad8\u6548\uff0c\u6709\u6ca1\u6709\u7ee7\u7eed\u6539\u8fdb\u7684\u7a7a\u95f4\uff0c\u8fd9\u5c31\u662f\u56de\u62a5\u51fd\u6570\u4e0e\u72b6\u6001\u7a7a\u95f4\u7684\u534f\u540c\u8bbe\u8ba1\uff0c\u4e8c\u8005\u76f8\u8f85\u76f8\u6210\u3002</p>"},{"location":"RL/landing_guide/#_17","title":"\u5851\u5f62\u56de\u62a5","text":"<p>\u57fa\u4e8e\u52bf\u80fd\u7684\u5851\u5f62\u56de\u62a5</p> <p>\u200b       \u524d\u4e00\u5c0f\u8282\u4ecb\u7ecd\u7684\u5b50\u76ee\u6807\u56de\u62a5\u662f\u9488\u5bf9\u7279\u5b9a\u4efb\u52a1\u8bbe\u8ba1\u7684\uff0c\u96be\u4ee5\u5728\u4e0d\u540c\u7c7b\u578b\u7684\u4efb\u52a1\u4e4b\u95f4\u8fdb\u884c\u63a8\u5e7f\u548c\u8fc1\u79fb\uff0c\u540c\u65f6\u57fa\u4e8e\u76ee\u6807\u5206\u89e3\u8bbe\u8ba1\u7684\u8f85\u52a9\u56de\u62a5\u867d\u7136\u6709\u6548\uff0c\u4f46\u662f\u7531\u4e8e\u6570\u91cf\u591a\u3001\u53d6\u503c\u968f\u610f\u6027\u5927\uff0c\u5728\u5b9e\u9645\u6548\u679c\u4e0a\u5bb9\u6613\u504f\u79bb\u4efb\u52a1\u521d\u8877\u800c\u53ea\u80fd\u5f97\u5230\u6b21\u4f18\u7b56\u7565\u3002\u9488\u5bf9\u8fd9\u4e00\u73b0\u8c61\uff0c\u5434\u6069\u8fbe\u63d0\u51fa\u4e86\u57fa\u4e8e\u52bf\u80fd\u7684\u56de\u62a5\u5851\u5f62\u6280\u672f\uff0c\u5728\u7ef4\u6301\u6700\u4f18\u7b56\u7565\u4e0d\u53d8\u6027\u7684\u524d\u63d0\u4e0b\u52a0\u901f\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u6536\u655b\uff0c\u5177\u4f53\u516c\u5f0f\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ \\overline r(s,a,s')=r(s,a,s')+\\gamma \\phi(s')-\\phi(s) $$  \u5728\u539f\u56de\u62a5\u51fd\u6570\u7684\u57fa\u7840\u4e0a\u589e\u52a0\u4e86\u4e00\u9879\u7279\u6b8a\u7684\u8f85\u52a9\u56de\u62a5\\gamma \\phi(s')-\\phi(s)\uff0c\u5176\u4e2d\\gamma\u4e3a\u6298\u6263\u56e0\u5b50\uff0c\\phi(s)\u4ee3\u8868\u67d0\u79cd\u5173\u4e8e\u72b6\u6001\u7684\u52bf\u80fd\u51fd\u6570\uff0c\u7528\u4e8e\u8861\u91cf\u5f53\u524d\u72b6\u6001\u4e0e\u76ee\u6807\u4e4b\u95f4\u7684\u8ddd\u79bb\uff08\u7c7b\u4f3c\u72b6\u6001\u4ef7\u503c\u51fd\u6570V(s)\uff09\uff0c\u8be5\u8f85\u52a9\u56de\u62a5\u5f62\u5f0f\u4e0e\u72b6\u6001\u5207\u6362\u6709\u5173\uff0c\u662f\u76f8\u90bb\u4e24\u4e2a\u72b6\u6001\u7684\u5dee\u503c\u3002\u7531\u4e8e\\phi(s)\u5728\u4efb\u4f55\u72b6\u6001\u4e0b\u90fd\u6709\u76f8\u5e94\u7684\u503c\uff0c\u539f\u6765\u7a00\u758f\u7684\u56de\u62a5\u51fd\u6570\u56e0\u4e3a\u5851\u5f62\u56de\u62a5\\gamma \\phi(s')-\\phi(s)\u7684\u5b58\u5728\u800c\u53d8\u5f97\u7a20\u5bc6\uff0c\u4ece\u800c\u8d77\u5230\u9ad8\u6548\u7684\u5f15\u5bfc\u4f5c\u7528\u3002</p> <p>\u6ce8\uff1a\u6211\u4eec\u60f3\u8981\u8bad\u7ec3\u7684\u662f\u667a\u80fd\u4f53\u7684\u51b3\u7b56\u529f\u80fd\uff0c\u800c\u8fd9\u91cc\u7684\u56de\u62a5\u90fd\u662f\u73af\u5883\u7ed9\u4e88\u7684\uff0c\u4e0e\u667a\u80fd\u4f53\u65e0\u5173\uff0c\u5373\u4f7fr(s,a,s')\u4e2d\u9700\u8981\u4f20\u5165\u52a8\u4f5ca\uff0c\u4f46\u8fd9\u4e00\u8fc7\u7a0b\u5bf9\u4e8e\u52a8\u4f5ca\u6765\u8bf4\u662f\u95f4\u65ad\u7684\uff0c\u56e0\u6b64\u5bfc\u6570\u5728\u4f20\u64ad\u7684\u65f6\u5019\uff0c\u53ea\u4f1a\u6cbf\u7740\u52a8\u4f5c\u4ea7\u751f\u7684\u8fc7\u7a0b\u56de\u4f20\uff0c\u4e5f\u5c31\u662f\u53ea\u6cbf\u7740\u51b3\u7b56\u51fd\u6570\u56de\u4f20\uff0c\u56de\u62a5\u53ea\u8d77\u5230\u8f85\u52a9\u7684\u4f5c\u7528\uff0c\u53ea\u9700\u8981\u63d0\u4f9b\u6570\u503c\u5373\u53ef\uff08\u4f8b\u5982\u5728\u57fa\u4e8e\u51b3\u7b56\u7684\u7b97\u6cd5\u4e2d\u7528\u4e8e\u52a0\u6743\uff09\uff0c\u56e0\u6b64\u8fd9\u91cc\u4e0d\u7528\u62c5\u5fc3\u201c\u5f15\u5165\u7684\u52bf\u80fd\u51fd\u6570\\phi(s)\u6ca1\u6709\u8f93\u5165\u52a8\u4f5ca\u800c\u65e0\u6cd5\u56de\u4f20\u68af\u5ea6\u201d\u7684\u95ee\u9898\uff0c\u8fd9\u91cc\u53ea\u6539\u53d8\u56de\u62a5\u7684\u6570\u503c\u5927\u5c0f\uff0c\u56de\u62a5\u5e76\u4e0d\u4f1a\u5355\u72ec\u4ea7\u751f\u4e00\u4e2a\u68af\u5ea6\u56de\u4f20\u5206\u652f\u3002</p> <p>\u200b       \u5bf9\u4e8e\u4e8c\u7ef4\u5e73\u9762\u5bfc\u822a\u4efb\u52a1\uff0c\u53ef\u4ee5\u9009\u62e9\u667a\u80fd\u4f53\u5f53\u524d\u4f4d\u7f6e\u4e0e\u7ec8\u70b9\u4e4b\u95f4\u8ddd\u79bb\u7684\u8d1f\u6570\u4f5c\u4e3a\u52bf\u80fd\u51fd\\phi(s)=-||p-g||\uff0c\u4ece\u800c\u4f7f\u7ec8\u70b9\u4f4d\u7f6e\u5728\u8be5\u52bf\u80fd\u51fd\u6570\u4e0b\u6210\u4e3a\u8679\u5438\u72b6\u6001\uff0c\u4e4b\u540e\u518d\u5c06\u4e4b\u524d\u7684\u9760\u8fd1\u7ec8\u70b9\u5956\u52b1r^n\u6539\u4e3a\uff1a $$ r^n=\\mu(||p_{t-1}-g||-\\gamma||p_t-g||) $$  \u6bcf\u5f53\u667a\u80fd\u4f53\u63a5\u8fd1\u7ec8\u70b9\u65f6\u5c31\u4f1a\u6536\u5230\u6b63\u5411\u5956\u52b1\uff0c\u800c\u8fdc\u79bb\u7ec8\u70b9\u65f6\u5219\u4f1a\u53d7\u5230\u8d1f\u5411\u60e9\u7f5a\uff0c\u8fd9\u79cd\u6709\u6b63\u6709\u8d1f\u7684\u53cc\u5411\u5956\u52b1\u8981\u6bd4\u4ec5\u9488\u5bf9\u9760\u8fd1\u7ec8\u70b9\u884c\u4e3a\u7684\u5355\u65b9\u9762\u6b63\u5956\u52b1\u6709\u66f4\u5f3a\u7684\u5f15\u5bfc\u4f5c\u7528\uff0c\u800c\u4e14\u8fd8\u80fd\u9632\u6b62\u667a\u80fd\u4f53\u5b66\u4f1a\u53cd\u590d\u9760\u8fd1\u3001\u8fdc\u79bb\u7ec8\u70b9\u6765\u8d5a\u53d6\u9ad8\u989d\u79ef\u7d2f\u6536\u76ca\u7684\u884c\u4e3a\u3002</p> <p>\u975e\u52bf\u80fd\u5851\u5f62\u56de\u62a5</p> <p>\u200b       \u5728\u5b9e\u8df5\u4e2d\uff0c\u8fd8\u7ecf\u5e38\u91c7\u7528\u4e00\u79cd\u9759\u6001\u7684\u5851\u5f62\u56de\u62a5\uff0c\u4e0e\u72b6\u6001\u5207\u6362\u65e0\u5173\uff0c\u76f4\u63a5\u5c06\u52bf\u80fd\u51fd\u6570\\phi(s)\u4f5c\u4e3a\u5851\u5f62\u56de\u62a5\uff0c\u968f\u7740\u667a\u80fd\u4f53\u79bb\u4e3b\u7ebf\u4efb\u52a1\u76ee\u6807\u8d8a\u6765\u8d8a\u8fd1\u65f6\uff0c\u5851\u5f62\u56de\u62a5\u4f1a\u8d8a\u6765\u8d8a\u5927\uff0c\u5e76\u4e14\u5728\u7ec8\u70b9\u4f4d\u7f6e\u8fbe\u5230\u6700\u5927\uff0c\u4ece\u800c\u5f15\u5bfc\u667a\u80fd\u4f53\u671d\u7740\u7ec8\u70b9\u65b9\u5411\u63a2\u7d22\u548c\u52a0\u901f\u7b97\u6cd5\u7684\u6536\u655b\u3002\u5728\u5b9e\u9645\u7684\u5e94\u7528\u4e2d\uff0c\u5982\u679c\u4f7f\u7528\u9759\u6001\u5851\u5f62\u56de\u62a5\uff0c\u5219\u6700\u597d\u91c7\u7528\u8d1f\u53cd\u9988\u5851\u5f62\u56de\u62a5\uff0c\u8feb\u4f7f\u667a\u80fd\u4f53\u4e3a\u4e86\u51cf\u5c11\u53d7\u5230\u7684\u60e9\u7f5a\u800c\u5c3d\u5feb\u5b8c\u6210\u76ee\u6807\u4efb\u52a1\uff0c\u56e0\u4e3a\u5982\u679c\u91c7\u7528\u6b63\u53cd\u9988\u5851\u5f62\u56de\u62a5\u7684\u8bdd\u5bb9\u6613\u9677\u5165\u201cbug\u201d\u4e2d\uff0c\u667a\u80fd\u4f53\u4f1a\u505c\u5728\u539f\u5730\u83b7\u5f97\u9ad8\u989d\u56de\u62a5\u3002</p> <p>\u200b       \u56de\u62a5\u5851\u5f62\u4e0d\u4ec5\u53ef\u4ee5\u5e94\u7528\u4e8e\u4e3b\u7ebf\u4e8b\u4ef6\u5bf9\u5e94\u7684\u76ee\u6807\uff0c\u4e5f\u540c\u6837\u53ef\u4ee5\u5e2e\u52a9\u5b50\u76ee\u6807\u7684\u5b66\u4e60\u3002\u4f8b\u5982\u4e4b\u524d\u7684\u4e8c\u7ef4\u5e73\u9762\u5bfc\u822a\u4efb\u52a1\u4e2d\uff0c\u907f\u514d\u78b0\u649e\u548c\u9632\u6b62\u7535\u91cf\u8fc7\u4f4e\u4e24\u4e2a\u5b50\u76ee\u6807\u6240\u5bf9\u5e94\u7684\u975e\u52bf\u80fd\u5851\u5f62\u56de\u62a5\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ r^c=-\\beta\\cdot\\max(D-d_{min},0)\\\\ r^e=-w\\cdot\\max(E-e_{left},0) $$  \u5728\u7a81\u7834\u4e86\u5b89\u5168\u8ddd\u79bbD\u548c\u5145\u7535\u9884\u8b66E\u4e4b\u540e\uff0c\u667a\u80fd\u4f53\u4e0e\u969c\u788d\u7269\u8ddd\u79bb\u8d8a\u8fd1\u3001\u5269\u4f59\u7535\u91cf\u8d8a\u4f4e\uff0c\u5176\u53d7\u5230\u7684\u60e9\u7f5a\u5c31\u8d8a\u5927\uff0c\u56e0\u6b64\u66f4\u5177\u6709\u5f15\u5bfc\u4f5c\u7528\u3002</p> <p>\u6ce8\uff1a\u5176\u5b9e\u5c31\u662f\u5c06\u56fa\u5b9a\u7684\u5956\u52b1/\u60e9\u7f5a\u8f6c\u53d8\u4e3a\u7ebf\u6027\u53d8\u5316\u7684\u5956\u52b1/\u60e9\u7f5a\uff0c\u5e76\u4e14\u53d8\u5316\u8303\u56f4\u8ddf\u72b6\u6001\u4fe1\u606f\u6709\u5173\u3002</p> <p>\u200b       \u5851\u5f62\u56de\u62a5\u4e0d\u4ec5\u662f\u7a20\u5bc6\u7684\uff0c\u800c\u4e14\u5929\u7136\u5b58\u5728\u4e0e\u4e4b\u5373\u65f6\u8054\u52a8\u7684\u72b6\u6001\u4fe1\u606f\u3002\u4f8b\u5982\u5728\u4e8c\u7ef4\u5e73\u9762\u5bfc\u822a\u4efb\u52a1\u4e2d\uff0c\u667a\u80fd\u4f53\u4e0e\u7ec8\u70b9\u4e4b\u95f4\u7684\u8ddd\u79bb||p-g||\u3001\u4e0e\u969c\u788d\u7269\u7684\u6700\u5c0f\u8ddd\u79bbd_{min}\u548c\u5f53\u524d\u5269\u4f59\u7535\u91cfe_{left}\u7b49\u7b49\uff0c\u4ed6\u4eec\u4e0d\u4ec5\u662f\u5404\u81ea\u5851\u5f62\u56de\u62a5\u7684\u76f4\u63a5\u76f8\u5173\u4fe1\u606f\uff0cd_{min}\u548ce_{left}\u66f4\u4e0e\u5851\u5f62\u56de\u62a5\u7684\u6e10\u8fdb\u5f0f\u53d8\u5316\u5448\u7ebf\u6027\u76f8\u5173\uff0c\u5341\u5206\u6709\u5229\u4e8eDRL\u7b97\u6cd5\u7684\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u4ece\u72b6\u6001\u4fe1\u606f\u4e2d\u9ad8\u6548\u5730\u63d0\u53d6\u7279\u5f81\uff0c\u5e76\u4e14\u51c6\u786e\u5730\u5efa\u7acb\u5176\u4e0e\u503c\u4f30\u8ba1\u548c\u6700\u4f18\u51b3\u7b56\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u3002</p> <p>\u6ce8\uff1a\u4e0e\u5b50\u76ee\u6807\u56de\u62a5\u4e00\u6837\uff0c\u5851\u5f62\u56de\u62a5\u7684\u8bbe\u8ba1\u540c\u6837\u5efa\u7acb\u5728\u5bf9\u4efb\u52a1\u903b\u8f91\u7684\u6df1\u5165\u7406\u89e3\u4e4b\u4e0a\uff0c\u5e76\u4e14\u9700\u8981\u7528\u5230\u9886\u57df\u77e5\u8bc6\uff0c\u5b9e\u9645\u60c5\u51b5\u4e2d\uff0c\u5e38\u5e38\u91c7\u6837\u5b50\u76ee\u6807\u56de\u62a5\u548c\u5851\u5f62\u56de\u62a5\u7ec4\u6210\u7684\u6df7\u5408\u8f85\u52a9\u56de\u62a5\u3002</p>"},{"location":"RL/landing_guide/#_18","title":"\u5185\u9a71\u56de\u62a5","text":"<p>\u200b       \u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\uff0c\u6211\u4eec\u9664\u4e86\u5e0c\u671b\u667a\u80fd\u4f53\u80fd\u591f\u672c\u80fd\u5730\u5bf9\u6765\u81ea\u5916\u90e8\u7684\u53cd\u9988\u4fe1\u53f7\u505a\u51fa\u8d8b\u5229\u907f\u5bb3\u7684\u53cd\u5e94\uff0c\u8fd8\u5e0c\u671b\u667a\u80fd\u4f53\u53ef\u4ee5\u4e3b\u52a8\u53bb\u63a2\u7d22\u4f4d\u7f6e\u73af\u5883\uff0c\u5bf9\u6b64\uff0c\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u5f15\u5165\u4e86\u5185\u9a71\u56de\u62a5\u7684\u6982\u5ff5\uff0c\u5185\u9a71\u56de\u62a5\u4e0d\u9488\u5bf9\u4efb\u4f55\u5177\u4f53\u7684\u5b50\u76ee\u6807\uff0c\u65e0\u5dee\u522b\u5730\u9f13\u52b1\u667a\u80fd\u4f53\u4e3b\u52a8\u63a2\u7d22\u672a\u77e5\u72b6\u6001\uff0c\u5e76\u501f\u6b64\u589e\u52a0\u6b63\u6837\u672c\u548c\u6709\u76ca\u884c\u4e3a\u7684\u53d1\u751f\u6982\u7387\u3002</p> <p>\u200b       \u5185\u9a71\u56de\u62a5\u7684\u5178\u578b\u4ee3\u8868\u5c31\u662f\u57fa\u4e8e\u597d\u5947\u5fc3\u7684\u63a2\u7d22\u7ea2\u5229\uff0c\u6839\u636e\u597d\u5947\u5fc3\u7684\u5b9a\u4e49\u548c\u5b9e\u73b0\u65b9\u6cd5\u7684\u4e0d\u540c\uff0c\u53ef\u4ee5\u5206\u4e3a\u4e09\u7c7b\uff1a</p> <ul> <li>\u57fa\u4e8e\u72b6\u6001\u8ba1\u6570\u7684\u597d\u5947\u5fc3\uff0c\u901a\u8fc7\u7edf\u8ba1\u72b6\u6001\u7a7a\u95f4\u4e2d\u4e0d\u540c\u72b6\u6001\u7684\u8bbf\u95ee\u6b21\u6570\u5e76\u6309\u7167\u53cd\u6bd4\u7ed9\u4e88\u5956\u52b1\uff0c\u4ece\u800c\u9f13\u52b1\u667a\u80fd\u4f53\u66f4\u591a\u5730\u63a2\u7d22\u65b0\u72b6\u6001</li> <li>\u57fa\u4e8e\u9884\u6d4b\u8bef\u5dee\u7684\u597d\u5947\u5fc3\uff0c\u5c06\u72b6\u6001\u7684\u672a\u77e5\u7a0b\u5ea6\u5b9a\u4e49\u4e3a\u5bf9\u672a\u6765\u4fe1\u606f\u7684\u9884\u6d4b\u8bef\u5dee\uff0c\u8bef\u5dee\u8d8a\u5927\u8bf4\u660e\u7b56\u7565\u5bf9\u8be5\u72b6\u6001\u8d8a\u964c\u751f\uff0c\u76f8\u5e94\u7684\u597d\u5947\u5fc3\u5956\u52b1\u4e5f\u5e94\u8be5\u8d8a\u591a</li> <li>\u57fa\u4e8e\u4f2a\u76ee\u6807\u751f\u6210\u7684\u597d\u5947\u5fc3\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u5730\u5bf9\u5f53\u524d\u7b56\u7565\u4e0b\u201c\u52c9\u5f3a\u201d\u53ef\u8fbe\u7684\u72b6\u6001\u7ed9\u4e88\u597d\u5947\u5fc3\u5956\u52b1\uff0c\u4f7f\u5176\u4e0d\u65ad\u6210\u4e3a\u65b0\u7684\u5b50\u76ee\u6807\uff0c\u4ece\u800c\u8d77\u5230\u9f13\u52b1\u63a2\u7d22\u7684\u4f5c\u7528</li> </ul> <p>\u200b       \u5728\u4e8c\u7ef4\u5e73\u9762\u5bfc\u822a\u4efb\u52a1\u4e2d\uff0c\u5047\u5982\u72b6\u6001\u4fe1\u606f\u4e2d\u4e0d\u5305\u542b\u5145\u7535\u6869\u7684\u4f4d\u7f6e\uff0c\u90a3\u4e48\u667a\u80fd\u4f53\u5728\u73af\u5883\u4e2d\u7684\u4e3b\u52a8\u63a2\u7d22\u5c31\u663e\u5f97\u5c24\u4e3a\u91cd\u8981\u3002\u5728\u79bb\u6563\u5316\u7a7a\u95f4\u7f16\u7801\u7684\u8868\u5f81\u4e0b\uff0c\u72b6\u6001\u7a7a\u95f4\u7ef4\u5ea6\u6709\u9650\u4e14\u89c4\u6a21\u9002\u4e2d\uff0c\u56e0\u6b64\u53ef\u4ee5\u91c7\u7528\u57fa\u4e8e\u8868\u683c\u8ba1\u6570\u7684\u597d\u5947\u5fc3\u56de\u62a5\u8bbe\u8ba1\u3002\u5047\u8bbec(s,a)\u4ee3\u8868\u4e4b\u524d\u7684\u63a2\u7d22\u4e2d\u5728\u72b6\u6001s\u4e0b\u9009\u62e9\u52a8\u4f5ca\u7684\u6b21\u6570\u7edf\u8ba1\uff0c\u667a\u80fd\u4f53\u7684\u5185\u9a71\u56de\u62a5\u8868\u793a\u4e3a\uff1a $$ r^i=\\frac{\\rho}{\\sqrt {c(s,a)}} $$  \u901a\u8fc7\u8be5\u5185\u9a71\u56de\u62a5\u7684\u4f5c\u7528\uff0c\u53ef\u4ee5\u9f13\u52b1\u667a\u80fd\u4f53\u53bb\u63a2\u7d22\u5730\u56fe\u4e2d\u4ece\u672a\u5230\u8fbe\u8fc7\u7684\u533a\u57df\u5e76\u4e14\u5c3d\u53ef\u80fd\u9009\u62e9\u591a\u6837\u5316\u7684\u52a8\u4f5c\uff0c\u4ece\u800c\u4e3b\u52a8\u53d1\u73b0\u6240\u6709\u5145\u7535\u6869\u7684\u4f4d\u7f6e\uff0c\u4ee5\u53ca\u5145\u7535\u64cd\u4f5c\u548c\u5269\u4f59\u7535\u91cf\u53d8\u5316\u4e4b\u95f4\u7684\u76f8\u5173\u6027\uff0c\u4e3a\u540e\u7eed\u66f4\u9ad8\u6548\u5730\u62b5\u8fbe\u7ec8\u70b9\u3001\u5408\u7406\u5730\u89c4\u5212\u5145\u7535\u65f6\u673a\u548c\u5145\u7535\u8def\u5f84\u5960\u5b9a\u57fa\u7840\u3002</p> <p>\u8865\u5145\uff1a\u56de\u62a5\u53d6\u503c\u7684\u6ce8\u610f\u4e8b\u9879</p> <p>\u200b       \u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u5bf9\u4e8e\u4e3b\u7ebf\u56de\u62a5\u9002\u5408\u8bbe\u8ba1\u4e3a\u6b63\u5411\u5956\u52b1\uff0c\u8f85\u52a9\u56de\u62a5\u6700\u597d\u8bbe\u8ba1\u4e3a\u8d1f\u5411\u60e9\u7f5a\uff0c\u5e76\u4e14\u4e3a\u4e86\u4fdd\u8bc1\u4e3b\u7ebf\u4efb\u52a1\u7684\u6838\u5fc3\u5730\u4f4d\uff0c\u5404\u9879\u8f85\u52a9\u56de\u62a5\u901a\u5e38\u90fd\u4f1a\u91c7\u7528\u6bd4\u8f83\u5c0f\u7684\u6570\u503c\u3002\u4e3b\u7ebf\u56de\u62a5\u4e0e\u5404\u9879\u8f85\u52a9\u56de\u62a5\u4e4b\u95f4\u7684\u76f8\u5bf9\u53d6\u503c\u552f\u4e00\u51b3\u5b9a\u4e86\u56de\u62a5\u51fd\u6570\u7684\u6574\u4f53\u903b\u8f91\u529f\u80fd\uff0c\u800c\u6240\u6709\u56de\u62a5\u9879\u7684\u7b49\u6bd4\u7f29\u653e\u4e0d\u4f1a\u6539\u53d8\u8fd9\u4e00\u529f\u80fd\u3002</p> <p>\u672a\u5b8c\u5f85\u7eed\u3002\u3002\u3002</p>"},{"location":"auto/PCC/","title":"\u70b9\u4e91\u4e0e\u56fe\u50cf\u505a\u6620\u5c04","text":""},{"location":"auto/PCC/#_2","title":"\u9488\u5b54\u76f8\u673a\u6a21\u578b","text":"<p>\u2003\u2003\u7b80\u5355\u6765\u8bf4\uff0c\u76f8\u673a\u7684\u6210\u50cf\u8fc7\u7a0b\u5c31\u662f\u5c06\u4e00\u4e2a\u4e09\u7ef4\u4e16\u754c\u4e2d\u7684\u70b9\u6620\u5c04\u5230\u4e8c\u7ef4\u5e73\u9762\u4e2d\uff0c\u5177\u4f53\u53ef\u7531\u4e0b\u56fe\u8868\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u8bbeO-x-y-z\u4e3a\u76f8\u673a\u5750\u6807\u7cfb\uff0c\u4e60\u60ef\u4e0a\u8ba9z\u8f74\u6307\u5411\u76f8\u673a\u524d\u65b9\uff0cx\u5411\u53f3\uff0cy\u5411\u4e0b\uff0cO\u4e3a\u6444\u50cf\u673a\u7684\u5149\u5fc3\uff0c\u73b0\u5b9e\u4e16\u754c\u4e2d\uff0c\u7a7a\u95f4\u4e0a\u7684\u4e00\u70b9P\uff0c\u7ecf\u8fc7\u5c0f\u5b54O\u6295\u5f71\u4e4b\u540e\uff0c\u843d\u5230\u5e73\u9762O'-x'-y'\u4e0a\uff0c\u6210\u50cf\u70b9\u4e3aP'\uff0c\u5047\u8bbe\u7126\u8ddd\u4e3af\uff08\u5373\u6210\u50cf\u5e73\u9762\u5230\u5c0f\u5b54\u7684\u8ddd\u79bb\uff09\uff0c\u6839\u636e\u4e09\u89d2\u5f62\u5173\u7cfb\u53ef\u5f97\uff08\u7ffb\u8f6c\u4e86\u4e00\u4e0b\uff09\uff1a $$ \\frac{Z}{f}=\\frac{X}{X'}=\\frac{Y}{Y'} $$  \u2003\u2003\u5728\u76f8\u673a\u6355\u83b7\u56fe\u50cf\u7684\u8fc7\u7a0b\u4e2d\uff0c\u6700\u7ec8\u6240\u83b7\u5f97\u7684\u662f\u4e00\u4e2a\u4e2a\u50cf\u7d20\u503c\uff0c\u56e0\u6b64\u9700\u8981\u5728\u6210\u50cf\u5e73\u9762\u4e0a\u8fdb\u884c\u91c7\u6837\u548c\u91cf\u5316\uff0c\u5373\u5229\u7528\u6210\u50cf\u5e73\u9762\u5750\u6807\u53bb\u8868\u793a\u50cf\u7d20\u5750\u6807\u3002\u50cf\u7d20\u5750\u6807\u7cfb\u901a\u5e38\u7684\u5b9a\u4e49\u65b9\u5f0f\u662f\uff1a\u539f\u70b9o'\u4f4d\u4e8e\u56fe\u50cf\u7684\u5de6\u4e0a\u89d2\uff0cu\u8f74\u4e0ex\u8f74\u5e73\u884c\uff0cv\u8f74\u5411\u4e0b\u4e0ey\u8f74\u5e73\u884c\uff0c\u8bbe\u6210\u50cf\u5e73\u9762\u4e0a\u56fa\u5b9a\u4e00\u4e2a\u50cf\u7d20\u5e73\u9762o-u-v\uff0c\u5bf9\u5e94\u5f97\u5230\u50cf\u7d20\u5750\u6807P'=[u,v]^T\u3002</p> <p>\u2003\u2003\u50cf\u7d20\u5750\u6807\u4e0e\u6210\u50cf\u5e73\u9762\u4e4b\u95f4\u76f8\u5dee\u4e00\u4e2a\u7f29\u653e\u548c\u4e00\u4e2a\u539f\u70b9\u7684\u5e73\u79fb\uff0c\u5176\u4e2d\u7f29\u653e\u662f\u7531\u4e8e\u4e0d\u540c\u76f8\u673a\u8bbe\u5907\u5206\u8fa8\u7387\u4e0d\u540c\uff0c\u56e0\u6b64\u6210\u50cf\u5e73\u9762\u7684\u5750\u6807\u5c3a\u5ea6\u4e0d\u540c\uff0c\u5e76\u4e14\u6210\u50cf\u5e73\u9762\u4f4d\u4e8e\u56fe\u50cf\u7684\u5de6\u4e0a\u89d2\uff0c\u6240\u4ee5\u8fd8\u8981\u518d\u6dfb\u52a0\u4e00\u4e2a\u504f\u79fb\u9879\u3002\u5047\u8bbe\u50cf\u7d20\u5750\u6807\u5728u\u8f74\u4e0a\u7f29\u653e\u4e86\\alpha\u500d\uff0c\u5728v\u8f74\u4e0a\u7f29\u653e\u4e86\\beta\u500d\uff0c\u539f\u70b9\u5e73\u79fb\u4e86[c_x,c_y]^T\uff0c\u90a3\u4e48P'\u7684\u5750\u6807\u4e0e\u50cf\u7d20\u5750\u6807[u,v]^T\u4e4b\u95f4\u7684\u5173\u7cfb\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ \\left\\{ \\begin{matrix} u=\\alpha X'+c_x\\\\ v=\\beta Y'+c_y \\end{matrix} \\right.  \\Rightarrow \\left\\{ \\begin{matrix} u=f_x\\frac{X}{Z}+c_x\\\\ v=f_y\\frac{Y}{Z}+c_y \\end{matrix} \\right. $$  \u5176\u4e2d\\alpha f\u4e0e\\beta f\u5206\u522b\u5408\u5e76\u6210f_x,f_y\uff0c\u8fdb\u4e00\u6b65\u53ef\u5316\u4e3a\u77e9\u9635\u5f62\u5f0f\uff1a $$ Z \\begin{bmatrix} u\\\\v\\\\1 \\end{bmatrix} =\\begin{bmatrix} f_x&amp;0&amp;c_x\\\\ 0&amp;f_y&amp;c_y\\\\ 0&amp;0&amp;1 \\end{bmatrix} \\begin{bmatrix} X\\\\Y\\\\Z \\end{bmatrix}=KP $$  \u5176\u4e2d\uff0cK\u79f0\u4e3a\u5185\u53c2\u77e9\u9635\uff0c\u4e5f\u79f0\u4e3a\u76f8\u673a\u7684\u6807\u5b9a\uff0c\u5f80\u5f80\u5728\u76f8\u673a\u7684\u51fa\u5382\u4e4b\u540e\u5c31\u56fa\u5b9a\u4e86\uff0c\u4e0d\u4f1a\u5728\u4f7f\u7528\u8fc7\u7a0b\u4e2d\u53d1\u751f\u53d8\u5316\u3002</p> <p>\u2003\u2003\u4e0a\u8ff0\u516c\u5f0f\u4e2d\uff0cP\u662f\u7269\u4f53\u5728\u76f8\u673a\u5750\u6807\u7cfb\u4e0b\u7684\u5750\u6807\uff0c\u4f46\u5b9e\u9645\u4e0a\uff0c\u7269\u4f53\u7684\u4e09\u7ef4\u5750\u6807\u5f80\u5f80\u4e0d\u80fd\u76f4\u63a5\u901a\u8fc7\u76f8\u673a\u5f97\u5230\uff0c\u9700\u8981\u901a\u8fc7\u5176\u4ed6\u7684\u8bbe\u5907\u6765\u6355\u83b7\uff0c\uff08\u4f8b\u5982\u5229\u7528\u6fc0\u5149\u96f7\u8fbe\u6765\u83b7\u53d6\u70b9\u4e91\u5750\u6807\uff09\uff0c\u5047\u8bbe\u5229\u7528\u5176\u4ed6\u8bbe\u5907\u6355\u83b7\u5230\u7684\u4e09\u7ef4\u5750\u6807\u8bb0\u4e3aP_w\uff0c\u4e4b\u540e\u5229\u7528\u76f8\u673a\u7684\u5f53\u524d\u4f4d\u59ff\u53d8\u6362\u5f97\u5230\u76f8\u673a\u4e0b\u7684\u5750\u6807\uff0c\u5047\u8bbeR\u548ct\u5206\u522b\u662f\u76f8\u673a\u4f4d\u59ff\u7684\u65cb\u8f6c\u77e9\u9635\u548c\u5e73\u79fb\u5411\u91cf\uff0c\u90a3\u4e48\u6709\uff1a $$ ZP_{uv}=K(RP_w+t)=KTP_w $$  \u5176\u4e2dR\u4e0et\u53c8\u79f0\u4e3a\u76f8\u673a\u7684\u5916\u53c2\u6570\uff0c\u5916\u53c2\u4f1a\u968f\u7740\u76f8\u673a\u7684\u8fd0\u52a8\u800c\u53d1\u751f\u6539\u53d8\u3002</p> <p>\u4ee5\u4e0a\u53c2\u8003\u300a\u89c6\u89c9SLAM\u5341\u56db\u8bb2\u300b\uff0c\u9ad8\u7fd4\u3001\u5f20\u6d9b\uff0c\u7b2c5\u8bb2\u3002</p>"},{"location":"auto/PCC/#kitti","title":"KITTI","text":"<p>\u6570\u636e\u96c6\u4e0b\u8f7d\u5730\u5740\uff1ahttps://www.cvlibs.net/datasets/kitti/index.php</p> <p> <p></p> <p></p> <p>\u6807\u5b9a\u6587\u4ef6</p> <p> <p></p> <p></p> <ul> <li>P0\u3001P1\u3001P2\u3001P3\uff1a\u5747\u4ee3\u8868\u5bf9\u5e94\u7684\u76f8\u673a\u5185\u53c2\u77e9\u9635\uff0c\u5176\u4e2d\u5e8f\u53f70-3\u5206\u522b\u4ee3\u8868\u5de6\u8fb9\u7070\u5ea6\u76f8\u673a\u3001\u53f3\u8fb9\u7070\u5ea6\u76f8\u673a\u3001\u5de6\u8fb9\u5f69\u8272\u76f8\u673a\u3001\u53f3\u8fb9\u5f69\u8272\u76f8\u673a\uff0c\u5c3a\u5bf8\u4e3a3\\times4\uff0c\u524d3\\times3\u7684\u77e9\u9635\u8868\u793aK\u9635\uff0c\u6700\u540e\u90a3\u52173\\times1\u7684\u77e9\u9635\u8868\u793aT\u9635\uff0c\u6570\u636e\u683c\u5f0f\u4e3a\uff1a</li> </ul> <pre><code>fx   0   cx   Tx\n 0  fy   cy   Ty\n 0   0    1   Tz\n</code></pre> <p>\u5176\u4e2dfx\u548cfy\u5206\u522b\u8868\u793a\u76f8\u673a\u5728x\u548cy\u65b9\u5411\u4e0a\u7684\u7126\u8ddd\uff0ccx\u548ccy\u5206\u522b\u8868\u793a\u76f8\u673a\u5149\u5fc3\uff08\u4e3b\u70b9\uff09\u5728\u56fe\u50cf\u5e73\u9762\u4e0a\u7684\u5750\u6807\uff0c\u800cTx\u3001Ty\u548cTz\u5206\u522b\u8868\u793a\u76f8\u673a\u5149\u5fc3\uff08\u4e3b\u70b9\uff09\u5728\u76f8\u673a\u5750\u6807\u7cfb\u4e0b\u7684\u5e73\u79fb\u5411\u91cf\uff0c\u8fd9\u4e2a\u5e73\u79fb\u5411\u91cf\u63cf\u8ff0\u4e86\u76f8\u673a\u5149\u5fc3\u76f8\u5bf9\u4e8e\u76f8\u673a\u5750\u6807\u7cfb\u539f\u70b9\u7684\u4f4d\u7f6e\uff0c\u5728\u8ba1\u7b97\u5750\u6807\u70b9\u7531\u76f8\u673a\u7cfb\u5230\u56fe\u50cf\u7cfb\u7684\u6295\u5f71\u65f6\u7528\u5230\uff0c\u6267\u884cKP+T\u8fd0\u7b97\uff08\u5177\u4f53\u53ef\u89c1\u6e90\u7801\u5b9e\u73b0\u90e8\u5206\uff09\u3002</p> <ul> <li> <p>R0_rect\uff1a\u4e3a0\u53f7\u76f8\u673a\u7684\u4fee\u6b63\u77e9\u9635\uff0c\u5c3a\u5bf8\u4e3a3\\times3\uff0c\u76ee\u7684\u662f\u4e3a\u4e86\u4f7f4\u4e2a\u76f8\u673a\u6210\u50cf\u8fbe\u5230\u5171\u9762\u7684\u6548\u679c\uff0c\u4fdd\u8bc14\u4e2a\u76f8\u673a\u5149\u5fc3\u5728\u540c\u4e00\u4e2axoy\u5e73\u9762\u4e0a\uff1b</p> </li> <li> <p>Tr_velo_to_cam\uff1a\u4e3a\u5916\u53c2\u77e9\u9635\uff0c\u5c3a\u5bf8\u4e3a3\\times4\uff0c\u7528\u4e8e\u5c06\u96f7\u8fbe\u7cfb\u4e0b\u7684\u5750\u6807\u8f6c\u4e3a\u76f8\u673a\u7cfb\u4e0b\u7684\u5750\u6807\uff0c\u5305\u542b\u65cb\u8f6c\u77e9\u9635R\u548c\u5e73\u79fb\u5411\u91cft\uff0c\u5373[R,t]_{(3,4)}\uff0c\u6570\u636e\u683c\u5f0f\u4e3a\uff1a</p> </li> </ul> <pre><code>R11  R12  R13  Tx\nR21  R22  R23  Ty\nR31  R32  R33  Tz\n</code></pre> <p>\u5176\u4e2dR_{(3,3)}\u8868\u793a\u65cb\u8f6c\u77e9\u9635\uff0c\u800cTx\u3001Ty\u548cTz\u5206\u522b\u8868\u793a\u76f8\u673a\u5728\u771f\u5b9e\u4e16\u754c\u5750\u6807\u7cfb\u4e0b\u7684\u5e73\u79fb\u5411\u91cf\uff0c\u5728\u8ba1\u7b97\u5750\u6807\u70b9\u7531\u96f7\u8fbe\u7cfb\u5230\u76f8\u673a\u7cfb\u7684\u6295\u5f71\u65f6\u7528\u5230\uff0c\u6267\u884cRP+T\u8fd0\u7b97\u3002</p> <p>\u2003\u2003\u5c06\u6fc0\u5149\u96f7\u8fbe\u5750\u6807\u7cfb\u4e2d\u7684\u70b9x\u6295\u5f71\u5230\u5f69\u8272\u56fe\u50cfy\u4e2d\u7684\u6b65\u9aa4\uff1a $$ y=P2*R0\\_rect*Tr\\_velo\\_to\\_cam*x $$ </p>"},{"location":"auto/PCC/#_3","title":"\u4ee3\u7801\u5b9e\u73b0","text":"<p>\u53c2\u8003\u94fe\u63a5\uff1ahttps://github.com/ZhengXinyue/bilibili_project</p> <p>\u6548\u679c\u56fe\uff1a</p> <p> <p></p> <p></p> <p></p> <pre><code>import sys\n\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport pyqtgraph.opengl as gl\nfrom PyQt5.QtWidgets import QApplication\n\n\ncmap = plt.cm.jet\n\n\ndef read_bin(bin_path, intensity=False):\n    \"\"\"\n    \u8bfb\u53d6kitti bin\u683c\u5f0f\u6587\u4ef6\u70b9\u4e91\n    :param bin_path:   \u70b9\u4e91\u8def\u5f84\n    :param intensity:  \u662f\u5426\u8981\u5f3a\u5ea6\n    :return:           numpy.ndarray `N x 3` or `N x 4`\n    \"\"\"\n    lidar_points = np.fromfile(bin_path, dtype=np.float32).reshape((-1, 4))\n    if not intensity:\n        lidar_points = lidar_points[:, :3]\n    return lidar_points\n\n\ndef read_calib(calib_path):\n    \"\"\"\n    \u8bfb\u53d6kitti\u6570\u636e\u96c6\u6807\u5b9a\u6587\u4ef6\n    \u4e0b\u8f7d\u7684\u5f69\u8272\u56fe\u50cf\u662f\u5de6\u8fb9\u76f8\u673a\u7684\u56fe\u50cf, \u6240\u4ee5\u8981\u7528P2\n    extrinsic = np.matmul(R0, lidar2camera)\n    intrinsic = P2\n    P\u4e2d\u5305\u542b\u7b2ci\u4e2a\u76f8\u673a\u52300\u53f7\u6444\u50cf\u5934\u7684\u8ddd\u79bb\u504f\u79fb(x\u65b9\u5411)\n    extrinsic\u53d8\u6362\u540e\u7684\u70b9\u4e91\u662f\u6295\u5f71\u5230\u7f16\u53f7\u4e3a0\u7684\u76f8\u673a(\u53c2\u8003\u76f8\u673a)\u5750\u6807\u7cfb\u4e2d\u5e76\u4fee\u6b63\u540e\u7684\u70b9\n    intrinsic(P2)\u53d8\u6362\u540e\u53ef\u4ee5\u6295\u5f71\u5230\u5de6\u8fb9\u76f8\u673a\u56fe\u50cf\u4e0a\n    P0, P1, P2, P3\u5206\u522b\u4ee3\u8868\u5de6\u8fb9\u7070\u5ea6\u76f8\u673a\uff0c\u53f3\u8fb9\u7070\u5ea6\u76f8\u673a\uff0c\u5de6\u8fb9\u5f69\u8272\u76f8\u673a\uff0c\u53f3\u8fb9\u5f69\u8272\u76f8\u673a\n    :return: P0-P3 numpy.ndarray           `3 x 4`\n             R0 numpy.ndarray              `4 x 4`\n             lidar2camera numpy.ndarray    `4 x 4`\n             imu2lidar numpy.ndarray       `4 x 4`\n\n    &gt;&gt;&gt; P0, P1, P2, P3, R0, lidar2camera_m, imu2lidar_m = read_calib(calib_path)\n    &gt;&gt;&gt; extrinsic_m = np.matmul(R0, lidar2camera_m)\n    &gt;&gt;&gt; intrinsic_m = P2\n    \"\"\"\n    with open(calib_path, 'r') as f:\n        raw = f.readlines()\n    # \u8bfb\u53d6\u56db\u4e2a\u76f8\u673a\u5185\u53c2\u77e9\u9635\uff0c0-3\u4f9d\u6b21\u8868\u793a:\u5de6\u8fb9\u7070\u5ea6\u76f8\u673a\u3001\u53f3\u8fb9\u7070\u5ea6\u76f8\u673a\u3001\u5de6\u8fb9\u5f69\u8272\u76f8\u673a\u3001\u53f3\u8fb9\u5f69\u8272\u76f8\u673a\n    P0 = np.array(list(map(float, raw[0].split()[1:]))).reshape((3, 4))\n    P1 = np.array(list(map(float, raw[1].split()[1:]))).reshape((3, 4))\n    P2 = np.array(list(map(float, raw[2].split()[1:]))).reshape((3, 4))\n    P3 = np.array(list(map(float, raw[3].split()[1:]))).reshape((3, 4))\n    R0 = np.array(list(map(float, raw[4].split()[1:]))).reshape((3, 3))\n    R0 = np.hstack((R0, np.array([[0], [0], [0]])))\n    R0 = np.vstack((R0, np.array([0, 0, 0, 1])))\n    # \u96f7\u8fbe\u5230\u76f8\u673a\u7684\u8f6c\u6362\u77e9\u9635\n    lidar2camera_m = np.array(list(map(float, raw[5].split()[1:]))).reshape((3, 4))\n    lidar2camera_m = np.vstack((lidar2camera_m, np.array([0, 0, 0, 1])))\n    imu2lidar_m = np.array(list(map(float, raw[6].split()[1:]))).reshape((3, 4))\n    imu2lidar_m = np.vstack((imu2lidar_m, np.array([0, 0, 0, 1])))\n    return P0, P1, P2, P3, R0, lidar2camera_m, imu2lidar_m\n\n\ndef vis_pointcloud(points, colors=None):\n    \"\"\"\n    \u6e32\u67d3\u663e\u793a\u96f7\u8fbe\u70b9\u4e91\n    :param points:    numpy.ndarray  `N x 3`\n    :param colors:    numpy.ndarray  `N x 3`  (0, 255)\n    :return:\n    \"\"\"\n    app = QApplication(sys.argv)\n    if colors is not None:\n        colors = colors / 255\n        colors = np.hstack((colors, np.ones(shape=(colors.shape[0], 1))))\n    else:\n        colors = (1, 1, 1, 1)\n    og_widget = gl.GLViewWidget()\n    point_size = np.zeros(points.shape[0], dtype=np.float16) + 0.1\n\n    points_item1 = gl.GLScatterPlotItem(pos=points, size=point_size, color=colors, pxMode=False)\n    og_widget.addItem(points_item1)\n\n    # \u4f5c\u4e3a\u5bf9\u6bd4\n    # points_item2 = gl.GLScatterPlotItem(pos=points, size=point_size, color=(1, 1, 1, 1), pxMode=False)\n    # points_item2.translate(0, 0, 20)\n    # og_widget.addItem(points_item2)\n\n    og_widget.show()\n    sys.exit(app.exec_())\n\n\ndef image2camera(point_in_image, intrinsic):\n    \"\"\"\n    \u56fe\u50cf\u7cfb\u5230\u76f8\u673a\u7cfb\u53cd\u6295\u5f71\n    :param point_in_image: numpy.ndarray `N x 3` (u, v, z)\n    :param intrinsic: numpy.ndarray `3 x 3` or `3 x 4`\n    :return: numpy.ndarray `N x 3` (x, y, z)\n    u = fx * X/Z + cx\n    v = fy * Y/Z + cy\n    X = (u - cx) * Z / fx\n    Y = (v - cy) * z / fy\n       [[fx, 0,  cx, -fxbi],\n    K=  [0,  fy, cy],\n        [0,  0,  1 ]]\n    \"\"\"\n    if intrinsic.shape == (3, 3):  # \u517c\u5bb9kitti\u7684P2, \u5bf9\u4e8e\u6ca1\u6709\u5e73\u79fb\u7684intrinsic\u6dfb0\n        intrinsic = np.hstack((intrinsic, np.zeros((3, 1))))\n\n    u = point_in_image[:, 0]\n    v = point_in_image[:, 1]\n    z = point_in_image[:, 2]\n    x = ((u - intrinsic[0, 2]) * z - intrinsic[0, 3]) / intrinsic[0, 0]\n    y = ((v - intrinsic[1, 2]) * z - intrinsic[1, 3]) / intrinsic[1, 1]\n    point_in_camera = np.vstack((x, y, z))\n    return point_in_camera\n\n\ndef lidar2camera(point_in_lidar, extrinsic):\n    \"\"\"\n    \u96f7\u8fbe\u7cfb\u5230\u76f8\u673a\u7cfb\u6295\u5f71\n    :param point_in_lidar: numpy.ndarray `N x 3`\n    :param extrinsic: numpy.ndarray `4 x 4`\n    :return: point_in_camera numpy.ndarray `N x 3`\n    \"\"\"\n    point_in_lidar = np.hstack((point_in_lidar, np.ones(shape=(point_in_lidar.shape[0], 1)))).T\n    point_in_camera = np.matmul(extrinsic, point_in_lidar)[:-1, :]  # (X, Y, Z)\n    point_in_camera = point_in_camera.T\n    return point_in_camera\n\n\ndef camera2image(point_in_camera, intrinsic):\n    \"\"\"\n    \u76f8\u673a\u7cfb\u5230\u56fe\u50cf\u7cfb\u6295\u5f71\n    :param point_in_camera: point_in_camera numpy.ndarray `N x 3`\n    :param intrinsic: numpy.ndarray `3 x 3` or `3 x 4`\n    :return: point_in_image numpy.ndarray `N x 3` (u, v, z)\n    \"\"\"\n    point_in_camera = point_in_camera.T\n    # z\u8f74\u7684\u8ddd\u79bb\u4fe1\u606f\n    point_z = point_in_camera[-1]\n\n    if intrinsic.shape == (3, 3):  # \u517c\u5bb9kitti\u7684P2, \u5bf9\u4e8e\u6ca1\u6709\u5e73\u79fb\u7684intrinsic\u6dfb0\n        intrinsic = np.hstack((intrinsic, np.zeros((3, 1))))  # (3, 3) + (3, 1) -&gt; (3, 4)\n    # point_in_camera\u5c3a\u5bf8\u4e3a(4,N)\n    point_in_camera = np.vstack((point_in_camera, np.ones((1, point_in_camera.shape[1]))))\n    # \u5411\u56fe\u50cf\u4e0a\u6295\u5f71\uff0c\u524d\u4e24\u4e2a\u7ef4\u5ea6\u662f\u50cf\u7d20\u5750\u6807\uff0c\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\u4e3a1\uff0c\u505a\u4e86\u5f52\u4e00\u5316\u5904\u7406\n    point_in_image = (np.matmul(intrinsic, point_in_camera) / point_z)\n    # \u4e0b\u9762\u7684\u8d4b\u503c\u64cd\u4f5c\u53ef\u6709\u53ef\u65e0\uff0c\u6700\u7ec8\u4e0a\u8272\u65f6\uff0cz\u8f74\u6570\u636e\u7684\u5927\u5c0f\u65e0\u5173\uff0c\u53ea\u8ddf\u6b63\u8d1f\u6709\u5173\n    point_in_image[-1] = point_z\n    point_in_image = point_in_image.T\n    # (N, 3)\n    return point_in_image\n\n\ndef lidar2image(point_in_lidar, extrinsic, intrinsic):\n    \"\"\"\n    \u96f7\u8fbe\u7cfb\u5230\u56fe\u50cf\u7cfb\u6295\u5f71  \u83b7\u5f97(u, v, z)\n    :param point_in_lidar: numpy.ndarray `N x 3`\n    :param extrinsic: numpy.ndarray `4 x 4`\n    :param intrinsic: numpy.ndarray `3 x 3` or `3 x 4`\n    :return: point_in_image numpy.ndarray `N x 3` (u, v, z)\n    \"\"\"\n    # \u96f7\u8fbe\u7cfb\u5230\u76f8\u673a\u7cfb\u7684\u6295\u5f71\n    point_in_camera = lidar2camera(point_in_lidar, extrinsic)\n    # \u76f8\u673a\u7cfb\u5230\u56fe\u50cf\u7cfb\u7684\u6295\u5f71\n    point_in_image = camera2image(point_in_camera, intrinsic)\n    return point_in_image\n\n\ndef get_fov_mask(point_in_lidar, extrinsic, intrinsic, h, w):\n    \"\"\"\n    \u83b7\u53d6fov\u5185\u7684\u70b9\u4e91mask, \u5373\u80fd\u591f\u6295\u5f71\u5728\u56fe\u50cf\u4e0a\u7684\u70b9\u4e91mask\n    :param point_in_lidar:   \u96f7\u8fbe\u70b9\u4e91 numpy.ndarray `N x 3`\n    :param extrinsic:        \u5916\u53c2 numpy.ndarray `4 x 4` \u96f7\u8fbe\u5230\u76f8\u673a\n    :param intrinsic:        \u5185\u53c2 numpy.ndarray `3 x 3` or `3 x 4` \u76f8\u673a\u5185\u90e8\u7684\u5185\u53c2\n    :param h:                \u56fe\u50cf\u9ad8 int\n    :param w:                \u56fe\u50cf\u5bbd int\n    :return: point_in_image: (u, v, z)  numpy.ndarray `N x 3`\n    :return:                 numpy.ndarray  `1 x N`\n    \"\"\"\n    # \u5c06\u96f7\u8fbe\u70b9\u4e91\u7cfb\u6570\u636e\u8f6c\u4e3a\u56fe\u50cf\u7cfb\u70b9\u4e91\u6570\u636e\uff0cpoint_in_image\u5c3a\u5bf8\u4e3a(N,3)\n    point_in_image = lidar2image(point_in_lidar, extrinsic, intrinsic)\n    # \u4e0b\u9762\u7b5b\u9009\u51fa\u4e0d\u5728\u6295\u5f71\u56fe\u50cf\u8303\u56f4\u5185\u7684\u70b9\u4e91\uff0c\u5373\u7b5b\u9009\u51fa\u7b2c\u4e00\u5366\u9650\u7684\u6570\u636e\n    # \u5148\u7b5b\u9009\u51faz\u8f74\u6b63\u4fa7\u7684\u70b9\uff0c\u4e5f\u5c31\u662f\u524d\u4fa7\u7684\u70b9\u4e91\n    front_bound = point_in_image[:, -1] &gt; 0\n    point_in_image[:, 0] = np.round(point_in_image[:, 0])\n    point_in_image[:, 1] = np.round(point_in_image[:, 1])\n    # \u7b5b\u9009\u51fa\u7b2c\u4e00\u8c61\u9650\u7684\u6570\u636e\n    u_bound = np.logical_and(point_in_image[:, 0] &gt;= 0, point_in_image[:, 0] &lt; w)\n    v_bound = np.logical_and(point_in_image[:, 1] &gt;= 0, point_in_image[:, 1] &lt; h)\n    uv_bound = np.logical_and(u_bound, v_bound)\n    # \u5f97\u5230\u5728\u89c6\u573a\u8303\u56f4\u5185\u70b9\u4e91\u7684mask\n    mask = np.logical_and(front_bound, uv_bound)\n    # \u7b5b\u9009\u51fa\u89c6\u573a\u8303\u56f4\u5185\u7684\u70b9\u4e91\n    return point_in_image[mask], mask, point_in_image\n\n\ndef get_point_in_image(point_in_lidar, extrinsic, intrinsic, h, w):\n    \"\"\"\n    \u628a\u96f7\u8fbe\u70b9\u4e91\u6295\u5f71\u5230\u56fe\u50cf\u4e0a, \u4e14\u7ecf\u8fc7\u7b5b\u9009.  \u7528\u8fd9\u4e2a\u5c31\u53ef\u4ee5\u4e86.\n    :param point_in_lidar:   \u96f7\u8fbe\u70b9\u4e91 numpy.ndarray `N x 3`\n    :param extrinsic:        \u5916\u53c2 numpy.ndarray `4 x 4`\n    :param intrinsic:        \u5185\u53c2 numpy.ndarray `3 x 3` or `3 x 4`\n    :param h:                \u56fe\u50cf\u9ad8 int\n    :param w:                \u56fe\u50cf\u5bbd int\n    :return: point_in_image  (u, v, z)  numpy.ndarray `M x 3`  \u7b5b\u9009\u6389\u4e86\u540e\u9762\u7684\u70b9\u548c\u4e0d\u843d\u5728\u56fe\u50cf\u4e0a\u7684\u70b9\n    :return: depth_image     numpy.ndarray `image_h x image_w` \u6df1\u5ea6\u56fe\n    \"\"\"\n    point_in_image_foreground, mask, point_in_image = get_fov_mask(point_in_lidar, extrinsic, intrinsic, h, w)\n    depth_image = np.zeros(shape=(h, w), dtype=np.float32)\n    depth_image[point_in_image_foreground[:, 1].astype(np.int32), point_in_image_foreground[:, 0].astype(np.int32)] = point_in_image_foreground[:, 2]\n    return point_in_image_foreground, depth_image\n\n\nif __name__ == '__main__':\n    image_path = '../../KITTI(part)/training/image_2/000036.png'\n    bin_path = '../../KITTI(part)/training/velodyne/000036.bin'\n    calib_path = '../../KITTI(part)/training/calib/000036.txt'\n    # \u8bfb\u53d6\u70b9\u4e91bin\u6570\u636e\n    point_in_lidar = read_bin(bin_path)\n    # \u8bfb\u53d6\u56fe\u50cf\u6570\u636e\n    color_image = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n    # \u8bfb\u53d6\u76f8\u673a\u53c2\u6570\uff0clidar2camera_matrix\u8868\u793a\u96f7\u8fbe\u5230\u76f8\u673a\u7684\u8f6c\u6362\u77e9\u9635\n    _, _, P2, _, R0, lidar2camera_matrix, _ = read_calib(calib_path)\n    intrinsic = P2                      # \u5185\u53c2\n    extrinsic = np.matmul(R0, lidar2camera_matrix)  # \u96f7\u8fbe\u5230\u76f8\u673a\u5916\u53c2\n    h, w = color_image.shape[:2]  # \u56fe\u50cf\u9ad8\u548c\u5bbd\n    # \u5148\u5c06\u96f7\u8fbe\u7cfb\u7684\u70b9\u4e91\u5750\u6807\u8f6c\u5316\u4e3a\u56fe\u50cf\u7cfb\u4e0a\u7684\u5750\u6807\uff0c\u4e4b\u540e\u9009\u53d6\u89c6\u91ce\u4e2d\u7684\u5750\u6807\u6570\u636e\n    point_in_image_foreground, mask, point_in_image = get_fov_mask(point_in_lidar, extrinsic, intrinsic, h, w)\n\n    # \u83b7\u53d6\u989c\u8272\n    colors = np.ones(point_in_lidar.shape) * 255\n    colors[mask] = color_image[point_in_image_foreground[:, 1].astype(np.int32),\n                         point_in_image_foreground[:, 0].astype(np.int32)]  # N x 3\n    vis_pointcloud(points=point_in_lidar, colors=colors)\n\n    # \u4fdd\u5b58numpy\u6570\u7ec4, \u7528\u4f5cros\u70b9\u4e91\u53d1\u5e03\u6570\u636e\n    # np.save('../data_example/points.npy', valid_points)   # (N, 3)  np.float32\n    # np.save('../data_example/colors.npy', colors)         # (N, 3)  np.uint8  [0, 255]\n</code></pre>"},{"location":"auto/PCC/#nuscenes","title":"nuScenes","text":"<ul> <li>\u6570\u636e\u96c6\u4e0b\u8f7d\u5730\u5740\uff1ahttps://www.nuscenes.org/nuscenes#download</li> <li>\u53c2\u8003\u94fe\u63a5\uff1ahttps://blog.csdn.net/qq_16137569/article/details/121066977</li> </ul> <p>\u5750\u6807\u8f6c\u6362\u7cfb</p> <p>\u2003\u2003\u76f8\u6bd4KITTI\uff0cnuScenes\u4e2d\u7684\u5750\u6807\u7cfb\u8f6c\u6362\u7565\u5fae\u6709\u70b9\u590d\u6742\uff0c\u5b58\u5728\u56db\u4e2a\u5750\u6807\u7cfb\uff1a\u5168\u5c40\u5750\u6807\u7cfb\uff08global frame\uff09\u3001\u8f66\u8eab\u5750\u6807\u7cfb\uff08ego vehicle frame\uff09\u3001\u76f8\u673a\u5750\u6807\u7cfb\uff08cameraframe\uff09\u548c\u96f7\u8fbe\u5750\u6807\u7cfb\uff08lidar frame\uff09\u3002\u540e\u9762\u4e09\u4e2a\u5750\u6807\u7cfb\u6bd4\u8f83\u597d\u7406\u89e3\uff0c\u90fd\u662f\u76f8\u5bf9\u5750\u6807\u7cfb\uff0c\u76ee\u6807\u7684\u4f4d\u7f6e\u968f\u7740\u672c\u8f66\u7684\u8fd0\u52a8\u800c\u53d1\u751f\u53d8\u5316\uff1b\u5168\u5c40\u5750\u6807\u7cfb\u662f\u7edd\u5bf9\u5750\u6807\u4e0d\u968f\u672c\u8f66\u7684\u8fd0\u52a8\u800c\u53d8\uff0c\u5404\u5750\u6807\u7684\u8f6c\u6362\u5173\u7cfb\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u6240\u6709\u8f6c\u6362\u5fc5\u987b\u5148\u8f6c\u5230\u8f66\u8eab\u5750\u6807\u7cfb\uff0c\u4e4b\u540e\u518d\u8f6c\u5230\u76ee\u6807\u5750\u6807\u7cfb\u3002\u6ce8\u610f\uff1a\u76f8\u673a\u548c\u96f7\u8fbe\u5728\u6355\u83b7\u6570\u636e\u65f6\u4e0d\u662f\u5b8c\u5168\u540c\u6b65\u8fdb\u884c\u7684\uff0c\u56e0\u6b64\u6bcf\u5f20\u56fe\u50cf\u7684\u65f6\u95f4\u6233\u3001\u70b9\u4e91\u7684\u65f6\u95f4\u6233\u90fd\u4e24\u4e24\u4e0d\u76f8\u540c\uff0c\u56e0\u6b64\u56fe\u50cf\u7684\u8f66\u4f53\u5750\u6807\u4e0e\u70b9\u4e91\u7684\u8f66\u4f53\u5750\u6807\u65e0\u6cd5\u76f4\u63a5\u5bf9\u5e94\u8d77\u6765\uff0c\u5728\u6267\u884c\u70b9\u4e91\u5230\u56fe\u50cf\u7684\u6295\u5f71\u8ba1\u7b97\u65f6\uff0c\u9700\u8981\u989d\u5916\u5229\u7528\u4f4d\u59ff\u8865\u507f\uff08ego data\uff09\u8f6c\u6362\u6210\u5168\u5c40\u5750\u6807\u7cfb\u4e0b\u7684\u70b9\uff0c\u5177\u4f53\u6b65\u9aa4\u4e3a\uff1a\u96f7\u8fbe\u5750\u6807\u7cfb\u2192\u8f66\u4f53\u5750\u6807\u7cfb\u2192\u5168\u5c40\u5750\u6807\u7cfb\u2192\u8f66\u4f53\u5750\u6807\u7cfb\u2192\u76f8\u673a\u5750\u6807\u7cfb\u2192\u56fe\u50cf\u5750\u6807\u7cfb\u3002</p> <p>\u6ce8\uff1a</p> <ul> <li> <p>\u524d\u56db\u6b21\u8f6c\u6362\u5229\u7528\u76f8\u673a\u5916\u53c2\u5b9e\u73b0\uff08\u65cb\u8f6c\u77e9\u9635+\u504f\u79fb\u5411\u91cf\uff09\uff1a(x,y,z)=RP+t\uff0c\u5e76\u4e14\u524d\u4e24\u6b21\u53d8\u6362\u5c5e\u4e8e\u4e00\u4e2a\u65f6\u95f4\u6233\uff08\u96f7\u8fbe\u6355\u83b7\u6570\u636e\u65f6\u7684\u65f6\u95f4\u6233\uff09\uff0c\u540e\u4e24\u6b21\u53d8\u6362\u5c5e\u4e8e\u4e00\u4e2a\u65f6\u95f4\u6233\uff08\u76f8\u673a\u6355\u83b7\u6570\u636e\u65f6\u7684\u65f6\u95f4\u6233\uff09\uff1b</p> </li> <li> <p>\u6700\u540e\u4e00\u6b21\u8f6c\u6362\u5229\u7528\u76f8\u673a\u5185\u53c2\u5b9e\u73b0\uff1a(u,v,1)=\\frac1zK(x,y,z)\uff1b</p> </li> </ul> <p> <p></p> <p></p>"},{"location":"auto/PCC/#_4","title":"\u4ee3\u7801\u5b9e\u73b0","text":"<p> <p></p> <p></p> <ul> <li>\u6ce8\uff1a\u6309\u76f8\u673a\u904d\u5386\uff0c\u4ee5\u524d\u9762\u7684\u76f8\u673a\u4e3a\u8d77\u70b9\uff0c\u987a\u65f6\u9488\u904d\u5386\uff0c\u5229\u7528\u56fe\u50cf\u7ed9\u70b9\u4e91\u4e0a\u8272\uff0c\u5bf9\u4e8e\u4e00\u7ec4\u70b9\u4e91\u6570\u636e\u603b\u5171\u4f1a\u4e0a\u516d\u6b21\u989c\u8272\uff0c\u5bf9\u5e94\u516d\u4e2a\u76f8\u673a\u62cd\u5230\u7684\u56fe\u50cf\u3002</li> </ul> <pre><code>import cv2\nimport copy\nimport os\nimport sys\nimport numpy as np\nimport pyqtgraph.opengl as gl\n\nfrom nuscenes.nuscenes import NuScenes\nfrom PyQt5.QtWidgets import QApplication\nfrom pyquaternion import Quaternion\n\n\ndef project_lidar2image(nusc, img, lidar_pt_list, lidar_file, camera_data):\n    img_h, img_w, _ = img.shape\n    points = copy.deepcopy(lidar_pt_list.transpose())\n\n    # step1: lidar frame -&gt; ego frame\n    # \u5c06\u96f7\u8fbe\u5750\u6807\u7cfb\u8f6c\u4e3a\u8f66\u8eab\u5750\u6807\u7cfb\n    calib_data = nusc.get('calibrated_sensor', lidar_file['calibrated_sensor_token'])\n    # \u5c06\u56db\u5143\u7ec4\u8f6c\u4e3a3*3\u7684\u65cb\u8f6c\u77e9\u9635\u683c\u5f0f\n    rot_matrix = Quaternion(calib_data['rotation']).rotation_matrix\n    # \u77e9\u9635\u76f8\u4e58\u4e0e\u504f\u79fb\u91cf\u76f8\u52a0\n    points[:3, :] = np.dot(rot_matrix, points[:3, :])\n    for i in range(3):\n        points[i, :] += calib_data['translation'][i]\n\n    # step2: ego frame -&gt; global frame\n    # \u5c06\u8f66\u8eab\u5750\u6807\u7cfb\u8f6c\u4e3a\u5168\u5c40\u5750\u6807\u7cfb\uff0c\u8fd9\u91cc\u5229\u7528\u96f7\u8fbe\u7684\u4f4d\u59ff\u504f\u79fb\u91cf\u5b9e\u73b0\uff08\u56e0\u4e3a\u6570\u636e\u4ece\u96f7\u8fbe\u5750\u6807\u7cfb\u5f97\u5230\uff09\n    ego_data = nusc.get('ego_pose', lidar_file['ego_pose_token'])\n    rot_matrix = Quaternion(ego_data['rotation']).rotation_matrix\n    points[:3, :] = np.dot(rot_matrix, points[:3, :])\n    for i in range(3):\n        points[i, :] += ego_data['translation'][i]\n\n    # step3: global frame -&gt; ego frame\n    # \u5c06\u5168\u5c40\u5750\u6807\u7cfb\u8f6c\u4e3a\u8f66\u8eab\u5750\u6807\u7cfb\uff0c\u8fd9\u91cc\u5229\u7528\u76f8\u673a\u7684\u4f4d\u59ff\u504f\u79fb\u91cf\u5b9e\u73b0\uff08\u56e0\u4e3a\u6700\u7ec8\u8981\u6295\u5f71\u5230\u56fe\u7247\u4e0a\uff09\n    # \u56e0\u4e3a\u56fe\u50cf\u7684\u65f6\u95f4\u6233\u4e0e\u6fc0\u5149\u7684\u65f6\u95f4\u6233\u4e24\u4e24\u4e0d\u540c\uff0c\u56e0\u6b64\u8981\u505a\u4e00\u6b65\u989d\u5916\u7684\u8f6c\u6362\n    ego_data = nusc.get('ego_pose', camera_data['ego_pose_token'])\n    for i in range(3):\n        points[i, :] -= ego_data['translation'][i]\n    rot_matrix = Quaternion(ego_data['rotation']).rotation_matrix.T\n    points[:3, :] = np.dot(rot_matrix, points[:3, :])\n\n    # step4: ego frame -&gt; cam frame\n    # \u5c06\u8f66\u8eab\u5750\u6807\u7cfb\u8f6c\u4e3a\u76f8\u673a\u5750\u6807\u7cfb\n    calib_data = nusc.get('calibrated_sensor', camera_data['calibrated_sensor_token'])\n    for i in range(3):\n        points[i, :] -= calib_data['translation'][i]\n    rot_matrix = Quaternion(calib_data['rotation']).rotation_matrix.T\n    points[:3, :] = np.dot(rot_matrix, points[:3, :])\n\n    # step5: cam frame -&gt; uv pixel\n    # \u5229\u7528\u5185\u53c2\uff0c\u5c06\u76f8\u673a\u5750\u6807\u7cfb\u4e0b\u4e09\u7ef4\u7684\u5750\u6807\u6570\u636e\u6295\u5f71\u5230\u56fe\u50cf\u5e73\u9762\u4e0a\n    intrinsic = calib_data['camera_intrinsic']\n    trans_mat = np.eye(4)\n    trans_mat[:3, :3] = np.array(intrinsic)\n    points = np.concatenate((points[:3, :], np.ones((1, points.shape[1]))), axis=0)\n    points = np.dot(trans_mat, points)[:3, :]\n    points /= points[2, :]\n\n    # \u8fc7\u6ee4\u76f8\u673a\u540e\u65b9\u70b9\u548c\u8d85\u51fa\u56fe\u50cf\u8fb9\u754c\u7684\u70b9\n    visible = points[2, :] &gt;= 0\n    visible = np.logical_and(visible, points[0, :] &gt;= 0)\n    visible = np.logical_and(visible, points[0, :] &lt; img_w)\n    visible = np.logical_and(visible, points[1, :] &gt;= 0)\n    visible = np.logical_and(visible, points[1, :] &lt; img_h)\n    points = points[:2, :]\n\n    return visible, points.T\n\ndef vis_pointcloud(points, colors=None):\n    \"\"\"\n    \u6e32\u67d3\u663e\u793a\u96f7\u8fbe\u70b9\u4e91\n    :param points:    numpy.ndarray  `N x 3`\n    :param colors:    numpy.ndarray  `N x 3`  (0, 255)\n    :return:\n    \"\"\"\n    app = QApplication(sys.argv)\n    if colors is not None:\n        colors = colors / 255\n        colors = np.hstack((colors, np.ones(shape=(colors.shape[0], 1))))\n    else:\n        colors = (1, 1, 1, 1)\n    og_widget = gl.GLViewWidget()\n    point_size = np.zeros(points.shape[0], dtype=np.float16) + 0.1\n\n    points_item1 = gl.GLScatterPlotItem(pos=points, size=point_size, color=colors, pxMode=False)\n    og_widget.addItem(points_item1)\n\n    og_widget.show()\n    # app.exec_()\n    sys.exit(app.exec_())\n\nLIDAR = \"LIDAR_TOP\"\nnusc = NuScenes(version='v1.0-mini', dataroot='nuScenes(part)', verbose=True)\n\nfor i, scene in enumerate(nusc.scene):\n    # \u5b9a\u4f4d\u7b2c\u51e0\u4e2a\u573a\u666f\n    if i &lt; 9:\n        continue\n    sample = None\n    while True:\n        if sample is None:\n            sample = nusc.get('sample', scene['first_sample_token'])\n        camera_file = dict()\n        data_root = nusc.dataroot\n        # \u83b7\u5f97\u6fc0\u5149\u96f7\u8fbe\u7684\u5404\u79cdtoken\uff0c\u7528\u4e8e\u540e\u7eed\u5b9a\u4f4d\u6fc0\u5149\u96f7\u8fbe\u7684\u6570\u636e\uff0c\u4f8b\u5982\u5916\u53c2\u7684\u65cb\u8f6c\u77e9\u9635\u3001\u4f4d\u59ff\u504f\u79fb\u91cf\n        lidar_file = nusc.get('sample_data', sample['data']['LIDAR_TOP'])\n        # \u83b7\u5f97\u76f8\u673a\u6570\u636e\n        for key in sample['data']:\n            if key.startswith('CAM'):\n                sample_data = nusc.get('sample_data', sample['data'][key])\n                camera_file[sample_data['channel']] = sample_data\n\n        lidar_path = os.path.join(data_root, lidar_file['filename'])\n        lidar_pt_list = np.fromfile(lidar_path, dtype=np.float32).reshape((-1, 5))[:, :4]\n        colors = np.ones(lidar_pt_list[:, :3].shape) * 255\n        count = np.zeros(lidar_pt_list[:, 0].shape)\n        # \u6309\u76f8\u673a\u904d\u5386\uff0c\u4ee5\u524d\u9762\u7684\u76f8\u673a\u4e3a\u8d77\u70b9\uff0c\u987a\u65f6\u9488\u904d\u5386\uff0c\u5229\u7528\u56fe\u50cf\u7ed9\u70b9\u4e91\u4e0a\u8272\n        for camera_type in ['FRONT', 'FRONT_RIGHT', 'BACK_RIGHT', 'BACK', 'BACK_LEFT', 'FRONT_LEFT']:\n            # \u83b7\u5f97\u76f8\u673a\u7684\u5404\u79cdtoken\uff0c\u7528\u4e8e\u540e\u7eed\u5b9a\u4f4d\u76f8\u673a\u7684\u6570\u636e\uff0c\u4f8b\u5982\u5185\u5916\u53c2\u7684\u65cb\u8f6c\u77e9\u9635\u3001\u4f4d\u59ff\u504f\u79fb\u91cf\n            camera_data = camera_file['CAM_{}'.format(camera_type)]\n            # \u539f\u59cb\u56fe\u50cf\n            img_path = os.path.join(data_root, camera_data['filename'])\n            img = cv2.imread(img_path)\n            h, w, _ = img.shape\n            color_in_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            mask, point_in_image = project_lidar2image(nusc, img, lidar_pt_list, lidar_file, camera_data)\n\n            point_in_image_foreground = point_in_image[mask]\n            colors[mask] = color_in_image[point_in_image_foreground[:, 1].astype(np.int32),\n            point_in_image_foreground[:, 0].astype(np.int32)]  # N x 3\n            count[mask] = 1\n        print('\u4e0a\u8272\u70b9\u4e91\u5360\u6bd4:', count.sum() / count.shape[0])\n        vis_pointcloud(points=lidar_pt_list[:, :3], colors=colors)\n        if sample['next'] != '':\n            sample = nusc.get('sample', sample['next'])\n        else:\n            break\n</code></pre> <p>\u521d\u6b65\u5b8c\u7a3f\u4e8e\uff1a2023\u5e747\u670831\u65e5\u3002</p>"},{"location":"auto/PCV/","title":"\u70b9\u4e91\u53ef\u89c6\u5316","text":"<p>\u53c2\u8003\u94fe\u63a5\uff1ahttps://github.com/ZhengXinyue/bilibili_project</p> <p>\u6548\u679c\u56fe\uff1a</p> <p> <p></p> <p></p> <p></p>"},{"location":"auto/PCV/#_2","title":"\u4ee3\u7801","text":"<pre><code>import sys\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport pyqtgraph.opengl as gl\nfrom PyQt5.QtWidgets import QApplication\n\ncmap = plt.cm.jet\n\n\ndef read_bin(bin_path, intensity=False):\n    \"\"\"\n    \u8bfb\u53d6kitti bin\u683c\u5f0f\u6587\u4ef6\u70b9\u4e91\n    :param bin_path:   \u70b9\u4e91\u8def\u5f84\n    :param intensity:  \u662f\u5426\u8981\u5f3a\u5ea6\n    :return:           numpy.ndarray `N x 3` or `N x 4`\n    \"\"\"\n    lidar_points = np.fromfile(bin_path, dtype=np.float32).reshape((-1, 4))\n    if not intensity:\n        lidar_points = lidar_points[:, :3]\n    return lidar_points\n\n\ndef vis_pointcloud(points, colors=None):\n    \"\"\"\n    \u6e32\u67d3\u663e\u793a\u96f7\u8fbe\u70b9\u4e91\n    :param points:    numpy.ndarray  `N x 3`\n    :param colors:    numpy.ndarray  `N x 3`  (0, 255)\n    :return:\n    \"\"\"\n    app = QApplication(sys.argv)\n    if colors is not None:\n        colors = colors / 255\n        colors = np.hstack((colors, np.ones(shape=(colors.shape[0], 1))))\n    else:\n        colors = (1, 1, 1, 1)\n    og_widget = gl.GLViewWidget()\n    point_size = np.zeros(points.shape[0], dtype=np.float16) + 0.1\n\n    points_item1 = gl.GLScatterPlotItem(pos=points, size=point_size, color=colors, pxMode=False)\n    og_widget.addItem(points_item1)\n\n    og_widget.show()\n    sys.exit(app.exec_())\n\n\nif __name__ == '__main__':\n    image_path = '../../KITTI(part)/training/image_2/000052.png'\n    bin_path = '../../KITTI(part)/training/velodyne/000052.bin'\n    # \u8bfb\u53d6\u70b9\u4e91bin\u6570\u636e\n    point_in_lidar = read_bin(bin_path)\n    # \u5b9a\u4e49\u70b9\u4e91\u989c\u8272\uff0c\u9ed8\u8ba4\u767d\u8272\n    colors = np.ones(point_in_lidar.shape) * 255\n    # \u53ef\u89c6\u5316\u64cd\u4f5c\n    vis_pointcloud(points=point_in_lidar, colors=colors)\n</code></pre>"},{"location":"auto/SLAM/SLAM_ch3/","title":"\u4e09\u7ef4\u7a7a\u95f4\u521a\u4f53\u8fd0\u52a8","text":"<p>\u53c2\u8003\u300a\u89c6\u89c9SLAM\u5341\u56db\u8bb2\u300b\uff0c\u9ad8\u7fd4\uff0c\u7b2c3\u7ae0</p>"},{"location":"auto/SLAM/SLAM_ch3/#_2","title":"\u5750\u6807\u7cfb\u4e4b\u95f4\u7684\u6b27\u6c0f\u53d8\u6362","text":"<p>\u2003\u2003\u5728\u673a\u5668\u4eba\u5b66\u4e2d\u5e38\u6709\u4e24\u4e2a\u5750\u6807\u7cfb\uff0c\u4e00\u4e2a\u662f\u60ef\u6027\u5750\u6807\u7cfb\uff08\u6216\u8005\u53eb\u4e16\u754c\u5750\u6807\u7cfb\uff09\uff0c\u53ef\u4ee5\u8ba4\u4e3a\u5b83\u662f\u56fa\u5b9a\u4e0d\u52a8\u7684\uff0c\u53e6\u4e00\u4e2a\u662f\u76f8\u673a\u6216\u8005\u673a\u5668\u4eba\uff0c\u662f\u4e00\u4e2a\u79fb\u52a8\u7684\u5750\u6807\u7cfb\u3002\u4e00\u4e2a\u5e38\u89c1\u7684\u95ee\u9898\u5c31\u662f\uff1a\u76f8\u673a\u89c6\u91ce\u4e2d\u67d0\u4e2a\u5411\u91cfp\uff0c\u5b83\u5728\u76f8\u673a\u5750\u6807\u7cfb\u4e0b\u7684\u5750\u6807\u4e3ap_c\uff0c\u5728\u4e16\u754c\u5750\u6807\u7cfb\u4e0b\u7684\u5750\u6807\u4e3ap_w\uff0cp_c\u4e0ep_w\u5982\u4f55\u8fdb\u884c\u8f6c\u6362\uff1f</p> <p>\u2003\u2003\u5750\u6807\u7cfb\u4e4b\u95f4\u7684\u53d8\u6362\u53ef\u7531\u4e0b\u56fe\u8868\u793a\uff0c\u76f4\u89c2\u6765\u770b\u4e3b\u8981\u7531\u4e24\u4e2a\u90e8\u5206\u7ec4\u6210\uff1a\u2460\u539f\u70b9\u4e4b\u95f4\u7684\u5e73\u79fb\uff1b\u2461\u4e09\u4e2a\u5750\u6807\u8f74\u7684\u65cb\u8f6c\uff1a</p> <p> <p></p> <p></p> <p>\u65cb\u8f6c</p> <p>\u2003\u2003\u8bbe\u67d0\u4e2a\u5355\u4f4d\u6b63\u4ea4\u57fa(e_1,e_2,e_3)\u7ecf\u8fc7\u4e00\u6b21\u65cb\u8f6c\u53d8\u6210\u4e86(e_1',e_2',e_3')\uff0c\u5bf9\u4e8e\u540c\u4e00\u4e2a\u5411\u91cfa\uff0c\u5b83\u5728\u4e24\u4e2a\u5750\u6807\u7cfb\u4e0b\u7684\u5750\u6807\u4e3a[a_1,a_2,a_3]^T\u548c[a_1',a_2',a_3']^T\uff0c\u56e0\u4e3a\u5411\u91cf\u672c\u8eab\u6ca1\u6709\u53d8\uff0c\u6240\u4ee5\u6839\u636e\u5750\u6807\u7684\u5b9a\u4e49\u6709\uff1a $$ [e_1,e_2,e_3] \\begin{bmatrix} a_1\\\\a_2\\\\a_3 \\end{bmatrix} = [e_1',e_2',e_3'] \\begin{bmatrix} a_1'\\\\a_2'\\\\a_3' \\end{bmatrix} $$  \u2003\u2003\u4e3a\u4e86\u63cf\u8ff0\u4e24\u4e2a\u5750\u6807\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5bf9\u4e0a\u8ff0\u7b49\u5f0f\u5de6\u53f3\u4e24\u8fb9\u540c\u65f6\u5de6\u4e58[e_1,e_2,e_3]^T\uff0c\u5219\u7b49\u5f0f\u5de6\u8fb9\u7684\u7cfb\u6570\u5c31\u53d8\u6210\u4e86\u5355\u4f4d\u77e9\u9635\uff0c\u6709\uff1a $$ \\begin{bmatrix} a_1\\\\a_2\\\\a_3 \\end{bmatrix} = \\begin{bmatrix} e^T_1e_1'&amp;e_1^Te_2'&amp;e_1^Te_3'\\\\ e^T_2e_1'&amp;e_2^Te_2'&amp;e_2^Te_3'\\\\ e^T_3e_1'&amp;e_3^Te_2'&amp;e_3^Te_3' \\end{bmatrix} \\begin{bmatrix} a_1'\\\\a_2'\\\\a_3' \\end{bmatrix} = Ra' $$  \u5176\u4e2d\uff0c\u4e2d\u95f4\u7684\u77e9\u9635R\u5c31\u79f0\u4e3a\u65cb\u8f6c\u77e9\u9635\uff0c\u8be5\u77e9\u9635\u7531\u4e24\u7ec4\u57fa\u4e4b\u95f4\u7684\u5185\u79ef\u7ec4\u6210\uff0c\u7531\u4e8e\u57fa\u5411\u91cf\u7684\u957f\u5ea6\u4e3a1\uff0c\u6240\u4ee5\u8be5\u77e9\u9635\u4e0a\u7684\u5143\u7d20\u5b9e\u9645\u4e0a\u662f\u5404\u57fa\u5411\u91cf\u5939\u89d2\u7684\u4f59\u5f26\u503c\uff0c\u6240\u4ee5\u8fd9\u4e2a\u77e9\u9635\u4e5f\u53eb\u65b9\u5411\u4f59\u5f26\u77e9\u9635\u3002</p> <p>\u2003\u2003\u65cb\u8f6c\u77e9\u9635\u8fd8\u6709\u4e00\u4e9b\u7279\u522b\u7684\u6027\u8d28\uff0c\u4e8b\u5b9e\u4e0a\uff0c\u5b83\u662f\u4e00\u4e2a\u884c\u5217\u5f0f\u4e3a1\u7684\u6b63\u4ea4\u77e9\u9635\uff0c\u53cd\u4e4b\uff0c\u884c\u5217\u5f0f\u4e3a1\u7684\u6b63\u4ea4\u77e9\u9635\u4e5f\u662f\u4e00\u4e2a\u65cb\u8f6c\u77e9\u9635\uff0c\u6240\u4ee5\u53ef\u4ee5\u5c06n\u7ef4\u65cb\u8f6c\u77e9\u9635\u7684\u96c6\u5408\u5b9a\u4e49\u4e3a\uff1a $$ SO(n)=\\{R\\in R^{n\\times n}|RR^T=I,det(R)=1\\} $$  \u5176\u4e2dSO(n)\u662f\u7279\u6b8a\u6b63\u4ea4\u7fa4\u7684\u610f\u601d\uff0c\u8fd9\u4e2a\u96c6\u5408\u7531n\u7ef4\u7a7a\u95f4\u7684\u65cb\u8f6c\u77e9\u9635\u7ec4\u6210\uff0cSO(3)\u662f\u6307\u4e09\u7ef4\u7a7a\u95f4\u7684\u65cb\u8f6c\u3002</p> <p>\u2003\u2003\u7279\u522b\u7684\uff0c\u65cb\u8f6c\u77e9\u9635\u7684\u9006\uff08\u7b49\u4e8e\u8f6c\u7f6e\uff09\u63cf\u8ff0\u4e86\u4e00\u4e2a\u76f8\u53cd\u7684\u65cb\u8f6c\uff0c\u5373\u5047\u8bbeR_{12}\u662f\u5750\u6807\u7cfb2\u53d8\u6362\u5230\u5750\u6807\u7cfb1\uff0cR_{21}\u662f\u5750\u6807\u7cfb1\u53d8\u6362\u5230\u5750\u6807\u7cfb2\uff0c\u5219\u5b58\u5728\u5982\u4e0b\u7b49\u5f0f\uff1a $$ R_{12}=R_{21}^{-1}=R_{21}^T $$ \u5e73\u79fb</p> <p>\u2003\u2003\u5e73\u79fb\u53ef\u4ee5\u76f4\u63a5\u901a\u8fc7\u52a0\u4e00\u4e2a\u504f\u79fb\u5411\u91cf\u6765\u5b9e\u73b0\u3002\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u5047\u8bbe\u6709\u5750\u6807\u7cfb1\u3001\u5750\u6807\u7cfb2\uff0c\u90a3\u4e48\u5411\u91cfa\u5728\u4e24\u4e2a\u5750\u6807\u7cfb\u4e0b\u7684\u5750\u6807\u4e3aa_1,a_2\uff0c\u5b83\u4eec\u4e4b\u95f4\u7684\u5173\u7cfb\u4e3a\uff1a $$ a_1=R_{12}a_2+t_{12} $$  \u8fd9\u91cc\u7684R_{12}\u8868\u793a\u628a\u5750\u6807\u7cfb2\u7684\u5411\u91cf\u53d8\u6362\u5230\u5750\u6807\u7cfb1\u4e2d\uff0c\u7531\u4e8e\u5411\u91cf\u4e58\u5728\u65cb\u8f6c\u77e9\u9635\u7684\u53f3\u8fb9\uff0c\u56e0\u6b64\u4e0b\u6807\u4ece\u53f3\u8bfb\u5230\u5de6\u3002\u5bf9\u4e8e\u5e73\u79fb\u5411\u91cft_{12}\uff0c\u5b9e\u9645\u5bf9\u5e94\u7684\u662f\u5750\u6807\u7cfb1\u539f\u70b9\u6307\u5411\u5750\u6807\u7cfb2\u539f\u70b9\u7684\u5411\u91cf\uff0c\u7b80\u79f0\u4e3a\u4ece1\u52302\u7684\u5411\u91cf\u3002</p>"},{"location":"auto/SLAM/SLAM_ch3/#_3","title":"\u53d8\u6362\u77e9\u9635\u4e0e\u9f50\u6b21\u5750\u6807","text":"<p>\u2003\u2003\u5bf9\u4e8e\u53d8\u6362\u5f0fa'=Ra+t\u53ef\u4ee5\u6539\u5199\u6210\uff1a $$ \\begin{bmatrix} a'\\\\1 \\end{bmatrix} = \\begin{bmatrix} R&amp;t\\\\ 0&amp;1 \\end{bmatrix} \\begin{bmatrix} a\\\\1 \\end{bmatrix} = T \\begin{bmatrix} a\\\\1 \\end{bmatrix} $$  \u5728\u4e09\u7ef4\u5411\u91cf\u7684\u672b\u5c3e\u6dfb\u52a01\uff0c\u5c06\u5176\u53d8\u4e3a\u56db\u7ef4\u5411\u91cf\uff0c\u79f0\u4e3a\u9f50\u6b21\u5750\u6807\uff0c\u5bf9\u4e8e\u8be5\u56db\u7ef4\u5411\u91cf\uff0c\u53ef\u4ee5\u628a\u65cb\u8f6c\u548c\u5e73\u79fb\u5199\u5728\u4e00\u4e2a\u77e9\u9635\u91cc\uff0c\u4f7f\u5f97\u6574\u4e2a\u5173\u7cfb\u53d8\u6210\u7ebf\u6027\u5173\u7cfb\uff0cT\u79f0\u4e3a\u53d8\u6362\u77e9\u9635\u3002</p> <p>\u2003\u2003\u5047\u8bbe\u4f7f\u7528\\widetilde a\u8868\u793aa\u7684\u9f50\u6b21\u5750\u6807\uff0c\u90a3\u4e48\u4f9d\u9760\u9f50\u6b21\u5750\u6807\u548c\u53d8\u6362\u77e9\u9635\uff0c\u591a\u6b21\u53d8\u6362\u7684\u53e0\u52a0\u53ef\u4ee5\u9760\u53d8\u6362\u77e9\u9635\u7684\u7d2f\u4e58\u5b9e\u73b0\uff1a $$ \\widetilde b=T_1\\widetilde a,\\widetilde c=T_2 \\widetilde b \\Rightarrow \\widetilde c=T_2T_1\\widetilde a $$  \u6ce8\u610f\u987a\u5e8f\uff0c\u65cb\u8f6c\u77e9\u9635\u4e3a\u5de6\u4e58\uff0c\u56e0\u6b64\u53e0\u52a0\u987a\u5e8f\u4e3a\u4ece\u5de6\u5411\u53f3\u3002</p> <p>\u2003\u2003\u5bf9\u4e8e\u53cd\u53d8\u6362\uff0c\u5219\u540c\u6837\u53ef\u4ee5\u901a\u8fc7\u53d6\u9006\u5b9e\u73b0\uff1a $$ T_{21}=T^{-1}_{12}=\\begin{bmatrix} R^T&amp;-R^Tt\\\\ 0&amp;1 \\end{bmatrix} $$  \u2003\u2003\u5bf9\u4e8e\u53d8\u6362\u77e9\u9635T\uff0c\u8fd9\u79cd\u77e9\u9635\u53c8\u79f0\u4e3a\u7279\u6b8a\u6b27\u5f0f\u7fa4\uff1a $$ SE(3)= \\left\\{ T=\\begin{bmatrix} R&amp;t\\\\ 0&amp;1 \\end{bmatrix} \\in R^{4\\times4}|R\\in SO(3),t\\in R^3 \\right\\} $$ </p>"},{"location":"auto/SLAM/SLAM_ch3/#_4","title":"\u65cb\u8f6c\u5411\u91cf\u548c\u6b27\u62c9\u89d2","text":"<p>\u65cb\u8f6c\u5411\u91cf</p> <p>\u2003\u2003\u5229\u7528\u77e9\u9635\u7684\u65b9\u5f0f\u8868\u793a\u7269\u4f53\u7684\u65cb\u8f6c\u53d8\u6362\u6709\u4e24\u4e2a\u7f3a\u70b9\uff1a</p> <ul> <li>SO(3)\u7684\u65cb\u8f6c\u77e9\u9635\u67099\u4e2a\u91cf\uff0c\u4f46\u4e00\u6b21\u65cb\u8f6c\u53ea\u67093\u4e2a\u81ea\u7531\u5ea6\uff0c\u56e0\u6b64\u8fd9\u79cd\u8868\u793a\u65b9\u6cd5\u662f\u5197\u4f59\u7684\uff0c\u540c\u7406\uff0c\u53d8\u6362\u77e9\u9635\u752816\u4e2a\u91cf\u6765\u8868\u8fbe6\u4e2a\u81ea\u7531\u5ea6\u7684\u53d8\u6362\u4e5f\u662f\u6bd4\u8f83\u5197\u4f59\u7684\uff0c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u7b80\u5316\u3001\u7d27\u51d1\u4e00\u4e9b\uff1b</li> <li>\u65cb\u8f6c\u77e9\u9635\u81ea\u8eab\u5e26\u6709\u7ea6\u675f\uff1a\u5b83\u5fc5\u987b\u662f\u4e2a\u6b63\u4ea4\u77e9\u9635\uff0c\u4e14\u884c\u5217\u5f0f\u4e3a1\uff0c\u53d8\u6362\u77e9\u9635\u4e5f\u662f\u5982\u6b64\uff0c\u5f53\u6211\u4eec\u4f30\u8ba1\u6216\u8005\u4f18\u5316\u4e00\u4e2a\u65cb\u8f6c\u77e9\u9635\u6216\u53d8\u6362\u77e9\u9635\u65f6\uff0c\u8fd9\u4e9b\u7ea6\u675f\u4f1a\u4f7f\u5f97\u6c42\u89e3\u53d8\u5f97\u66f4\u52a0\u56f0\u96be\u3002</li> </ul> <p>\u2003\u2003\u4e8b\u5b9e\u4e0a\uff0c\u4efb\u4f55\u65cb\u8f6c\u90fd\u53ef\u4ee5\u7528\u4e00\u4e2a\u65cb\u8f6c\u8f74\u548c\u4e00\u4e2a\u65cb\u8f6c\u89d2\u6765\u8868\u793a\uff0c\u5177\u4f53\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u56e0\u6b64\u53ef\u4ee5\u4f7f\u7528\u4e00\u4e2a\u5355\u4f4d\u957f\u5ea6\u7684\u5411\u91cfn\u6765\u8868\u793a\u65cb\u8f6c\u8f74\uff08\u5373\u65cb\u8f6c\u8f74\u7684\u65b9\u5411\u5411\u91cf\uff09\uff0c\u8fd9\u79cd\u5411\u91cf\u79f0\u4e3a\u65cb\u8f6c\u5411\u91cf\uff0c\u5229\u7528\u89d2\u5ea6\\theta\u6765\u8868\u793a\u65cb\u8f6c\u89d2\uff0c\u53ef\u4ee5\u7528\u5411\u91cf\\theta n\u6765\u63cf\u8ff0\u8fd9\u4e2a\u65cb\u8f6c\u3002\u7531\u7f57\u5fb7\u91cc\u683c\u65af\u516c\u5f0f\u53ef\u4ee5\u5f97\u5230\uff0c\u65cb\u8f6c\u77e9\u9635R\u548cn\u3001\\theta\u7684\u5173\u7cfb\u4e3a\uff1a $$ R=cos\\theta I+(1-cos\\theta)nn^T+sin\\theta n^\\wedge $$  \u5176\u4e2dI\u8868\u793a\u5355\u4f4d\u77e9\u9635\uff0c\\wedge\u8868\u793a\u5411\u91cf\u5230\u53cd\u5bf9\u79f0\u77e9\u9635\u7684\u8f6c\u6362\u7b26\uff0c\u4e24\u8fb9\u53d6\u8ff9\u53ef\u4ee5\u5f97\u5230\uff1a $$ \\theta=arccos\\frac{tr(R)-1}{2} $$  \u5bf9\u4e8e\u8f6c\u8f74n\uff0c\u65cb\u8f6c\u8f74\u4e0a\u7684\u5411\u91cf\u5728\u65cb\u8f6c\u540e\u4e0d\u53d1\u751f\u6539\u53d8\uff0c\u5219\u6709\uff1a $$ Rn=n $$  \u56e0\u6b64\uff0c\u8f6c\u8f74n\u662f\u65cb\u8f6c\u77e9\u9635R\u7279\u5f81\u503c1\u5bf9\u5e94\u7684\u7279\u5f81\u5411\u91cf\uff0c\u6c42\u89e3\u6b21\u65b9\u7a0b\uff0c\u518d\u5f52\u4e00\u5316\u53ef\u5f97\u5230\u65cb\u8f6c\u8f74n\u3002</p> <p>\u6b27\u62c9\u89d2</p> <p>\u2003\u2003\u5bf9\u4e8e\u4e00\u6b21\u65cb\u8f6c\uff0c\u53ef\u4ee5\u5c06\u5176\u5206\u89e3\u4e3a3\u4e2a\u5206\u79bb\u7684\u8f6c\u89d2\uff0c\u5373\u5206\u89e3\u62103\u6b21\u7ed5\u4e0d\u540c\u8f74\u7684\u65cb\u8f6c\uff0c\u5206\u522b\u79f0\u4e3a\uff1a\u504f\u822a-\u4fef\u4ef0-\u6eda\u8f6c\uff0c\u8fd9\u6837\u7406\u89e3\u8d77\u6765\u6bd4\u8f83\u76f4\u89c2\uff1a</p> <ul> <li>\u7ed5\u7269\u4f53\u7684Z\u8f74\u65cb\u8f6c\uff0c\u5f97\u5230\u504f\u822a\u89d2yaw\uff1b</li> <li>\u7ed5\u7269\u4f53\u7684Y\u8f74\u65cb\u8f6c\uff0c\u5f97\u5230\u4fef\u4ef0\u89d2pitch\uff1b</li> <li>\u7ed5\u7269\u4f53\u7684X\u8f74\u65cb\u8f6c\uff0c\u5f97\u5230\u6eda\u8f6c\u89d2roll\uff1b</li> </ul> <p> <p></p> <p></p> <p>\u2003\u2003\u5229\u7528\u6b27\u62c9\u89d2\u8868\u793a\u65cb\u8f6c\u64cd\u4f5c\u6700\u5927\u7684\u95ee\u9898\u5c31\u662f\u4f1a\u78b0\u5230\u4e07\u5411\u9501\u95ee\u9898\uff1a\u5728\u4fef\u4ef0\u89d2\u4e3a\\pm90\u00b0\u65f6\uff0c\u7b2c\u4e00\u6b21\u65cb\u8f6c\u4e0e\u7b2c\u4e09\u6b21\u65cb\u8f6c\u4f7f\u7528\u540c\u4e00\u4e2a\u8f74\uff0c\u5177\u4f53\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u7406\u8bba\u4e0a\uff0c\u53ea\u8981\u60f3\u75283\u4e2a\u5b9e\u6570\u6765\u8868\u8fbe\u4e09\u7ef4\u65cb\u8f6c\uff0c\u90fd\u4f1a\u4e0d\u53ef\u907f\u514d\u5730\u78b0\u5230\u5947\u5f02\u6027\u95ee\u9898\u3002\u7531\u4e8e\u8fd9\u79cd\u5c40\u9650\u6027\uff0c\u6b27\u62c9\u89d2\u7684\u4e0d\u9002\u7528\u4e8e\u63d2\u503c\u548c\u8fed\u4ee3\uff0c\u53ea\u9002\u7528\u4e8e\u4eba\u673a\u4ea4\u4e92\uff08\u76f4\u89c2\u5730\u8868\u793a\u4e00\u4e2a\u65cb\u8f6c\u8fc7\u7a0b\uff09\u3002</p>"},{"location":"auto/SLAM/SLAM_ch3/#_5","title":"\u56db\u5143\u6570","text":"<p>\u2003\u2003\u56db\u5143\u6570\u662f\u4e00\u79cd\u6269\u5c55\u7684\u590d\u6570\uff0c\u76f8\u6bd4\u4e8e\u666e\u901a\u7684\u590d\u6570\uff08a+bi\uff09\uff0c\u56db\u5143\u6570\u6709\u4e09\u4e2a\u865a\u90e8\uff0c\u53ef\u4ee5\u5229\u7528\u5355\u4f4d\u56db\u5143\u6570\u8868\u8fbe\u4e09\u7ef4\u7a7a\u95f4\u4e2d\u7684\u65cb\u8f6c\uff1a $$ q=q_0+q_1i+q_2j+q_3k $$  \u5176\u4e2d\uff0ci,j,k\u4e3a\u56db\u5143\u6570\u7684\u4e09\u4e2a\u865a\u90e8\uff0c\u6ee1\u8db3\u4ee5\u4e0b\u5173\u7cfb\uff1a $$ \\left\\{ \\begin{matrix} i^2=j^2=k^2=-1\\\\ ij=k,ji=-k\\\\ jk=i,kj=-i\\\\ ki=j,ik=-j \\end{matrix} \\right. $$  \u6709\u65f6\u4e5f\u7528\u4e00\u4e2a\u6807\u91cf\u548c\u4e00\u4e2a\u5411\u91cf\u6765\u8868\u8fbe\u56db\u5143\u6570\uff1a $$ q=[s,v]^T,s=q_0\\in R,v=[q_1,q_2,q_3]^T\\in R^3 $$  \u5229\u7528\u56db\u4f4d\u6570\u8868\u793a\u65cb\u8f6c\u65e2\u662f\u7d27\u51d1\u7684\uff0c\u4e5f\u6ca1\u6709\u5947\u5f02\u6027\u3002</p> <p>\u56db\u5143\u6570\u7684\u8fd0\u7b97</p> <ul> <li> <p>\u52a0\u51cf\u4e58\u6cd5\u3001\u6570\u4e58\u3001\u70b9\u4e58\u3001\u6a21\u957f\u4e0e\u666e\u901a\u7684\u865a\u6570\u8fd0\u7b97\u4e00\u6837\uff1b</p> </li> <li> <p>\u5171\u8f6d\uff1aq^*_a=s_a-x_ai-y_aj-z_ak=[s_a,-v_a]^T</p> </li> <li>\u9006\uff1aq^{-1}=q^*/||q||^2\uff0c\u5e76\u4e14\u6709(q_aq_b)^{-1}=q_b^{-1}q_a^{-1}</li> </ul>"},{"location":"auto/SLAM/SLAM_ch3/#_6","title":"\u56db\u5143\u6570\u8868\u793a\u65cb\u8f6c","text":"<p>\u2003\u2003\u5047\u8bbe\u4e00\u4e2a\u7a7a\u95f4\u4e09\u7ef4\u70b9p=[x,y,z]\\in R^3\uff0c\u4ee5\u53ca\u4e00\u4e2a\u7531\u5355\u4f4d\u56db\u5143\u6570q\u6307\u5b9a\u7684\u65cb\u8f6c\uff0c\u4e09\u7ef4\u70b9p\u7ecf\u8fc7\u65cb\u8f6c\u5f97\u5230p'\uff0c\u5148\u5c06p\u7684\u5750\u6807\u7528\u865a\u56db\u5143\u6570\u8868\u793a\uff1ap=[0,x,y,z]=[0,v]\uff0c\u65cb\u8f6c\u4e4b\u540e\u7684\u5173\u7cfb\u4e3a\uff1a $$ p'=qpq^{-1} $$  \u5bb9\u6613\u9a8c\u8bc1\uff0c\u6240\u5f97\u7684p'\u4e5f\u662f\u865a\u56db\u5143\u6570\uff0c\u628a\u865a\u90e8\u53d6\u51fa\u5c31\u5f97\u5230\u4e86\u65cb\u8f6c\u4e4b\u540e\u7684\u5750\u6807\u3002</p> <p>\u56db\u5143\u6570\u548c\u5176\u4ed6\u65cb\u8f6c\u8868\u793a\u7684\u8f6c\u6362</p> <p>\u89d2\u8f74(n,\\theta)\u5230\u56db\u5143\u6570q\uff1a $$ q=[cos\\frac\\theta 2,n_xsin\\frac\\theta2,n_ysin\\frac\\theta2,n_zsin\\frac\\theta2]^T $$  \u56db\u5143\u6570q\u5230\u89d2\u8f74(n,\\theta)\uff1a $$ \\left\\{ \\begin{matrix} \\theta=2arccosq_0\\\\ [n_x,n_y,n_z]^T=[q_1,q_2,q_3]^T/sin\\frac\\theta2 \\end{matrix} \\right. $$  \u65cb\u8f6c\u77e9\u9635R={m_{ij}}\u5230\u56db\u5143\u6570q\uff1a</p> <p> $$ q_0=\\frac{\\sqrt{tr(R)+1}}{2},q_1=\\frac{m_{23}-m_{32}}{4q_0}\\\\ q_2=\\frac{m_{31}-m_{13}}{4q_0},q_3=\\frac{m_{12}-m_{21}}{4q_0} $$  \u56db\u5143\u6570q\u5230\u65cb\u8f6c\u77e9\u9635R=m_{ij}\uff1a $$ R= \\begin{bmatrix} 1-2q_2^2-2q_3^2&amp;2q_1q_2+2q_0q_3&amp;2q_1q_3-2q_0q_2\\\\ 2q_1q_2-2q_0q_3&amp;1-2q_1^2-2q_3^2&amp;2q_2q_3+2q_0q_1\\\\ 2q_1q_3+2q_0q_2&amp;2q_2q_3-2q_0q_1&amp;1-2q_1^2-2q_2^2 \\end{bmatrix} $$  \u7a0b\u5e8f</p> <pre><code>from pyquaternion import Quaternion\n# \u5c06\u56db\u5143\u6570\u8f6c\u4e3a\u65cb\u8f6c\u77e9\u9635R\uff0c\u4fbf\u4e8e\u540e\u7eed\u6267\u884cRx+t\uff0c\u505a\u65cb\u8f6c\u53d8\u6362\nrot_matrix = Quaternion(calib_data['rotation']).rotation_matrix\n</code></pre> <p>\u521d\u6b65\u5b8c\u7a3f\u4e8e\uff1a2023\u5e748\u67081\u65e5</p>"},{"location":"auto/paper/BEVFormer/","title":"BEVFormer\u2014\u2014\u8bba\u6587\u7b14\u8bb0","text":""},{"location":"auto/paper/BEVFormer/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aECCV 2022</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://arxiv.org/pdf/2203.17270v2.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/fundamentalvision/BEVFormer</p>"},{"location":"auto/paper/BEVFormer/#_2","title":"\u4e3b\u8981\u601d\u60f3","text":"<p> 3D\u7a7a\u95f4\u611f\u77e5\u5bf9\u4e8e\u81ea\u52a8\u9a7e\u9a76\u3001\u673a\u5668\u4eba\u7b49\u5404\u79cd\u5e94\u7528\u81f3\u5173\u91cd\u8981\uff0c\u5c3d\u7ba1\u5bf9\u4e8e\u6fc0\u5149\u96f7\u8fbe\u7684\u65b9\u6cd5\u53d6\u5f97\u4e86\u663e\u8457\u7684\u8fdb\u5c55\uff0c\u53ef\u4ee5\u5f88\u597d\u5730\u7528\u4e8e\u611f\u77e5\u7269\u4f53\u7684\u6df1\u5ea6\u4fe1\u606f\uff0c\u4f46\u662f\u76f8\u673a\u5728\u611f\u77e5\u4efb\u52a1\u4e2d\u6240\u627f\u62c5\u7684\u89d2\u8272\u540c\u6837\u4e5f\u5f88\u91cd\u8981\uff0c\u56e0\u4e3a\u5176\u90e8\u7f72\u6210\u672c\u4f4e\uff0c\u5e76\u4e14\u76f8\u673a\u6355\u83b7\u7684\u56fe\u7247\u53ef\u4ee5\u7528\u4e8e\u68c0\u6d4b\u8fdc\u8ddd\u79bb\u7269\u4f53\u3001\u8bc6\u522b\u57fa\u4e8e\u89c6\u89c9\u7684\u9053\u8def\u5143\u7d20\uff08\u4f8b\u5982\u4ea4\u901a\u4fe1\u53f7\u706f\u3001\u505c\u8f66\u7ebf\uff09\u7b49\u7b49\u3002\u5728\u81ea\u52a8\u9a7e\u9a76\u4efb\u52a1\u4e2d\uff0c\u5e38\u89c1\u7684\u505a\u6cd5\u662f\u4ece\u591a\u4e2a\u6444\u50cf\u5934\u7ed9\u51fa\u7684\u4e8c\u7ef4\u56fe\u50cf\u6765\u611f\u77e5\u73b0\u5b9e\u7684\u4e09\u7ef4\u4e16\u754c\uff0c\u4ece\u800c\u5b8c\u62103D\u76ee\u6807\u68c0\u6d4b\u6216\u8005\u5730\u56fe\u5206\u5272\u7b49\u4efb\u52a1\uff0c\u8fd9\u7c7b\u7b97\u6cd5\u8bbe\u8ba1\u8fc7\u7a0b\u6700\u91cd\u8981\u7684\u5c31\u662f\u8981\u8003\u8651\u5982\u4f55\u5b9e\u73b0\u8de8\u76f8\u673a\u7684\u4fe1\u606f\u4ea4\u4e92\uff0c\u4ece\u591a\u4e2a\u76f8\u673a\u63d0\u53d6\u6574\u4f53\u7684\u7279\u5f81\u8868\u793a\uff0c\u968f\u7740Transformer\u3001\u6ce8\u610f\u529b\u673a\u5236\u5728\u89c6\u89c9\u4e0a\u7684\u666e\u53ca\u5e94\u7528\uff0c\u8fd9\u4e00\u8fc7\u7a0b\u9010\u6e10\u53ef\u4ee5\u88ab\u5f88\u597d\u5730\u5b9e\u73b0\u3002</p> <p>\u2003\u2003\u9e1f\u77b0\u56fe\uff08bird-eye-view, BEV\uff09\u662f\u4e00\u79cd\u5e38\u7528\u4e8e\u5468\u56f4\u573a\u666f\u8868\u793a\u7684\u65b9\u6cd5\uff0c\u56e0\u4e3a\u4ed6\u53ef\u4ee5\u6e05\u6670\u5730\u5448\u73b0\u7269\u4f53\u7684\u4f4d\u7f6e\u548c\u89c4\u6a21\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u81ea\u52a8\u9a7e\u9a76\u4efb\u52a1\uff0c\u867d\u7136\u4ee5\u524d\u7684\u5730\u56fe\u5206\u5272\u65b9\u6cd5\u8bc1\u660e\u4e86BEV\u7684\u6709\u6548\u6027\uff0c\u4f46\u662f\u57fa\u4e8eBEV\u7684\u65b9\u6cd5\u57283D\u76ee\u6807\u68c0\u6d4b\u4e2d\u5e76\u4e0d\u80fd\u4f53\u73b0\u5f88\u597d\u5730\u68c0\u6d4b\u6027\u80fd\uff0c\u6839\u672c\u539f\u56e0\u5c31\u662f\u96be\u4ee5\u51c6\u786e\u5730\u5b9e\u73b0\u4ece2D\u5e73\u9762\u5230BEV\u7279\u5f81\u7684\u6620\u5c04\uff0c\u5373\u65e0\u6cd5\u5f88\u597d\u5730\u89e3\u51b3\u8de8\u76f8\u673a\u4fe1\u606f\u4ea4\u4e92\u7684\u95ee\u9898\uff0c\u65e0\u6cd5\u751f\u6210\u51c6\u786e\u7684BEV\u7279\u5f81\u3002\u8fd8\u6709\u4e00\u79cd\u65b9\u6cd5\u5c31\u662f\u57fa\u4e8e\u6df1\u5ea6\u4fe1\u606f\u6765\u751f\u6210BEV\u7279\u5f81\uff0c\u8fd9\u7c7b\u65b9\u6cd5\u5bf9\u4e8e\u6df1\u5ea6\u6570\u503c\u548c\u6df1\u5ea6\u5206\u5e03\u7684\u51c6\u786e\u6027\u5f88\u654f\u611f\uff0cBEV\u7684\u7279\u5f81\u8868\u793a\u5bb9\u6613\u53d7\u5230\u590d\u5408\u8bef\u5dee\u7684\u5f71\u54cd\uff08\u539f\u6587\u76f4\u63a5\u7ffb\u8bd1\u7684\uff09\u3002\u4e0d\u51c6\u786e\u7684\u7684BEV\u7279\u5f81\u4f1a\u4e25\u91cd\u5f71\u54cd\u4e0b\u6e38\u4efb\u52a1\u7684\u6027\u80fd\u3002\u7531\u4e8eTransformer\u4e2d\u4f7f\u7528\u4e86\u6ce8\u610f\u529b\u673a\u5236\uff0c\u53ef\u4ee5\u52a8\u6001\u5730\u805a\u5408\u6709\u4ef7\u503c\u7684\u7279\u5f81\uff0c\u56e0\u6b64\u4f5c\u8005\u57fa\u4e8eTF\u6a21\u5757\u8bbe\u8ba1\u4e86\u4e00\u6b3e\u4e0d\u4f9d\u8d56\u6df1\u5ea6\u4fe1\u606f\u7684BEV\u7279\u5f81\u751f\u6210\u7b97\u6cd5\uff0c\u53ef\u4ee5\u81ea\u9002\u5e94\u5b66\u4e60BEV\u7279\u5f81\u3002</p> <p>\u8fd9\u91cc\u63d0\u5230\u7684\u590d\u5408\u8bef\u5dee\u6307\u7684\u662f\u4ec0\u4e48\uff1f</p> <p> BEV\u7279\u5f81\u662f\u8fde\u63a5\u65f6\u95f4\u548c\u7a7a\u95f4\u7684\u7406\u60f3\u6865\u6881\uff0c\u8fd9\u4e5f\u662f\u81ea\u52a8\u9a7e\u9a76\u4efb\u52a1\u4e2d\u4f7f\u7528BEV\u7279\u5f81\u6267\u884c\u611f\u77e5\u4efb\u52a1\u7684\u53e6\u4e00\u4e2a\u52a8\u673a\u3002\u5bf9\u4e8e\u4eba\u7c7b\u7684\u89c6\u89c9\u611f\u77e5\u7cfb\u7edf\u800c\u8a00\uff0c\u65f6\u95f4\u4fe1\u606f\u5728\u63a8\u7406\u7269\u4f53\u7684\u8fd0\u52a8\u72b6\u6001\u548c\u8bc6\u522b\u88ab\u906e\u6321\u7684\u7269\u4f53\u65b9\u9762\u8d77\u7740\u81f3\u5173\u91cd\u8981\u7684\u4f5c\u7528\uff0c\u8bb8\u591a\u89c6\u89c9\u9886\u57df\u7684\u5de5\u4f5c\u5df2\u7ecf\u8bc1\u660e\u4e86\u4f7f\u7528\u89c6\u9891\u6570\u636e\u7684\u6709\u6548\u6027\u3002\u7136\u800c\uff0c\u73b0\u6709\u57fa\u4e8e\u591a\u6444\u50cf\u5934\u76843D\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u5f88\u5c11\u5229\u7528\u65f6\u95f4\u4fe1\u606f\uff0c\u5728\u81ea\u52a8\u9a7e\u9a76\u4efb\u52a1\u4e2d\uff0c\u573a\u666f\u7269\u4f53\u53d8\u5316\u5f88\u5feb\uff0c\u7b80\u5355\u5730\u53e0\u52a0\u8de8\u65f6\u95f4\u6233\u7684BEV\u7279\u5f81\u4f1a\u5e26\u6765\u989d\u5916\u7684\u8ba1\u7b97\u6210\u672c\u548c\u5e72\u6270\u4fe1\u606f\u3002\u53d7\u9012\u5f52\u795e\u7ecf\u7f51\u7edc\uff08RNN\uff09\u7684\u542f\u53d1\uff0c\u4f5c\u8005\u5229\u7528BEV\u7279\u5f81\u9012\u5f52\u5730\u4f20\u9012\u4ece\u8fc7\u53bb\u5230\u73b0\u5728\u7684\u65f6\u95f4\u4fe1\u606f\uff0c\u8fd9\u4e0eRNN\u6a21\u578b\u7684\u9690\u85cf\u72b6\u6001\u5177\u6709\u76f8\u540c\u7684\u601d\u60f3\u3002</p> <p>\u2003\u2003\u7efc\u4e0a\u6240\u8ff0\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eTransformer\u7684BEV\u7f16\u7801\u5668\uff0c\u79f0\u4e3aBEVFormer\uff0c\u5b83\u53ef\u4ee5\u6709\u6548\u5730\u805a\u5408\u6765\u81ea\u591a\u89c6\u56fe\u76f8\u673a\u7684\u65f6\u7a7a\u7279\u5f81\u548c\u5386\u53f2BEV\u7279\u5f81\uff0c\u7531BEVFormer\u751f\u6210\u7684BEV\u7279\u5f81\u53ef\u4ee5\u652f\u6301\u591a\u79cd3D\u611f\u77e5\u4efb\u52a1\uff0c\u59823D\u76ee\u6807\u68c0\u6d4b\u3001\u5730\u56fe\u5206\u5272\u7b49\u7b49\u3002\u7b97\u6cd5\u5305\u62ec\u4e09\u4e2a\u5173\u952e\u7684\u8bbe\u8ba1\uff1a\u2460\u7f51\u683c\u72b6BEV\u67e5\u8be2\u5411\u91cf\uff08grid-shaped BEV queries\uff09\uff0c\u529f\u80fd\u7c7b\u4f3ctokens\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u7075\u6d3b\u5730\u878d\u5408\u65f6\u95f4\u548c\u7a7a\u95f4\u4fe1\u606f\uff08\u67e5\u8be2\u5411\u91cf\u4e3a\u4e00\u7ec4\u53ef\u5b66\u4e60\u7684\u53c2\u6570\uff09\uff1b\u2461\u7a7a\u95f4\u4ea4\u53c9\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u7528\u4e8e\u4ece\u591a\u4e2a\u76f8\u673a\u56fe\u50cf\u4e2d\u805a\u5408\u7a7a\u95f4\u7279\u5f81\uff1b\u2462\u65f6\u95f4\u81ea\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u4ece\u5386\u53f2BEV\u7279\u5f81\u4e2d\u63d0\u53d6\u65f6\u95f4\u4fe1\u606f\uff0c\u6709\u5229\u4e8e\u8fd0\u52a8\u76ee\u6807\u7684\u901f\u5ea6\u4f30\u8ba1\u548c\u4e25\u91cd\u906e\u6321\u7269\u4f53\u7684\u76ee\u6807\u68c0\u6d4b\u3002\u501f\u52a9BEVFormer\u751f\u6210\u7684\u7edf\u4e00\u7279\u5f81\uff0c\u8be5\u6a21\u578b\u53ef\u4ee5\u4e0e\u4e0d\u540c\u7684\u4efb\u52a1\u5934\u534f\u4f5c\uff0c\u4ece\u800c\u5b8c\u6210\u5404\u79cd\u7aef\u5230\u7aef\u7684\u73af\u5883\u611f\u77e5\u4efb\u52a1\u3002</p>"},{"location":"auto/paper/BEVFormer/#_3","title":"\u65b9\u6cd5","text":"<p>\u2003\u2003BEVFormer\u6574\u4f53\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u5171\u6709\u516d\u5c42\u7f16\u7801\u5668\uff0c\u4e0e\u4f20\u7edfTransformer\u7ed3\u6784\u4e0d\u540c\uff0c\u8fd9\u91cc\u65b0\u5f15\u5165\u4e86BEV\u67e5\u8be2\u5411\u91cf\u3001\u7a7a\u95f4\u4ea4\u53c9\u6ce8\u610f\u529b\u548c\u65f6\u95f4\u81ea\u6ce8\u610f\u529b\u3002\u5177\u4f53\u5730\u6765\u8bf4\uff0cBEV\u67e5\u8be2\u5411\u91cf\u662f\u7f51\u683c\u72b6\u7684\u53ef\u5b66\u4e60\u53c2\u6570\uff0c\u65e8\u5728\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u4ece\u591a\u6444\u50cf\u5934\u89c6\u56fe\u4e2d\u67e5\u8be2BEV\u7a7a\u95f4\u4e2d\u7684\u7279\u5f81\uff1b\u7a7a\u95f4\u4ea4\u53c9\u6ce8\u610f\u529b\u548c\u65f6\u95f4\u81ea\u6ce8\u610f\u529b\u7528\u4e8e\u6839\u636eBEV\u67e5\u8be2\u6765\u67e5\u627e\u548c\u805a\u5408\u6765\u81ea\u591a\u76f8\u673a\u7684\u7a7a\u95f4\u7279\u5f81\u3001\u6765\u81ea\u5386\u53f2BEV\u7684\u65f6\u95f4\u7279\u5f81\u3002</p> <p> <p></p> <p></p> <p>\u2003\u2003\u63a8\u7406\u9636\u6bb5\uff0c\u5728\u65f6\u95f4\u6b65t\u4e2d\uff0c\u6211\u4eec\u5c06\u591a\u76f8\u673a\u6240\u62cd\u6444\u7684\u56fe\u50cf\u4f20\u5165backbone\u4e2d\uff08\u4f8b\u5982ResNet101\uff09\uff0c\u83b7\u5f97\u4e0d\u540c\u76f8\u673a\u89c6\u89d2\u4e0b\u7684\u56fe\u50cf\u7279\u5f81F_t=\\{F^i_t\\}^{N_{view}}_{i=1}\uff0c\u5176\u4e2di\u548cN_{view}\u5206\u522b\u8868\u793a\u76f8\u673a\u5e8f\u53f7\u548c\u76f8\u673a\u4e2a\u6570\uff0c\u540c\u65f6\uff0c\u6211\u4eec\u4fdd\u7559\u4e86\u524d\u4e00\u65f6\u95f4\u6233t-1\u7684BEV\u7279\u5f81B_{t-1}\u4f5c\u4e3a\u56fe\u50cf\u5148\u9a8c\uff0c\u5728\u6bcf\u4e2a\u7f16\u7801\u5668\u5c42\uff0c\u6211\u4eec\u9996\u5148\u4f7f\u7528BEV\u67e5\u8be2\u5411\u91cfQ\uff0c\u901a\u8fc7\u65f6\u95f4\u81ea\u6ce8\u610f\u529b\u4eceB_{t-1}\u4e2d\u67e5\u8be2\u65f6\u95f4\u4fe1\u606f\uff0c\u4e4b\u540e\u4f7f\u7528BEV\u67e5\u8be2\u5411\u91cfQ\uff0c\u901a\u8fc7\u7a7a\u95f4\u4ea4\u53c9\u6ce8\u610f\u529b\u4ece\u591a\u4e2a\u76f8\u673a\u7279\u5f81F_t\u4e2d\u67e5\u8be2\u7a7a\u95f4\u4fe1\u606f\uff0c\u6700\u540e\u4f20\u5165\u524d\u9988\u7f51\u7edc\uff0c\u8f93\u51fa\u7ec6\u5316\u540e\u7684BEV\u7279\u5f81\uff0c\u4f5c\u4e3a\u4e0b\u4e00\u7f16\u7801\u5668\u5c42\u7684\u8f93\u5165\u3002\u7ecf\u8fc76\u5c42\u7f16\u7801\u5668\u7684\u53e0\u52a0\u8fd0\u7b97\uff0cBEV\u67e5\u8be2\u5411\u91cf\u4f1a\u7ecf\u8fc7\u65f6\u7a7a\u4fe1\u606f\u7684\u4ea4\u66ff\u4f18\u5316\u8868\u793a\uff0c\u6700\u7ec8\u4f1a\u751f\u6210\u5f53\u524d\u65f6\u95f4\u6233t\u4e0b\u7edf\u4e00\u7684BEV\u7279\u5f81B_t\uff0c\u4ee5BEV\u7279\u5f81B_t\u4f5c\u4e3a\u8f93\u5165\uff0c3D\u68c0\u6d4b\u5934\u548c\u5730\u56fe\u5206\u5272\u5934\u53ef\u4ee5\u5bf93D\u8fb9\u754c\u6846\u548c\u5730\u56fe\u7b49\u611f\u77e5\u7ed3\u679c\u8fdb\u884c\u9884\u6d4b\u3002</p> <p>\u6ce8\uff1a\u4e24\u6b21\u6ce8\u610f\u529b\u5747\u4ee5BEV\u67e5\u8be2\u5411\u91cf\u4e3a\u4e2d\u5fc3\uff0c\u878d\u5408\u5386\u53f2BEV\u7279\u5f81\u548c\u591a\u4e2a\u89c6\u89d2\u7684\u56fe\u50cf\u7279\u5f81\u3002</p>"},{"location":"auto/paper/BEVFormer/#bev","title":"BEV\u67e5\u8be2\u5411\u91cf","text":"<p>\u2003\u2003\u4f5c\u8005\u9996\u5148\u9884\u5b9a\u4e49\u4e86\u4e00\u7ec4\u7f51\u683c\u578b\u53ef\u5b66\u4e60\u7684\u53c2\u6570Q\\in R^{H\\times W\\times C}\u4f5c\u4e3aBEVFormer\u7684\u67e5\u8be2\u5411\u91cf\uff0c\u5176\u4e2dH,W\u4e3aBEV\u5e73\u9762\u7684\u7a7a\u95f4\u5f62\u72b6\uff0c\u5177\u4f53\u5730\u6765\u8bf4\uff0c\u4f4d\u4e8eQ\u4e2dp=(x,y)\u7684\u67e5\u8be2\u5411\u91cfQ_p\\in R^{1\\times C}\u8d1f\u8d23\u8868\u793aBEV\u5e73\u9762\u4e2d\u76f8\u5e94\u7684\u7f51\u683c\u5355\u5143\u533a\u57df\uff0cBEV\u5e73\u9762\u4e2d\u7684\u6bcf\u4e2a\u7f51\u683c\u5355\u5143\u5bf9\u5e94\u4e8e\u5b9e\u9645\u5c3a\u5bf8\u7684s\u7c73\uff0c\u5728\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0cBEV\u7279\u5f81\u7684\u4e2d\u5fc3\u5bf9\u5e94\u4e8e\u6c7d\u8f66\u7684\u4f4d\u7f6e\u3002\u5c06BEV\u67e5\u8be2\u5411\u91cfQ\u8f93\u5165\u5230BEVFormer\u4e4b\u524d\uff0c\u4e3a\u5176\u6dfb\u52a0\u4e86\u53ef\u5b66\u4e60\u7684\u4f4d\u7f6e\u7f16\u7801\u3002</p>"},{"location":"auto/paper/BEVFormer/#_4","title":"\u7a7a\u95f4\u4ea4\u53c9\u6ce8\u610f\u529b","text":"<p>\u2003\u2003\u7531\u4e8e\u591a\u76f8\u673a3D\u611f\u77e5\u4efb\u52a1\u901a\u5e38\u9700\u8981\u8f93\u5165\u591a\u7ec4\u5206\u8fa8\u7387\u5f88\u9ad8\u7684\u56fe\u7247\uff0c\u4f20\u7edf\u7684Transformer\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u9700\u8981\u6d88\u8017\u5f88\u5927\u7684\u8ba1\u7b97\u91cf\uff0c\u56e0\u6b64\uff0c\u8fd9\u91cc\u4f5c\u8005\u91c7\u6837\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u6a21\u5757\uff08\u5177\u4f53\u53ef\u89c1DeDETR\uff09\u6765\u5b9e\u73b0\u7a7a\u95f4\u4e0a\u7684\u4ea4\u53c9\u6ce8\u610f\u529b\uff0c\u8fd9\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u6ce8\u610f\u529b\u5c42\uff0c\u5176\u4e2d\u6bcf\u4e2aBEV\u67e5\u8be2\u5411\u91cfQ_p\u4ec5\u4e0e\u76f8\u673a\u89c6\u56fe\u4e2d\u611f\u5174\u8da3\u7684\u533a\u57df\u4ea4\u4e92\uff08\u53ea\u5229\u7528\u6709\u9650\u4e2a\u91c7\u6837\u70b9\u8ba1\u7b97\u6ce8\u610f\u529b\uff09\uff0c\u7136\u800c\uff0c\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u6700\u521d\u662f\u4e3a2D\u611f\u77e5\u8bbe\u8ba1\u7684\uff0c\u56e0\u6b64\u9700\u8981\u5bf93D\u573a\u666f\u8fdb\u884c\u4e00\u4e9b\u8c03\u6574\u3002</p> <p>\u2003\u2003\u7a7a\u95f4\u4ea4\u53c9\u6ce8\u610f\u529b\u7684\u8ba1\u7b97\u8fc7\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u9996\u5148\u5c06BEV\u5e73\u9762\u4e0a\u7684\u6bcf\u4e2a\u67e5\u8be2\u63d0\u5347\u4e3a\u67f1\u72b6\u67e5\u8be2\uff0c\u4ece\u67f1\u72b6\u67e5\u8be2\u4e2d\u91c7\u6837N_{ref}\u4e2a3D\u53c2\u8003\u70b9\uff0c\u4e4b\u540e\u5c06\u8fd9\u4e9b\u70b9\u6295\u5f71\u52302D\u89c6\u56fe\u4e2d\uff0c\u5bf9\u4e8e\u4e00\u4e2aBEV\u67e5\u8be2\uff0c\u6295\u5f71\u76842D\u70b9\u5e76\u4e0d\u4f1a\u843d\u5728\uff08\u51fb\u4e2d\uff09\u6240\u6709\u89c6\u56fe\u4e0a\uff0c\u4f8b\u5982\u4e0b\u56fe(x',y')\u53ea\u843d\u5728\u4e86\u53f3\u4fa7\u4e24\u4e2a\u89c6\u56fe\u4e0a\uff0c\u5373\u5355\u4e2aBEV\u67e5\u8be2\u5411\u91cf\u5e76\u4e0d\u4f1a\u4e0e\u6240\u6709\u89c6\u56fe\u90fd\u6709\u5bf9\u5e94\u5173\u7cfb\uff0c\u8fd9\u91cc\u6211\u4eec\u79f0\u88ab\u51fb\u4e2d\u7684\u89c6\u56fe\u4e3aV_{hit}\uff0c\u4e4b\u540e\uff0c\u6211\u4eec\u5c06\u8fd9\u4e9b2D\u70b9\u4f5c\u4e3a\u67e5\u8be2\u5411\u91cfQ_p\u7684\u53c2\u8003\u70b9\uff0c\u5e76\u4ece\u8fd9\u4e9b\u53c2\u8003\u70b9\u5468\u56f4\u7684\u547d\u4e2d\u89c6\u56feV_{hit}\u4e2d\u91c7\u6837\u7279\u5f81\uff0c\u6700\u540e\uff0c\u5bf9\u6240\u91c7\u6837\u7684\u7279\u5f81\u8fdb\u884c\u52a0\u6743\u6c42\u548c\uff08\u6dfb\u52a0\u6ce8\u610f\u529b\u6743\u91cd\uff09\uff0c\u4f5c\u4e3a\u7a7a\u95f4\u4ea4\u53c9\u6ce8\u610f\u529b\u7684\u8f93\u51fa\uff0c\u6574\u4e2a\u8fc7\u7a0b\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ SCA(Q_p,F_t)=\\frac{1}{|V_{hit}|}\\sum_{i\\in V_{hit}}\\sum^{N_{ref}}_{j=1}DeformAttn(Q_p,P(p,i,j),F^i_t) $$  \u5176\u4e2di\u8868\u793a\u76f8\u673a\u89c6\u89d2\u7684\u7d22\u5f15\uff0cj\u8868\u793a\u53c2\u8003\u70b9\u7d22\u5f15\uff0cN_{ref}\u8868\u793a\u6bcf\u4e2aBEV\u67e5\u8be2\u5411\u91cf\u4e2d\u53c2\u8003\u70b9\u7684\u603b\u6570\uff08\u4e5f\u5c31\u662f\u4e0a\u8ff0\u67f1\u72b6\u56fe\u7684\u9ad8\u5ea6\uff09\uff0cF_t^i\u8868\u793a\u7b2ci\u4e2a\u76f8\u673a\u89c6\u89d2\u7684\u7279\u5f81\uff0c\u5bf9\u4e8e\u6bcf\u4e2aBEV\u67e5\u8be2\u5411\u91cfQ_p\uff0c\u4f5c\u8005\u4f7f\u7528\u4e00\u4e2a\u51fd\u6570P(p,i,j)\u5f97\u5230\u7b2ci\u5f20\u89c6\u56fe\u4e0a\u7684\u7b2cj\u4e2a\u53c2\u8003\u70b9\uff0c\u4e5f\u5c31\u662f\u5f97\u5230\u6bcf\u4e2a\u67e5\u8be2\u5411\u91cf\u4e0e\u7279\u5f81\u70b9\u7684\u5bf9\u5e94\u5173\u7cfb\u3002</p> <p>\u2003\u2003\u6838\u5fc3\u95ee\u9898\u8f6c\u53d8\u4e3a\u4e86\u5982\u4f55\u5f97\u5230\u51fd\u6570P\uff0c\u5373\u5982\u4f55\u5f97\u5230\u6bcf\u4e2a\u89c6\u56fe\u4e0a\u5bf9\u5e94\u7684\u53c2\u8003\u70b9\u3002BEV\u7279\u5f81\u672c\u8d28\u4e0a\u6765\u8bf4\u5c31\u662f\u4fef\u89c6\u89c6\u89d2\u4e0b\u7684\u5730\u56fe\u7279\u5f81\uff0c\u6bcf\u4e2a\u50cf\u7d20\u70b9\u5728\u771f\u5b9e\u4e16\u754c\u4e2d\u90fd\u6709\u5bf9\u5e94\u5173\u7cfb\uff0c\u56e0\u6b64\uff0c\u53ef\u4ee5\u5c06\u5176\u89c6\u4e3a\u4e00\u4e2a\u4e2a\u771f\u5b9e\u4e16\u754c\u4e2d\u7684\u70b9\uff08\u5373\u70b9\u4e91\u6570\u636e\uff09\uff0c\u5229\u7528\u65cb\u8f6c\u77e9\u9635\uff0c\u5c06\u73b0\u5b9e\u5750\u6807\u7cfb\uff08\u70b9\u4e91\u7cfb\uff09\u4e2d3D\u5750\u6807\u6570\u636e\u8f6c\u4e3a\u56fe\u50cf\u5750\u6807\u7cfb\u4e0b\u7684\u5750\u6807\u3002</p> <p>\u2003\u2003\u9996\u5148\u8ba1\u7b97\u4f4d\u4e8eQ\u7684p=(x,y)\u70b9\u5904\u7684\u67e5\u8be2\u5411\u91cfQ_p\u5bf9\u5e94\u771f\u5b9e\u4e16\u754c\uff0c\u9996\u5148\u8ba1\u7b97Q\u7684p=(x,y)\u5904\u7684\u67e5\u8be2\u5411\u91cfQ_p\u5bf9\u5e94\u771f\u5b9e\u4e16\u754c\u7684\u4f4d\u7f6e(x',y')\uff1a $$ x'=(x-\\frac W2)\\times s,y'=(y-\\frac H2)\\times s $$  \u5176\u4e2dH,W\u8868\u793aBEV\u5411\u91cf\u7684\u7a7a\u95f4\u5c3a\u5bf8\uff0cs\u8868\u793aBEV\u7f51\u683c\u7684\u5206\u8fa8\u7387\u5927\u5c0f\uff0c\u5373\u5355\u4f4d\u7f51\u683c\u5927\u5c0f\u4e0e\u73b0\u5b9e\u4e16\u754c\u7684\u6bd4\u4f8b\u5c3a\u5bf8\uff0c(x',y')\u4e3a\u8f66\u8f86\u5750\u6807\u7cfb\u4e0b\u7684\u5750\u6807\uff08\u8f66\u4f53\u5728\u539f\u70b9\u4f4d\u7f6e\uff09\uff0c\u57283D\u7a7a\u95f4\u4e2d\uff0c\u4f4d\u4e8e(x_0,y_0)\u7684\u7269\u4f53\u5728z\u8f74\u4e0a\u4e5f\u5177\u6709\u4e00\u5b9a\u7684\u9ad8\u5ea6\uff0c\u5047\u8bbe\u4e3az'\uff0c\u6240\u4ee5\u4f5c\u8005\u9884\u5148\u5b9a\u4e49\u4e86\u4e00\u7ec4\u951a\u70b9\u9ad8\u5ea6\\{z_j'\\}^{N_{ref}}_{j=1}\uff0c\u4ece\u800c\u786e\u4fdd\u7b97\u6cd5\u53ef\u4ee5\u6355\u6349\u5230\u51fa\u73b0\u5728\u4e0d\u540c\u9ad8\u5ea6\u7684\u7ebf\u7d22\uff08\u5373\u8868\u73b0\u7269\u4f53\u7684\u4e0d\u540c\u9ad8\u5ea6\uff09\u3002\u8fd9\u6837\uff0c\u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u67e5\u8be2\u5411\u91cfQ_p\uff0c\u6211\u4eec\u90fd\u53ef\u4ee5\u5f97\u5230\u4e00\u4e2a\u67f1\u72b6\u7684\u4e09\u7ef4\u53c2\u8003\u70b9(x',y',z'_j)^{N_{ref}}_{j=1}\uff08\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u5750\u6807\u70b9\uff09\uff0c\u6700\u540e\uff0c\u901a\u8fc7\u76f8\u673a\u7684\u6295\u5f71\u77e9\u9635\uff08\u5373\u5185\u53c2\uff09\uff0c\u5c06\u4e09\u7ef4\u53c2\u8003\u70b9\u6295\u5f71\u5230\u4e0d\u540c\u7684\u56fe\u50cf\u89c6\u56fe\u4e2d\uff0c\u53ef\u4ee5\u5199\u6210\uff1a $$ P(p,i,j)=(x_{ij},y_{ij})\\\\ \u5176\u4e2d\uff0cz_{ij}\\cdot[x_{ij} \\quad y_{ij} \\quad 1]^T=T_i\\cdot[x' \\quad y' \\quad z_j' \\quad 1]^T $$  \u5176\u4e2d\uff0cP(p,i,j)\u662f\u4ece\u7b2cj\u4e2a3D\u70b9(x',y',z'_j)\u6295\u5f71\u51fa\u6765\u7684\u7b2ci\u4e2a\u89c6\u56fe\u4e0a\u76842D\u70b9\uff0cT_i\\in R^{3\\times4}\u662f\u7b2ci\u4e2a\u76f8\u673a\u7684\u6295\u5f71\u77e9\u9635\uff08\u5373\u76f8\u673a\u5185\u53c2\uff09\u3002</p> <p>\u6ce8\u610f\uff1a</p> <ul> <li>2D\u5230BEV\u7684\u6295\u5f71\u662f\u9760\u76f8\u673a\u5185\u53c2\u5b9e\u73b0\u7684\uff0c\u901a\u8fc7\u70b9\u4e91\u6570\u636e\u53ef\u4ee5\u83b7\u5f97\u7269\u4f53\u7684\u4e09\u7ef4\u5750\u6807\uff0c\u53ef\u4ee5\u5229\u7528\u76f8\u673a\u5185\u53c2\u6765\u8fdb\u4e00\u6b65\u5b9e\u73b0\u4e09\u7ef4\u76f8\u673a\u5750\u6807\u7cfb\u5230\u4e8c\u7ef4\u56fe\u50cf\u5750\u6807\u7cfb\u7684\u6620\u5c04\uff0c\u6620\u5c04\u70b9\u5c31\u89c6\u4e3a\u53c2\u8003\u5750\u6807\u70b9\uff0c\u5229\u7528\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u5728\u53c2\u8003\u70b9\u5468\u56f4\u9009\u62e9\u4e00\u4e9b\u70b9\u6765\u5b9e\u73b0\u6ce8\u610f\u529b\u7684\u8fd0\u7b97\uff08\u901a\u8fc7\u504f\u79fb\u64cd\u4f5c\u5b9e\u73b0\uff09\uff1b</li> <li>\u5bf9\u4e8eBEV\u4e0a\u4f4d\u7f6e\u4e3a(x,y)\u7684\u67e5\u8be2\u5411\u91cfQ_p\uff0c\u4f1a\u5bf9\u5e94\u591a\u4e2a\u89c6\u56fe\u4e0a\u7684\u51fb\u4e2d\u70b9\uff0c\u6bcf\u4e2a\u51fb\u4e2d\u70b9\u4f1a\u5728\u5750\u6807(x,y)\u7684\u57fa\u7840\u4e0a\u9884\u8bbeN_{ref}\u4e2a\u9ad8\u5ea6\u951a\u70b9\uff0c\u7528\u4e8e\u5b9a\u4f4d\u771f\u5b9e\u4e16\u754c\u4e2d\u7269\u4f53\u7684\u9ad8\u5ea6\uff0c\u83b7\u5f97\u9ad8\u5ea6\u4fe1\u606f\uff08\u53ea\u6709\u5229\u7528\u4e09\u7ef4\u5750\u6807\u6570\u636e(x,y,z)\u624d\u80fd\u5c06\u4e09\u7ef4\u7269\u4f53\u6295\u5f71\u5230\u4e8c\u7ef4\u5e73\u9762\u4e0a\uff09\uff0c\u6295\u5f71\u5230\u4e8c\u7ef4\u5e73\u9762\u4e0a\u7684\u70b9\u79f0\u4e3a\u53c2\u8003\u70b9\uff0c\u5229\u7528\u53c2\u8003\u70b9\u6765\u8ba1\u7b97\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\uff0c\u6700\u540e\u518d\u6cbfz\u8f74\u3001\u89c6\u56fe\u65b9\u5411\u76f8\u52a0\uff0c\u5f97\u5230\u5f53\u524d\u4f4d\u7f6e(x,y)\u4e0a\u6700\u7ec8\u7684\u67e5\u8be2\u7279\u5f81Q_p\uff1b\uff08\u4e00\u5f20\u56fe\u4e0a\u7684\u70b9\uff0c\u53ea\u80fd\u6620\u5c04\u5230z\u8f74\u4e0a\u7684\u4e00\u4e2a\u70b9\uff0c\u4f46\u662fz\u8f74\u4e0a\u7684\u67d0\u4e2a\u70b9\uff0c\u53ef\u80fd\u4f1a\u63a5\u53d7\u6765\u81ea\u591a\u4e2a\u89c6\u56fe\u7684\u6620\u5c04\uff09</li> </ul>"},{"location":"auto/paper/BEVFormer/#_5","title":"\u65f6\u95f4\u81ea\u6ce8\u610f\u529b","text":"<p>\u2003\u2003\u9664\u4e86\u7a7a\u95f4\u4fe1\u606f\u4e4b\u5916\uff0c\u65f6\u95f4\u4fe1\u606f\u5bf9\u4e8e\u89c6\u89c9\u7cfb\u7edf\u7406\u89e3\u5468\u56f4\u73af\u5883\u4e5f\u81f3\u5173\u91cd\u8981\uff0c\u4f8b\u5982\u5728\u6ca1\u6709\u65f6\u95f4\u7ebf\u7d22\u7684\u60c5\u51b5\u4e0b\u63a8\u65ad\u79fb\u52a8\u7269\u4f53\u7684\u901f\u5ea6\u6216\u4ece\u9759\u6001\u56fe\u50cf\u4e2d\u68c0\u6d4b\u9ad8\u5ea6\u906e\u6321\u7684\u7269\u4f53\u662f\u96be\u4ee5\u5b9e\u73b0\u7684\uff0c\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4f5c\u8005\u8bbe\u8ba1\u4e86\u65f6\u95f4\u81ea\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u5b83\u53ef\u4ee5\u901a\u8fc7\u7ed3\u5408\u5386\u53f2BEV\u7279\u5f81\u6765\u8868\u793a\u5f53\u524d\u73af\u5883\u3002</p> <p>\u2003\u2003\u7ed9\u5b9a\u4e00\u4e2a\u5728\u65f6\u95f4\u6233t\u4e0b\u7684BEV\u67e5\u8be2\u5411\u91cfQ\u548c\u5728\u65f6\u95f4\u6233t-1\u4e0b\u7684\u5386\u53f2BEV\u7279\u5f81B_{t-1}\uff0c\u7531\u4e8e\u4e24\u4e2a\u7279\u5f81\u7684\u65f6\u95f4\u6233\u4e0d\u4e00\u81f4\uff0c\u8f66\u4f53\u7684\u4f4d\u7f6e\u53ef\u80fd\u4f1a\u53d1\u751f\u53d8\u5316\uff0c\u56e0\u6b64\u5bf9\u5e94\u7684BEV\u9e1f\u77b0\u56fe\u4e5f\u4e0d\u4e00\u5b9a\u81f4\uff0c\u5bf9\u6b64\uff0c\u9996\u5148\u6839\u636e\u8f66\u4f53\u7684\u8fd0\u52a8\u5c06B_{t-1}\u4e0eQ\u5bf9\u9f50\uff0c\u4f7f\u5f97\u540c\u4e00\u7f51\u683c\u53ef\u4ee5\u5bf9\u5e94\u73b0\u5b9e\u4e16\u754c\u76f8\u540c\u7684\u4f4d\u7f6e\uff0c\u5728\u8fd9\u91cc\uff0c\u6211\u4eec\u5c06\u5bf9\u5176\u540e\u7684\u5386\u53f2BEV\u7279\u5f81B_{t-1}\u8868\u793a\u4e3aB_{t-1}'\u3002\u8fd8\u6709\u4e00\u4e2a\u95ee\u9898\uff0c\u4ecet-1\u5230t\u65f6\u523b\uff0c\u4e0d\u540c\u7684\u7269\u4f53\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u4f1a\u4ee5\u4e0d\u540c\u7684\u504f\u79fb\u91cf\u79fb\u52a8\uff0c\u5728\u4e0d\u540c\u65f6\u95f4\u6233\u4e4b\u95f4\u6784\u5efa\u76f8\u540c\u76ee\u6807BEV\u7279\u5f81\u4e4b\u95f4\u7684\u5173\u8054\u662f\u975e\u5e38\u96be\u7684\u3002\u5bf9\u6b64\uff0c\u4f5c\u8005\u901a\u8fc7\u65f6\u95f4\u81ea\u6ce8\u610f\u529b\u5c42\u5bf9\u7279\u5f81\u4e4b\u95f4\u7684\u8fd9\u79cd\u65f6\u95f4\u5173\u8054\u8fdb\u884c\u5efa\u6a21\uff1a $$ TSA(Q_p,\\{Q,B_{t-1}'\\})=\\sum_{V\\in\\{Q,B_{t-1}'\\}}DeformAttn(Q_p,p,V) $$  \u5176\u4e2d\uff0cQ_p\u8868\u793a\u5728\u70b9p=(x,y)\u5904\u7684BEV\u7279\u5f81\u3002\u6b64\u5916\uff0c\u4e0e\u666e\u901a\u7684\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u4e0d\u540c\uff0c\u65f6\u95f4\u81ea\u6ce8\u610f\u529b\u7684\u504f\u79fb\u91cf\\Delta p\u662f\u901a\u8fc7\u9884\u6d4b\u201c\u67e5\u8be2\u5411\u91cfQ\u548c\u5386\u53f2BEV\u7279\u5f81B_{t-1}'\u7684\u5408\u5e76\u201d\u5b9e\u73b0\u3002\u7279\u522b\u5730\uff0c\u5bf9\u4e8e\u6bcf\u4e2a\u5e8f\u5217\u7684\u7b2c\u4e00\u4e2a\u6837\u672c\uff0c\u5c06\u65f6\u95f4\u81ea\u6ce8\u610f\u529b\u9000\u5316\u4e3a\u4e0d\u542b\u65f6\u95f4\u4fe1\u606f\u7684\u81ea\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u5373\u7528\\{Q,Q\\}\u6765\u4ee3\u66ff\\{Q,B_{t-1}'\\}\u3002</p> <p>\u2003\u2003\u4e0e\u7b80\u5355\u5730\u53e0\u52a0BEV\u76f8\u6bd4\uff0c\u4f5c\u8005\u63d0\u51fa\u7684\u65f6\u95f4\u81ea\u6ce8\u610f\u529b\u6a21\u5757\u53ef\u4ee5\u6709\u6548\u5730\u5bf9\u957f\u65f6\u95f4\u4f9d\u8d56\u5efa\u6a21\uff0c\u5373\u4f7f\u76f8\u9694\u5f88\u8fdc\uff0c\u4e24\u5e27\u4e4b\u95f4\u7684\u4fe1\u606f\u53ef\u4ee5\u6709\u6548\u5730\u901a\u8fc7B_{t-1}'\u4f20\u9012\u4e0b\u53bb\u3002\u540c\u65f6\uff0cBEVFormer\u4ec5\u4ece\u524d\u4e00\u5e27\u7684BEV\u7279\u5f81\u4e2d\u63d0\u53d6\u65f6\u95f4\u4fe1\u606f\uff0c\u5e76\u6ca1\u6709\u53e0\u52a0\u5f88\u591a\u5e27\u7684BEV\u7279\u5f81\uff0c\u56e0\u6b64\u4ea7\u751f\u8f83\u5c11\u7684\u8ba1\u7b97\u6210\u672c\u548c\u8f83\u5c11\u7684\u5e72\u6270\u4fe1\u606f\u3002</p> <p>\u95ee\u9898\u8bb0\u5f55\uff1a\u5982\u4f55\u5bf9\u9f50Bt-1\u4e0eQ\uff1f\u6e90\u7801\u4e2d\u7528\u5230\u4e86shift\u504f\u79fb\u91cf\uff0c\u73b0\u5b9e\u4e2d\u8be5\u5982\u4f55\u6d4b\u5f97\u8fd9\u4e00\u53d8\u91cf\uff1f</p>"},{"location":"auto/paper/BEVFormer/#bev_1","title":"BEV\u7279\u5f81\u7684\u5e94\u7528","text":"<p>\u2003\u2003BEV\u7279\u5f81B_t\\in R^{H\\times W\\times C}\u662f\u4e00\u4e2a\u901a\u7528\u76842D\u7279\u5f81\u56fe\uff1a</p> <p>3D\u76ee\u6807\u68c0\u6d4b\uff1a\u4f5c\u8005\u57fa\u4e8e2D\u68c0\u6d4b\u5668Deformable DETR\u8bbe\u8ba1\u4e86\u4e00\u6b3e\u7aef\u5230\u7aef\u7684\u4e09\u7ef4\u68c0\u6d4b\u5934\uff0c\u4f7f\u7528\u5355\u5c3a\u5ea6BEV\u7279\u5f81B_t\u4f5c\u4e3a\u89e3\u7801\u5668\u7684\u8f93\u5165\uff0c\u76f4\u63a5\u9884\u6d4b3D\u8fb9\u754c\u6846\u548c\u901f\u5ea6\uff0c\u5e76\u4e14\u4ec5\u4f7f\u7528L_1\u635f\u5931\u6765\u76d1\u77633D\u8fb9\u754c\u6846\u7684\u56de\u5f52\u3002\u6ce8\uff1a\u4f7f\u7528\u8be5\u68c0\u6d4b\u5668\uff08Deformable DETR\uff09\uff0c\u53ef\u4ee5\u76f4\u63a5\u5b9e\u73b0\u7aef\u5230\u7aef\u76843D\u8fb9\u754c\u6846\u548c\u901f\u5ea6\u9884\u6d4b\uff0c\u65e0\u9700NMS\u540e\u5904\u7406</p> <p>\u5730\u56fe\u5206\u5272\uff1a\u4f5c\u8005\u57fa\u4e8e2D\u5206\u5272\u7b97\u6cd5Panoptic SegFormer\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5730\u56fe\u5206\u5272\u5934\uff0c\u57fa\u4e8eBEV\u7684\u5730\u56fe\u5206\u5272\u4efb\u52a1\u548c\u5e38\u89c1\u7684\u8bed\u4e49\u5206\u5272\u4efb\u52a1\u57fa\u672c\u76f8\u540c\uff0c\u4f5c\u8005\u4f7f\u7528Panoptic SegFormer\u7684\u63a9\u7801\u89e3\u7801\u5668\u548c\u7c7b\u522b\u56fa\u5b9a\u7684\u67e5\u8be2\u5411\u91cf\u6765\u9488\u5bf9\u6bcf\u4e2a\u8bed\u4e49\u7c7b\u522b\u505a\u5206\u5272\uff0c\u5305\u62ec\uff1a\u6c7d\u8f66\u3001\u8f66\u9053\u548c\u53ef\u884c\u9a76\u533a\u57df\u7b49\u7b49\u3002</p> <p>\u8bad\u7ec3\u9636\u6bb5</p> <p>\u2003\u2003\u5bf9\u4e8e\u65f6\u95f4\u6233t\u7684\u6bcf\u4e2a\u6837\u672c\uff0c\u4f5c\u8005\u4ece\u8fc7\u53bb2\u79d2\u7684\u8fde\u7eed\u5e8f\u5217\u4e2d\u968f\u673a\u62bd\u53d6\u53e6\u59163\u4e2a\u6837\u672c\uff0c\u8fd9\u79cd\u968f\u673a\u62bd\u6837\u7b56\u7565\u53ef\u4ee5\u589e\u5f3a\u81ea\u6211\u8fd0\u52a8\u7684\u591a\u6837\u6027\u3002\u5c06\u8fd9\u56db\u4e2a\u6837\u672c\u7684\u65f6\u95f4\u6233\u5206\u522b\u8bb0\u4e3at-3,t-2,t-1,t\uff0c\u524d\u4e09\u4e2a\u65f6\u95f4\u6233\u6837\u672c\u6309\u987a\u5e8f\u751f\u6210\\{B_{t-3}\u3001B_{t-2}\u3001B_{t-1}\\}\uff0c\u8fd9\u4e00\u8fc7\u7a0b\u4e0d\u8ba1\u5165\u68af\u5ea6\uff0c\u5bf9\u4e8e\u65f6\u95f4\u6233t-3\u7684\u7b2c\u4e00\u4e2a\u6837\u672c\uff0c\u6ca1\u6709\u5148\u524d\u7684BEV\u7279\u5f81\uff0c\u5229\u7528\u81ea\u6ce8\u610f\u529b\u4ee3\u66ff\u65f6\u95f4\u81ea\u6ce8\u610f\u529b\uff08\u5373\u7528BEV\u67e5\u8be2Q\u4ee3\u66ff\u5386\u53f2BEV\uff09\uff0c\u5728t\u65f6\u523b\uff0c\u6a21\u578b\u540c\u65f6\u57fa\u4e8e\u591a\u6444\u50cf\u5934\u8f93\u5165\u548c\u5386\u53f2BEV\u7279\u5f81B_{t-1}\u751f\u6210\u5f53\u524d\u65f6\u523b\u7684BEV\u7279\u5f81B_t\uff0c\u4f7f\u5f97B_t\u5305\u542b\u4e86\u8de8\u8d8a\u56db\u4e2a\u6837\u672c\u7684\u65f6\u7a7a\u7ebf\u7d22\uff0c\u6700\u540e\uff0c\u5c06BEV\u7279\u5f81B_t\u8f93\u5165\u5230\u68c0\u6d4b\u5934\u548c\u5206\u5272\u5934\u4e2d\uff0c\u5e76\u8ba1\u7b97\u76f8\u5e94\u7684\u635f\u5931\u3002</p> <p>\u63a8\u7406\u9636\u6bb5</p> <p>\u2003\u2003\u6309\u65f6\u95f4\u987a\u5e8f\u8bc4\u4f30\u89c6\u9891\u5e8f\u5217\u7684\u6bcf\u4e00\u5e27\uff0c\u5c06\u524d\u4e00\u4e2a\u65f6\u95f4\u6233\u7684BEV\u7279\u5f81\u4fdd\u5b58\u4e0b\u6765\uff0c\u7528\u4e8e\u4e0b\u4e00\u4e2a\u65f6\u95f4\u6233BEV\u7279\u5f81\u7684\u8ba1\u7b97\u3002</p> <p>\u6ce8\u610f\uff1a\u5728\u672c\u6587\u4e2d\uff0cBEV\u7279\u5f81\u751f\u6210\u5668\u4e0d\u9700\u8981\u5355\u72ec\u8bbe\u8ba1\u635f\u5931\u6765\u8bad\u7ec3\uff0c\u6211\u4eec\u53ea\u9700\u8981\u9488\u5bf9\u4e0b\u6e38\u4efb\u52a1\u8bbe\u8ba1\u635f\u5931\u6765\u8bad\u7ec3\u7f51\u7edc\u53c2\u6570\u5373\u53ef\u3002</p> <p>\u8865\u5145\uff1a</p> <ul> <li>BEVFormer\u8bc1\u660e\u4e86\u4f7f\u7528\u591a\u6444\u50cf\u5934\u8f93\u5165\u7684\u65f6\u7a7a\u4fe1\u606f\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u89c6\u89c9\u611f\u77e5\u6a21\u578b\u7684\u6027\u80fd\uff0c\u65f6\u95f4\u81ea\u6ce8\u610f\u529b\u6a21\u5757\u548c\u7a7a\u95f4\u4ea4\u53c9\u6ce8\u610f\u529b\u6a21\u5757\u53ef\u4ee5\u51c6\u786e\u5730\u4f30\u8ba1\u7269\u4f53\u7684\u79fb\u52a8\u901f\u5ea6\uff0c\u540c\u65f6\u53ef\u4ee5\u51c6\u786e\u5730\u63d0\u5347\u4f4e\u53ef\u89c1\u7269\u4f53\u7684\u53ec\u56de\u7387\uff0c\u5bf9\u6784\u5efa\u66f4\u5b89\u5168\u7684\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\uff1b</li> <li>\u5229\u7528\u76f8\u673a\u7684\u4f30\u8ba1\u65b9\u6cd5\u4e0e\u5229\u7528\u6fc0\u5149\u96f7\u8fbe\u4f30\u8ba1\u7684\u65b9\u6cd5\u5728\u6548\u7387\u4e0a\u8fd8\u6709\u4e00\u5b9a\u7684\u5dee\u8ddd\uff0c\u5229\u7528\u4e8c\u7ef4\u4fe1\u606f\u53bb\u63a8\u65ad\u4e09\u7ef4\u4f4d\u7f6e\u4ecd\u5177\u6709\u6311\u6218\u3002</li> </ul>"},{"location":"auto/paper/BEVFormer/#_6","title":"\u5b9e\u9a8c","text":"<p>\u5b9e\u9a8c\u7ec6\u8282</p> <p>\u2003\u2003\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u4f7f\u7528FPN\u8f93\u51fa\u7684\u591a\u5c3a\u5ea6\u7279\u5f81\uff0c\u5927\u5c0f\u5206\u522b\u4e3a\u539f\u56fe\u7684\\frac{1}{16}\u3001\\frac{1}{32}\u3001\\frac{1}{64}\uff0c\u901a\u9053\u6570\u4e3a256\u3002\u5728nuScenes\u4e0a\u7684\u5b9e\u9a8c\u4e2d\uff0cBEV\u67e5\u8be2\u5411\u91cf\u7684\u9ed8\u8ba4\u5927\u5c0f\u4e3a200\\times 200\uff0cX\u8f74\u548cY\u8f74\u7684\u611f\u77e5\u8303\u56f4\u4e3a[-51.2m,51.2m]\uff0cBEV\u7f51\u683c\u5206\u8fa8\u7387s\u7684\u5927\u5c0f\u4e3a0.512m\uff0c\u5bf9BEV\u67e5\u8be2\u5411\u91cf\u91c7\u7528\u4e86\u53ef\u5b66\u4e60\u7684\u4f4d\u7f6e\u5d4c\u5165\uff08\u5373\u5d4c\u5165\u4f4d\u7f6e\u7f16\u7801\uff09\uff0cBEV\u7f16\u7801\u5668\u5305\u542b6\u4e2a\u7f16\u7801\u5668\u5c42\uff0c\u9012\u5f52\u6539\u8fdb\u6bcf\u5c42\u4e2d\u7684BEV\u67e5\u8be2\u5411\u91cf\uff0c\u6bcf\u4e2a\u7f16\u7801\u5668\u5c42\u8f93\u5165\u7684\u5386\u53f2BEV\u7279\u5f81B_{t-1}\u90fd\u662f\u76f8\u540c\u7684\uff0c\u4e0d\u9700\u8981\u8ba1\u7b97\u68af\u5ea6\u3002\u5bf9\u4e8e\u6bcf\u4e2a\u5c40\u90e8\u67e5\u8be2Q_p\uff0c\u5728\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u673a\u5236\u5b9e\u73b0\u7684\u7a7a\u95f4\u4ea4\u53c9\u6ce8\u610f\u529b\u4e2d\uff0c\u90fd\u4f1a\u5bf9\u5e94\u4e09\u7ef4\u7a7a\u95f4\u4e2dN_{ref}=4\u4e2a\u4e0d\u540c\u9ad8\u5ea6\u7684\u70b9\uff0c\u5728-5m\\sim3m\u8303\u56f4\u5185\u5747\u5300\u91c7\u6837\u9884\u5b9a\u4e49\u9ad8\u5ea6\u7684\u951a\u70b9\uff0c\u5bf9\u4e8e2D\u89c6\u56fe\u7279\u5f81\u4e0a\u7684\u6bcf\u4e2a\u53c2\u8003\u70b9\uff0c\u6211\u4eec\u5728\u6bcf\u4e2a\u5934\u90e8\u7684\u53c2\u8003\u70b9\u5468\u56f4\u4f7f\u75284\u4e2a\u91c7\u6837\u70b9\uff0c\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u603b\u5171\u8bad\u7ec324\u4e2aepoch\uff0c\u5b66\u4e60\u7387\u8bbe\u4e3a2\\times 10^{-4}\u3002</p> <p>z\u8f74\u8868\u793a\u7684\u9ad8\u5ea6\u4e3a\u4ec0\u4e48\u8981\u4ece\u8d1f\u6570\u5f00\u59cb\uff0c\u800c\u4e14\u8fd8\u8981\u4ece-5\u5f00\u59cb\uff1f\u662f\u56e0\u4e3a\u76f8\u673a\u5728\u8f66\u9876\uff0c\u76f8\u5bf9\u4e8e\u5730\u9762\u6765\u8bf4\uff0c\u6c34\u5e73\u9762\u53d8\u9ad8\u7684\u7f18\u6545\u4e48\u3002</p>"},{"location":"auto/paper/BEVFormer/#_7","title":"\u53ef\u89c6\u5316\u56fe","text":"<p>\u2003\u2003BEVFormer-S\u8868\u793a\u5f15\u5165\u4e86\u65f6\u95f4\u81ea\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u4ece\u5bf9\u6bd4\u56fe\u4e2d\u53ef\u4ee5\u53d1\u73b0\uff0c\u5f15\u5165\u65f6\u95f4\u81ea\u6ce8\u610f\u529b\u6a21\u5757\u4e4b\u540e\uff0c\u7b97\u6cd5\u53ef\u4ee5\u5f88\u597d\u5730\u68c0\u6d4b\u906e\u6321\u8f83\u5927\u7684\u7269\u4f53\u3002</p> <p> <p></p> <p></p> <p>\u2003\u2003\u5730\u56fe\u5206\u5272\u53ef\u89c6\u5316\uff1a</p> <p> <p></p> <p></p>"},{"location":"auto/paper/BEVFormer/#_8","title":"\u6e90\u7801\u7b14\u8bb0","text":""},{"location":"auto/paper/BEVFormer/#_9","title":"\u6d41\u7a0b","text":"<p>\u6838\u5fc3\u6a21\u5757\uff1a</p> <ul> <li>\u65f6\u95f4\u81ea\u6ce8\u610f\u529b\uff1aq\u4e3aBEV\u67e5\u8be2\u5411\u91cf\u3001kv\u5747\u4e3a\u5386\u53f2BEV\u7279\u5f81\uff0c\u7528\u4e8e\u6839\u636eBEV\u5386\u53f2\u7279\u5f81\u5f97\u5230\u67e5\u8be2\u5411\u91cfQ\uff0c\u4ee5BEV\u67e5\u8be2\u5411\u91cfQ\u4e3a\u4e2d\u5fc3\uff0c\u878d\u5408\u5386\u53f2BEV\u7279\u5f81\uff1b</li> <li>\u7a7a\u95f4\u4ea4\u53c9\u6ce8\u610f\u529b\uff1a\u65f6\u95f4\u81ea\u6ce8\u610f\u529b\u8f93\u51fa\u7684\u7ed3\u679c\uff0c\u53ef\u4ee5\u770b\u6210BEV\u67e5\u8be2\u5411\u91cf\uff0ckv\u5747\u8868\u793a\u56fe\u50cf\u7279\u5f81\uff0c\u7528\u4e8e\u6839\u636e\u56fe\u50cf\u7279\u5f81\u5f97\u5230BEV\u7279\u5f81\uff0c\u4ee5BEV\u67e5\u8be2\u5411\u91cfQ\u4e3a\u4e2d\u5fc3\uff0c\u878d\u5408\u5bf9\u5e94\u7684\u56fe\u50cf\u7279\u5f81\uff08\u878d\u5408\u8fc7\u7a0b\u4e2d\u901a\u8fc7\u76f8\u673a\u5185\u53c2\uff0c\u5f15\u5165BEV\u4e0e\u56fe\u50cf\u50cf\u7d20\u70b9\u7684\u4f4d\u7f6e\u5173\u7cfb\u5148\u9a8c\uff09\uff1b</li> <li>BEV\u89e3\u7801\u6a21\u5757\uff08\u4e0b\u6e38\u4efb\u52a1\uff09\uff1aq\u4e3a\u7269\u4f53\u67e5\u8be2\u5411\u91cf\uff0cv\u4e3aBEV\u7279\u5f81\uff0c\u4ee5\u7269\u4f53\u67e5\u8be2\u5411\u91cfq\u4e3a\u4e2d\u5fc3\uff0c\u878d\u5408\u5bf9\u5e94\u7684BEV\u7279\u5f81</li> </ul> <p>\u6ce8\uff1a</p> <ul> <li>\u7a7a\u95f4\u4ea4\u53c9\u6ce8\u610f\u529b\u4e2d\u7684\u5173\u7cfb\u5148\u9a8c\uff0c\u662f\u5c06\u4e09\u7ef4\u7684BEV\u7279\u5f81\u4f9d\u6b21\u6295\u5f71\u5230\u4e8c\u7ef4\u7684\u56fe\u50cf\u4e0a\uff08\u4e0e\u70b9\u4e91\u5411\u56fe\u50cf\u6295\u5f71\u7c7b\u4f3c\uff09\u3002\u65f6\u95f4\u81ea\u6ce8\u610f\u529b\u4e0a\uff0c\u53c2\u8003\u70b9\u5728BEV\u4e8c\u7ef4\u5e73\u9762\u4e0a\u5efa\u7acb\uff0c\u7a7a\u95f4\u4ea4\u53c9\u6ce8\u610f\u529b\u4e0a\uff0c\u53c2\u8003\u70b9\u5728BEV\u4e09\u7ef4\u7a7a\u95f4\u4e2d\u5efa\u7acb\u3002</li> <li>\u56fe\u50cf\u4e0d\u80fd\u76f4\u63a5\u6295\u5f71\u5230\u70b9\u4e91\u4e0a\uff0c\u4f46\u70b9\u4e91\u53ef\u4ee5\u6295\u5f71\u5230\u56fe\u50cf\u4e0a\uff0c\u6ce8\u610f\u903b\u8f91\u5173\u7cfb\uff1b</li> <li>\u65f6\u95f4\u81ea\u6ce8\u610f\u529b\u548c\u7a7a\u95f4\u4ea4\u53c9\u6ce8\u610f\u529b\u5171\u540c\u6784\u6210BEV\u7f16\u7801\u6a21\u5757\uff0cBEVFormer\u9ed8\u8ba4\u75316\u4e2a\u7f16\u7801\u6a21\u5757\u6784\u6210\uff0c\u5728BEV\u7f16\u7801\u7684\u8fc7\u7a0b\u4e2d\uff0cBEV\u67e5\u8be2\u5411\u91cfQ\u4e0d\u65ad\u505a\u66f4\u65b0\uff0c\u8fed\u4ee3\u4f18\u5316\uff0c\u5386\u53f2BEV\u7279\u5f81\u548c\u56fe\u50cf\u7279\u5f81\u4e0d\u505a\u66f4\u65b0\uff0c\u6700\u540e\u7f16\u7801\u5f97\u5230\u7684BEV\u67e5\u8be2\u5411\u91cf\u5373\u4e3a\u5f53\u524d\u65f6\u95f4\u6233\u4e0b\u7684BEV\u7279\u5f81\u3002</li> </ul> <p>backbone\u6a21\u5757</p> <ul> <li>\u5c06\u56fe\u7247\u5e8f\u5217\u4f9d\u6b21\u4f20\u5165ResNet\u7f51\u7edc\u4e2d\uff0c\u5f97\u5230\u540e\u4e09\u4e2a\u5c42\u7ea7\u7684\u7279\u5f81\u56fe\uff0c</li> <li>\u5c06\u5176\u4f20\u5165FPN\u6a21\u5757\u4e2d\uff0c\u6784\u5efa\u6a2a\u5411\u8fde\u63a5\u7ed3\u6784\uff0c\u63d0\u5347\u6a21\u578b\u7684\u591a\u5c3a\u5ea6\u7279\u5f81\u8868\u793a\u80fd\u529b\uff0c\u901a\u9053\u6570\u7edf\u4e00\u53d8\u4e3a256\uff0c\u5e76\u4e14\u5c06\u6700\u540e\u4e00\u4e2a\u5c42\u7ea7\u7684\u7279\u5f81\u4f20\u5165\u6b65\u957f\u4e3a2\u7684\u5377\u79ef\uff0c\u505a\u4e0b\u91c7\u6837\uff0c\u603b\u5171\u4f1a\u5f97\u52304\u4e2a\u5c42\u7ea7\u7684\u7279\u5f81\u56fe\uff1b</li> </ul> <p>\u6ce8\uff1a\u8fd9\u91cc\u5e76\u4e0d\u9700\u8981\u5bf9\u6bcf\u4e2a\u56fe\u50cf\u5f15\u5165\u4f4d\u7f6e\u7f16\u7801\uff0c\u56e0\u4e3a\u56fe\u50cf\u53ea\u5229\u7528CNN\u63d0\u53d6\u7279\u5f81\uff0c\u5e76\u6ca1\u6709\u7ecf\u8fc7TF\u7f16\u7801\u5668\u63d0\u53d6\u7279\u5f81\u3002\u5e76\u4e14\u56e0\u4e3a\u8fd9\u91cc\u6ca1\u6709\u7528TF\u7f16\u7801\u5668\uff0c\u56e0\u6b64\u5c42\u7ea7\u95f4\u7684\u56fe\u50cf\u5e8f\u5217\u65e0\u6cd5\u5efa\u6a21\uff0c\u9700\u8981\u7528FPN\u6765\u52a0\u5f3a\u6d45\u5c42\u4e0e\u6df1\u5c42\u7279\u5f81\u7684\u8054\u7cfb\uff0c\u8981\u548cDeDETR\u505a\u597d\u533a\u5206\u3002</p> <p>BEVFormer</p> <ul> <li>\u9884\u8bbe\u4e00\u7ec4BEV\u67e5\u8be2\u5411\u91cfQ\u548cBEV\u4f4d\u7f6e\u7f16\u7801\u5411\u91cf\uff0c\u5c3a\u5bf8\u5747\u4e3a[w_{bev}*h_{bev}, 256]\uff0c\u5176\u4e2d\u67e5\u8be2\u5411\u91cf\u4e3a\u53ef\u5b66\u4e60\u7684\u53c2\u6570\uff0c\u4f4d\u7f6e\u7f16\u7801\u5411\u91cf\u4e3a\u9884\u8bbe\u597d\u7684\u53c2\u6570\uff1b</li> <li>\u9884\u8bbe\u4e00\u7ec4\u76f8\u673a\u5e8f\u53f7\u7f16\u7801\u548c\u7279\u5f81\u5c42\u7ea7\u7f16\u7801\uff0c\u5c3a\u5bf8\u5206\u522b\u4e3a[n_{cam},256]\u548c[4,256]\uff0c\u5747\u4e3a\u53ef\u5b66\u4e60\u7684\u53c2\u6570\uff0c\u4e4b\u540e\u5c06\u56fe\u50cf\u7279\u5f81\u6cbf\u957f\u5bbd\u65b9\u5411\u62c9\u76f4\uff0c\u53d8\u4e3a\u7279\u5f81\u5e8f\u5217\uff0c\u5e76\u4e14\u6dfb\u52a0\u9884\u8bbe\u597d\u7684\u76f8\u673a\u5e8f\u53f7\u7f16\u7801\u4e0e\u7279\u5f81\u5c42\u7f16\u7801\uff1b</li> <li>\u5c0618\u7ef4\u5ea6\u7684CAN\u603b\u7ebf\u4fe1\u53f7\u6620\u5c04\u6210256\u7ef4\u5ea6\uff0c\u6dfb\u52a0\u5230BEV\u67e5\u8be2\u5411\u91cf\u4e2d\uff1b</li> <li>\u5229\u7528CAN\u603b\u7ebf\u6570\u636e\u8ba1\u7b97shift\u504f\u79fb\u91cf\uff0c\u7528\u4e8e\u8868\u793a\u8f66\u8f86\u5728BEV\u56fe\u4e2d\u7684\u504f\u79fb\u91cf\uff1b</li> </ul> <p>\u65f6\u95f4\u81ea\u6ce8\u610f\u529b\u6a21\u5757</p> <ul> <li>\u5728BEV\u4e8c\u7ef4\u4fef\u89c6\u5e73\u9762\u4e0a\uff0c\u8bbe\u7f6e\u4e00\u7ec4\u53c2\u8003\u70b9\uff0c\u53c2\u8003\u70b9\u7684\u6570\u91cf\u4e0eBEV\u7279\u5f81\u6570\u91cf\u4e00\u6837\uff08\u53ef\u4ee5\u89c6\u4e3a\u7f51\u683c\u70b9\uff09\uff0c\u5c3a\u5bf8\u4e3a[w_{bev}*h_{bev}, 2]\uff0c\u6570\u503c\u4ece0\u52301\uff0c\u7b49\u95f4\u8ddd\u589e\u5927\uff0c</li> <li>\u9884\u8bbe\u597d\u4e4b\u540e\uff0c\u4e0e\u524d\u9762\u8ba1\u7b97\u7684shift\u504f\u79fb\u91cf\u76f8\u52a0\uff0c\u5f97\u5230\u504f\u79fb\u4e8c\u7ef4\u53c2\u8003\u70b9\u5750\u6807\uff1b</li> <li>\u5728\u81ea\u6ce8\u610f\u529b\u6a21\u5757\u4e2d\uff0c\u5e94\u7528\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u8fd0\u7b97\uff0c\u5c06BEV\u67e5\u8be2\u5411\u91cfQ\u4e0eBEV\u4f4d\u7f6e\u7f16\u7801\u76f8\u52a0\uff0c\u4e4b\u540e\u4e0e\u5386\u53f2BEV\u7279\u5f81\u5806\u53e0\uff0c\u5145\u5f53\u4e3aq\uff0c\u5c06\u67e5\u8be2\u5411\u91cfQ\u4e0e\u5386\u53f2BEV\u7279\u5f81B_{t-1}\u5806\u53e0\uff0c\u5145\u5f53\u4e3av\u3002\u5c06q\u4f20\u5165\u7ebf\u6027\u6620\u5c04\u5c42\uff0c\u5206\u522b\u5f97\u5230\u53c2\u8003\u70b9\u7684\u504f\u79fb\u91cf\u548c\u6ce8\u610f\u529b\u6743\u91cd\uff0c\u4e4b\u540e\u5c06v\u3001\u91c7\u6837\u70b9\u3001\u6ce8\u610f\u529b\u6743\u91cd\u4f20\u5165\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u8ba1\u7b97\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u3002</li> </ul> <p>\u6ce8\uff1aBEV\u67e5\u8be2\u5411\u91cfQ\u540c\u65f6\u5bf9\u5386\u53f2BEV\u7279\u5f81B_{t-1}\u548c\u81ea\u8eabQ\u540c\u65f6\u505a\u6ce8\u610f\u529b\u8fd0\u7b97\uff0c\u4ece\u4e24\u7ec4\u7279\u5f81\u4e0a\u505a\u6295\u5f71\uff0c\u4e4b\u540e\u6709\u4e2a\u6c42\u5747\u503c\u64cd\u4f5c\u3002\uff08\u662f\u600e\u4e48\u5b9e\u73b0\u7684\uff0c\u7ec6\u8282\u90e8\u5206\u8fd8\u9700\u8981\u518d\u5b66\u4e60\u4e00\u4e0b\uff09\u3002</p> <p>\u7a7a\u95f4\u81ea\u6ce8\u610f\u529b\u6a21\u5757</p> <ul> <li>\u5728BEV\u4e09\u7ef4\u7a7a\u95f4\u4e0a\uff0c\u8bbe\u7f6e\u4e00\u7ec4\u53c2\u8003\u70b9\uff0c\u7528\u4e8e\u8868\u793aBEV\u7279\u5f81\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u4f4d\u7f6e\u5750\u6807\uff0c\u53c2\u8003\u70b9\u7684\u6570\u91cf</li> <li>\u5c06\u9884\u8bbe\u597d\u7684\u53c2\u8003\u70b9\u4f9d\u6b21\u6295\u5f71\u5230\u56fe\u50cf\u5e73\u9762\u4e2d\uff0c3D\u5750\u6807\u8f6c\u6362\u4e3a\u56fe\u50cf\u5750\u6807\uff0c\u5bf9\u4e8e\u6bcf\u4e2a\u76f8\u673a\uff0c\u7b5b\u9009\u51fa\u76f8\u673a\u89c6\u91ce\u5185\u7684BEV\u7279\u5f81\u3002\u5148\u5c06\u5750\u6807\u70b9\u8f6c\u4e3a\u771f\u5b9e\u4e16\u754c\u4e2d\u7684\u5750\u6807\u6570\u636e\uff08\u4e4b\u524d\u8bbe\u7f6e\u7684\u662f\u5f52\u4e00\u5316\u540e\u7684\u76f8\u5bf9\u5750\u6807\uff09\uff0c\u76f8\u5f53\u4e8e\u5728\u771f\u5b9e\u4e16\u754c\u4e2d\u5efa\u7acb3D\u7684\u7f51\u683c\uff0c\u4ee5\u6570\u636e\u96c6nuScenes\u4e3a\u4f8b\uff0c\u957f\u5bbd\u8303\u56f4\u5747\u4e3a[-51.2m,51.2m]\uff0c\u9ad8\u5ea6\u8303\u56f4\uff08z\u8f74\uff09\u4e3a[-5m,3m]\uff1b\u6b64\u65f6\u53ef\u4ee5\u5c06\u53c2\u8003\u70b9\u770b\u6210\u70b9\u4e91\u5750\u6807\u6570\u636e\uff0c\u8ba9\u5750\u6807\u6570\u636e\u4e0e\u65cb\u8f6c\u77e9\u9635\u505a\u4e58\u6cd5\uff0c\u8f6c\u4e3a\u56fe\u50cf\u5750\u6807\u7cfb\u4e0b\u7684\u6570\u636e\uff0c\u4e4b\u540e\u6839\u636e\u662f\u5426\u8d8a\u754c\uff0c\u5bf9\u6bcf\u4e2a\u5750\u6807\u6253\u4e0amask\u6807\u7b7e\uff1b</li> </ul> <p>\u6ce8\uff1a\u4e00\u4e2aBEV\u53c2\u8003\u70b9\u5750\u6807\u6570\u636e\u4f1a\u751f\u6210\u591a\u4e2a\u56fe\u50cf\u5750\u6807\u7cfb\u4e0b\u7684\u6570\u636e\uff08\u6bcf\u4e2a\u76f8\u673a\u4e00\u4e2a\uff09\uff0c\u6ca1\u8d8a\u754c\u7684\u5750\u6807\u8bf4\u660e\u5728\u76f8\u673a\u89c6\u91ce\u5185\uff0c\u5373\u5f53\u524d\u70b9\u7684BEV\u7279\u5f81\u4f1a\u4e0e\u5f53\u524d\u56fe\u50cf\u7684\u8be5\u5750\u6807\u70b9\u4e0b\u6709\u5bf9\u5e94\u5173\u7cfb\uff0c\u53ef\u4ee5\u7528\u6ce8\u610f\u529b\u673a\u5236\u505a\u8fd0\u7b97\uff0c\u63d0\u53d6\u6709\u7528\u7684\u7279\u5f81\u3002</p> <ul> <li>\u5728\u4ea4\u53c9\u6ce8\u610f\u529b\u6a21\u5757\u4e2d\uff0cq\u4e3aBEV\u67e5\u8be2\u5411\u91cf\uff0ckv\u4e3a\u56fe\u50cf\u7279\u5f81\u3002\u5bf9\u4e8e\u6bcf\u5f20\u56fe\u50cf\uff0c\u5148\u901a\u8fc7\u53c2\u8003\u70b9\u7684mask\u6807\u7b7e\uff0c\u627e\u51fa\u4e0e\u4e4b\u5bf9\u5e94\u7684BEV\u67e5\u8be2\u5411\u91cf\u7279\u5f81\u70b9\uff0c\u5c06\u8fd9\u4e9bBEV\u67e5\u8be2\u7279\u5f81\u4e0e\u5bf9\u5e94\u7684\u53c2\u8003\u70b9\u5750\u6807\u63d0\u51fa\u6765\uff0c\u5355\u72ec\u8ba1\u7b97\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\uff0c\u4ee5nuScenes\u4e3a\u4f8b\uff0c\u6bcf\u4e2abatch\u4f1a\u5bf9\u5e946\u7ec4kv\u6570\u636e\u3002\u540c\u65f6\u4e5f\u5bf9\u5e946\u7ec4q\u6570\u636e\uff0c\u4f9d\u6b21\u8ba1\u7b97\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\uff0c\u8ba1\u7b97\u5b8c\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u540e\uff0c\u5c06\u5f97\u5230\u7684\u6570\u636e\u8d4b\u503c\u56de\u53bb\uff08\u4eceBEV\u67e5\u8be2\u5411\u91cf\u4e2d\u54ea\u62c6\u51fa\u6765\u7684\uff0c\u5c31\u518d\u653e\u54ea\u56de\u53bb\uff09\u3002</li> </ul> <p>\u6ce8\uff1a</p> <ul> <li>\u5bf9\u4e8eBEV\u67e5\u8be2\u5411\u91cf\u4e0a\u7684\u6bcf\u4e2a\u7279\u5f81\u70b9\uff0c\u53ef\u4ee5\u89c6\u4e3a\u4e00\u4e2a\u67f1\u72b6\uff0c\u4e0a\u9762\u6709\u56db\u4e2a\u5750\u6807\uff0c\u56fe\u50cf\u4e0a\u7684\u50cf\u7d20\u5728\u4e0eBEV\u7279\u5f81\u505a\u5173\u8054\u65f6\uff0c\u53ef\u80fd\u4f1a\u5173\u8054\u5230\u56db\u4e2a\u5750\u6807\u4e2d\u7684\u4efb\u610f\u4e00\u4e2a\uff08\u6ce8\u610f\uff0c\u6700\u591a\u53ea\u80fd\u5173\u8054\u5230\u4e00\u4e2a\uff0c\u53734\u90091\uff0c\u56e0\u4e3a\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u7269\u4f53\uff0c\u9ad8\u5ea6\u6570\u503c\u662f\u552f\u4e00\u7684\uff09\uff0c\u53ea\u8981\u6709\u4e00\u4e2a\u5750\u6807\u80fd\u591f\u6620\u5c04\u5230\u56fe\u50cf\u4e0a\u7684\u8be5\u50cf\u7d20\u70b9\uff0c\u5219\u6211\u4eec\u8ba4\u4e3aBEV\u67e5\u8be2\u5411\u91cf\u4e2d\u7684\u8be5\u7279\u5f81\u70b9\u53ef\u4ee5\u4e0e\u8be5\u56fe\u50cf\u7279\u5f81\u5efa\u7acb\u8054\u7cfb\uff0c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u8ba1\u7b97\u6ce8\u610f\u529b\uff1b</li> <li>\u6ce8\u610f\u8fd9\u79cd\u903b\u8f91\u5173\u7cfb\uff1a\u5728\u505aBEV\u67e5\u8be2\u5411\u91cf\u4e0e\u56fe\u50cf\u7279\u5f81\u4e4b\u95f4\u7684\u6620\u5c04\u65f6\uff0c\u67e5\u8be2\u5411\u91cf\u5148\u5efa\u7acb\u4e09\u7ef4\u7f51\u683c\u70b9\uff08\u4e0e\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u4e09\u7ef4\u5750\u6807\u70b9\u76f8\u5bf9\u5e94\uff0c\u7c7b\u4f3c\u4e8e\u6784\u9020\u57fa\u4e8eBEV\u7684\u201c\u70b9\u4e91\u201d\u6570\u636e\uff09\uff0c\u4e4b\u540e\u901a\u8fc7\u65cb\u8f6c\u77e9\u9635\uff0c\u5c06\u5750\u6807\u70b9\u6620\u5c04\u5230\u6bcf\u4e2a\u56fe\u50cf\u4e0a\u53bb\uff0c\u6620\u5c04\u5230\u7684\u5750\u6807\u70b9\u5c31\u53ef\u4ee5\u89c6\u4e3a\u53c2\u8003\u70b9\uff0c\u540e\u7eed\u518d\u901a\u8fc7q\u9884\u6d4b\u504f\u79fb\u91cf\uff0c\u8fdb\u4e00\u6b65\u8ba1\u7b97\u91c7\u6837\u70b9\uff0c\u672c\u8d28\u4e0a\u6765\u8bf4\uff0c\u6ce8\u610f\u529b\u64cd\u4f5c\u5c31\u662f\u5728\u56fe\u50cf\u7279\u5f81\u4e0a\u91c7\u6837\uff0c\u4e4b\u540e\u52a0\u6743\u56deBEV\u7279\u5f81\u3002</li> <li>\u4e4b\u6240\u4ee5\u8981\u6cbf\u76f8\u673a\u65b9\u5411\u505a\u62c6\u5206\uff0c\u5c31\u662f\u4e3a\u4e86\u8ba9\u6bcf\u4e2a\u76f8\u673a\u56fe\u7247\u53ea\u4e0e\u76f8\u5e94\u7684BEV\u67e5\u8be2\u5411\u91cf\u505a\u4ea4\u4e92\uff0c\u5927\u5927\u51cf\u5c11GPU\u7684\u8fd0\u7b97\u91cf\u3002</li> </ul> <p>\u89e3\u7801\u6a21\u5757\uff08\u8fd9\u91cc\u4e0e\u4e00\u822c\u7684\u89e3\u7801\u6a21\u5757\u7c7b\u4f3c\uff0c\u5982DeDETR\uff09</p> <ul> <li>\u9884\u8bbe\u4e00\u7ec4\u7269\u4f53\u67e5\u8be2\u5411\u91cfQ\u3001\u521d\u59cb\u7684\u89e3\u7801\u7279\u5f81tgt\uff08\u4e8c\u8005\u7c7b\u4f3c\uff0c\u6570\u636e\u5747\u4e3a\u53ef\u5b66\u4e60\u7684\u53c2\u6570\uff0c\u5c3a\u5bf8\u5747\u4e3a[\u67e5\u8be2\u4e2a\u6570\u3001\u7279\u5f81\u7ef4\u5ea6]\uff09\uff0c\u5c06\u67e5\u8be2\u5411\u91cf\u4f20\u5165\u7ebf\u6027\u6620\u5c04\u5c42\uff0c\u6620\u5c04\u4e3a3\u4e2a\u6570\uff0c\u8868\u793a\u8fb9\u754c\u6846\u53c2\u8003\u70b9\u5750\u6807\uff0c\u53c2\u8003\u70b9\u5750\u6807\u6570\u636e\u7684\u5c3a\u5bf8\u4e3a[\u67e5\u8be2\u4e2a\u6570, 3]\uff08\u540e\u7eed\u518d\u590d\u52364\u500d\uff0c\u6bcf\u4e2a\u7269\u4f53\u67e5\u8be2\u91c7\u68374\u4e2a\u70b9\uff09\uff0c\u8fd9\u91cc\u8ba1\u7b97\u53c2\u8003\u70b9\u4e5f\u662f\u4e3a\u4e86\u540e\u7eed\u5728\u89e3\u7801\u8fc7\u7a0b\u4e2d\uff0c\u5f15\u5165\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u8fd0\u7b97\uff1b</li> <li>\u8ba1\u7b97\u4ea4\u53c9\u6ce8\u610f\u529b\uff08\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u8fd0\u7b97\uff09\uff0c\u5176\u4e2dq\u4e3a\u89e3\u7801\u7279\u5f81tgt\u4e0e\u67e5\u8be2\u5411\u91cfQ\u76f8\u52a0\uff0c\u5c3a\u5bf8\u4e3a[\u67e5\u8be2\u4e2a\u6570,\u7279\u5f81\u7ef4\u5ea6]\uff0ck\u4e3a\u8fb9\u754c\u6846\u53c2\u8003\u70b9\u5750\u6807\uff0c\u5c3a\u5bf8\u4e3a[\u67e5\u8be2\u4e2a\u6570,4,2]\uff08\u9009\u53d6\u524d\u4e24\u4e2a\u5750\u6807\uff0c\u4ee5\u4fef\u89c6\u7684\u89c6\u89d2\u6765\u770b\uff09\uff0cv\u4e3aBEV\u7279\u5f81\uff0c\u5c3a\u5bf8\u4e3a[w_{bev}*h_{bev}, 256]\u3002q\u5148\u7ecf\u8fc7\u4e24\u6b21\u7ebf\u6027\u6620\u5c04\uff0c\u5f97\u5230\u53c2\u8003\u70b9\u7684\u504f\u79fb\u91cf\u548c\u6ce8\u610f\u529b\u6743\u91cd\uff0c\u504f\u79fb\u91cf\u4e0e\u53c2\u8003\u70b9\u5750\u6807\u76f8\u52a0\uff0c\u5f97\u5230\u91c7\u6837\u70b9\uff0c\u4e4b\u540e\u5c06v\u3001\u91c7\u6837\u70b9\u3001\u6ce8\u610f\u529b\u6743\u91cd\u4f20\u5165\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u8ba1\u7b97\u6ce8\u610f\u529b\uff1b</li> <li>\u5c06\u89e3\u7801\u7279\u5f81\u4f20\u5165\u9884\u6d4b\u5934\uff0c\u5229\u7528256\u4e2a\u7279\u5f81\u6570\u636e\u9884\u6d4b\u8fb9\u754c\u6846\u548c\u7c7b\u522b\uff0c\u5177\u4f53\u601d\u60f3\u8ddfDETR\u7c7b\u4f3c\u3002</li> </ul> <p>\u8bad\u7ec3\u9636\u6bb5</p> <ul> <li>\u8ba1\u7b97\u635f\u5931\u9636\u6bb5\u5f85\u5b9a\uff1b</li> </ul> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u6307\u6b63\u3002</p>"},{"location":"auto/paper/HADAR/","title":"HADAR\u2014\u2014\u70ed\u8f85\u52a9\u611f\u77e5\u7cfb\u7edf","text":""},{"location":"auto/paper/HADAR/#_1","title":"\u7efc\u8ff0","text":"<p>\u671f\u520a\u65f6\u95f4\uff1aNature 2023</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://www.nature.com/articles/s41586-023-06174-6</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/FanglinBao/HADAR</p>"},{"location":"auto/paper/HADAR/#_2","title":"\u9884\u5907\u77e5\u8bc6","text":""},{"location":"auto/paper/HADAR/#emissionscatter","title":"\u53d1\u5c04\uff08Emission\uff09\u548c\u6563\u5c04\uff08Scatter\uff09","text":"<p>\u5b9a\u4e49</p> <ul> <li>Emission\uff08\u53d1\u5c04\uff09\uff1a\u8fd9\u662f\u6307\u4e00\u79cd\u8fc7\u7a0b\uff0c\u5176\u4e2d\u4e00\u4e2a\u7269\u4f53\u6216\u7cfb\u7edf\u91ca\u653e\u80fd\u91cf\u6216\u7c92\u5b50\u3002\u8fd9\u53ef\u4ee5\u662f\u5149\u3001\u70ed\u80fd\u3001\u7c92\u5b50\u7b49\u7684\u91ca\u653e\u3002\u4f8b\u5982\uff0c\u4e00\u4e2a\u70ed\u4f53\u53d1\u5c04\u70ed\u8f90\u5c04\u5c31\u662f\u4e00\u4e2a\u53d1\u5c04\u8fc7\u7a0b\uff0c\u7c7b\u4f3c\u4e8e\u592a\u9633\u53d1\u5c04\u5149\u548c\u70ed\u80fd\uff1b</li> <li>Scatter\uff08\u6563\u5c04\uff09\uff1a\u8fd9\u662f\u6307\u5f53\u5149\u6216\u7c92\u5b50\u4e0e\u7269\u8d28\u76f8\u4e92\u4f5c\u7528\u65f6\uff0c\u6539\u53d8\u5176\u4f20\u64ad\u65b9\u5411\u800c\u4e0d\u6539\u53d8\u5176\u80fd\u91cf\u7684\u8fc7\u7a0b\u3002\u5728\u6563\u5c04\u8fc7\u7a0b\u4e2d\uff0c\u5149\u6216\u7c92\u5b50\u4f1a\u4ece\u539f\u6765\u7684\u8def\u5f84\u4e0a\u504f\u79bb\uff08\u504f\u79bb\u4e86\u4f1a\u600e\u4e48\u6837\uff1f\uff09\uff0c\u4f46\u901a\u5e38\u4fdd\u6301\u5176\u80fd\u91cf\u4e0d\u53d8\u3002\u8fd9\u4e2a\u8fc7\u7a0b\u53ef\u4ee5\u5728\u591a\u79cd\u60c5\u51b5\u4e0b\u53d1\u751f\uff0c\u5982\u5149\u5728\u7a7a\u6c14\u4e2d\u6563\u5c04\u3001X\u5c04\u7ebf\u5728\u7269\u8d28\u4e2d\u6563\u5c04\u7b49\u3002</li> </ul> <p>\u80fd\u91cf\u6539\u53d8</p> <ul> <li>Emission\uff08\u53d1\u5c04\uff09\uff1a\u5728\u53d1\u5c04\u8fc7\u7a0b\u4e2d\uff0c\u7269\u4f53\u6216\u7cfb\u7edf\u901a\u5e38\u91ca\u653e\u80fd\u91cf\uff0c\u8fd9\u610f\u5473\u7740\u80fd\u91cf\u4ece\u9ad8\u72b6\u6001\u8f6c\u79fb\u5230\u4f4e\u72b6\u6001\u3002\u8fd9\u662f\u4e00\u4e2a\u80fd\u91cf\u91ca\u653e\u7684\u8fc7\u7a0b\u3002</li> <li>Scatter\uff08\u6563\u5c04\uff09\uff1a\u5728\u6563\u5c04\u8fc7\u7a0b\u4e2d\uff0c\u901a\u5e38\u4e0d\u6539\u53d8\u5149\u6216\u7c92\u5b50\u7684\u603b\u80fd\u91cf\uff0c\u53ea\u662f\u6539\u53d8\u4e86\u5176\u4f20\u64ad\u65b9\u5411\u3002</li> </ul> <p>\u5149\u8c31\u8f90\u5c04\u7387\uff08spectral emissivity\uff09</p> <p>\u200b   \u5149\u8c31\u8f90\u5c04\u7387\uff08spectral emissivity\uff09\u662f\u4e00\u4e2a\u7528\u4e8e\u63cf\u8ff0\u7269\u4f53\u8868\u9762\u5bf9\u70ed\u8f90\u5c04\u7684\u7279\u6027\u7684\u7269\u7406\u91cf\u3002\u5b83\u662f\u4e00\u4e2a\u4e0e\u6ce2\u957f\u6216\u9891\u7387\u6709\u5173\u7684\u53c2\u6570\uff0c\u7528\u4e8e\u8868\u793a\u7269\u4f53\u5728\u4e0d\u540c\u6ce2\u957f\u6216\u9891\u7387\u4e0b\u5438\u6536\u548c\u8f90\u5c04\u70ed\u8f90\u5c04\u7684\u80fd\u529b\u3002</p> <p>\u200b   \u5177\u4f53\u6765\u8bf4\uff0c\u5149\u8c31\u8f90\u5c04\u7387\u662f\u4e00\u4e2a\u4ecb\u4e8e0\u548c1\u4e4b\u95f4\u7684\u6570\u503c\uff0c\u8868\u793a\u4e86\u7269\u4f53\u8868\u9762\u5728\u7279\u5b9a\u6ce2\u957f\u6216\u9891\u7387\u4e0b\u5438\u6536\u548c\u8f90\u5c04\u70ed\u8f90\u5c04\u7684\u76f8\u5bf9\u80fd\u529b\u3002\u5f53\u5149\u8c31\u8f90\u5c04\u7387\u4e3a1\u65f6\uff0c\u8868\u793a\u7269\u4f53\u8868\u9762\u662f\u5b8c\u7f8e\u7684\u9ed1\u4f53\uff0c\u5b83\u80fd\u591f\u5b8c\u5168\u5438\u6536\u5e76\u8f90\u5c04\u70ed\u8f90\u5c04\u3002\u5f53\u5149\u8c31\u8f90\u5c04\u7387\u4e3a0\u65f6\uff0c\u8868\u793a\u7269\u4f53\u8868\u9762\u662f\u5b8c\u5168\u53cd\u5c04\u70ed\u8f90\u5c04\u7684\uff0c\u4e0d\u5438\u6536\u4efb\u4f55\u8f90\u5c04\u3002\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\uff0c\u7269\u4f53\u7684\u5149\u8c31\u8f90\u5c04\u7387\u4ecb\u4e8e0\u548c1\u4e4b\u95f4\uff0c\u8868\u73b0\u4e3a\u4e0d\u540c\u6ce2\u957f\u6216\u9891\u7387\u4e0b\u7684\u53d8\u5316\u3002</p> <p>\u200b   \u5149\u8c31\u8f90\u5c04\u7387\u901a\u5e38\u662f\u6ce2\u957f\u6216\u9891\u7387\u7684\u51fd\u6570\uff0c\u56e0\u6b64\u5b83\u53ef\u4ee5\u63cf\u8ff0\u7269\u4f53\u5728\u4e0d\u540c\u7684\u5149\u8c31\u8303\u56f4\u5185\u7684\u8f90\u5c04\u7279\u6027\u3002\u4e0d\u540c\u7684\u6750\u6599\u548c\u8868\u9762\u72b6\u6001\u4f1a\u5bfc\u81f4\u4e0d\u540c\u7684\u5149\u8c31\u8f90\u5c04\u7387\u66f2\u7ebf\uff0c\u8fd9\u5bf9\u4e8e\u7ea2\u5916\u6210\u50cf\u3001\u70ed\u611f\u5e94\u548c\u70ed\u8f90\u5c04\u5206\u6790\u7b49\u5e94\u7528\u975e\u5e38\u91cd\u8981\u3002\u79d1\u5b66\u5bb6\u548c\u5de5\u7a0b\u5e08\u4f7f\u7528\u5149\u8c31\u8f90\u5c04\u7387\u6765\u4e86\u89e3\u7269\u4f53\u7684\u70ed\u6027\u8d28\u3001\u6750\u6599\u7279\u6027\u548c\u8868\u9762\u72b6\u6001\uff0c\u8fd9\u5728\u5404\u79cd\u9886\u57df\uff0c\u5305\u62ec\u6750\u6599\u79d1\u5b66\u3001\u5de5\u7a0b\u3001\u7ea2\u5916\u6210\u50cf\u548c\u9065\u611f\u7b49\u65b9\u9762\u90fd\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u3002</p>"},{"location":"auto/paper/HADAR/#_3","title":"\u4e3b\u8981\u601d\u60f3","text":"<p>\u2003\u2003\u5728\u73b0\u4ee3\u5de5\u4e1a\u6280\u672f\u7684\u53d1\u5c55\u4e2d\uff0c\u667a\u80fd\u4f53\u901a\u5e38\u4f7f\u7528\u975e\u5e38\u5148\u8fdb\u7684\u4f20\u611f\u5668\u8bbe\u5907\u6765\u611f\u77e5\u5468\u56f4\u7684\u73af\u5883\uff0c\u4ece\u800c\u5728\u6ca1\u6709\u4eba\u4e3a\u5e72\u9884\u7684\u60c5\u51b5\u4e0b\u505a\u51fa\u51b3\u7b56\u3002\u7136\u800c\uff0c\u4ece\u5b89\u5168\u6027\u7684\u89d2\u5ea6\u51fa\u53d1\uff0c\u8bb8\u591a\u667a\u80fd\u4f53\u5728\u611f\u77e5\u573a\u666f\u65f6\u4ece\u6839\u672c\u4e0a\u7981\u6b62\u4e3b\u52a8\u6a21\u5f0f\uff0c\u5373\u4e0d\u5141\u8bb8\u8ba9\u667a\u80fd\u4f53\u4e3b\u52a8\u91c7\u53d6\u884c\u52a8\u8fdb\u884c\u4ea4\u4e92\uff0c\u5f80\u5f80\u9700\u8981\u4f9d\u9760\u76f8\u673a\u3001\u96f7\u8fbe\u8bbe\u5907\u6765\u88ab\u52a8\u5730\u611f\u77e5\u3001\u63a2\u7d22\u73af\u5883\u3002\u4f46\u662f\uff0c\u8fd9\u79cd\u88ab\u52a8\u7b56\u7565\u4e5f\u5177\u6709\u4e00\u5b9a\u7684\u5c40\u9650\u6027\uff0c\u4f8b\u5982\u7528\u76f8\u673a\u53bb\u611f\u77e5\u73af\u5883\u8fd9\u4e00\u8fc7\u7a0b\u5bf9\u5149\u7167\u6761\u4ef6\u8981\u6c42\u5f88\u9ad8\uff0c\u5728\u5f3a\u5149\u3001\u9ed1\u6697\u6216\u8005\u6076\u52a3\u5929\u6c14\u4e2d\u5f80\u5f80\u96be\u4ee5\u6355\u83b7\u573a\u666f\u4fe1\u606f\u3002</p> <p>\u2003\u2003\u5728\u8fd9\u79cd\u9ed1\u591c\u6216\u6076\u52a3\u5929\u6c14\u7684\u60c5\u51b5\u4e0b\uff0c\u4e00\u79cd\u5e38\u89c1\u7684\u5e94\u5bf9\u65b9\u6cd5\u5c31\u662f\u4f7f\u7528\u6765\u81ea\u7ea2\u5916\u70ed\u8f90\u5c04\u4fe1\u53f7\u53bb\u611f\u77e5\u73af\u5883\uff0c\u4e5f\u5c31\u662f\u5229\u7528\u7ea2\u5916\u70ed\u4fe1\u53f7\u53bb\u6210\u50cf\uff0c\u53ef\u4ee5\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u770b\u6e05\u7269\u4f53\u7684\u8f6e\u5ed3\u3001\u5f62\u72b6\u3002\u7136\u800c\uff0c\u70ed\u8f85\u52a9\u611f\u77e5\u5b58\u5728\u6839\u672c\u7684\u969c\u788d\uff0c\u573a\u666f\u7684\u591a\u79cd\u7269\u7406\u5c5e\u6027\u6df7\u5408\u5728\u5149\u5b50\u6d41\u4e2d\uff08\u5373\uff1a\u6e29\u5ea6T-\u7269\u7406\u72b6\u6001\u3001\u8f90\u5c04\u7cfb\u6570M-\u6750\u6599\u6307\u7eb9\u3001\u7eb9\u7406X-\u8868\u9762\u51e0\u4f55\uff09\uff0c\u7269\u4f53\u548c\u73af\u5883\u4e0d\u65ad\u5730\u53d1\u5c04\u548c\u6563\u5c04\u70ed\u8f90\u5c04\uff0c\u8fdb\u4e00\u6b65\u5bfc\u81f4\u6210\u50cf\u56fe\u7247\u7f3a\u5c11\u7eb9\u7406\u3001\u6df1\u5ea6\u4fe1\u606f\uff0c\u8fd9\u4e00\u8fc7\u7a0b\u8868\u73b0\u4e3a\u201c\u91cd\u5f71\u6548\u5e94\u201d\uff08ghosting effect\uff09\uff0c\u7eb9\u7406\u3001\u6df1\u5ea6\u4fe1\u606f\u7684\u7f3a\u5931\u964d\u4f4e\u4e86\u70ed\u6210\u50cf\u7684\u4fe1\u606f\u4e30\u5bcc\u5ea6\uff0c\u5bfc\u81f4\u70ed\u6210\u50cf\u5177\u6709\u6a21\u7cca\u3001\u7f3a\u4e4f\u7ec6\u8282\u7b49\u95ee\u9898\uff0c\u667a\u80fd\u4f53\u5f88\u96be\u6839\u636e\u70ed\u6210\u50cf\u5224\u65ad\u7269\u4f53\u7684\u5f62\u72b6\u3001\u8ddd\u79bb\u3001\u6750\u8d28\u7b49\u5c5e\u6027\uff0c\u4e25\u91cd\u5f71\u54cd\u4e86\u667a\u80fd\u4f53\u7684\u73af\u5883\u611f\u77e5\u3002</p> <p>\u2003\u2003\u672c\u6587\u4e2d\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u70ed\u8f85\u52a9\u68c0\u6d4b\u548c\u6d4b\u8ddd\u7b97\u6cd5\uff08Heat-Assisted Detection And Ranging, HADAR\uff09\u6765\u514b\u670d\u8fd9\u4e00\u6311\u6218\uff0cHADAR\u4e0d\u4ec5\u80fd\u5728\u9ed1\u591c\u4e2d\u770b\u5230\u7eb9\u7406\u548c\u6df1\u5ea6\u4fe1\u606f\uff08\u5c31\u50cf\u767d\u5929\u4e00\u6837\uff09\uff0c\u8fd8\u53ef\u4ee5\u611f\u77e5\u5230RGB\u6216\u70ed\u89c6\u89c9\u4e4b\u5916\u7684\u7269\u7406\u5c5e\u6027\uff0c\u4e3a\u5b9e\u73b0\u5b8c\u5168\u88ab\u52a8\u7684\u667a\u80fd\u4f53\u611f\u77e5\u4efb\u52a1\u94fa\u5e73\u4e86\u9053\u8def\u3002\u4f5c\u8005\u5728\u672c\u6587\u4e2d\u63d0\u51fa\u4e86HADAR\u4f30\u8ba1\u7406\u8bba\uff0c\u5e76\u89e3\u51b3\u4e86\u5b83\u7684\u5149\u5b50\u5c04\u51fb\u566a\u58f0\u9650\u5236\uff0c\u63cf\u7ed8\u4e86\u57fa\u4e8eHADAR\u7684\u4eba\u5de5\u667a\u80fd\u6027\u80fd\u7684\u4fe1\u606f\u8bba\u754c\u9650\uff0cHADAR\u5728\u591c\u95f4\u7684\u611f\u77e5\u6027\u80fd\u8981\u4f18\u4e8e\u70ed\u6210\u50cf\u7684\u611f\u77e5\u6027\u80fd\uff0c\u5e76\u4e14\u5728\u767d\u5929\u663e\u793a\u51fa\u4e86\u4e0eRGB\u7acb\u4f53\u89c6\u89c9\u76f8\u5f53\u7684\u7cbe\u5ea6\u3002</p> <p>Tex\u5206\u89e3\u548cTex\u89c6\u89c9</p> <p>\u2003\u2003\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cdTex\u5206\u89e3\u65b9\u6cd5\u6765\u89e3\u51b3\u91cd\u5f71\u6548\u5e94\uff0c\u8fd9\u79cd\u7b56\u7565\u53ef\u4ee5\u4ece\u6742\u4e71\u7684\u70ed\u4fe1\u53f7\u4e2d\u6062\u590d\u7eb9\u7406\uff0c\u5e76\u4e14\u51c6\u786e\u5730\u89e3\u51faCramer-Rao\u8fb9\u754c\u4e0a\u7684\u6e29\u5ea6\u548c\u53d1\u5c04\u7387\uff08\u514b\u62c9\u7f8e-\u52b3\u754c\u9650\uff0c\u7edf\u8ba1\u5b66\u6982\u5ff5\uff09\uff0c\u5177\u4f53\u6d41\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u5177\u4f53\u6062\u590d\u6548\u679c\u56fe\u5982\u4e0b\u6240\u793a\uff0c\u5728\u591c\u95f4\uff0cHADAR\u53ef\u4ee5\u6709\u6548\u5730\u514b\u670d\u591c\u95f4\u91cd\u5f71\u6548\u5e94\uff0c\u6355\u83b7\u7eb9\u7406\u7279\u5f81\u6e05\u6670\u7684\u56fe\u50cf\uff08\u9ed1\u767d\u56fe\u4e3a\u70ed\u6210\u50cf\u6848\u4f8b\uff0c\u5f69\u8272\u56fe\u4e3aHADAR\u6210\u50cf\u6848\u4f8b\uff09\uff1a</p> <p> <p></p> <p></p> <p>\u91cd\u5f71\u6548\u5e94\uff08ghosting effect\uff09</p> <p>\u2003\u2003\u9996\u5148\u4f5c\u8005\u4f7f\u7528\u4e86\u4e00\u4e2a\u706f\u6ce1\u70ed\u8f90\u5c04\u7684\u4f8b\u5b50\u6765\u89e3\u91ca\u91cd\u5f71\u6548\u5e94\u7684\u8d77\u6e90\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u53ea\u6709\u5f53\u706f\u6ce1\u5173\u95ed\u65f6\uff0c\u624d\u80fd\u770b\u5230\u706f\u6ce1\u8868\u9762\u7684\u51e0\u4f55\u7eb9\u7406\uff0c\u5f53\u706f\u6ce1\u6253\u5f00\u65f6\uff0c\u53cd\u5c04\u6240\u663e\u793a\u7684\u7eb9\u7406\u5728\u201c\u76f4\u63a5\u8f90\u5c04\u201d\uff08direct emission\uff09\u4e2d\u4f1a\u5b8c\u5168\u6d88\u5931\u3002\u800c\u5728\u590d\u6742\u573a\u666f\u4e2d\uff0c\u6bcf\u4e2a\u7269\u4f53\u90fd\u4f1a\u53d1\u5c04\u70ed\u8f90\u5c04\uff0c\u56e0\u6b64\u4ed6\u4eec\u90fd\u662f\u6ca1\u6709\u7eb9\u7406\u7684\u70ed\u5149\u6e90\uff0c\u7c7b\u4f3c\u4e8e\u53d1\u5149\u7684\u706f\u6ce1\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u5bf9\u4e8e\u4e00\u4e2a\u79fb\u52a8\u7684\u7269\u4f53\\alpha\u800c\u8a00\uff0c\u603b\u70ed\u4fe1\u53f7\u6709\u4e24\u4e2a\u9644\u52a0\u503c\uff1a $$ S_{\\alpha v}=e_{\\alpha v}B_v(T_{\\alpha})+[1-e_{\\alpha v}]X_{\\alpha v} $$  \u5176\u4e2d\uff0ce\u8868\u793a\u6750\u8d28\u7684\u53d1\u5c04\u7387\u4fe1\u606f\uff0c\u7b2c\u4e00\u9879\u4e3a\u7269\u4f53\u76f4\u63a5\u7684\u70ed\u8f90\u5c04\uff08\u6563\u5c04\uff0c\u65e0\u7eb9\u7406\uff09\uff0c\u7b2c\u4e8c\u9879\u4e3a\u73af\u5883\u8f90\u5c04\uff0c\u5b83\u662f\u7ecf\u8fc7\u4ece\u5176\u4ed6\u7269\u4f53\u6563\u5c04\u540e\u8fdb\u5165\u63a2\u6d4b\u5668\u7684\u8f90\u5c04\uff08\u643a\u5e26\u7eb9\u7406\uff09\uff0c\u4e0b\u6807v\u8868\u793a\u6ce2\u6570\uff08\u8c31\u6bb5\uff09\u7684\u4f9d\u8d56\u6027\uff08wavenumber dependence\uff0c\u8868\u793a\u8fd9\u4e9b\u7269\u7406\u91cf\u5982\u4f55\u968f\u7740\u6ce2\u6570\u7684\u53d8\u5316\u800c\u53d8\u5316\uff09\uff0c\u9ed1\u4f53\u8f90\u5c04Bv\u4e0e\u53d1\u5149\u706f\u6ce1\u7684\u5173\u952e\u533a\u522b\u5728\u4e8e\uff0c\u9ed1\u4f53\u81ea\u8eab\u7684\u70ed\u8f90\u5c04\u4ece\u6839\u672c\u4e0a\u53d7\u666e\u6717\u514b\u5b9a\u5f8b\u652f\u914d\uff0c\u65e0\u6cd5\u88ab\u5173\u95ed\uff0c\u56e0\u6b64\u603b\u70ed\u4fe1\u53f7\u4e2d\uff0c\u603b\u4f1a\u63ba\u6742\u4e00\u5b9a\u6bd4\u4f8b\u7684\u65e0\u7eb9\u7406\u70ed\u4fe1\u53f7\u3002\u65e0\u7eb9\u7406\u7684\u70ed\u6210\u50cf\u88ab\u5e7f\u6cdb\u8ba4\u4e3a\u662f\u4e0d\u53ef\u80fd\u7528\u4e8e\u5bf9\u573a\u666f\u7684\u5b9a\u91cf\u6d1e\u5bdf\uff0c\u6240\u6709\u5176\u4ed6\u7269\u4f53\u03b2\u5bf9\u5f53\u524d\u7269\u4f53\u03b1\u7684\u73af\u5883\u70ed\u7167\u5ea6\u7531\u4e0b\u9762\u8fd9\u4e2a\u5f0f\u5b50\u7ed9\u51fa\uff1a $$ X_{\\alpha v}=\\sum_{\\beta\\neq\\alpha}V_{\\alpha\\beta}S_{\\beta v} $$ </p> <p>\u5176\u4e2dV_{\u03b1\u03b2}\u4e3a\u70ed\u7167\u5ea6\u56e0\u5b50\uff0c\u5bf9\u4e8e\u81ea\u7136\u4e2d\u9ad8\u53d1\u5c04\u7387\u7684\u6750\u6599\uff08\u4f8b\u5982\u76ae\u80a4\u548c\u690d\u7269\uff0ce\u22481\uff09\uff0c\u91cd\u5f71\u6548\u679c\u5c06\u4f1a\u52a0\u5267\uff0c\u56e0\u4e3a\u6536\u96c6\u5230\u7684\u603b\u4fe1\u53f7\u4e3b\u8981\u7531\u76f4\u63a5\u53d1\u5c04\u548c\u5fae\u5f31\u7684\u6563\u5c04\u4fe1\u53f7\u7ec4\u6210\uff0c\u56e0\u6b64\u7269\u4f53\u7684\u80fd\u91cf\u662f\u6162\u6162\u964d\u4f4e\u7684\uff0c\u6211\u4eec\u6ce8\u610f\u5230S_{\u03b1v}\u5728\u6e29\u5ea6T\u3001\u53d1\u5c04\u7387e\u548c\u7eb9\u7406X\u7684\u8054\u5408\u53d8\u6362\u4e0b\u662f\u4e0d\u53d8\u7684\uff08\u8054\u5408\u4e0d\u53d8\u7684\u662f\u6307\uff1f\u53ef\u4ee5\u552f\u4e00\u786e\u5b9a\u5417\uff1f\uff09\uff0c\u6211\u4eec\u5c06\u5176\u79f0\u4e3aTeX\u9000\u5316\u3002\u548c\u91cd\u5f71\u6548\u5e94\u4e00\u6837\uff0c\u8fd9\u79cdTeX\u9000\u5316\u4f7f\u5f97\u6e29\u5ea6\u548c\u53d1\u5c04\u7387\u7684\u5206\u79bb\u6210\u4e3a\u5b9a\u91cf\u70ed\u4f20\u611f\u7684\u4e00\u4e2a\u76f8\u5f53\u5927\u7684\u969c\u788d\u3002</p> <p>\u200b   \u4f5c\u8005\u901a\u8fc7\u6253\u7834TeX\u9000\u5316\uff0c\u5e76\u5c06\u5149\u8c31\u53d1\u5c04\u7387e_{\u03b1v}\u79bb\u6563\u4e3ae_v(m_a)\u6765\u6062\u590d\u7eb9\u7406\u4fe1\u606f\uff0c\u6750\u8d28\u5e93\u5305\u542b\u573a\u666f\u4e2d\u6240\u6709\u53ef\u80fd\u7684\u5149\u8c31\u53d1\u5c04\u7387\uff0c\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ \\mathcal M=\\{e_v(m)|m=1,2,\\dots,M\\} $$  \u8fd9\u79cd\u51cf\u5c11\u7ef4\u5ea6\u7684\u673a\u4f1a\u5728\u667a\u80fd\u5e94\u7528\u4e2d\u81ea\u7136\u5b58\u5728\uff0c\u56e0\u4e3a\u6750\u6599\u901a\u5e38\u5177\u6709\u5de5\u4e1a\u6807\u51c6\uff0c\u6750\u8d28\u5e93\u7528\u4e8e\u89e3\u91ca\u7269\u4f53\u7279\u5f81\uff0c\u540c\u65f6\u901a\u5e38\u9700\u8981\u73b0\u573a\u6536\u96c6/\u6821\u51c6\uff0c\u4f5c\u8005\u8fd8\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4e0d\u9700\u8981\u8f93\u5165\u7d20\u6750\u5e93\u7684\u5e7f\u4e49HADAR\u7406\u8bba\uff08\u5177\u4f53\u89c1\u8865\u5145\u6750\u6599SV.C\uff09\uff0c\u4f5c\u8005\u7684TeX-Net\u65b9\u6cd5\u4f7f\u7528\u516c\u5f0f\uff081\uff09\u6765\u8bbe\u8ba1\u57fa\u4e8e\u7269\u7406\u7684\u635f\u5931\uff08\u4e0a\u9762\u8ba1\u7b97Sav\u7684\u65b9\u6cd5\uff09\uff0c\u5e76\u4e14\u4f7f\u75283D\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6765\u5b66\u4e60\u6062\u590d\u7eb9\u7406X\u3001\u6e29\u5ea6T\u548c\u53d1\u5c04\u7387e\u7684\u7a7a\u95f4\u5149\u8c31\u7279\u5f81\u3002</p> <p>HADAR\u7684\u53ef\u8fa8\u522b\u6027</p> <p>\u2003\u2003\u4f5c\u8005\u53d1\u5c55\u4e86HADAR\u4f30\u8ba1\u7406\u8bba\u6765\u89e3\u51b3\u4ece\u5176\u70ed\u7ea2\u5916\u7279\u5f81\u8bc6\u522b\u76ee\u6807\u7684\u57fa\u672c\u9650\u5236\uff0c\u4ece\u6839\u6e90\u4e0a\u63d0\u5347\u673a\u5668\u611f\u77e5\u7684\u6027\u80fd\u3002HADAR\u4e0d\u540c\u4e8e\u4f20\u7edf\u7684\u9ad8\u5149\u8c31\u6210\u50cf\uff0c\u5728\u4f20\u7edf\u7684\u9ad8\u5149\u8c31\u6210\u50cf\u4e2d\uff0c\u6750\u6599\u7684\u5dee\u5f02\u662f\u7531\u5b83\u4eec\u53cd\u5c04\u5149\u8c31\u4e4b\u95f4\u7684\u6b27\u6c0f\u8ddd\u79bb\u51b3\u5b9a\u7684\u3002\u5f62\u6210\u9c9c\u660e\u5bf9\u6bd4\u7684\u662f\uff0cHADAR\u7684\u53ef\u8fa8\u522b\u6027\u7531\u6e29\u5ea6T\u3001\u53d1\u5c04\u7387E\u548c\u7eb9\u7406T\u4e09\u7ec4\u53c2\u6570\u4f30\u8ba1\u6240\u51b3\u5b9a\u7684\u3002\u4f5c\u8005\u63a2\u7d22\uff08exploit\uff09\u4e86\u591a\u53c2\u6570Cram\u00e9r\u2013Rao\u8fb9\u754c\uff0c\u5e76\u4e14\u63d0\u51fa\u4e86\u57fa\u4e8e\u7269\u4f53\u56fa\u6709\u7269\u8d28\u5c5e\u6027\u7684\u8bed\u4e49\u8ddd\u79bb\u5bf9\u7269\u4f53\u8fdb\u884c\u5206\u7c7b\uff0c\u4e0b\u56fe\u5c55\u793a\u4e86\u4eba\u7c7b\u4e0e\u673a\u5668\u4eba\u8bc6\u522b\u7684\u76f8\u5173\u793a\u4f8b\uff1a</p> <p> <p></p> <p></p> <p>\u4e00\u4e2a\u4eba\u5f62\u7684\u76ee\u6807\u53ef\u4ee5\u662f\u5177\u6709\u4e0d\u540c\u53d1\u5c04\u7387\u7684\u7269\u4f53\uff0c\u4f8b\u5982\u4eba\uff08\u6709\u673a\u76ae\u80a4\u6216\u7ec7\u7269\u6750\u6599\uff09\u6216\u673a\u5668\u4eba\uff08\u91d1\u5c5e\uff09\uff0c\u4f46\u4ed6\u4eec\u5728\u63a2\u6d4b\u5668\u4e0a\u4f1a\u4ea7\u751f\u89c6\u89c9\u4e0a\u65e0\u6cd5\u533a\u5206\u7684\u5165\u5c04\u5149\u8c31\uff0c\u4f5c\u8005\u5c06HADAR\u7684\u53ef\u8bc6\u522b\u6027\u5b9a\u4e49\u4e3a\u4eceN\u4e2a\u5165\u5c04\u5149\u5b50\u4e2d\u68c0\u7d22\u5230\u76ee\u6807\u6750\u6599\u7684\u6700\u5927\u9999\u519c\uff08Shannon\uff09\u4fe1\u606f\uff0c\u5b83\u9002\u7528\u4e8e\u6240\u6709\u573a\u666f\uff08\u82e5\u63a8\u5e7f\u5230\u591a\u6750\u8d28\u573a\u666f\uff0c\u53ef\u4ee5\u53c2\u8003\u6269\u5c55\u6570\u636e\u56fe6\uff09\uff0cHADAR\u7684\u53ef\u8fa8\u522b\u6027I\u5b9a\u4e49\u4e3a\uff1a $$ I=\\log_2\\{1+erf[\\sqrt{\\frac{Nd_0^2}{2(1+\\gamma)}}]\\} $$  \u5176\u4e2d\uff0c\\gamma=\\gamma_1N+\\gamma_0\u4e3a\u63a2\u6d4b\u5668\u7ecf\u5149\u5b50\u53d1\u5c04\u566a\u58f0\u529f\u7387\u5f52\u4e00\u5316\u540e\u7684\u7535\u5b50\u566a\u58f0\u529f\u7387\uff0c\u4f5c\u8005\u5f15\u5165d0\u4f5c\u4e3a\u5df2\u77e5\u5149\u8c31\u53d1\u5c04\u7387\u7684\u4e24\u79cd\u6750\u6599\u4e4b\u95f4\u7684\u8bed\u4e49\u8ddd\u79bb\uff0c\u5149\u8c31\u53d1\u5c04\u7387\u4f7f\u7528\u5355\u5149\u5b50Fisher\u4fe1\u606f\u77e9\u9635\u5b9a\u4e49\u3002\uff08\u5565\u610f\u601d\uff1f\uff09</p> <p>\u2003\u2003\u4ece\u4e0a\u9762\u7684\u65b9\u7a0b\u4e2d\u53ef\u4ee5\u770b\u51fa\uff0c\u7531\u5149\u5b50\u7684\u79bb\u6563\u6027\u5f15\u8d77\u7684\u77ed\u566a\u58f0\u9650\u5236\u4e3a\u6240\u6709\u8bc6\u522b\u7b97\u6cd5\u7684\u6027\u80fd\u8bbe\u5b9a\u4e86\u4fe1\u606f\u8bba\u7684\u4e0a\u9650\u3002\u5728\u8fd9\u91cc\uff0c\u4f5c\u8005\u5230\u8fbe\u4e86\u5e7f\u6cdb\u7528\u4e8e\u611f\u77e5\u7684\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u7684\u754c\u9650\uff0c\u4f5c\u8005\u5229\u7528\u8499\u7279\u5361\u7f57\u6a21\u62df\u5728\u77ed\u566a\u58f0\u9650\u5236\u4e0b\u751f\u6210\u4e86\u4eba\u7c7b\u548c\u673a\u5668\u4eba\u7684\u51e0\u79cd\u5149\u8c31\uff0c\u5e76\u4e14\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u7b56\u7565\u5b9e\u73b0\u6750\u8d28\u7684\u5206\u7c7b\u3002\u4ece\u4e0b\u56feb\u4e2d\u53ef\u4ee5\u53d1\u73b0\uff0c\u673a\u5668\u5b66\u4e60\u6027\u80fd\uff08\u7ea2\u8272\u5706\u5708\uff09\u786e\u5b9e\u53d7\u5230\u7406\u8bba\u6781\u9650\uff08\u7ea2\u8272\u66f2\u7ebf\uff09\u7684\u9650\u5236\uff0c\u6211\u4eec\u7684\u7406\u8bba\u4e5f\u9002\u7528\u4e8e\u5177\u6709\u5e38\u89c1\u566a\u58f0\u6e90\u7684\u73b0\u5b9e\u68c0\u6d4b\u5668\u548c\u76f8\u5e94\u7684\u7b97\u6cd5\u6027\u80fd\uff0c\u4e0b\u56fec\u663e\u793a\u4e86\u8bc6\u522b\u4eba\u5f62\u76ee\u6807\u6240\u9700\u7684\u6700\u5c0f\u5149\u5b50\u6570\uff0c\u8be5\u5149\u5b50\u6570\u7531\u5355\u4f4d\u7edf\u8ba1\u8ddd\u79bb\u51b3\u5b9a\uff08\\sqrt Nd_0=1,I\\approx 0.75bits\uff09</p> <p> <p></p> <p></p> <p>HADAR\u6df1\u5ea6\u4f30\u8ba1\u7b56\u7565</p> <p>\u200b   \u7269\u4f53\u7684\u6df1\u5ea6\u662f\u81ea\u4e3b\u5bfc\u822a\u5173\u952e\u7684\u573a\u666f\u5c5e\u6027\uff0c\u767d\u5929\u4e0b\u7684RGB\u7acb\u4f53\u89c6\u89c9\u5df2\u7ecf\u6709\u4e86\u5e7f\u6cdb\u7684\u5e94\u7528\uff0c\u4f46\u662f\u57fa\u4e8e\u7ea2\u5916\u70ed\u80fd\u7684\u6d4b\u8ddd\u96be\u4ee5\u5b9e\u73b0\uff0c\u4f5c\u8005\u8bc1\u660e\u4e86HADAR\u5728\u591c\u95f4\u6d4b\u8ddd\u65b9\u9762\u8981\u4f18\u4e8e\u4f20\u7edf\u7684\u70ed\u6d4b\u8ddd\uff0c\u5229\u7528HADAR\u7684\u6d4b\u8ddd\u7cbe\u5ea6\u4e0e\u767d\u5929\u4e0b\u7684RGB\u7acb\u4f53\u89c6\u89c9\u76f8\u5f53\u3002HADAR\u7684\u6d4b\u8ddd\u65b9\u6cd5\u5229\u7528\u57fa\u4e8eTeX\u89c6\u89c9\u7684\u7acb\u4f53\u89c6\u89c9\uff0c\u4f46\u662f\u4e3a\u4e86\u5c55\u793a\u7eb9\u7406\u7279\u5f81\u5728\u6d4b\u8ddd\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u5e76\u4e14\u66f4\u597d\u5730\u6355\u6349\u7269\u7406\u73b0\u8c61\uff0c\u8fd9\u91cc\u6211\u4eec\u91cd\u70b9\u5173\u6ce8\u53ef\u4ee5\u901a\u8fc7TeX\u5206\u89e3\u6765\u91cd\u5efa\u7684\u6563\u5c04\u4fe1\u53f7\uff0c\u7a0d\u540e\u8ba8\u8bba\u771f\u5b9e\u4e16\u754c\u4e0b\u7684HADAR\u6d4b\u8ddd\u3002\u5bf9\u4e8e\u4e00\u4e2a\u7b80\u6d01\u7684\u6c7d\u8f66/\u884c\u4eba\u573a\u666f\uff0c\u70ed\u6210\u50cf\u7531\u4e8eTeX\u7684\u9000\u5316\u800c\u4e22\u5931\u7eb9\u7406\uff0c\u5e76\u4e14\u5bfc\u81f4\u6d4b\u8ddd\u4e0d\u51c6\uff08\u5982\u4e0b\u56fead\uff09\uff0cHADAR\u7684\u6062\u590d\u7684\u7eb9\u7406\uff08b\uff09\u4e0e\u7070\u5ea6\u5149\u5b66\u6210\u50cf\uff08c\uff09\u76f8\u5f53\uff0cHADAR\u7684\u6d4b\u8ddd\u7ed3\u679c\uff08e\uff09\u4e0eRGB\u7acb\u4f53\u89c6\u89c9\uff08f\uff09\u76f8\u5f53\uff0c\u5728\u5b9a\u91cf\u4e0a\uff0c\u5bf9\u4e8e\u865a\u7ebf\u4e0a\u7684\u7edd\u5bf9\u6d4b\u8ddd\u8bef\u5dee\uff0c\u4e0e\u70ed\u6d4b\u8ddd\u76f8\u6bd4\uff0cHADAR\u7684\u7cbe\u5ea6\u63d0\u9ad8\u4e86\u5927\u7ea6100\u500d\uff1a</p> <p> <p></p> <p></p> <p>\u200b   \u4f5c\u8005\u5f97\u5230\u4e86HADAR\u6d4b\u8ddd\u7684\u57fa\u672c\u9650\u5236\uff0c\u4e3a\u672a\u6765\u81ea\u4e3b\u5bfc\u822a\u5e94\u7528\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u7406\u8bba\u57fa\u7840\uff08\u4e5f\u5c31\u662f\u63d0\u4f9b\u4e86\u6027\u80fd\u4e0a\u9650\uff0c\u6682\u65f6\u4e0d\u592a\u7406\u89e3\u8fd9\u91cc\u600e\u4e48\u5f97\u5230\u7684\uff09 $$ \\sqrt{N}\\sigma z\\ge\\sqrt{2(1+\\gamma)(\\sigma^2_d+\\sigma^2_c)} $$  \u2003\u2003\u603b\u4e4b\uff0c\u4f5c\u8005\u8bbe\u8ba1\u4e86HADAR\u6210\u50cf\u7cfb\u7edf\uff0c\u6539\u8fdb\u4e86\u4f20\u7edf\u70ed\u6210\u50cf\u7684\u4e0d\u8db3\uff0c\u5728\u4f20\u7edf\u70ed\u6210\u50cf\u56fe\u7684\u57fa\u7840\u4e0a\u6062\u590d\u4e86\u56fe\u50cf\u7684\u7eb9\u7406\u7ec6\u8282\uff0c\u5e76\u4e14\u53ef\u4ee5\u4f30\u8ba1\u7269\u4f53\u8868\u9762\u7684\u8f90\u5c04\u53d1\u5c04\u7387\uff0c\u8fdb\u4e00\u6b65\u533a\u5206\u7269\u4f53\u6750\u8d28\uff0c\u5b9e\u73b0\u56fe\u50cf\u4e0a\u8272\u7684\u6548\u679c\u3002</p>"},{"location":"auto/paper/HADAR/#_4","title":"\u65b9\u6cd5","text":"<p>TeX\u9000\u5316</p> <p>\u200b   \u5bf9\u4e8e\u4e00\u4e2a\u7269\u4f53\\alpha\uff0c\u5176\u5149\u8c31\u8f90\u5c04\u53ef\u4ee5\u8868\u793a\u4e3aS_{\\alpha v}=e_{\\alpha v}B_v(T_{\\alpha})+[1-e_{\\alpha v}]X_{\\alpha v}\uff0c\u5c06\u5176\u7269\u7406\u5c5e\u6027\\{T_{\\alpha},e_{\\alpha v},X_{\\alpha v}\\}\u6539\u4e3a\\{T'_{\\alpha},e'_{\\alpha v},X'_{\\alpha v}\\}\u5149\u8c31\u8f90\u5c04\u4e0d\u53d8\uff0c\u5176\u4e2dT'_{\\alpha}\u4e3a\u4efb\u610f\u7684\u6e29\u5ea6\u503c\uff0cX\u2019_{\\alpha v}\u4e3a\u4efb\u610f\u7684\u5149\u8c31\u7eb9\u7406\u66f2\u7ebf\uff0c\u5149\u8c31\u53d1\u5c04\u7387e'_{\\alpha v}\u7531\u5982\u4e0b\u516c\u5f0f\u5f97\u5230\uff1a $$ e'_{\\alpha v}=\\frac{e_{\\alpha v}[B_v(T_\\alpha)-X_{\\alpha v}]+[X_{\\alpha v}-X'_{\\alpha v}]}{B_v(T'_{\\alpha})-X'_{\\alpha v}} $$  \u200b   \u8fd9\u91cc\uff0cv\u8868\u793a\u6ce2\u6570\uff08wavenumber\uff09\uff0cB\u8868\u793a\u9ed1\u4f53\u8f90\u5c04\uff08blackbody radiation\uff09\uff0c\u5177\u6709\u76f8\u540c\u89c2\u6d4b\u5f97\u5230\u7684\u70ed\u4fe1\u53f7S_{v}\u4f46\u662f\u5177\u6709\u4e0d\u540c\u7684\u4e09\u7ec4TeX\u5c5e\u6027\u7684\u73b0\u8c61\u79f0\u4e3aTeX\u9000\u5316\uff08degeneracy\uff09</p> <p>TeX\u5206\u89e3</p> <p>\u200b   \u4f5c\u8005\u5229\u7528\u6750\u8d28\u5e93\\mathcal M \u548cXXXX\u7684\u6570\u5b66\u7ed3\u6784\u6765\u514b\u670dTeX\u7684\u9000\u5316\u95ee\u9898\uff0c\u5728\u672c\u6587\u4e2d\uff0c\u4f5c\u8005\u6839\u636e\u5177\u4f53\u95ee\u9898\u63d0\u51fa\u4e86\u51e0\u79cd\u5b8c\u5168\u89e3\u51b3TeX\u9000\u5316\u7684\u65b9\u6cd5\uff0c\u57fa\u4e8e\u5b66\u4e60\u7684TeX-Net\u5728\u5206\u89e3TeX\u65f6\u4f7f\u7528\u7a7a\u95f4\u548c\u5149\u8c31\u4fe1\u606f\uff0c\u662f\u89e3\u51b3TeX\u9000\u5316\u7684\u4e00\u822c\u65b9\u6848\uff0c\u540c\u65f6\u4f5c\u8005\u8fd8\u63d0\u4f9b\u4e86\u89e3\u6790\u9006\u51fd\u6570\u3001\u6700\u5c0f\u4e8c\u4e58\u4f30\u8ba1\u5668\u548cTeX-SGD\uff08\u534a\u5168\u5c40\u5206\u89e3\uff09\u4f5c\u4e3a\u975e\u673a\u5668\u5b66\u4e60\u7684\u57fa\u7ebf\u3002\u5bf9\u4e8eHADAR\u6570\u636e\u5e93\u548cHADAR\u539f\u578b\u673a2\u7684\u5b9e\u9a8c\uff0c\u4f5c\u8005\u4f7f\u7528TeX-Net\u548cTeX-SGD\u65b9\u6cd5\u3002</p> <p>\u5f15\u5bfc\u516c\u5171\u653f\u7b56</p> <p>\u200b   HADAR\u7684\u8bc6\u522b\u51c6\u5219\u4e3a\\frac{Nd_0^2}{1+\\gamma}=1\uff0c\u5f53\\frac{Nd_0^2}{1+\\gamma}\\ge 1\u65f6\uff0c\u6211\u4eec\u53ef\u4ee5\u8bc6\u522b\u76ee\u6807\u7684\u6750\u8d28\u4fe1\u606f\u3002\u4e3e\u4e2a\u4f8b\u5b50\u6765\u8bf4\uff0c\u4eba\uff08\u76ae\u80a4\uff09\u4e0e\u673a\u5668\u4eba\uff08\u94dd\uff09\u4e4b\u95f4\u7684\u8bed\u4e49\u8ddd\u79bb\u4e3ad_0\\approx0.001\uff0c\u5982\u679c\u73af\u5883\u6e29\u5ea6\u4e3aT_0=20\u2103\uff0cV_0=0.5\uff0c\u90a3\u4e48\u9700\u8981\\frac{N}{1+\\gamma}\\ge10^6\u624d\u80fd\u8bc6\u522b\u76ee\u6807\uff0c\u89c2\u6d4b\u5230\u7684\u5149\u5b50\u6570N\u4e0e\u4eba\u673a\u573a\u666f\uff08human-robot scene\uff09\uff0cf\u503c\uff08f-number\uff0c\u7126\u8dddf\u8d85\u8fc7\u5149\u5708\u5927\u5c0fD\uff09\uff0c\u66dd\u5149\u65f6\u95f4t\uff0c\u548c\u50cf\u5143\u5927\u5c0fA_p\u6709\u5173\uff08\u4e5f\u5c31\u662f\u8ddf\u76f8\u673a\u786c\u4ef6\u6709\u5173\uff0c\u53ef\u4ee5\u53c2\u8003\u8865\u5145\u6750\u6599SI\u7684\u70ed\u4fe1\u53f7\u6a21\u578b\uff09\uff0c\u6700\u7ec8\u4f1a\u5f97\u5230\u4e00\u4e2a\u76f8\u673a\u6700\u4f4e\u914d\u7f6e\u8981\u6c42\\frac{tA_p}{(1+\\gamma)(f/D)^2}\\ge5\\times10^{-16}\uff0c\u5982\u679c\u76f8\u673a\u786c\u4ef6\u914d\u7f6e\u4e0d\u591f\uff0c\u5219\u6355\u83b7\u5230\u7684\u5149\u5b50\u6570\u636e\u5c31\u4f1a\u4fe1\u606f\u4e0d\u8db3\uff0c\u65e0\u8bba\u6536\u96c6\u591a\u5c11\u8bad\u7ec3\u6570\u636e\u7528\u4e8e\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\uff0c\u6548\u679c\u90fd\u4e0d\u4f1a\u7279\u522b\u597d\u3002</p> <p>\u200b   \u5bf9\u4e8e\u539f\u578b\u673a1\uff0c\u5373FLIR A325sc\uff0c\u6709\\frac{tA_p}{(1+\\gamma)(f/D)^2}= 8.16\\times10^{-18}\uff0c\u5982\u679c\u5728\u4e00\u4e2a\u56fe\u50cf\u5e27\u5185\u60f3\u8981\u6ee1\u8db3\u8981\u6c42\uff0c\u90a3\u4e48\u5c31\u5fc5\u987b\u6709d_0&gt;0.0078\uff0c\u5373\u8bed\u4e49\u4fe1\u606f\u8ddd\u79bb\u4e0d\u80fd\u8fc7\u8fd1\u3002\u603b\u7ed3\uff1a\u76f8\u673a\u786c\u4ef6\u8bbe\u5907\uff0c\u5373\u53ef\u6355\u83b7\u7684\u5149\u5b50\u6570\u4e0e\u7b97\u6cd5\u6700\u7ec8\u8bc6\u522b\u6750\u6599\u7684\u6027\u80fd\u606f\u606f\u76f8\u5173\uff0c\u53ef\u6355\u83b7\u7684\u5149\u5b50\u6570\u8d8a\u591a\uff0c\u5219\u540e\u7eed\u7684\u7b97\u6cd5\u8d8a\u80fd\u533a\u522b\u76f8\u4f3c\u5ea6\u9ad8\u7684\u6750\u8d28\u3002</p> <p>\u7b97\u6cd5\u6d41\u7a0b</p> <p>\u2003\u2003\u7b97\u6cd5\u7684\u5177\u4f53\u6d41\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003HADAR\u4ee5\u70ed\u5149\u5b50\u6d41\u4f5c\u4e3a\u8f93\u5165\uff0c\u8bb0\u5f55\u9ad8\u5149\u8c31\u6210\u50cf\u7684\u70ed\u7acb\u65b9\u4f53\uff08\u4f5c\u8005\u4e13\u95e8\u53d1\u660e\u4e86\u4e00\u6b3e\u8bbe\u5907\uff0c\u6765\u6355\u83b7\u70ed\u5149\u5b50\u6d41\uff0c\u5177\u4f53\u600e\u4e48\u64cd\u4f5c\u7684\u6682\u65f6\u8fd8\u4e0d\u592a\u7406\u89e3\uff09\uff0c\u4e4b\u540e\u5c06\u6570\u636e\u4f20\u5165TeX-Net\u7f51\u7edc\u4e2d\u9884\u6d4b\u4e09\u7ec4\u6570\u636e\uff0c\u5373\u7269\u4f53\u8868\u9762\u7684\u6e29\u5ea6\u3001\u7269\u4f53\u7684\u53d1\u5c04\u7387\u4ee5\u53ca\u7269\u4f53\u7684\u7eb9\u7406\uff0c\u4e09\u7ec4\u6570\u636e\u5171\u540c\u6784\u6210TeX\u6210\u50cf\u3002</p> <p>\u2003\u2003\u5bf9\u4e8e\u7f51\u7edc\u90e8\u5206\uff0c\u7f51\u7edc\u7ed3\u6784\u5982\u4e0b\u56feTeX-Net\u6240\u793a\uff0c\u7b97\u6cd5\u5bf9\u6bcf\u4e2a\u50cf\u7d20\u70b9\u8fdb\u884c\u5206\u7c7b\u56de\u5f52\uff08\u7c7b\u4f3c\u8bed\u4e49\u5206\u5272\uff09\uff0c\u4ece\u800c\u5f97\u5230\u4e09\u7ec4\u8f93\u51fa\uff1a\u7269\u4f53\u8868\u9762\u7684\u6e29\u5ea6T\u3001\u7269\u4f53\u6750\u8d28\u7684\u53d1\u5c04\u7387m\uff08\u8868\u793a\u7269\u4f53\u8868\u9762\u53d1\u5c04\u7ea2\u5916\u8f90\u5c04\u7684\u80fd\u529b\uff0c\u7528\u4e8e\u533a\u5206\u4e0d\u540c\u7684\u6750\u8d28\uff09\u548c\u5149\u7167\u56e0\u5b50V\uff0c\u4e09\u4e2a\u8f93\u51fa\u5171\u540c\u6784\u6210HADAR\u7b97\u6cd5\u5bf9\u7269\u4f53\u548c\u73af\u5883\u7684\u7269\u7406\u63cf\u8ff0\u3002HADAR\u7b97\u6cd5\u518d\u6839\u636e\u4f30\u8ba1\u5f97\u5230\u7684\u6e29\u5ea6\u3001\u53d1\u5c04\u7387\u548c\u5149\u7167\u56e0\u5b50\u6765\u91cd\u5efa\u51fa\u7269\u4f53\u548c\u73af\u5883\u7684\u7eb9\u7406\u3001\u5f62\u72b6\u548c\u989c\u8272\uff0c\u91cd\u5efa\u7ed3\u679c\u5171\u540c\u6784\u6210\u4e86HADAR\u7b97\u6cd5\u5bf9\u7269\u4f53\u548c\u73af\u5883\u7684\u89c6\u89c9\u5448\u73b0\u3002</p> <p> <p></p> <p></p> <p>\u2003\u2003TeX-Net\u7f51\u7edc\u5728\u4e09\u4e2a\u65b9\u9762\u53d7\u5230\u4e86\u7269\u7406\u5b66\u7684\u542f\u53d1\uff1a\u9996\u5148\uff0c\u70ed\u7acb\u65b9\u4f53\u7684TeX\u5206\u89e3\u4f9d\u8d56\u4e8e\u7a7a\u95f4\u6a21\u5f0f\u548c\u5149\u8c31\u70ed\u7279\u5f81\uff0c\u56e0\u6b64\uff0c\u7f51\u7edc\u7ed3\u6784\u91c7\u6837\u5149\u8c31\u548c\u91d1\u5b57\u5854\uff08\u7a7a\u95f4\uff09\u6ce8\u610f\u529b\u5c42\uff1b\u5176\u6b21\uff0c\u7531\u4e8eTeX\u7684\u7b80\u5e76\u6027\uff0c\u5fc5\u987b\u6307\u5b9a\u6570\u5b66\u7ed3\u6784X_{\\alpha v}=\\sum_{\\beta\\neq\\alpha}V_{\\alpha\\beta}S_{\\beta v}\u6765\u4fdd\u8bc1\u9006\u6620\u5c04\u7684\u552f\u4e00\u6027\uff0c\u56e0\u6b64\u7f51\u7edc\u5fc5\u987b\u8981\u5b66\u4e60\u5149\u7167\u56e0\u5b50V\uff0c\u800c\u4e0d\u662f\u7eb9\u7406X\uff0c\u5373\u7f51\u7edc\u4e0d\u80fd\u7aef\u5230\u7aef\u7684\u8bad\u7ec3\uff1b\u7b2c\u4e09\uff0c\u6750\u8d28\u5e93m\uff08\u5373\u53d1\u5c04\u7387\uff09\u53ca\u5176\u7ef4\u5ea6\u662f\u6574\u4e2a\u7f51\u7edc\u7684\u5173\u952e\uff0cTeX-Net\u65e2\u53ef\u4ee5\u4f7f\u7528T\u3001m\u548cV\u7684\u771f\u503c\u6765\u8fdb\u884c\u6709\u76d1\u7763\u8bad\u7ec3\uff0c\u4e5f\u53ef\u4ee5\u4f7f\u7528\u6750\u8d28\u5e93m\u3001\u666e\u6717\u514b\u5b9a\u5f8bB_v(T_{\\alpha})\u548cX_{\\alpha v}\u7684\u6570\u5b66\u7ed3\u6784\u6765\u8fdb\u884c\u65e0\u76d1\u7763\u8bad\u7ec3\u3002\u5728\u76d1\u7763\u8bad\u7ec3\u4e2d\uff0c\u635f\u5931\u51fd\u6570\u662f\u4e2a\u4f53\u635f\u5931\u548c\u6b63\u5219\u5316\u8d85\u53c2\u6570\u7684\u7ec4\u5408\uff1b\u5728\u65e0\u76d1\u7763\u8bad\u7ec3\u4e2d\uff0c\u635f\u5931\u51fd\u6570\u5b9a\u4e49\u5728\u91cd\u6784\u70ed\u7acb\u65b9\u4f53\u4e0a\uff0c\u5e76\u4e14\u57fa\u4e8e\u70ed\u4fe1\u53f7\u7684\u7269\u7406\u6a21\u578b\u3002\u5728\u5b9e\u8df5\u4e2d\uff0c\u4f5c\u8005\u4f7f\u7528\u4e86T,e,V\u8d21\u732e50\\%\u548c\u7269\u7406\u635f\u5931\u8d21\u732e50\\%\u7684\u6df7\u5408\u635f\u5931\u8bad\u7ec3\u7f51\u7edc\u3002</p> <p>\u6ce8\uff1a</p> <ul> <li>X_{\\alpha v}=\\sum_{\\beta\\neq\\alpha}V_{\\alpha\\beta}S_{\\beta v}\u8868\u793a\u73af\u5883\u4e2d\u6240\u6709\u5176\u4ed6\u7269\u4f53\\beta\u5bf9\u7269\u4f53\\alpha\u7684\u70ed\u7167\u5ea6\uff0c\u5176\u4e2dV_{\\alpha\\beta}\u4e3a\u70ed\u7167\u5ea6\u56e0\u5b50\uff1b</li> </ul>"},{"location":"auto/paper/HADAR/#_5","title":"\u6e90\u7801\u8bb0\u5f55","text":"<ul> <li>\u6574\u4e2aTeX-Net\u7f51\u7edc\u5c31\u662f\u4e00\u4e2a\u8bed\u4e49\u5206\u5272\u7f51\u7edc\uff0c\u6539\u4e86\u4e00\u4e0b\u8f93\u5165\u901a\u9053\u6570\u548c\u8f93\u51fa\u901a\u9053\u6570\uff0c\u8f93\u5165\u901a\u9053\u6570\u6539\u4e3a\u4e8649\uff0c\u8f93\u51fa\u901a\u9053\u6570\u4e3a30+1(train on T)+2(train on v)\uff0c30\u5e94\u8be5\u662f\u6307\u7684\u6750\u8d28\u4fe1\u606fe/m\u7684\u901a\u9053\u6570\uff0c\u4e5f\u5373\u7c7b\u522b\u6570\uff08\u540e\u9762\u7528\u9884\u6d4b\u7684e\u8ba1\u7b97\u4ea4\u53c9\u71b5\u635f\u5931\uff09</li> <li>\u7f51\u7edc\u5f97\u5230\u8f93\u51fa\u4e4b\u540e\uff0c\u6309\u901a\u9053\u65b9\u5411\u5c06\u5176\u62c6\u5206\uff1ae/m\u670930\u4e2a\u901a\u9053\uff0cv\u67092\u4e2a\u901a\u9053\uff08\u8f93\u51fa\u7ed3\u679c\u4f1a\u7ecf\u8fc7\u4e00\u6b21softmax\u8fd0\u7b97\uff0c\u518d\u8ba1\u7b97KL\u6563\u5ea6\u635f\u5931\uff09\uff0cT\u67091\u4e2a\u901a\u9053\uff1be/m\u91c7\u7528\u4ea4\u53c9\u71b5\u4f18\u5316\u3001v\u91c7\u7528KL\u6563\u5ea6\u4f18\u5316\u3001T\u91c7\u7528MSE\u635f\u5931\u4f18\u5316\uff1b\u65e0\u76d1\u7763\u635f\u5931\u7684\u8ba1\u7b97\u8fc7\u7a0b\u8fd8\u6ca1\u5f04\u6e05\u695a\uff0c\u6709\u70b9\u590d\u6742\u3002</li> </ul>"},{"location":"auto/paper/HADAR/#_6","title":"\u53ef\u89c6\u5316","text":"<p>\u591c\u95f4\u70ed\u6210\u50cf\u3001\u591c\u95f4HADAR\u6210\u50cf\u3001\u767d\u95f4\u6240\u62cd\u6444\u7684\u56fe\u50cf\u5bf9\u6bd4</p> <p> <p></p> <p></p> <p>\u70ed\u6210\u50cf\u4e0eHADAR\u6210\u50cf\u5728\u6d4b\u8ddd\u4e0a\u7684\u5bf9\u6bd4</p> <p>\u2003\u2003\u7b2c\u4e00\u884c\u5c55\u793a\u4e86\u57fa\u4e8e\u539f\u59cb\u70ed\u56fe\u50cf\u7684\u6d4b\u8ddd\u7ed3\u679c\uff0c\u7b2c\u4e8c\u884c\u5c55\u793a\u4e86\u5229\u7528HADAR\u6210\u50cf\u7684\u6d4b\u8ddd\u7ed3\u679c\uff0c\u7b2c\u4e09\u884c\u662f\u6b63\u5e38\u5149\u7167\u4e0b\u7684\u6d4b\u8ddd\u7ed3\u679c\uff0c\u4ece\u5bf9\u6bd4\u56fe\u4e2d\u53ef\u4ee5\u53d1\u73b0\uff0c\u539f\u59cb\u70ed\u56fe\u7531\u4e8e\u91cd\u5f71\u73b0\u8c61\uff0c\u5bfc\u81f4\u6d4b\u8ddd\u7ed3\u679c\u7684\u7cbe\u5ea6\u5f88\u4f4e\uff0c\u800cHADAR\u6210\u50cf\u53ef\u4ee5\u5f88\u597d\u5730\u6062\u590d\u7eb9\u7406\u7279\u5f81\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u63d0\u5347\u6df1\u5ea6\u4f30\u8ba1\u7684\u7cbe\u5ea6\uff1a</p> <p> <p></p> <p></p> <p>\u70ed\u6210\u50cf\u3001\u6fc0\u5149\u96f7\u8fbe\u6210\u50cf\u4e0eHADAR\u5728\u76ee\u6807\u68c0\u6d4b\u4e0a\u7684\u5bf9\u6bd4</p> <p>\u2003\u2003\u56fe\u50cf\u4e2d\u6709\u4e00\u8f86\u8f66\u3001\u4e00\u4e2a\u4eba\u548c\u4e00\u4e2a\u4eba\u50cf\u7eb8\u677f\uff0c\u56fe\u50cf\uff08a\uff09\u8868\u793a\u70ed\u6210\u50cf\u7684\u76ee\u6807\u68c0\u6d4b\u7ed3\u679c\uff0c\u9519\u8bef\u7684\u68c0\u6d4b\u51fa\u4e24\u4e2a\u4eba\u548c\u4e00\u8f86\u8f66\uff0c\uff08c\uff09\u8868\u793a\u6fc0\u5149\u96f7\u8fbe\u70b9\u4e91\u6210\u50cf\uff0c\u68c0\u6d4b\u51fa\u4e24\u4e2a\u4eba\uff0c\u53ea\u6709HADAR\u6210\u50cf\u65b9\u6cd5\uff08b\uff09\u505a\u51fa\u4e86\u51c6\u786e\u7684\u68c0\u6d4b\uff0c\u68c0\u6d4b\u51fa\u4e00\u4e2a\u4eba\u548c\u4e00\u8f86\u8f66\u3002</p> <p> <p></p> <p></p> <p>HADAR\u6210\u50cf\u4e0e\u70ed\u4fe1\u53f7+AI\u7b97\u6cd5\u589e\u5f3a\u540e\u7684\u56fe\u50cf\u5728\u8bed\u4e49\u65b9\u9762\u7684\u5bf9\u6bd4</p> <p> <p></p> <p></p> <p>\u6ce8\uff1a\u8fd9\u7bc7\u6587\u7ae0\u7684\u4e3b\u8981\u8d21\u732e\u5728\u4e8e\u70ed\u529b\u5b66\u3001\u5149\u5b66\u6210\u50cf\u7684\u7814\u7a76\uff0c\u7b97\u6cd5\u76f8\u5173\u7684\u7814\u7a76\u975e\u5e38\u5c11\uff0c\u6240\u4ee5\u539f\u7406\u90e8\u5206\u770b\u7684\u4e0d\u662f\u5f88\u660e\u767d\uff0c\u53ea\u662f\u7b80\u5355\u6574\u7406\u4e86\u4e00\u4e0b\u7814\u7a76\u52a8\u673a\u548c\u7814\u7a76\u7ed3\u679c\u3002</p>"},{"location":"computing_imaging/%E3%80%8A%E5%85%89%E7%94%B5%E6%88%90%E5%83%8F%E4%B8%8E%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E3%80%8B%E7%AC%94%E8%AE%B0/","title":"\u300a\u5149\u7535\u6210\u50cf\u4e0e\u56fe\u50cf\u5904\u7406\u300b\u7b14\u8bb0","text":""},{"location":"computing_imaging/%E3%80%8A%E5%85%89%E7%94%B5%E6%88%90%E5%83%8F%E4%B8%8E%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E3%80%8B%E7%AC%94%E8%AE%B0/#_2","title":"\u300a\u5149\u7535\u6210\u50cf\u4e0e\u56fe\u50cf\u5904\u7406\u300b\u7b14\u8bb0","text":""},{"location":"computing_imaging/%E3%80%8A%E8%AE%A1%E7%AE%97%E6%88%90%E5%83%8F%E4%B8%8E%E6%84%9F%E7%9F%A5%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/","title":"\u300a\u8ba1\u7b97\u6210\u50cf\u4e0e\u611f\u77e5\u300b\u8bfb\u4e66\u7b14\u8bb0","text":"<p>\u300a\u8ba1\u7b97\u6210\u50cf\u4e0e\u611f\u77e5\u300b\u8fb9\u4e3d\u8605\uff0c\u6234\u743c\u6d77\uff0c\u4eba\u6c11\u90ae\u7535\u51fa\u7248\u793e\uff0c2022.3</p>"},{"location":"computing_imaging/%E3%80%8A%E8%AE%A1%E7%AE%97%E6%88%90%E5%83%8F%E4%B8%8E%E6%84%9F%E7%9F%A5%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/#_2","title":"\u7eea\u8bba","text":"<p>\u200b   \u73b0\u6709\u89c6\u89c9\u611f\u77e5\u7cfb\u7edf\u9762\u4e34\u54cd\u5e94\u7ef4\u5ea6\u5355\u4e00\u3001\u4f20\u8f93\u5e26\u5bbd\u53d7\u9650\u3001\u4fe1\u53f7\u566a\u58f0\u4e32\u6270\u3001\u4fe1\u606f\u901a\u91cf\u4e0d\u8db3\u7b49\u4e25\u5cfb\u6311\u6218\uff0c\u5b58\u5728\u9ad8\u7ef4\u201c\u770b\u4e0d\u5230\u201d\u3001\u5e7f\u57df\u201c\u770b\u4e0d\u5168\u201d\u3001\u7ec6\u8282\u201c\u770b\u4e0d\u6e05\u201d\u3001\u8bed\u4e49\u201c\u770b\u4e0d\u61c2\u201d\u7b49\u95ee\u9898\uff0c\u6210\u4e3a\u53ef\u9760\u89c6\u89c9\u611f\u77e5\u7684\u684e\u688f\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u89c6\u89c9\u611f\u77e5\u7cfb\u7edf\u901a\u5e38\u7531\u5149\u5b66\u900f\u955c\u3001\u4f20\u611f\u5668\u3001\u5904\u7406\u5668\u6784\u6210\uff0c\u5176\u4e2d\u5149\u5b66\u900f\u955c\u7528\u4e8e\u5149\u573a\u7684\u7f29\u653e\u548c\u805a\u7126\uff0c\u4f20\u611f\u5668\u7528\u4e8e\u5149\u4fe1\u53f7\u7684\u91c7\u96c6\u548c\u4f20\u8f93\uff0c\u5904\u7406\u5668\u7528\u4e8e\u5149\u4fe1\u53f7\u7684\u5904\u7406\u548c\u8ba1\u7b97\u3002\u5728\u5149\u5b66\u900f\u955c\u90e8\u5206\uff0c\u900f\u955c\u5236\u9020\u5de5\u827a\u7684\u4e0d\u8db3\u4f1a\u9020\u6210\u5149\u7ebf\u4f20\u64ad\u7684\u7578\u53d8\uff0c\u4ece\u800c\u5f71\u54cd\u6210\u50cf\u8d28\u91cf\uff1b\u5149\u5b66\u6210\u50cf\u5206\u8fa8\u7387\u53d7\u9650\u4e8e\u900f\u955c\u7684\u6570\u503c\u5b54\u5f84\uff0c\u96be\u4ee5\u7a81\u7834\u5149\u6ce2\u7684\u884d\u5c04\u6781\u9650\u3002\u5728\u4f20\u611f\u5668\u90e8\u5206\uff0c\u50cf\u7d20\u5316\u7684\u79bb\u6563\u91c7\u6837\u3001\u6a21\u6570\u8f6c\u6362\u3001\u7eaf\u5f3a\u5ea6\u6d4b\u91cf\u7b49\u4f1a\u5bfc\u81f4\u5149\u4fe1\u53f7\u591a\u4e2a\u7ef4\u5ea6\u7684\u4fe1\u606f\u4e22\u5931\uff0c\u4f7f\u6210\u50cf\u7ed3\u679c\u5927\u5e45\u964d\u8d28\u3002\u5728\u5904\u7406\u5668\u90e8\u5206\uff0c\u6709\u9650\u7684\u4f20\u8f93\u5e26\u5bbd\u9650\u5236\u4e86\u6210\u50cf\u901f\u5ea6\uff0c\u800c\u6709\u9650\u7684\u7b97\u529b\u5219\u9650\u5236\u4e86\u611f\u77e5\u7cfb\u7edf\u7684\u4fe1\u606f\u901a\u91cf\uff0c\u5177\u4f53\u5982\u4e0b\u56fe\u6240\u793a\u3002\u7efc\u4e0a\u6240\u8ff0\uff0c\u5982\u4f55\u7a81\u7834\u786c\u4ef6\u5de5\u827a\u3001\u7cfb\u7edf\u5e26\u5bbd\u3001\u4f20\u611f\u5236\u5f0f\u7b49\u9650\u5236\uff0c\u63d0\u51fa\u65b0\u578b\u611f\u77e5\u65b9\u6cd5\uff0c\u5b9e\u73b0\u591a\u7ef4\u5ea6\u9ad8\u901a\u91cf\u89c6\u89c9\u611f\u77e5\uff0c\u662f\u673a\u5668\u667a\u80fd\u4e9f\u5f85\u89e3\u51b3\u7684\u5173\u952e\u95ee\u9898\u3002</p> <p></p> <p>\u200b   \u8ba1\u7b97\u6210\u50cf\u662f\u901a\u8fc7\u5c06\u7269\u7406\u5149\u5b66\u3001\u7535\u5b50\u4fe1\u606f\u4ee5\u53ca\u7edf\u8ba1\u5b66\u4e60\u7b49\u5b66\u79d1\u6df1\u5ea6\u4ea4\u53c9\uff0c\u4ece\u6210\u50cf\u673a\u7406\u7684\u89d2\u5ea6\u6539\u8fdb\u4f20\u7edf\u76f8\u673a\uff0c\u5e76\u5c06\u786c\u4ef6\u8bbe\u8ba1\u4e0e\u8f6f\u4ef6\u8ba1\u7b97\u80fd\u529b\u6709\u673a\u7ed3\u5408\uff0c\u4ece\u800c\u7a81\u7834\u4f20\u7edf\u89c6\u89c9\u611f\u77e5\u4e2d\u7ecf\u5178\u6210\u50cf\u6a21\u578b\u5b58\u5728\u7684\u4e0a\u8ff0\u5c40\u9650\uff0c\u589e\u5f3a\u4f20\u7edf\u76f8\u673a\u7684\u6570\u636e\u91c7\u96c6\u80fd\u529b\uff0c\u5168\u65b9\u4f4d\u5730\u6355\u6349\u771f\u5b9e\u4e16\u754c\u7684\u573a\u666f\u4fe1\u606f\u3002\u5177\u4f53\u800c\u8a00\uff0c\u8ba1\u7b97\u6210\u50cf\u5c06\u8ba1\u7b97\u5f15\u5165\u6210\u50cf\u5168\u8fc7\u7a0b\uff0c\u6280\u672f\u67b6\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p></p> <p>\u9996\u5148\uff0c\u8ba1\u7b97\u6210\u50cf\u5728\u5149\u7167\u548c\u4f20\u611f\u7aef\u8fdb\u884c\u7f16\u7801\u8c03\u5236\uff0c\u8026\u5408\u91c7\u96c6\u8c03\u5236\u540e\u7684\u9ad8\u7ef4\u8fde\u7eed\u5149\u4fe1\u53f7\uff0c\u56e0\u6b64\uff0c\u8ba1\u7b97\u6210\u50cf\u7684\u91c7\u96c6\u6570\u636e\u5e76\u975e\u4f20\u7edf\u611f\u77e5\u4e2d\u76f4\u89c2\u7684\u53ef\u89c6\u5316\u56fe\u50cf\u6216\u89c6\u9891\uff0c\u800c\u662f\u7f16\u7801\u540e\u7684\u975e\u53ef\u89c6\u5316\u8026\u5408\u6570\u636e\u3002\u7136\u540e\uff0c\u8ba1\u7b97\u6210\u50cf\u5728\u8f6f\u4ef6\u7aef\u901a\u8fc7\u76f8\u5e94\u7684\u7b97\u6cd5\u4ece\u6d4b\u91cf\u6570\u636e\u4e2d\u89e3\u8026\u5e76\u91cd\u5efa\u591a\u7ef4\u5ea6\u3001\u9ad8\u901a\u91cf\u7684\u53ef\u89c6\u5316\u89c6\u89c9\u4fe1\u606f\uff0c\u4ece\u800c\u6784\u5efa\u91c7\u6837\u548c\u91cd\u5efa\u7684\u65b0\u578b\u5149\u4f20\u8f93\u6a21\u578b\u3002\u8ba1\u7b97\u6210\u50cf\u901a\u8fc7\u591a\u5b66\u79d1\u4ea4\u53c9\uff0c\u53d1\u660e\u4e86\u8ba1\u7b97\u5149\u7167\u3001\u8ba1\u7b97\u4f20\u611f\u548c\u8ba1\u7b97\u91cd\u5efa\u7b49\u6280\u672f\uff0c\u5de7\u5999\u5730\u907f\u5f00\u4e86\u5149\u5b66\u6210\u50cf\u786c\u4ef6\u7cfb\u7edf\u7684\u56fa\u6709\u7269\u7406\u9650\u5236\uff0c\u4ece\u672c\u8d28\u4e0a\u7a81\u7834\u4e86\u73b0\u6709\u6210\u50cf\u6a21\u578b\u5728\u9ad8\u7ef4\u5149\u4fe1\u53f7\u83b7\u53d6\u53ca\u5904\u7406\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002\u8ba1\u7b97\u6210\u50cf\u6280\u672f\u901a\u8fc7\u5341\u4f59\u5e74\u7684\u53d1\u5c55\uff0c\u5728\u6210\u50cf\u7ef4\u5ea6\u3001\u573a\u57df\u3001\u5206\u8fa8\u7387\u7b49\u591a\u65b9\u9762\u5747\u5b9e\u73b0\u4e86\u6027\u80fd\u7684\u5927\u5e45\u5ea6\u63d0\u5347\uff0c\u80fd\u591f\u4e3a\u673a\u5668\u667a\u80fd\u63d0\u4f9b\u591a\u7ef4\u5ea6\u3001\u5168\u65b9\u4f4d\u7684\u89c6\u89c9\u4fe1\u606f\u3002</p> <p>\u200b   \u867d\u7136\u8ba1\u7b97\u6210\u50cf\u6280\u672f\u901a\u8fc7\u8c03\u5236\u8026\u5408\u548c\u8ba1\u7b97\u89e3\u8026\u5b9e\u73b0\u4e86\u6210\u50cf\u7ef4\u5ea6\u5347\u9ad8\u3001\u573a\u57df\u6269\u5927\u3001\u7cbe\u5ea6\u63d0\u5347\uff0c\u4f46\u968f\u4e4b\u800c\u6765\u7684\u6570\u636e\u91cf\u5927\u5e45\u589e\u52a0\u4e3a\u540e\u7eed\u89c6\u89c9\u8bed\u4e49\u7684\u9ad8\u6548\u63d0\u53d6\u548c\u7406\u89e3\u5e26\u6765\u4e86\u66f4\u5927\u7684\u56f0\u96be\uff0c\u7279\u522b\u662f\u5728\u67d0\u4e9b\u8d44\u6e90\u53d7\u9650\u7684\u5e73\u53f0\u4e0a\uff0c\u8ba1\u7b97\u6210\u50cf\u5177\u6709\u8f7d\u8377\u8f7b\u3001\u4f9b\u7535\u5c11\u3001\u8ba1\u7b97\u5f31\u3001\u4f20\u8f93\u6162\u7b49\u7279\u70b9\uff0c\u96be\u4ee5\u5b9e\u73b0\u5b9e\u65f6\u7684\u76ee\u6807\u5185\u5bb9\u89e3\u6790\uff0c\u5f88\u5927\u7a0b\u5ea6\u4e0a\u5f71\u54cd\u5176\u5e7f\u6cdb\u5e94\u7528\u3002</p> <p>\u200b   \u4ece\u7edf\u8ba1\u5b66\u7684\u89d2\u5ea6\u6765\u770b\uff0c\u81ea\u7136\u56fe\u50cf\u5f80\u5f80\u5177\u6709\u7a00\u758f\u76ee\u6807\u7684\u7279\u5f81\uff0c\u4eba\u4eec\u771f\u6b63\u5173\u6ce8\u7684\u76ee\u6807\u5f80\u5f80\u53ea\u5360\u573a\u666f\u7684\u4e00\u5c0f\u90e8\u5206\uff0c\u9ad8\u6e05\u56fe\u50cf\u5305\u542b\u8f83\u591a\u7684\u975e\u76ee\u6807\u533a\u57df\uff0c\u8fd9\u4e9b\u5927\u8303\u56f4\u975e\u76ee\u6807\u533a\u57df\u4f1a\u6d6a\u8d39\u5927\u91cf\u7684\u6210\u50cf\u3001\u901a\u4fe1\u786c\u4ef6\u8d44\u6e90\uff08\u5982\u5927\u89c4\u6a21\u9ad8\u7075\u654f\u5ea6\u4f20\u611f\u5668\u9635\u5217\u3001\u9ad8\u901a\u91cf\u901a\u4fe1\u94fe\u8def\u7b49\uff09\u548c\u91cd\u5efa\u7b97\u6cd5\u8d44\u6e90\uff08\u5982\u53bb\u566a\u3001\u53bb\u6a21\u7cca\u7b97\u6cd5\uff09\uff0c\u66f4\u4f1a\u5bf9\u611f\u77e5\u8fc7\u7a0b\u4ea7\u751f\u5e72\u6270\uff0c\u964d\u4f4e\u611f\u77e5\u7cbe\u5ea6\uff0c\u56e0\u6b64\u4f20\u7edf\u7684\u201c\u5148\u6210\u50cf-\u540e\u7406\u89e3\u201d\u611f\u77e5\u6a21\u5f0f\u5e76\u975e\u5927\u89c4\u6a21\u673a\u5668\u667a\u80fd\u7684\u6700\u4f73\u9009\u7684\uff0c\u4f1a\u524a\u5f31\u8ba1\u7b97\u6210\u50cf\u67b6\u6784\u7684\u4f18\u52bf\u3002</p> <p>\u200b   \u4e3a\u4e86\u7a81\u7834\u6570\u636e\u901a\u91cf\u5bf9\u9ad8\u6548\u611f\u77e5\u7684\u9650\u5236\uff0c\u672c\u4e66\u4f5c\u8005\u56e2\u961f\u521b\u9020\u6027\u5730\u63d0\u51fa\u4e86\u8ba1\u7b97\u611f\u77e5\u8fd9\u4e00\u65b0\u578b\u7814\u7a76\u65b9\u5411\uff0c\u7ed5\u8fc7\u590d\u6742\u7684\u6210\u50cf\u8fc7\u7a0b\uff0c\u76f4\u63a5\u83b7\u53d6\u76ee\u6807\u7684\u9ad8\u7ea7\u8bed\u4e49\u7279\u5f81\uff0c\u4e8c\u8005\u65b9\u5411\u7684\u5bf9\u6bd4\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p></p> <p>\u5177\u4f53\u800c\u8a00\uff0c\u8ba1\u7b97\u611f\u77e5\u7701\u53bb\u4e86\u56fe\u50cf\u91c7\u96c6\u548c\u91cd\u6784\u8fc7\u7a0b\uff0c\u5c06\u5149\u4fe1\u53f7\u5728\u7269\u7406\u5c42\u7531\u7a7a\u95f4\u5206\u5e03\u7f16\u7801\u8f6c\u5316\u4e3a\u9ad8\u7ea7\u8bed\u4e49\u7279\u5f81\uff0c\u76f4\u63a5\u4f7f\u7528\u975e\u53ef\u89c6\u5316\u8bed\u4e49\u7279\u5f81\u4f5c\u4e3a\u89c6\u89c9\u4fe1\u606f\u8f7d\u4f53\uff0c\u6784\u5efa\u66f4\u9ad8\u6548\u7684\u975e\u53ef\u89c6\u5316\u6570\u636e\u91c7\u96c6\u8303\u5f0f\u3002\u7136\u540e\uff0c\u5728\u4f20\u611f\u5c42\u8026\u5408\u91c7\u96c6\u591a\u4e2a\u7ef4\u5ea6\u7684\u7f16\u7801\u5149\uff0c\u5e76\u6839\u636e\u573a\u666f\u7279\u5f81\u81ea\u9002\u5e94\u5730\u533a\u5206\u76ee\u6807\u4fe1\u53f7\u548c\u65e0\u6548\u4fe1\u53f7\uff0c\u8fdb\u4e00\u6b65\u63d0\u5347\u4fe1\u606f\u901a\u91cf\uff0c\u6700\u5927\u5316\u4fe1\u53f7\u91c7\u96c6\u6548\u7387\uff0c\u7a81\u7834\u786c\u4ef6\u7cfb\u7edf\u6709\u9650\u6570\u636e\u5e26\u5bbd\u7684\u91c7\u96c6\u3001\u4f20\u8f93\u4e0e\u5904\u7406\u74f6\u9888\u3002\u6700\u540e\uff0c\u53bb\u9664\u590d\u6742\u7684\u56fe\u50cf\u91cd\u5efa\u548c\u7279\u5f81\u63d0\u53d6\u8fc7\u7a0b\uff0c\u4f7f\u7528\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u7684\u89e3\u6790\u611f\u77e5\u7b97\u6cd5\u4ece\u975e\u53ef\u89c6\u5316\u7684\u8bed\u4e49\u8026\u5408\u6570\u636e\u4e2d\u76f4\u63a5\u89e3\u8026\u63a8\u65ad\u9ad8\u7ea7\u8bed\u4e49\u7ed3\u679c\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u514d\u6210\u50cf\u667a\u80fd\u611f\u77e5\u3002</p> <p>\u200b   \u7efc\u4e0a\u6240\u793a\uff0c\u8ba1\u7b97\u611f\u77e5\u901a\u8fc7\u9769\u65b0\u7f16\u7801\u539f\u7406\u3001\u4f20\u611f\u673a\u5236\u548c\u89e3\u8026\u65b9\u6cd5\uff0c\u6784\u5efa\u5168\u65b0\u7684\u667a\u80fd\u611f\u77e5\u6a21\u6001\uff0c\u4f7f\u89c6\u89c9\u7cfb\u7edf\u7531\u201c\u770b\u5f97\u5230\u3001\u770b\u7684\u5168\u3001\u770b\u5f97\u6e05\u201d\u53d1\u5c55\u4e3a\u201d\u770b\u5f97\u61c2\u201c\uff0c\u5c06\u8ba1\u7b97\u6210\u50cf\u6570\u636e\u901a\u91cf\u7684\u63d0\u5347\u8fdb\u5316\u4e3a\u8ba1\u7b97\u611f\u77e5\u4fe1\u606f\u901a\u91cf\u7684\u63d0\u5347\u3002</p>"},{"location":"computing_imaging/%E4%BF%A1%E6%81%AF%E8%8E%B7%E5%8F%96%E2%80%94%E2%80%94%E2%80%9C%E4%BB%8E%E6%97%A0%E5%88%B0%E6%9C%89%E2%80%9D/","title":"\u4fe1\u606f\u83b7\u53d6\u2014\u2014\u201c\u4ece\u65e0\u5230\u6709\u201d","text":"<p>\u200b   \u5149\u6ce2\u5177\u6709\u5149\u5f3a\u3001\u5149\u8c31\u3001\u76f8\u4f4d\u7b49\u591a\u4e2a\u7ef4\u5ea6\u7684\u4fe1\u606f\uff0c\u5177\u4f53\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p></p> <p>\u591a\u7ef4\u5ea6\u5149\u4fe1\u53f7\u8868\u5f81\u4e86\u89c2\u6d4b\u76ee\u6807\u7684\u5168\u65b9\u4f4d\u89c6\u89c9\u7279\u5f81\uff0c\u5728\u4e0d\u540c\u9886\u57df\u5747\u5177\u6709\u91cd\u8981\u7684\u5e94\u7528\uff0c\u4f8b\u5982\u5149\u5f3a\u6210\u50cf\u3001\u5149\u8c31\u6210\u50cf\u4ee5\u53ca\u76f8\u4f4d\u6210\u50cf\u7b49\u7b49\u3002\u73b0\u6709\u4f20\u611f\u5668\u4ef6\uff08\u5982\u7535\u8377\u8026\u5408\u5668\u4ef6\uff0cCCD\uff09\u6216\u4e92\u8865\u91d1\u5c5e\u6c27\u5316\u7269\u534a\u5bfc\u4f53\uff08CMOS\uff09\u4f20\u611f\u5668\u4ef6\u54cd\u5e94\u7ef4\u5ea6\u5355\u4e00\uff0c\u4ec5\u80fd\u91c7\u96c6\u4f4e\u7ef4\u7a7a\u95f4\u5f3a\u5ea6\u4fe1\u606f\uff0c\u96be\u4ee5\u76f4\u63a5\u63a2\u6d4b\u5149\u8c31\u548c\u76f8\u4f4d\u4fe1\u606f\uff0c\u9020\u6210\u9ad8\u7ef4\u5ea6\u4fe1\u606f\u201c\u770b\u4e0d\u5230\u201d\u7684\u95ee\u9898\u3002\u5df2\u6709\u7684\u5149\u8c31\u63a2\u6d4b\u548c\u76f8\u4f4d\u6210\u50cf\u65b9\u6cd5\u5927\u591a\u4f9d\u8d56\u590d\u6742\u7684\u5149\u5b66\u7cfb\u7edf\uff0c\u5806\u79ef\u591a\u4e2a\u7167\u660e\u3001\u63a2\u6d4b\u5355\u5143\u5bf9\u4e0d\u540c\u7ef4\u5ea6\u4f9d\u6b21\u72ec\u7acb\u63a2\u6d4b\uff0c\u727a\u7272\u65f6\u95f4\u3001\u7a7a\u95f4\u5206\u8fa8\u7387\u4ee5\u53ca\u5149\u6548\u7387\uff0c\u9002\u7528\u6ce2\u6bb5\u6709\u9650\u3002\u56e0\u6b64\uff0c\u5982\u4f55\u4f7f\u7528\u4f4e\u7ef4\u4f20\u611f\u5668\u4ef6\u91c7\u96c6\u9ad8\u5149\u8c31\u4fe1\u606f\u662f\u611f\u77e5\u9886\u57df\u4e9f\u5f85\u89e3\u51b3\u7684\u96be\u9898\u3002</p> <p>\u200b   \u672c\u7ae0\u805a\u7126\u5229\u7528\u4f4e\u7ef4\u4f20\u611f\u5668\u83b7\u53d6\u9ad8\u7ef4\u5149\u4fe1\u606f\u7684\u6311\u6218\uff0c\u4ece\u8ba1\u7b97\u6210\u50cf\u7684\u89d2\u5ea6\u9769\u65b0\u8ba1\u7b97\u5149\u7167\u548c\u8ba1\u7b97\u4f20\u611f\u65b9\u6cd5\uff0c\u63ed\u793a\u964d\u7ef4\u91c7\u6837\u7684\u75c5\u6001\u6027\u548c\u9ad8\u7ef4\u4fe1\u606f\u5197\u4f59\u5ea6\u4e4b\u95f4\u7684\u5173\u8054\uff0c\u6784\u5efa\u9ad8\u6548\u590d\u7528\u673a\u5236\uff0c\u642d\u5efa\u9ad8\u7ef4\u7ed3\u6784\u5149\u8c03\u5236\u7684\u5355\u63a2\u6d4b\u5355\u5143\u8ba1\u7b97\u4f20\u611f\u7cfb\u7edf\uff0c\u5c06\u7a7a-\u65f6-\u8c31-\u76f8\u591a\u7ef4\u5149\u4fe1\u606f\u8026\u5408\u5728\u4f4e\u7ef4\u4f20\u611f\u5668\u6d4b\u5ea6\uff0c\u4ece\u800c\u5b9e\u73b0\u4f4e\u7ef4\u4f20\u611f\u5668\u7684\u591a\u5149\u8c31\u548c\u76f8\u4f4d\u9ad8\u7ef4\u6210\u50cf\u3002\u4e0b\u9762\u5206\u522b\u4ece\u5149\u5f3a\u3001\u5149\u8c31\u3001\u5149\u76f83\u4e2a\u7ef4\u5ea6\u5bf9\u76f8\u5173\u6280\u672f\u8fdb\u884c\u8be6\u7ec6\u4ecb\u7ecd\u3002</p>"},{"location":"computing_imaging/%E4%BF%A1%E6%81%AF%E8%8E%B7%E5%8F%96%E2%80%94%E2%80%94%E2%80%9C%E4%BB%8E%E6%97%A0%E5%88%B0%E6%9C%89%E2%80%9D/#_2","title":"\u5149\u5f3a\u5347\u7ef4","text":""},{"location":"computing_imaging/%E4%BF%A1%E6%81%AF%E8%8E%B7%E5%8F%96%E2%80%94%E2%80%94%E2%80%9C%E4%BB%8E%E6%97%A0%E5%88%B0%E6%9C%89%E2%80%9D/#_3","title":"\u5355\u50cf\u7d20\u4e8c\u7ef4\u6210\u50cf","text":"<p>\u200b   \u4f20\u7edfCCD\u6216\u8005CMOS\u7b49\u7845\u57fa\u4f20\u611f\u5668\u4ec5\u80fd\u591f\u5de5\u4f5c\u5728\u53ef\u89c1\u5149\u6ce2\u6bb5\uff0c\u96be\u4ee5\u5728\u5176\u4ed6\u5e38\u7528\u6ce2\u6bb5\uff08\u5982\u7d2b\u5916\u6ce2\u6bb5\u3001\u7ea2\u5916\u6ce2\u6bb5\u548cX\u5149\u6ce2\u6bb5\u7b49\uff09\u4ea7\u751f\u54cd\u5e94\u5e76\u91c7\u96c6\u76f8\u5e94\u7684\u5149\u4fe1\u53f7\u3002\u56e0\u6b64\uff0c\u8fd9\u4e9b\u6ce2\u6bb5\u7684\u4e8c\u7ef4\u9762\u9635\u6210\u50cf\u662f\u4e00\u4e2a\u4e9f\u5f85\u89e3\u51b3\u7684\u95ee\u9898\u3002\u5f97\u76ca\u4e8e\u5355\u50cf\u7d20\u63a2\u6d4b\u5668\u54cd\u5e94\u6ce2\u6bb5\u5bbd\u7684\u7279\u70b9\uff0c\u4f7f\u7528\u5355\u50cf\u7d20\u63a2\u6d4b\u5668\u8fdb\u884c\u7a7a\u95f4\u626b\u63cf\u53ef\u4ee5\u5b9e\u73b0\u4e8c\u7ef4\u6210\u50cf\uff0c\u4f46\u662f\u8fd9\u79cd\u65b9\u5f0f\u8017\u65f6\u957f\uff0c\u727a\u7272\u4e86\u65f6\u95f4\u5206\u8fa8\u7387\u3002\u672c\u5c0f\u8282\u4ecb\u7ecd\u7684\u5355\u50cf\u7d20\u6210\u50cf\u6280\u672f\u80fd\u591f\u4f7f\u7528\u5355\u50cf\u7d20\u63a2\u6d4b\u5668\u9ad8\u6548\u5730\u83b7\u53d6\u76ee\u6807\u573a\u666f\u7684\u4e8c\u7ef4\u7a7a\u95f4\u4fe1\u606f\u3002</p>"},{"location":"computing_imaging/%E4%BF%A1%E6%81%AF%E8%8E%B7%E5%8F%96%E2%80%94%E2%80%94%E2%80%9C%E4%BB%8E%E6%97%A0%E5%88%B0%E6%9C%89%E2%80%9D/#_4","title":"\u80cc\u666f\u4ecb\u7ecd","text":"<p>\u200b   \u5355\u50cf\u7d20\u6210\u50cf\uff08Single-pixel Imaging, SPI\uff09\u4e0e\u4f20\u7edf\u7684\u6210\u50cf\u65b9\u6cd5\u4f7f\u7528\u4e8c\u7ef4\u4f20\u611f\u5668\u9635\u5217\u5bf9\u5149\u6ce2\u8fdb\u884c\u63a2\u6d4b\u4e0d\u540c\uff0c\u800c\u662f\u4f7f\u7528\u5355\u50cf\u7d20\u63a2\u6d4b\u5668\uff08\u5982\u5149\u7535\u4e8c\u6781\u7ba1\uff09\u6765\u6355\u83b7\u4e8c\u7ef4\u573a\u666f\u51fa\u5c04\u7684\u6240\u6709\u5149\u5b50\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff0cSPI\u4f7f\u7528\u5149\u8c03\u5236\u5668\u6765\u7f16\u7801\u7167\u660e\uff08\u4f8b\u5982\u6563\u5c04\u7247\u6216\u8005\u53ef\u7f16\u7a0b\u7684\u7a7a\u95f4\u5149\u8c03\u5236\u5668SLM\uff09\uff0c\u4ece\u76ee\u6807\u573a\u666f\u51fa\u5c04\u7684\u5149\u6700\u7ec8\u7531\u4e00\u4e2a\u5355\u50cf\u7d20\u63a2\u6d4b\u5668\u6536\u96c6\uff0c\u5e38\u89c1\u7684SPI\u7cfb\u7edf\u5206\u4e3a\u4e24\u79cd\u2014\u2014\u4e3b\u52a8\u5149\u7167SPI\u7cfb\u7edf\uff08\u7a7a\u95f4\u5149\u8c03\u5236\u5668\u4f4d\u4e8e\u5149\u6e90\u548c\u76ee\u6807\u573a\u666f\u4e4b\u95f4\uff09\u548c\u88ab\u52a8\u5149\u7167SPI\u7cfb\u7edf\uff08\u7a7a\u95f4\u5149\u8c03\u5236\u5668\u4f4d\u4e8e\u76ee\u6807\u573a\u666f\u548c\u91c7\u96c6\u6a21\u5757\u4e4b\u95f4\uff09\u3002\u88ab\u52a8\u5149\u7167SPI\u7cfb\u7edf\u4e0d\u9700\u8981\u5305\u542b\u5149\u6e90\uff0c\u57fa\u4e8e\u4e00\u7ef4\u91c7\u96c6\u6570\u636e\u548c\u5bf9\u5e94\u7684\u7167\u660e\u7f16\u7801\uff0cSPI\u901a\u8fc7\u7b97\u6cd5\u4ece\u4e00\u7ef4\u6d4b\u91cf\u6570\u636e\u4e2d\u8ba1\u7b97\u5e76\u91cd\u5efa\u4e8c\u7ef4\u76ee\u6807\u573a\u666f\u56fe\u50cf\u3002\u5df2\u6709\u7684\u91cd\u5efa\u7b97\u6cd5\u5305\u62ec\u7ebf\u6027\u76f8\u5173\u65b9\u6cd5\u3001\u4ea4\u66ff\u6295\u5f71\u65b9\u6cd5\u4ee5\u53ca\u57fa\u4e8e\u538b\u7f29\u611f\u77e5\u7684\u5404\u79cd\u7b97\u6cd5\uff1a</p> <p></p> <p>\u200b   \u4e0e\u4f7f\u7528\u4e8c\u7ef4\u63a2\u6d4b\u5668\u7684\u6210\u50cf\u65b9\u6cd5\u76f8\u6bd4\uff0cSPI\u5177\u6709\u4ee5\u4e0b\u4f18\u70b9\uff1a</p> <p>\u9ad8\u4fe1\u566a\u6bd4</p> <p>\u200b   \u7531\u4e8e\u5149\u8def\u4e2d\u6240\u6709\u7684\u5149\u5b50\u90fd\u88ab\u805a\u96c6\u5230\u5355\u50cf\u7d20\u63a2\u6d4b\u5668\u4e2d\uff0c\u4e14\u5355\u50cf\u7d20\u63a2\u6d4b\u5668\u5177\u6709\u8f83\u5f3a\u7684\u5149\u654f\u6027\uff0c\u56e0\u6b64SPI\u5177\u6709\u8f83\u9ad8\u7684\u4fe1\u566a\u6bd4\uff08SNR\uff09\uff0c\u80fd\u591f\u5728\u5149\u5f3a\u6781\u5c0f\u7684\u73af\u5883\u4e0b\u83b7\u5f97\u9ad8\u4fdd\u771f\u5ea6\u7684\u573a\u666f\u4fe1\u606f\u3002\u8fd9\u5bf9\u4e8e\u591a\u79cd\u6697\u5149\u6210\u50cf\u5e94\u7528\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u4f8b\u5982\u5728\u663e\u5fae\u8367\u5149\u6210\u50cf\u4e2d\uff0c\u7531\u4e8e\u8367\u5149\u6fc0\u53d1\u539f\u7406\uff0c\u7531\u6837\u672c\u5230\u8fbe\u63a2\u6d4b\u5668\u7684\u5149\u5b50\u6570\u8f83\u5c11\uff0c\u4e14\u663e\u5fae\u9886\u57df\u8981\u6c42\u5c3d\u91cf\u964d\u4f4e\u5165\u5c04\u5149\u5149\u5f3a\u4ee5\u964d\u4f4e\u5149\u6bd2\u6027\u3002</p> <p>\u5bbd\u5149\u8c31</p> <p>\u200b   \u7531\u4e8e\u5355\u50cf\u7d20\u63a2\u6d4b\u5668\u7684\u5149\u8c31\u54cd\u5e94\u8303\u56f4\u5f88\u5bbd\uff0c\u56e0\u6b64SPI\u6613\u4e8e\u5b9e\u73b0\u5bbd\u5149\u8c31\u6210\u50cf\uff0c\u5bf9\u4e8e\u591a\u79cd\u9700\u8981\u591a\u5149\u8c31\u4fe1\u606f\u7684\u5e94\u7528\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u4f8b\u5982\u7ea2\u5916\u6210\u50cf\u6d3b\u4f53\u8ddf\u8e2a\u3001\u8d85\u5149\u8c31\u6210\u50cf\u7269\u4f53\u8bc6\u522b\u7b49\u7b49\u3002</p> <p>\u6297\u6563\u5c04</p> <p>\u200b   \u7531\u4e8e\u5355\u50cf\u7d20\u63a2\u6d4b\u5668\u91c7\u96c6\u7684\u662f\u573a\u666f\u4e2d\u6240\u6709\u5149\u7ebf\u7684\u603b\u5149\u5f3a\uff0c\u56e0\u6b64\u5149\u8def\u4e2d\u7684\u4ecb\u8d28\u6563\u5c04\u4e0d\u4f1a\u5f71\u54cd\u6700\u7ec8\u6210\u50cf\u7ed3\u679c\uff0c\u5373SPI\u5bf9\u4e8e\u6837\u672c\u5230\u63a2\u6d4b\u5668\u4e4b\u95f4\u7684\u5149\u8def\u6ca1\u6709\u4efb\u4f55\u8981\u6c42\uff0c\u53ea\u9700\u8981\u5c06\u6837\u672c\u7684\u51fa\u5c04\u5149\u90fd\u6536\u96c6\u5230\u63a2\u6d4b\u5668\u5373\u53ef\u3002\u56e0\u6b64\uff0cSPI\u5728\u5b9e\u73b0\u65e0\u7578\u53d8\u6297\u6563\u5c04\u6210\u50cf\u65b9\u9762\u6709\u5f88\u5927\u7684\u6f5c\u529b\u3002</p> <p>\u200b   \u7531\u4e8e\u5176\u9ad8\u4fe1\u566a\u6bd4\u3001\u5bbd\u5149\u8c31\u3001\u6297\u6563\u5c04\u3001\u4f4e\u6210\u672c\u4ee5\u53ca\u7075\u6d3b\u7684\u7cfb\u7edf\u914d\u7f6e\u7b49\u7279\u6027\uff0cSPI\u5728\u8fd1\u4e9b\u5e74\u5f15\u8d77\u4e86\u8d8a\u6765\u8d8a\u591a\u7684\u5173\u6ce8\uff0c\u5e76\u4e14\u5df2\u88ab\u5e7f\u6cdb\u5e94\u7528\u4e8e\u591a\u5149\u8c31\u6210\u50cf\u3001\u4e09\u7ef4\u5efa\u6a21\u3001\u5149\u5b66\u52a0\u5bc6\u3001\u9065\u611f\u6210\u50cf\u3001\u76ee\u6807\u8ddf\u8e2a\u3001\u900f\u8fc7\u5927\u6c14\u6e4d\u6d41\u6210\u50cf\u7b49\u573a\u666f\u3002</p> <p>\u200b   SPI\u548c\u9b3c\u6210\u50cf\uff08Ghost Imaging, GI\uff09\u5177\u6709\u76f8\u4f3c\u7684\u6210\u50cf\u6a21\u578b\uff0c\u5b83\u4eec\u90fd\u5c06\u76ee\u6807\u573a\u666f\u4fe1\u606f\u4ee5\u5149\u5b66\u65b9\u5f0f\u590d\u7528\u5230\u4e00\u7ef4\u91c7\u96c6\u6570\u636e\u4e2d\uff0c\u5e76\u4e14\u4ee5\u8ba1\u7b97\u7684\u65b9\u5f0f\u4ece\u91c7\u96c6\u6570\u636e\u4e2d\u89e3\u8026\u91cd\u5efa\u4e8c\u7ef4\u573a\u666f\u56fe\u50cf\u3002GI\u8d77\u6e90\u4e8e\u91cf\u5b50\u5149\u5b66\uff0c\u4f7f\u7528\u7ea0\u7f20\u5149\u5b50\u5bf9\u7684\u7a7a\u95f4\u76f8\u5173\u6027\uff08\u4e00\u4e2a\u5149\u5b50\u548c\u573a\u666f\u76f8\u4e92\u4f5c\u7528\u800c\u53e6\u4e00\u4e2a\u4e0d\u548c\u573a\u666f\u76f8\u4e92\u4f5c\u7528\uff09\u5f97\u5230\u7684\u573a\u666f\u56fe\u50cf\u3002GI\u5df2\u7ecf\u88ab\u8bc1\u660e\u9002\u7528\u4e8e\u7ecf\u5178\u7684\u70ed\u5149\u6e90\u3002\u4e3a\u4e86\u7701\u53bb\u8bb0\u5f55\u7167\u660e\u7f16\u7801\u7684\u6b65\u9aa4\uff0c</p> <p>\u200b   \u5b9e\u9645\u7684SPI\u7cfb\u7edf\u4e2d\u5b58\u5728\u591a\u4e2a\u5f71\u54cd\u56fe\u50cf\u91cd\u5efa\u8d28\u91cf\u7684\u56e0\u7d20\uff0c\u5305\u62ec\u5149\u5f3a\u6296\u52a8\uff08\u7535\u538b\u4e0d\u7a33\uff09\u3001\u73af\u5883\u5149\u3001\u6570\u5b57\u5fae\u955c\u5668\u4ef6\uff08DMD\uff09\u8c03\u5236\u504f\u5dee\u3001\u63a2\u6d4b\u5668\u7684\u70ed\u566a\u58f0\u7b49\u3002\u56e0\u6b64\uff0c\u566a\u58f0\u9c81\u68d2\u7684\u91cd\u5efa\u7b97\u6cd5\u5bf9\u6d88\u9664\u4e0a\u8ff0\u8d1f\u9762\u5f71\u54cd\u662f\u5fc5\u8981\u7684\u3002\u53e6\u5916\uff0c\u867d\u7136SPI\u548cGI\u5df2\u7ecf\u5f15\u8d77\u4e86\u5404\u9886\u57df\u8d8a\u6765\u8d8a\u591a\u7684\u5173\u6ce8\uff0c\u4f46\u5176\u7814\u7a76\u76ee\u524d\u5206\u522b\u5728\u8ba1\u7b97\u673a\u79d1\u5b66\u548c\u5149\u5b66\u9886\u57df\u72ec\u7acb\u8fdb\u884c\uff0c\u800c\u5728\u540c\u4e00\u6846\u67b6\u4e0b\u6bd4\u8f83\u5404\u79cd\u91cd\u5efa\u7b97\u6cd5\u662f\u5fc5\u8981\u7684\uff0c\u56e0\u4e3a\u8fd9\u79cd\u7edf\u4e00\u7684\u6bd4\u8f83\u53ef\u4ee5\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u6e05\u6670\u7684\u7406\u89e3\uff0c\u5e76\u5bf9\u4ed6\u4eec\u9009\u62e9\u5408\u9002\u7684\u91cd\u5efa\u7b97\u6cd5\u6709\u6240\u5e2e\u52a9\uff0c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a8\u52a8SPI\u7684\u53d1\u5c55\u548c\u5e94\u7528\u3002</p>"},{"location":"computing_imaging/%E4%BF%A1%E6%81%AF%E8%8E%B7%E5%8F%96%E2%80%94%E2%80%94%E2%80%9C%E4%BB%8E%E6%97%A0%E5%88%B0%E6%9C%89%E2%80%9D/#spi","title":"\u4e0d\u540cSPI\u91cd\u5efa\u7b97\u6cd5\u7684\u5efa\u6a21\u548c\u63a8\u5bfc\u8fc7\u7a0b","text":"<p>\u200b   SPI\u7cfb\u7edf\u662f\u4e00\u4e2a\u7ebf\u6027\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u91c7\u96c6\u6570\u636e\u7684\u751f\u6210\u6a21\u578b\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ Ax=b $$  \u5176\u4e2d\uff0cA\\in R^{m\\times n}\u4e3a\u5149\u7f16\u7801\u77e9\u9635\uff08m\u4e2a\u7f16\u7801\uff0c\u6bcf\u4e2a\u7f16\u7801\u5305\u542bn\u4e2a\u50cf\u7d20\uff09\uff1bx\\in R^{n\\times1}\u4e3a\u9700\u8981\u91cd\u5efa\u7684\u76ee\u6807\u573a\u666f\uff08\u5411\u91cf\u5f62\u5f0f\uff09\uff1bb\\in R^{m\\times1}\u4e3a\u91c7\u96c6\u6570\u636e\u5411\u91cf\uff0cm\u8868\u793a\u91c7\u96c6\u6570\u636e\u7684\u6570\u91cf\uff0cn\u8868\u793a\u9700\u8981\u91cd\u5efa\u7684\u4fe1\u53f7\u6570\u91cf\uff08\u50cf\u7d20\u503c\uff09\u3002SPI\u7684\u91cd\u5efa\u76ee\u7684\u4e3a\u4ece\u7f16\u7801\u77e9\u9635A\u548c\u91c7\u96c6\u6570\u636eb\u4e2d\u91cd\u5efa\u51fa\u76ee\u6807\u573a\u666fx\u3002</p> <p>\u200b   SPI\u91cd\u5efa\u7b97\u6cd5\u53ef\u4ee5\u6839\u636e\u5176\u8fed\u4ee3\u7c7b\u578b\u5206\u4e3a3\u7c7b\uff0c\u5305\u62ec\u7ebf\u6027\u975e\u8fed\u4ee3\u65b9\u6cd5\u3001\u7ebf\u6027\u8fed\u4ee3\u65b9\u6cd5\u4ee5\u53ca\u975e\u7ebf\u6027\u8fed\u4ee3\u65b9\u6cd5\u3002</p>"},{"location":"computing_imaging/%E4%BF%A1%E6%81%AF%E8%8E%B7%E5%8F%96%E2%80%94%E2%80%94%E2%80%9C%E4%BB%8E%E6%97%A0%E5%88%B0%E6%9C%89%E2%80%9D/#_5","title":"\u5355\u50cf\u7d20\u4e09\u7ef4\u6210\u50cf","text":"<p>\u200b   \u4f20\u7edf\u76f8\u673a\u4f7f\u7528\u4e8c\u7ef4\u4f20\u611f\u5668\u9635\u5217\u4f5c\u4e3a\u611f\u5149\u5143\u4ef6\uff0c\u4fe1\u566a\u6bd4\u8f83\u4f4e\uff0c\u76f8\u5e94\u5149\u8c31\u8303\u56f4\u6709\u9650\u3002\u5355\u50cf\u7d20\u63a2\u6d4b\u5668\u4f5c\u4e3a\u65b0\u578b\u7684\u6210\u50cf\u8bbe\u5907\uff0c\u5176\u6700\u5927\u7684\u7279\u70b9\u662f\u4ec5\u5177\u6709\u4e00\u4e2a\u611f\u77e5\u5355\u5143\uff0c\u5c06\u76ee\u6807\u5149\u573a\u7ecf\u8fc7\u8c03\u5236\u540e\u6c47\u805a\u91c7\u96c6\uff0c\u7136\u540e\u4f7f\u7528\u91cd\u5efa\u7b97\u6cd5\uff08\u5982\u7ebf\u6027\u5173\u8054\u3001\u538b\u7f29\u611f\u77e5\u6216\u6df1\u5ea6\u5b66\u4e60\u7b49\uff09\u89e3\u8026\u76ee\u6807\u56fe\u50cf\u3002\u4e0e\u9635\u5217\u4f20\u611f\u6210\u50cf\u76f8\u6bd4\uff0cSPI\u7684\u4fe1\u566a\u6bd4\u9ad8\uff0c\u5149\u8c31\u54cd\u5e94\u8303\u56f4\u66f4\u5bbd\u3002\u5f97\u76ca\u4e8e\u8fd9\u4e9b\u4f18\u52bf\uff0cSPI\u5df2\u88ab\u5e7f\u6cdb\u5e94\u7528\u4e8e\u591a\u4e2a\u9886\u57df\uff0c\u4f8b\u5982\u591a\u5149\u8c31\u6210\u50cf\u3001\u6c14\u4f53\u68c0\u6d4b\u548c\u76ee\u6807\u5206\u7c7b\u7b49\u3002</p> <p>\u200b   \u7136\u800c\uff0c\u7531\u4e8e\u4f20\u7edf\u7684SPI\u4ec5\u5b58\u5728\u4e8c\u7ef4\u7a7a\u95f4\u8c03\u5236\u800c\u7f3a\u5c11\u6df1\u5ea6\u4fe1\u606f\u8c03\u5236\uff0c\u56e0\u6b64\u76ee\u6807\u7684\u6df1\u5ea6\u4fe1\u606f\u4f1a\u5728\u5355\u50cf\u7d20\u91c7\u96c6\u8fc7\u7a0b\u4e2d\u4e22\u5931\uff0c\u5bfc\u81f4\u91cd\u5efa\u56fe\u50cf\u4e2d\u4ec5\u5305\u542b\u4e8c\u7ef4\u7a7a\u95f4\u4fe1\u606f\u3002\u6df1\u5ea6\u4fe1\u606f\u5bf9\u4e8e\u8bf8\u5982\u673a\u5668\u4eba\u6280\u672f\u548c\u865a\u62df\u73b0\u5b9e\u7b49\u8bb8\u591a\u5e94\u7528\u90fd\u81f3\u5173\u91cd\u8981\u3002\u90e8\u5206\u7814\u7a76\u4eba\u5458\u5229\u7528\u4e00\u4e9b\u989d\u5916\u7684\u786c\u4ef6\uff08\u89c1\u4e6632\u9875\uff09\uff0c\u6765\u5b9e\u73b0SPI\u7684\u6df1\u5ea6\u91c7\u96c6\uff0c\u8fd9\u4f1a\u589e\u52a0\u7cfb\u7edf\u7684\u6210\u672c\u548c\u5b9e\u9a8c\u6210\u672c\u3002</p>"},{"location":"computing_imaging/%E4%BF%A1%E6%81%AF%E8%8E%B7%E5%8F%96%E2%80%94%E2%80%94%E2%80%9C%E4%BB%8E%E6%97%A0%E5%88%B0%E6%9C%89%E2%80%9D/#spi_1","title":"SPI\u6df1\u5ea6\u6210\u50cf\u65b9\u6cd5","text":"<p>\u200b   SPI\u6df1\u5ea6\u6210\u50cf\u65b9\u6cd5\u7684\u6846\u67b6\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p></p> <p>SPI\u7f16\u7801\u8fc7\u7a0b\u4ee5\u53ca\u91cd\u5efa\u8fc7\u7a0b\u7684\u5177\u4f53\u6b65\u9aa4\u89c1\u4e6624\u9875</p>"},{"location":"computing_imaging/%E4%BF%A1%E6%81%AF%E8%8E%B7%E5%8F%96%E2%80%94%E2%80%94%E2%80%9C%E4%BB%8E%E6%97%A0%E5%88%B0%E6%9C%89%E2%80%9D/#_6","title":"\u603b\u7ed3","text":""},{"location":"computing_imaging/%E4%BF%A1%E6%81%AF%E8%8E%B7%E5%8F%96%E2%80%94%E2%80%94%E2%80%9C%E4%BB%8E%E6%97%A0%E5%88%B0%E6%9C%89%E2%80%9D/#_7","title":"\u5149\u8c31\u5347\u7ef4","text":"<p>\u200b   \u73b0\u6709\u6444\u50cf\u6280\u672f\u5927\u591a\u57fa\u4e8e\u7ea2\u3001\u7eff\u3001\u84dd\u4e09\u57fa\u8272\u4fe1\u606f\u7ec4\u6210\u5f69\u8272\u56fe\u50cf\u3001\u89c6\u9891\u3002\u867d\u7136\u4e09\u8272\u4f20\u611f\u7b26\u5408\u4eba\u7c7b\u89c6\u89c9\u7cfb\u7edf\u7684\u611f\u77e5\u9700\u6c42\uff0c\u4f46\u662f\u7269\u7406\u4e16\u754c\u5305\u542b\u4e86\u8fdc\u591a\u4e8e\u4e09\u8272\u6570\u636e\u7684\u5149\u8c31\u4fe1\u606f\u3002\u5149\u8c31\u4ee3\u8868\u4e86\u5149\u4fe1\u53f7\u5728\u4e0d\u540c\u6ce2\u6bb5\uff08\u5149\u9891\u7387\uff09\u7684\u5f3a\u5ea6\u5206\u5e03\uff0c\u8868\u5f81\u4e86\u89c2\u6d4b\u5bf9\u8c61\u5bf9\u5149\u7684\u53cd\u5c04\u3001\u900f\u5c04\u7684\u672c\u8d28\u5c5e\u6027\u3002\u5149\u8c31\u4fe1\u606f\u83b7\u53d6\u80fd\u591f\u63d0\u4f9b\u66f4\u591a\u573a\u666f\u7684\u6709\u6548\u7279\u5f81\uff0c\u89e3\u51b3\u4f20\u7edf\u7070\u5ea6\u3001\u5f69\u8272\u6210\u50cf\u4e2d\u7684\u201c\u540c\u8272\u5f02\u8c31\u201c\u95ee\u9898\uff0c\u5e2e\u52a9\u4eba\u4eec\u51c6\u786e\u5730\u533a\u5206 \u4e0d\u540c\u7684\u7269\u8d28\u6210\u5206\uff0c\u66f4\u52a0\u5168\u9762\u3001\u6e05\u6670\u5730\u8ba4\u8bc6\u89c2\u6d4b\u76ee\u6807\u3002</p> <p>\u200b   \u9ad8\u5149\u8c31\u89c6\u9891\u6210\u50cf\u63d0\u4f9b\u7269\u7406\u4e16\u754c\u7684\u7a7a\u95f4\u3001\u5149\u8c31\u3001\u65f6\u95f4\u56db\u7ef4\u4fe1\u606f\u5206\u5e03\uff08\u7a7a\u95f4\u5305\u542b\u4e24\u7ef4\uff09\uff0c\u5305\u542b\u51e0\u5341\u751a\u81f3\u4e0a\u767e\u4e2a\u5149\u8c31\u901a\u9053\uff0c\u6bcf\u4e2a\u5149\u8c31\u901a\u9053\u7684\u6570\u636e\u4ee3\u8868\u4e86\u76ee\u6807\u573a\u666f\u5728\u8be5\u6ce2\u6bb5\u968f\u65f6\u95f4\u53d8\u5316\u7684\u5f3a\u5ea6\u4fe1\u606f\uff1a</p> <p></p> <p>\u5f97\u76ca\u4e8e\u7a7a-\u8c31-\u65f6\u9ad8\u7ef4\u4fe1\u606f\u83b7\u53d6\uff0c\u9ad8\u5149\u8c31\u89c6\u9891\u6210\u50cf\u5df2\u7ecf\u5e7f\u6cdb\u5e94\u7528\u4e8e\u519b\u4e8b\u3001\u5de5\u4e1a\u3001\u519c\u4e1a\u3001\u533b\u5b66\u7b49\u9886\u57df\uff0c\u4f8b\u5982\u9690\u85cf\u76ee\u6807\u4fa6\u67e5\u3001\u77ff\u7269\u5730\u8d28\u52d8\u63a2\u3001\u519c\u4f5c\u7269\u957f\u52bf\u76d1\u6d4b\u3001\u75c5\u7406\u7ec4\u7ec7\u68c0\u67e5\u7b49\u3002\u9664\u6b64\u4e4b\u5916\uff0c\u9ad8\u5149\u8c31\u89c6\u9891\u6210\u50cf\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u3001\u56fe\u5f62\u5b66\u9886\u57df\u7684\u5e94\u7528\u5728\u4e0d\u65ad\u83b7\u5f97\u7a81\u7834\uff0c\u4f8b\u5982\u7269\u4f53\u8ddf\u8e2a\u3001\u56fe\u50cf\u5206\u5272\u3001\u573a\u666f\u6e32\u67d3\u7b49\u3002</p>"},{"location":"computing_imaging/%E4%BF%A1%E6%81%AF%E8%8E%B7%E5%8F%96%E2%80%94%E2%80%94%E2%80%9C%E4%BB%8E%E6%97%A0%E5%88%B0%E6%9C%89%E2%80%9D/#_8","title":"\u591a\u5149\u8c31\u5355\u50cf\u7d20\u6210\u50cf","text":"<p>\u200b   \u591a\u5149\u8c31\u6210\u50cf\u91c7\u96c6\u76ee\u6807\u573a\u666f\u7684\u7a7a\u57df-\u5149\u8c31\u4fe1\u606f\uff0c\u5176\u4ea7\u751f\u7684\u6570\u636e\u5305\u542b\u4e00\u7ec4\u4e0d\u540c\u6ce2\u957f\u7684\u4e8c\u7ef4\u56fe\u50cf\uff0c\u540c\u65f6\u5177\u6709\u7a7a\u95f4\u548c\u5149\u8c31\u89e3\u6790\u80fd\u529b\u3002\u73b0\u6709\u7684\u591a\u5149\u8c31\u6210\u50cf\u5927\u591a\u5229\u7528\u8272\u6563\u5149\u5b66\u88c5\u7f6e\uff08\u5982\u68f1\u955c\u548c\u884d\u5c04\u5149\u6805\uff09\u6216\u7a84\u5e26\u6ee4\u5149\u5668\u6765\u5206\u79bb\u4e0d\u540c\u6ce2\u957f\u7684\u5149\uff0c\u7136\u540e\u4f7f\u7528\u4f20\u611f\u5668\u9635\u5217\u8fdb\u884c\u591a\u6b21\u91c7\u96c6\uff0c\u5229\u7528\u538b\u7f29\u611f\u77e5\u6280\u672f\uff0c\u53ef\u4ee5\u5c06\u591a\u5149\u8c31\u56fe\u50cf\u590d\u7528\u5728\u4e00\u8d77\u4ee5\u51cf\u5c11\u6240\u9700\u7684\u91c7\u96c6\u6570\u636e\u91cf\u3002\u53e6\u4e00\u79cd\u591a\u5149\u8c31\u6210\u50cf\u65b9\u6cd5\u662f\u5085\u91cc\u53f6\u5149\u8c31\u6210\u50cf\u6280\u672f\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5229\u7528\u5e72\u6d89\u4eea\u5c06\u5165\u5c04\u5149\u675f\u5206\u4e3a\u4e24\u90e8\u5206\uff0c\u901a\u8fc7\u6539\u53d8\u5b83\u4eec\u7684\u5149\u7a0b\u5dee\u4f7f\u5f97\u5728\u6bcf\u4e2a\u7a7a\u95f4\u70b9\u4ea7\u751f\u53d8\u5316\u7684\u5e72\u6d89\u5f3a\u5ea6\uff08\u901a\u8fc7\u8c03\u6574\u6216\u6539\u53d8\u5149\u7ebf\u4ece\u4e0d\u540c\u5149\u6e90\u70b9\u5230\u8fbe\u89c2\u5bdf\u70b9\u7684\u8def\u5f84\u957f\u5ea6\u5dee\uff0c\u53ef\u4ee5\u5728\u6bcf\u4e2a\u89c2\u5bdf\u7684\u7a7a\u95f4\u70b9\u4ea7\u751f\u4e0d\u540c\u7684\u5e72\u6d89\u5f3a\u5ea6\uff09\uff0c\u7136\u540e\u901a\u8fc7\u5085\u91cc\u53f6\u53d8\u6362\u4ece\u9635\u5217\u63a2\u6d4b\u5668\u4e0a\u7684\u5f3a\u5ea6\u6d4b\u91cf\u503c\u4e2d\u5c06\u5149\u8c31\u4fe1\u606f\u63d0\u53d6\u51fa\u6765\u3002\u5c3d\u7ba1\u4e0a\u8ff0\u591a\u5149\u8c31\u6210\u50cf\u65b9\u6cd5\u7684\u539f\u7406\u548c\u88c5\u7f6e\u5404\u4e0d\u540c\uff0c\u4f46\u5728\u7a7a\u95f4\u57df\u6216\u5149\u8c31\u57df\u4e2d\u8fdb\u884c\u6d4b\u91cf\u5747\u7531\u4f20\u611f\u5668\u9635\u5217\u5b8c\u6210\uff0c\u56e0\u6b64\u591a\u5149\u8c31\u6210\u50cf\u4eea\u7684\u5149\u5b50\u6548\u7387\u8f83\u4f4e\uff0c\u4e14\u5149\u8c31\u63a2\u6d4b\u8303\u56f4\u6709\u9650\u3002\u6b64\u5916\uff0c\u5b83\u4eec\u666e\u904d\u4f53\u79ef\u5e9e\u5927\u4e14\u8f83\u4e3a\u6602\u8d35\uff0c\u4f7f\u5b83\u4eec\u96be\u4ee5\u7528\u4e8e\u5927\u91cf\u7684\u65e5\u5e38\u5e94\u7528\u3002</p> <p>\u200b   \u5355\u50cf\u7d20\u6210\u50cf\u6280\u672f\u4e3a\u89e3\u51b3\u4e0a\u8ff0\u591a\u5149\u8c31\u6210\u50cf\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u7684\u65b9\u6848\uff0cSPI\u4f7f\u7528\u5355\u50cf\u7d20\u63a2\u6d4b\u5668\u4ee3\u66ff\u6602\u8d35\u4e14\u590d\u6742\u7684CCD\u6216CMOS\u4f20\u611f\u5668\u4ef6\uff0c\u56e0\u6b64\u6210\u672c\u4f4e\u3001\u7ed3\u6784\u7d27\u51d1\u4e14\u5177\u6709\u66f4\u5bbd\u7684\u5149\u8c31\u54cd\u5e94\u8303\u56f4\u3002\u6b64\u5916\uff0cSPI\u53ef\u5c06\u76ee\u6807\u573a\u666f\u53cd\u5c04\u6216\u900f\u5c04\u7684\u6240\u6709\u5149\u7ebf\u6536\u96c6\u5230\u4e00\u4e2a\u4f20\u611f\u5355\u5143\u4e2d\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u5149\u5b50\u6548\u7387\u3002\u8fd1\u5e74\u6765\uff0cSPI\u5728\u4e8c\u7ef4\u6210\u50cf\u548c\u5404\u79cd\u884d\u751f\u5e94\u7528\u4e2d\u5747\u53d6\u5f97\u4e86\u5e7f\u6cdb\u4e14\u6210\u529f\u7684\u5e94\u7528\u3002</p> <p>\u200b   \u5229\u7528SPI\u6280\u672f\u8fdb\u884c\u591a\u5149\u8c31\u6210\u50cf\u6709\u4e24\u79cd\u76f4\u63a5\u7684\u65b9\u6cd5\u3002\u4e00\u79cd\u662f\u5bf9\u5165\u5c04\u5149\u5149\u8c31\u8fdb\u884c\u5206\u89e3\uff0c\u4ece\u800c\u5bf9\u4e0d\u540c\u5149\u8c31\u5206\u522b\u8fdb\u884c\u6d4b\u91cf\u3002\u6b64\u7c7b\u65b9\u6cd5\u5305\u62ec\uff1a</p> <ul> <li>\u76f4\u63a5\u4f7f\u7528\u5149\u8c31\u4eea\u66ff\u6362\u5355\u50cf\u7d20\u63a2\u6d4b\u5668\uff1b</li> <li>\u5728\u6d4b\u91cf\u524d\u4f7f\u7528\u6ee4\u6ce2\u7247\u6216\u8272\u6563\u5149\u5b66\u88c5\u7f6e\u6765\u5206\u79bb\u4e0d\u540c\u6ce2\u957f\u7684\u5149\uff0c\u7136\u540e\u4f7f\u7528\u5355\u50cf\u7d20\u63a2\u6d4b\u5668\u8fdb\u884c\u626b\u63cf\u6d4b\u91cf\u3002</li> </ul> <p>\u200b   \u53e6\u4e00\u79cd\u76f4\u63a5\u7684\u65b9\u6cd5\u662f\u4f7f\u7528\u4e24\u4e2a\u7a7a\u95f4\u5149\u8c03\u5236\u5668\u5c06\u4f20\u7edfSPI\u4e2d\u7684\u4e8c\u7ef4\u7a7a\u57df\u8c03\u5236\u76f4\u63a5\u6269\u5c55\u4e3a\u7a7a\u57df-\u5149\u8c31\u8c03\u5236\u3002\u7136\u800c\uff0c\u8fd9\u5c06\u589e\u52a0\u91cd\u5efa\u6240\u9700\u7684\u8c03\u5236\u63a9\u6a21\u6570\u91cf\u548c\u76f8\u5e94\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u3002\u7efc\u4e0a\uff0c\u7531\u4e8e\u5355\u4e2a\u5355\u50cf\u7d20\u63a2\u6d4b\u5668\u96be\u4ee5\u533a\u5206\u4e0d\u540c\u7684\u5149\u8c31\uff0c\u56e0\u6b64\u4e0a\u8ff0\u65b9\u6cd5\u662f\u901a\u8fc7\u589e\u52a0\u6210\u672c\u6216\u8c03\u5236\u63a9\u6a21\u6570\u91cf\uff08\u8ba1\u7b97\u91cf\uff09\u6765\u5b9e\u73b0\u591a\u5149\u8c31\u6210\u50cf\u3002</p> <p>\u200b   \u63a5\u4e0b\u6765\u4ecb\u7ecd\u4e00\u79cd\u591a\u5149\u8c31\u5355\u50cf\u7d20\u6210\u50cf\u6280\u672f\uff08MSPI\uff09\uff0c\u4e0e\u4f20\u7edf\u7684SPI\u76f8\u6bd4\uff0cMSPI\u65e0\u9700\u589e\u52a0\u8c03\u5236\u63a9\u6a21\u6570\u91cf\u548c\u91c7\u96c6\u65f6\u95f4\uff0c\u4e0b\u56fe\u5c55\u793a\u4e86MSPI\u4e0e\u4f20\u7edfSPI\u5728\u5149\u7167\u7aef\u7684\u4e3b\u8981\u533a\u522b\uff1a</p> <p></p> <p>\u200b   \u7531\u4e8e\u5355\u50cf\u7d20\u63a2\u6d4b\u5668[\u5146\u8d6b\u5179MHz\u6216\u5409\u8d6b\u5179GHz]\u7684\u54cd\u5e94\u901f\u5ea6\u6bd4\u7a7a\u95f4\u5149\u8c03\u5236\u5668[\u4e0d\u9ad8\u4e8e\u5343\u8d6b\u5179kHz]\u5feb\uff0c\u6240\u4ee5\u76ee\u6807\u573a\u666f\u7684\u5149\u8c31\u4fe1\u606f\u80fd\u591f\u88ab\u7f16\u7801\u5230\u8fd9\u4e2a\u901f\u5ea6\u5dee\u4e2d\u3002MSPI\u5728\u6bcf\u6b21\u7a7a\u57df\u8c03\u5236\u63a9\u6a21\u8fd0\u884c\u671f\u95f4\u5f15\u5165\u4e86\u5149\u8c31\u6b63\u5f26\u8c03\u5236\u3002\u56e0\u6b64\uff0c\u76ee\u6807\u573a\u666f\u7684\u53cd\u5c04\uff08\u6216\u900f\u5c04\uff09\u5149\u7ebf\u88ab\u590d\u7528\u5230\u5355\u50cf\u7d20\u63a2\u6d4b\u5668\u7684\u4e00\u7ef4\u6d4b\u91cf\u6570\u636e\u4e2d\u3002\u7531\u4e8e\u4e0d\u540c\u6ce2\u957f\u7684\u54cd\u5e94\u4fe1\u53f7\u5728\u5085\u91cc\u53f6\u57df\u4e2d\u7684\u4e3b\u9891\u4e0d\u540c\uff0c\u56e0\u6b64\u8fdb\u884c\u7b80\u5355\u7684\u5085\u91cc\u53f6\u5206\u89e3\u540e\u5c31\u80fd\u591f\u5c06\u4e0d\u540c\u7684\u591a\u5149\u8c31\u4fe1\u53f7\u5206\u79bb\uff0c\u7136\u540e\u5229\u7528\u538b\u7f29\u611f\u77e5\u7b97\u6cd5\u5206\u522b\u91cd\u5efa\u4e0d\u540c\u6ce2\u6bb5\u7684\u591a\u5149\u8c31\u56fe\u50cf\u3002\u53e6\u5916\uff0c\u5085\u91cc\u53f6\u57df\u4e2d\u7684\u590d\u7528\u548c\u5206\u89e3\u80fd\u591f\u6709\u6548\u5730\u6291\u5236\u7cfb\u7edf\u566a\u58f0\uff0c\u4ece\u800c\u63d0\u9ad8\u7cfb\u7edf\u5bf9\u566a\u58f0\u7684\u9c81\u68d2\u6027\u5e76\u786e\u4fdd\u91cd\u5efa\u8d28\u91cf\u3002</p> <p>\u200b   MSPI\u5177\u6709\u8bb8\u591a\u6f5c\u5728\u7684\u5e94\u7528\uff0c\u5f97\u76ca\u4e8e\u5176\u7a7a\u57df-\u5149\u8c31\u7684\u591a\u7ef4\u590d\u7528\u548c\u5206\u89e3\u6280\u672f\uff0cMSPI\u7684\u5149\u5b50\u6548\u7387\u9ad8\u4e14\u566a\u58f0\u9c81\u68d2\u6027\u5f3a\uff0c\u56e0\u6b64\u5728\u5f31\u5149\u6761\u4ef6\u4e0b\uff08\u5982\u8367\u5149\u663e\u5fae\u548c\u62c9\u66fc\u6210\u50cf\uff09\u5177\u6709\u66f4\u5927\u7684\u4f18\u52bf\u3002\u6b64\u5916\uff0c\u4e0e\u4f20\u7edf\u7684\u591a\u5149\u8c31\u6210\u50cf\u6280\u672f\u76f8\u6bd4\uff0cMSPI\u6240\u4f7f\u7528\u7684\u5355\u50cf\u7d20\u63a2\u6d4b\u5668\u53ef\u4f7f\u7cfb\u7edf\u5177\u6709\u7d27\u51d1\u7684\u5c3a\u5bf8\u548c\u8f83\u8f7b\u7684\u8d28\u91cf\uff0c\u8fd9\u5bf9\u5730\u8d28\u52d8\u63a2\u3001\u519c\u4f5c\u7269\u8bc4\u4f30\u548c\u73af\u5883\u76d1\u6d4b\u7b49\u7a7a\u57fa\u5e94\u7528\u8f83\u4e3a\u6709\u5229\u3002\u91c7\u7528MSPI\u6280\u672f\u7684\u8bbe\u5907\u62e5\u6709\u8f83\u5bbd\u7684\u5149\u8c31\u54cd\u5e94\u8303\u56f4\u4e14\u4ef7\u683c\u8f83\u4f4e\uff0c\u56e0\u6b64\u53ef\u4ee5\u4f5c\u4e3a\u4f4e\u6210\u672c\u3001\u4fbf\u643a\u5f0f\u8bbe\u5907\u8fdb\u884c\u91cf\u4ea7\u3002</p> <p>MSPI\u8ba1\u7b97\u6210\u50cf\u7b56\u7565\u89c1P33\u3002</p>"},{"location":"computing_imaging/%E4%BF%A1%E6%81%AF%E8%8E%B7%E5%8F%96%E2%80%94%E2%80%94%E2%80%9C%E4%BB%8E%E6%97%A0%E5%88%B0%E6%9C%89%E2%80%9D/#_9","title":"\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u5149\u8c31\u91cd\u5efa","text":"<p>\u200b   \u9ad8\u5149\u8c31\u56fe\u50cf\u63d0\u4f9b\u76ee\u6807\u573a\u666f\u6bcf\u4e2a\u7a7a\u95f4\u70b9\u7684\u5149\u8c31\u5206\u5e03\u66f2\u7ebf\uff0c\u4ee3\u8868\u4e86\u76ee\u6807\u573a\u666f\u5728\u4e0d\u540c\u6ce2\u957f\uff08\u5149\u8c31\u7387\uff09\u5904\u7684\u54cd\u5e94\u3002\u7136\u800c\uff0c\u4f20\u7edf\u7684\u9ad8\u5149\u8c31\u6210\u50cf\u7cfb\u7edf\u51e0\u4e4e\u90fd\u9700\u8981\u7279\u5236\u7684\u5206\u5149/\u6ee4\u5149\u5668\u4ef6\u8fdb\u884c\u5149\u8c31\u8c03\u5236\uff0c\u5bfc\u81f4\u7cfb\u7edf\u975e\u5e38\u590d\u6742\u3002\u5177\u4f53\u800c\u8a00\uff0c\u4f20\u7edf\u7684\u9ad8\u5149\u8c31\u6210\u50cf\u65b9\u6cd5\u53ef\u4ee5\u5206\u4e3a\u626b\u63cf\u5f0f\u65b9\u6cd5\u548c\u975e\u626b\u63cf\u5f0f\u65b9\u6cd5\uff0c\u626b\u63cf\u5f0f\u65b9\u6cd5\u5305\u62ec\u4e86\u7a7a\u95f4\u626b\u63cf\u548c\u5149\u8c31\u626b\u63cf\u4e24\u79cd\u7c7b\u4f3c\u3002\u7a7a\u95f4\u626b\u63cf\u5229\u7528\u5149\u8c31\u4eea\u5bf9\u573a\u666f\u8fdb\u884c\u9010\u70b9\u626b\u63cf\uff0c\u4ee5\u83b7\u53d6\u573a\u666f\u4e2d\u6bcf\u4e2a\u7a7a\u95f4\u70b9\u7684\u5149\u8c31\u4fe1\u606f\uff0c\u6700\u7ec8\u5b8c\u6210\u9ad8\u5149\u8c31\u6210\u50cf\uff1b\u5149\u8c31\u626b\u63cf\u5229\u7528\u7a84\u5e26\u6ee4\u6ce2\u5668\u4ef6\u5bf9\u76ee\u6807\u573a\u666f\u8fdb\u884c\u9010\u6ce2\u6bb5\u7684\u62cd\u6444\uff0c\u6700\u7ec8\u5b8c\u6210\u9ad8\u5149\u8c31\u6210\u50cf\u3002\u626b\u63cf\u5f0f\u65b9\u6cd5\u727a\u7272\u4e86\u65f6\u95f4\u5206\u8fa8\u7387\u4ee5\u6362\u53d6\u7a7a\u95f4/\u5149\u8c31\u5206\u8fa8\u7387\u3002\u975e\u626b\u63cf\u5f0f\u65b9\u6cd5\uff08\u5982\u5feb\u7167\u9ad8\u5149\u8c31\u6210\u50cf\uff09\u5177\u6709\u8f83\u9ad8\u7684\u65f6\u95f4\u5206\u8fa8\u7387\uff0c\u4f46\u4f9d\u8d56\u4e8e\u7279\u6b8a\u8bbe\u8ba1\u7684\u5149\u5b66\u5668\u4ef6\u4ee5\u53ca\u5bf9\u5e94\u7684\u91cd\u5efa\u7b97\u6cd5\uff0c\u7cfb\u7edf\u8f83\u4e3a\u590d\u6742\uff0c\u5e76\u4e14\u4f1a\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u727a\u7272\u7a7a\u95f4\u5206\u8fa8\u7387\u3002\u4ee5\u7f16\u7801\u5b54\u5f84\u5feb\u7167\u5149\u8c31\u6210\u50cf\uff08CASSI\uff09\u65b9\u6cd5\u4e3a\u4f8b\uff0c\u5b83\u901a\u8fc7\u5728\u4f20\u611f\u5668\u524d\u5f15\u5165\u5b54\u5f84\u7f16\u7801\uff0c\u5b8c\u6210\u4e86\u4e09\u7ef4\u9ad8\u5149\u8c31\u4fe1\u606f\u5411\u4e8c\u7ef4\u6d4b\u91cf\u503c\u7684\u8026\u5408\u91c7\u96c6\uff0c\u5e76\u4f7f\u7528\u538b\u7f29\u611f\u77e5\u7b97\u6cd5\u8fdb\u884c\u9ad8\u5149\u8c31\u91cd\u5efa\uff0c\u7136\u800c\uff0c\u8fd9\u79cd\u538b\u7f29\u611f\u77e5\u7b97\u6cd5\u5bf9\u590d\u6742\u573a\u666f\u7684\u9ad8\u5149\u8c31\u91cd\u5efa\u6548\u679c\u8f83\u5dee\uff0c\u4e14\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u3002</p> <p>\u200b   \u8fd1\u5e74\u6765\uff0c\u57fa\u4e8eRGB\u5f69\u8272\u56fe\u50cf\u91cd\u5efa\u9ad8\u5149\u8c31\u56fe\u50cf\u9010\u6e10\u6210\u4e3a\u7814\u7a76\u70ed\u70b9\uff0c\u8be5\u7b97\u6cd5\u6240\u9700\u7684\u786c\u4ef6\u7cfb\u7edf\u8f83\u4e3a\u7b80\u5355\uff0c\u4ec5\u9700\u8981RGB\u76f8\u673a\u5373\u53ef\u3002\u4e00\u822c\u5f69\u8272RGB\u76f8\u673a\u7684\u4f20\u611f\u5668\u524d\u90fd\u8986\u76d6\u4e86\u4e00\u5c42\u5f69\u8272\u6ee4\u5149\u9635\u5217\uff08CFA\uff09\uff0c\u5b83\u5bf9\u5149\u8c31\u7684\u8c03\u5236\u5747\u4e3a\u5bbd\u8c31\u5e26\u8026\u5408\u8c03\u5236\uff0c\u56e0\u6b64\u4f20\u611f\u5668\u91c7\u96c6\u7684\u6570\u636e\u4e2d\u5305\u542b\u4e86\u76ee\u6807\u573a\u666f\u591a\u4e2a\u8c31\u6bb5\u8026\u5408\u5728\u4e00\u8d77\u7684\u4fe1\u606f\uff0c\u53ef\u4ee5\u5229\u7528\u7edf\u8ba1\u5b66\u4e60\u7684\u65b9\u6cd5\u5bf9\u5176\u8fdb\u884c\u4fe1\u606f\u89e3\u8026\u3002\u5229\u7528\u5168\u5206\u8fa8\u7387RGB\u4e09\u901a\u9053\u56fe\u50cf\u4f5c\u4e3a\u8f93\u5165\uff0c\u91cd\u5efa\u9ad8\u5149\u8c31\u56fe\u50cf\uff0c\u800c\u5b9e\u9645\u4e2d\u7684RGB\u76f8\u673a\u5927\u591a\u53ea\u80fd\u91c7\u96c6\u5230\u4e00\u5f20\u56fe\u50cf\uff0c\u5373\u9a6c\u8d5b\u514b\u56fe\u50cf\uff08mosaic\uff09\uff0c\u4e3a\u4e86\u5f97\u5230\u5168\u5206\u8fa8\u7387\u7684RGB\u4e09\u901a\u9053\u56fe\u50cf\uff0c\u9700\u8981\u8fdb\u884c\u53bb\u9a6c\u8d5b\u514b\u8fc7\u7a0b\uff08\u5177\u4f53\u89c1\u8bba\u6587\u300aComparison of color demosaicing methods\u300b\uff09\uff0c\u8fd9\u4f1a\u589e\u52a0\u5149\u8c31\u91cd\u5efa\u8fc7\u7a0b\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u4ee5\u53ca\u79ef\u7d2f\u8bef\u5dee\u3002</p> <p>\u200b   \u672c\u4e66\u4ecb\u7ecd\u4e86\u4e00\u79cd\u4ece\u5355\u5f20\u9a6c\u8d5b\u514b\u56fe\u50cf\u76f4\u63a5\u91cd\u5efa\u591a\u5149\u8c31\u56fe\u50cf\u7684\u7aef\u5230\u7aef\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u53ef\u4ee5\u7701\u53bb\u201c\u53bb\u9a6c\u8d5b\u514b\u201d\u7684\u8fc7\u7a0b</p> <p>\u95ee\u9898\uff1a\u5927\u90e8\u5206\u76f8\u673a\u5982\u679c\u662f\u53ea\u80fd\u6355\u83b7\u5355\u56fe\u6570\u636e\u7684\u8bdd\uff0c\u90a3\u91cd\u5efa\u7b97\u6cd5\u4e00\u822c\u662f\u600e\u6837\u7684\uff1f\u76f8\u673a\u5185\u90e8\u4e00\u5b9a\u4f1a\u5185\u5d4c\u4e00\u4e2a\u53bb\u9a6c\u8d5b\u514b\u8fc7\u7a0b\u5417\uff1f</p>"},{"location":"detection/detection_sum/","title":"\u76ee\u6807\u68c0\u6d4b\u6c47\u603b","text":""},{"location":"detection/detection_sum/#_2","title":"\u5173\u952e\u6982\u5ff5","text":"<ul> <li>\u951a\u70b9\uff1a\u9884\u8bbe\u7684\u68c0\u6d4b\u6846</li> <li>\u56de\u5f52\u53c2\u6570\uff1a\u5fae\u8c03\u951a\u70b9\u8fb9\u754c\u6846</li> <li>IoU\uff1a\u8861\u91cf\u8fb9\u754c\u6846\u4e4b\u95f4\u7684\u91cd\u5408\u5ea6</li> </ul>"},{"location":"detection/detection_sum/#_3","title":"\u901a\u7528\u7a0b\u5e8f","text":"<ul> <li>\u951a\u70b9\u751f\u6210\uff1a\u9488\u5bf9\u6bcf\u7ec4\u7279\u5f81\u56fe\u751f\u6210\u951a\u70b9\u56fe</li> <li>\u951a\u70b9\u5339\u914d\uff1a\u5229\u7528\u7269\u4f53\u8fb9\u754c\u6846\u6807\u7b7e\u5bf9\u751f\u6210\u951a\u70b9\u6807\u7b7e</li> <li>\u53c2\u6570\u7f16\u7801\u89e3\u7801\uff1a\u5b9e\u73b0\u8fb9\u754c\u6846\u7f16\u7801\u548c\u56de\u5f52\u53c2\u6570\u89e3\u7801</li> <li>\u8ba1\u7b97IoU\uff1a\u8ba1\u7b97IoU</li> <li>\u6570\u636e\u5904\u7406\u6a21\u5757\uff1a\u6570\u636e\u9884\u5904\u7406\u2014\u2014\u5c06\u56fe\u7247\u7f29\u653e\u3001\u6253\u5305\uff0c\u6570\u636e\u540e\u5904\u7406\u2014\u2014\u5c06\u5f97\u5230\u7684\u5750\u6807\u6620\u5c04\u56de\u539f\u6765\u7684\u56fe\u7247\u5c3a\u5bf8</li> <li>\u8bad\u7ec3\u7a0b\u5e8f\uff1a\u8bad\u7ec3\u68c0\u6d4b\u7f51\u7edc</li> </ul>"},{"location":"detection/detection_sum/#_4","title":"\u6570\u636e\u589e\u5f3a","text":"<ul> <li>\u4eff\u5c04\u53d8\u6362\uff1a\u5229\u7528\u4eff\u5c04\u53d8\u6362\u5b9e\u73b0\u56fe\u7247\u4ee5\u53ca\u6807\u7b7e\u7684\u65cb\u8f6c\u3001\u5e73\u79fb\u3001\u7f29\u653e\u3001\u9519\u5207</li> <li>mosaic\u589e\u5f3a\uff1a\u5c06\u56db\u5f20\u56fe\u7247\u968f\u673a\u62fc\u63a5\u6210\u4e00\u5f20\u56fe\u7247</li> </ul>"},{"location":"detection/detection_sum/#_5","title":"\u68c0\u6d4b\u7f51\u7edc","text":"<ul> <li>Faster R-CNN\uff1a\u7b2c\u4e00\u9636\u6bb5RPN\u3001\u7b2c\u4e8c\u9636\u6bb5ROI Head</li> <li>RetinaNet</li> <li>YOLOv3-SPP\u3001YOLOv4</li> <li>DETR\uff1a\u57fa\u4e8eTransformers\u7684\u7aef\u5230\u7aef\u76ee\u6807\u68c0\u6d4b\u5668</li> </ul>"},{"location":"detection/detection_sum/#_6","title":"\u5e38\u7528\u6a21\u5757","text":"<ul> <li>\u7279\u5f81\u91d1\u5b57\u5854\uff1aFeature Pyramid Networks\u2014\u2014FPN</li> <li>\u7126\u70b9\u635f\u5931\uff1aFocal Loss\u2014\u2014FL</li> <li>\u975e\u5c40\u90e8\u6ce8\u610f\u529b\uff1aNon-local Neural Networks\u2014\u2014NL</li> </ul> <p>\u6ce8\uff1aCOCO\u6570\u636e\u96c6\u4e0b\u8f7d\uff1ahttps://cocodataset.org/#download</p> <p>\u4fee\u6539\u4e8e\uff1a2023\u5e744\u670821\u65e5</p>"},{"location":"detection/concept/IoU/","title":"IoU\u2014\u2014\u8fb9\u754c\u6846\u91cd\u5408\u5ea6","text":"<p>\u76f8\u5173\u7a0b\u5e8f\uff1a\u8ba1\u7b97IoU</p>"},{"location":"detection/concept/IoU/#_1","title":"\u7b80\u4ecb","text":"<p>\u2003\u2003\u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\u5e38\u7528\u5230\u4e00\u4e2a\u6307\u6807IoU\uff0c\u53c8\u79f0\u4ea4\u5e76\u6bd4\uff0c\u7528\u4e8e\u8861\u91cf\u4e00\u5e45\u56fe\u50cf\u4e2d\u4e24\u4e2a\u8fb9\u754c\u6846\u7684\u91cd\u5408\u5ea6\u3002\u5728\u8bad\u7ec3\u9636\u6bb5\uff0c\u53ef\u4ee5\u7528\u4e8e\u8861\u91cf\u951a\u6846\u548c\u7269\u4f53\u8fb9\u754c\u6846\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6\uff0c\u6765\u7ed9\u6bcf\u4e2a\u951a\u70b9\u5212\u5206\u6b63\u8d1f\u6837\u672c\uff0c\u5373\u7ed9\u951a\u70b9\u5339\u914d\u6807\u7b7e\uff0c\u540c\u65f6\u4e5f\u53ef\u4ee5\u7528\u4f5c\u635f\u5931\u51fd\u6570\uff0c\u901a\u8fc7\u63d0\u9ad8\u9884\u6d4b\u8fb9\u754c\u6846\u4e0e\u771f\u5b9e\u8fb9\u754c\u6846\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6\u6765\u6539\u5584\u7f51\u7edc\u9884\u6d4b\u7269\u4f53\u8fb9\u754c\u6846\u7684\u80fd\u529b\uff1b\u5728\u6d4b\u8bd5\u9636\u6bb5\uff0c\u53ef\u4ee5\u5229\u7528IoU\u6765\u8861\u91cf\u9884\u6d4b\u8fb9\u754c\u6846\u4e4b\u95f4\u7684\u91cd\u5408\u5ea6\uff0c\u7528\u4e8e\u8fc7\u6ee4\u91cd\u5408\u5ea6\u9ad8\u7684\u8fb9\u754c\u6846\uff0c\u5373\u53c2\u4e0eNMS\u8fd0\u7b97\u3002</p> <p>\u8ba1\u7b97\u516c\u5f0f</p> <p>\u2003\u2003\u8fb9\u754c\u6846A\u548c\u8fb9\u754c\u6846B\u4e4b\u95f4\u7684\u4ea4\u96c6\u533a\u57df\u9762\u79ef\u9664\u4ee5\u5e76\u96c6\u533a\u57df\u9762\u79ef\uff1a $$ \\text{IoU}=\\frac{A\\cap B}{A\\cup B} $$ </p> <p>\u5176\u4e2dA\u548cB\u5206\u522b\u8868\u793a\u4e24\u4e2a\u8fb9\u754c\u6846\u533a\u57df\u3002</p> <p>\u2003\u2003\u5728\u4f20\u7edf\u5229\u7528l_1\u516c\u5f0f\u8ba1\u7b97\u8fb9\u754c\u6846\u635f\u5931\u65f6\uff0c\u5f88\u5bb9\u6613\u53d7\u5230\u7269\u4f53\u5c3a\u5ea6\u53d8\u5316\u7684\u5e72\u6270\uff0c\u5373\u5927\u7269\u4f53\u6240\u5bf9\u5e94\u7684\u8fb9\u754c\u6846\u6570\u503c\u5f88\u5927\uff0c\u5f80\u5f80\u5177\u6709\u5f88\u5927\u7684\u8ddd\u79bb\u635f\u5931\uff0c\u5bb9\u6613\u4e3b\u5bfc\u7f51\u7edc\u671d\u7740\u68c0\u6d4b\u5927\u7269\u4f53\u7684\u65b9\u5411\u4f18\u5316\uff0c\u4e0d\u5229\u4e8e\u7f51\u7edc\u68c0\u6d4b\u5c0f\u7269\u4f53\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u5229\u7528IoU\u8ba1\u7b97\u8fb9\u754c\u6846\u635f\u5931\u65f6\u6709\u4e00\u4e2a\u5f88\u5927\u7684\u4f18\u70b9\u2014\u2014\u635f\u5931\u7ed3\u679c\u5177\u6709\u5c3a\u5ea6\u4e0d\u53d8\u6027\uff0c\u5373\u635f\u5931\u5927\u5c0f\u4e0d\u4f1a\u53d7\u5230\u7269\u4f53\u5c3a\u5ea6\u4fe1\u606f\u7684\u5f71\u54cd\uff0c\u53ef\u4ee5\u66f4\u51c6\u786e\u5730\u53cd\u5e94\u8fb9\u754c\u6846\u76f8\u4f3c\u5ea6\u3002</p> <p>\u2003\u2003\u4f46\u662f\uff0c\u5229\u7528\u4f20\u7edf\u7684IoU\u8861\u91cf\u76f8\u4f3c\u5ea6\u65f6\u4e5f\u6709\u4e00\u5b9a\u7684\u95ee\u9898\uff0c\u82e5\u4e24\u4e2a\u8fb9\u754c\u6846\u65e0\u91cd\u53e0\uff0c\u5219IoU\u6570\u503c\u4e3a0\uff0c\u5e76\u4e0d\u80fd\u53cd\u5e94\u4e24\u4e2a\u8fb9\u754c\u6846\u4e4b\u95f4\u7684\u76f8\u5bf9\u76f8\u4f3c\u5ea6\uff0c\u4f8b\u5982\uff1a\u4e0d\u80fd\u5f88\u597d\u5730\u53cd\u5e94\u8ddd\u79bb\uff0c\u79bb\u5f97\u8fd1\u7684\u8fb9\u754c\u6846\u80af\u5b9a\u8981\u6bd4\u79bb\u5f97\u8fdc\u7684\u8fb9\u754c\u6846\u66f4\u201c\u76f8\u4f3c\u201d\uff0c\u6b64\u65f6\uff0c\u5982\u679c\u5c06IoU\u7528\u4f5c\u635f\u5931\uff0c\u5219\u68af\u5ea6\u4e3a0\uff0c\u65e0\u6cd5\u8fdb\u884c\u4f18\u5316\u3002</p>"},{"location":"detection/concept/IoU/#_2","title":"\u6539\u8fdb","text":""},{"location":"detection/concept/IoU/#generalized_iougiou","title":"Generalized IoU\u2014\u2014GIoU","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aIEEE Conference on Computer Vision and Pattern Recognition 2019 (CVPR, 2019)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content_CVPR_2019/papers/Rezatofighi_Generalized_Intersection_Over_Union_A_Metric_and_a_Loss_for_CVPR_2019_paper.pdf</p> <p>\u2003\u2003\u4e3a\u4e86\u89e3\u51b3\u4e24\u4e2a\u8fb9\u754c\u6846\u4e0d\u60f3\u4ea4\u65f6\u65e0\u6cd5IoU\u65e0\u6cd5\u8861\u91cf\u76f8\u4f3c\u5ea6\u8fd9\u4e00\u95ee\u9898\uff0c\u5728\u8bba\u6587\u300aGIoU\u300b\u4e2d\uff0c\u4f5c\u8005\u5f15\u5165\u4e86\u4e24\u4e2a\u8fb9\u754c\u6846\u6700\u5c0f\u5916\u63a5\u77e9\u5f62\u8fd9\u4e00\u6982\u5ff5\uff0c\u5177\u4f53\u5982\u4e0b\u56fe\u7070\u8272\u865a\u7ebf\u77e9\u5f62\u6846\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u6700\u5c0f\u5916\u63a5\u77e9\u5f62\u7684\u9762\u79ef\u53ef\u4ee5\u5f88\u597d\u5730\u8861\u91cf\u8fb9\u754c\u6846\u4e4b\u95f4\u975e\u91cd\u5408\u533a\u57df\u7684\u76f8\u4f3c\u5ea6\u3002</p> <p>\u8ba1\u7b97\u516c\u5f0f $$ GIoU=IoU-\\frac{C-A\\cup B}{C} $$  \u5176\u4e2d\uff0cC\u8868\u793a\u8fb9\u754c\u6846A\u548cB\u4e4b\u95f4\u7684\u6700\u5c0f\u5916\u63a5\u77e9\u5f62\uff0cC-A\\cup B\u6bd4\u8f83\u5927\u65f6\uff0c\u8bf4\u660e\u4e24\u4e2a\u8fb9\u754c\u6846\u975e\u91cd\u5408\u533a\u57df\u6bd4\u8f83\u5927\u3001\u8ddd\u79bb\u6bd4\u8f83\u8fdc\uff0c\u6b64\u65f6GIoU\u6570\u503c\u8f83\u5c0f\u3002</p> <p>\u635f\u5931\u51fd\u6570 $$ L_{GIoU}=1-GIoU $$ \u4f18\u70b9\uff1a</p> <ul> <li>\u5f53IoU\u4e3a0\u65f6\uff0c\u4ecd\u53ef\u4ee5\u901a\u8fc7\u8861\u91cf\u4e24\u4e2a\u8fb9\u754c\u6846\u4e4b\u95f4\u7684\u8ddd\u79bb\u6765\u8861\u91cf\u8fb9\u754c\u6846\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6\uff1b</li> <li>\u76f8\u5bf9\u4e8eIoU\u800c\u8a00\uff0cGIoU\u4e0d\u4ec5\u5173\u6ce8\u91cd\u5408\u533a\u57df\uff0c\u8fd8\u5173\u6ce8\u975e\u91cd\u5408\u533a\u57df\uff0c\u53ef\u4ee5\u66f4\u597d\u5730\u53cd\u5e94\u4e24\u4e2a\u8fb9\u754c\u6846\u4e4b\u95f4\u7684\u91cd\u5408\u5ea6\u3002</li> </ul> <p>\u7f3a\u70b9\uff1a</p> <ul> <li>\u5f53\u4e24\u4e2a\u8fb9\u754c\u6846\u4e3a\u5305\u542b\u5173\u7cfb\u65f6\uff0cC=A\\cup B=\\max\\{A, B\\}\uff0c\u6b64\u65f6GIoU\u4f1a\u9000\u5316\u4e3aIoU\uff0c\u65e0\u6cd5\u533a\u5206\u76f8\u5bf9\u7684\u76f8\u4f3c\u5ea6\uff08\u7c7b\u4f3c\u65e0\u4ea4\u96c6\u65f6\u7684\u7f3a\u70b9\uff09\uff1b</li> <li>\u5728GIoU\u4e2d\uff0c\u8fb9\u754c\u6846\u4e4b\u95f4\u7684\u8ddd\u79bb\u5f88\u5927\u7a0b\u5ea6\u4e0a\u9760\u6700\u5c0f\u5916\u63a5\u77e9\u5f62\u4f53\u73b0\uff0c\u5f53\u4e24\u4e2a\u8fb9\u754c\u6846\u6c34\u5e73\u6216\u8005\u5782\u76f4\u65f6\uff0c\u6c34\u5e73\u6216\u5782\u76f4\u79fb\u52a8\u4e00\u4fa7\u7684\u8fb9\u754c\u6846\uff0c\u6700\u5c0f\u5916\u63a5\u77e9\u5f62\u53ef\u80fd\u4e0d\u53d1\u751f\u53d8\u5316\uff0cGIoU\u53ef\u80fd\u4e0d\u53d8\uff1b</li> </ul> <p> <p></p> <p></p> <p>\u5176\u4e2d\uff0c\u6309\u884c\u6765\u770b\uff0c\u6bcf\u884c\u4e2d\u4e09\u79cd\u60c5\u51b5\u7684GIoU\u7ed3\u679c\u76f8\u540c\uff0c\u4f46\u53ea\u6709C\u7684\u91cd\u5408\u60c5\u51b5\u662f\u6700\u597d\u7684\uff0c\u5373\u4e24\u4e2a\u8fb9\u754c\u6846\u662f\u76f8\u4f3c\u5ea6\u6700\u9ad8\u7684\u3002</p>"},{"location":"detection/concept/IoU/#distance_ioudiou","title":"Distance IoU\u2014\u2014DIoU","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aAssociation for the Advancement of Artificial Intelligence, 2020 (AAAI, 2020)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://arxiv.org/pdf/1911.08287.pdf</p> <p>\u2003\u2003\u9488\u5bf9GIoU\u6240\u5177\u6709\u7684\u95ee\u9898\uff0c\u5728\u8bba\u6587\u300aDIoU\u300b\u4e2d\uff0c\u4f5c\u8005\u5220\u53bb\u4e86\u8ba1\u7b97\u6700\u5c0f\u5916\u63a5\u77e9\u5f62\u9762\u79ef\u7684\u64cd\u4f5c\uff0c\u5f15\u5165\u4e24\u4e2a\u8fb9\u754c\u6846\u8ddd\u79bb\u8fd9\u4e00\u53d8\u91cf\uff08\u4e24\u4e2a\u8fb9\u754c\u6846\u4e2d\u5fc3\u70b9\u4e4b\u95f4\u7684\u8ddd\u79bb\uff09\uff0c\u5229\u7528\u8fb9\u754c\u6846\u8ddd\u79bb\u6765\u8f85\u52a9\u8861\u91cf\u4e24\u4e2a\u8fb9\u754c\u6846\u7684\u76f8\u4f3c\u5ea6\uff0c\u5177\u4f53\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u8ba1\u7b97\u516c\u5f0f\uff1a $$ DIoU=IoU-\\frac{\\rho^2(b,b^{gt})}{c^2} $$  \u5176\u4e2d\\rho\u8868\u793a\u8ba1\u7b97\u5411\u91cf\u4e4b\u95f4\u7684\u6b27\u6c0f\u8ddd\u79bb\uff0cb,b^{gt}\u5206\u522b\u8868\u793a\u4e24\u4e2a\u8fb9\u754c\u6846\uff08\u9884\u6d4b\u6846\u548c\u6807\u7b7e\u6846\uff09\uff0cc\u8868\u793a\u6700\u5c0f\u5916\u63a5\u77e9\u5f62\u7684\u5bf9\u89d2\u7ebf\u8ddd\u79bb\uff0c\\rho^2(b,b^{gt})\u5bf9\u5e94\u4e0a\u56fe\u4e2d\u7684d\u3002</p> <p>\u635f\u5931\u51fd\u6570\uff1a $$ L_{DIoU}=1-DIoU $$ \u4f18\u70b9\uff1a</p> <ul> <li>L_{DIoU}\u53ef\u4ee5\u76f4\u63a5\u6700\u5c0f\u5316\u4e24\u4e2a\u8fb9\u754c\u6846\u4e4b\u95f4\u7684\u8ddd\u79bb\uff0c\u56e0\u6b64\u6536\u655b\u901f\u5ea6\u8981\u6bd4GIoU\u5feb\uff1b</li> <li>\u89e3\u51b3\u4e86GIoU\u4e2d\u8fb9\u754c\u6846\u5305\u542b\u4ee5\u53ca\u7f16\u8f91\u6846\u6c34\u5e73\uff08\u6216\u5782\u76f4\uff09\u5e26\u6765\u7684\u95ee\u9898\uff1b</li> </ul> <p>\u6ce8\uff1a</p> <ul> <li>DIoU\u5e76\u6ca1\u6709\u76f4\u63a5\u5229\u7528\u8fb9\u754c\u6846\u8ddd\u79bb\u505a\u8fd0\u7b97\uff0c\u8fd8\u5bf9\u8ddd\u79bb\u505a\u4e86\u5f52\u4e00\u5316\u5904\u7406\uff08\u9664\u4ee5\u6700\u5c0f\u5916\u63a5\u77e9\u5f62\u7684\u5bf9\u89d2\u7ebf\u957f\u5ea6\uff09\uff0c\u9632\u6b62\u8fb9\u754c\u6846\u5c3a\u5ea6\u53d8\u5316\u5e26\u6765\u7684\u5e72\u6270\uff1b</li> <li>DIoU\u8fd8\u53ef\u4ee5\u5e94\u7528\u5230NMS\u8fd0\u7b97\u4e2d\uff0c\u66ff\u6362\u539f\u59cb\u7684IoU\u8bc4\u4ef7\u7b56\u7565\uff0c\u4f7fNMS\u7684\u8bc4\u4ef7\u7ed3\u679c\u66f4\u52a0\u5408\u7406\u6709\u6548\u3002</li> </ul> <p>\u7f3a\u70b9\uff1a</p> <ul> <li>\u8fb9\u754c\u6846\u4e4b\u95f4\u7684\u5bbd\u9ad8\u6bd4\u4f8b\u4e5f\u662f\u8861\u91cf\u4e24\u4e2a\u8fb9\u754c\u6846\u76f8\u4f3c\u5ea6\u7684\u91cd\u8981\u6307\u6807\uff0c\u53ea\u901a\u8fc7\u8861\u91cf\u8fb9\u754c\u6846\u7684\u8ddd\u79bb\u65e0\u6cd5\u4f53\u73b0\u5bbd\u9ad8\u6bd4\u4f8b\u8fd9\u4e00\u56e0\u7d20\uff0c\u5177\u4f53\u5982\u4e0b\u56fe\u6240\u793a\uff1a</li> </ul> <p> <p></p> <p></p> <p>\u5176\u4e2d\uff0c\u4e09\u79cd\u60c5\u51b5DIoU\u6570\u503c\u76f8\u540c\uff0c\u4f46C\u7684\u76f8\u4f3c\u5ea6\u660e\u663e\u66f4\u597d\uff0cDIoU\u7684\u8fd0\u7b97\u5ffd\u7565\u4e86\u8fd9\u79cd\u72b6\u51b5\u3002</p>"},{"location":"detection/concept/IoU/#complete_iouciou","title":"Complete IoU\u2014\u2014CIoU","text":"<p>\u2003\u2003\u5bf9\u4e8eDIoU\u7684\u7f3a\u70b9\uff0c\u4f5c\u8005\u540c\u65f6\u8bbe\u8ba1\u4e86CIoU\uff0c\u5728\u8ba1\u7b97\u76f8\u4f3c\u5ea6\u65f6\u5f15\u5165\u8fb9\u754c\u6846\u7684\u5bbd\u9ad8\u6bd4\u4f8b\u8fd9\u4e00\u56e0\u7d20\u3002</p> <p>\u8ba1\u7b97\u516c\u5f0f $$ CIoU=IoU-(\\frac{\\rho^2(b,b^{gt})}{c^2}+\\alpha v)\\\\ \\alpha=\\frac{v}{(1-IoU)+v}\\\\ v=\\frac{4}{\\pi^2}(arctan\\frac{w_{gt}}{h_{gt}}-arctan\\frac{w}{h})^2 $$  \u5176\u4e2d\\alpha\u4e3a\u6743\u91cd\uff0cIoU\u8d8a\u5927\uff0c\u8bf4\u660e\u5bbd\u9ad8\u6bd4\u4f8b\u8d8a\u91cd\u8981\uff0cv\u7528\u6765\u8861\u91cf\u5bbd\u9ad8\u6bd4\u4f8b\u7684\u4e00\u81f4\u6027\uff08\u6bd4\u4f8b\u8f6c\u5316\u4e3a\u89d2\u5ea6\uff0c\u518d\u8861\u91cf\u89d2\u5ea6\u4e4b\u95f4\u7684\u6b27\u6c0f\u8ddd\u79bb\uff0c\u4ece\u800c\u8861\u91cf\u6bd4\u4f8b\u5dee\u5f02\uff09\u3002</p> <p>\u635f\u5931\u51fd\u6570 $$ L_{CIoU}=1-CIoU $$ \u4f18\u70b9\uff1a</p> <ul> <li>\u5f15\u5165\u4e86\u8fb9\u754c\u6846\u5bbd\u9ad8\u6bd4\u4f8b\u8fd9\u4e00\u56e0\u7d20\uff0c\u53ef\u4ee5\u66f4\u597d\u5730\u8861\u91cf\u8fb9\u754c\u6846\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6\u3002</li> </ul> <p>\u53c2\u8003\u94fe\u63a5\uff1ahttps://blog.csdn.net/xian0710830114/article/details/128177705</p>"},{"location":"detection/concept/IoU/#_3","title":"\u603b\u7ed3","text":"<p>\u2003\u2003\u5bf9\u4e8e\u8bbe\u8ba1\u8fb9\u754c\u6846\u76f8\u4f3c\u5ea6\u7684\u8ba1\u7b97\u516c\u5f0f\uff0c\u6700\u4e3b\u8981\u7684\u5c31\u662f\u53ef\u4ee5\u8861\u91cf\u4e24\u4e2a\u8fb9\u754c\u6846\u5904\u4e8e\u4efb\u610f\u4f4d\u7f6e\u65f6\u7684\u76f8\u4f3c\u5ea6\uff0c\u8981\u5145\u5206\u8003\u8651\u5404\u79cd\u7279\u6b8a\u60c5\u51b5\uff08\u5982\u8fb9\u754c\u6846\u5305\u542b\u3001\u5206\u79bb\u7b49\uff09\uff0c\u4f4d\u7f6e\u4e0d\u540c\u65f6\u5fc5\u987b\u8981\u4f53\u73b0\u51fa\u4e0d\u540c\u7684\u76f8\u4f3c\u5ea6\u6570\u503c\uff08\u5de7\u5408\u9664\u5916\uff09\uff0c\u8fd9\u6837\u624d\u80fd\u66f4\u597d\u5730\u8861\u91cf\u76f8\u4f3c\u5ea6\uff0c\u7528\u4f5c\u635f\u5931\u53ef\u4ee5\u66f4\u597d\u5730\u8f85\u52a9\u7f51\u7edc\u4f18\u5316\u53c2\u6570\u3002</p> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u6307\u6b63</p> <p>\u521d\u6b65\u5b8c\u7a3f\u4e8e\uff1a2023\u5e742\u670816\u65e5</p>"},{"location":"detection/concept/anchor/","title":"\u951a\u70b9","text":"<p>\u76f8\u5173\u7a0b\u5e8f</p> <p>\u751f\u6210\u951a\u70b9\u56fe\u3001\u951a\u70b9\u5339\u914d</p>"},{"location":"detection/concept/anchor/#_2","title":"\u4ecb\u7ecd","text":"<p>\u2003\u2003\u951a\u70b9\u76f8\u5f53\u4e8e\u5728\u5f85\u9884\u6d4b\u7684\u7279\u5f81\u6570\u636e\u4e0a\u9884\u8bbe\u51fa\u53ef\u80fd\u7684\u7269\u4f53\u8fb9\u754c\u6846\uff0c\u5373\u9884\u8bbe\u51fa\u7279\u5f81\u6570\u636e\u53ef\u80fd\u4ee3\u8868\u7684\u7269\u4f53\u533a\u57df\uff0c\u6bcf\u4e2a\u533a\u57df\u901a\u5e38\u7531\u4e24\u4e2a\u5c5e\u6027\u6784\u6210\u2014\u2014\u5c3a\u5ea6\uff08scale\u6216size\uff09\u548c\u6bd4\u4f8b\uff08ratios\uff09\uff0c\u5373\u533a\u57df\u9762\u79ef\u548c\u533a\u57df\u77e9\u5f62\u7684\u5bbd\u9ad8\u6bd4\u4f8b\uff0c\u4e5f\u53ef\u4ee5\u662f\u951a\u70b9\u5bbd\u9ad8\u6570\u636e\u3002\u6bcf\u4e2a\u951a\u70b9\u90fd\u662f\u5728\u7279\u5f81\u56fe\u50cf\u7d20\u70b9\u7684\u57fa\u7840\u4e0a\u8bbe\u7f6e\u7684\uff0c\u5728\u8bbe\u7acb\u951a\u70b9\u4e4b\u524d\uff0c\u6bcf\u4e2a\u50cf\u7d20\u70b9\u90fd\u53ef\u4ee5\u4ee3\u8868\u539f\u59cb\u56fe\u50cf\u7684\u4e00\u4e2a\u5c0f\u533a\u57df\uff0c\u79f0\u4e3a\u611f\u53d7\u91ce\uff0c\u5982\u679c\u7279\u5f81\u6570\u636e\u7684\u611f\u53d7\u91ce\u8f83\u5927\uff0c\u5219\u8bf4\u660e\u8be5\u7279\u5f81\u53ef\u4ee5\u4ee3\u8868\u539f\u59cb\u56fe\u50cf\u8f83\u5927\u7684\u533a\u57df\uff0c\u4e00\u4e2a\u7279\u5f81\u6570\u636e\u7684\u611f\u53d7\u91ce\u8d8a\u5927\uff0c\u5219\u8bf4\u660e\u8be5\u7279\u5f81\u53ef\u4ee5\u201c\u770b\u201d\u5230\u8d8a\u5927\u7684\u533a\u57df\uff0c\u56e0\u6b64\u8be5\u7279\u5f81\u4e0a\u951a\u70b9\u5c3a\u5ea6\u5c31\u5e94\u8be5\u8d8a\u5927\uff08\u540e\u7eedFPN\u4f1a\u7528\u5230\u8fd9\u4e00\u6982\u5ff5\uff09\uff0c\u4f8b\u5982\u5728Faster R-CNN\u4e2d\uff0c\u4f5c\u8005\u5728\u6700\u540e\u4e00\u4e2a\u7279\u5f81\u5c42\u4e0a\u505a\u9884\u6d4b\uff0c\u5c3a\u5ea6\u88ab\u8bbe\u4e3a128^2\u3001256^2\u3001512^2\uff0c\u6bd4\u4f8b\u88ab\u8bbe\u7f6e\u4e3a1:1\u30011:2\u30012:1\uff0c\u56e0\u6b64\u7279\u5f81\u56fe\u4e0a\u6bcf\u4e2a\u50cf\u7d20\u70b9\u5f80\u5f80\u5bf9\u5e94\u591a\u4e2a\u951a\u70b9\uff0c\u4ece\u800c\u5bf9\u5e94\u539f\u56fe\u591a\u79cd\u533a\u57df\uff0c\u8fdb\u4e00\u6b65\u53ef\u4ee5\u5bf9\u5e94\u591a\u79cd\u53ef\u80fd\u5b58\u5728\u7269\u4f53\u7684\u533a\u57df\u3002</p> <p>\u6ce8\u610f\uff1a</p> <ul> <li>\u540c\u4e00\u7279\u5f81\u53ef\u4ee5\u540c\u65f6\u9884\u8bbe\u591a\u4e2a\u5c3a\u5ea6\u4e0d\u540c\u7684\u951a\u70b9\uff0c\u5373\u951a\u70b9\u5c3a\u5ea6\u548c\u7279\u5f81\u611f\u53d7\u91ce\u65e0\u4e00\u4e00\u5bf9\u5e94\u5173\u7cfb\uff0c\u4f46\u4ed6\u4eec\u5f80\u5f80\u662f\u6b63\u76f8\u5173\u7684\uff0c\u5373\u5927\u611f\u53d7\u91ce\u5f80\u5f80\u5bf9\u5e94\u8f83\u5927\u7684\u951a\u70b9\uff0c\u53cd\u4e4b\u4ea6\u7136\u3002\u5982\u679c\u7279\u5f81\u611f\u53d7\u91ce\u8f83\u5927\uff0c\u5219\u8be5\u7279\u5f81\u5f80\u5f80\u5bf9\u5e94\u5927\u7684\u5c3a\u5ea6\uff0c\u5373\u9884\u6d4b\u5927\u7684\u7269\u4f53\uff0c\u56e0\u4e3a\u5b83\u4eec\u53ef\u4ee5\u770b\u5230\u66f4\u5927\u7684\u533a\u57df\uff0c\u53c8\u56e0\u4e3a\u5b83\u4eec\u770b\u5230\u7684\u533a\u57df\u6bd4\u8f83\u5927\uff0c\u56e0\u6b64\u9884\u6d4b\u5c0f\u7269\u4f53\u4f1a\u4e0d\u51c6\uff0c\u56e0\u4e3a\u5bb9\u6613\u88ab\u540c\u4e00\u533a\u57df\u5185\u7684\u5176\u4ed6\u7269\u4f53\u6240\u5e72\u6270\u3002</li> <li>\u4e3a\u4e86\u540c\u65f6\u68c0\u6d4b\u5927\u7269\u4f53\u548c\u5c0f\u7269\u4f53\uff0c\u5b9e\u9645\u7684\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u5f80\u5f80\u5728\u591a\u7ec4\u7279\u5f81\u56fe\u4e0a\u90e8\u7f72\u951a\u70b9\uff0c\u5b9e\u73b0\u591a\u5c3a\u5ea6\u76ee\u6807\u68c0\u6d4b\u7684\u529f\u80fd\uff0c\u53ef\u4ee5\u53c2\u8003FPN\u7f51\u7edc\uff1b</li> <li>\u951a\u70b9\u5c3a\u5ea6\u53ef\u4ee5\u5927\u4e8e\u7279\u5f81\u611f\u53d7\u91ce\uff0c\u901a\u4fd7\u6765\u8bb2\u5373\u4f7f\u4e00\u4e2a\u7279\u5f81\u53ea\u80fd\u770b\u5230\u7269\u4f53\u7684\u4e00\u534a\uff0c\u4f46\u4ed6\u4e5f\u53ef\u4ee5\u5229\u7528\u8fd9\u4e00\u534a\u6765\u9884\u6d4b\u6574\u4e2a\u7269\u4f53\u3002</li> </ul> <p> <p></p> <p></p>"},{"location":"detection/concept/anchor/#_3","title":"\u5e94\u7528","text":""},{"location":"detection/concept/anchor/#_4","title":"\u751f\u6210\u951a\u70b9\u56fe","text":"<p>\u2003\u2003\u6bcf\u4e2a\u7279\u5f81\u6570\u636e\u5bf9\u5e94\u4e00\u7ec4\u951a\u70b9\uff0c\u6bcf\u4e2a\u951a\u70b9\u5bf9\u5e94\u539f\u56fe\u4e0a\u7684\u4e00\u4e2a\u5c0f\u533a\u57df\uff0c\u5982\u679c\u60f3\u5229\u7528\u6240\u6709\u7684\u951a\u70b9\u56fe\u53c2\u4e0e\u8fb9\u754c\u6846\u9884\u6d4b\uff0c\u5fc5\u987b\u8981\u5c06\u6bcf\u4e2a\u951a\u70b9\u6240\u5bf9\u5e94\u7684\u533a\u57df\u4ee5\u5750\u6807\u7684\u5f62\u5f0f\u8868\u793a\u51fa\u6765\uff0c\u4e5f\u5c31\u662f\u5c06\u6bcf\u4e2a\u951a\u70b9\u533a\u57df\u8868\u793a\u51fa\u6765\uff0c\u5f97\u5230\u4e00\u7ec4\u5750\u6807\u6570\u636e\uff08\u8fd9\u91cc\u7684\u5750\u6807\u5bf9\u5e94\u539f\u59cb\u56fe\u50cf\u7684\u7edd\u5bf9\u5750\u6807\uff09\uff0c\u6bd4\u5982\u5728\u4e0a\u56fe\u4e2d\uff0c\u8981\u5c06\u53f3\u4fa7\u5f69\u8272\u6846\u7684\u5750\u6807\u8868\u793a\u51fa\u6765\uff0c\u5e76\u4e14\u548c\u5de6\u56fe\u7684\u7279\u5f81\u6570\u636e\u505a\u597d\u5bf9\u5e94\u5173\u7cfb\u3002</p>"},{"location":"detection/concept/anchor/#_5","title":"\u6b65\u9aa4","text":"<ul> <li>\u7ed9\u5b9a\u539f\u59cb\u56fe\u50cf\u5c3a\u5bf8\u3001\u7279\u5f81\u56fe\u7684\u5c3a\u5bf8\uff08\u53ef\u4ee5\u662f\u591a\u4e2a\uff0c\u5bf9\u5e94\u4e0d\u540c\u7279\u5f81\u5c42\u53c2\u4e0e\u9884\u6d4b\uff09\u548c\u6bcf\u4e2a\u951a\u70b9\u7684\u5c3a\u5bf8\uff08\u4f8b\u5982Faster R-CNN\u4e2d\u7684size\u548caspect_ratios\uff0c\u4e5f\u53ef\u4ee5\u662fYOLO\u4e2d\u7684\u5bbd\u9ad8\u6570\u636e\uff09\uff1b</li> <li>\u6839\u636e\u7ed9\u5b9a\u7684\u951a\u70b9\u5c3a\u5bf8\u751f\u6210\u951a\u70b9\u6a21\u677f\u5750\u6807\uff1b</li> <li>\u5229\u7528\u539f\u56fe\u5c3a\u5bf8\u548c\u7279\u5f81\u56fe\u5c3a\u5bf8\u8ba1\u7b97\u6b65\u957f\uff0c\u4e4b\u540e\u5c06\u7279\u5f81\u56fe\u50cf\u7d20\u70b9\u6309\u7b49\u6bd4\u6620\u5c04\u5230\u539f\u56fe\u533a\u57df\u4f4d\u7f6e\uff08\u76f8\u5f53\u4e8e\u611f\u53d7\u91ce\u5de6\u4e0a\u89d2\uff0c\u7f51\u683c\u7684\u4ea4\u6c47\u70b9\uff09\uff0c\u5f97\u5230\u7279\u5f81\u6570\u636e\u5728\u539f\u56fe\u4e0a\u7684\u6620\u5c04\u5750\u6807\uff0c\u5750\u6807\u7b49\u8ddd\u5206\u5e03\uff1b</li> <li>\u6620\u5c04\u5750\u6807\u548c\u951a\u70b9\u5750\u6807\u76f8\u52a0\uff0c\u505a\u4e00\u6b21\u5750\u6807\u504f\u79fb\uff0c\u5f97\u5230\u539f\u56fe\u4e0a\u7684\u951a\u70b9\u56fe\u3002</li> </ul> <p>\u951a\u70b9\u6a21\u677f</p> <p>\u2003\u2003\u4ee5\u50cf\u7d20\u70b9\u4e3a\u4e2d\u5fc3\u7684\u4e00\u7ec4\u951a\u70b9\u56fe\uff0c\u8868\u793a\u6bcf\u4e2a\u7279\u5f81\u6570\u636e\u4e0a\u7684\u6240\u6709\u951a\u70b9\u6846\u3002\u4ee5\u5750\u6807\u7684\u5f62\u5f0f\u50a8\u5b58\uff0c(0,0)\u8868\u793a\u951a\u70b9\u4e2d\u5fc3\uff0c\u5373\u539f\u56fe\u50cf\u7d20\u70b9\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u4e0a\u56fe\u4e00\u5171\u6709\u4e5d\u4e2a\u6846\uff0c\u8868\u793a\u5f53\u524d\u7279\u5f81\uff08\u7279\u5f81\u5c42\uff09\u5bf9\u5e94\u4e5d\u4e2a\u951a\u70b9\uff0c\u4e0d\u540c\u989c\u8272\u4ee3\u8868\u4e0d\u540c\u7684\u5c3a\u5ea6\uff0c\u4e5d\u4e2a\u951a\u70b9\u5bf9\u5e943*3\uff0c\u53733\u4e2a\u5c3a\u5ea6\u30013\u4e2a\u6bd4\u4f8b\u3002\uff08\u5f15\u81eaFaster R-CNN\u7b97\u6cd5\uff09</p> <p>\u6ce8\uff1a</p> <ul> <li>\u5e76\u975e\u6240\u6709\u7684\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u90fd\u9700\u8981\u751f\u6210\u951a\u70b9\u56fe\uff0c\u4f8b\u5982YOLO\u7b97\u6cd5\u4fee\u6539\u4e86\u68c0\u6d4b\u673a\u5236\uff0c\u4e0d\u9700\u8981\u751f\u6210\u6574\u5f20\u56fe\u50cf\u7684\u951a\u70b9\u6570\u636e\uff0c\u53ea\u9700\u8981\u7b5b\u9009\u201c\u524d\u666f\u951a\u70b9\u201d\uff0c\u4e4b\u540e\u518d\u6839\u636e\u524d\u666f\u951a\u70b9\u5750\u6807\u6570\u636e\u751f\u6210\u6307\u5b9a\u7684\u951a\u70b9\u6846\u5373\u53ef\uff1b</li> <li>\u5177\u4f53\u4ee3\u7801\u5b9e\u73b0\u65b9\u6cd5\u89c1\uff1a\u951a\u70b9\u751f\u6210\u5668</li> </ul>"},{"location":"detection/concept/anchor/#_6","title":"\u951a\u70b9\u5339\u914d","text":"<p>\u2003\u2003\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6211\u4eec\u4e0d\u4ec5\u9700\u8981\u5229\u7528\u951a\u70b9\u9884\u6d4b\u51fa\u8fb9\u754c\u6846\u6765\uff0c\u8fd8\u9700\u8981\u6307\u5bfc\u6bcf\u4e2a\u951a\u70b9\u6837\u672c\u9884\u6d4b\u7684\u5bf9\u4e0d\u5bf9\uff0c\u5229\u7528\u671f\u671b\u503c\u4e0e\u9884\u6d4b\u503c\u4e4b\u95f4\u7684\u5dee\u989d\u6765\u4f18\u5316\u7f51\u7edc\u53c2\u6570\uff0c\u4e5f\u5c31\u662f\u9700\u8981\u5bf9\u6bcf\u4e2a\u951a\u70b9\u6253\u6807\u7b7e\uff0c\u5224\u5b9a\u8be5\u951a\u70b9\u662f\u5c5e\u4e8e\u80cc\u666f\u8fd8\u662f\u524d\u666f\uff0c\u5982\u679c\u662f\u524d\u666f\u5219\u9700\u8981\u518d\u6307\u660e\u662f\u5c5e\u4e8e\u6807\u7b7e\u4e2d\u7684\u54ea\u4e2a\u7269\u4f53\uff08\u7b2c\u51e0\u4e2a\u524d\u666f\uff09\uff0c\u4fbf\u4e8e\u540e\u7eed\u7ed9\u951a\u70b9\u751f\u6210\u951a\u70b9\u6807\u7b7e\uff08\u5373\u5c5e\u4e8e\u8be5\u951a\u70b9\u7684\u7269\u4f53\u7c7b\u522b\u548c\u5bf9\u5e94\u7684\u56de\u5f52\u53c2\u6570\uff09\u3002</p>"},{"location":"detection/concept/anchor/#_7","title":"\u6b65\u9aa4","text":"<p>Faster R-CNN\u673a\u5236</p> <p>\u2003\u2003\u4e0d\u540c\u7684\u9884\u6d4b\u673a\u5236\u5177\u6709\u4e0d\u540c\u7684\u951a\u70b9\u5339\u914d\u6b65\u9aa4\uff0c\u5982\u679c\u60f3\u5229\u7528\u6574\u5f20\u56fe\u4e2d\u6240\u6709\u7684\u951a\u70b9\u53c2\u4e0e\u9884\u6d4b\uff08\u4f8b\u5982Faster R-CNN\u548cRetinaNet\u7b97\u6cd5\uff09\uff0c\u5219\u9700\u8981\u6839\u636e\u6bcf\u4e2a\u951a\u70b9\u6240\u4ee3\u8868\u7684\u533a\u57df\u4e0e\u7269\u4f53\u8fb9\u754c\u6846\u533a\u57df\u6253\u6807\u7b7e\uff0c\u6b65\u9aa4\u5982\u4e0b\uff1a</p> <ul> <li>\u7ed9\u5b9a\u524d\u666f\u9608\u503c\u3001\u80cc\u666f\u9608\u503c\u3001\u524d\u666f\u8fb9\u754c\u6846\u5750\u6807\u4e0e\u951a\u70b9\u8fb9\u754c\u6846\u5750\u6807\uff1b</li> <li>\u9010\u4e00\u8ba1\u7b97\u6bcf\u4e2a\u951a\u70b9\u4e0e\u6240\u6709\u524d\u666f\u4e4b\u95f4\u7684IoU\u503c\uff0c\u5f97\u5230IoU\u77e9\u9635\uff1b</li> <li>\u5bf9IoU\u77e9\u9635\uff0c\u6cbf\u7269\u4f53\u65b9\u5411\u6c42\u6700\u5927\u503c\uff0c\u5373\u5f97\u5230\u6bcf\u4e2a\u951a\u70b9\u6700\u5927\u7684IoU\u503c\u53ca\u5bf9\u5e94\u7684\u524d\u666f\u7269\u4f53\uff1b</li> <li>\u9010\u4e00\u5224\u65ad\u6bcf\u4e2a\u951a\u70b9\u7684\u6700\u5927IoU\u6570\u503c\uff0c\u5927\u4e8e\u524d\u666f\u9608\u503c\u7684\u6807\u8bb0\u6210\u5bf9\u5e94\u524d\u666f\u7684\u5e8f\u53f7\u3001\u5c0f\u4e8e\u80cc\u666f\u9608\u503c\u7684\u6807\u8bb0\u6210-1\uff0c\u4ecb\u4e8e\u4e8c\u8005\u4e4b\u95f4\u7684\u820d\u5f03\uff0c\u9ed8\u8ba4\u6807\u8bb0\u6210-2\u3002</li> </ul> <p>\u6ce8\uff1a</p> <ul> <li>\u82e5\u8be5\u951a\u70b9\u5c5e\u4e8e\u524d\u666f\uff0c\u5219\u5bf9\u5e94\u503c\u4e3a[0, M-1]\uff0c\u5176\u4e2dM\u4e3a\u5f53\u524d\u56fe\u7247\u7684\u7269\u4f53\u6570\u91cf\uff0c\u4f7f\u6bcf\u4e2a\u5c5e\u4e8e\u524d\u666f\u7684\u951a\u70b9\u90fd\u6709\u4e00\u4e2a\u771f\u5b9e\u524d\u666f\u7269\u4f53\u505a\u5bf9\u5e94\uff0c\u4fbf\u4e8e\u540e\u7eed\u751f\u6210\u7c7b\u522b\u6807\u7b7e\u4ee5\u53ca\u56de\u5f52\u53c2\u6570\u6807\u7b7e\uff1b</li> <li>iou\u503c\u8ba1\u7b97\u516c\u5f0f\uff1a</li> </ul>  \\text{IoU}=\\frac{S_{a\\cap t}}{S_{a\\cup t}}  <p>\u5176\u4e2d\u4e0b\u6807a\u548ct\u5206\u522b\u8868\u793a\u951a\u70b9\u533a\u57df\u548c\u524d\u666f\u6807\u7b7e\u533a\u57df\uff0c\u4e5f\u5c31\u662f\u76f8\u4ea4\u7684\u9762\u79ef\u9664\u4ee5\u76f8\u5e76\u7684\u9762\u79ef\u3002</p> <p>YOLO\u673a\u5236</p> <p>\u2003\u2003\u5982\u679c\u53ea\u671f\u671b\u5229\u7528\u8fb9\u754c\u6846\u9644\u8fd1\uff0c\u5e76\u4e14\u5f62\u72b6\u76f8\u4f3c\u7684\u951a\u70b9\u53c2\u4e0e\u9884\u6d4b\uff08\u4f8b\u5982YOLO\u7b97\u6cd5\uff09\uff0c\u5219\u53ea\u9700\u8981\u7b5b\u9009\u51fa\u6307\u5b9a\u7684\u951a\u70b9\uff08\u5373\u524d\u666f\u951a\u70b9\uff09\uff0c\u5e76\u4e14\u6253\u4e0a\u6807\u7b7e\u5373\u53ef\uff0c\u6b65\u9aa4\u5982\u4e0b\uff1a</p> <ul> <li>\u9010\u4e00\u8ba1\u7b97\u7269\u4f53\u8fb9\u754c\u6846\u548c\u9884\u8bbe\u951a\u70b9\u6a21\u677f\u4e4b\u95f4\u7684IoU\uff08\u9ed8\u8ba40.2\uff09\uff0c\u5bf9\u4e8e\u6bcf\u4e2a\u7269\u4f53\u5339\u914d\u51fa\u5bbd\u9ad8\u6bd4\u4f8b\u6bd4\u8f83\u50cf\u7684\u9884\u8bbe\u951a\u70b9\uff08\u8fd9\u91cc\u6bcf\u4e2a\u7269\u4f53\u53ef\u80fd\u4f1a\u5339\u914d\u591a\u4e2a\u951a\u70b9\u6a21\u677f\uff09\uff1b</li> <li> <p>\u4e4b\u540e\u5c06\u6bcf\u4e2a\u9884\u6d4b\u7279\u5f81\u6570\u636e\u89c6\u4e3a\u4e00\u4e2a\u7f51\u683c\uff0c\u8fb9\u754c\u6846\u4e2d\u5fc3\u5750\u6807\u5411\u4e0b\u53d6\u6574\uff0c\u5f97\u5230\u7f51\u683c\u5de6\u4e0a\u89d2\u5750\u6807\uff0c\u7528\u4e8e\u5224\u65ad\u7269\u4f53\u8fb9\u754c\u6846\u5c5e\u4e8e\u54ea\u4e2a\u9884\u6d4b\u7279\u5f81\uff0c\u8be5\u7279\u5f81\u4e0a\u7684\u951a\u70b9\u624d\u53ef\u80fd\u662f\u524d\u666f\u951a\u70b9\uff0c\u518d\u7ed3\u5408\u521a\u624d\u5339\u914d\u5230\u7684\u9884\u8bbe\u951a\u70b9\uff0c\u5f97\u5230\u524d\u666f\u951a\u70b9\uff0c\u524d\u666f\u951a\u70b9\u6ee1\u8db3\u4e24\u70b9\uff1a\u5bbd\u9ad8\u6bd4\u4f8b\u548c\u7269\u4f53\u8fb9\u754c\u6846\u5bbd\u9ad8\u6bd4\u4f8b\u7c7b\u4f3c\u3001\u7269\u4f53\u4e2d\u5fc3\u4f4d\u4e8e\u8be5\u951a\u70b9\u5185\u90e8\uff08\u4e5f\u5c31\u662f\u7f51\u683c\u5185\u90e8\uff09\uff1b</p> </li> <li> <p>\u5bf9\u4e8e\u6bcf\u4e2a\u5339\u914d\u5230\u7684\u951a\u70b9\uff0c\u9010\u4e00\u8ba1\u7b97\u7f51\u683c\u5de6\u4e0a\u89d2\u5750\u6807\u548c\u8fb9\u754c\u6846\u4e2d\u5fc3\u4e4b\u95f4\u7684\u504f\u79fb\u91cf\uff0c\u5e76\u4e14\u518d\u63d0\u53d6\u5bf9\u5e94\u8fb9\u754c\u6846\u7684\u5bbd\u9ad8\u6570\u636e\uff0c\u5f97\u5230\u951a\u70b9\u7684\u5750\u6807\u6807\u7b7e\uff0c\u4e4b\u540e\u6839\u636e\u4e2d\u5fc3\u70b9\u5750\u6807\u5f97\u5230\u7f6e\u4fe1\u5ea6\u6807\u7b7e\uff0c\u518d\u5229\u7528\u951a\u70b9\u4e0e\u8fb9\u754c\u6846\u4e4b\u95f4\u7684IoU\uff08\u6216GIoU\uff09\u5bf9\u7f6e\u4fe1\u5ea6\u6807\u7b7e\u505a\u52a0\u6743\u5904\u7406\uff08\u5bbd\u9ad8\u6bd4\u4f8b\u8d8a\u50cf\uff0c\u6743\u91cd\u8d8a\u5927\uff09\u3002</p> </li> </ul> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u6307\u6b63</p> <p>\u4fee\u6539\u4e8e\uff1a2023\u5e742\u670816\u65e5</p>"},{"location":"detection/concept/regression/","title":"\u56de\u5f52\u53c2\u6570","text":""},{"location":"detection/concept/regression/#_2","title":"\u7b80\u4ecb","text":"<p>\u2003\u2003\u867d\u7136\u901a\u8fc7\u8bbe\u5b9a\u951a\u70b9\uff0c\u53ef\u4ee5\u8ba9\u7279\u5f81\u56fe\u4e0a\u7684\u50cf\u7d20\u70b9\u4ee3\u8868\u5f62\u72b6\u4e0d\u4e00\u7684\u77e9\u5f62\u533a\u57df\uff0c\u4f46\u5b9e\u9645\u9700\u8981\u68c0\u6d4b\u7684\u533a\u57df\u5bbd\u9ad8\u6bd4\u4f8b\u5177\u6709\u672a\u77e5\u6027\uff0c\u6211\u4eec\u4e0d\u53ef\u80fd\u9884\u8bbe\u51fa\u6240\u6709\u53ef\u80fd\u51fa\u73b0\u7684\u6bd4\u4f8b\uff0c\u56e0\u6b64\u5e76\u4e0d\u80fd\u5355\u5355\u4f9d\u9760\u951a\u70b9\u6765\u5b8c\u6210\u5bf9\u533a\u57df\u7684\u68c0\u6d4b\u3002\u8fd9\u65f6\u5c31\u5f15\u5165\u4e86\u56de\u5f52\u53c2\u6570\u8fd9\u4e00\u6982\u5ff5\uff0c\u56de\u5f52\u53c2\u6570\u76f8\u5f53\u4e8e\u662f\u951a\u70b9\u4e0e\u7269\u4f53\u8fb9\u754c\u6846\uff08\u4ee5\u4e0b\u7b80\u79f0\u8fb9\u754c\u6846\uff09\u4e4b\u95f4\u7684\u201c\u6865\u6881\u201d\uff0c\u6211\u4eec\u53ef\u4ee5\u627e\u51fa\u4e0e\u8fb9\u754c\u6846\u6700\u76f8\u4f3c\u951a\u70b9\uff0c\u4e4b\u540e\u5229\u7528\u56de\u5f52\u53c2\u6570\uff0c\u5c06\u951a\u70b9\u6240\u4ee3\u8868\u7684\u533a\u57df\u5fae\u8c03\u6210\u8fb9\u754c\u6846\u6240\u4ee3\u8868\u7684\u533a\u57df\uff0c\u56e0\u6b64\u56de\u5f52\u53c2\u6570\u5f80\u5f80\u6709\u56db\u4e2a\u503c\uff0c\u5206\u522b\u5bf9\u5e94\u5b9a\u4f4d\u951a\u70b9\u77e9\u5f62\u533a\u57df\u7684\u56db\u4e2a\u503c\uff0c\u53ef\u4ee5\u662f\u77e9\u5f62\u6846\u7684\u5bbd\u3001\u9ad8\u3001\u4e2d\u5fc3\u70b9\u5750\u6807\u7684x\u548cy\uff0c\u4e5f\u53ef\u4ee5\u662f\u77e9\u5f62\u6846\u5de6\u4e0a\u89d2\u7684x\u548cy\u4ee5\u53ca\u53f3\u4e0b\u89d2\u7684x\u548cy\uff0c\u56e0\u6b64\u7f51\u7edc\u5e76\u4e0d\u662f\u76f4\u63a5\u9884\u6d4b\u51fa\u5bf9\u8c61\u7684\u5177\u4f53\u4f4d\u7f6e\uff0c\u800c\u662f\u9884\u6d4b\u51fa\u56de\u5f52\u53c2\u6570\uff0c\u518d\u4e0e\u5bf9\u5e94\u7684\u951a\u70b9\u5750\u6807\u76f8\u7ed3\u5408\uff0c\u5f97\u5230\u5bf9\u8c61\u7684\u4f4d\u7f6e\u3002\u6ce8\u610f\uff1a\u5373\u4f7f\u5bf9\u4e8e\u56fe\u50cf\u4e2d\u7684\u540c\u4e00\u7269\u4f53\uff0c\u7531\u4e8e\u5404\u4e2a\u951a\u70b9\u4f4d\u4e8e\u539f\u56fe\u7684\u4e0d\u540c\u4f4d\u7f6e\uff0c\u56e0\u6b64\u6bcf\u4e2a\u951a\u70b9\u7684\u56de\u5f52\u53c2\u6570\u5747\u4e0d\u540c\u3002</p> <p> <p></p> <p></p> <p>\u2003\u2003\u7f51\u7edc\u901a\u8fc7\u9884\u6d4b\u56de\u5f52\u53c2\u6570\u6765\u95f4\u63a5\u9884\u6d4b\u8fb9\u754c\u6846\u5750\u6807\u8fd8\u6709\u4e00\u4e2a\u597d\u5904\u5c31\u662f\u53ef\u4ee5\u7a33\u5b9a\u7f51\u7edc\u7684\u8f93\u51fa\u3002\u8fb9\u754c\u6846\u5750\u6807\u503c\u7684\u8303\u56f4\u4f1a\u5f88\u5927\uff08\u548c\u56fe\u50cf\u5927\u5c0f\u6709\u5173\uff09\uff0c\u76f4\u63a5\u9884\u6d4b\u5750\u6807\u6570\u636e\u7684\u8bdd\uff0c\u7f51\u7edc\u8f93\u51fa\u7684\u6d6e\u52a8\u8f83\u5927\uff0c\u4ece\u800c\u5bfc\u81f4\u7f51\u7edc\u7a33\u5b9a\u6027\u8f83\u5dee\uff0c\u800c\u56de\u5f52\u53c2\u6570\u7684\u6d6e\u52a8\u8f83\u5c0f\uff0c\u53ea\u8d77\u5230\u5fae\u8c03\u951a\u70b9\u7684\u4f5c\u7528\uff0c\u56e0\u6b64\u7f51\u7edc\u7684\u8f93\u51fa\u4e0d\u4f1a\u8fc7\u5c0f\u6216\u8005\u8fc7\u5927\uff0c\u4fdd\u6301\u5728\u4e00\u4e2a\u7a33\u5b9a\u7684\u8303\u56f4\u5185\uff0c\u907f\u514d\u5728\u53cd\u5411\u4f20\u64ad\u8fc7\u7a0b\u4e2d\u9020\u6210\u68af\u5ea6\u5931\u63a7\u7684\u95ee\u9898\uff0c\u5728\u5904\u7406\u56fe\u50cf\u65f6\u6211\u4eec\u4e5f\u5e38\u5e38\u5c06\u56fe\u50cf\u4f20\u5165\u7f51\u7edc\u4e4b\u524d\u5bf9\u56fe\u50cf\u6570\u636e\u505a\u6807\u51c6\u5316\u6216\u8005\u5f52\u4e00\u5316\uff0c\u4e24\u8005\u53ef\u4ee5\u7ed3\u5408\u7740\u7406\u89e3\u3002</p>"},{"location":"detection/concept/regression/#_3","title":"\u56de\u5f52\u7b56\u7565","text":""},{"location":"detection/concept/regression/#_4","title":"\u539f\u59cb\u7b56\u7565","text":"<p>\u2003\u2003\u5728\u7b97\u6cd5Faster R-CNN\u3001RetinaNet\u4e2d\u4f7f\u7528\u7684\u56de\u5f52\u7b56\u7565\uff0c\u5047\u8bbex_a,y_a,w_a,h_a\u4e3a\u951a\u70b9\u7edd\u5bf9\u5750\u6807\uff0cx,y,w,h\u4e3a\u7269\u4f53\u8fb9\u754c\u6846\u5750\u6807\uff0ct_x,t_y,t_w,t_h\u4e3a\u5404\u4e2a\u5750\u6807\u6570\u636e\u7684\u56de\u5f52\u53c2\u6570\uff1a</p> <ul> <li>\u8fb9\u754c\u6846\u7f16\u7801\uff1a\u8fb9\u754c\u6846\u5750\u6807-&gt;\u56de\u5f52\u53c2\u6570</li> </ul>  t_x=\\frac{x-x_a}{w_a},t_y=\\frac{y-y_a}{h_a},t_w=\\log{\\frac{w}{w_a}},t_h=\\log{\\frac{h}{h_a}}  <ul> <li>\u56de\u5f52\u53c2\u6570\u89e3\u7801\uff1a\u56de\u5f52\u53c2\u6570-&gt;\u8fb9\u754c\u6846\u5750\u6807</li> </ul>  x=w_a*t_x+x_a,y=t_y*h_a+y_a,w=w_a*e^{t_w},h=h_a*e^{t_h}  <p>\u8865\uff1a\u53c2\u6570\u7f16\u7801\u4e0e\u89e3\u7801\u2014\u2014\u6e90\u7801\u7b14\u8bb0</p>"},{"location":"detection/concept/regression/#yolov2","title":"YOLOv2\u505a\u7684\u6539\u8fdb","text":"<p>\u2003\u2003\u4f5c\u8005\u5728\u8bba\u6587YOLOv2\u4e2d\u6307\u51fa\u539f\u59cb\u7684\u8fb9\u754c\u6846\u56de\u5f52\u7b56\u7565\u7531\u4e8e\u6ca1\u6709\u9650\u5236\u504f\u79fb\u91cf\u7684\u53d6\u503c\u8303\u56f4\uff0c\u5bb9\u6613\u5bfc\u81f4\u4e2d\u5fc3\u70b9x,y\u53ef\u80fd\u4f1a\u9884\u6d4b\u5728\u56fe\u50cf\u7684\u4efb\u4f55\u4e00\u70b9\u4e0a\uff0c\u76f8\u5bf9\u4e8e\u5f53\u524d\u9884\u6d4b\u70b9\u4f1a\u4ea7\u751f\u8f83\u5927\u7684\u504f\u79fb\uff0c\u8fdb\u4e00\u6b65\u5bfc\u81f4\u8bad\u7ec3\u65f6\u7684\u4e0d\u7a33\u5b9a\u3002\u5bf9\u6b64\uff0c\u4f5c\u8005\u505a\u4e86\u6539\u8fdb\uff0c\u5c06\u6bcf\u4e2a\u9884\u6d4b\u7279\u5f81\u70b9\u89c6\u4e3a\u4e00\u4e2a\u7f51\u683c\uff0c\u5c06\u951a\u70b9\u4e2d\u5fc3\u7684\u504f\u79fb\u91cf\u6539\u4e3a\u7f51\u683c\u5de6\u4e0a\u89d2\u5750\u6807\u7684\u504f\u79fb\u91cf\uff0c\u5373\u7f51\u683c\u5de6\u4e0a\u89d2\u89c6\u4e3a\u951a\u70b9\u6846\u7684\u4e2d\u5fc3\uff0c\u5177\u4f53\u8ba1\u7b97\u516c\u5f0f\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a</p> <ul> <li>\u56de\u5f52\u53c2\u6570\u89e3\u7801</li> </ul>  x=\\sigma(t_x)+c_x,y=\\sigma(t_y)+c_y,w=p_w*e^{t_w},h=p_h*e^{t_h}  <p>\u5176\u4e2dc_x,c_y\u8868\u793a\u7f51\u683c\u5de6\u4e0a\u89d2\u7684\u5750\u6807\uff0cp_w,p_h\u8868\u793a\u951a\u70b9\u7684\u5bbd\u9ad8\uff0c\\sigma(\\cdot)\u8868\u793a\\text{Sigmoid}\u5f52\u4e00\u5316\u51fd\u6570\uff0c\u53ef\u4ee5\u5c06\u504f\u79fb\u91cf\u9650\u5236\u5728(0,1)\u8303\u56f4\u5185\uff0c\u6539\u8fdb\u4e4b\u540e\u9884\u6d4b\u6846\u7684\u4e2d\u5fc3\u70b9\u88ab\u9650\u5236\u5728\u951a\u70b9\u4e2d\u5fc3\u70b9\u6240\u5728\u7684\u7f51\u683c\u5355\u5143\u5185\uff0c\u6709\u5229\u4e8e\u6a21\u578b\u7684\u6536\u655b\u3002\u7531\u4e8eYOLO\u7cfb\u5217\u7684\u7b97\u6cd5\u5e76\u6ca1\u6709\u76f4\u63a5\u5229\u7528\u56de\u5f52\u53c2\u6570\u505a\u635f\u5931\uff0c\u800c\u662f\u5229\u7528\u8fb9\u754c\u6846\u91cd\u5408\u5ea6\u8ba1\u7b97\u635f\u5931\uff0c\u56e0\u6b64\u4e0d\u9700\u8981\u5c06\u8fb9\u754c\u6846\u505a\u7f16\u7801\u64cd\u4f5c\u3002\uff08\u5177\u4f53\u53ef\u89c1\u300aYOLOv3-SPP\u300b\uff09</p> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u6307\u6b63</p> <p>\u4fee\u6539\u4e8e\uff1a2023\u5e742\u670816\u65e5</p>"},{"location":"detection/module/FL/","title":"\u7126\u70b9\u635f\u5931\u2014\u2014Focal Loss","text":""},{"location":"detection/module/FL/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aIEEE International Conference on Computer Vision 2017 (ICCV, 2017)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content_ICCV_2017/papers/Lin_Focal_Loss_for_ICCV_2017_paper.pdf</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u76ee\u6807\u68c0\u6d4b</p>"},{"location":"detection/module/FL/#_2","title":"\u4e3b\u8981\u601d\u60f3","text":"<p>\u2003\u2003\u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\uff0c\u5927\u90e8\u5206\u60c5\u51b5\u4e0b\u524d\u666f\u533a\u57df\u53ea\u5360\u4e00\u5c0f\u90e8\u5206\uff0c\u56e0\u6b64\u5bf9\u5e94\u4e8e\u524d\u666f\u7684\u951a\u70b9\u6570\u91cf\u5f80\u5f80\u5c0f\u4e8e\u5bf9\u5e94\u4e8e\u80cc\u666f\u7684\u951a\u70b9\u6570\u91cf\uff0c\u524d\u666f\u80cc\u666f\u5b58\u5728\u4e25\u91cd\u7684\u5206\u7c7b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u76f4\u63a5\u5c06\u6240\u6709\u951a\u70b9\u90fd\u7528\u4e8e\u8bad\u7ec3\u7684\u8bdd\uff0c\u5206\u7c7b\u5668\u7684\u8bad\u7ec3\u8fc7\u7a0b\u5f88\u5bb9\u6613\u88ab\u80cc\u666f\u6240\u4e3b\u5bfc\uff0c\u4ece\u800c\u5f71\u54cd\u5bf9\u524d\u666f\u7684\u68c0\u6d4b\u5206\u7c7b\u3002\u56e0\u6b64\u5728\u4e8c\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\u5668\u4e2d\uff0c\u7b2c\u4e00\u9636\u6bb5\u5f80\u5f80\u662f\u63d0\u8bae\u9636\u6bb5\uff08proposal\u9636\u6bb5\uff09\uff0c\u4f8b\u5982Faster R-CNN\u4e2d\u7684RPN\u6a21\u5757\uff0c\u9996\u5148\u9884\u6d4b\u51fa\u53ef\u80fd\u662f\u524d\u666f\u7684\u533a\u57df\uff08\u4f8b\u5982\u7b5b\u9009\u51fa\u524d2000\u4e2a\u6837\u672c\uff09\uff0c\u8fdb\u4e00\u6b65\u4f20\u5165\u7b2c\u4e8c\u9636\u6bb5\u6267\u884c\u5206\u7c7b\uff0c\u4ece\u800c\u907f\u514d\u5927\u91cf\u7684\u80cc\u666f\u533a\u57df\u5f71\u54cd\u5206\u7c7b\u5668\u7684\u8bad\u7ec3\u3002</p> <p>\u2003\u2003\u800c\u5728\u5355\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\u4e2d\uff0c\u68c0\u6d4b\u5668\u5fc5\u987b\u8981\u540c\u65f6\u9762\u5bf9\u6240\u6709\u7684\u9884\u8bbe\u951a\u70b9\uff08\u6ca1\u6709proposal\u6a21\u5757\u9884\u5148\u6311\u9009\u951a\u70b9\u8fd9\u4e00\u8fc7\u7a0b\uff09\uff0c\u9762\u5bf9\u8fd9\u4e00\u95ee\u9898\u5e38\u7528\u7684\u89e3\u51b3\u65b9\u6cd5\u5c31\u662f\u6309\u4e00\u5b9a\u7684\u6b63\u8d1f\u6837\u672c\u6bd4\u4f8b\u7b5b\u9009\u53c2\u4e0e\u4f18\u5316\u7684\u951a\u70b9\u6837\u672c\u6216\u8005\u7b5b\u9009\u51fa\u635f\u5931\u5927\u7684\u6837\u672c\u53c2\u4e0e\u7f51\u7edc\u7684\u4f18\u5316\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u90fd\u6ca1\u6709\u5728\u6839\u6e90\u4e0a\u89e3\u51b3\u95ee\u9898\u3002</p> <p>\u2003\u2003\u5bf9\u4e8e\u80cc\u666f\u533a\u57df\uff0c\u6709\u4e00\u4e2a\u5f88\u660e\u663e\u7684\u7279\u70b9\u5c31\u662f\u5bb9\u6613\u5206\u7c7b\uff0c\u9762\u5bf9\u80cc\u666f\u4e0a\u7684\u951a\u70b9\uff0c\u5206\u7c7b\u5668\u5f88\u5bb9\u6613\u505a\u51fa\u6b63\u786e\u7684\u51b3\u7b56\uff0c\u56e0\u6b64\u4f1a\u5bf9\u5e94\u4e00\u4e2a\u5c0f\u635f\u5931\uff1b\u800c\u9762\u5bf9\u524d\u666f\u533a\u57df\u4e0a\u7684\u951a\u70b9\uff0c\u5206\u7c7b\u5668\u5f80\u5f80\u4e0d\u5bb9\u6613\u505a\u51fa\u5206\u7c7b\u51b3\u7b56\uff0c\u56e0\u6b64\u5f80\u5f80\u4f1a\u5bf9\u5e94\u4e00\u4e2a\u6bd4\u8f83\u5927\u7684\u635f\u5931\u3002\u7406\u60f3\u60c5\u51b5\u4e0b\uff0c\u80cc\u666f\u533a\u57df\u635f\u5931\u5c0f\uff0c\u5bf9\u7f51\u7edc\u5f71\u54cd\u5c0f\uff0c\u524d\u666f\u533a\u57df\u635f\u5931\u5927\uff0c\u5bf9\u7f51\u7edc\u5f71\u54cd\u5927\uff0c\u7f51\u7edc\u4f1a\u671d\u7740\u4fbf\u4e8e\u524d\u666f\u5206\u7c7b\u7684\u65b9\u5411\u53d1\u5c55\u3002\u4f46\u5b9e\u9645\u5e76\u975e\u5982\u6b64\uff0c\u80cc\u666f\u951a\u70b9\u6570\u91cf\u8981\u8fdc\u5927\u4e8e\u524d\u666f\u951a\u70b9\u6570\u91cf\uff0c\u4f18\u5316\u80cc\u666f\u7684\u6b21\u6570\u8981\u8fdc\u8fdc\u8d85\u8fc7\u4f18\u5316\u524d\u666f\u7684\u6b21\u6570\uff0c\u5e76\u4e14\u80cc\u666f\u533a\u57df\u4e0d\u53ef\u80fd\u505a\u51fa\u5b8c\u7f8e\u7684\u9884\u6d4b\uff0c\u56e0\u6b64\u6bcf\u4e2a\u80cc\u666f\u951a\u70b9\u5fc5\u7136\u4f1a\u4ea7\u751f\u4e00\u4e2a\u4e0d\u53ef\u5ffd\u7565\u7684\u635f\u5931\u503c\uff08\u5982\u4e0b\u56fe\u84dd\u8272\u66f2\u7ebf\uff09\uff0c\u5927\u91cf\u7684\u80cc\u666f\u635f\u5931\u76f8\u52a0\u4e4b\u540e\uff0c\u6700\u7ec8\u7528\u4e8e\u4f18\u5316\u80cc\u666f\u7684\u635f\u5931\u8981\u8fdc\u5927\u4e8e\u4f18\u5316\u524d\u666f\u7684\u635f\u5931\uff0c\u4ece\u800c\u4e3b\u5bfc\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u4f7f\u7f51\u7edc\u671d\u7740\u4fbf\u4e8e\u80cc\u666f\u5206\u7c7b\u7684\u65b9\u5411\u53d1\u5c55\u3002</p> <p> <p></p> <p></p> <p>\u2003\u2003\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u6700\u597d\u7684\u65b9\u6cd5\u5c31\u662f\u5bf9\u80cc\u666f\u533a\u57df\u7684\u951a\u70b9\u635f\u5931\u52a0\u4e00\u4e2a\u6743\u91cd\uff0c\u6765\u964d\u4f4e\u80cc\u666f\u635f\u5931\uff08\u5982\u4e0a\u56fe\u975e\u84dd\u8272\u66f2\u7ebf\uff09\uff0c\u4ece\u800c\u6291\u5236\u80cc\u666f\u7684\u5f71\u54cd\u3002\u73b0\u5728\u5173\u952e\u5c31\u5728\u4e8e\u5982\u4f55\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u8bc6\u522b\u8be5\u951a\u70b9\u662f\u4f4d\u4e8e\u80cc\u666f\u8fd8\u662f\u524d\u666f\u4e0a\uff0c\u524d\u9762\u63d0\u5230\u80cc\u666f\u533a\u57df\u5bb9\u6613\u505a\u51fa\u9884\u6d4b\uff0c\u524d\u666f\u533a\u57df\u4e0d\u5bb9\u6613\u505a\u51fa\u9884\u6d4b\uff0c\u56e0\u6b64\u53ef\u4ee5\u5c06\u95ee\u9898\u8f6c\u5316\u4e00\u4e0b\uff1a\u9700\u8981\u8bbe\u8ba1\u4e00\u4e2a\u6743\u91cd\u8ba1\u7b97\u65b9\u6cd5\uff0c\u9762\u5bf9\u5bb9\u6613\u9884\u6d4b\u7684\u7ed3\u679c\uff0c\u9700\u8981\u5f97\u5230\u4e00\u4e2a\u5c0f\u6743\u91cd\uff0c\u9762\u5bf9\u4e0d\u5bb9\u6613\u9884\u6d4b\u7684\u7ed3\u679c\uff0c\u9700\u8981\u5f97\u5230\u4e00\u4e2a\u5927\u6743\u91cd\uff0c\u4f7f\u5f97\u7f51\u7edc\u8bad\u7ec3\u4f18\u5316\u7684\u91cd\u70b9\u96c6\u4e2d\u5230\u4e0d\u5bb9\u6613\u9884\u6d4b\u7684\u951a\u70b9\u4e0a\u9762\uff0c\u8fd9\u5c31\u662f\u7126\u70b9\u635f\u5931\uff08Focal Loss\uff09\u7684\u6838\u5fc3\u601d\u60f3\u3002</p>"},{"location":"detection/module/FL/#_3","title":"\u65b9\u6cd5","text":"<p>\u2003\u2003\u4ece\u4e8c\u5143\u4ea4\u53c9\u71b5\u5165\u624b\uff0c\u4f20\u7edf\u7684\u4e8c\u5143\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ CE(p,y)=-y_i\\log{(p)}-(1-y_i)\\log{(1-p)} $$  \u5176\u4e2dy_i\\in\\{0,1\\}\u8868\u793a\u6807\u7b7e\uff0cp\u8868\u793a\u9884\u6d4b\u6982\u7387\u3002\u60f3\u8981\u5f97\u5230\u8be5\u951a\u70b9\u6837\u672c\u662f\u5426\u5bb9\u6613\u9884\u6d4b\uff0c\u6700\u76f4\u63a5\u5730\u65b9\u5f0f\u5c31\u662f\u5206\u6790p\uff0c\u9884\u6d4b\u503cp\u548c\u771f\u5b9e\u503c\u5dee\u8ddd\u8d8a\u5c0f\uff0c\u5219\u8868\u660e\u8be5\u6837\u672c\u8d8a\u5bb9\u6613\u9884\u6d4b\uff0c\u56e0\u6b64\u4e3a\u4e86\u65b9\u4fbf\u8d77\u89c1\uff0c\u5047\u8bbep_t\u4e3a\uff1a $$ p_t=\\left\\{  \\begin{matrix} p,&amp;if\\quad y=1 \\\\ 1-p,&amp;otherwise\\end{matrix}  \\right. $$  \u5219\u4ea4\u53c9\u71b5\u635f\u5931\u53ef\u4ee5\u8868\u793a\u4e3aCE(p,y)=-\\log{(p_t)}\u3002\u5176\u4e2dp_t\u8d8a\u5927\uff08\u5728\u5c0f\u4e8e1\u7684\u60c5\u51b5\u4e0b\uff09\uff0c\u5bf9\u5e94\u53d6\\log\u8fd0\u7b97\u4e4b\u540e\u7ed3\u679c\u8d8a\u5c0f\uff0c\u8be5\u635f\u5931\u5bf9\u7f51\u7edc\u5f71\u54cd\u8d8a\u5c0f\uff0c\u8868\u660e\u9884\u6d4b\u7ed3\u679c\u548c\u771f\u5b9e\u7ed3\u679c\u5dee\u8ddd\u8d8a\u5c0f\uff0c\u6837\u672c\u8d8a\u5bb9\u6613\u9884\u6d4b\uff0c\u56e0\u6b64\u6211\u4eec\u53ef\u4ee5\u501f\u52a9p_t\u7684\u5927\u5c0f\u6765\u8868\u793a\u6837\u672c\u9884\u6d4b\u7684\u96be\u6613\u7a0b\u5ea6\u3002</p> <p> p_t\u8d8a\u5927\u8981\u6c42\u6743\u91cd\u8d8a\u5c0f\uff0cp_t\u8d8a\u5c0f\u8981\u6c42\u6743\u91cd\u8d8a\u5927\uff0c\u56e0\u6b64\u6743\u91cd\u4e0ep_t\u4e4b\u524d\u662f\u8d1f\u76f8\u5173\u7684\u5173\u7cfb\uff0c\u672c\u6587\u4f5c\u8005\u8bbe\u6743\u91cd\u8ba1\u7b97\u65b9\u6cd5\u4e3a(1-p_t)^\\gamma\uff0c\u5219\u4fee\u6539\u540e\u7684\u635f\u5931\u65b9\u7a0b\u4e3a\uff1a $$ \\text{FL}(p_t)=-(1-p_t)^\\gamma\\log{(p_t)} $$  \u5176\u4e2d\\gamma\u4e3a\u805a\u7126\u53c2\u6570\uff0c\u7528\u4e8e\u8c03\u6574\u6743\u91cd\u51cf\u5c0f\u7684\u901f\u5ea6\uff0c\u53c2\u6570\\gamma\u8d8a\u5927\uff0c\u5219\u6743\u91cd\u51cf\u5c0f\u5730\u8d8a\u5feb\uff08\u5177\u4f53\u53ef\u89c1\u524d\u9762\u7684\u66f2\u7ebf\u56fe\uff09\u3002</p> <p>\u2003\u2003\u540c\u65f6\u4f5c\u8005\u8fd8\u9488\u5bf9\u6b63\u8d1f\u6837\u672c\u7c7b\u522b\u4e0d\u5e73\u8861\u5f15\u5165\u52a0\u6743\u56e0\u5b50\\alpha_t\uff1a $$ \\alpha_t=\\left\\{  \\begin{matrix} \\alpha,&amp;if\\quad y=1 \\\\ 1-\\alpha,&amp;otherwise\\end{matrix}  \\right. $$  \u5176\u4e2d\\alpha\u4e3a\u8d85\u53c2\u6570\uff0c\u6700\u7ec8\u7684\u635f\u5931\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ \\text{FL}(p_t)=-\\alpha_t(1-p_t)^\\gamma\\log{(p_t)} $$  \u5176\u4e2d\\gamma\u53d62\uff0c\\alpha\u53d60.25\uff0c\u8fd9\u91cc\u7684\\alpha\u5f88\u50cf\u4e8c\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\u4e2d\uff0c\u5728\u8bad\u7ec3\u7b2c\u4e8c\u9636\u6bb5\u7684\u5206\u7c7b\u5668\u65f6\uff0c\u6240\u8bbe\u7f6e\u7684\u6b63\u8d1f\u6837\u672c\u91c7\u6837\u6bd4\u4f8b\u3002</p> <p>\u6ce8\u610f\uff1a</p> <ul> <li>\u6574\u4e2a\u635f\u5931\u53d7\u4e24\u4e2a\u6743\u91cd\u53c2\u6570\u5f71\u54cd\uff0c\u5176\u4e2d(1-p_t)^\\gamma\u6839\u636e\u6837\u672c\u5206\u7c7b\u7684\u96be\u6613\u7a0b\u5ea6\u505a\u53d8\u5316\uff0c\u7528\u4e8e\u63d0\u5347\u96be\u5206\u7c7b\u6837\u672c\u7684\u635f\u5931\u6743\u91cd\uff0c\\alpha_t\u9488\u5bf9\u6b63\u8d1f\u6837\u672c\u7684\u5dee\u5f02\u800c\u53d8\u5316\uff0c\u7528\u4e8e\u89e3\u51b3\u6b63\u8d1f\u7c7b\u4e0d\u5e73\u8861\u95ee\u9898\uff1b</li> <li>(1-p_t)^\\gamma\u5f62\u5f0f\u4e0d\u552f\u4e00\uff0c\u53ea\u8981\u662f\u548cp_t\u8d1f\u76f8\u5173\u5373\u53ef\u3002</li> </ul> <p>\u2003\u2003\u6362\u4e2a\u89d2\u5ea6\u6765\u770b\uff0c\u5176\u5b9e\u8fd9\u79cd\u635f\u5931\u5e76\u4e0d\u4ec5\u4ec5\u53ea\u9488\u5bf9\u524d\u80cc\u666f\u7684\u5904\u7406\uff0c\u5047\u8bbe\u73b0\u6709A\u3001B\u4e24\u7c7b\uff0c\u5982\u679cA\u7c7b\u6bd4\u8f83\u597d\u8bc6\u522b\uff0cB\u7c7b\u4e0d\u597d\u8bc6\u522b\uff0c\u90a3\u4e48\u5229\u7528\u8be5\u635f\u5931\uff0c\u5f88\u5bb9\u6613\u5c06\u7f51\u7edc\u4f18\u5316\u7684\u4fa7\u91cd\u70b9\u653e\u5230B\u7c7b\u4e0a\uff0c\u6291\u5236\u80cc\u666f\u548cA\u7c7b\u7684\u5f71\u54cd\uff0c\u4f7f\u5f97\u7f51\u7edc\u7684\u4f18\u5316\u671d\u7740\u80fd\u591f\u6b63\u786e\u5224\u65adB\u7c7b\u522b\u7684\u65b9\u5411\u53d1\u5c55\uff0c\u8fdb\u4e00\u6b65\u5b9e\u73b0\u80fd\u591f\u540c\u65f6\u5bf9\u80cc\u666f\u3001A\u3001B\u505a\u51fa\u6b63\u786e\u5206\u7c7b\u7684\u76ee\u6807\uff0c\u4ece\u89e3\u51b3\u524d\u80cc\u666f\u4e0d\u5e73\u8861\u51fa\u53d1\uff0c\u8fdb\u4e00\u6b65\u89e3\u51b3\u5206\u7c7b\u96be\u6613\u7a0b\u5ea6\u4e0d\u5747\u8861\u7684\u95ee\u9898\u3002\u95ee\u9898\u6839\u6e90\u8fd8\u662f\u5728\u4e8e\u5206\u7c7b\u96be\u6613\u7a0b\u5ea6\u4e0d\u5747\u8861\uff0c\u524d\u666f\u80cc\u666f\u4e0d\u5e73\u8861\u53ea\u662f\u4e00\u79cd\u8868\u8c61\u3002\u6700\u91cd\u8981\u7684\u8fd8\u662f\u5728\u201c\u52a8\u6001\u201d\u4e24\u4e2a\u5b57\uff0c\u52a8\u6001\u8c03\u6574\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u7528\u4e00\u4e2a\u8fde\u7eed\u53d8\u5316\u7684\u6743\u91cd\u6765\u5f71\u54cd\u635f\u5931\u7684\u4f5c\u7528\u7ed3\u679c\uff0c\u5206\u7c7b\u7ed3\u679cp\u6b63\u597d\u53ef\u4ee5\u5145\u5f53\u8fd9\u4e00\u8fc7\u7a0b\u7684\u4e2d\u4ecb\uff0c\u5efa\u7acb\u8d77\u6a21\u578b\u7684\u5206\u7c7b\u51b3\u7b56\u4e0e\u4f18\u5316\u51b3\u7b56\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u7528\u4e00\u4e2a\u8fde\u7eed\u7684\u6570\u503c\u6765\u642d\u5efa\u201c\u6865\u6881\u201d\u3002</p> <p>\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u6307\u6b63</p>"},{"location":"detection/module/FL/#_4","title":"\u4ee3\u7801\u5b9e\u73b0","text":"<p>\u53c2\u8003\u94fe\u63a5\uff1a</p> <ul> <li>https://github.com/WZMIAOMIAO/deep-learning-for-image-processing</li> <li>https://github.com/pytorch/vision/tree/master/torchvision/models/detection</li> </ul> <p>\u8f93\u5165\uff1a\u7f51\u7edc\u9884\u6d4b\u7ed3\u679c\u548c\u6807\u7b7e\u503c\uff0c\u6ce8\u610f\u8fd9\u91cc\u6807\u7b7e\u503c\u5e94\u4e3a\u72ec\u70ed\u7f16\u7801\u7684\u5f62\u5f0f\uff0c\u56e0\u6b64\u9884\u6d4b\u503c\u548c\u6807\u7b7e\u5177\u6709\u4e00\u6837\u7684\u6570\u7ec4\u5c3a\u5bf8\u3002</p> <p>\u8f93\u51fa\uff1a\u7126\u70b9\u635f\u5931\u503c</p> <p>\u6ce8\u610f\uff1a</p> <ul> <li>\u4e3a\u4e86\u4fbf\u4e8e\u5c06\u7126\u70b9\u635f\u5931\u63a8\u5e7f\u5230\u591a\u5206\u7c7b\uff0c\u8fd9\u91cc\u5728\u8ba1\u7b97\u5206\u7c7b\u635f\u5931\u65f6\uff0c\u91c7\u7528\u591a\u5206\u7c7b\u7f51\u7edc\u7684\u4f18\u5316\u7b56\u7565\u3002\u5047\u8bbe\u4e00\u5171\u6709n\u7c7b\uff08\u8ba1\u7b97\u65f6\u4e0d\u5305\u542b\u80cc\u666f\uff09\uff0c\u5728\u8ba1\u7b97\u4ea4\u53c9\u71b5\u635f\u5931\u65f6\u9762\u5bf9\u540c\u4e00\u951a\u70b9\u6837\u672c\uff0c\u8ba1\u7b97n\u6b21\u4e8c\u5143\u4ea4\u53c9\u71b5\u7ed3\u679c\uff08\u4e8c\u5206\u7c7b\u635f\u5931\u7684\u5f62\u5f0f\u4fbf\u4e8e\u548c\u7126\u70b9\u635f\u5931\u7ed3\u5408\uff09\uff0c\u4e4b\u540e\u5229\u7528n\u4e2a\u635f\u5931\u5171\u540c\u4f18\u5316\u7f51\u7edc\uff1b</li> </ul> <pre><code>def sigmoid_focal_loss(\n    inputs: torch.Tensor,\n    targets: torch.Tensor,\n    alpha: float = 0.25,\n    gamma: float = 2,\n    reduction: str = \"none\",\n):\n    \"\"\"\n    Original implementation from https://github.com/facebookresearch/fvcore/blob/master/fvcore/nn/focal_loss.py .\n    Loss used in RetinaNet for dense detection: https://arxiv.org/abs/1708.02002.\n\n    Args:\n        inputs: A float tensor of arbitrary shape.\n                The predictions for each example.\n        targets: A float tensor with the same shape as inputs. Stores the binary\n                classification label for each element in inputs\n                (0 for the negative class and 1 for the positive class).\n        alpha: (optional) Weighting factor in range (0,1) to balance\n                positive vs negative examples or -1 for ignore. Default = 0.25\n        gamma: Exponent of the modulating factor (1 - p_t) to\n               balance easy vs hard examples.\n        reduction: 'none' | 'mean' | 'sum'\n                 'none': No reduction will be applied to the output.\n                 'mean': The output will be averaged.\n                 'sum': The output will be summed.\n    Returns:\n        Loss tensor with the reduction option applied.\n    \"\"\"\n    # p\u8868\u793a\u6bcf\u4e2a\u951a\u70b9\u7684\u9884\u6d4b\u6982\u7387\uff0c\u5c3a\u5bf8\u4e3a(\u951a\u70b9\u6570\u91cf\uff0c\u7c7b\u522b\u6570)\uff0c\u7b2c\u4e8c\u7ef4\u5ea6\u4e0d\u52a0\u80cc\u666f\n    p = torch.sigmoid(inputs)\n    # \u5148\u5229\u7528\u9884\u6d4b\u7ed3\u679c\u4e0e\u6807\u7b7e\u6c42\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u6ce8\u610f\uff0c\u8fd9\u91cctargets\u662f\u5c06\u6807\u7b7e\u6570\u636e\u505a\u72ec\u70ed\u7f16\u7801\u540e\u7684\u6570\u636e\uff0c\u5c3a\u5bf8\u548cinputs\u5c3a\u5bf8\u4e00\u6837\n    # reduction\u8bbe\u7f6e\u4e3a\"none\"\uff0c\u4e0d\u5bf9\u7ed3\u679c\u505a\u4efb\u4f55\u5904\u7406\uff08\u5982\uff1a\u6c42\u5747\u503c\uff09\uff0c\u56e0\u4e3a\u4e4b\u540e\u8fd8\u8981\u4e58\u4ee5\u6743\u91cd\uff08FL\u6838\u5fc3\u601d\u60f3\uff09\n    # \u8fd9\u91ccinputs\u4f20\u5165\u539f\u59cb\u9884\u6d4b\u503c\uff0cF.binary_cross_entropy_with_logits\u65b9\u6cd5\u4f1a\u81ea\u52a8\u5bf9\u5176\u52a0\u5165sigmoid\u8fd0\u7b97\n    ce_loss = F.binary_cross_entropy_with_logits(\n        inputs, targets, reduction=\"none\"\n    )\n    # \u8ba1\u7b97\u5f97\u5230pt\uff0c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f2\u3002\u6ce8\u610f\u8fd9\u91cc\u5904\u7406\u5f97\u5f88\u5999\uff0c\u5c06\u591a\u4e2a\u5206\u6bb5\u51fd\u6570\u5f0f\u5b50\u5316\u4e3a\u4e00\u4e2a\u51fd\u6570\u5f0f\u5b50\n    # \u6ce8\u610f\u8fd9\u91ccp\u8981\u5148\u5c06\u7f51\u7edc\u7684\u8f93\u51fa\u4f20\u5165sigmoid\n    p_t = p * targets + (1 - p) * (1 - targets)\n    # \u4e58\u4ee5\u6743\u91cd\u56e0\u5b50(1-pt)^gamma\uff0c\u6291\u5236\u6613\u5206\u7c7b\u7684\u635f\u5931\uff0c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f4\n    loss = ce_loss * ((1 - p_t) ** gamma)\n    # \u8fd9\u91ccalpha\u5bf9\u5e94\u8bba\u6587\u03b1\u7cfb\u6570\uff0c\u7528\u4e8e\u5e73\u8861\u6b63\u8d1f\u6837\u672c\uff0c\u9ed8\u8ba40.25\n    if alpha &gt;= 0:\n        # \u548cpt\u5904\u7406\u4e00\u6837\uff0c\u5206\u6bb5\u51fd\u6570\u8f6c\u5316\u4e3a\u5355\u4e00\u51fd\u6570\u5f0f\u5b50\uff0c\u6b63\u6837\u672c\u5bf9\u5e94\u03b1\uff0c\u8d1f\u6837\u672c\u5bf9\u5e941-\u03b1\n        alpha_t = alpha * targets + (1 - alpha) * (1 - targets)\n        # \u5bf9\u5e94\u8bba\u6587\u516c\u5f0f5\n        loss = alpha_t * loss\n\n    # \u5747\u503c\u6216\u6c42\u548c\n    if reduction == \"mean\":\n        loss = loss.mean()\n    elif reduction == \"sum\":\n        loss = loss.sum()\n\n    return loss\n</code></pre> <p>\u521d\u6b65\u5b8c\u7a3f\u4e8e2023\u5e741\u670814\u65e5</p>"},{"location":"detection/module/FPN/","title":"\u7279\u5f81\u91d1\u5b57\u5854\u2014\u2014Feature Pyramid Networks","text":""},{"location":"detection/module/FPN/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aIEEE Conference on Computer Vision and Pattern Recognition 2017 (CVPR, 2017)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content_ICCV_2017/papers/Lin_Focal_Loss_for_ICCV_2017_paper.pdf</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u76ee\u6807\u68c0\u6d4b</p>"},{"location":"detection/module/FPN/#_2","title":"\u4e3b\u8981\u601d\u60f3","text":"<p>\u2003\u2003\u6df1\u5c42\u7279\u5f81\u5177\u6709\u5206\u8fa8\u7387\u4f4e\uff0c\u7279\u5f81\u6c34\u5e73\u9ad8\uff08high-level\uff09\u7684\u7279\u70b9\uff0c\u5373\u7279\u5f81\u56fe\u5c3a\u5bf8\u5c0f\uff0c\u6bcf\u4e2a\u7279\u5f81\u6570\u636e\u5305\u542b\u4e30\u5bcc\u7684\u8bed\u4e49\u4fe1\u606f\u3001\u5177\u6709\u8f83\u5927\u7684\u611f\u53d7\u91ce\u3001\u5e76\u4e14\u5bf9\u5e94\u539f\u56fe\u8f83\u5927\u7684\u533a\u57df\uff1b\u6d45\u5c42\u7279\u5f81\u5177\u6709\u5206\u8fa8\u7387\u9ad8\uff0c\u7279\u5f81\u6c34\u5e73\u4f4e\uff08low-level\uff09\u7684\u7279\u70b9\uff0c\u5373\u7279\u5f81\u56fe\u5c3a\u5bf8\u5927\uff0c\u6bcf\u4e2a\u7279\u5f81\u6570\u636e\u5305\u542b\u5c11\u91cf\u7684\u8bed\u4e49\u4fe1\u606f\u3001\u5177\u6709\u8f83\u5c0f\u7684\u611f\u53d7\u91ce\u3001\u5e76\u4e14\u5bf9\u5e94\u539f\u56fe\u8f83\u5c0f\u7684\u533a\u57df\u3002\u76ee\u6807\u68c0\u6d4b\u7f51\u7edc\u5728\u68c0\u6d4b\u76ee\u6807\u65f6\u662f\u57fa\u4e8e\u7279\u5f81\u56fe\u4e0a\u6bcf\u4e2a\u7279\u5f81\u6570\u636e\u6765\u68c0\u6d4b\u7684\uff0c\u6df1\u5c42\u7684\u7279\u5f81\u6570\u636e\u7531\u4e8e\u611f\u53d7\u91ce\u8f83\u5927\uff0c\u56e0\u6b64\u9002\u7528\u4e8e\u68c0\u6d4b\u5927\u7269\u4f53\uff0c\u4f46\u540c\u65f6\u7531\u4e8e\u611f\u53d7\u91ce\u5927\uff0c\u5bf9\u5e94\u539f\u56fe\u8f83\u5927\u7684\u533a\u57df\uff0c\u9762\u5bf9\u4e00\u4e2a\u5c0f\u7269\u4f53\uff0c\u5bb9\u6613\u88ab\u540c\u4e00\u533a\u57df\u5185\u5176\u4ed6\u7684\u7269\u4f53\u6240\u5e72\u6270\uff0c\u56e0\u6b64\u4e0d\u9002\u7528\u4e8e\u68c0\u6d4b\u5c0f\u7269\u4f53\uff1b\u6d45\u5c42\u7279\u5f81\u867d\u7136\u611f\u53d7\u91ce\u5c0f\uff0c\u5bf9\u5e94\u539f\u56fe\u5c0f\u533a\u57df\uff0c\u53ef\u4ee5\u5bf9\u5e94\u5c0f\u7269\u4f53\uff0c\u4f46\u662f\u6d45\u5c42\u7279\u5f81\u6240\u5bb9\u7eb3\u7684\u8bed\u4e49\u4fe1\u606f\u5c11\uff0c\u96be\u4ee5\u63cf\u8ff0\u539f\u59cb\u56fe\u50cf\u7684\u7269\u4f53\u7279\u5f81\uff0c\u76f4\u63a5\u5229\u7528\u6d45\u5c42\u7279\u5f81\u505a\u9884\u6d4b\u7684\u8bdd\uff0c\u96be\u4ee5\u68c0\u6d4b\u7269\u4f53\u3002\u4f20\u7edf\u7684\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u5927\u591a\u629b\u5f03\u4e86\u6d45\u5c42\u7279\u5f81\uff0c\u53ea\u5229\u7528\u6700\u540e\u4e00\u5c42\u7279\u5f81\uff08\u5373\u6700\u6df1\u7684\u7279\u5f81\uff09\u505a\u9884\u6d4b\uff0c\u56e0\u6b64\u5f80\u5f80\u96be\u4ee5\u9884\u6d4b\u5c0f\u7269\u4f53\uff0c\u7f51\u7edc\u9c81\u68d2\u6027\u8f83\u4f4e\u3002</p> <p>\u2003\u2003\u4e3a\u4e86\u540c\u65f6\u68c0\u6d4b\u7f51\u7edc\u4e2d\u7684\u5927\u7269\u4f53\u548c\u5c0f\u7269\u4f53\uff0cSSD\u7b97\u6cd5\u540c\u65f6\u5229\u7528\u4e0d\u540c\u5c42\u7684\u7279\u5f81\u505a\u9884\u6d4b\uff0c\u5982\u4e0b\u56fe\uff08c\uff09\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u540c\u65f6\u63d0\u53d6VGG\u7f51\u7edc\u540e\u51e0\u4e2a\u9636\u6bb5\u7684\u7279\u5f81\u56fe\u53c2\u4e0e\u9884\u6d4b\uff0c\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u7f13\u89e3\u4e86\u591a\u5c3a\u5ea6\u7269\u4f53\u68c0\u6d4b\u6240\u5e26\u6765\u7684\u95ee\u9898\uff0c\u4f46\u662f\u4e0d\u540c\u7279\u5f81\u5c42\u4e4b\u95f4\u76f8\u4e92\u72ec\u7acb\uff0c\u8f83\u6d45\u7684\u7279\u5f81\u8fd8\u662f\u5177\u6709\u8bed\u4e49\u4fe1\u606f\u5c11\u7684\u7f3a\u70b9\uff0c\u76f8\u5bf9\u4e8e\u6df1\u5c42\u7279\u5f81\uff0c\u8fd8\u662f\u96be\u4ee5\u63cf\u8ff0\u7269\u4f53\uff0c\u6ca1\u6709\u4ece\u6839\u6e90\u4e0a\u89e3\u51b3\u95ee\u9898\u3002</p> <p>\u2003\u2003\u60f3\u8981\u63d0\u9ad8\u6d45\u5c42\u7279\u5f81\u7684\u8bed\u4e49\u4fe1\u606f\u91cf\uff0c\u6700\u7b80\u5355\u7684\u65b9\u6cd5\u5c31\u662f\u505a\u7279\u5f81\u878d\u5408\uff0c\u878d\u5408\u6df1\u5c42\u7279\u5f81\u4e0e\u6d45\u5c42\u7279\u5f81\uff08\u5982\u4e0a\u56fed\uff09\uff0c\u4f7f\u5f97\u9ad8\u5206\u8fa8\u7387\u7684\u6d45\u5c42\u7279\u5f81\u4e5f\u6709\u9ad8\u6c34\u5e73\u8bed\u4e49\u4fe1\u606f\u7684\u7279\u70b9\uff0c\u4ece\u800c\u4f7f\u5176\u66f4\u597d\u5730\u53c2\u4e0e\u7269\u4f53\u9884\u6d4b\uff0c\u8fd9\u5c31\u662fFPN\u7b97\u6cd5\u7684\u6838\u5fc3\u6240\u5728\u3002\uff08\u5bf9\u5e94\u8bba\u6587\uff1acreating a feature pyramid that has strong semantics at all scales.\uff09</p>"},{"location":"detection/module/FPN/#_3","title":"\u65b9\u6cd5","text":"<p>\u7f51\u7edc\u7ed3\u6784\u56fe\u5982\u4e0b\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u6ce8\uff1a\u56fe\u7247\u539f\u521b\uff0c\u4f7f\u7528\u8bf7\u544a\u77e5</p> <p>\u2003\u2003\u9996\u5148\u5c06\u539f\u56fe\u4f20\u5165\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u4e2d\uff0c\u8fd9\u91cc\u4ee5ResNet\u4e3a\u4f8b\uff0c\u5c06layer1\u5c42\u5230layer4\u5c42\u4e4b\u540e\u7684\u7279\u5f81\u4f9d\u6b21\u547d\u540d\u4e3a\\{C_2\u3001C_3\u3001C_4\u3001C_5\\}\uff0c\u603b\u5171\u5f97\u5230\u56db\u7ec4\u7279\u5f81\u3002\u6700\u7b80\u5355\u7684\u7279\u5f81\u878d\u5408\u65b9\u6cd5\u5c31\u662f\u505a\u52a0\u6cd5\u8fd0\u7b97\uff0c\u5982\uff1aU-Net\uff0c\u4f46\u8fd9\u91cc\u4e0d\u540c\u5c42\u4e4b\u95f4\u7279\u5f81\u56fe\u901a\u9053\u6570\u4ee5\u53ca\u7279\u5f81\u56fe\u5bbd\u9ad8\u5c3a\u5bf8\u5747\u4e0d\u540c\uff0c\u56e0\u6b64\u4e0d\u80fd\u76f4\u63a5\u878d\u5408\uff0c\u9700\u8981\u505a\u989d\u5916\u7684\u5904\u7406\u3002</p> <p>\u2003\u2003\u5c06\u56db\u7ec4\u7279\u5f81\u5206\u522b\u4f20\u5165\u5377\u79ef\u6838\u5c3a\u5bf8\u4e3a1\\times1\u7684\u5377\u79ef\u5c42\u4e2d\u538b\u7f29\u901a\u9053\uff0c\u901a\u9053\u7ef4\u6570\u538b\u7f29\u6210256\uff0c\u7edf\u4e00\u901a\u9053\u6570\u4fbf\u4e8e\u540e\u7eed\u7684\u878d\u5408\u3002\u9996\u5148\u4eceC_5\u5f00\u59cb\uff0c\u5148\u5bf9\u8f83\u6df1\u7684\u7279\u5f81\u505a\u4e0a\u91c7\u6837\u8fd0\u7b97\uff08\u8fd9\u91cc\u76f4\u63a5\u5229\u7528\u201dnearest\u201d\u63d2\u503c\u8fd0\u7b97\u5373\u53ef\uff0c\u5177\u4f53\u89c1\u6e90\u7801\uff09\uff0c\u5bbd\u9ad8\u53d8\u4e3a\u539f\u6765\u7684\u4e24\u500d\uff0c\u4e4b\u540e\u518d\u4e0e\u901a\u9053\u538b\u7f29\u540e\u7684\u8f83\u6d45\u7279\u5f81\u505a\u52a0\u6cd5\u8fd0\u7b97\uff0c\u6700\u540e\u5c06\u7ed3\u679c\u4f20\u5165\u5377\u79ef\u6838\u5c3a\u5bf8\u4e3a3\\times3\u7684\u5377\u79ef\u5c42\uff0c\u505a\u7279\u5f81\u878d\u5408\uff0c\u5f97\u5230\u6700\u7ec8\u7528\u4e8e\u9884\u6d4b\u7684\u7279\u5f81\u3002\u7ecf\u8fc7\u4e0a\u8ff0\u7279\u5f81\u878d\u5408\u6b65\u9aa4\u4f1a\u5f97\u5230\\{P_2\u3001P_3\u3001P_4\\}\uff0c\u4e4b\u540e\u518d\u5bf9\u9876\u5c42\u7279\u5f81\uff08\u5373\u6700\u6df1\u5c42\u7279\u5f81\uff09C_5\u5355\u72ec\u5904\u7406\uff0c\u76f4\u63a5\u5c06\u5176\u4f20\u5165\u5377\u79ef\u6838\u5c3a\u5bf8\u4e3a3\\times3\u7684\u5377\u79ef\u5c42\uff0c\u5f97\u5230\u9884\u6d4b\u7279\u5f81P_5\u3002\u5bf9\u4e8e\u611f\u53d7\u91ce\u66f4\u5927\u7684P_6\uff0c\u6709\u591a\u79cd\u8ba1\u7b97\u65b9\u6cd5\uff0c\u8fd9\u91cc\u76f4\u63a5\u5c06P_5\u505a\u4e0b\u91c7\u6837\u5904\u7406\u3002</p> <p>\u6ce8\uff1a</p> <ul> <li>\u7279\u5f81\u56fe\u5206\u8fa8\u7387\u8d8a\u9ad8\uff0c\u951a\u70b9\u8d8a\u591a\uff0c\u951a\u70b9\u5728\u539f\u56fe\u4e0a\u7684\u5206\u5e03\u8d8a\u5bc6\uff0c\u5bf9\u5e94\u8ba1\u7b97\u91cf\u5c31\u4f1a\u8d8a\u5927\uff0c\u56e0\u6b64\u5229\u7528\u6d45\u5c42\u7279\u5f81\u505a\u9884\u6d4b\u4f1a\u5e26\u6765\u8ba1\u7b97\u91cf\u8f83\u5927\u7684\u95ee\u9898\uff0c\u5982\u679c\u60f3\u8981\u51cf\u8f7b\u8ba1\u7b97\u91cf\uff0c\u5219\u53ef\u4ee5\u820d\u53bb\u4e00\u90e8\u5206\u7279\u5f81\u5c42\uff0c\u5982\u672c\u6587\u4f5c\u8005\u820d\u53bb\u4e86\u7279\u5f81\u56feC_1\uff0cRetinaNet\u820d\u53bb\u4e86\u7279\u5f81\u56feC_2\uff1b\uff08FPN\u7f51\u7edc\u7ed3\u6784\u53ea\u662f\u63d0\u5347\u4e86\u6d45\u5c42\u7279\u5f81\u7684\u8bed\u4e49\u4fe1\u606f\uff0c\u6d45\u5c42\u7279\u5f81\u7684\u7279\u5f81\u6570\u636e\u5f88\u591a\uff0c\u56e0\u6b64\u53c2\u4e0e\u9884\u6d4b\u65f6\u4f1a\u4e0d\u53ef\u907f\u514d\u5730\u5f15\u5165\u8fc7\u91cf\u7684\u8ba1\u7b97\uff0c\u4e24\u4e2a\u95ee\u9898\u4e0d\u8981\u5f04\u6df7\uff09</li> <li>\u4f5c\u8005\u5728Faster R-CNN\u4e0a\u505a\u7684\u5b9e\u9a8c\uff0c\u5728RPN\u4e2d\uff0c\u6bcf\u4e2a\u9884\u6d4b\u7279\u5f81\u53ea\u8bbe\u7f6e\u4e00\u4e2a\u951a\u70b9\u5c3a\u5ea6\uff0c\\{P_2\u3001P_3\u3001P_4\u3001P_5\u3001P_6\\}\u5206\u522b\u5bf9\u5e94\\{32^2\u300164^2\u3001128^2\u3001256^2\\}\uff0c\u6bcf\u4e2a\u951a\u70b9\u5c3a\u5ea6\u5bf9\u5e94\u4e09\u7ec4\u6bd4\u4f8b\\{1:2\u30011:1\u30012:1\\}\uff0c\u5176\u4e2dP_6\u53ea\u53c2\u4e0eRPN\u6a21\u5757\uff0c\u9884\u6d4b\u524d\u666f\u8fb9\u754c\uff0c\u4e0d\u53c2\u4e0e\u540e\u671f\u7684\u5206\u7c7b\u9884\u6d4b\uff1b</li> <li>\u76f8\u52a0\u540e\u7684\u7279\u5f81\u6709\u4e24\u4e2a\u65b9\u5411\uff0c\u4e00\u4e2a\u662f\u4f20\u5165\u5377\u79ef\u6838\u5c3a\u5bf8\u4e3a3\\times3\u7684\u5377\u79ef\u5c42\uff0c\u5f97\u5230\u5f53\u524d\u5c42\u7684\u9884\u6d4b\u7279\u5f81P_i\uff0c\u53e6\u4e00\u4e2a\u662f\u7ee7\u7eed\u4e0a\u91c7\u6837\uff0c\u53c2\u4e0e\u4e0b\u4e00\u6b21\u7684\u7279\u5f81\u878d\u5408\uff0c\u56e0\u6b64\u52a0\u6cd5\u7279\u5f81\uff08\u76f8\u52a0\u540e\u7684\u7279\u5f81\uff09\u662f\u7531\u4e0a\u5230\u4e0b\u4e00\u8109\u76f8\u4f20\u7684\uff0c\u6700\u5e95\u5c42\u4e5f\u4f1a\u53d7\u5230\u9876\u5c42\u7279\u5f81\u7684\u5f71\u54cd\uff0c\u5373\u6700\u6d45\u5c42\u7684\u7279\u5f81\u4e5f\u5177\u6709\u6700\u9ad8\u7684\u8bed\u4e49\u4fe1\u606f\uff1b</li> </ul> <p>\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u6307\u6b63\u3002</p>"},{"location":"detection/module/FPN/#_4","title":"\u4ee3\u7801\u5b9e\u73b0","text":"<p>\u53c2\u8003\u94fe\u63a5\uff1a</p> <ul> <li>https://github.com/WZMIAOMIAO/deep-learning-for-image-processing</li> <li>https://github.com/pytorch/vision/tree/master/torchvision/models/detection</li> </ul> <p>\u8f93\u5165\uff1a\u591a\u4e2a\u7279\u5f81\u5c42\u4e0a\u7684\u5377\u79ef\u7279\u5f81\uff1b\u8f93\u51fa\uff1a\u878d\u5408\u540e\u7684\u7279\u5f81\uff0c\u8f93\u51fa\u7684\u7279\u5f81\u901a\u9053\u6570\u4e00\u6837\uff0c\u9ed8\u8ba4256\u3002</p> <pre><code>class FeaturePyramidNetwork(nn.Module):\n    \"\"\"\n    Module that adds a FPN from on top of a set of feature maps. This is based on\n    `\"Feature Pyramid Network for Object Detection\" &lt;https://arxiv.org/abs/1612.03144&gt;`_.\n    The feature maps are currently supposed to be in increasing depth\n    order.\n    The input to the model is expected to be an OrderedDict[Tensor], containing\n    the feature maps on top of which the FPN will be added.\n    Arguments:\n        in_channels_list (list[int]): number of channels for each feature map that\n            is passed to the module\n        out_channels (int): number of channels of the FPN representation\n        extra_blocks (ExtraFPNBlock or None): if provided, extra operations will\n            be performed. It is expected to take the fpn features, the original\n            features and the names of the original features as input, and returns\n            a new list of feature maps and their corresponding names\n    \"\"\"\n\n    def __init__(self, in_channels_list, out_channels, extra_blocks=None):\n        super(FeaturePyramidNetwork, self).__init__()\n        # \u7528\u6765\u8c03\u6574resnet\u7279\u5f81\u77e9\u9635(layer1,2,3,4)\u7684channel\uff08kernel_size=1\uff09\n        # \u8fd9\u91cc\u8f93\u5165\u901a\u9053\u6570\u56e0\u7279\u5f81\u5c42\u800c\u5f02\uff0c\u8f93\u51fa\u901a\u9053\u6570\u4e00\u81f4\uff0c\u9ed8\u8ba4256\n        self.inner_blocks = nn.ModuleList()\n        # \u5bf9\u8c03\u6574\u540e\u7684\u7279\u5f81\u77e9\u9635\u4f7f\u75283x3\u7684\u5377\u79ef\u6838\u6765\u5f97\u5230\u5bf9\u5e94\u7684\u9884\u6d4b\u7279\u5f81\u77e9\u9635\n        self.layer_blocks = nn.ModuleList()\n        # \u904d\u5386\u6240\u6709\u7684\u7279\u5f81\u5c42\n        for in_channels in in_channels_list:\n            if in_channels == 0:\n                continue\n            # \u5b9a\u4e49\u5377\u79ef\u6838\u4e3a1\u7684\u5377\u79ef\uff0c\u7528\u4e8e\u538b\u7f29\u7279\u5f81\n            inner_block_module = nn.Conv2d(in_channels, out_channels, 1)\n            # \u5b9a\u4e49\u5377\u79ef\u6838\u4e3a3\u7684\u5377\u79ef\uff0c\u7528\u4e8e\u5f97\u5230\u9884\u6d4b\u7279\u5f81\u77e9\u9635\n            layer_block_module = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n            self.inner_blocks.append(inner_block_module)\n            self.layer_blocks.append(layer_block_module)\n\n        # initialize parameters now to avoid modifying the initialization of top_blocks\n        # \u521d\u59cb\u5316\u6a21\u578b\u53c2\u6570\n        for m in self.children():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_uniform_(m.weight, a=1)\n                nn.init.constant_(m.bias, 0)\n        # Faster R-CNN\u4e2d\u9ed8\u8ba4\u8bbe\u7f6e\u989d\u5916\u7684\u6c60\u5316\u6a21\u5757\uff0c\u5c06\u9876\u5c42\u7279\u5f81\u505a\u4e00\u6b65\u6c60\u5316\uff0c\u751f\u6210P6\n        self.extra_blocks = extra_blocks\n\n    def forward(self, x):\n        # type: (Dict[str, Tensor]) -&gt; Dict[str, Tensor]\n        \"\"\"\n        Computes the FPN for a set of feature maps.\n        Arguments:\n            x (OrderedDict[Tensor]): \u6bcf\u4e2a\u7279\u5f81\u5c42\u4e0a\u7684\u7279\u5f81\u56fe\n        Returns:\n            results (OrderedDict[Tensor]): feature maps after FPN layers.\n                They are ordered from highest resolution first.\n        \"\"\"\n        # unpack OrderedDict into two lists for easier handling\n        names = list(x.keys())\n        x = list(x.values())\n\n        # \u5c06resnet layer4\u7684channel\u8c03\u6574\u5230\u6307\u5b9a\u7684out_channels\n        # last_inner = self.inner_blocks[-1](x[-1])\n        # \u9996\u5148\u5c06\u9876\u5c42\u7279\u5f81\u4f20\u5165\u5377\u79ef\u6838\u4e3a1*1\u7684\u5377\u79ef\u4e2d\u538b\u7f29\u7279\u5f81\uff0c\u538b\u7f29\u540elast_inner\u5c3a\u5bf8\u4e3a(b,256,w,h)\n        last_inner = self.get_result_from_inner_blocks(x[-1], -1)\n        # result\u4e2d\u4fdd\u5b58\u7740\u6bcf\u4e2a\u9884\u6d4b\u7279\u5f81\u5c42\n        results = []\n        # \u5c06layer4\u8c03\u6574channel\u540e\u7684\u7279\u5f81\u77e9\u9635\uff0c\u901a\u8fc73x3\u5377\u79ef\u540e\u5f97\u5230\u5bf9\u5e94\u7684\u9884\u6d4b\u7279\u5f81\u77e9\u9635\n        results.append(self.get_result_from_layer_blocks(last_inner, -1))\n        # \u4f9d\u6b21\u4ece\u9876\u5c42\u5411\u4f4e\u5c42\u904d\u5386\uff0c\u8fd9\u91cc\u7684\u9876\u5c42\u6307\u6df1\u5c42\u7279\u5f81\uff0c\u4f4e\u5c42\u6307\u6d45\u5c42\u7279\u5f81\n        for idx in range(len(x) - 2, -1, -1):\n            # \u9996\u5148\u538b\u7f29\u6df1\u5c42\u7279\u5f81\u7684\u901a\u9053\u6570\uff0c\u538b\u7f29\u6210256*256\n            inner_lateral = self.get_result_from_inner_blocks(x[idx], idx)\n            # \u5f97\u5230\u6d45\u5c42\u7279\u5f81\u7684\u5c3a\u5bf8\uff0c\u4e4b\u540e\u5bf9\u6df1\u5c42\u7279\u5f81\u6267\u884c\u4e0a\u91c7\u6837\u64cd\u4f5c\n            feat_shape = inner_lateral.shape[-2:]\n            # \u5bf9\u5e94\u8bba\u6587\u201cnearest\u201d\u63d2\u503c\n            inner_top_down = F.interpolate(last_inner, size=feat_shape, mode=\"nearest\")\n            # \u6d45\u5c42\u7279\u5f81\u4e0e\u6df1\u5c42\u7279\u5f81\u505a\u52a0\u6cd5\u8fd0\u7b97\uff0c\u878d\u5408\u548c\u7279\u5f81\n            last_inner = inner_lateral + inner_top_down\n            # \u5c06\u878d\u5408\u540e\u7684\u7279\u5f81\u4f20\u51653*3\u7684\u5377\u79ef\u5c42\u4e2d\uff0c\u5f97\u5230\u6700\u540e\u7684\u9884\u6d4b\u7279\u5f81\n            results.insert(0, self.get_result_from_layer_blocks(last_inner, idx))\n\n        # \u5728layer4\u5bf9\u5e94\u7684\u9884\u6d4b\u7279\u5f81\u5c42\u57fa\u7840\u4e0a\u751f\u6210\u9884\u6d4b\u7279\u5f81\u77e9\u96355\uff0c\u5373\u5bf9\u9876\u5c42\u7279\u5f81\u505a\u6c60\u5316\u5904\u7406\uff0c\u751f\u6210\u8bba\u6587\u4e2d\u7684P6\n        if self.extra_blocks is not None:\n            results, names = self.extra_blocks(results, x, names)\n\n        # make it back an OrderedDict\n        out = OrderedDict([(k, v) for k, v in zip(names, results)])\n\n        return out\n</code></pre> <p>\u5176\u5b83\u51fd\u6570</p> <p>\u538b\u7f29\u901a\u9053\u6570</p> <pre><code>def get_result_from_inner_blocks(self, x, idx):\n    # type: (Tensor, int) -&gt; Tensor\n    \"\"\"\n    \u5c06\u9ad8\u5c42\u7684\u7279\u5f81\u4f20\u51651*1\u7684\u5377\u79ef\u4e2d\uff0c\u538b\u7f29\u901a\u9053\u6570\n    \"\"\"\n    num_blocks = len(self.inner_blocks)\n    if idx &lt; 0:\n        idx += num_blocks\n    i = 0\n    out = x\n    for module in self.inner_blocks:\n        if i == idx:\n            out = module(x)\n        i += 1\n    return out\n</code></pre> <p>\u5f97\u5230\u6700\u7ec8\u7684\u9884\u6d4b\u7279\u5f81</p> <pre><code>`def get_result_from_layer_blocks(self, x, idx):\n    # type: (Tensor, int) -&gt; Tensor\n    \"\"\"\n    \u5c06\u878d\u5408\u540e\u7684\u7279\u5f81\u4f20\u51653*3\u7684\u5377\u79ef\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u9884\u6d4b\u7279\u5f81\n    \"\"\"\n    num_blocks = len(self.layer_blocks)\n    if idx &lt; 0:\n        idx += num_blocks\n    i = 0\n    out = x\n    for module in self.layer_blocks:\n        if i == idx:\n            out = module(x)\n        i += 1\n    return out\n</code></pre> <p>\u521d\u6b65\u5b8c\u7a3f\u4e8e2023\u5e741\u670812\u65e5</p>"},{"location":"detection/module/NL/","title":"\u975e\u5c40\u90e8\u6ce8\u610f\u529b\u2014\u2014Non-local Neural Networks","text":""},{"location":"detection/module/NL/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aIEEE Conference on Computer Vision and Pattern Recognition 2018 (CVPR, 2018)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Non-Local_Neural_Networks_CVPR_2018_paper.pdf</p>"},{"location":"detection/module/NL/#_2","title":"\u7b80\u4ecb","text":"<p>\u2003\u2003\u4f20\u7edf\u7684\u5377\u79ef\u8fd0\u7b97\u548c\u5faa\u73af\u8fd0\u7b97\u90fd\u662f\u5904\u7406\u5c40\u90e8\u9886\u57df\u7684\u8fd0\u7b97\uff0c\u4ee5\u5377\u79ef\u8fd0\u7b97\u4e3a\u4f8b\uff0c\u7ecf\u8fc73\\times3\u5377\u79ef\u8fd0\u7b97\u5f97\u5230\u7684\u7279\u5f81\u56fe\u4e2d\uff0c\u6bcf\u4e2a\u7279\u5f81\u6570\u636e\u53ea\u4e0e\u8fd0\u7b97\u524d\u76849\u4e2a\u6570\u636e\u6709\u5173\uff0c\u5373\u611f\u53d7\u91ce\u4e3a3\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff0c9\u4e2a\u6df1\u84dd\u6570\u636e\u7ecf\u8fc7\u67d0\u79cd\u8fd0\u7b97\u5f97\u5230\u6570\u636eA\uff0cA\u53ef\u4ee5\u540c\u65f6\u53cd\u5e949\u4e2a\u76f8\u90bb\u7684\u7279\u5f81\u6570\u636e\uff1a</p> <p> <p></p> <p></p> <p>\u5377\u79ef\u8fd0\u7b97\u7684\u4e00\u5927\u4f18\u70b9\u5c31\u662f\u5c40\u90e8\u611f\u77e5\uff0c\u53ea\u5bf9\u5c40\u90e8\u533a\u57df\u505a\u7279\u5f81\u63d0\u53d6\uff0c\u964d\u4f4e\u4e86\u53c2\u6570\u91cf\uff0c\u4f46\u8fd9\u79cd\u7279\u5f81\u63d0\u53d6\u65b9\u5f0f\u4e0d\u5229\u4e8e\u6784\u5efa\u8fdc\u7a0b\u4f9d\u8d56\u5173\u7cfb\uff08long-range dependencies\uff09\uff0c\u6bd4\u5982\u5728\u4e0a\u56fe\u4e2d\uff0c\u5355\u6b21\u5377\u79ef\u53ea\u80fd\u5c06\u76f8\u90bb\u76849\u4e2a\u7279\u5f81\u6570\u636e\u52a0\u4ee5\u5173\u8054\uff0c\u4f46\u662f\u5982\u679c\u60f3\u8ba9\u4e0d\u76f8\u90bb\u7684\u6570\u636e\u505a\u5173\u8054\uff0c\u5982\u4e0a\u56fe\u4e2d\u7684B\u548cC\uff0c\u5219\u9700\u8981\u7ecf\u8fc7\u591a\u6b21\u5377\u79ef\u8fd0\u7b97\uff0c\u5373\u5806\u79ef\u591a\u4e2a\u5377\u79ef\u5c42\uff0c\u9010\u6b65\u6269\u5927\u611f\u53d7\u91ce\uff0c\u5f53\u611f\u53d7\u91ce\u589e\u5927\u5230\u4e00\u5b9a\u7a0b\u5ea6\u65f6\uff0cB\u548cC\u5c31\u53ef\u4ee5\u5173\u8054\u8d77\u6765\uff0c\u6b64\u65f6\u7f51\u7edc\u53ef\u4ee5\u6316\u6398B\u548cC\u4e4b\u95f4\u5171\u6709\u7684\u7279\u6027\uff0c\u5229\u7528\u8fd9\u79cd\u5171\u6027\u53ef\u4ee5\u8f85\u52a9\u7f51\u7edc\u505a\u5224\u65ad\u3002\u4f46\u5806\u53e0\u591a\u4e2a\u5377\u79ef\u5c42\u4f1a\u5e26\u6765\u53c2\u6570\u8fc7\u591a\uff0c\u8ba1\u7b97\u91cf\u8fc7\u5927\u7b49\u95ee\u9898\uff0c\u4e0d\u5229\u4e8e\u7f51\u7edc\u7684\u4f18\u5316\u3002</p> <p>\u2003\u2003\u76f4\u89c2\u5730\u6765\u8bb2\uff0c\u5355\u770b\u4e0b\u9762\u7b2c\u4e00\u5f20\u56fe\uff0c\u8db3\u7403\u7684\u4f4d\u7f6e\u4e0d\u4ec5\u4ec5\u7531\u8db3\u7403\u672c\u8eab\u6240\u53cd\u6620\uff0c\u4eba\u7684\u671d\u5411\uff0c\u773c\u775b\u6240\u6ce8\u89c6\u7684\u65b9\u5411\u540c\u6837\u4e5f\u53ef\u4ee5\u95f4\u63a5\u53cd\u6620\u8db3\u7403\u7684\u4f4d\u7f6e\uff0c\u56e0\u6b64\u8fd9\u4e9b\u7279\u5f81\u4e4b\u95f4\u5177\u6709\u67d0\u79cd\u8054\u7cfb\uff08\u5bf9\u5e94\u7a7a\u95f4\u8054\u7cfb\uff09\uff0c\u5355\u7eaf\u4f7f\u7528\u5377\u79ef\u8fd0\u7b97\u5f88\u96be\u8ba9\u7f51\u7edc\u6316\u6398\u8fd9\u79cd\u8054\u7cfb\u3002\u6269\u5c55\u5230\u89c6\u9891\u4e2d\uff0c\u4e0d\u540c\u5e27\u4e4b\u95f4\u540c\u6837\u4e5f\u6709\u4e00\u5b9a\u7684\u8054\u7cfb\uff08\u5bf9\u5e94\u65f6\u95f4\u8054\u7cfb\uff09\uff0c\u5e27\u4e4b\u95f4\u7684\u56fe\u50cf\u7279\u70b9\u4e5f\u53ef\u4ee5\u76f8\u4e92\u53cd\u6620\uff1a</p> <p> <p></p> <p></p> <p>\u60f3\u8981\u5efa\u7acb\u8fd9\u79cd\u8054\u7cfb\uff0c\u6838\u5fc3\u5c31\u662f\u5229\u7528\u67d0\u79cd\u8fd0\u7b97\u5c06\u6bcf\u4e2a\u7279\u5f81\u4e0e\u6240\u6709\u7279\u5f81\u6570\u636e\u90fd\u5173\u8054\u8d77\u6765\uff0c\u5bf9\u6b64\uff0c\u4f5c\u8005\u53c2\u8003\u975e\u5c40\u90e8\u5747\u503c\u64cd\u4f5c\uff08non-local mean operation\uff09\uff0c\u5b9a\u4e49\u4e86\u4e00\u79cd\u901a\u7528\u7684\u975e\u5c40\u90e8\u64cd\u4f5c\uff0c\u5229\u7528\u4e0d\u540c\u4f4d\u7f6e\u4e4b\u95f4\u7684\u8054\u7cfb\uff08relationship\uff09\u6765\u8ba1\u7b97\u54cd\u5e94\u503c\uff0c\u53ef\u4ee5\u7528\u5982\u4e0b\u516c\u5f0f\u8868\u793a\uff1a $$ y_i=\\frac1{\\mathcal C(x)}\\sum_{\\forall j}f(x_i,x_j)g(x_j) $$  \u5176\u4e2d\uff0ci\u8868\u793a\u5f53\u524d\u50cf\u7d20\u4f4d\u7f6e\uff0cj\u8868\u793a\u5176\u4ed6\u6240\u6709\u7684\u50cf\u7d20\u4f4d\u7f6e\uff0cx\u662f\u8f93\u5165\u7684\u7279\u5f81\u6570\u636e\uff0cf(\\cdot)\u8868\u793a\u8ba1\u7b97\u4f4d\u7f6ei\u548cj\u4e4b\u95f4\u5173\u7cfb\u7684\u51fd\u6570\uff0cg(\\cdot)\u8868\u793a\u8ba1\u7b97j\u5904\u8f93\u5165\u4fe1\u53f7\u7684\u8868\u793a\uff08representation\uff09\uff0c\\mathcal C(x)\u7528\u4e8e\u5f52\u4e00\u5316\uff0c\u5f62\u5f0f\u56e0f(\\cdot)\u800c\u5f02\uff0cy_i\u53ef\u4ee5\u8868\u793a\u5176\u4ed6\u6240\u6709\u4f4d\u7f6e\u4e0a\u7684\u7279\u5f81\u6570\u636e\u5bf9\u5f53\u524d\u4f4d\u7f6ei\u4e0a\u7279\u5f81\u6570\u636e\u7684\u54cd\u5e94\uff0c\u4e5f\u5c31\u662fy_i\u53ef\u4ee5\u8868\u793a\u5176\u4ed6\u4f4d\u7f6e\u4e0e\u5f53\u524d\u4f4d\u7f6e\u7684\u5173\u7cfb\u3002</p> <p>f(\\cdot)\u7684\u9009\u62e9\uff1a</p> <ul> <li>Gaussian\uff1af(x_i,x_j)=e^{x_i^Tx_j}\uff0c\\mathcal C(x)=\\sum_{\\forall j}f(x_i,x_j)\uff0cx_i^Tx_j\u8868\u793a\u70b9\u79ef\u8fd0\u7b97</li> <li>Embedded Gaussian\uff1af(x_i,x_j)=e^{\\theta(x_i)^T \\phi(x_j)}\uff0c\\mathcal C(x)=\\sum_{\\forall j}f(x_i,x_j)</li> </ul> <p>\u5176\u4e2d\\theta(x_i)=W_{\\theta}x_i\uff0c\\phi(x_j)=W_{\\phi}x_j\uff0c\u53ef\u4ee5\u5229\u75281\\times1\u7684\u5377\u79ef\u8fd0\u7b97\u5b9e\u73b0\uff0c\u524d\u4e24\u7c7b\u52a0\u4e00\u4e2ae\u7684\u6307\u6570\uff0c\u76f8\u5f53\u4e8e\u7ecf\u8fc7\u4e86\u4e00\u6b21softmax\u51fd\u6570\uff0c\u5373Embedded Gaussian\u53ef\u4ee5\u5199\u4e3ay=softmax(x^TW^T_\\theta W_\\phi x)</p> <ul> <li>Dot product\uff1af(x_i,x_j)=\\theta(x_i)^T \\phi(x_j)\uff0c\\mathcal C(x)=N</li> <li>Concatenation\uff1af(x_i,x_j)=ReLU(w^T_f[\\theta(x_i), \\phi(x_j)])\uff0c\\mathcal C(x)=N</li> </ul> <p>\u6ce8\u610f\uff1af(\\cdot)\u7684\u5f62\u5f0f\u4e0d\u91cd\u8981\uff0c\u91cd\u8981\u7684\u662f\u975e\u5c40\u90e8\u5173\u7cfb\u7684\u8ba1\u7b97\uff0c\u5373y_i\u7684\u8ba1\u7b97\u5f62\u5f0f\uff1b</p> <p>\u2003\u2003\u4e3a\u4e86\u5c06\u975e\u5c40\u90e8\u64cd\u4f5c\u5d4c\u5165\u5230\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u4e2d\uff0c\u4f5c\u8005\u8fdb\u4e00\u6b65\u5b9a\u4e49\u4e86\u975e\u5c40\u90e8\u5757\uff08non-local block\uff09\uff0c\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ z_i=W_zy_i+x_i $$  \u7531\u4e8e\u6b8b\u5dee\u8fde\u63a5+x_i\u7684\u5b58\u5728\uff0c\u4f7f\u5f97\u975e\u5c40\u90e8\u5757\u53ef\u4ee5\u5d4c\u5165\u5230\u4efb\u4f55\u9884\u8bad\u7ec3\u7f51\u7edc\u4e2d\uff0c\u4e0d\u9700\u8981\u6539\u53d8\u521d\u59cb\u53c2\u6570\uff08\u6b64\u65f6\u53ef\u4ee5\u5c06W_z\u521d\u59cb\u5316\u4e3a0\uff09\uff0c\u6a21\u5757\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u5176\u4e2d\uff0cW_g\u3001W_\\theta\u3001W_\\phi\u5c06\u6bcf\u4e2a\u4f4d\u7f6e\u4e0a\u7684\u7279\u5f81\u6570\u76ee\u538b\u7f29\u4e00\u534a\uff0c\u4e5f\u5c31\u662f\u5c06\u6574\u5f20\u7279\u5f81\u56fe\u7684\u901a\u9053\u6570\u538b\u7f29\u4e00\u534a\uff0c\u53ef\u4ee5\u5229\u75281\\times1\u7684\u5377\u79ef\u8fd0\u7b97\u5b9e\u73b0\uff0c\u540c\u7406\uff0cW_z\u5c06y_i\u7684\u901a\u9053\u6570\u518d\u6269\u5145\u56de\u6765\uff0c\u8fd9\u79cd\u74f6\u9888\u5f0f\u7684\u64cd\u4f5c\u53ef\u4ee5\u5c06\u8ba1\u7b97\u91cf\u51cf\u5c0f\u4e00\u534a\u3002</p> <p>\u2003\u2003\u540c\u65f6\uff0c\u8fd8\u53ef\u4ee5\u5229\u7528\u4e0b\u91c7\u6837\u64cd\u4f5c\u8fdb\u4e00\u6b65\u964d\u4f4e\u8ba1\u7b97\u91cf\uff0cy_i\u7684\u8ba1\u7b97\u65b9\u5f0f\u53ef\u4ee5\u6539\u4e3a\uff1a $$ y_i=\\frac1{\\mathcal C(\\hat x)}\\sum_{\\forall j}f(x_i,\\hat x_j)g(\\hat x_j) $$  \u5176\u4e2d\\hat x\u8868\u793ax\u7684\u4e0b\u91c7\u6837\u6570\u636e\uff0c\u5229\u7528\u91c7\u6837\u6570\u636e\u53bb\u8ba1\u7b97\u7279\u5f81\u4e4b\u95f4\u7684\u8054\u7cfb\u53ef\u4ee5\u964d\u4f4e1/4\u7684\u8ba1\u7b97\u91cf\uff0c\u53ef\u4ee5\u5728\\phi\u548cg\u4e4b\u540e\u6dfb\u52a0\u4e00\u4e2a\u6700\u5927\u6c60\u5316\u5c42\u6765\u5b9e\u73b0\u3002</p> <p>\u2003\u2003\u4f5c\u8005\u5728\u8bba\u6587\u4e2d\u4ee5ResNet\u7f51\u7edc\u4e3a\u57fa\u7840\u7f51\u7edc\u505a\u5b9e\u9a8c\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u975e\u5c40\u90e8\u6a21\u5757\u52a0\u5728res2\u3001res3\u3001res4\u9636\u6bb5\u8f83\u597d\uff0c\u6bcf\u4e2a\u9636\u6bb5\u52a0\u5728\u6700\u540e\u4e00\u4e2a\u6b8b\u5dee\u5757\u524d\u9762\uff0c\u5e76\u4e14\u4e4b\u524d\u63d0\u5230\u7684f(\\cdot)\u8ba1\u7b97\u65b9\u6cd5\u6548\u679c\u5747\u7c7b\u4f3c\uff08\u9664\u4e86Gaussian\u63d0\u5347\u4e0d\u5927\uff09\uff0c\u8bba\u6587\u540e\u534a\u90e8\u5206\u7684\u5b9e\u9a8c\u5747\u7528Embedded Gaussian\u6765\u8ba1\u7b97\u7279\u5f81\u8054\u7cfb\u3002</p> <p>\u8865\u5145\uff1a</p> <p>\u2003\u2003\u5728\u795e\u7ecf\u7f51\u7edc\u4e2d\uff0c\u5168\u8fde\u63a5\u5c42\u4e5f\u53ef\u4ee5\u5c06\u6240\u6709\u7279\u5f81\u6570\u636e\u52a0\u4ee5\u5173\u8054\uff08\u52a0\u6743\u6c42\u548c\uff09\uff0c\u4e0b\u4e00\u7ec4\u7279\u5f81\u4e2d\u6bcf\u4e2a\u7279\u5f81\u6570\u636e\u5747\u7531\u4e0a\u4e00\u7ec4\u6240\u6709\u7684\u7279\u5f81\u6570\u636e\u6784\u6210\uff0c\u4f46\u662f\u5168\u8fde\u63a5\u5c42\u4e2d\u7684\u52a0\u6743\u6c42\u548c\u64cd\u4f5c\u5ffd\u7565\u4e86\u7279\u5f81\u4f4d\u7f6e\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u8fd9\u4e5f\u662fNL\u8fd9\u7bc7\u6587\u7ae0\u4e00\u76f4\u5728\u5f3a\u8c03\u7684\u5185\u5bb9\uff0cNL\u66f4\u6ce8\u91cd\u50cf\u7d20\u70b9\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u8fd9\u91cc\u7684\u8054\u7cfb\u4ee5\u4e00\u79cd\u51fd\u6570\u5173\u7cfb\u5448\u73b0\u3002\u4e3e\u4f8b\u6765\u8bf4\uff0c\u5728\u7b2c\u4e00\u5f20\u56fe\u4e2d\uff0c\u7531\u4e8e\u975e\u5c40\u90e8\u6a21\u5757\u7684\u5f15\u5165\uff0c\u53ef\u4ee5\u8ba9\u7f51\u7edc\u77e5\u9053B\u70b9\u7684\u5b58\u5728\u5bf9C\u70b9\u7684\u5f71\u54cd\uff0c\u5728\u7b2c\u4e8c\u5f20\u56fe\u4e2d\uff0c\u4e5f\u53ef\u4ee5\u8ba9\u7f51\u7edc\u53d1\u73b0\u8eab\u4f53\u671d\u5411\u4e0e\u8db3\u7403\u4f4d\u7f6e\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u5229\u7528\u8eab\u4f53\u671d\u5411\u8f85\u52a9\u9884\u6d4b\u8db3\u7403\u7684\u4f4d\u7f6e\u3002\u5168\u8fde\u63a5\u5c42\u53ea\u662f\u7528\u4e8e\u50cf\u7d20\u4e4b\u95f4\u7b80\u5355\u7684\u6c42\u548c\u76f8\u52a0\uff0c\u4e0d\u80fd\u8ba9\u7f51\u7edc\u6316\u6398\u8fd9\u79cd\u9690\u542b\u8054\u7cfb\u3002\uff08\u5e76\u4e14\u5168\u8fde\u63a5\u5c42\u4f1a\u6253\u6df7\u7279\u5f81\u7684\u7a7a\u95f4\u5206\u5e03\uff0c\u56e0\u6b64\u4e0d\u80fd\u52a0\u5728\u5377\u79ef\u8fd0\u7b97\u4e2d\u95f4\u505a\u8f85\u52a9\u8fd0\u7b97\uff0c\u5168\u8fde\u63a5\u5c42\u5e38\u9002\u7528\u4e8e\u52a0\u5728\u6700\u540e\u505a\u5206\u7c7b\u3002\uff09</p>"},{"location":"detection/module/NL/#_3","title":"\u4ee3\u7801\u5b9e\u73b0","text":"<p>\u53c2\u8003\u4ee3\u7801\uff1a</p> <ul> <li>https://github.com/AlexHex7/Non-local_pytorch</li> </ul> <p>\u4ee5Embedded Gaussian\u4e3a\u4f8b\uff1a</p> <pre><code>class _NonLocalBlockND(nn.Module):\n    def __init__(self, in_channels, inter_channels=None, dimension=3, sub_sample=True, bn_layer=True):\n        \"\"\"\n        :param in_channels:\n        :param inter_channels:\n        :param dimension:\n        :param sub_sample:\n        :param bn_layer:\n        \"\"\"\n\n        super(_NonLocalBlockND, self).__init__()\n\n        assert dimension in [1, 2, 3]\n\n        self.dimension = dimension\n        self.sub_sample = sub_sample\n\n        self.in_channels = in_channels\n        self.inter_channels = inter_channels\n\n        # \u9ed8\u8ba4\u538b\u7f29\u4e00\u6b21\u901a\u9053\uff0c\u5c06\u539f\u59cb\u901a\u9053\u6570\u538b\u7f29\u4e00\u534a\n        if self.inter_channels is None:\n            self.inter_channels = in_channels // 2\n            if self.inter_channels == 0:\n                self.inter_channels = 1\n\n        # \u5224\u65ad\u7528\u54ea\u7c7b\u5377\u79ef\u8fd0\u7b97\uff0c\u5bf9\u5e94\u4e0d\u540c\u7684\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\n        if dimension == 3:\n            conv_nd = nn.Conv3d\n            max_pool_layer = nn.MaxPool3d(kernel_size=(1, 2, 2))\n            bn = nn.BatchNorm3d\n        elif dimension == 2:\n            conv_nd = nn.Conv2d\n            max_pool_layer = nn.MaxPool2d(kernel_size=(2, 2))\n            bn = nn.BatchNorm2d\n        else:\n            conv_nd = nn.Conv1d\n            max_pool_layer = nn.MaxPool1d(kernel_size=(2))\n            bn = nn.BatchNorm1d\n\n        # \u5b9a\u4e49g\u8fd0\u7b97\uff0c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f1\u4e2d\u7684g(xj)\n        self.g = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n                         kernel_size=1, stride=1, padding=0)\n\n        # \u5b9a\u4e49\u6700\u540e\u7684\u5377\u79ef\u5c42\uff0c\u7528\u4e8e\u8fd8\u539f\u901a\u9053\u6570\u91cf\n        if bn_layer:\n            self.W = nn.Sequential(\n                conv_nd(in_channels=self.inter_channels, out_channels=self.in_channels,\n                        kernel_size=1, stride=1, padding=0),\n                bn(self.in_channels)\n            )\n            nn.init.constant_(self.W[1].weight, 0)\n            nn.init.constant_(self.W[1].bias, 0)\n        else:\n            self.W = conv_nd(in_channels=self.inter_channels, out_channels=self.in_channels,\n                             kernel_size=1, stride=1, padding=0)\n            nn.init.constant_(self.W.weight, 0)\n            nn.init.constant_(self.W.bias, 0)\n\n        # \u5b9a\u4e49\u03b8\u8fd0\u7b97\n        self.theta = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n                             kernel_size=1, stride=1, padding=0)\n        # \u5b9a\u4e49\u03c6\u8fd0\u7b97\n        self.phi = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n                           kernel_size=1, stride=1, padding=0)\n        # \u662f\u5426\u4e0b\u91c7\u6837\uff0c\u5982\u679c\u6267\u884c\u4e0b\u91c7\u6837\u7684\u8bdd\uff0c\u53c2\u4e0eg\u8fd0\u7b97\u548c\u03c6\u8fd0\u7b97\u7684\u7279\u5f81\u56fe\u4e4b\u540e\u4f1a\u7ecf\u8fc7\u4e00\u6b21\u4e0b\u91c7\u6837\n        if sub_sample:\n            self.g = nn.Sequential(self.g, max_pool_layer)\n            self.phi = nn.Sequential(self.phi, max_pool_layer)\n\n    def forward(self, x):\n        \"\"\"\n        :param x: (b, c, t, h, w)\n        :param return_nl_map: if True return z, nl_map, else only return z.\n        :return:\n        \"\"\"\n\n        batch_size = x.size(0)\n        # \u7279\u5f81\u56fe\u7ecf\u8fc7g(\u00b7)\u8fd0\u7b97\uff0c\u5e76\u4e14\u505a\u4e00\u6b21\u8f6c\u7f6e\uff0c\u5c06\u7279\u5f81\u56fe\u5c3a\u5bf8\u8f6c\u4e3a(b, t\u00d7h\u00d7w, c//2)\uff0c\u4fbf\u4e8e\u540e\u7eed\u77e9\u9635\u76f8\u4e58\uff0c\u5f97\u5230g(xj)\n        g_x = self.g(x).view(batch_size, self.inter_channels, -1)\n        g_x = g_x.permute(0, 2, 1)\n        # \u7279\u5f81\u56fe\u7ecf\u8fc7\u03b8\u8fd0\u7b97\uff0c\u5e76\u4e14\u518d\u8f6c\u7f6e\uff0c\u5c3a\u5bf8\u540c\u6837\u4e3a(b, t\u00d7h\u00d7w, c//2)\uff0c\u5f97\u5230\u03b8(xi)\n        theta_x = self.theta(x).view(batch_size, self.inter_channels, -1)\n        theta_x = theta_x.permute(0, 2, 1)\n        # \u7279\u5f81\u56fe\u7ecf\u8fc7\u03c6\u8fd0\u7b97\uff0c\u5f97\u5230\u03c6(xj)\uff0c\u5c3a\u5bf8\u4e3a(b, c//2, t\u00d7h\u00d7w)\n        phi_x = self.phi(x).view(batch_size, self.inter_channels, -1)\n        # \u03b8(xi)\u4e0e\u03c6(xj)\u505a\u77e9\u9635\u76f8\u4e58\uff0c\u76f8\u5f53\u4e8e\u5143\u7d20\u76f8\u4e58\u5e76\u4e14\u6309j\u6c42\u548c\uff0c\u5f97\u5230\u7279\u5f81\u56fe\u5c3a\u5bf8\u4e3a(b, t\u00d7h\u00d7w, t\u00d7h\u00d7w)\n        f = torch.matmul(theta_x, phi_x)\n        # \u4f20\u5165softmax\u8fd0\u7b97(\u6cbf\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6)\n        f_div_C = F.softmax(f, dim=-1)\n\n        # \u5c06\u5f97\u5230\u7684\u7ed3\u679c\u518d\u548cg(xj)\u505a\u77e9\u9635\u76f8\u4e58\uff0c\u5f97\u5230\u7279\u5f81\u56fe\u5c3a\u5bf8\u4e3a(b, t\u00d7h\u00d7w, c//2)\n        y = torch.matmul(f_div_C, g_x)\n        # \u4e4b\u540e\u5c06\u7ed3\u679c\u7ecf\u8fc7\u8f6c\u7f6e\u3001\u8c03\u6574\u7ef4\u5ea6\uff0c\u8c03\u6574\u4e3a(b, c//2, t, h, w)\n        y = y.permute(0, 2, 1).contiguous()\n        y = y.view(batch_size, self.inter_channels, *x.size()[2:])\n        # \u4f20\u5165\u6700\u540e\u4e00\u5c42\u5377\u79ef\uff0c\u901a\u9053\u6570\u8fd8\u539f\u4e3ac\n        W_y = self.W(y)\n        # \u4e0e\u8f93\u5165x\u76f8\u52a0\uff0c\u5f97\u5230\u6700\u540e\u7684\u7ed3\u679c\n        z = W_y + x\n\n        return z\n</code></pre> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u6307\u6b63</p> <p>\u521d\u6b65\u5b8c\u7a3f\u4e8e2023\u5e741\u670827\u65e5</p>"},{"location":"detection/network/RetinaNet/","title":"\u76ee\u6807\u68c0\u6d4b\u2014\u2014RetinaNet","text":""},{"location":"detection/network/RetinaNet/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aIEEE International Conference on Computer Vision 2017 (ICCV, 2017)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content_ICCV_2017/papers/Lin_Focal_Loss_for_ICCV_2017_paper.pdf</p> <p>\u7c7b\u578b\uff1a\u5355\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\uff08one-stage\uff09</p>"},{"location":"detection/network/RetinaNet/#_2","title":"\u4ecb\u7ecd","text":""},{"location":"detection/network/RetinaNet/#_3","title":"\u7f51\u7edc\u7ed3\u6784\u56fe","text":"<p> <p></p> <p></p> <p>\u5176\u4e2d\uff0cBackbone\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u6d41\u7a0b\u56fe\u539f\u521b\uff0c\u4f7f\u7528\u8bf7\u544a\u77e5</p>"},{"location":"detection/network/RetinaNet/#_4","title":"\u7ec6\u8282","text":"<p>\u7f51\u7edc\u7ed3\u6784</p> <ul> <li>P_3\u5230P_7\u951a\u70b9\u7684\u539f\u59cb\u5c3a\u5ea6(scale)\u4f9d\u6b21\u4e3a\uff1a\\{32\u300164\u3001128\u3001256\u3001512\\}\uff0c\u5e76\u4e14\u5728\u539f\u5c3a\u5ea6\u57fa\u7840\u4e0a\uff0c\u518d\u6dfb\u52a0\u500d\u6570\u4e3a2^{\\frac13}\u30012^{\\frac23}\u7684\u4e24\u4e2a\u5c3a\u5ea6\uff0c\u56e0\u6b64\uff0c\u6bcf\u7ec4\u9884\u6d4b\u7279\u5f81\u4f1a\u5bf9\u5e94\u4e09\u79cd\u5c3a\u5ea6\uff0c\u53ef\u4ee5\u8868\u793a\u4e3a((32, 40, 50), (64, 80, 101), (128, 161, 203), (256, 322, 406), (512, 645, 812))\uff0c\u6bcf\u4e2a\u5c3a\u5ea6\u5747\u5206\u914d3\u79cd\u6bd4\u4f8b(ratio)\uff1a\\{1:2\u30011:1\u30012:1\\}\uff0c\u56e0\u6b64\u7efc\u4e0a\u6240\u8ff0\uff0c\u6bcf\u7ec4\u9884\u6d4b\u7279\u5f81\u4f1a\u5bf9\u5e949\u7ec4\u951a\u70b9\uff08\u4e00\u4e2a\u7279\u5f81\u70b9\u5bf9\u5e949\u4e2a\u951a\u70b9\uff09\uff1b</li> <li>Backbone\u91c7\u7528FPN\u7684\u7f51\u7edc\u7ed3\u6784\uff0c\u6240\u6709\u9884\u6d4b\u7279\u5f81\u7684\u901a\u9053\u6570\u4e3a256\uff1b</li> <li>\u5728\u9884\u6d4b\u56de\u5f52\u53c2\u6570\u65f6\uff0c\u6267\u884c\u7c7b\u522b\u4e0d\u53ef\u77e5\u7684\u9884\u6d4b\uff0c\u5373\u6bcf\u4e2a\u951a\u70b9\u53ea\u8f93\u51fa1\u7ec4\u56de\u5f52\u53c2\u6570\uff08\u5bf9\u6bd4Faster R-CNN\u4e2d\uff0c\u6bcf\u4e2a\u951a\u70b9\u8f93\u51faK\u7ec4\u56de\u5f52\u53c2\u6570\uff0cK\u4e3a\u7c7b\u522b\u6570\u91cf\uff09\uff1b</li> <li>\u5728\u9884\u6d4b\u5b50\u7f51\u7edc\u4e2d\uff0c\u7279\u5f81\u4f1a\u7ecf\u8fc74\u6b21\u5377\u79ef\u548cReLU\u8fd0\u7b97\u63d0\u53d6\u7279\u5f81\uff0c\u4e4b\u540e\u5229\u7528\u5377\u79ef\u6838\u5c3a\u5bf8\u4e3a3\\times3\u7684\u5377\u79ef\u5c42\u6765\u9884\u6d4b\u7c7b\u522b\u548c\u56de\u5f52\u53c2\u6570\uff08\u5bf9\u6bd4Faster R-CNN\u4e2d\uff0c\u4f7f\u7528\u5377\u79ef\u6838\u4e3a1\\times1\u7684\u5377\u79ef\u8fd0\u7b97\u9884\u6d4b\uff09\uff1b</li> <li>\u5728\u9884\u6d4b\u7269\u4f53\u7c7b\u522b\u65f6\uff0c\u4e0d\u5355\u72ec\u9884\u6d4b\u80cc\u666f\u6982\u7387\uff0c\u5373\u6bcf\u4e2a\u951a\u70b9\u8f93\u51faK\u4e2a\u6570\u503c\uff08\u5bf9\u6bd4Faster R-CNN\u8f93\u51faK+1\u4e2a\u6570\u503c\uff09\u3002</li> </ul> <p>\u8bad\u7ec3\u9636\u6bb5</p> <ul> <li>\u5728\u951a\u70b9\u5339\u914d\u4e2d\uff0c\u4e0e\u7269\u4f53\u8fb9\u754c\u6846IOU\u503c\u5927\u4e8e\u7b49\u4e8e0.5\u7684\u951a\u70b9\u8bbe\u7f6e\u4e3a\u524d\u666f\u951a\u70b9\u3001IOU\u503c\u5c0f\u4e8e0.4\u7684\u8bbe\u7f6e\u4e3a\u80cc\u666f\u951a\u70b9\u3001\u820d\u5f03\u4ecb\u4e8e0.4\u52300.5\uff08[0.4,0.5)\uff09\u4e4b\u95f4\u7684\u951a\u70b9\uff1b</li> <li>\u7531\u4e8e\u5206\u7c7b\u635f\u5931\u91c7\u7528\u7126\u70b9\u635f\u5931\uff0c\u56e0\u6b64\u9ed8\u8ba4\u91c7\u7528\u6240\u6709\u951a\u70b9\u53c2\u4e0e\u8bad\u7ec3\uff1b</li> <li>\u8bad\u7ec3\u5206\u7c7b\u5668\u65f6\uff0c\u5229\u7528\u7126\u70b9\u635f\u5931\u8bad\u7ec3\uff0c\u7126\u70b9\u635f\u5931\u57fa\u4e8e\u4e8c\u5143\u4ea4\u53c9\u71b5\u635f\u5931\u800c\u6765\uff0c\u56e0\u6b64\u5bf9\u6bcf\u4e2a\u951a\u70b9\uff0c\u8ba1\u7b97K\u6b21\u7126\u70b9\u635f\u5931\uff08\u6bcf\u4e2a\u7c7b\u522b\u4e00\u6b21\uff09\uff1b</li> <li>\u8bad\u7ec3\u56de\u5f52\u5668\u65f6\uff0c\u5229\u7528l_1\u635f\u5931\u8bad\u7ec3\u3002</li> </ul> <p>\u6d4b\u8bd5\u9636\u6bb5</p> <ul> <li>\u6d4b\u8bd5\u6b65\u9aa4\uff1a\u79fb\u9664\u9884\u6d4b\u6982\u7387\u4f4e\u7684\u951a\u70b9\u2192\u6309\u6982\u7387\u9009\u53d6\u524dN_1\u4e2a\u9884\u6d4b\u8fb9\u754c\u2192\u6267\u884cNMS\u8fd0\u7b97\u2192\u6309\u6982\u7387\u9009\u53d6\u524dN_2\u4e2a\u9884\u6d4b\u8fb9\u754c\u4f5c\u4e3a\u6700\u7ec8\u7684\u7f51\u7edc\u9884\u6d4b\u7ed3\u679c\uff1b</li> <li>\u9ed8\u8ba4\u503c\uff1a\u4f4e\u6982\u73870.05\uff0cN_1\u4e3a1000\uff0cNMS\u9608\u503c0.5\uff0cN_2\u4e3a100\uff1b</li> <li>\u5bf9\u4e8e\u6bcf\u4e2a\u951a\u70b9\uff0c\u5982\u679c\u6709\u591a\u4e2a\u9884\u6d4b\u6982\u7387\u8f83\u5927\uff0c\u5219\u53d6\u9884\u6d4b\u6982\u7387\u4e2d\u6700\u5927\u503c\u7684\u5e8f\u53f7\u4f5c\u4e3a\u5f53\u524d\u951a\u70b9\u7684\u9884\u6d4b\u7c7b\u522b\uff0c\u4e0d\u4f1a\u51fa\u73b0\u5355\u951a\u70b9\u591a\u7c7b\u522b\u7684\u60c5\u51b5\uff08\u5229\u7528NMS\u8fc7\u6ee4\uff0c\u91cd\u5408\u7684\u8fb9\u754c\u6846\u4f1a\u88ab\u8fc7\u6ee4\u6389\uff09\uff1b</li> <li>\u5728\u8ba1\u7b97NMS\u65f6\uff0c\u4f1a\u5148\u5bf9\u6bcf\u4e2a\u8fb9\u754c\u6846\u52a0\u4e00\u4e2a\u7c7b\u522b\u504f\u79fb\u91cf\uff0c\u4fdd\u8bc1\u4e0d\u540c\u7c7b\u522b\u4e4b\u95f4\u4e0d\u4f1a\u91cd\u5408\u3002</li> </ul>"},{"location":"detection/network/RetinaNet/#_5","title":"\u4ee3\u7801\u5b9e\u73b0","text":"<p>\u4ee3\u7801\u53c2\u8003\uff1a</p> <ul> <li>https://github.com/WZMIAOMIAO/deep-learning-for-image-processing</li> <li>https://github.com/pytorch/vision/tree/master/torchvision/models/detection</li> </ul>"},{"location":"detection/network/RetinaNet/#_6","title":"\u7f51\u7edc\u7ed3\u6784","text":"<p>\u53c2\u6570\u610f\u4e49\uff1a</p> <ul> <li><code>backbone</code>\uff1a\u4e3b\u5e72\u7279\u5f81\u63d0\u53d6\u7f51\u7edc</li> <li><code>num_classes</code>\uff1a\u7269\u4f53\u7c7b\u522b\u6570\u91cf</li> <li><code>min_size</code>\u3001<code>max_size</code>\uff1a\u56fe\u50cf\u6700\u5927\u8fb9\u957f\u4e0e\u6700\u5c0f\u8fb9\u957f</li> <li><code>image_mean</code>\u3001<code>image_std</code>\uff1a\u9884\u5904\u7406\u65f6\uff0c\u6807\u51c6\u5316\u7528\u5230\u7684\u5747\u503c\u65b9\u5dee</li> <li><code>anchor_generator</code>\uff1a\u4e3a\u951a\u70b9\u751f\u6210\u5668\uff0c\u7528\u4e8e\u5728\u7279\u5f81\u56fe\u4e0a\u751f\u6210\u951a\u70b9\u56fe</li> <li><code>head</code>\uff1a\u9884\u6d4b\u5206\u652f\uff0c\u7528\u4e8e\u9884\u6d4b\u951a\u70b9\u7c7b\u522b\u548c\u8fb9\u754c\u6846\u56de\u5f52\u53c2\u6570</li> <li><code>proposal_matcher</code>\uff1a\u7528\u4e8e\u5bf9\u951a\u70b9\u505a\u5212\u5206\uff0c\u6839\u636e\u951a\u70b9\u4e0e\u8fb9\u754c\u6846\u7684IOU\u503c\u5212\u5206\u8be5\u951a\u70b9\u662f\u6b63\u6837\u672c\u8fd8\u662f\u8d1f\u6837\u672c</li> <li><code>score_thresh</code>\uff1a\u6d4b\u8bd5\u65f6\u7528\u5230\u7684\u9608\u503c\uff0c\u5c0f\u4e8e\u8be5\u9608\u503c\u7684\u9884\u6d4b\u89c6\u4e3a\u80cc\u666f</li> <li><code>nms_thresh</code>\uff1aNMS\u5904\u7406\u65f6\u7528\u5230\u7684\u9608\u503c</li> <li><code>detection_per_image</code>\uff1a\u6d4b\u8bd5\u65f6\uff0c\u6bcf\u5f20\u56fe\u7247\u6700\u591a\u9884\u6d4b\u7684\u7269\u4f53\u6570\u91cf</li> <li><code>fg_iou_thresh</code>\u548c<code>bg_iou_thresh</code>\uff1a\u8bad\u7ec3\u65f6\u7528\u4e8e\u5224\u5b9a\u8be5\u951a\u70b9\u5c5e\u4e8e\u524d\u666f\u8fd8\u662f\u80cc\u666f\u7684\u9608\u503c\uff0ciou\u5927\u4e8e\u524d\u8005\uff0c\u5c06\u8be5\u951a\u70b9\u89c6\u4e3a\u524d\u666f\u951a\u70b9\uff0ciou\u5c0f\u4e8e\u540e\u8005\uff0c\u5c06\u8be5\u951a\u70b9\u89c6\u4e3a\u80cc\u666f</li> <li><code>topk_candidates</code>\uff1a\u6d4b\u8bd5\u65f6\uff0c\u5728NMS\u4e4b\u524d\uff0c\u6bcf\u4e2a\u7279\u5f81\u5c42\u6700\u591a\u53d6\u524dtopk_candidates\u4e2a\u524d\u666f\u951a\u70b9</li> </ul> <pre><code>class RetinaNet(nn.Module):\n    \"\"\"\n    Implements RetinaNet.\n\n    The input to the model is expected to be a list of tensors, each of shape [C, H, W], one for each\n    image, and should be in 0-1 range. Different images can have different sizes.\n\n    The behavior of the model changes depending if it is in training or evaluation mode.\n\n    During training, the model expects both the input tensors, as well as a targets (list of dictionary),\n    containing:\n        - boxes (``FloatTensor[N, 4]``): the ground-truth boxes in ``[x1, y1, x2, y2]`` format, with\n          ``0 &lt;= x1 &lt; x2 &lt;= W`` and ``0 &lt;= y1 &lt; y2 &lt;= H``.\n        - labels (Int64Tensor[N]): the class label for each ground-truth box\n\n    The model returns a Dict[Tensor] during training, containing the classification and regression\n    losses.\n\n    During inference, the model requires only the input tensors, and returns the post-processed\n    predictions as a List[Dict[Tensor]], one for each input image. The fields of the Dict are as\n    follows:\n        - boxes (``FloatTensor[N, 4]``): the predicted boxes in ``[x1, y1, x2, y2]`` format, with\n          ``0 &lt;= x1 &lt; x2 &lt;= W`` and ``0 &lt;= y1 &lt; y2 &lt;= H``.\n        - labels (Int64Tensor[N]): the predicted labels for each image\n        - scores (Tensor[N]): the scores for each prediction\n    \"\"\"\n\n    __annotations__ = {\n        'box_coder': det_utils.BoxCoder,\n        'proposal_matcher': det_utils.Matcher,\n    }\n\n    def __init__(self, backbone, num_classes,\n                 # transform parameters\n                 min_size=800, max_size=1333,\n                 image_mean=None, image_std=None,\n                 # Anchor parameters\n                 anchor_generator=None, head=None,\n                 proposal_matcher=None,\n                 score_thresh=0.05,\n                 nms_thresh=0.5,\n                 detections_per_img=100,\n                 fg_iou_thresh=0.5, bg_iou_thresh=0.4,\n                 topk_candidates=1000):\n        super(RetinaNet, self).__init__()\n\n        if not hasattr(backbone, \"out_channels\"):\n            raise ValueError(\n                \"backbone should contain an attribute out_channels \"\n                \"specifying the number of output channels (assumed to be the \"\n                \"same for all the levels)\"\n            )\n\n        self.backbone = backbone\n\n        assert isinstance(anchor_generator, (AnchorsGenerator, type(None)))\n\n        if anchor_generator is None:\n            # \u539f\u8bba\u6587\u4e2d\u8bf4\u5728\u6bcf\u4e2a\u9884\u6d4b\u7279\u5f81\u5c42\u4e0a\u9664\u4e86\u4f7f\u7528\u7ed9\u5b9a\u7684\u5c3a\u5ea6x\u5916\uff0c\u8fd8\u8981\u989d\u5916\u6dfb\u52a0x*2^(1/3)\u548cx*2^(2/3)\u8fd9\u4e24\u4e2a\u5c3a\u5ea6\n            # \u4e94\u4e2a\u9884\u6d4b\u7279\u5f81\u5c42\u91c7\u7528\u7684\u539f\u59cb\u5c3a\u5ea6\u5206\u522b\u4e3a32\uff0c 64\uff0c 128\uff0c 256\uff0c 512\n            # \u6ce8\u610f\u5c3a\u5ea6\u548c\u9762\u79ef\u7684\u5173\u7cfb\uff0c\u9762\u79ef=\u5c3a\u5ea6^2\n            anchor_sizes = tuple((x, int(x * 2 ** (1.0 / 3)), int(x * 2 ** (2.0 / 3)))\n                                 for x in [32, 64, 128, 256, 512])\n            # \u5bf9\u4e8e\u6bcf\u4e2a\u9884\u6d4b\u7279\u5f81\u5c42\u4e0aanchors\uff0c\u90fd\u4f1a\u4f7f\u7528\u4e09\u79cd\u6bd4\u4f8b\n            aspect_ratios = ((0.5, 1.0, 2.0),) * len(anchor_sizes)\n            anchor_generator = AnchorsGenerator(anchor_sizes, aspect_ratios)\n\n        self.anchor_generator = anchor_generator\n        # \u5b9a\u4e49\u5934\u90e8\u7684\u9884\u6d4b\u5c42\uff0c\u5373\u9884\u6d4b\u6bcf\u4e2a\u951a\u70b9\u7684\u7c7b\u522b\u548c\u56de\u5f52\u53c2\u6570\n        if head is None:\n            head = RetinaNetHead(backbone.out_channels,   # in_channels\n                                 anchor_generator.num_anchors_per_location()[0],  # num_anchors\n                                 num_classes)  # num_classes\n        self.head = head\n        # proposal_matcher\u7528\u4e8e\u5bf9\u951a\u70b9\u505a\u5212\u5206\uff0c\u6839\u636e\u951a\u70b9\u4e0e\u8fb9\u754c\u6846\u7684IOU\u503c\u5212\u5206\u8be5\u951a\u70b9\u662f\u6b63\u6837\u672c\u8fd8\u662f\u8d1f\u6837\u672c\n        if proposal_matcher is None:\n            proposal_matcher = det_utils.Matcher(\n                fg_iou_thresh,\n                bg_iou_thresh,\n                allow_low_quality_matches=True\n            )\n        self.proposal_matcher = proposal_matcher\n        # box_coder\u7528\u4e8e\u7f16\u7801\u8fd0\u7b97\uff0c\u7ed3\u5408\u951a\u70b9\u4e0e\u5bf9\u5e94\u7684\u8fb9\u754c\u6846\uff0c\u8ba1\u7b97\u4e8c\u8005\u4e4b\u95f4\u7684\u56de\u5f52\u53c2\u6570\n        self.box_coder = det_utils.BoxCoder(weights=(1.0, 1.0, 1.0, 1.0))\n\n        # \u7528\u4e8e\u56fe\u50cf\u9884\u5904\u7406\u7684\u5747\u503c\u65b9\u5dee\n        if image_mean is None:\n            image_mean = [0.485, 0.456, 0.406]\n        if image_std is None:\n            image_std = [0.229, 0.224, 0.225]\n        # \u5b9a\u4e49\u56fe\u50cf\u9884\u5904\u7406\u8fc7\u7a0b\uff0c\u5305\u62ec\u8f93\u5165\u56fe\u50cf\u7684\u6700\u5c0f\u8fb9\u957f\u8303\u56f4\u3001\u6700\u5927\u8fb9\u957f\u8303\u56f4\u4ee5\u53ca\u56fe\u50cf\u6807\u51c6\u5316\u65f6\u7528\u5230\u7684\u5747\u503c\u65b9\u5dee\n        self.transform = GeneralizedRCNNTransform(min_size, max_size, image_mean, image_std)\n\n        self.score_thresh = score_thresh\n        self.nms_thresh = nms_thresh\n        self.detections_per_img = detections_per_img\n        self.topk_candidates = topk_candidates\n\n        # used only on torchscript mode\n        self._has_warned = False\n\n    def forward(self, images, targets=None):\n        # type: (List[Tensor], Optional[List[Dict[str, Tensor]]]) -&gt; Tuple[Dict[str, Tensor], List[Dict[str, Tensor]]]\n        \"\"\"\n        Args:\n            images (list[Tensor]): images to be processed\n            targets (list[Dict[Tensor]]): ground-truth boxes present in the image (optional)\n\n        Returns:\n            result (list[BoxList] or dict[Tensor]): the output from the model.\n                During training, it returns a dict[Tensor] which contains the losses.\n                During testing, it returns list[BoxList] contains additional fields\n                like `scores`, `labels` and `mask` (for Mask R-CNN models).\n\n        \"\"\"\n        if self.training and targets is None:\n            raise ValueError(\"In training mode, targets should be passed\")\n\n        if self.training:\n            assert targets is not None\n            # \u68c0\u67e5\u6807\u7b7e\u4fe1\u606f\n            for target in targets:\n                boxes = target[\"boxes\"]\n                if isinstance(boxes, torch.Tensor):\n                    if len(boxes.shape) != 2 or boxes.shape[-1] != 4:\n                        raise ValueError(\"Expected target boxes to be a tensor\"\n                                         \"of shape [N, 4], got {:}.\".format(boxes.shape))\n                else:\n                    raise ValueError(\"Expected target boxes to be of type \"\n                                     \"Tensor, got {:}.\".format(type(boxes)))\n\n        # \u5f97\u5230\u539f\u59cb\u56fe\u7247\u7684\u9ad8\u5bbd\u5c3a\u5bf8\uff0c\u7528\u4e8e\u540e\u7eedpostprocess\uff0c\u505a\u8fd8\u539f\n        original_img_sizes: List[Tuple[int, int]] = []\n        for img in images:\n            val = img.shape[-2:]\n            assert len(val) == 2\n            original_img_sizes.append((val[0], val[1]))  # h, w\n\n        # \u5bf9\u8f93\u5165\u6570\u636e\u505a\u9884\u5904\u7406\uff0c\u5c06\u56fe\u7247\u6253\u5305\u6210\u4e00\u4e2abatch\n        images, targets = self.transform(images, targets)\n\n        # Check for degenerate boxes\n        # TODO: Move this to a function\n        # \u68c0\u67e5\u6807\u7b7e\u8fb9\u754c\u6846\u4fe1\u606f\n        if targets is not None:\n            for target_idx, target in enumerate(targets):\n                boxes = target[\"boxes\"]\n                degenerate_boxes = boxes[:, 2:] &lt;= boxes[:, :2]\n                if degenerate_boxes.any():\n                    # print the first degenerate box\n                    bb_idx = torch.where(degenerate_boxes.any(dim=1))[0][0]\n                    degen_bb: List[float] = boxes[bb_idx].tolist()\n                    raise ValueError(\"All bounding boxes should have positive height and width.\"\n                                     \" Found invalid box {} for target at index {}.\"\n                                     .format(degen_bb, target_idx))\n\n        # get the features from the backbone\n        # \u5c06\u56fe\u7247\u4f20\u5165\u4e3b\u5e72\u7f51\u7edc\u63d0\u53d6\u7279\u5f81\uff0c\u6b64\u65f6features\u4e3aOrderedDict\u683c\u5f0f\n        # \u952e\u5206\u522b\u4e3a\uff1a['0','1','2','p6','p7']\uff0c\u5bf9\u5e94\u8bba\u6587p3-p7\n        features = self.backbone(images.tensors)\n        if isinstance(features, torch.Tensor):\n            features = OrderedDict([(\"0\", features)])\n\n        features = list(features.values())\n        # compute the retinanet heads outputs using the features\n        # \u5c06\u5f97\u5230\u7684\u7279\u5f81\u4f20\u5165\u540e\u7eed\u9884\u6d4b\u7f51\u7edc\uff0c\u9884\u6d4b\u6bcf\u4e2a\u951a\u70b9\u7684\u7c7b\u522b\u548c\u8fb9\u754c\u6846\u56de\u5f52\u53c2\u6570\n        head_outputs = self.head(features)\n        # create the set of anchors\n        # \u521b\u9020\u4e00\u7ec4\u951a\u70b9\uff0canchors\u4e3a\u5217\u8868\u6570\u636e\uff0c\u91cc\u9762\u6bcf\u4e2a\u5143\u7d20\u4e3a\u4e8c\u7ef4\u6570\u636e\uff0c\n        # \u5c3a\u5bf8\u4e3a[\u951a\u70b9\u603b\u6570\uff0c4]\uff0c\u951a\u70b9\u603b\u6570=\u53c2\u4e0e\u9884\u6d4b\u7684\u7279\u5f81\u6570\u636e\u4e2a\u6570(\u7531\u7279\u5f81\u5c42\u5c3a\u5bf8\u6c42\u548c\u5f97\u5230)*\u6bcf\u4e2a\u7279\u5f81\u4e0a\u9884\u8bbe\u7684\u951a\u70b9\u6570\u91cf(\u6bd4\u4f8b\u6570\u4e58\u4ee5\u5c3a\u5ea6\u6570)\n        # \u7b2c\u4e8c\u7ef4\u5ea6\u8868\u793a\u6bcf\u4e2a\u951a\u70b9\u7684\u5750\u6807\u503c\n        anchors = self.anchor_generator(images, features)\n\n        losses = {}\n        detections: List[Dict[str, Tensor]] = []\n        # \u5982\u679c\u662f\u8bad\u7ec3\u9636\u6bb5\uff0c\u5219\u9700\u8981\u989d\u5916\u8ba1\u7b97\u635f\u5931\n        if self.training:\n            assert targets is not None\n            # \u4f20\u5165\u6807\u7b7e\u3001\u7f51\u7edc\u7684\u9884\u6d4b\u503c\u3001\u951a\u70b9\u5750\u6807\uff0c\u5f97\u5230\u5206\u7c7b\u635f\u5931\u4ee5\u53ca\u8fb9\u754c\u6846\u56de\u5f52\u635f\u5931\n            losses = self.compute_loss(targets, head_outputs, anchors)\n        # \u5982\u679c\u662f\u6d4b\u8bd5\u9636\u6bb5\uff0c\u5219\u9700\u8981\u5c06\u9884\u6d4b\u5230\u7684\u76ee\u6807\u6846\n        else:\n            # \u5f97\u5230\u6bcf\u4e2a\u7279\u5f81\u5c42\u7684\u7279\u5f81\u56fe\u5927\u5c0f(\u951a\u70b9\u662f\u57fa\u4e8e\u7279\u5f81\u56fe\u4e0a\u6bcf\u4e2a\u7279\u5f81\u6570\u636e\u800c\u8bbe\u7f6e\u7684)\n            num_anchors_per_level = [x.size(2) * x.size(3) for x in features]\n            HW = 0  # HW\u8868\u793a\u6240\u6709\u7279\u5f81\u5c42\u4e0a\u53c2\u4e0e\u9884\u6d4b\u7684\u7279\u5f81\u603b\u6570\n            for v in num_anchors_per_level:\n                HW += v\n            HWA = head_outputs[\"cls_logits\"].size(1)\n            # \u9884\u6d4b\u603b\u6570\u9664\u4ee5\u7279\u5f81\u603b\u6570\u5f97\u5230\u6bcf\u4e2a\u7279\u5f81\u4e0a\u7684\u951a\u70b9\u6570\u91cf\uff0c\u8fd9\u91cc\u9ed8\u8ba49\n            A = HWA // HW\n            # num_anchors_per_level\u8868\u793a\u6bcf\u4e2a\u7279\u5f81\u5c42\u4e0a\u7684\u951a\u70b9\u6570\u91cf\n            num_anchors_per_level = [hw * A for hw in num_anchors_per_level]\n\n            # split outputs per level\n            # \u5c06\u8f93\u51fa\u7684\u9884\u6d4b\u503c\u5212\u5206\u5230\u6bcf\u4e2a\u7279\u5f81\u5c42\u4e0a\uff0c\u4e00\u5171\u5212\u5206\u6210\u4e94\u7ec4\uff0c\u5bf9\u5e94\u4e94\u4e2a\u7279\u5f81\u5c42\u4e0a\u7684\u9884\u6d4b\n            split_head_outputs: Dict[str, List[Tensor]] = {}\n            for k in head_outputs:\n                split_head_outputs[k] = list(head_outputs[k].split(num_anchors_per_level, dim=1))\n            # \u5bf9\u9884\u8bbe\u7684\u6240\u6709\u951a\u70b9\u4e5f\u505a\u5212\u5206\uff0c\u548c\u4e0a\u9762\u4e00\u6837\n            split_anchors = [list(a.split(num_anchors_per_level)) for a in anchors]\n\n            # compute the detections\n            # \u5bf9\u9884\u6d4b\u7ed3\u679c\u505a\u5904\u7406\uff0c\u79fb\u9664\u4f4e\u6982\u7387\u7684\u76ee\u6807\uff0c\u5e76\u4e14\u5c06\u7ed3\u679c\u4f20\u5165nms\u5220\u53bb\u91cd\u53e0\u6846\uff0c\u6700\u540e\u9009\u53d6\u9884\u6d4b\u5206\u6570\u6700\u5927\u7684\u524d\u51e0\u4e2a\u9884\u6d4b\u76ee\u6807\u5f53\u505a\u9884\u6d4b\u7ed3\u679c\n            detections = self.postprocess_detections(split_head_outputs, split_anchors, images.image_sizes)\n            # \u5bf9\u7f51\u7edc\u7684\u9884\u6d4b\u7ed3\u679c\u8fdb\u884c\u540e\u5904\u7406\uff08\u4e3b\u8981\u5c06bboxes\u8fd8\u539f\u5230\u539f\u56fe\u50cf\u5c3a\u5ea6\u4e0a\uff09\n            detections = self.transform.postprocess(detections, images.image_sizes, original_img_sizes)\n\n        if torch.jit.is_scripting():\n            if not self._has_warned:\n                warnings.warn(\"RetinaNet always returns a (Losses, Detections) tuple in scripting\")\n                self._has_warned = True\n            return losses, detections\n        return self.eager_outputs(losses, detections)\n</code></pre>"},{"location":"detection/network/RetinaNet/#_7","title":"\u4e3b\u5e72\u7279\u5f81\u63d0\u53d6\u7f51\u7edc","text":"<p>\u2003\u2003\u5927\u4f53\u548cFPN\u76f8\u540c\uff0c\u53ea\u662fextra_blocks\u53d8\u91cf\u4e0d\u540c\uff0c\u8fd9\u91cc\u8fd8\u591a\u4e86\u4e24\u5c42\u6b65\u957f\u4e3a2\u7684\u5377\u79ef\uff0c\u7528\u4e8e\u4e0b\u91c7\u6837\uff0c\u4ee3\u7801\u5982\u4e0b\uff1a</p> <pre><code>class LastLevelP6P7(ExtraFPNBlock):\n    \"\"\"\n    This module is used in RetinaNet to generate extra layers, P6 and P7.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int):\n        super(LastLevelP6P7, self).__init__()\n        # \u8f93\u5165in_channels\u548c\u8f93\u51faout_channels\u9ed8\u8ba4\u90fd\u662f256\n        # \u5b9a\u4e49\u540e\u4e24\u5c42\u5377\u79ef\uff0c\u5229\u7528\u6b65\u957f\u4e3a2\u7684\u5377\u79ef\u8fd0\u7b97\u5206\u522b\u505a\u4e0b\u91c7\u6837\u5904\u7406\uff0c\u5f97\u5230\u8bba\u6587\u4e2d\u7684p6\u3001p7\n        self.p6 = nn.Conv2d(in_channels, out_channels, 3, 2, 1)\n        self.p7 = nn.Conv2d(out_channels, out_channels, 3, 2, 1)\n        # \u521d\u59cb\u5316\u6a21\u578b\u53c2\u6570\n        for module in [self.p6, self.p7]:\n            nn.init.kaiming_uniform_(module.weight, a=1)\n            nn.init.constant_(module.bias, 0)\n        self.use_P5 = in_channels == out_channels\n\n    def forward(self,\n                p: List[Tensor],\n                c: List[Tensor],\n                names: List[str]) -&gt; Tuple[List[Tensor], List[str]]:\n        p5, c5 = p[-1], c[-1]\n        x = p5 if self.use_P5 else c5\n        # \u7b2c\u4e94\u5c42\u7279\u5f81\u7ecf\u8fc7\u5377\u79ef\u5c42\u5f97\u5230p6\n        p6 = self.p6(x)\n        # \u518d\u4f20\u5165\u6fc0\u6d3b\u51fd\u6570\u4ee5\u53ca\u5377\u79ef\u5c42\uff0c\u5f97\u5230p7\n        p7 = self.p7(F.relu(p6))\n        p.extend([p6, p7])\n        names.extend([\"p6\", \"p7\"])\n        return p, names\n</code></pre>"},{"location":"detection/network/RetinaNet/#_8","title":"\u9884\u6d4b\u7f51\u7edc","text":"<p>\u2003\u2003\u548cFaster R-CNN\u4e0d\u540c\u7684\u662f\uff0c\u8fd9\u91cc\u9488\u5bf9\u9884\u6d4b\u7279\u5f81\u91c7\u7528\u66f4\u6df1\u7684\u7f51\u7edc\u8fdb\u884c\u63d0\u53d6\u7279\u5f81\uff08\u56db\u5c42\u5377\u79ef\uff09\uff0c\u4ee5\u53ca\u5229\u7528\u5377\u79ef\u6838\u5c3a\u5bf8\u4e3a3\u00d73\u7684\u5377\u79ef\u8fd0\u7b97\u505a\u9884\u6d4b\uff08Faster R-CNN\u75281\u00d71\u7684\uff09</p> <pre><code>class RetinaNetHead(nn.Module):\n    \"\"\"\n    A regression and classification head for use in RetinaNet.\n\n    Args:\n        in_channels (int): number of channels of the input feature\n        num_anchors (int): number of anchors to be predicted\n        num_classes (int): number of classes to be predicted\n    \"\"\"\n\n    def __init__(self, in_channels, num_anchors, num_classes):\n        super(RetinaNetHead, self).__init__()\n        # \u5206\u7c7b\u5b50\u7f51\u7edc\uff0c\u7528\u4e8e\u9884\u6d4b\u7269\u4f53\u7c7b\u522b\n        self.classification_head = RetinaNetClassificationHead(in_channels, num_anchors, num_classes)\n        # \u56de\u5f52\u5b50\u7f51\u7edc\uff0c\u7528\u4e8e\u9884\u6d4b\u7269\u4f53\u8fb9\u754c\u6846\u56de\u5f52\u53c2\u6570\n        self.regression_head = RetinaNetRegressionHead(in_channels, num_anchors)\n\n    def compute_loss(self,\n                     targets: List[Dict[str, Tensor]],\n                     head_outputs: Dict[str, Tensor],\n                     anchors: List[Tensor],\n                     matched_idxs: List[Tensor]) -&gt; Dict[str, Tensor]:\n        # \u4f9d\u6b21\u8ba1\u7b97\u5206\u7c7b\u635f\u5931\u548c\u56de\u5f52\u635f\u5931\uff0c\u5177\u4f53\u7ec6\u8282\u89c1\u5bf9\u5e94\u7684compute_loss\u65b9\u6cd5\n        return {\n            \"classification\": self.classification_head.compute_loss(targets, head_outputs, matched_idxs),\n            \"bbox_regression\": self.regression_head.compute_loss(targets, head_outputs, anchors, matched_idxs)\n        }\n\n    def forward(self, x: List[Tensor]) -&gt; Dict[str, Tensor]:\n        # \u5206\u522b\u505a\u9884\u6d4b\uff0c\u4e4b\u540e\u8fd4\u56de\n        return {\n            \"cls_logits\": self.classification_head(x),\n            \"bbox_regression\": self.regression_head(x)\n        }\n</code></pre> <p>\u5206\u7c7b\u5b50\u7f51\u7edc\uff08class subnet\uff09</p> <pre><code># \u5206\u7c7b\u5b50\u7f51\u7edc\nclass RetinaNetClassificationHead(nn.Module):\n    \"\"\"\n    A classification head for use in RetinaNet.\n\n    Args:\n        in_channels (int): number of channels of the input feature\n        num_anchors (int): number of anchors to be predicted\n        num_classes (int): number of classes to be predicted\n    \"\"\"\n\n    def __init__(self, in_channels, num_anchors, num_classes, prior_probability=0.01):\n        super(RetinaNetClassificationHead, self).__init__()\n\n        # class subnet\u662f\u7531\u56db\u4e2a3x3\u7684\u5377\u79ef\u5c42(\u6fc0\u6d3b\u51fd\u6570\u4e3aReLU) + \u4e00\u4e2a3x3\u7684\u5377\u79ef\u5c42(\u5206\u7c7b\u5668)\n        conv = []\n        for _ in range(4):\n            conv.append(nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1))\n            conv.append(nn.ReLU(inplace=True))\n        self.conv = nn.Sequential(*conv)\n        # \u5206\u7c7b\u5668\u529f\u80fd\u75313\u00d73\u7684\u5377\u79ef\u8fd0\u7b97\u5b8c\u6210\uff0c\u8f93\u51fa\u901a\u9053\u6570\u4e3a\u951a\u70b9\u6570A*\u7c7b\u522b\u6570K\n        self.cls_logits = nn.Conv2d(in_channels, num_anchors * num_classes, kernel_size=3, stride=1, padding=1)\n\n        # initial weights\n        # \u521d\u59cb\u5316\u7f51\u7edc\u53c2\u6570\n        for layer in self.conv.children():\n            if isinstance(layer, nn.Conv2d):\n                torch.nn.init.normal_(layer.weight, std=0.01)\n                torch.nn.init.constant_(layer.bias, 0)\n\n        torch.nn.init.normal_(self.cls_logits.weight, std=0.01)\n        torch.nn.init.constant_(self.cls_logits.bias, -math.log((1 - prior_probability) / prior_probability))\n        # \u5206\u7c7b\u6570\n        self.num_classes = num_classes\n        # \u6bcf\u4e2a\u7279\u5f81\u6570\u636e\u4e0a\u7684\u951a\u70b9\u6570\uff0c\u9ed8\u8ba49\u4e2a\uff08\u5c3a\u5ea6\u4e58\u4ee5\u6bd4\u4f8b\uff0c\u53733*3\uff09\n        self.num_anchors = num_anchors\n\n        # iou\u5728fg_iou_thresh\u548cbg_iou_thresh\u4e4b\u95f4\u7684\u820d\u5f03\uff0c\u7f16\u53f7\u8bbe\u7f6e\u4e3a-2\uff0c\u7528\u4e8e\u7b5b\u9009\u53c2\u4e0e\u8ba1\u7b97\u5206\u7c7b\u635f\u5931\u7684\u6837\u672c\n        self.BETWEEN_THRESHOLDS = det_utils.Matcher.BETWEEN_THRESHOLDS\n\n    def compute_loss(self,\n                     targets: List[Dict[str, Tensor]],\n                     head_outputs: Dict[str, Tensor],\n                     matched_idxs: List[Tensor]) -&gt; Tensor:\n        # matched_idxs\u4e3a\u951a\u70b9\u7f16\u53f7\uff0c\u5229\u7528\u951a\u70b9\u548c\u524d\u666f\u6807\u7b7e\u4e4b\u95f4\u7684iou\u503c\u505a\u5206\u914d\n        # \u5927\u4e8e\u7b49\u4e8e0\u65f6\u8868\u793a\u524d\u666f\u533a\u57df\uff0c\u4e14\u6570\u503c\u4e3a\u524d\u666f\u6807\u7b7e\u7684\u5e8f\u53f7(\u5373\uff0c\u6570\u503c\u8868\u793a\u7b2c\u51e0\u4e2a\u524d\u666f)\uff0c\u6839\u636e\u5339\u914d\u5230\u7684\u524d\u666f\u6807\u7b7e\u751f\u6210\u7c7b\u522b\u6807\u7b7e\n        # -1\u8868\u793a\u4e3a\u80cc\u666f\u533a\u57df\uff0c-2\u8868\u793a\u4ecb\u4e8e\u524d\u666f\u80cc\u666f\u4e4b\u95f4\uff0c\u8bad\u7ec3\u65f6\u8981\u820d\u53bb\n\n        losses = []\n        # \u9996\u5148\u7c7b\u522b\u9884\u6d4b\u5411\u91cf\n        cls_logits = head_outputs[\"cls_logits\"]\n        # \u6309\u56fe\u7247\u904d\u5386\uff0c\u6bcf\u5f20\u56fe\u5355\u72ec\u8ba1\u7b97\u635f\u5931\n        for targets_per_img, cls_logits_per_img, matched_idxs_per_img in zip(targets, cls_logits, matched_idxs):\n            # determine only the foreground\n            # \u627e\u51fa\u6240\u6709\u524d\u666f\u951a\u70b9\uff0c\u4e5f\u5c31\u662f\u7f16\u53f7\u5927\u4e8e\u7b49\u4e8e0\u7684\u951a\u70b9\n            foreground_idxs_per_img = torch.ge(matched_idxs_per_img, 0)  # ge: &gt;=\n            num_foreground = foreground_idxs_per_img.sum()  # num_foreground\u524d\u666f\u6570\u91cf\uff0c\u7528\u4e8e\u540e\u7eed\u505a\u9664\u6cd5\uff0c\u5f97\u5230\u5747\u503c\n\n            # create the target classification\n            # \u4ee5\u72ec\u70ed\u7f16\u7801\u7684\u5f62\u5f0f\u521b\u5efa\u5206\u7c7b\u6807\u7b7e\uff0c\u9996\u5148\u521d\u59cb\u5316\u4e00\u4e2a\u5168\u96f6\u5411\u91cf\uff0c\u5c3a\u5bf8\u548c\u9884\u6d4b\u7ed3\u679c\u5c3a\u5bf8\u4e00\u6837\uff0c[\u951a\u70b9\u6570,\u7c7b\u522b\u6570]\n            gt_classes_target = torch.zeros_like(cls_logits_per_img)\n            # \u7b2c\u4e00\u7ef4\u5ea6\u7684foreground_idxs_per_img\u7528\u4e8e\u5b9a\u4f4d\u524d\u666f\u951a\u70b9\n            # \u7b2c\u4e8c\u4e2a\u7ef4\u5ea6\u7528\u4e8e\u5b9a\u4f4d\u8be5\u951a\u70b9\u7684\u7c7b\u522b\uff0c\u5c06\u6307\u5b9a\u524d\u666f\u951a\u70b9\u7684\u5bf9\u5e94\u7c7b\u522b\u5206\u91cf\u8bbe\u7f6e\u4e3a1\n            # \u5982\u679c\u8be5\u951a\u70b9\u662f\u524d\u666f\u951a\u70b9\uff0c\u5219\u8be5\u951a\u70b9\u5bf9\u5e94\u7684\u5411\u91cf\u6709\u4e00\u4e2a\u6570\u4e3a1\uff0c\u5176\u4f59\u4e3a0,\n            # \u82e5\u8be5\u951a\u70b9\u662f\u80cc\u666f\u951a\u70b9\uff0c\u5219\u8be5\u951a\u70b9\u5bf9\u5e94\u7684\u5411\u91cf\u5168\u4e3a0\n            gt_classes_target[\n                foreground_idxs_per_img,\n                targets_per_img[\"labels\"][matched_idxs_per_img[foreground_idxs_per_img]]\n            ] = 1.0\n\n            # find indices for which anchors should be ignored\n            # \u5ffd\u7565iou\u5728[0.4, 0.5)\u4e4b\u95f4\u7684anchors\n            valid_idxs_per_img = torch.ne(matched_idxs_per_img, self.BETWEEN_THRESHOLDS)  # ne: !=\n\n            # \u5229\u7528\u7126\u70b9\u635f\u5931\u8ba1\u7b97\u5206\u7c7b\u635f\u5931\uff0c\u5177\u4f53\u8ba1\u7b97\u8fc7\u7a0b\u89c1\u7126\u70b9\u635f\u5931\u6a21\u5757\n            losses.append(sigmoid_focal_loss(\n                cls_logits_per_img[valid_idxs_per_img],\n                gt_classes_target[valid_idxs_per_img],\n                reduction=\"sum\"\n            ) / max(1, num_foreground))  # \u6ce8\u610f\u8fd9\u91cc\u9664\u4ee5\u7684\u662f\u6b63\u6837\u672c\u7684\u4e2a\u6570\n\n        # \u6c42\u548c\u9664\u4ee5batch\uff0c\u8fd4\u56de\u635f\u5931\u5747\u503c\n        return _sum(losses) / len(targets)\n\n    def forward(self, x: Tensor) -&gt; Tensor:\n        all_cls_logits = []\n\n        # \u904d\u5386\u6bcf\u4e2a\u9884\u6d4b\u7279\u5f81\u5c42\n        for features in x:  # \u4f9d\u6b21\u7ecf\u8fc7\u5b9a\u4e49\u597d\u7684\u5377\u79ef\u5c42\u4e0e\u9884\u6d4b\u5c42\uff0c\u5f97\u5230\u7c7b\u522b\u9884\u6d4b\u7ed3\u679c\n            cls_logits = self.conv(features)\n            cls_logits = self.cls_logits(cls_logits)\n            # \u8c03\u6574\u9884\u6d4b\u7ed3\u679c\u7684\u5c3a\u5ea6\uff0c\u4f7f\u5176\u53d8\u4e3a[N, HWA, K]\uff0c\u7b2c\u4e8c\u7ef4\u5ea6\u4e3a\u951a\u70b9\u6570\u91cf\uff0c\u7b2c\u4e09\u7ef4\u5ea6\u8868\u793a\u7c7b\u522b\n            # Permute classification output from (N, A * K, H, W) to (N, HWA, K).\n            N, _, H, W = cls_logits.shape\n            cls_logits = cls_logits.view(N, -1, self.num_classes, H, W)\n            # [N, A, K, H, W] -&gt; [N, H, W, A, K]\n            cls_logits = cls_logits.permute(0, 3, 4, 1, 2)\n            # [N, H, W, A, K] -&gt; [N, HWA, K]\n            cls_logits = cls_logits.reshape(N, -1, self.num_classes)\n\n            all_cls_logits.append(cls_logits)\n\n        return torch.cat(all_cls_logits, dim=1)\n</code></pre> <p>\u56de\u5f52\u5b50\u7f51\u7edc\uff08box subnet\uff09</p> <pre><code># \u56de\u5f52\u5b50\u7f51\u7edc\nclass RetinaNetRegressionHead(nn.Module):\n    \"\"\"\n    A regression head for use in RetinaNet.\n    # \u9884\u6d4b\u56de\u5f52\u53c2\u6570\u5b50\u7f51\u7edc\n    Args:\n        in_channels (int): number of channels of the input feature\n        num_anchors (int): number of anchors to be predicted\n    \"\"\"\n\n    __annotations__ = {\n        'box_coder': det_utils.BoxCoder,\n    }\n\n    def __init__(self, in_channels, num_anchors):\n        super(RetinaNetRegressionHead, self).__init__()\n\n        # box subnet\u662f\u7531\u56db\u4e2a3x3\u7684\u5377\u79ef\u5c42(\u6fc0\u6d3b\u51fd\u6570\u4e3aReLU) + \u4e00\u4e2a3x3\u7684\u5377\u79ef\u5c42(\u8fb9\u754c\u6846\u56de\u5f52\u5668)\n        # \u548c\u5206\u7c7b\u5b50\u7f51\u7edc\u4e00\u6837\uff0c\u9996\u5148\u5b9a\u4e49\u56db\u5c42\u5377\u79ef+ReLU\u8fd0\u7b97\u5c42\n        conv = []\n        for _ in range(4):\n            conv.append(nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1))\n            conv.append(nn.ReLU(inplace=True))\n        self.conv = nn.Sequential(*conv)\n        # \u5b9a\u4e49\u9884\u6d4b\u8fb9\u754c\u6846\u56de\u5f52\u53c2\u6570\u7684\u8fd0\u7b97\u5c42\uff0c\u75313*3\u7684\u5377\u79ef\u8fd0\u7b97\u5b8c\u6210\uff0c\u8f93\u51fa\u901a\u9053\u6570\u4e3a\u951a\u70b9\u6570A*4\n        self.bbox_reg = nn.Conv2d(in_channels, num_anchors * 4, kernel_size=3, stride=1, padding=1)\n\n        # initial weights\n        # \u521d\u59cb\u5316\u7f51\u7edc\u53c2\u6570\n        for layer in self.conv.children():\n            if isinstance(layer, nn.Conv2d):\n                torch.nn.init.normal_(layer.weight, std=0.01)\n                torch.nn.init.zeros_(layer.bias)\n        # bbox_coder\u7528\u4e8e\u7f16\u7801\u64cd\u4f5c\uff0c\u5c06\u6bcf\u4e2a\u951a\u70b9\u6240\u5339\u914d\u5230\u7684\u8fb9\u754c\u6846\u7f16\u7801\u6210\u56de\u5f52\u53c2\u6570\uff0c\u7f51\u7edc\u5b9e\u9645\u662f\u6839\u636e\u951a\u70b9\u6765\u9884\u6d4b\u8fb9\u754c\u6846\u56de\u5f52\u53c2\u6570\n        self.bbox_coder = det_utils.BoxCoder(weights=(1.0, 1.0, 1.0, 1.0))\n\n    def compute_loss(self,\n                     targets: List[Dict[str, Tensor]],\n                     head_outputs: Dict[str, Tensor],\n                     anchors: List[Tensor],\n                     matched_idxs: List[Tensor]) -&gt; Tensor:\n        losses = []\n        # \u5f97\u5230\u7f51\u7edc\u9884\u6d4b\u7684\u8fb9\u754c\u6846\u56de\u5f52\u53c2\u6570\n        bbox_regression = head_outputs[\"bbox_regression\"]\n        for targets_per_img, bbox_regression_per_img, anchors_per_img, matched_idxs_per_img in \\\n                zip(targets, bbox_regression, anchors, matched_idxs):\n            # determine only the foreground indices, ignore the rest\n            # \u5f97\u5230\u5bf9\u5e94\u524d\u666f\u533a\u57df\u7684\u951a\u70b9\u5e8f\u53f7\n            foreground_idxs_per_img = torch.where(torch.ge(matched_idxs_per_img, 0))[0]  # ge: &gt;=\n            num_foreground = foreground_idxs_per_img.numel()\n\n            # select only the foreground boxes\n            # \u53ea\u7b5b\u9009\u51fa\u6bcf\u4e2a\u524d\u666f\u951a\u70b9\u5339\u914d\u7684\u8fb9\u754c\u6846\u5750\u6807\u3001\u56de\u5f52\u53c2\u6570\u4ee5\u53ca\u951a\u70b9\u5750\u6807\n            matched_gt_boxes_per_img = targets_per_img[\"boxes\"][matched_idxs_per_img[foreground_idxs_per_img]]\n            bbox_regression_per_img = bbox_regression_per_img[foreground_idxs_per_img, :]\n            anchors_per_img = anchors_per_img[foreground_idxs_per_img, :]\n\n            # compute the regression targets\n            # \u5bf9\u6bcf\u4e2a\u951a\u70b9\u6240\u5339\u914d\u7684\u8fb9\u754c\u6846\u5750\u6807\u505a\u7f16\u7801\uff08\u951a\u70b9\u5750\u6807\u548c\u8fb9\u754c\u6846\u5750\u6807\u7f16\u7801\uff09\uff0c\u5f97\u5230\u771f\u5b9e\u7684\u56de\u5f52\u53c2\u6570(\u5373\u6807\u7b7e)\uff0c\u7528\u4e8e\u8ba1\u7b97\u635f\u5931\n            targets_regression = self.bbox_coder.encode_single(matched_gt_boxes_per_img, anchors_per_img)\n\n            # compute the box regression loss\n            # \u8ba1\u7b97\u9884\u6d4b\u7684\u56de\u5f52\u53c2\u6570\u548c\u771f\u5b9e\u7684\u56de\u5f52\u53c2\u6570\u4e4b\u95f4\u7684l1\u635f\u5931\n            losses.append(torch.nn.functional.l1_loss(\n                bbox_regression_per_img,\n                targets_regression,\n                reduction=\"sum\"\n            ) / max(1, num_foreground))\n\n        return _sum(losses) / max(1, len(targets))\n\n    def forward(self, x: List[Tensor]) -&gt; Tensor:\n        all_bbox_regression = []\n\n        # \u904d\u5386\u6bcf\u4e2a\u9884\u6d4b\u7279\u5f81\u5c42\n        for features in x:\n            # \u9996\u5148\u4f20\u5165\u5b9a\u4e49\u597d\u7684\u5377\u79ef\u5c42\u4e0e\u9884\u6d4b\u5c42\uff0c\u9884\u6d4b\u56de\u5f52\u53c2\u6570\n            bbox_regression = self.conv(features)\n            bbox_regression = self.bbox_reg(bbox_regression)\n\n            # Permute bbox regression output from (N, 4 * A, H, W) to (N, HWA, 4).\n            # \u548c\u5206\u7c7b\u5b50\u7f51\u7edc\u4e00\u6837\uff0c\u8c03\u6574\u9884\u6d4b\u7ed3\u679c\u7684\u5c3a\u5bf8\uff0c\u8c03\u6574\u4e3a[N, HWA, 4]\n            N, _, H, W = bbox_regression.shape\n            # [N, 4 * A, H, W] -&gt; [N, A, 4, H, W]\n            bbox_regression = bbox_regression.view(N, -1, 4, H, W)\n            # [N, A, 4, H, W] -&gt; [N, H, W, A, 4]\n            bbox_regression = bbox_regression.permute(0, 3, 4, 1, 2)\n            # [N, H, W, A, 4] -&gt; [N, HWA, 4]\n            bbox_regression = bbox_regression.reshape(N, -1, 4)\n\n            all_bbox_regression.append(bbox_regression)\n\n        return torch.cat(all_bbox_regression, dim=1)\n</code></pre>"},{"location":"detection/network/RetinaNet/#_9","title":"\u8ba1\u7b97\u635f\u5931","text":"<pre><code>def compute_loss(self, targets, head_outputs, anchors):\n    # type: (List[Dict[str, Tensor]], Dict[str, Tensor], List[Tensor]) -&gt; Dict[str, Tensor]\n    matched_idxs = []\n    for anchors_per_img, targets_per_img in zip(anchors, targets):\n        # \u5982\u679ctargets\u4e2d\u65e0\u524d\u666f\u5bf9\u8c61\uff0c\u5219\u5ffd\u7565\n        if targets_per_img[\"boxes\"].numel() == 0:\n            matched_idxs.append(torch.full((anchors_per_img.size(0),), -1, dtype=torch.int64))\n            continue\n        # \u8ba1\u7b97\u951a\u70b9\u548c\u524d\u666f\u7269\u4f53\u4e4b\u95f4\u7684iou\u503c\n        match_quality_matrix = box_ops.box_iou(targets_per_img[\"boxes\"], anchors_per_img)\n        # \u5229\u7528\u5f97\u5230\u7684iou\u503c\u5bf9\u951a\u70b9\u505a\u5339\u914d\u786e\u5b9a\u5e8f\u53f7\uff0c\u5982\u679c\u662f\u8be5\u951a\u70b9\u5c5e\u4e8e\u80cc\u666f\u533a\u57df\uff0c\u5219\u5e8f\u53f7\u4e3a-1\uff0c\u65e0\u5173\u533a\u57df\u5219\u4e3a-2\n        # \u5982\u679c\u8be5\u951a\u70b9\u5c5e\u4e8e\u524d\u666f\u533a\u57df\uff0c\u5219\u5e8f\u53f7\u8868\u793atargets\u4e2d\u524d\u666f\u7269\u4f53\u7684\u5e8f\u53f7\uff0c\u4fbf\u4e8e\u540e\u7eed\u6307\u5b9a\u951a\u70b9\u7684\u7c7b\u522b\u6807\u7b7e\n        matched_idxs.append(self.proposal_matcher(match_quality_matrix))\n    # \u8ba1\u7b97\u635f\u5931\uff0c\u5177\u4f53\u89c1head\u4e2d\u7684compute_loss\n    return self.head.compute_loss(targets, head_outputs, anchors, matched_idxs)\n</code></pre> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u6307\u6b63</p> <p>\u521d\u6b65\u5b8c\u7a3f\u4e8e\uff1a2023\u5e741\u670826\u65e5</p>"},{"location":"detection/network/Faster_RCNN/ROI_Head/","title":"Faster R-CNN\uff1aROI Head\u6a21\u5757","text":""},{"location":"detection/network/Faster_RCNN/ROI_Head/#_1","title":"\u7b80\u4ecb","text":"<p>\u2003\u2003\u76ee\u7684\uff1a\u4e3aRPN\u6a21\u5757\u63d0\u4f9b\u7684\u6bcf\u4e2aproposal\u8fdb\u884c\u7c7b\u522b\u9884\u6d4b\u548c\u56de\u5f52\u53c2\u6570\u7684\u9884\u6d4b\uff0c\u9884\u6d4b\u5bf9\u8c61\u7c7b\u522b\u548c\u5fae\u8c03RPN\u9884\u6d4b\u51fa\u6765\u7684\u8fb9\u754c\u533a\u57df</p> <p>\u2003\u2003\u8f93\u5165\uff1a\u7279\u5f81\u56fe\u3001proposal</p> <p>\u2003\u2003\u8f93\u51fa\uff1a\u7269\u4f53\u7c7b\u522b\u4ee5\u53ca\u5bf9\u5e94\u7684\u8fb9\u754c\u6846\u5750\u6807</p> <p>\u2003\u2003\u6a21\u5757\u6d41\u7a0b\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u635f\u5931\u8ba1\u7b97\u8fc7\u7a0b\uff08\u8fd9\u91cc\u4e0eRPN\u6a21\u5757\u7c7b\u4f3c\uff09\uff1a</p> <p> <p></p> <p></p> <p>\u6d41\u7a0b\u56fe\u539f\u521b\uff0c\u4f7f\u7528\u8bf7\u544a\u77e5</p>"},{"location":"detection/network/Faster_RCNN/ROI_Head/#_2","title":"\u7ec6\u8282","text":"<p>\u7f51\u7edc\u7ed3\u6784</p> <ul> <li>\u7b2c\u4e8c\u9636\u6bb5\u7684proposal\u76f8\u5f53\u4e8e\u7b2c\u4e00\u9636\u6bb5\u7684\u951a\u70b9\uff1b</li> <li>\u7b2c\u4e8c\u9636\u6bb5\u4e3b\u8981\u6709\u4e24\u4e2a\u529f\u80fd\uff1a\u7b2c\u4e00\uff0c\u5bf9\u6bcf\u4e2a\u524d\u666fproposals\u505a\u4e00\u6b21\u5206\u7c7b\uff0c\u7b2c\u4e8c\uff0c\u5bf9\u6bcf\u4e2a\u9884\u6d4b\u7684\u524d\u666fproposals\u505a\u5fae\u8c03\uff08\u4e8c\u6b21\u8c03\u6574\u8fb9\u754c\u6846\uff09\uff1b</li> <li>\u5728\u9884\u6d4b\u56de\u5f52\u53c2\u6570\u65f6\uff0c\u6267\u884c\u7c7b\u522b\u53ef\u77e5\u7684\u9884\u6d4b\uff0c\u5373\u6bcf\u4e2aproposal\u8f93\u51faK\u7ec4\u56de\u5f52\u53c2\u6570\uff0cK\u4e3a\u7c7b\u522b\u6570\u91cf\uff0c\u6bcf\u7ec4\u5bf9\u5e941\u4e2a\u7c7b\u522b\uff08\u5bf9\u6bd4RetinaNet\u4e2d\uff0c\u6bcf\u4e2a\u951a\u70b9\u8f93\u51fa1\u7ec4\u56de\u5f52\u53c2\u6570\uff09\uff1b</li> <li>\u5728\u9884\u6d4b\u7269\u4f53\u7c7b\u522b\u65f6\uff0c\u5355\u72ec\u9884\u6d4b\u80cc\u666f\u6982\u7387\uff0c\u5373\u6bcf\u4e2a\u951a\u70b9\u8f93\u51faK+1\u4e2a\u6570\u503c\uff08\u5bf9\u6bd4RetinaNet\u8f93\u51faK\u4e2a\u6570\u503c\uff09\u3002</li> </ul> <p>\u8bad\u7ec3\u9636\u6bb5</p> <ul> <li>\u8bad\u7ec3\u9636\u6bb5\uff0c\u9996\u5148\u8981\u5bf9RPN\u5f97\u5230\u7684proposals\u505a\u7b5b\u9009\uff0c\u7b5b\u9009\u51fa\u53c2\u4e0e\u635f\u5931\u8ba1\u7b97\u7684proposals\uff0c\u6700\u540e\u5c06\u7b5b\u9009\u7684proposals\u4f20\u5165\u9884\u6d4b\u5668\uff1b</li> <li>\u7b5b\u9009\u8fc7\u7a0b\uff1a\u6bcf\u5f20\u56fe\u968f\u673a\u91c7\u6837512\u4e2aproposals\u8fdb\u884c\u8bad\u7ec3\uff0c\u6b63\u8d1f\u6837\u672c\u6bd4\u4f8b\u9ed8\u8ba41:3\uff0c\u5982\u679c\u6b63\u6837\u672c\u5c11\u4e8e128\uff0c\u5219\u7528\u8d1f\u6837\u672c\u586b\u5145\uff1b</li> <li>\u5728\u951a\u70b9\u5339\u914d\u4e2d\uff0c\u4e0e\u7269\u4f53\u8fb9\u754c\u6846IOU\u503c\u5927\u4e8e0.5\u7684\u951a\u70b9\u8bbe\u7f6e\u4e3a\u524d\u666f\u951a\u70b9\u3001IOU\u503c\u5c0f\u4e8e0.5\u7684\u8bbe\u7f6e\u4e3a\u80cc\u666f\u951a\u70b9\u3002</li> </ul> <p>\u6d4b\u8bd5\u9636\u6bb5</p> <ul> <li>\u6d4b\u8bd5\u9636\u6bb5\uff0c\u5c06\u6240\u6709\u7684proposals\u4f20\u5165\u9884\u6d4b\u5668\uff1b</li> <li>\u5c06\u9884\u6d4b\u7ed3\u679c\u505a\u540e\u5904\u7406\uff1a\u7ed3\u5408proposals\u5bf9\u9884\u6d4b\u7684\u56de\u5f52\u53c2\u6570\u505a\u89e3\u7801\u5f97\u5230bbox\u3001\u79fb\u9664\u80cc\u666f\u4fe1\u606f\u3001\u4f4e\u6982\u7387\u76ee\u6807\u3001\u5c0f\u5c3a\u5bf8\u76ee\u6807\u3001\u6267\u884cNMS\u3001\u7b5b\u9009\u51fa\u524dN\u4e2a\u76ee\u6807\u4f5c\u4e3a\u6700\u7ec8\u7684\u9884\u6d4b\u7ed3\u679c\uff1b</li> <li>\u9ed8\u8ba4\uff1a\u4f4e\u6982\u7387\u4e3a0.05\u3001NMS\u9608\u503c\u4e3a0.5\u3001\u5c0f\u5c3a\u5bf8\u4e3a\u5bbd\u9ad8\u5c0f\u4e8e1\u4e2a\u50cf\u7d20\u7684\u7269\u4f53\u3001N\u4e3a100\u3002</li> </ul>"},{"location":"detection/network/Faster_RCNN/ROI_Head/#_3","title":"\u4ee3\u7801","text":"<p>\u6ce8\uff1aROI Head\u6a21\u5757\u4ee3\u7801\u6765\u6e90\u4e8ePyTorch\u5b98\u65b9\u5b9e\u73b0\u7684Faster R-CNN\u7b97\u6cd5\uff0c\u603b\u7684\u7f51\u7edc\u6a21\u578b\u53ef\u7531\u5982\u4e0b\u51fd\u6570\u6307\u4ee4\u76f4\u63a5\u8c03\u53d6\uff1a</p> <pre><code>torchvision.models.detection.FasterRCNN()\n</code></pre> <p>\u53c2\u8003\u94fe\u63a5\uff1a</p> <ul> <li>https://www.bilibili.com/video/BV1of4y1m7nj</li> <li>https://github.com/WZMIAOMIAO/deep-learning-for-image-processing</li> </ul>"},{"location":"detection/network/Faster_RCNN/ROI_Head/#_4","title":"\u6a21\u5757\u7ed3\u6784","text":"<pre><code>class RoIHeads(torch.nn.Module):\n    __annotations__ = {\n        'box_coder': det_utils.BoxCoder,\n        'proposal_matcher': det_utils.Matcher,\n        'fg_bg_sampler': det_utils.BalancedPositiveNegativeSampler,\n    }\n\n    def __init__(self,\n                 # ROI Pooling\u6a21\u5757\n                 box_roi_pool,   # Multi-scale RoIAlign pooling\n                 # \u4e24\u5c42MLP\uff0c\u7528\u4e8e\u5bf9pooling\u7279\u5f81\u63d0\u7279\u5f81\n                 box_head,       # TwoMLPHead\n                 # \u9884\u6d4b\u6a21\u5757\uff0c\u7528\u4e8e\u9884\u6d4b\u7269\u4f53\u7c7b\u522b\u548c\u56de\u5f52\u53c2\u6570\n                 box_predictor,  # FastRCNNPredictor\n                 # Faster R-CNN training\n                 # \u5212\u5206\u524d\u666f\u548c\u80cc\u666f\u7684iou\u503c\n                 fg_iou_thresh, bg_iou_thresh,  # default: 0.5, 0.5\n                 # \u7528\u4e8e\u8bad\u7ec3\u7684\u9884\u6d4b\u6837\u672c\u603b\u6570\uff0c\u4ee5\u53ca\u6b63\u6837\u672c(\u524d\u666f)\u5360\u6bd4\n                 batch_size_per_image, positive_fraction,  # default: 512, 0.25\n                 bbox_reg_weights,  # None\n                 # Faster R-CNN inference\n                 # \u4f4e\u5206\u6570\u9608\u503c\uff0c\u9884\u6d4b\u5206\u6570\u4f4e\u4e8e\u6b64\u503c\u7684\u88ab\u79fb\u9664\n                 score_thresh,        # default: 0.05\n                 # nms\u5904\u7406\u65f6\u7684\u9608\u503c\n                 nms_thresh,          # default: 0.5\n                 # \u83b7\u53d6\u9884\u6d4b\u5206\u6570\u524ddetection_per_img\u4e2a\u9884\u6d4b\u76ee\u6807\n                 detection_per_img):  # default: 100\n        super(RoIHeads, self).__init__()\n        # \u8ba1\u7b97\u4e24\u4e2a\u6846\u4e4b\u95f4\u7684IOU\u503c\n        self.box_similarity = box_ops.box_iou\n        # \u6b63\u8d1f\u6837\u672c\u5212\u5206\u7b56\u7565\uff0c\u5373\u5212\u5206\u524d\u3001\u540e\u666f\n        self.proposal_matcher = det_utils.Matcher(  # \u5c06proposal\u5212\u5206\u4e3a\u6b63\u8d1f\u6837\u672c\uff0c\u53c2\u8003\u4e24\u4e2a\u9608\u503c\n            fg_iou_thresh,  # default: 0.5\n            bg_iou_thresh,  # default: 0.5\n            allow_low_quality_matches=False)\n        # \u786e\u4fdd\u5305\u542b\u56fa\u5b9a\u7684\u6b63\u8d1f\u6837\u672c\u6bd4\u4f8b\u3002\u91c7\u56fa\u5b9a\u6570\u91cf\u7684\u6837\u672c(512)\uff0c\u4ee5\u53ca\u6b63\u6837\u672c\u81f3\u5c11\u5360\u6bd4(0.25)\n        self.fg_bg_sampler = det_utils.BalancedPositiveNegativeSampler(\n            batch_size_per_image,  # default: 512\n            positive_fraction)     # default: 0.25\n\n        if bbox_reg_weights is None:\n            bbox_reg_weights = (10., 10., 5., 5.)\n        # \u8fb9\u754c\u6846\u4e0e\u56de\u5f52\u53c2\u6570\u4e4b\u95f4\u7684\u76f8\u4e92\u8f6c\u6362\n        self.box_coder = det_utils.BoxCoder(bbox_reg_weights)\n        # \u5c06\u8f93\u5165\u7684\u53d8\u91cf\u5747\u8f6c\u5316\u4e3a\u7c7b\u5c5e\u6027\n        self.box_roi_pool = box_roi_pool    # Multi-scale RoIAlign pooling\n        self.box_head = box_head            # TwoMLPHead\n        self.box_predictor = box_predictor  # FastRCNNPredictor\n\n        self.score_thresh = score_thresh  # default: 0.05\n        self.nms_thresh = nms_thresh      # default: 0.5\n        self.detection_per_img = detection_per_img  # default: 100\n\n    def forward(self,\n                features,       # type: Dict[str, Tensor]\n                proposals,      # type: List[Tensor]\n                image_shapes,   # type: List[Tuple[int, int]]\n                targets=None    # type: Optional[List[Dict[str, Tensor]]]\n                ):\n        # type: (...) -&gt; Tuple[List[Dict[str, Tensor]], Dict[str, Tensor]]\n        \"\"\"\n        Arguments:\n            features (List[Tensor])  # \u4e0d\u540c\u7684\u7279\u5f81\u5c42\uff0c\u6570\u636e\u7c7b\u578b\u4e3a\u5b57\u5178\u683c\u5f0f\n            proposals (List[Tensor[N, 4]])  # \u4eceRPN\u5f97\u5230\u7684\u9884\u6d4b\u6846\u5750\u6807\uff0c\u5bf9\u4e8e\u539f\u56fe\u7684\u7edd\u5bf9\u5750\u6807\uff0c\u975e\u56de\u5f52\u53c2\u6570\n            image_shapes (List[Tuple[H, W]])  # \u6bcf\u5f20\u56fe\u7684\u8f93\u5165\u5927\u5c0f\n            targets (List[Dict])  # \u6807\u7b7e\n        \"\"\"\n\n        # \u68c0\u67e5targets\u7684\u6570\u636e\u7c7b\u578b\u662f\u5426\u6b63\u786e\n        if targets is not None:\n            for t in targets:\n                floating_point_types = (torch.float, torch.double, torch.half)\n                assert t[\"boxes\"].dtype in floating_point_types, \"target boxes must of float type\"\n                assert t[\"labels\"].dtype == torch.int64, \"target labels must of int64 type\"\n\n        if self.training:\n            # \u5bf9\u6837\u672c\u8fdb\u884c\u7b5b\u9009\uff0c\u5212\u5206\u6b63\u8d1f\u6837\u672c\uff0c\u7edf\u8ba1\u5bf9\u5e94gt\u7684\u6807\u7b7e\u4ee5\u53ca\u8fb9\u754c\u6846\u56de\u5f52\u4fe1\u606f\u3002\u4f20\u5165\u9884\u6d4b\u7684\u5750\u6807\u6846\uff0c\u6807\u7b7e\n            # regression_targets\u8868\u793a\u7531RPN\u5f97\u5230\u7684\u8fb9\u754c\u6846\u5230\u771f\u5b9e\u6807\u7b7e\u7684\u8fb9\u754c\u6846\u4e4b\u95f4\u7684\u771f\u6b63\u56de\u5f52\u53c2\u6570\u5e94\u8be5\u662f\u591a\u5c11\uff0cROI\u7684\u9884\u6d4b\u5c31\u8be5\u5411\u8fd9\u91cc\u9760\u8fd1\uff0c\u7528\u4e8e\u4fee\u6b63RPN\u7684\u9519\u8bef\u3002\n            # \u56e0\u6b64\uff0c\u8fd9\u91ccregression_targets\u5c31\u662fROI\u7684\u56de\u5f52\u53c2\u6570\u6807\u7b7e\n            proposals, labels, regression_targets = self.select_training_samples(proposals, targets)\n        else:\n            labels = None\n            regression_targets = None\n\n        # \u5c06\u91c7\u96c6\u6837\u672c\u901a\u8fc7Multi-scale RoIAlign pooling\u5c42\n        # \u8fd9\u91cc\u8f93\u5165\u7684\u7279\u5f81\u56fe\u7ec4\u5fc5\u987b\u662f\u5b57\u5178\u683c\u5f0f\u7684\uff0c\u952e\u8868\u793a\u7279\u5f81\u56fe\u540d\u79f0\uff0c\u503c\u8868\u793a\u76f8\u5e94\u7684\u7279\u5f81\u56fe\n        # \u5f97\u5230\u6bcf\u4e2a\u533a\u57df\u7684\u7279\u5f81,\u76f8\u5f53\u4e8e\u5c06\u76ee\u6807\u6846\u7684\u7279\u5f81\u88c1\u526a\u51fa\u6765\n        # box_features_shape: [num_proposals, channel, height, width]\n        box_features = self.box_roi_pool(features, proposals, image_shapes)\n\n        # \u5c06\u88c1\u526a\u5230\u7684\u7279\u5f81\u4f20\u5165MLP\uff0c\u6bcf\u5c42\u5747\u7531\u4e00\u4e2a\u7ebf\u6027\u56de\u5f52\u8fd0\u7b97\u6784\u6210\n        # box_features_shape: [num_proposals, representation_size]\n        box_features = self.box_head(box_features)\n\n        # \u63a5\u7740\u5206\u522b\u9884\u6d4b\u76ee\u6807\u7c7b\u522b\u548c\u8fb9\u754c\u6846\u56de\u5f52\u53c2\u6570\u3002\u9884\u6d4b\u7c7b\u522b\u548c\u56de\u5f52\u53c2\u6570\n        class_logits, box_regression = self.box_predictor(box_features)\n\n        result = torch.jit.annotate(List[Dict[str, torch.Tensor]], [])\n        losses = {}\n        # \u5982\u679c\u662f\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u5219\u9700\u8981\u8ba1\u7b97\u635f\u5931\uff0c\u65e0\u9700\u5bf9\u7ed3\u679c\u8fdb\u884c\u540e\u5904\u7406\n        if self.training:\n            assert labels is not None and regression_targets is not None\n            # \u8ba1\u7b97\u635f\u5931\uff0c\u8fd9\u91cc\u6b63\u8d1f\u6837\u672c\u5df2\u7ecf\u7b5b\u9009\u597d\u4e86\uff0c\u53ef\u4ee5\u76f4\u63a5\u8ba1\u7b97\n            loss_classifier, loss_box_reg = fastrcnn_loss( \n                class_logits, box_regression, labels, regression_targets)\n            losses = {\n                \"loss_classifier\": loss_classifier,\n                \"loss_box_reg\": loss_box_reg\n            }\n        # \u6d4b\u8bd5\u8fc7\u7a0b\u53ea\u9700\u8981\u4e00\u4e2a\u540e\u5904\u7406\uff0c\u65e0\u9700\u8ba1\u7b97\u635f\u5931\n        else:\n            # \u5bf9\u9884\u6d4b\u7ed3\u679c\u7684\u540e\u5904\u7406\u8fc7\u7a0b\uff0c\u4e3b\u8981\u662f\u5c06\u56de\u5f52\u53c2\u6570\u8f6c\u5316\u4e3a\u8fb9\u754c\u6846\u4fe1\u606f\uff0c\u5e76\u4e14\u6620\u5c04\u5230\u539f\u59cb\u56fe\u50cf\u7684\u5c3a\u5ea6\n            boxes, scores, labels = self.postprocess_detections(class_logits, box_regression, proposals, image_shapes)\n            num_images = len(boxes)\n            for i in range(num_images):\n                result.append(\n                    {\n                        \"boxes\": boxes[i],\n                        \"labels\": labels[i],\n                        \"scores\": scores[i],\n                    }\n                )\n        # \u8fd4\u56de\u9884\u6d4b\u7ed3\u679c\u4e0e\u635f\u5931\n        return result, losses\n</code></pre>"},{"location":"detection/network/Faster_RCNN/ROI_Head/#_5","title":"\u7b5b\u9009\u76ee\u6807\u533a\u57df","text":"<p>\u8fd9\u91cc\u53ea\u9488\u5bf9\u8bad\u7ec3\u8fc7\u7a0b</p> <pre><code>def select_training_samples(self,\n                            proposals,  # type: List[Tensor]\n                            targets     # type: Optional[List[Dict[str, Tensor]]]\n                            ):\n    # type: (...) -&gt; Tuple[List[Tensor], List[Tensor], List[Tensor]]\n    \"\"\"\n    \u5212\u5206\u6b63\u8d1f\u6837\u672c\uff0c\u7edf\u8ba1\u5bf9\u5e94gt\u7684\u6807\u7b7e\u4ee5\u53ca\u8fb9\u754c\u6846\u56de\u5f52\u4fe1\u606f\n    list\u5143\u7d20\u4e2a\u6570\u4e3abatch_size\n    Args:\n        proposals: rpn\u9884\u6d4b\u7684boxes\uff0c\u76ee\u6807\u8fb9\u754c\u6846\n        targets: \u6807\u7b7e\n\n    Returns:\n        \u8fd4\u56de\u7b5b\u9009\u540e\u7684\u9884\u6d4b\u6846proposal\u3001\u5bf9\u5e94\u7684\u7c7b\u522b\u6807\u7b7e\u3001\u5bf9\u5e94\u7684\u56de\u5f52\u53c2\u6570\u6807\u7b7e\n    \"\"\"\n\n    # \u68c0\u67e5target\u6570\u636e\u662f\u5426\u4e3a\u7a7a\uff0c\u662f\u5426\u6709boxes\u548clabels\n    self.check_targets(targets)\n\n    assert targets is not None\n    # \u5f97\u5230\u6570\u636e\u7c7b\u578b\u548c\u5b58\u50a8\u8bbe\u5907\n    dtype = proposals[0].dtype\n    device = proposals[0].device\n\n    # \u83b7\u53d6\u6807\u6ce8\u597d\u7684boxes\u4ee5\u53calabels\u4fe1\u606f\n    gt_boxes = [t[\"boxes\"].to(dtype) for t in targets]\n    gt_labels = [t[\"labels\"] for t in targets]\n\n    # append ground-truth bboxes to proposal\n    # \u5c06gt_boxes\u62fc\u63a5\u5230proposal\u540e\u9762(\u4e3a\u5565)\n    proposals = self.add_gt_proposals(proposals, gt_boxes)\n    # get matching gt indices for each proposal\n    # \u4e3a\u6bcf\u4e2aproposal\u5339\u914d\u5bf9\u5e94\u7684gt_box\uff0c\u5e76\u4e14\u5212\u5206\u6b63\u8d1f\u6837\u672c\uff0c\u5f97\u5230RPN\u6bcf\u4e2a\u9884\u6d4b\u6846\u7684\u7c7b\u522b\u6807\u7b7elabel\n    # \u4f20\u5165\u8fb9\u754c\u6846\u3001\u8fb9\u754c\u6846\u6807\u7b7e\u4ee5\u53ca\u7c7b\u522b\u6807\u7b7e\u3002\u8fd4\u56de\u5339\u914d\u5230\u7684gt\u7269\u4f53\u7d22\u5f15\u548c\u9884\u6d4b\u6846\u7c7b\u522b\n    matched_idxs, labels = self.assign_targets_to_proposals(proposals, gt_boxes, gt_labels)\n\n    # sample a fixed proportion of positive-negative proposals\n    # \u6309\u7ed9\u5b9a\u6570\u91cf\u548c\u6bd4\u4f8b\u91c7\u6837\u6b63\u8d1f\u6837\u672c\n    sampled_inds = self.subsample(labels)\n    matched_gt_boxes = []\n    num_images = len(proposals)\n\n    # \u904d\u5386\u6bcf\u5f20\u56fe\u50cf\uff0c\u6309batch\u904d\u5386\n    for img_id in range(num_images):\n        # \u83b7\u53d6\u6bcf\u5f20\u56fe\u50cf\u53c2\u4e0e\u8fd0\u7b97\u7684\u9884\u6d4b\u6846\u6837\u672c\u7d22\u5f15\n        img_sampled_inds = sampled_inds[img_id]\n        # \u83b7\u53d6\u5bf9\u5e94\u6b63\u8d1f\u6837\u672c\u7684proposals\u4fe1\u606f\n        proposals[img_id] = proposals[img_id][img_sampled_inds]\n        # \u83b7\u53d6\u5bf9\u5e94\u6b63\u8d1f\u6837\u672c\u7684\u771f\u5b9e\u7c7b\u522b\u4fe1\u606f\n        labels[img_id] = labels[img_id][img_sampled_inds]\n        # \u83b7\u53d6\u5bf9\u5e94\u6b63\u8d1f\u6837\u672c\u7684gt\u7d22\u5f15\u4fe1\u606f\uff0c\u5373\u56fe\u50cf\u4e2d\u4e0e\u7b2c\u51e0\u4e2a\u5bf9\u8c61\u76f8\u5339\u914d\n        matched_idxs[img_id] = matched_idxs[img_id][img_sampled_inds]\n        # \u8fb9\u754c\u6846\u4fe1\u606f\n        gt_boxes_in_image = gt_boxes[img_id]\n        if gt_boxes_in_image.numel() == 0:  # \u5982\u679c\u6ca1\u6709\u7269\u4f53\uff0c\u5219\u8fb9\u754c\u6846\u7d22\u5f15\u8bbe\u4e3a0\n            gt_boxes_in_image = torch.zeros((1, 4), dtype=dtype, device=device)\n        # \u83b7\u53d6\u5bf9\u5e94\u6b63\u8d1f\u6837\u672c\u7684gt box\u4fe1\u606f\uff0c\u5373\u6bcf\u4e2aproposal\u7684\u8fb9\u754c\u6846\u6807\u7b7e\uff0c\u80cc\u666f\u9ed8\u8ba4\u4e3a\u7b2c\u4e00\u4e2a\u5bf9\u8c61\u7684\u8fb9\u754c\u6846\n        matched_gt_boxes.append(gt_boxes_in_image[matched_idxs[img_id]])\n\n    # \u6839\u636egt(\u6807\u7b7e)\u548cproposal(RPN\u9884\u6d4b)\u8ba1\u7b97\u8fb9\u6846\u56de\u5f52\u53c2\u6570\uff08\u9488\u5bf9gt\u7684\uff09\uff0c\u7528\u4e8e\u8fdb\u4e00\u6b65\u4fee\u6b63RPN\u5f97\u5230\u7684\u8fb9\u754c\u6846\u5750\u6807\n    # \u8fd9\u91cc\u4e0e\u4e4b\u524dRPN\u4e2d\u7c7b\u4f3c\uff0cRPN\u4e2d\u4e5f\u6709\u4e00\u4e2a\u4fee\u6b63\u4f5c\u7528\uff0c\u4fee\u6b63\u9884\u5148\u8bbe\u5b9a\u7684\u6807\u51c6\u951a\u70b9\u6846\u5230\u51c6\u786e\u7684\u76ee\u6807\u6846\uff0c\u8fd9\u91cc\u662f\u4fee\u6b63RPN\u9884\u6d4b\u7684\u76ee\u6807\u6846\u5230\u51c6\u786e\u7684\u76ee\u6807\u6846\u3002\u6574\u4e2aFaster RCNN\u4f1a\u4fee\u6b63\u4e24\u6b21\n    # \u53ea\u8ba1\u7b97\u5bf9\u6240\u6709proposal\u90fd\u8ba1\u7b97\u4e00\u6b21\u56de\u5f52\u53c2\u6570\uff0c\u4f46\u662f\u5728\u8ba1\u7b97\u635f\u5931\u65f6\u53ea\u7528\u5230\u6b63\u6837\u672c\u53bb\u8ba1\u7b97(\u4e0eRPN\u6a21\u5757\u4e2d\u7684\u635f\u5931\u8ba1\u7b97\u65b9\u6cd5\u7c7b\u4f3c)\uff0c\u7528\u4f5c\u7b2c\u4e8c\u9636\u6bb5\u7684\u56de\u5f52\u53c2\u6570\u6807\u7b7e\n    regression_targets = self.box_coder.encode(matched_gt_boxes, proposals)\n    return proposals, labels, regression_targets\n</code></pre> <p>\u5bf9\u53c2\u4e0e\u635f\u5931\u8ba1\u7b97\u7684\u6b63\u8d1f\u6837\u672c\u91c7\u6837</p> <pre><code>def subsample(self, labels):\n    # type: (List[Tensor]) -&gt; List[Tensor]\n    # BalancedPositiveNegativeSampler\uff0c\u548cRPN\u4e2d\u4f7f\u7528\u7684\u65b9\u6cd5\u7c7b\u4f3c\uff0c\u53ea\u662f\u53c2\u6570\u4e0d\u540c\n    sampled_pos_inds, sampled_neg_inds = self.fg_bg_sampler(labels)\n    sampled_inds = []\n    # \u904d\u5386\u6bcf\u5f20\u56fe\u7247\u7684\u6b63\u8d1f\u6837\u672c\u7d22\u5f15\n    for img_idx, (pos_inds_img, neg_inds_img) in enumerate(zip(sampled_pos_inds, sampled_neg_inds)):\n        # \u8bb0\u5f55\u6240\u6709\u91c7\u96c6\u6837\u672c\u7d22\u5f15\uff08\u5305\u62ec\u6b63\u6837\u672c\u548c\u8d1f\u6837\u672c\uff09\n\n        img_sampled_inds = torch.where(pos_inds_img | neg_inds_img)[0]  # \u5f97\u5230\u53c2\u4e0e\u540e\u7eed\u8fd0\u7b97\u7684\u6837\u672c\u7d22\u5f15\n        sampled_inds.append(img_sampled_inds)\n    return sampled_inds\n</code></pre> <p>\u4e3a\u6bcf\u4e2aRPN\u9884\u6d4b\u5f97\u5230\u7684\u8fb9\u754c\u6846(proposal)\u5339\u914d\u6807\u7b7e</p> <pre><code>def assign_targets_to_proposals(self, proposals, gt_boxes, gt_labels):\n    # type: (List[Tensor], List[Tensor], List[Tensor]) -&gt; Tuple[List[Tensor], List[Tensor]]\n    \"\"\"\n    \u4e3a\u6bcf\u4e2aproposal\u5339\u914d\u5bf9\u5e94\u7684gt_box\uff0c\u5e76\u5212\u5206\u5230\u6b63\u8d1f\u6837\u672c\u4e2d\n    Args:\n        proposals: \u9884\u6d4b\u5f97\u5230\u7684\u8fb9\u754c\u6846\n        gt_boxes: \u8fb9\u754c\u6846\u6807\u7b7e\n        gt_labels: \u7c7b\u522b\u6807\u7b7e\n\n    Returns:\n\n    \"\"\"\n    matched_idxs = []\n    labels = []\n    # \u904d\u5386\u6bcf\u5f20\u56fe\u50cf\u7684proposals, gt_boxes, gt_labels\u4fe1\u606f\n    for proposals_in_image, gt_boxes_in_image, gt_labels_in_image in zip(proposals, gt_boxes, gt_labels):\n        if gt_boxes_in_image.numel() == 0:  # \u5982\u679c\u8be5\u5f20\u56fe\u50cf\u4e2d\u6ca1\u6709gt\u6846\uff0c\u5219\u76ee\u6807\u6846\u5e94\u8be5\u5168\u4e3a\u80cc\u666f\n            # background image\n            device = proposals_in_image.device\n            clamped_matched_idxs_in_image = torch.zeros(\n                (proposals_in_image.shape[0],), dtype=torch.int64, device=device\n            )\n            labels_in_image = torch.zeros(\n                (proposals_in_image.shape[0],), dtype=torch.int64, device=device\n            )\n        else:\n            #  set to self.box_similarity when https://github.com/pytorch/pytorch/issues/27495 lands\n            # \u8ba1\u7b97proposal\u4e0e\u6bcf\u4e2agt_box\u7684iou\u91cd\u5408\u5ea6\uff0cmatch_quality_matrix\u5c3a\u5bf8\u4e3a[ge_box\u8fb9\u754c\u6846\u6807\u7b7e\u6570\u91cf\uff0cRPN\u9884\u6d4b\u6846\u7684\u6570\u91cf(\u62fc\u63a5\u540e\u7684)]\n            # \u8fd9\u91cc\u4e0eRPN\u4e2d\u8ba1\u7b97\u951a\u70b9\u4e0e\u8fb9\u754c\u6846\u6807\u7b7e\u91cd\u5408\u5ea6\u7c7b\u4f3c\n            match_quality_matrix = box_ops.box_iou(gt_boxes_in_image, proposals_in_image)\n\n            # \u8ba1\u7b97proposal\u4e0e\u6bcf\u4e2agt_box\u5339\u914d\u7684iou\u6700\u5927\u503c\uff0c\u5e76\u8bb0\u5f55\u7d22\u5f15\uff0c\n            # iou &gt; high_threshold\u7d22\u5f15\u503c\u4e3a\u5bf9\u8c61\u7684\u7d22\u5f15\uff0ciou &lt; low_threshold\u7d22\u5f15\u503c\u4e3a -1\uff0c low_threshold &lt;= iou &lt; high_threshold\u7d22\u5f15\u503c\u4e3a -2\n            # \u8fd9\u91cc\u4e0eRPN\u4e2d\u7684\u5339\u914d\u7c7b\u4f3c\n            matched_idxs_in_image = self.proposal_matcher(match_quality_matrix)\n\n            # \u9650\u5236\u6700\u5c0f\u503c\uff0c\u9632\u6b62\u5339\u914d\u6807\u7b7e\u65f6\u51fa\u73b0\u8d8a\u754c\u7684\u60c5\u51b5\n            # \u6ce8\u610f-1, -2\u5bf9\u5e94\u7684gt\u7d22\u5f15\u4f1a\u8c03\u6574\u52300\uff0c\u8fd9\u91cc\u548cRPN\u4e2d\u4e00\u6837\uff0c\u4e3b\u8981\u7528\u4e8e\u4e3a\u6bcf\u4e2a\u9884\u6d4b\u6846\u5339\u914d\u56de\u5f52\u53c2\u6570\uff0c-1\u548c-2\u4e0d\u4ea7\u751f\u56de\u5f52\u635f\u5931\uff0c\u56e0\u6b64\u8fd9\u91cc\u65e0\u5f71\u54cd\n            clamped_matched_idxs_in_image = matched_idxs_in_image.clamp(min=0)\n            # \u83b7\u53d6\u9884\u6d4b\u6846proposal\u5339\u914d\u5230\u7684\u7c7b\u522b\u6807\u7b7e\uff0c\u6b64\u65f6\u80cc\u666f\u548c\u4e22\u5f03\u7684\u6837\u672c\u90fd\u88ab\u8d4b\u503c\u4e3a\u7b2c\u4e00\u4e2a\u7269\u4f53\u7684\u7c7b\u522b\uff0c\u540e\u7eed\u8fd8\u4f1a\u518d\u5904\u7406\n            labels_in_image = gt_labels_in_image[clamped_matched_idxs_in_image]\n            labels_in_image = labels_in_image.to(dtype=torch.int64)\n\n            # label background (below the low threshold)\n            # bg_inds\u80cc\u666f\u6837\u672c\u7684\u7d22\u5f15\uff0c\u6807\u7b7e\u8bbe\u7f6e\u4e3a0\n            bg_inds = matched_idxs_in_image == self.proposal_matcher.BELOW_LOW_THRESHOLD  # -1\n            labels_in_image[bg_inds] = 0\n\n            # label ignore proposals (between low and high threshold)\n            # ignore_inds\u4e22\u5f03\u6837\u672c\u7684\u7d22\u5f15\uff0c\u6807\u7b7e\u8bbe\u7f6e\u4e3a-1\n            ignore_inds = matched_idxs_in_image == self.proposal_matcher.BETWEEN_THRESHOLDS  # -2\n            labels_in_image[ignore_inds] = -1  # -1 is ignored by sampler\n\n        matched_idxs.append(clamped_matched_idxs_in_image)\n        labels.append(labels_in_image)\n    return matched_idxs, labels\n</code></pre>"},{"location":"detection/network/Faster_RCNN/ROI_Head/#roi_pooling","title":"ROI Pooling\u6a21\u5757","text":"<p>\u53ef\u76f4\u63a5\u7531\u5982\u4e0b\u51fd\u6570\u76f4\u63a5\u8c03\u53d6</p> <pre><code>torchvision.ops.MultiScaleRoIAlign(featmap_names, output_size, sampling_ratio, canonical_scale = 224, canonical_level = 4)\n</code></pre> <ul> <li><code>featmap_names</code>\uff1a\u7528\u4e8e\u6c60\u5316\u7684\u7279\u5f81\u56fe\u540d\u79f0\uff08\u952e\uff09\uff0c\u56e0\u6b64\u8f93\u5165\u65f6\u9700\u8981\u4f20\u5165\u5b57\u5178\u683c\u5f0f\u7684\u6570\u636e\uff0c\u503c\u8868\u793a\u76f8\u5e94\u7684\u7279\u5f81\u56fe</li> <li><code>output_size</code>\uff1a\u8f93\u51fa\u7279\u5f81\u7684\u5c3a\u5bf8</li> <li><code>sampling_ratio</code>\uff1a\u8868\u793a\u91c7\u6837\u7387</li> </ul> <p>\u5728\u505aroi_pooling\u65f6\uff0c\u8f93\u5165\u7279\u5f81\u56fe\u5b57\u5178\u7684\u952e\u5fc5\u987b\u4e0e<code>`featmap_names</code>\u5bf9\u5e94\u8d77\u6765</p>"},{"location":"detection/network/Faster_RCNN/ROI_Head/#roi","title":"ROI\u68c0\u6d4b\u5934","text":"<p>\u2003\u2003\u8fd9\u91ccROI\u68c0\u6d4b\u5934\u4f1a\u4e3a\u6bcf\u4e2aproposal\u5747\u5bf9\u6bcf\u4e2a\u7c7b\u522b\u9884\u6d4b\u4e00\u6b21\u7c7b\u522b\u5206\u6570\u4ee5\u53ca\u76f8\u5e94\u7684\u8fb9\u754c\u6846\u56de\u5f52\u53c2\u6570\uff0c\u5177\u4f53\u89c1\u9884\u6d4b\u6a21\u5757\u4e2d\u7684\u7a0b\u5e8f\u3002</p> <p>\u4e24\u5c42MLP\u7ed3\u6784</p> <pre><code>class TwoMLPHead(nn.Module):\n    \"\"\"\n    Standard heads for FPN-based models\n\n    Arguments:\n        in_channels (int): \u8f93\u5165\u7279\u5f81\u56fe\u7684\u901a\u9053\u6570\n        representation_size (int): \u9690\u85cf\u8282\u70b9\u7684\u6570\u91cf\n    \"\"\"\n\n    def __init__(self, in_channels, representation_size):\n        super(TwoMLPHead, self).__init__()\n        # \u5b9a\u4e49\u4e24\u5c42\u7ebf\u6027\u56de\u5f52\n        self.fc6 = nn.Linear(in_channels, representation_size)\n        self.fc7 = nn.Linear(representation_size, representation_size)\n\n    def forward(self, x):\n        # \u5148\u5c06\u7279\u5f81\u62c9\u76f4\uff0c\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u4e3a(batch*\u68c0\u6d4b\u5934\u6570\u91cf)\n        # \u6ce8\u610f\uff0c\u8fd9\u91cc\u5e76\u4e0d\u662f\u7ecf\u8fc7\u5168\u5c40\u5e73\u5747\u6c60\u5316\uff0c\u800c\u662f\u76f4\u63a5\u5c06\u7279\u5f81\u62c9\u76f4\n        x = x.flatten(start_dim=1)\n        # \u4f9d\u6b21\u7ecf\u8fc7fc\u548crelu\n        x = F.relu(self.fc6(x))\n        x = F.relu(self.fc7(x))\n\n        return x\n</code></pre> <p>\u9884\u6d4b\u6a21\u5757</p> <pre><code>class FastRCNNPredictor(nn.Module):\n    \"\"\"\n    Standard classification + bounding box regression layers\n    for Fast R-CNN.\n\n    Arguments:\n        in_channels (int): \u8f93\u5165\u7684\u8282\u70b9\u6570\u91cf\n        num_classes (int): \u5206\u7c7b\u6570\u91cf\uff0c\u5305\u62ec\u80cc\u666f\n    \"\"\"\n\n    def __init__(self, in_channels, num_classes):\n        super(FastRCNNPredictor, self).__init__()\n        # \u5b9a\u4e49\u4e24\u5c42\u7ebf\u6027\u56de\u5f52\uff0c\u5206\u522b\u9884\u6d4b\u6bcf\u4e2a\u8fb9\u754c\u6846\u7684\u6240\u8ff0\u7c7b\u522b\uff0c\u4ee5\u53ca\u8fb9\u754c\u6846\u56de\u5f52\u53c2\u6570\n        # \u8fd9\u91cc\u6709\u9884\u6d4b\u4e86\u4e00\u6b21\u56de\u5f52\u53c2\u6570\uff0c\u7528\u4e8e\u5fae\u8c03RPN\u9884\u6d4b\u7684\u7269\u4f53\u8fb9\u754c\u6846\n        # \u6ce8\u610f\uff0c\u8fd9\u91cc\u5bf9\u4e8e\u6bcf\u4e2a\u8fb9\u754c\u6846\u5747\u4e3a\u6240\u6709\u7c7b\u522b\u9884\u6d4b\u4e00\u6b21\u5206\u6570\u4ee5\u53ca\u5bf9\u5e94\u7684\u56de\u5f52\u53c2\u6570\n        self.cls_score = nn.Linear(in_channels, num_classes)\n        self.bbox_pred = nn.Linear(in_channels, num_classes * 4)\n\n    def forward(self, x):\n        if x.dim() == 4:\n            assert list(x.shape[2:]) == [1, 1]\n        # \u5c06\u7279\u5f81\u62c9\u76f4\n        x = x.flatten(start_dim=1)\n        # \u4f9d\u6b21\u9884\u6d4b\u5f97\u5206\u548c\u5bf9\u5e94\u7684\u8fb9\u754c\u6846\u56de\u5f52\u53c2\u6570\n        scores = self.cls_score(x)\n        bbox_deltas = self.bbox_pred(x)\n\n        return scores, bbox_deltas\n</code></pre>"},{"location":"detection/network/Faster_RCNN/ROI_Head/#roi_1","title":"ROI\u635f\u5931\u7684\u8ba1\u7b97","text":"<p>\u8fd9\u91cc\u53ea\u9488\u5bf9\u8bad\u7ec3\u8fc7\u7a0b</p> <pre><code>def fastrcnn_loss(class_logits, box_regression, labels, regression_targets):\n    # type: (Tensor, Tensor, List[Tensor], List[Tensor]) -&gt; Tuple[Tensor, Tensor]\n    \"\"\"\n    Computes the loss for Faster R-CNN.\n\n    Arguments:\n        class_logits : \u9884\u6d4b\u7684\u7c7b\u522b\u6982\u7387\u4fe1\u606f\uff0cshape=[num_anchors, num_classes]\n        box_regression : \u9884\u6d4b\u7684\u8fb9\u76ee\u6807\u754c\u6846\u56de\u5f52\u53c2\u6570\n        labels : \u771f\u5b9e\u7684\u7c7b\u522b\u4fe1\u606f(\u5373\u6807\u7b7e)\n        regression_targets : \u771f\u5b9e\u7684\u76ee\u6807\u8fb9\u754c\u6846\u56de\u5f52\u53c2\u6570\n\n    Returns:\n        classification_loss (Tensor)\n        box_loss (Tensor)\n    \"\"\"\n    # \u5c06\u540c\u4e00\u4e2abatch\u91cc\u7684\u6807\u7b7e\u6cbf\u7b2c\u4e00\u7ef4\u5ea6\u5408\u5e76\uff0c\u7b2c\u4e00\u7ef4\u5ea6\u5c3a\u5bf8\u4e3abatch*512(512\u4e3a\u53c2\u4e0e\u635f\u5931\u8ba1\u7b97\u9ed8\u8ba4\u7684proposal\u6570\u91cf)\n    labels = torch.cat(labels, dim=0)\n    regression_targets = torch.cat(regression_targets, dim=0)\n\n    # \u8ba1\u7b97\u7c7b\u522b\u635f\u5931\u4fe1\u606f\uff0clabel\u4e3a0\u65f6\u8868\u793a\u80cc\u666f\u7c7b\u522b\n    classification_loss = F.cross_entropy(class_logits, labels)\n\n    # \u5f97\u5230\u6807\u7b7e\u7c7b\u522b\u5927\u4e8e0\u7684proposal\u7d22\u5f15\uff0c\u5373\u975e\u80cc\u666f\u7c7b\u522b\uff0c\u7528\u4e8e\u8ba1\u7b97\u56de\u5f52\u53c2\u6570\u635f\u5931\n    sampled_pos_inds_subset = torch.where(torch.gt(labels, 0))[0]\n\n    # \u5f97\u5230\u6807\u7b7e\u7c7b\u522b\u5927\u4e8e0\u7684\u7c7b\u522b\u4fe1\u606f\uff0c\u7528\u4e8e\u7d22\u5f15\u56de\u5f52\u53c2\u6570\n    # \u56e0\u4e3a\u5bf9\u4e8e\u6bcf\u4e2aproposal\uff0c\u7f51\u7edc\u4f1a\u4e3a\u6bcf\u4e2a\u7c7b\u522b\u5747\u9884\u6d4b\u4e00\u4e2a\u56de\u5f52\u53c2\u6570\uff0c\u56e0\u6b64\u9700\u8981\u5229\u7528\u7c7b\u522b\u4fe1\u606f\u5c06\u6307\u5b9a\u7c7b\u522b\u7684\u56de\u5f52\u53c2\u6570\u63d0\u53d6\u51fa\u6765\n    labels_pos = labels[sampled_pos_inds_subset]\n\n    # shape=[num_proposal, num_classes]\n    N, num_classes = class_logits.shape\n    # \u6539\u53d8\u5f62\u72b6\n    box_regression = box_regression.reshape(N, -1, 4)\n\n    # \u8ba1\u7b97\u8fb9\u754c\u6846\u635f\u5931\u4fe1\u606f\n    box_loss = det_utils.smooth_l1_loss(\n        # \u83b7\u53d6\u6307\u5b9a\u7d22\u5f15proposal\u7684\u6307\u5b9a\u7c7b\u522b\u56de\u5f52\u53c2\u6570\u7684\u9884\u6d4b\u4fe1\u606f\uff0c\u7d22\u5f15\u4e24\u6b21\n        box_regression[sampled_pos_inds_subset, labels_pos],\n        # \u56de\u5f52\u53c2\u6570\u7684\u6807\u7b7e\n        regression_targets[sampled_pos_inds_subset],\n        beta=1 / 9,\n        size_average=False,\n    ) / labels.numel()\n\n    return classification_loss, box_loss\n</code></pre>"},{"location":"detection/network/Faster_RCNN/ROI_Head/#_6","title":"\u540e\u5904\u7406\u6a21\u5757","text":"<p>\u8fd9\u91cc\u53ea\u9488\u5bf9\u6d4b\u8bd5\u8fc7\u7a0b\uff0c\u5305\u62ec\uff1a</p> <ul> <li>\u6839\u636eRPN\u6a21\u5757\u4e2d\u9884\u6d4b\u7684\u8fb9\u754c\u6846proposal\u4ee5\u53caROI Head\u9884\u6d4b\u7684\u56de\u5f52\u53c2\u6570\u8ba1\u7b97\u51fa\u6700\u7ec8bbox\u5750\u6807</li> <li>\u5c06\u8d8a\u754c(\u8d85\u51fa\u56fe\u50cf\u8303\u56f4)\u7684\u8fb9\u754c\u6846\u5750\u6807\u8c03\u6574\u5230\u8fb9\u754c\u4e0a</li> <li>\u5bf9\u9884\u6d4b\u7c7b\u522b\u7ed3\u679c\u8fdb\u884csoftmax\u5904\u7406\uff0c\u5f97\u5230\u6982\u7387\u503c</li> <li>\u79fb\u9664\u6982\u7387\u8fc7\u5c0f\u7684\u76ee\u6807\uff08\u5148\u7ecf\u8fc7softmax\uff0c\u518d\u8fdb\u884c\u79fb\u9664\uff09</li> <li>\u79fb\u9664\u6240\u6709\u80cc\u666f\u7684\u9884\u6d4b\u4fe1\u606f</li> <li>\u79fb\u9664\u5c0f\u5c3a\u5bf8\u76ee\u6807</li> <li>\u6267\u884c\u975e\u6781\u5927\u503c\u6291\u5236\u5904\u7406\uff08NMS\uff09\uff0c\u5e76\u4e14\u6309\u9884\u6d4b\u5206\u6570\u8fdb\u884c\u6392\u5e8f</li> <li>\u6839\u636e\u6392\u5e8f\u60c5\u51b5\u9009\u53d6\u524dtopk\u4e2a\u76ee\u6807</li> </ul> <pre><code>def postprocess_detections(self,\n                           class_logits,    # type: Tensor\n                           box_regression,  # type: Tensor\n                           proposals,       # type: List[Tensor]\n                           image_shapes     # type: List[Tuple[int, int]]\n                           ):\n    # type: (...) -&gt; Tuple[List[Tensor], List[Tensor], List[Tensor]]\n    \"\"\"\n    Args:\n        class_logits: \u7f51\u7edc\u9884\u6d4b\u7c7b\u522b\u6982\u7387\u4fe1\u606f\n        box_regression: \u7f51\u7edc\u9884\u6d4b\u7684\u8fb9\u754c\u6846\u56de\u5f52\u53c2\u6570\n        proposals: rpn\u8f93\u51fa\u7684proposal\n        image_shapes: \u6253\u5305\u6210batch\u524d\u6bcf\u5f20\u56fe\u50cf\u7684\u5bbd\u9ad8\n\n    Returns:\n\n    \"\"\"\n    device = class_logits.device\n    # \u9884\u6d4b\u76ee\u6807\u7c7b\u522b\u6570\n    num_classes = class_logits.shape[-1]\n\n    # \u83b7\u53d6\u6bcf\u5f20\u56fe\u50cf\u7684\u9884\u6d4bbbox\u6570\u91cf\n    boxes_per_image = [boxes_in_image.shape[0] for boxes_in_image in proposals]\n    # \u6839\u636eproposal\u4ee5\u53ca\u9884\u6d4b\u7684\u56de\u5f52\u53c2\u6570\u8ba1\u7b97\u51fa\u6700\u7ec8bbox\u5750\u6807\n    pred_boxes = self.box_coder.decode(box_regression, proposals)\n\n    # \u5bf9\u9884\u6d4b\u7c7b\u522b\u7ed3\u679c\u8fdb\u884csoftmax\u5904\u7406\uff0c\u5f97\u5230\u6982\u7387\u503c\uff0c\u540e\u7eed\u518d\u5c06\u6982\u7387\u8fc7\u5c0f\u76ee\u6807\u7684\u5220\u9664\n    pred_scores = F.softmax(class_logits, -1)\n\n    # split boxes and scores per image\n    # \u6839\u636e\u6bcf\u5f20\u56fe\u50cf\u7684\u9884\u6d4bbbox\u6570\u91cf\u5206\u5272\u7ed3\u679c\n    pred_boxes_list = pred_boxes.split(boxes_per_image, 0)\n    pred_scores_list = pred_scores.split(boxes_per_image, 0)\n\n    all_boxes = []\n    all_scores = []\n    all_labels = []\n    # \u904d\u5386\u6bcf\u5f20\u56fe\u50cf\u9884\u6d4b\u4fe1\u606f\n    for boxes, scores, image_shape in zip(pred_boxes_list, pred_scores_list, image_shapes):\n        # \u88c1\u526a\u9884\u6d4b\u7684boxes\u4fe1\u606f\uff0c\u5c06\u8d8a\u754c\u7684\u5750\u6807\u8c03\u6574\u5230\u56fe\u7247\u8fb9\u754c\u4e0a\n        boxes = box_ops.clip_boxes_to_image(boxes, image_shape)\n\n        # \u4e3a\u6bcf\u4e2a\u9884\u6d4b\u5206\u6570\u521b\u5efa\u5bf9\u5e94\u7684\u7c7b\u522b\u4fe1\u606f\uff0c\u8fd9\u91ccroi head\u4f1a\u4e3a\u6bcf\u4e2aproposal\u5747\u5bf9\u6240\u6709\u7c7b\u522b\u9884\u6d4b\u4e00\u6b21(\u5206\u6570\u3001\u56de\u5f52\u53c2\u6570)\n        labels = torch.arange(num_classes, device=device)\n        labels = labels.view(1, -1).expand_as(scores)\n\n        # remove prediction with the background label\n        # \u79fb\u9664\u7d22\u5f15\u4e3a0\u7684\u6240\u6709\u9884\u6d4b\u4fe1\u606f\uff080\u4ee3\u8868\u80cc\u666f\uff09\n        boxes = boxes[:, 1:]\n        scores = scores[:, 1:]\n        labels = labels[:, 1:]\n\n        # \u5c06\u6240\u6709\u7684\u9884\u6d4b\u7c7b\u522b\u53d8\u4e3a\u72ec\u7acb\u7684\u4e2a\u4f53\uff0c\u7b2c\u4e00\u7ef4\u5ea6\u5c3a\u5bf8\u5747\u4e3a:proposal\u6570\u91cf*\u5206\u7c7b\u6570\u91cf\n        boxes = boxes.reshape(-1, 4)\n        scores = scores.reshape(-1)\n        labels = labels.reshape(-1)\n\n        # remove low scoring boxes\n        # \u79fb\u9664\u4f4e\u6982\u7387\u76ee\u6807\uff0cself.scores_thresh=0.05\n        # gt: Computes input &gt; other element-wise.\n        inds = torch.where(torch.gt(scores, self.score_thresh))[0]\n        boxes, scores, labels = boxes[inds], scores[inds], labels[inds]\n\n        # remove empty boxes\n        # \u79fb\u9664\u5c0f\u76ee\u6807\n        keep = box_ops.remove_small_boxes(boxes, min_size=1.)\n        boxes, scores, labels = boxes[keep], scores[keep], labels[keep]\n\n        # non-maximun suppression, independently done per class\n        # \u6267\u884cnms\u5904\u7406\uff0c\u6267\u884c\u540e\u7684\u7ed3\u679c\u4f1a\u6309\u7167scores\u4ece\u5927\u5230\u5c0f\u8fdb\u884c\u6392\u5e8f\u8fd4\u56de\n        keep = box_ops.batched_nms(boxes, scores, labels, self.nms_thresh)\n\n        # \u83b7\u53d6scores\u6392\u5728\u524dtopk\u4e2a\u9884\u6d4b\u76ee\u6807\n        keep = keep[:self.detection_per_img]\n        boxes, scores, labels = boxes[keep], scores[keep], labels[keep]\n        # \u5c06\u9884\u6d4b\u7ed3\u679c\u50a8\u5b58\n        all_boxes.append(boxes)\n        all_scores.append(scores)\n        all_labels.append(labels)\n\n    return all_boxes, all_scores, all_labels\n</code></pre> <p>\u8c03\u6574\u8d8a\u754c\u8fb9\u754c\u6846</p> <pre><code>def clip_boxes_to_image(boxes, size):\n    # type: (Tensor, Tuple[int, int]) -&gt; Tensor\n    \"\"\"\n    \u8f93\u5165\u88c1\u526a\u9884\u6d4b\u7684boxes\u4fe1\u606f\uff0c\u5c06\u8d8a\u754c\u7684\u5750\u6807\u8c03\u6574\u5230\u56fe\u7247\u8fb9\u754c\u4e0a\n    Arguments:\n        boxes (Tensor[N, 4]): \u8fb9\u754c\u6846\u5750\u6807 (x1, y1, x2, y2)\n        size (Tuple[height, width]): \u56fe\u7247\u5c3a\u5bf8\n\n    Returns:\n        clipped_boxes (Tensor[N, 4]): \u8c03\u6574\u540e\u7684\u5750\u6807\n    \"\"\"\n    dim = boxes.dim()\n    # \u5f97\u5230x\u5750\u6807\uff0c\u5c3a\u5bf8\u4e3a(\u8fb9\u754c\u6846\u6570\u91cf,2)\n    boxes_x = boxes[..., 0::2]\n    # \u5f97\u5230y\u5750\u6807\uff0c\u5c3a\u5bf8\u548cx\u5c3a\u5bf8\u76f8\u540c\n    boxes_y = boxes[..., 1::2]\n    # \u5f97\u5230\u9ad8\u3001\u5bbd\uff0c\u7528\u4e8e\u9650\u5236x\uff0cy\u5750\u6807\n    height, width = size\n    if torchvision._is_tracing():\n        boxes_x = torch.max(boxes_x, torch.tensor(0, dtype=boxes.dtype, device=boxes.device))\n        boxes_x = torch.min(boxes_x, torch.tensor(width, dtype=boxes.dtype, device=boxes.device))\n        boxes_y = torch.max(boxes_y, torch.tensor(0, dtype=boxes.dtype, device=boxes.device))\n        boxes_y = torch.min(boxes_y, torch.tensor(height, dtype=boxes.dtype, device=boxes.device))\n    else:  \n        # \u4e00\u822c\u6267\u884c\u8fd9\u91cc\n        # \u9650\u5236x\u5750\u6807\u8303\u56f4\u5728[0,width]\u4e4b\u95f4\n        boxes_x = boxes_x.clamp(min=0, max=width)\n        # \u9650\u5236y\u5750\u6807\u8303\u56f4\u5728[0,height]\u4e4b\u95f4\n        boxes_y = boxes_y.clamp(min=0, max=height)\n    # \u5408\u5e76\n    clipped_boxes = torch.stack((boxes_x, boxes_y), dim=dim)\n    # \u5c06\u6570\u636e\u5f62\u72b6\u53d8\u4e3a\u4e0e\u8f93\u5165\u6570\u636e\u76f8\u540c\u7684\u5f62\u72b6\n    return clipped_boxes.reshape(boxes.shape)\n</code></pre> <p>\u521d\u6b65\u5b8c\u7a3f\u4e8e\uff1a2022\u5e742\u670816\u65e5</p>"},{"location":"detection/network/Faster_RCNN/RPN/","title":"Faster R-CNN\uff1aRPN\u6a21\u5757","text":""},{"location":"detection/network/Faster_RCNN/RPN/#_1","title":"\u7b80\u4ecb","text":"<p>\u2003\u2003\u76ee\u7684\uff1a\u9884\u6d4b\u51fa\u56fe\u50cf\u4e2d\u76ee\u6807\u6240\u5728\u7684\u4f4d\u7f6e</p> <p>\u2003\u2003\u8f93\u5165\uff1a\u7279\u5f81\u56fe</p> <p>\u2003\u2003\u8f93\u51fa\uff1a\u7269\u4f53\u8fb9\u754c\u6846\uff0c\u5927\u81f4\u5c06\u56fe\u50cf\u4e2d\u7684\u7269\u4f53\u6807\u6ce8\u51fa\u6765</p> <p>\u2003\u2003\u6a21\u5757\u6d41\u7a0b\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u635f\u5931\u8ba1\u7b97\u8fc7\u7a0b\uff1a</p> <p> <p></p> <p></p> <p>\u6d41\u7a0b\u56fe\u539f\u521b\uff0c\u4f7f\u7528\u8bf7\u544a\u77e5</p>"},{"location":"detection/network/Faster_RCNN/RPN/#_2","title":"\u7ec6\u8282","text":"<p>\u7f51\u7edc\u7ed3\u6784</p> <ul> <li>\u521d\u59cb\u9ed8\u8ba4\u53ea\u91c7\u7528\u6700\u540e\u4e00\u5c42\u7279\u5f81\u8fdb\u884c\u9884\u6d4b\uff0c\u951a\u70b9\u5c3a\u5ea6\u4e3a128\u3001256\u3001512\uff0c\u6bcf\u79cd\u5c3a\u5ea6\u518d\u8bbe\u7f6e3\u79cd\u6bd4\u4f8b\\{1:2\u30011:1\u30012:1\\}\uff0c\u56e0\u6b64\u6bcf\u4e2a\u7279\u5f81\u50cf\u7d20\u70b9\u4f1a\u5bf9\u5e949\u4e2a\u951a\u70b9\uff1b</li> <li>RPN\u4e2d\u951a\u70b9\u9884\u6d4b\u7c7b\u522b\u53ea\u6709\u4e24\u7c7b\uff0c\u524d\u666f\u548c\u80cc\u666f\uff1b</li> <li>\u6bcf\u4e2a\u951a\u70b9\u5bf9\u5e941\u7ec4\u56de\u5f52\u53c2\u6570\uff0c\u5bf9\u5e94\u524d\u666f\u7684\u56de\u5f52\u53c2\u6570\uff1b</li> <li>\u7f51\u7edc\u9884\u6d4b\u7684\u524d\u666fproposals\u518d\u4f20\u5165NMS\u8fd0\u7b97\uff0c\u53bb\u9664\u5197\u4f59\u7684\u8fb9\u754c\u6846\uff0cNMS\u9608\u503c\u9ed8\u8ba40.7\uff0c\u6700\u540e\u6309\u9884\u6d4b\u5206\u6570\u7b5b\u9009\u51fa\u524d2000\u4e2aproposals\u4f20\u5165ROI Head\u6a21\u5757\uff1b</li> </ul> <p>\u8bad\u7ec3\u9636\u6bb5</p> <ul> <li>\u5728\u951a\u70b9\u5339\u914d\u4e2d\uff0c\u4e0e\u7269\u4f53\u8fb9\u754c\u6846IOU\u503c\u5927\u4e8e0.7\u7684\u951a\u70b9\u8bbe\u7f6e\u4e3a\u524d\u666f\u951a\u70b9\uff08\u6b63\u6837\u672c\uff09\u3001IOU\u503c\u5c0f\u4e8e0.3\u7684\u8bbe\u7f6e\u4e3a\u80cc\u666f\u951a\u70b9\uff08\u8d1f\u6837\u672c\uff09\uff1b</li> <li>\u5728\u8bad\u7ec3RPN\u65f6\uff0c\u6bcf\u5f20\u56fe\u968f\u673a\u91c7\u6837256\u4e2a\u951a\u70b9\u8fdb\u884c\u8bad\u7ec3\uff0c\u6b63\u8d1f\u6837\u672c\u6bd4\u4f8b\u9ed8\u8ba41:1\uff0c\u5982\u679c\u6b63\u6837\u672c\u5c11\u4e8e128\uff0c\u5219\u7528\u8d1f\u6837\u672c\u586b\u5145\u3002\uff08\u8fd9\u91cc\u53ef\u4ee5\u7528Focal loss\u6539\u8fdb\uff09\uff1b</li> </ul>"},{"location":"detection/network/Faster_RCNN/RPN/#_3","title":"\u4ee3\u7801","text":"<p>\u6ce8\uff1aRPN\u6a21\u5757\u4ee3\u7801\u6765\u6e90\u4e8ePyTorch\u5b98\u65b9\u5b9e\u73b0\u7684Faster R-CNN\u7b97\u6cd5\uff0c\u603b\u7684\u7f51\u7edc\u6a21\u578b\u53ef\u7531\u5982\u4e0b\u51fd\u6570\u6307\u4ee4\u76f4\u63a5\u8c03\u53d6\uff1a</p> <pre><code>torchvision.models.detection.FasterRCNN()\n</code></pre> <p>\u53c2\u8003\u94fe\u63a5\uff1a</p> <ul> <li>https://www.bilibili.com/video/BV1of4y1m7nj</li> <li>https://github.com/WZMIAOMIAO/deep-learning-for-image-processing</li> </ul>"},{"location":"detection/network/Faster_RCNN/RPN/#rpn","title":"RPN\u6a21\u5757\u7ed3\u6784","text":"<pre><code>class RegionProposalNetwork(torch.nn.Module):\n    __annotations__ = {\n        'box_coder': det_utils.BoxCoder,\n        'proposal_matcher': det_utils.Matcher,\n        'fg_bg_sampler': det_utils.BalancedPositiveNegativeSampler,\n        'pre_nms_top_n': Dict[str, int],\n        'post_nms_top_n': Dict[str, int],\n    }\n\n    def __init__(self, anchor_generator, head,\n                 fg_iou_thresh, bg_iou_thresh,  # fg\u524d\u666f\u76ee\u6807\uff0cbg\u80cc\u666f\u76ee\u6807\n                 batch_size_per_image, positive_fraction,  # RPN\u8ba1\u7b97\u635f\u5931\u65f6\uff0c\u4f7f\u7528\u7684\u6837\u672c\u6570\u548c\u6b63\u6837\u672c\u5360\u6bd4\n                 pre_nms_top_n, post_nms_top_n, nms_thresh, score_thresh=0.0):  # nms\u5904\u7406\u4e4b\u524d\uff0c\u9488\u5bf9\u6bcf\u4e2a\u7279\u5f81\u5c42\u4fdd\u7559\u7684\u76ee\u6807\u4e2a\u6570\uff0cnms\u4e4b\u540e\u6240\u6709\u7279\u5f81\u5c42\u5269\u4f59\u7684\u6570\u91cf\uff0cnms\u5904\u7406\u65f6\uff0c\u53d6\u5b9a\u7684\u9608\u503c\n        super(RegionProposalNetwork, self).__init__()\n        # \u951a\u70b9\u751f\u6210\u5668\n        self.anchor_generator = anchor_generator\n        # RPN\u68c0\u6d4b\u5934\n        self.head = head\n        # \u5b9a\u4e49\u8fb9\u754c\u6846\u7684\u7f16\u7801-\u89e3\u7801\u65b9\u6cd5\n        self.box_coder = det_utils.BoxCoder(weights=(1.0, 1.0, 1.0, 1.0))\n\n        # use during training\n        # \u8ba1\u7b97anchors\u4e0e\u771f\u5b9ebbox\u7684iou(\u4e24\u7ec4\u6846\u4e4b\u95f4\u7684iou)\n        self.box_similarity = box_ops.box_iou\n        # \u5224\u65ad\u6b63\u8d1f\u6837\u672c(\u524d\u540e\u666f)\u6240\u7528\u5230\u7684\u65b9\u6cd5\n        self.proposal_matcher = det_utils.Matcher(\n            # \u5f53iou\u5927\u4e8efg_iou_thresh(0.7)\u65f6\u89c6\u4e3a\u6b63\u6837\u672c(\u524d\u666f)\n            fg_iou_thresh,\n            # \u5f53iou\u5c0f\u4e8ebg_iou_thresh(0.3)\u65f6\u89c6\u4e3a\u8d1f\u6837\u672c(\u80cc\u666f)\n            bg_iou_thresh,\n            allow_low_quality_matches=True\n        )\n        # \u8ba1\u7b97\u635f\u5931\u65f6\uff0c\u5bf9\u6b63\u6837\u672c\u548c\u8d1f\u6837\u672c\u7684\u91c7\u6837\u7684\u65b9\u6cd5(\u603b\u6570\u591a\u5c11\uff0c\u6b63\u6837\u672c\u591a\u5c11\u6bd4\u4f8b)\n        self.fg_bg_sampler = det_utils.BalancedPositiveNegativeSampler(\n            batch_size_per_image, positive_fraction  # 256, 0.5\n        )\n\n        # NMS\u5904\u7406\u4e4b\u524d\uff0c\u6bcf\u5c42\u7279\u5f81\u5c42\u6700\u591a\u4fdd\u7559\u7684\u9884\u6d4b\u76ee\u6807\u6570\u91cf(\u4f9d\u636e\u9884\u6d4b\u5206\u6570\u7b5b\u9009)\n        self._pre_nms_top_n = pre_nms_top_n\n        # NMS\u5904\u7406\u540e\uff0c\u6240\u6709\u7279\u5f81\u5c42\u6700\u591a\u4fdd\u7559\u7684\u9884\u6d4b\u76ee\u6807\u603b\u6570(\u540c\u6837\u6839\u636e\u9884\u6d4b\u5206\u6570\u7b5b\u9009)\n        self._post_nms_top_n = post_nms_top_n\n        # NMS\u5904\u7406\u65f6\u7684\u9608\u503c\n        self.nms_thresh = nms_thresh\n        # \u9884\u6d4b\u5206\u6570\u4e0b\u9650\uff0c\u5c0f\u4e8e\u8be5\u503c\u7684\u9884\u6d4b\u5c06\u88ab\u8fc7\u6ee4\u6389\uff0c\u4e0d\u8fdb\u5165\u540e\u7eed\u7684ROI Head\u6a21\u5757\n        self.score_thresh = score_thresh\n        # \u9884\u6d4b\u76ee\u6807\u8fb9\u754c\u6846\u7684\u4e0b\u9650\uff0c\u5982\u679c\u76ee\u6807\u8fb9\u754c\u6846\u9ad8\u5bbd\u6709\u4e00\u4e2a\u5c0f\u4e8e\u6b64\u503c\uff0c\u5219\u4e5f\u88ab\u8fc7\u6ee4\u6389\uff0c\u4e0d\u8fdb\u5165\u540e\u7eed\u7684ROI Head\n        self.min_size = 1.\n\n    def forward(self,\n                images,        # type: ImageList\n                features,      # type: Dict[str, Tensor]\n                targets=None   # type: Optional[List[Dict[str, Tensor]]]\n                ):\n        # type: (...) -&gt; Tuple[List[Tensor], Dict[str, Tensor]]\n        \"\"\"\n        Arguments:\n            images (ImageList): images for which we want to compute the predictions\n            features (Dict[Tensor]): features computed from the images that are\n                used for computing the predictions. Each tensor in the list\n                correspond to different feature levels\n            targets (List[Dict[Tensor]): ground-truth boxes present in the image (optional).\n                If provided, each element in the dict should contain a field `boxes`,\n                with the locations of the ground-truth boxes.\n\n        Returns:\n            boxes (List[Tensor]): the predicted boxes from the RPN, one Tensor per\n                image.\n            losses (Dict[Tensor]): the losses for the model during training. During\n                testing, it is an empty dict.\n        \"\"\"\n        # RPN uses all feature maps that are available\n        # features\u662f\u6240\u6709\u9884\u6d4b\u7279\u5f81\u5c42\u7ec4\u6210\u7684OrderedDict\uff0c\u5982\u679c\u4f7f\u7528fpn\u7684\u8bdd\uff0c\u5171\u67095\u4e2a\u7279\u5f81\u5c42\uff0c\u5373\u8be5\u5b57\u5178\u4e2d\u6709\u4e94\u4e2a\u6570\u636e\n        features = list(features.values())\n\n        # \u9884\u6d4b\u6bcf\u4e2a\u9884\u6d4b\u7279\u5f81\u5c42\u4e0a\u6bcf\u4e2a\u50cf\u7d20\u70b9\u5b58\u5728\u76ee\u6807\u7684\u6982\u7387\u548cbboxes regression\u8fb9\u754c\u6846\u56de\u5f52\u53c2\u6570\n        # objectness\u548cpred_bbox_deltas\u90fd\u662flist\u3002objectness\u5c3a\u5bf8\u4e3a(b,\u951a\u70b9\u6570,h,w),pred_bbox_deltas\u5c3a\u5bf8\u4e3a(b,4*\u951a\u70b9\u6570,h,w)\n        objectness, pred_bbox_deltas = self.head(features)\n\n        # \u751f\u6210\u4e00\u4e2abatch\u56fe\u50cf\u7684\u6240\u6709anchors\u4fe1\u606f,list(tensor)\u5143\u7d20\u4e2a\u6570\u7b49\u4e8ebatch_size\u3002\n        # \u5f97\u5230\u6bcf\u4e2a\u56fe\u7247\u4e0a\u7684\u951a\u70b9\u6846\u7684\u5750\u6807\u4fe1\u606f\n        # anchors\u6570\u636e\u7c7b\u578b\u4e3a\u5217\u8868\u683c\u5f0f\uff0c\u5217\u8868\u957f\u5ea6\u4e3abatch\uff0c\u5217\u8868\u4e2d\u6bcf\u4e2a\u5143\u7d20\u5c3a\u5bf8\u5747\u4e3a(\u539f\u56fe\u4e0a\u951a\u70b9\u6570\u91cf,4)\uff0c\u951a\u70b9\u6570\u91cf\u4e0e\u53c2\u4e0e\u9884\u6d4b\u7684\u7279\u5f81\u56fe\u5bbd\u9ad8\u3001ratios\u6570\u91cf\u6709\u5173\uff0c\u8fd9\u91cc\u5c06\u6240\u6709\u7279\u5f81\u5c42\u4e0a\u7684\u951a\u70b9\u5408\u5e76\u4e86\n        anchors = self.anchor_generator(images, features)\n        # batch_size\n        num_images = len(anchors)\n\n        # numel() Returns the total number of elements in the input tensor.\n        # \u8ba1\u7b97\u6bcf\u4e2a\u9884\u6d4b\u7279\u5f81\u5c42\u4e0a\u7684\u5bf9\u5e94\u7684anchors\u6570\u91cf\u3002\u7279\u5f81\u5c42\u957f*\u5bbd*\u951a\u70b9\u6570\n        num_anchors_per_level_shape_tensors = [o[0].shape for o in objectness]\n        # \u5c06num_anchors_per_level\u4e2d\u7684\u539f\u8bc9\u6c42\u548c\uff0c\u5c31\u662fanchors\u4e2d\u5217\u8868\u5143\u7d20\u7684\u7b2c\u4e00\u7ef4\u5ea6\n        num_anchors_per_level = [s[0] * s[1] * s[2] for s in num_anchors_per_level_shape_tensors]\n        # \u8c03\u6574\u5185\u90e8tensor\u683c\u5f0f\u4ee5\u53cashape\u3002\u4ee5objectness\u4e3a\u4f8b\uff1a\u4ece[b,3,h,w]\u53d8\u4e3a[\u951a\u70b9\u6570,1]\n        objectness, pred_bbox_deltas = concat_box_prediction_layers(objectness,\n                                                                    pred_bbox_deltas)\n\n        # \u5c06\u9884\u6d4b\u7684bbox\u56de\u5f52\u53c2\u6570\u5e94\u7528\u5230anchors\u4e0a\u5f97\u5230\u6700\u7ec8\u9884\u6d4b\u7684\u8fb9\u754c\u6846\u5750\u6807\u3002\u56de\u5f52\u53c2\u6570\u4e0e\u951a\u70b9\u6846\u7ed3\u5408\uff0c\u5f97\u5230\u7269\u4f53\u6846\uff0c\u539f\u59cb\u56fe\u50cf\u4e0a\u7684\u7edd\u5bf9\u5750\u6807\n        # \u6ce8\u610f\u8fd9\u91cc\u5207\u65ad\u68af\u5ea6\uff0c\u540e\u7eedROI\u6a21\u5757\u7684\u635f\u5931\u4e0d\u4f1a\u5f71\u54cd\u5230RPN\u8fb9\u754c\u6846\u56de\u5f52\n        proposals = self.box_coder.decode(pred_bbox_deltas.detach(), anchors)\n        # \u8c03\u6574\u6570\u636e\u5f62\u72b6\uff0c\u5728\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\u8868\u793a\u5750\u6807\u4fe1\u606f\n        proposals = proposals.view(num_images, -1, 4)\n        # \u6b64\u65f6proposals\u5df2\u7ecf\u4ee3\u8868\u7269\u4f53\u6846\u4e86\n        # \u7b5b\u9664\u5c0fboxes\u6846\uff0cnms\u5904\u7406\uff0c\u6839\u636e\u9884\u6d4b\u6982\u7387\u83b7\u53d6\u524dpost_nms_top_n\u4e2a\u76ee\u6807\n        # \u8fd9\u91cc\u9009\u53d6\u4e24\u5343\u4e2a\u53ea\u662f\u4e3a\u4e86\u9001\u7ed9\u540e\u9762\u7684roi\u7528\u4e8e\u8fdb\u4e00\u6b65\u9884\u6d4b\u7c7b\u522b\u548c\u6821\u6b63\u76ee\u6807\u6846\n        # \u800cRPN\u8ba1\u7b97\u635f\u5931\u65f6\u662f\u4f20\u5165\u6240\u6709\u7684\u70b9\u8ba1\u7b97(\u5f53\u7136\u8ba1\u7b97\u635f\u5931\u65f6\u8fd8\u4f1a\u518d\u7b5b\u9009\u6b63\u8d1f\u6837\u672c\uff0c\u5728compute_loss\u65b9\u6cd5\u4e2d\u7b5b\u9009)\n        boxes, scores = self.filter_proposals(proposals, objectness, images.image_sizes, num_anchors_per_level)\n\n        losses = {}\n        # \u5982\u679c\u662f\u8bad\u7ec3\u9636\u6bb5\u7684\u8bdd\uff0c\u9700\u8981\u8ba1\u7b97\u635f\u5931\n        if self.training:\n            # \u5fc5\u987b\u6709\u6807\u7b7e\n            assert targets is not None\n            # \u8ba1\u7b97\u6bcf\u4e2aanchors\u6700\u5339\u914d\u7684gt(\u6807\u7b7e\u6846)\n            # labels\u8868\u793a\u6bcf\u4e2a\u951a\u70b9\u7684\u7c7b\u522b\u6807\u7b7e\uff0c\u524d\u666f(1.0)\uff0c\u80cc\u666f(0.0)\u4ee5\u53ca\u4e22\u5f03\u7684anchors(-1.0\uff0cIOU\u503c\u5904\u4e8e\u4e2d\u95f4)\n            # matched_gt_boxes\u8868\u793a\u9760\u8fd1\u6bcf\u4e2a\u951a\u70b9\u7684\u8fb9\u754c\u6846\u5750\u6807\uff0c\u80cc\u666f\u548c\u8981\u4e22\u5f03\u7684\u951a\u70b9\u5747\u8bbe\u7f6e\u4e3a\u7b2c\u4e00\u4e2a\u76ee\u6807\u7684\u8fb9\u754c\u6846\u5750\u6807\uff0c\u540e\u7eed\u7528\u4e0d\u5230\n            # \u8fd9\u91cc\u7684\u8fb9\u754c\u6846\u5750\u6807\u662f\u771f\u5b9e\u6807\u7b7e\u5750\u6807\uff0c\u4e0d\u662f\u56de\u5f52\u53c2\u6570\uff0c\u540e\u7eed\u8fd8\u9700\u8981\u5bf9\u6bcf\u4e2a\u951a\u70b9\u90fd\u8ba1\u7b97\u4e00\u6b21\u56de\u5f52\u53c2\u6570\n            # \u4ece\u800c\u8ba9\u951a\u70b9\u5bf9\u5e94\u7684\u533a\u57df\u4e0e\u76ee\u6807\u771f\u5b9e\u533a\u57df\u91cd\u5408\u8d77\u6765\n            # \u56e0\u6b64RPN\u5c31\u662f\u901a\u8fc7\u9884\u6d4b\u4f4d\u4e8e\u76ee\u6807\u533a\u57df\u5468\u56f4\u7684\u951a\u70b9\u4ee5\u53ca\u5176\u56de\u5f52\u53c2\u6570\u6765\u51c6\u786e\u7684\u9884\u6d4b\u76ee\u6807\u533a\u57df\u3002\n            labels, matched_gt_boxes = self.assign_targets_to_anchors(anchors, targets)\n            # \u7ed3\u5408anchors\u4ee5\u53ca\u5bf9\u5e94\u7684gt\uff0c\u8ba1\u7b97regression\u53c2\u6570\u3002\u8ba1\u7b97\u951a\u70b9\u4e0e\u5339\u914d\u7684gt\u6846\u4e4b\u95f4\u7684\u56de\u5f52\u53c2\u6570\u3002\n            # \u5373\u6307\u5b9a\u7684\u951a\u70b9\u4e0e\u951a\u70b9\u5bf9\u5e94\u7684gt\u6846\u4e4b\u95f4\u7684\u6807\u51c6\u56de\u5f52\u53c2\u6570\uff0c\u5f97\u5230RPN\u7684\u56de\u5f52\u6807\u7b7e\uff0c\u7528\u4e8e\u8ba1\u7b97\u635f\u5931\n            # \u8fd9\u91cc\u76f8\u5f53\u4e8e\u4e00\u4e2a\u9006\u8fd0\u7b97\uff0c\u5c06\u771f\u5b9e\u5750\u6807\u503c\u8f6c\u5316\u4e3a\u56de\u5f52\u53c2\u6570\n            # \u5373\u4f7f\u540c\u4e00\u4e2a\u7269\u4f53\uff0c\u9762\u5bf9\u4e0d\u540c\u7684\u951a\u70b9\u5c06\u4f1a\u5f97\u5230\u4e0d\u540c\u7684\u56de\u5f52\u53c2\u6570\n            regression_targets = self.box_coder.encode(matched_gt_boxes, anchors)\n            # \u8ba1\u7b97RPN\u7684\u5206\u7c7b\u635f\u5931\u548c\u56de\u5f52\u635f\u5931\uff0c\u4f20\u5165:\u9884\u6d4b\u7684\u76ee\u6807\u5206\u6570\uff0c\u9884\u6d4b\u7684\u5750\u6807\u56de\u5f52\u53c2\u6570\uff0c\u76ee\u6807\u6807\u7b7e(\u524d\u540e\u666f\u6807\u7b7e)\uff0c\u56de\u5f52\u53c2\u6570\u6807\u7b7e\n            loss_objectness, loss_rpn_box_reg = self.compute_loss(\n                objectness, pred_bbox_deltas, labels, regression_targets\n            )\n            losses = {\n                \"loss_objectness\": loss_objectness,\n                \"loss_rpn_box_reg\": loss_rpn_box_reg\n            }\n        # boxes\u8fd4\u56de\u7684\u662f\u7edd\u5bf9\u5750\u6807\u4e0b\u7684\u7269\u4f53\u6846\uff0c\u975e\u56de\u5f52\u53c2\u6570\n        return boxes, losses\n</code></pre>"},{"location":"detection/network/Faster_RCNN/RPN/#rpn_1","title":"RPN\u68c0\u6d4b\u5934","text":"<pre><code>class RPNHead(nn.Module):\n    \"\"\"\n    add a RPN head with classification and regression\n    \u901a\u8fc7\u6ed1\u52a8\u7a97\u53e3\u8ba1\u7b97\u9884\u6d4b\u76ee\u6807\u6982\u7387\u4e0ebbox regression\u8fb9\u754c\u6846\u56de\u5f52\u53c2\u6570\n\n    Arguments:\n        in_channels: \u8f93\u5165\u7279\u5f81\u56fe\u7684\u901a\u9053\u6570\n        num_anchors: \u951a\u70b9\u6570\u91cf\uff0c\u8868\u793a\u6bcf\u4e2a\u50cf\u7d20\u70b9\u5bf9\u5e94\u591a\u5c11\u4e2a\u68c0\u6d4b\u6846\uff0c\u4e0esize\u6570\u91cf\u548cratios\u6570\u91cf\u6709\u5173(\u4e58\u79ef)\n        \u4e00\u822c\u4e00\u4e2a\u7279\u5f81\u5c42\u5bf9\u5e94\u4e00\u4e2asize\uff0c\u56e0\u6b64\u951a\u70b9\u6570\u91cf\u7531\u68c0\u6d4b\u6846\u9ad8\u5bbd\u6bd4\u4f8bratios\u7684\u6570\u91cf\u51b3\u5b9a\n        \u8fd9\u91cc\u9ed8\u8ba43\u4e2a\uff0c\u6bd4\u4f8b\u5206\u522b\u4e3a[0.5,1.0,1.5]\uff0c\u56e0\u6b64\u4e00\u4e2a\u50cf\u7d20\u70b9\u5bf9\u5e94\u4e09\u4e2a\u951a\u70b9\n    \"\"\"\n\n    def __init__(self, in_channels, num_anchors):\n        super(RPNHead, self).__init__()\n        # 3x3 \u6ed1\u52a8\u7a97\u53e3\n        self.conv = nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1)\n        # \u8fd9\u91ccnum_anchors\u53d8\u91cf\u9ed8\u8ba4\u4e3a3(\u4e00\u4e2a\u7279\u5f81\u5c42\u5bf9\u5e94\u4e00\u4e2asize\uff0c\u4e00\u4e2asize\u5bf9\u5e94\u4e09\u4e2aratios\uff0c\u56e0\u6b64\u4e00\u5171\u4e09\u4e2a\u951a\u70b9)\uff0c\u76f8\u5f53\u4e8e\u4e00\u4e2a\u68c0\u6d4b\u5934\u5bf9\u4e00\u4e2a\u70b9\u53ea\u68c0\u6d4b\u4e09\u6b21\n        # size\u4e0e\u611f\u53d7\u91ce\u7c7b\u4f3c\uff0c\u6bcf\u4e2a\u7279\u5f81\u5c42\u90fd\u5bf9\u5e94\u4e00\u4e2a\u611f\u53d7\u91ce\uff0c\u800c\u7279\u5f81\u56fe\u4e0a\u6bcf\u4e2a\u50cf\u7d20\u70b9\u5747\u5bf9\u5e94\u4e09\u4e2aratios\uff0c\u5373\u6bcf\u4e2a\u50cf\u7d20\u70b9\u5bf9\u5e94\u4e09\u4e2a\u951a\u70b9\u68c0\u6d4b\u6846\uff0c\n        # \u53ef\u4ee5\u901a\u8fc7\u4fee\u6539ratios\u6765\u4fee\u6539\u6bcf\u4e2a\u50cf\u7d20\u70b9\u5bf9\u5e94\u7684\u68c0\u6d4b\u6846\u5f62\u72b6(\u6570\u91cf)\n        # \u8ba1\u7b97\u9884\u6d4b\u7684\u76ee\u6807\u5206\u6570\uff08\u8fd9\u91cc\u7684\u76ee\u6807\u53ea\u662f\u6307\u524d\u666f\u6216\u8005\u80cc\u666f\uff09\uff0c\u751f\u6210k\u4e2a\u5206\u6570\uff0c\u8fd9\u91cc\u7684k\u8868\u793a\u6bcf\u4e2a\u7279\u5f81\u5c42\u4e2dsize\u4e0eratios\u7684\u4e58\u79ef\n        self.cls_logits = nn.Conv2d(in_channels, num_anchors, kernel_size=1, stride=1)\n        # \u8ba1\u7b97\u9884\u6d4b\u7684\u76ee\u6807bbox regression\u53c2\u6570\uff0c\u751f\u62104k\u4e2a\u53c2\u6570\n        self.bbox_pred = nn.Conv2d(in_channels, num_anchors * 4, kernel_size=1, stride=1)\n        # \u521d\u59cb\u5316\u53c2\u6570\n        for layer in self.children():\n            if isinstance(layer, nn.Conv2d):\n                torch.nn.init.normal_(layer.weight, std=0.01)\n                torch.nn.init.constant_(layer.bias, 0)\n\n    def forward(self, x):  # \u4f20\u5165\u9884\u6d4b\u7279\u5f81\u5c42\n        # type: (List[Tensor]) -&gt; Tuple[List[Tensor], List[Tensor]]\n        # \u521d\u59cb\u5316\u5b58\u50a8\u9884\u6d4b\u5206\u6570\u548c\u8fb9\u754c\u6846\u56de\u5f52\u53c2\u6570\u7684\u53d8\u91cf\n        logits = []\n        bbox_reg = []\n        # \u904d\u5386\u6bcf\u4e2a\u9884\u6d4b\u7279\u5f81\u5c42\n        for i, feature in enumerate(x):\n            # \u9996\u5148\u7ecf\u8fc7\u4e00\u5c42\u5377\u79ef\u4e0erelu\n            t = F.relu(self.conv(feature))\n            # \u4e4b\u540e\u5206\u522b\u7ecf\u8fc7\u5377\u79ef\uff0c\u5f97\u5230\u9884\u6d4b\u5206\u6570\u548c\u5bf9\u5e94\u7684\u8fb9\u754c\u6846\u56de\u5f52\u53c2\u6570\n            # \u8fd9\u91cc\u7684\u9884\u6d4b\u5206\u6570\u4e0e\u56de\u5f52\u53c2\u6570\u5747\u662f\u50cf\u7d20\u70b9\u7ea7\u522b\u7684\uff0c\u5373\u7279\u5f81\u56fe\u4e0a\u6bcf\u4e2a\u50cf\u7d20\u70b9\u5747\u5bf9\u5e94\u4e00\u4e2a\u5206\u6570\u548c\u56db\u4e2a\u56de\u5f52\u53c2\u6570\n            logits.append(self.cls_logits(t))\n            bbox_reg.append(self.bbox_pred(t))\n        # \u4f9d\u6b21\u8fd4\u56de\u9884\u6d4b\u5206\u6570\u548c\u8fb9\u754c\u6846\u56de\u5f52\u53c2\u6570\n        # \u5c3a\u5bf8\u5206\u522b\u4e3a(b,k,w,h),(b,4k,w,h)\uff0cb\u8868\u793abatch\uff0ck\u8868\u793a\u7279\u5f81\u56fe\u4e0a\u7684\u951a\u70b9\u6570\u91cf\uff0c\u5373\u4e00\u4e2a\u50cf\u7d20\u70b9\u4ee3\u8868\u591a\u5c11\u4e2a\u951a\u70b9\u68c0\u6d4b\u6846\n        return logits, bbox_reg\n</code></pre>"},{"location":"detection/network/Faster_RCNN/RPN/#_4","title":"\u5408\u5e76\u9884\u6d4b\u7ed3\u679c","text":"<pre><code>def concat_box_prediction_layers(box_cls, box_regression):\n    # type: (List[Tensor], List[Tensor]) -&gt; Tuple[Tensor, Tensor]\n    \"\"\"\n    \u5bf9box_cla\u548cbox_regression\u4e24\u4e2alist\u4e2d\u7684\u6bcf\u4e2a\u9884\u6d4b\u7279\u5f81\u5c42\u7684\u9884\u6d4b\u4fe1\u606f\n    \u7684tensor\u6392\u5217\u987a\u5e8f\u4ee5\u53cashape\u8fdb\u884c\u8c03\u6574 -&gt; [N, -1, C]\n    Args:\n        box_cls: \u6bcf\u4e2a\u9884\u6d4b\u7279\u5f81\u5c42\u4e0a\u7684\u9884\u6d4b\u76ee\u6807\u6982\u7387\n        box_regression: \u6bcf\u4e2a\u9884\u6d4b\u7279\u5f81\u5c42\u4e0a\u7684\u9884\u6d4b\u76ee\u6807bboxes regression\u53c2\u6570\n    Returns:\n\n    \"\"\"\n    box_cls_flattened = []  # \u5b58\u50a8\u9884\u6d4b\u5206\u6570\n    box_regression_flattened = []  # \u5b58\u50a8\u9884\u6d4b\u6846\n\n    # \u904d\u5386\u6bcf\u4e2a\u9884\u6d4b\u7279\u5f81\u5c42\n    for box_cls_per_level, box_regression_per_level in zip(box_cls, box_regression):\n        # [batch_size, anchors_num_per_position * classes_num, height, width]\n        # \u6ce8\u610f\uff0c\u5f53\u8ba1\u7b97RPN\u4e2d\u7684proposal\u65f6\uff0cclasses_num=1,\u53ea\u533a\u5206\u76ee\u6807\u548c\u80cc\u666f\n        N, AxC, H, W = box_cls_per_level.shape\n        # # [batch_size, anchors_num_per_position * 4, height, width]\n        Ax4 = box_regression_per_level.shape[1]\n        # anchors_num_per_position\uff0c\u8fd9\u91cc\u8868\u793a\u6bcf\u4e2a\u50cf\u7d20\u70b9\u4e0a\u7684\u951a\u70b9\u6570\u91cf\uff0c\u5373ratios\u7684\u957f\u5ea6\uff0c\u9ed8\u8ba43\n        A = Ax4 // 4\n        # classes_num\u3002\u5224\u65ad\u662f\u5426\u662f\u524d\u666f\uff0c\u56e0\u6b64\u53ea\u6709\u4e00\u4e2a\u7c7b\n        C = AxC // A\n\n        # [N, -1, C]\uff0c\u8c03\u6362\u7ef4\u5ea6\u4fe1\u606f\uff0c\u4fbf\u4e8e\u540e\u9762\u4e0e\u951a\u70b9\u7ed3\u5408\uff0c\u4e5f\u4fbf\u4e8e\u8fc7\u6ee4\uff0c\u8fd9\u91ccC=1\uff0c\u8868\u793a\u662f\u5426\u662f\u524d\u666f\n        box_cls_per_level = permute_and_flatten(box_cls_per_level, N, A, C, H, W)\n        box_cls_flattened.append(box_cls_per_level)\n\n        # [N, -1, C]\uff0c\u548c\u4e0a\u9762\u4e00\u6837\uff0c\u8c03\u6362\u7ef4\u5ea6\uff0c\u8fd9\u91ccC=4\uff0c\u8868\u793a\u56db\u4e2a\u56de\u5f52\u53c2\u6570\n        box_regression_per_level = permute_and_flatten(box_regression_per_level, N, A, 4, H, W)\n        box_regression_flattened.append(box_regression_per_level)\n    # flatten(0, -2)\u8868\u793a\u4e00\u76f4\u5c55\u5e73\u5230\u5012\u6570\u7b2c\u4e8c\u4e2a\u7ef4\u5ea6\u3002box_cls\u7efc\u5408\u4e86\u6240\u6709\u7684\u9884\u6d4b\u503c\uff0cbox_regression\u7efc\u5408\u6240\u6709\u7684\u9884\u6d4b\u6846\n    # \u76f8\u5f53\u4e8e\u5f97\u5230(-1, C)\u7684\u6570\u636e\uff0c\u5206\u7c7b\u4e0e\u56de\u5f52\u635f\u5931\u5747\u662f\u8fd9\u6837\n    box_cls = torch.cat(box_cls_flattened, dim=1).flatten(0, -2)  # start_dim, end_dim\n    box_regression = torch.cat(box_regression_flattened, dim=1).reshape(-1, 4)\n    return box_cls, box_regression\n</code></pre> <p>\u8c03\u6574\u6570\u636e\u7ef4\u5ea6</p> <pre><code>def permute_and_flatten(layer, N, A, C, H, W):\n    # type: (Tensor, int, int, int, int, int) -&gt; Tensor\n    \"\"\"\n    \u8c03\u6574tensor\u987a\u5e8f\uff0c\u5e76\u8fdb\u884creshape\n    Args:\n        layer: \u9884\u6d4b\u7279\u5f81\u5c42\u4e0a\u9884\u6d4b\u7684\u76ee\u6807\u6982\u7387\u6216bboxes regression\u53c2\u6570\n        N: batch_size\n        A: anchors_num_per_position\n        C: classes_num or 4(bbox coordinate)\n        H: height\n        W: width\n\n    Returns:\n        layer: \u8c03\u6574tensor\u987a\u5e8f\uff0c\u5e76reshape\u540e\u7684\u7ed3\u679c[N, -1, C]\n    \"\"\"\n    # view\u548creshape\u529f\u80fd\u662f\u4e00\u6837\u7684\uff0c\u5148\u5c55\u5e73\u6240\u6709\u5143\u7d20\u5728\u6309\u7167\u7ed9\u5b9ashape\u6392\u5217\n    # view\u51fd\u6570\u53ea\u80fd\u7528\u4e8e\u5185\u5b58\u4e2d\u8fde\u7eed\u5b58\u50a8\u7684tensor\uff0cpermute\u7b49\u64cd\u4f5c\u4f1a\u4f7ftensor\u5728\u5185\u5b58\u4e2d\u53d8\u5f97\u4e0d\u518d\u8fde\u7eed\uff0c\u6b64\u65f6\u5c31\u4e0d\u80fd\u518d\u8c03\u7528view\u51fd\u6570\n    # reshape\u5219\u4e0d\u9700\u8981\u4f9d\u8d56\u76ee\u6807tensor\u662f\u5426\u5728\u5185\u5b58\u4e2d\u662f\u8fde\u7eed\u7684\n    # [batch_size, anchors_num_per_position * (C or 4), height, width]\n    layer = layer.view(N, -1, C,  H, W)\n    # \u8c03\u6362tensor\u7ef4\u5ea6\u3002\u8c03\u6362\u7ef4\u5ea6\u4fe1\u606f\uff0c\u5f97\u5230[N, H, W, -1, C]\n    layer = layer.permute(0, 3, 4, 1, 2)\n    layer = layer.reshape(N, -1, C)  # \u53ef\u4ee5\u7528\u4e8e\u4e0d\u8fde\u7eed\u7684\u6570\u636e\n    return layer\n</code></pre>"},{"location":"detection/network/Faster_RCNN/RPN/#_5","title":"\u7b5b\u9009\u8fb9\u754c\u6846\u5750\u6807","text":"<p>\u2003\u2003\u6ce8\u610f\uff1a\u8fd9\u91cc\u7b5b\u9009\u51fa\u4e24\u5343\u4e2a(\u9ed8\u8ba4)\u53ea\u662f\u4e3a\u4e86\u9001\u7ed9\u540e\u9762\u7684roi\u7528\u4e8e\u8fdb\u4e00\u6b65\u9884\u6d4b\u7c7b\u522b\u548c\u6821\u6b63\u76ee\u6807\u6846\uff0c\u800cRPN\u8ba1\u7b97\u635f\u5931\u65f6\u662f\u4f20\u5165\u6240\u6709\u7684\u70b9\u8ba1\u7b97(\u5f53\u7136\u8ba1\u7b97\u635f\u5931\u65f6\u8fd8\u4f1a\u518d\u7b5b\u9009\u6b63\u8d1f\u6837\u672c\u4e2a\u6570\u53ca\u6bd4\u4f8b\uff0c\u5728compute_loss\u65b9\u6cd5\u4e2d\u7b5b\u9009)</p> <p>\u2003\u2003\u5148\u4ece\u6bcf\u5c42\u7b5b\u9009\u51fa\u9884\u6d4b\u5206\u6570\u524dpre_nms_top_n\u4e2a\u8fb9\u754c\u6846\uff0c\u4e4b\u540e\u518d\u7ecf\u8fc7NMS\u5904\u7406\uff0c\u8fc7\u6ee4\u6389\u91cd\u5408\u7387\u9ad8\u7684\uff0c\u4e4b\u540e\u518d\u4f9d\u636e\u9884\u6d4b\u5206\u6570\u7b5b\u9009\uff0c\u7b5b\u9009\u51fa\u524drpn_post_nms_top_n\u4e2a\u5750\u6807</p> <pre><code>def filter_proposals(self, proposals, objectness, image_shapes, num_anchors_per_level):\n    # type: (Tensor, Tensor, List[Tuple[int, int]], List[int]) -&gt; Tuple[List[Tensor], List[Tensor]]\n    \"\"\"\n    \u7b5b\u9664\u5c0fboxes\u6846\uff0cnms\u5904\u7406\uff0c\u6839\u636e\u9884\u6d4b\u6982\u7387\u83b7\u53d6\u524dpost_nms_top_n\u4e2a\u76ee\u6807\n    Args:\n        proposals: \u9884\u6d4b\u7684bbox\u5750\u6807\n        objectness: \u9884\u6d4b\u7684\u76ee\u6807\u6982\u7387\n        image_shapes: batch\u4e2d\u6bcf\u5f20\u56fe\u7247\u7684size\u4fe1\u606f\n        num_anchors_per_level: \u6bcf\u4e2a\u9884\u6d4b\u7279\u5f81\u5c42\u4e0a\u9884\u6d4banchors\u7684\u6570\u76ee\n    Returns:\n        final_boxes: \u7b5b\u9009\u540e\u7684\u5750\u6807\u6846\n        final_scores: \u5bf9\u5e94\u7684\u9884\u6d4b\u5206\u6570\n    \"\"\"\n    # batch\n    num_images = proposals.shape[0]\n    # \u5b58\u50a8\u6570\u636e\u7684\u8bbe\u5907\u4fe1\u606f\n    device = proposals.device\n    # \u5207\u65ad\u68af\u5ea6\uff0c\u53ea\u83b7\u53d6\u6570\u503c\uff0c\u8f93\u5165\u5230fast r-cnn\u4e2d\n    objectness = objectness.detach()\n    # \u8c03\u6574\u7ef4\u5ea6\uff0c(batch,\u951a\u70b9\u603b\u6570)\n    objectness = objectness.reshape(num_images, -1)\n    # levels\u8d1f\u8d23\u8bb0\u5f55\u5206\u9694\u4e0d\u540c\u9884\u6d4b\u7279\u5f81\u5c42\u4e0a\u7684anchors\u7d22\u5f15\u4fe1\u606f\u3002\u4e3a\u4e86\u540e\u7eed\u628a\u4e0d\u540c\u7279\u5f81\u5c42\u7684\u9884\u6d4b\u7269\u4f53\u6846\u5206\u5f00\n    # levels\u8868\u793a\u4e00\u4e2a\u5217\u8868\uff0c\u5217\u8868\u957f\u5ea6\u4e3a\u53c2\u4e0e\u9884\u6d4b\u7684\u7279\u5f81\u5c42\u6570\u91cf\uff0c\u800c\u91cc\u9762\u7684\u6570\u636e\u957f\u5ea6\u4e3a\u76f8\u5e94\u7279\u5f81\u5c42\u4e0a\u7684\u951a\u70b9\u6570\u91cf\uff0c\u6570\u503c\u4e3a\u7279\u5f81\u5c42\u7f16\u53f7\uff0c\u4ece0\u5f00\u59cb\n    levels = [torch.full((n, ), idx, dtype=torch.int64, device=device)\n              for idx, n in enumerate(num_anchors_per_level)]\n    # \u5c06\u751f\u6210\u7684\u7279\u5f81\u5c42\u7f16\u53f7\u5408\u5e76\uff0c\u901a\u8fc7level\u6765\u533a\u5206\u6bcf\u4e2a\u9884\u6d4b\u8fb9\u754c\u6846\u5c5e\u4e8e\u54ea\u4e2a\u7279\u5f81\u5c42\uff0c\u76f8\u5f53\u4e8e\u5bf9\u6bcf\u4e2a\u9884\u6d4b\u7ed3\u679c\u505a\u4e86\u6807\u8bb0\n    levels = torch.cat(levels, 0)\n    # \u5728\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u590d\u5236\uff0c\u590d\u5236batch\u4efd\n    levels = levels.reshape(1, -1).expand_as(objectness)\n\n    # \u83b7\u53d6\u6bcf\u5f20\u9884\u6d4b\u7279\u5f81\u56fe\u4e0a\u9884\u6d4b\u6982\u7387\u6392\u524dpre_nms_top_n\u7684anchors\u7d22\u5f15\u503c\n    top_n_idx = self._get_top_n_idx(objectness, num_anchors_per_level)\n    # image_range\u8868\u793abatch\u7d22\u5f15\n    image_range = torch.arange(num_images, device=device)\n    # \u52a0\u4e00\u4e2a\u7ef4\u5ea6\uff0c\u53d8\u6210\u4e8c\u7ef4\u6570\u7ec4\uff0c\u5c31\u4e00\u5217\uff0c\u6bcf\u884c\u8868\u793a\u540c\u4e00\u6279batch\u4e2d\u4e0d\u540c\u56fe\u7247\u7684\u6807\u7b7e\uff0c\u7528\u4e8e\u540e\u7eed\u7684\u7d22\u5f15\n    batch_idx = image_range[:, None]  # [batch_size, 1]\n\n    # \u6839\u636e\u6bcf\u4e2a\u9884\u6d4b\u7279\u5f81\u5c42\u9884\u6d4b\u6982\u7387\u6392\u524dpre_nms_top_n\u7684anchors\u7d22\u5f15\u503c\u83b7\u53d6\u76f8\u5e94\u6982\u7387\u4fe1\u606f\n    # \u53d6\u5f97\u7b5b\u9009\u540e\u7684\u9884\u6d4b\u4fe1\u606f\n    objectness = objectness[batch_idx, top_n_idx]\n    # \u8fd9\u91cc\u6267\u884c\u540c\u6837\u7684\u64cd\u4f5c\uff0c\u4e3a\u4e86\u8bb0\u5f55\u5206\u9694\u7b26\uff0c\u5373\u8bb0\u5f55\u6bcf\u4e2a\u9884\u6d4b\u5c5e\u4e8e\u54ea\u4e2a\u7279\u5f81\u5c42\n    levels = levels[batch_idx, top_n_idx]\n    # \u9884\u6d4b\u6982\u7387\u6392\u524dpre_nms_top_n\u7684anchors\u7d22\u5f15\u503c\u83b7\u53d6\u76f8\u5e94bbox\u5750\u6807\u4fe1\u606f\n    proposals = proposals[batch_idx, top_n_idx]\n    # \u5c06\u9884\u6d4b\u5206\u6570\u7ecf\u8fc7sigmoid\u5f52\u4e00\u5316\u5904\u7406\n    objectness_prob = torch.sigmoid(objectness)\n    # \u7528\u4e8e\u5b58\u50a8\u7ecf\u8fc7\u6700\u7ec8\u7b5b\u9009\u7684\u8fb9\u754c\u6846\u5750\u6807\u548c\u9884\u6d4b\u5206\u6570\n    final_boxes = []\n    final_scores = []\n    # \u904d\u5386\u6bcf\u5f20\u56fe\u50cf\u7684\u76f8\u5173\u9884\u6d4b\u4fe1\u606f\uff0c\u6309batch\u904d\u5386\n    for boxes, scores, lvl, img_shape in zip(proposals, objectness_prob, levels, image_shapes):\n        # \u8c03\u6574\u9884\u6d4b\u7684boxes\u4fe1\u606f\uff0c\u5c06\u8d8a\u754c\u7684\u5750\u6807\u8c03\u6574\u5230\u56fe\u7247\u8fb9\u754c\u4e0a\uff0c\u5c06\u9884\u6d4b\u6846\u9650\u5236\u5728\u56fe\u7247\u5185\u90e8\n        boxes = box_ops.clip_boxes_to_image(boxes, img_shape)\n\n        # \u8fd4\u56deboxes\u6ee1\u8db3\u5bbd\uff0c\u9ad8\u90fd\u5927\u4e8emin_size\u7684\u7d22\u5f15\uff0c\u5220\u9664\u5c0f\u76ee\u6807\u3002\u6ce8\u610f\u7b2c\u4e00\u884c\u53ea\u83b7\u53d6\u7d22\u5f15\uff0c\u540e\u9762\u5229\u7528\u7d22\u5f15\u7b5b\u9009\n        keep = box_ops.remove_small_boxes(boxes, self.min_size)\n        # \u4f9d\u6b21\u83b7\u53d6\u6b63\u5e38\u7684\u8fb9\u754c\u6846\u5750\u6807\u3001\u5206\u6570\u3001\u7279\u5f81\u5c42\u5f52\u5c5e\n        boxes, scores, lvl = boxes[keep], scores[keep], lvl[keep]\n\n        # \u79fb\u9664\u5c0f\u6982\u7387boxes\uff0c\u53c2\u8003\u4e0b\u9762\u8fd9\u4e2a\u94fe\u63a5\n        # https://github.com/pytorch/vision/pull/3205\n        keep = torch.where(torch.ge(scores, self.score_thresh))[0]  # ge: &gt;= \u5927\u4e8e\u7b49\u4e8e\n        # \u548c\u4e0a\u9762\u4e00\u6837\uff0c\u6839\u636e\u7d22\u5f15\u83b7\u53d6\u7b5b\u9009\u540e\u7684\u6570\u636e\n        boxes, scores, lvl = boxes[keep], scores[keep], lvl[keep]\n\n        # \u975e\u6781\u5927\u503c\u6291\u5236\u5904\u7406\u2014\u2014NMS\u5904\u7406\n        keep = box_ops.batched_nms(boxes, scores, lvl, self.nms_thresh)\n\n        # \u5229\u7528\u5207\u7247\u7684\u65b9\u5f0f\uff0c\u83b7\u53d6\u524dpost_nms_top_n\u4e2a\u76ee\u6807(\u6216\u8005\u83b7\u53d6\u6240\u6709\u7684\uff0cNMS\u540e\u5750\u6807\u6846\u6570\u91cf\u5c0f\u4e8epost_nms_top_n\u7684\u8bdd)\n        keep = keep[: self.post_nms_top_n()]  \n        boxes, scores = boxes[keep], scores[keep]\n        # \u50a8\u5b58\u6570\u636e\n        final_boxes.append(boxes)  \n        final_scores.append(scores)\n    # \u6700\u540e\u8fd4\u56de\u7ecf\u8fc7\u7b5b\u9009\u540e\u7684\u8fb9\u754c\u6846\u4ee5\u53ca\u5206\u6570\n    return final_boxes, final_scores\n</code></pre>"},{"location":"detection/network/Faster_RCNN/RPN/#nms","title":"NMS\u524d\u7684\u8fb9\u754c\u6846\u7b5b\u9009","text":"<pre><code>def _get_top_n_idx(self, objectness, num_anchors_per_level):\n    # type: (Tensor, List[int]) -&gt; Tensor\n    \"\"\"\n    \u83b7\u53d6\u6bcf\u5f20\u9884\u6d4b\u7279\u5f81\u56fe\u4e0a\u9884\u6d4b\u6982\u7387\u6392\u524dpre_nms_top_n\u7684anchors\u7d22\u5f15\u503c\n    Args:\n        objectness: Tensor(\u6bcf\u5f20\u56fe\u50cf\u7684\u9884\u6d4b\u76ee\u6807\u6982\u7387\u4fe1\u606f )\n        num_anchors_per_level: List\uff08\u6bcf\u4e2a\u9884\u6d4b\u7279\u5f81\u5c42\u4e0a\u7684\u9884\u6d4b\u7684anchors\u4e2a\u6570\uff09\n    Returns:\n\n    \"\"\"\n    # \u8bb0\u5f55\u6bcf\u4e2a\u9884\u6d4b\u7279\u5f81\u5c42\u4e0a\u9884\u6d4b\u76ee\u6807\u6982\u7387\u524dpre_nms_top_n\u7684\u7d22\u5f15\u4fe1\u606f\n    r = []\n    offset = 0\n    # \u904d\u5386\u6bcf\u4e2a\u9884\u6d4b\u7279\u5f81\u5c42\u4e0a\u7684\u9884\u6d4b\u76ee\u6807\u6982\u7387\u4fe1\u606f\n    for ob in objectness.split(num_anchors_per_level, 1):  # \u5bf9objectness\u5728\u7b2c\u4e00\u7ef4\u5ea6\u505a\u5206\u5272\uff0c\u4fdd\u7559batch\u4fe1\u606f\n        if torchvision._is_tracing():\n            num_anchors, pre_nms_top_n = _onnx_get_num_anchors_and_pre_nms_top_n(ob, self.pre_nms_top_n())\n        else:\n            # \u9884\u6d4b\u7279\u5f81\u5c42\u4e0a\u7684\u9884\u6d4b\u7684anchors\u4e2a\u6570\n            num_anchors = ob.shape[1]  \n            # \u5982\u679cnum_anchors\u5c0f\u4e8epre_nms_top_n(\u53c2\u4e0enms\u524d\uff0c\u6bcf\u5c42\u6700\u591a\u4fdd\u7559\u7684\u9884\u6d4b\u6846\u6570\u91cf\uff0c\u9ed8\u8ba42000)\u7684\u8bdd\uff0c\u5c31\u53d6\u5168\u90e8\u7684num_anchors\n            pre_nms_top_n = min(self.pre_nms_top_n(), num_anchors)  \n\n        # Returns the k largest elements of the given input tensor along a given dimension\n        # \u8bad\u7ec3\u4fdd\u75592000\uff0c\u6d4b\u8bd5\u4fdd\u75591000\u3002topk\u8868\u793a\u53d6\u524dk\u4e2a\u6700\u5927\u7684\u503c\u7684\u503c\u548c\u7d22\u5f15\uff0c\u8fd9\u91cc\u53ea\u63d0\u53d6\u51fa\u7d22\u5f15\u6765\n        _, top_n_idx = ob.topk(pre_nms_top_n, dim=1)  \n        # \u4e0b\u9762\u4e24\u6b65\u5f88\u5173\u952e\uff0c\u5bf9\u5f53\u524d\u5c42\u7684\u7d22\u5f15\u505a\u504f\u79fb\uff0c\u4ece\u5355\u4e2a\u5c42\u6765\u770b\uff0c\u5f53\u524d\u5c42\u7d22\u5f15\u4ece0\u5f00\u59cb\uff0c\u4ece\u6574\u4f53\u6765\u770b\uff0c\u5f53\u524d\u5c42\u7684\u7d22\u5f15\u662f\u4ece\u524d\u4e00\u5c42\u6700\u540e\u4e00\u4e2a\u6570\u7684\u7d22\u5f15\u5f00\u59cb\u7684\n        # offset\u8868\u793a\u504f\u79fb\u91cf\uff0c\u6bcf\u4e00\u5c42\u7684\u504f\u79fb\u3002\u7b2c\u4e8c\u5c42\u9884\u6d4b\u503c\u7684\u7d22\u5f15\u9700\u8981\u52a0\u4e0a\u7b2c\u4e00\u5c42\u9884\u6d4b\u503c\u7684\u603b\u6570\u3002(\u57fa\u4e8e\u524d\u9762\u6240\u6709\u7684)\n        r.append(top_n_idx + offset)  \n        offset += num_anchors\n    # \u5c06\u7b5b\u9009\u5230\u7684\u8fb9\u754c\u6846\u505a\u5408\u5e76\uff0c\u4e4b\u540e\u8fd4\u56de\uff0c\u518d\u8fdb\u884cNMS\u5904\u7406\n    return torch.cat(r, dim=1)\n</code></pre>"},{"location":"detection/network/Faster_RCNN/RPN/#_6","title":"\u4fee\u6b63\u5f02\u5e38\u8fb9\u754c\u6846","text":"<p>\u8c03\u6574\u8d8a\u754c\u8fb9\u754c\u6846</p> <pre><code>def clip_boxes_to_image(boxes, size):\n    # type: (Tensor, Tuple[int, int]) -&gt; Tensor\n    \"\"\"\n    \u8f93\u5165\u88c1\u526a\u9884\u6d4b\u7684boxes\u4fe1\u606f\uff0c\u5c06\u8d8a\u754c\u7684\u5750\u6807\u8c03\u6574\u5230\u56fe\u7247\u8fb9\u754c\u4e0a\n    Arguments:\n        boxes (Tensor[N, 4]): \u8fb9\u754c\u6846\u5750\u6807 (x1, y1, x2, y2)\n        size (Tuple[height, width]): \u56fe\u7247\u5c3a\u5bf8\n\n    Returns:\n        clipped_boxes (Tensor[N, 4]): \u8c03\u6574\u540e\u7684\u5750\u6807\n    \"\"\"\n    dim = boxes.dim()\n    # \u5f97\u5230x\u5750\u6807\uff0c\u5c3a\u5bf8\u4e3a(\u8fb9\u754c\u6846\u6570\u91cf,2)\n    boxes_x = boxes[..., 0::2]\n    # \u5f97\u5230y\u5750\u6807\uff0c\u5c3a\u5bf8\u548cx\u5c3a\u5bf8\u76f8\u540c\n    boxes_y = boxes[..., 1::2]\n    # \u5f97\u5230\u9ad8\u3001\u5bbd\uff0c\u7528\u4e8e\u9650\u5236x\uff0cy\u5750\u6807\n    height, width = size\n    if torchvision._is_tracing():\n        boxes_x = torch.max(boxes_x, torch.tensor(0, dtype=boxes.dtype, device=boxes.device))\n        boxes_x = torch.min(boxes_x, torch.tensor(width, dtype=boxes.dtype, device=boxes.device))\n        boxes_y = torch.max(boxes_y, torch.tensor(0, dtype=boxes.dtype, device=boxes.device))\n        boxes_y = torch.min(boxes_y, torch.tensor(height, dtype=boxes.dtype, device=boxes.device))\n    else:  # \u4e00\u822c\u6267\u884c\u8fd9\u91cc\n        # \u9650\u5236x\u5750\u6807\u8303\u56f4\u5728[0,width]\u4e4b\u95f4\n        boxes_x = boxes_x.clamp(min=0, max=width)\n        # \u9650\u5236y\u5750\u6807\u8303\u56f4\u5728[0,height]\u4e4b\u95f4\n        boxes_y = boxes_y.clamp(min=0, max=height)\n    # \u5408\u5e76\n    clipped_boxes = torch.stack((boxes_x, boxes_y), dim=dim)\n    # \u5c06\u6570\u636e\u5f62\u72b6\u53d8\u4e3a\u4e0e\u8f93\u5165\u6570\u636e\u76f8\u540c\u7684\u5f62\u72b6\n    return clipped_boxes.reshape(boxes.shape)\n</code></pre> <p>\u5220\u9664\u8fc7\u5c0f\u7684\u76ee\u6807</p> <pre><code>def remove_small_boxes(boxes, min_size):\n    # type: (Tensor, float) -&gt; Tensor\n    \"\"\"\n    \u79fb\u9664\u5bbd\u9ad8\u5c0f\u4e8e\u6307\u5b9a\u9608\u503c\u7684\u8fb9\u754c\u6846\n    Arguments:\n        boxes (Tensor[N, 4]): \u8fb9\u754c\u6846\u5750\u6807,(x1, y1, x2, y2)\n        min_size (float): \u6700\u5c0f\u8fb9\u957f\u7684\u9608\u503c\n    Returns:\n        keep (Tensor[K]): \u6b63\u5e38\u8fb9\u754c\u6846\u7684\u7d22\u5f15\uff0c\u5373\u8fb9\u957f\u5927\u4e8emin_size\u7684\u8fb9\u754c\u6846\n    \"\"\"\n    # \u9884\u6d4bboxes\u7684\u5bbd\u548c\u9ad8\n    ws, hs = boxes[:, 2] - boxes[:, 0], boxes[:, 3] - boxes[:, 1]\n    # \u5f53\u6ee1\u8db3\u5bbd\uff0c\u9ad8\u90fd\u5927\u4e8e\u7ed9\u5b9a\u9608\u503c\u65f6\u4e3aTrue\n    keep = torch.logical_and(torch.ge(ws, min_size), torch.ge(hs, min_size))\n    # \u8fd9\u91cc\u641c\u5bfb\u975e\u96f6\u5143\u7d20\u7684\u7d22\u5f15\uff0c\u5373True\u7684\u7d22\u5f15\n    # [0]\u8868\u793a\u83b7\u53d6True\u5143\u7d20\u7b2c\u4e00\u7ef4\u5ea6\u7684\u7d22\u5f15\u5217\u8868\n    keep = torch.where(keep)[0]\n    # \u6ce8\u610f\uff0c\u8fd9\u91cc\u53ea\u8fd4\u56de\u7d22\u5f15\n    return keep\n</code></pre>"},{"location":"detection/network/Faster_RCNN/RPN/#nms_1","title":"NMS\u5904\u7406","text":"<p>\u2003\u2003\u6ce8\u610f:\u8fd9\u91cc\u540c\u4e00\u4e2a\u6279\u6b21\u4e2d\u53ef\u80fd\u4f1a\u6709\u7531\u4e0d\u540c\u7279\u5f81\u5c42\u9884\u6d4b\u7684\u8fb9\u754c\u6846\uff0c\u6b64\u65f6\u5c5e\u4e8e\u4e0d\u540c\u7279\u5f81\u5c42\u7684\u7279\u5f81\u9700\u8981\u770b\u6210\u4e0d\u540c\u7684\u7c7b\u522b\uff0cNMS\u5904\u7406\u65f6\u4e0d\u80fd\u8de8\u7c7b\u5904\u7406\uff0c\u5373\u9700\u8981\u5bf9\u539f\u59cb\u8fb9\u754c\u6846\u505a\u4e00\u4e2a\u504f\u79fb\uff0c\u5c06\u5c5e\u4e8e\u4e0d\u540c\u7279\u5f81\u5c42\u7684\u8fb9\u754c\u6846\u504f\u79fb\u5230\u7a7a\u95f4\u4e2d\u4e0d\u540c\u7684\u4f4d\u7f6e\uff0c\u4fdd\u8bc1\u7279\u5f81\u5c42\u4e4b\u95f4\u9884\u6d4b\u7684\u8fb9\u754c\u6846\u6ca1\u6709\u4ea4\u53c9\u3002</p> <pre><code>def batched_nms(boxes, scores, idxs, iou_threshold):\n    # type: (Tensor, Tensor, Tensor, float) -&gt; Tensor\n    \"\"\"\n    \u5bf9\u4e8e\u4e00\u4e2a\u6279\u6b21batch\u6267\u884cNMS\u64cd\u4f5c\n    Parameters\n    ----------\n    boxes : Tensor[N, 4]\n        \u8fb9\u754c\u6846\u5750\u6807\uff0c(x1, y1, x2, y2)\n    scores : Tensor[N]\n        \u6bcf\u4e2a\u8fb9\u754c\u6846\u7684\u9884\u6d4b\u5206\u6570\n    idxs : Tensor[N]\n        \u6bcf\u4e2a\u8fb9\u754c\u6846\u7684\u7c7b\u522b\uff0c\u5373\u7279\u5f81\u5c42\u7684\u5e8f\u53f7\uff0c\u7528\u4e8e\u540e\u7eed\u7684\u504f\u79fb\n    iou_threshold : float\n        NMS\u5904\u7406\u4e2d\u4f7f\u7528\u5230\u7684IOU\u9608\u503c\n\n    Returns\n    -------\n    keep : Tensor\n        \u7ecf\u8fc7NMS\u5904\u7406\u540e\u7684\u8fb9\u754c\u6846\u7d22\u5f15\n    \"\"\"\n    if boxes.numel() == 0:\n        return torch.empty((0,), dtype=torch.int64, device=boxes.device)\n\n    # \u5982\u524d\u9762\u6240\u8bf4\uff0c\u4e3a\u4e86\u72ec\u7acb\u5728\u6bcf\u4e2a\u7279\u5f81\u5c42\u6267\u884cNMS\uff0c\u9700\u8981\u4e3a\u6240\u6709\u7684\u8fb9\u754c\u6846\u6dfb\u52a0\u504f\u79fb\u91cf\n    # \u504f\u79fb\u91cf\u53ea\u4e0e\u7279\u5f81\u5c42\u7684\u5e8f\u53f7\u6709\u5173\uff0c\u5e76\u4e14\u9700\u8981\u8db3\u591f\u5927\uff0c\u4ee5\u4fbf\u8ba9\u6240\u6709\u5c42\u4e4b\u95f4\u4e92\u4e0d\u4ea4\u53c9\n    # \u83b7\u53d6\u6240\u6709boxes\u4e2d\u6700\u5927\u7684\u5750\u6807\u503c\uff0c\u5f53\u505a\u504f\u79fb\u57fa\u6570\n    max_coordinate = boxes.max()\n\n    # \u4e3a\u6bcf\u4e00\u4e2a\u7c7b\u522b/\u6bcf\u4e00\u5c42\u751f\u6210\u4e00\u4e2a\u5f88\u5927\u7684\u504f\u79fb\u91cf\n    # \u8fd9\u91cc\u7684to\u53ea\u662f\u8ba9\u751f\u6210tensor\u7684dytpe\u548cdevice\u4e0eboxes\u4fdd\u6301\u4e00\u81f4\n    offsets = idxs.to(boxes) * (max_coordinate + 1)\n    # boxes\u52a0\u4e0a\u5bf9\u5e94\u5c42\u7684\u504f\u79fb\u91cf\u540e\uff0c\u4fdd\u8bc1\u4e0d\u540c\u7c7b\u522b/\u5c42\u4e4b\u95f4boxes\u4e0d\u4f1a\u6709\u91cd\u5408\u7684\u73b0\u8c61\u3002\n    # \u9488\u5bf9\u6bcf\u4e00\u5c42\u7684\u6846\u5750\u6807\u90fd\u4e0d\u4f1a\u6709\u91cd\u53e0\u3002\u7b2c\u4e8c\u5c42\u5750\u6807\u6570\u503c\u662f\u57fa\u4e8e\u7b2c\u4e00\u5c42\u7684\u6570\u503c(\u4ee5max_coordinate\u4e3a\u5206\u5272\u5355\u4f4d)\n    # \u52a0\u4e0a\u7279\u5f81\u504f\u7f6e\u9879\uff0c\u6b64\u65f6\u5404\u4e2a\u5c42\u7684\u8fb9\u754c\u6846\u5750\u6807\u5c06\u4e92\u76f8\u5206\u79bb\n    boxes_for_nms = boxes + offsets[:, None]\n    # \u53ea\u9700\u8981\u6267\u884c\u4e00\u6b21nms\uff0c\u4e0d\u9700\u8981\u9488\u5bf9\u6240\u6709\u7684\u7279\u5f81\u5c42\u90fd\u6267\u884c\u4e00\u6b21\n    keep = nms(boxes_for_nms, scores, iou_threshold)  \n    # \u8fd4\u56de\u7ecf\u8fc7NMS\u8fc7\u6ee4\u540e\u7684\u8fb9\u754c\u6846\u7d22\u5f15\n    return keep\n</code></pre> <p>NMS\u64cd\u4f5c\u76f4\u63a5\u8c03\u7528torch\u91cc\u9762\u5c01\u88c5\u597d\u7684\u51fd\u6570\u5373\u53ef</p> <pre><code>def nms(boxes, scores, iou_threshold):\n    # type: (Tensor, Tensor, float) -&gt; Tensor\n    # \u53ea\u9700\u4f20\u5165\u8fb9\u754c\u6846\u5750\u6807\u3001\u5206\u6570\u3001IOU\u9608\u503c\u5373\u53ef\n    return torch.ops.torchvision.nms(boxes, scores, iou_threshold)\n</code></pre>"},{"location":"detection/network/Faster_RCNN/RPN/#rpn_2","title":"\u8ba1\u7b97RPN\u635f\u5931","text":""},{"location":"detection/network/Faster_RCNN/RPN/#_7","title":"\u951a\u70b9\u4e0e\u8fb9\u754c\u6846\u6807\u7b7e\u7684\u5339\u914d","text":"<pre><code>def assign_targets_to_anchors(self, anchors, targets):\n    # type: (List[Tensor], List[Dict[str, Tensor]]) -&gt; Tuple[List[Tensor], List[Tensor]]\n    \"\"\"\n    anchors\u8868\u793a\u6240\u6709\u7684\u9884\u8bbe\u951a\u70b9\uff0c\u8fd9\u91cc\u5339\u914d\u7684\u662f\u9884\u5148\u8bbe\u5b9a\u7684\u6807\u51c6\u6a21\u677f\u56fe\uff0c\u6240\u6709\u6a21\u677f\u90fd\u5bf9\u5e94\u539f\u56fe\u7684\u4e00\u4e2a\u533a\u57df\n    \u7528\u4e8e\u4e0e\u76ee\u6807\u76f8\u5339\u914d\uff0c\u9009\u53d6\u6bd4\u8f83\u9760\u8fd1\u76ee\u6807\u7684\u951a\u70b9\uff0c\u540e\u7eed\u518d\u5229\u7528\u56de\u5f52\u53c2\u6570\u5c06\u9760\u8fd1\u76ee\u6807\u7684\u951a\u70b9\u6240\u4ee3\u8868\u7684\u533a\u57df\u4fee\u6b63\u5230\u51c6\u786e\u7684\u76ee\u6807\u533a\u57df\n    \u8ba1\u7b97\u6bcf\u4e2aanchors\u6700\u5339\u914d\u7684gt\uff0c\u5e76\u5212\u5206\u4e3a\u6b63\u6837\u672c\uff0c\u80cc\u666f\u4ee5\u53ca\u5e9f\u5f03\u7684\u6837\u672c\n    Args\uff1a\n        anchors: (List[Tensor])\n        targets: (List[Dict[Tensor])\n    Returns:\n        labels: \u6807\u8bb0anchors\u5f52\u5c5e\u7c7b\u522b\uff081, 0, -1\u5206\u522b\u5bf9\u5e94\u6b63\u6837\u672c\uff0c\u80cc\u666f\uff0c\u5e9f\u5f03\u7684\u951a\u70b9\uff09\n                \u6ce8\u610f\uff0c\u5728RPN\u4e2d\u53ea\u6709\u524d\u666f\u548c\u80cc\u666f\uff0c\u6240\u6709\u6b63\u6837\u672c\u7684\u7c7b\u522b\u90fd\u662f1\uff0c0\u4ee3\u8868\u80cc\u666f\n        matched_gt_boxes\uff1a\u4e0eanchors\u5339\u914d\u7684gt\n    \"\"\"\n    # \u521d\u59cb\u5316\u951a\u70b9\u7c7b\u522b\u548c\u4e0e\u951a\u70b9\u5339\u914d\u7684\u6807\u7b7e\n    labels = []\n    matched_gt_boxes = []\n    # \u6309batch\u904d\u5386\n    for anchors_per_image, targets_per_image in zip(anchors, targets):\n        # \u63d0\u53d6\u6807\u7b7e\u4e2d\u7684\u77e9\u5f62\u6846\u5750\u6807\n        gt_boxes = targets_per_image[\"boxes\"]\n        # \u5982\u679c\u56fe\u7247\u65e0\u76ee\u6807\uff0c\u5219\u7c7b\u522b\u4e0e\u8fb9\u754c\u6846\u5168\u90e8\u5f52\u4e3a0\n        if gt_boxes.numel() == 0:\n            device = anchors_per_image.device\n            matched_gt_boxes_per_image = torch.zeros(anchors_per_image.shape, dtype=torch.float32, device=device)\n            labels_per_image = torch.zeros((anchors_per_image.shape[0],), dtype=torch.float32, device=device)\n        else:\n            # \u8ba1\u7b97anchors\u4e0e\u771f\u5b9ebbox\u7684iou\u4fe1\u606f\uff0c\u5373\u4ea4\u96c6\u9762\u79ef\u6bd4\u4f8b\uff0c\u8fd4\u56de\u56fe\u7247\u4e2d\u6bcf\u4e2a\u5bf9\u8c61\u4e0e\u6bcf\u4e2a\u951a\u70b9\u7684IOU\u503c\uff0c\u5c3a\u5bf8\u4e3a[\u8be5\u56fe\u76ee\u6807\u6570\u91cf,\u9884\u8bbe\u951a\u70b9\u6570\u91cf]\n            match_quality_matrix = box_ops.box_iou(gt_boxes, anchors_per_image)\n            # \u8ba1\u7b97\u6bcf\u4e2aanchors\u4e0egt\u5339\u914diou\u6700\u5927\u7684\u7d22\u5f15\uff08\u5982\u679ciou&lt;0.3\u7d22\u5f15\u7f6e\u4e3a-1\uff0c0.3&lt;iou&lt;0.7\u7d22\u5f15\u4e3a-2\uff09\n            # \u9884\u6d4b\u6846\u4e0e\u6807\u7b7e\u6846\u5339\u914d\uff0c\u8fd4\u56de\u5339\u914d\u4fe1\u606f\uff0c\u5c3a\u5bf8\u4e0e\u4e0a\u4e2a\u4e00\u81f4[\u8be5\u56fe\u76ee\u6807\u6570\u91cf,\u9884\u8bbe\u951a\u70b9\u6570\u91cf]\n            # \u5982\u679c\u951a\u70b9\u4e3a\u524d\u666f\uff0c\u5219\u6570\u503c\u4e3a\u5339\u914d\u5230\u7684\u5bf9\u8c61\u5e8f\u53f7\uff1b\u5982\u679c\u4e3a\u80cc\u666f\u5219\u6570\u503c\u4e3a-1\uff1b\u5982\u679c\u8be5\u951a\u70b9\u88ab\u4e22\u5f03(\u5904\u4e8e\u9608\u503c\u4e4b\u95f4)\uff0c\u5219\u6570\u503c\u4e3a-2\n            matched_idxs = self.proposal_matcher(match_quality_matrix)\n            # \u8fd9\u91cc\u4f7f\u7528clamp\u8bbe\u7f6e\u4e0b\u96500\u662f\u4e3a\u4e86\u65b9\u4fbf\u53d6\u6bcf\u4e2aanchors\u5bf9\u5e94\u7684gt_boxes\u4fe1\u606f\uff0c\u7528\u4e8e\u8ba1\u7b97\u8fb9\u754c\u6846\u56de\u5f52\u635f\u5931\n            # \u8d1f\u6837\u672c\u548c\u820d\u5f03\u7684\u6837\u672c\u90fd\u662f\u8d1f\u503c\uff0c\u6240\u4ee5\u4e3a\u4e86\u9632\u6b62\u8d8a\u754c\u76f4\u63a5\u7f6e\u4e3a0\uff0c\u9ed8\u8ba4\u5339\u914d\u7b2c\u4e00\u4e2abox\n            # \u56e0\u4e3a\u540e\u671f\u4e0d\u7528\u8fd9\u4e9b\u6837\u672c\u6765\u8ba1\u7b97\u56de\u5f52\u635f\u5931\uff0c\u53ea\u5229\u7528\u6b63\u6837\u672c\u8ba1\u7b97\u56de\u5f52\u635f\u5931\uff0c\u56e0\u6b64\u65e0\u5f71\u54cd\n            # \u540e\u9762\u662f\u901a\u8fc7labels_per_image\u53d8\u91cf\u6765\u8bb0\u5f55\u6b63\u6837\u672c\u4f4d\u7f6e\u7684\uff0c\n            # matched_gt_boxes_per_image\u8868\u793a\u6bcf\u4e2a\u951a\u70b9\u6240\u5339\u914d\u5230\u7684box\u5750\u6807\u3002\n            matched_gt_boxes_per_image = gt_boxes[matched_idxs.clamp(min=0)]\n\n            # \u8bb0\u5f55\u6240\u6709anchors\u5339\u914d\u540e\u7684\u6807\u7b7e\n            labels_per_image = matched_idxs &gt;= 0\n            # \u6b63\u951a\u70b9\u6837\u672c\u5904\u6807\u8bb0\u4e3a1\n            labels_per_image = labels_per_image.to(dtype=torch.float32)\n\n            # background (negative examples) \u5f97\u5230\u80cc\u666f\u7d22\u5f15\n            bg_indices = matched_idxs == self.proposal_matcher.BELOW_LOW_THRESHOLD  # -1\n            # \u8d1f\u951a\u70b9\u6837\u672c\u5904\u6807\u8bb0\u4e3a0\n            labels_per_image[bg_indices] = 0.0\n\n            # IOU\u503c\u5728\u4e24\u4e2a\u9608\u503c\u4e4b\u95f4\uff0c\u8981\u4e22\u5f03\u7684\u6837\u672c\n            inds_to_discard = matched_idxs == self.proposal_matcher.BETWEEN_THRESHOLDS  # -2\n            # \u4e22\u5f03\u951a\u70b9\u6837\u672c\u8bbe\u7f6e\u4e3a-1\n            labels_per_image[inds_to_discard] = -1.0\n\n        # \u8fd9\u91cc\u7684label\u8868\u793a\u6bcf\u4e2a\u951a\u70b9\u6b63\u8d1f\u6837\u672c\u7684\u5212\u5206\n        # matched_gt_boxes_per_image\u8868\u793a\u6bcf\u4e2a\u951a\u70b9\u4e0e\u76f8\u5339\u914d\u7684\u76ee\u6807\u6846\n        labels.append(labels_per_image)\n        matched_gt_boxes.append(matched_gt_boxes_per_image)\n    # \u8fd4\u56de\u951a\u70b9\u6807\u7b7e\u4e0e\u951a\u70b9\u5339\u914d\u7684box\u5750\u6807(\u6807\u7b7e\u6846\u7684\u5750\u6807)\n    return labels, matched_gt_boxes  \n</code></pre>"},{"location":"detection/network/Faster_RCNN/RPN/#_8","title":"\u8ba1\u7b97\u635f\u5931","text":"<pre><code>def compute_loss(self, objectness, pred_bbox_deltas, labels, regression_targets):\n    # type: (Tensor, Tensor, List[Tensor], List[Tensor]) -&gt; Tuple[Tensor, Tensor]\n    \"\"\"\n    \u8ba1\u7b97RPN\u635f\u5931\uff0c\u5305\u62ec\u7c7b\u522b\u635f\u5931\uff08\u524d\u666f\u4e0e\u80cc\u666f\uff09\uff0cbbox regression\u8fb9\u754c\u6846\u56de\u5f52\u635f\u5931\n    Arguments:\n        objectness (Tensor)\uff1a\u6bcf\u4e2a\u951a\u70b9\u9884\u6d4b\u7684\u524d\u666f\u6982\u7387\n        pred_bbox_deltas (Tensor)\uff1a\u6bcf\u4e2a\u951a\u70b9\u9884\u6d4b\u7684bbox regression\n        labels (List[Tensor])\uff1a\u6bcf\u4e2a\u951a\u70b9\u7684\u771f\u5b9e\u7684\u6807\u7b7e 1, 0, -1\uff08batch\u4e2d\u6bcf\u4e00\u5f20\u56fe\u7247\u7684labels\u5bf9\u5e94List\u7684\u4e00\u4e2a\u5143\u7d20\u4e2d\uff09\n        regression_targets (List[Tensor])\uff1a\u771f\u5b9e\u7684\u8fb9\u754c\u6846\u56de\u5f52\u635f\u5931bbox regression\n\n    Returns:\n        objectness_loss (Tensor) : \u7c7b\u522b\u635f\u5931\n        box_loss (Tensor)\uff1a\u8fb9\u754c\u6846\u56de\u5f52\u635f\u5931\n    \"\"\"\n    # \u6309\u7167\u7ed9\u5b9a\u7684batch_size_per_image, positive_fraction\u7b5b\u9009\u7279\u5b9a\u6bd4\u4f8b\u7684\u6b63\u8d1f\u6837\u672c\n    # \u5206\u522b\u8fd4\u56de\u6b63\u6837\u672c\u548c\u8d1f\u6837\u672c\u7684mask\uff0c\u4fdd\u8bc1\u8d1f\u6837\u672c\u4e0d\u5360\u4e3b\u5bfc\n    sampled_pos_inds, sampled_neg_inds = self.fg_bg_sampler(labels)\n    # \u5c06\u4e00\u4e2abatch\u4e2d\u7684\u6240\u6709\u6b63\u8d1f\u6837\u672cList(Tensor)\u5206\u522b\u62fc\u63a5\u5728\u4e00\u8d77\uff0c\u5e76\u83b7\u53d6\u76f8\u5e94\u7684\u7d22\u5f15\n    sampled_pos_inds = torch.where(torch.cat(sampled_pos_inds, dim=0))[0]\n    sampled_neg_inds = torch.where(torch.cat(sampled_neg_inds, dim=0))[0]\n\n    # \u5c06\u53c2\u4e0e\u635f\u5931\u8ba1\u7b97\u7684\u6b63\u8d1f\u6837\u672c\u7d22\u5f15\u62fc\u63a5\u5728\u4e00\u8d77\uff0c\u6ce8\u610f\uff0c\u8fd9\u91cc\u62fc\u63a5\u7684\u662f\u7d22\u5f15\n    sampled_inds = torch.cat([sampled_pos_inds, sampled_neg_inds], dim=0)\n    # \u5c06\u9884\u6d4b\u5f97\u5230\u7684\u5206\u6570\u5c55\u5e73\n    objectness = objectness.flatten()\n    # \u5c06\u540c\u4e00\u4e2abatch\u91cc\u7684\u6240\u6709\u951a\u70b9\u6807\u7b7e\u5408\u5e76\n    labels = torch.cat(labels, dim=0)\n    regression_targets = torch.cat(regression_targets, dim=0)\n\n    # \u8ba1\u7b97\u8fb9\u754c\u6846\u56de\u5f52\u635f\u5931\n    box_loss = det_utils.smooth_l1_loss(\n        pred_bbox_deltas[sampled_pos_inds],  # \u6b63\u6837\u672c\u7684\u4f4d\u7f6e\n        regression_targets[sampled_pos_inds],  # \u771f\u5b9egt\u76f8\u5bf9\u4e8e\u951a\u70b9\u7684\u4f4d\u7f6e\n        beta=1 / 9,\n        size_average=False,\n    ) / (sampled_inds.numel())\n\n    # \u8ba1\u7b97\u76ee\u6807\u9884\u6d4b\u6982\u7387\u635f\u5931\uff0c\u4ea4\u53c9\u71b5\u635f\u5931\n    objectness_loss = F.binary_cross_entropy_with_logits(\n        objectness[sampled_inds], labels[sampled_inds]\n    )\n    # \u4f9d\u6b21\u8fd4\u56deRPN\u5206\u7c7b\u635f\u5931\u548c\u8fb9\u754c\u6846\u56de\u5f52\u635f\u5931\n    return objectness_loss, box_loss\n</code></pre> <p>\u5e73\u6ed1\u7684L1\u635f\u5931</p> <p>\u8fd9\u91cc\u5176\u5b9e\u4e5f\u53ef\u4ee5\u76f4\u63a5\u8c03\u7528<code>nn.SmoothL1Loss</code></p> <pre><code>def smooth_l1_loss(input, target, beta: float = 1. / 9, size_average: bool = True):\n    # \u9996\u5148\u6c42\u9884\u6d4b\u503c\u4e0e\u6807\u7b7e\u503c\u4e4b\u95f4\u7684L1\u8ddd\u79bb\n    n = torch.abs(input - target)\n    # \u6839\u636e\u8ddd\u79bb\u4e0ebeta\u7684\u76f8\u5bf9\u5927\u5c0f\uff0c\u8fd4\u56de\u4e0d\u540c\u7684\u503c\n    cond = torch.lt(n, beta)\n    # \u5982\u679c\u8ddd\u79bb\u5c0f\u4e8ebeta\uff0c\u5219\u8fd4\u56de0.5 * n ** 2 / beta\uff0c\u5426\u5219\u8fd4\u56den - 0.5 * beta\n    loss = torch.where(cond, 0.5 * n ** 2 / beta, n - 0.5 * beta)\n    if size_average:\n        return loss.mean()\n    return loss.sum()\n</code></pre>"},{"location":"detection/network/Faster_RCNN/RPN/#_9","title":"\u7b5b\u9009\u7279\u5b9a\u6bd4\u4f8b\u7684\u6b63\u8d1f\u6837\u672c","text":"<pre><code>class BalancedPositiveNegativeSampler(object):\n    \"\"\"\n    \u8ba1\u7b97\u635f\u5931\u65f6\uff0c\u6b63\u8d1f\u6837\u672c\u6240\u5360\u7684\u6bd4\u4f8b\uff0c\u786e\u4fdd\u6b63\u6837\u672c\u5360\u6bd4\u4e0d\u4f1a\u592a\u4f4e\n    \"\"\"\n\n    def __init__(self, batch_size_per_image, positive_fraction):\n        # type: (int, float) -&gt; None\n        \"\"\"\n        Arguments:\n            batch_size_per_image (int): \u6bcf\u5f20\u56fe\u7247\u53c2\u4e0e\u8ba1\u7b97\u635f\u5931\u7684\u951a\u70b9\u6570\u91cf\n            positive_fraction (float): \u671f\u671b\u7684\u6b63\u6837\u672c\u5360\u6bd4\n        \"\"\"\n        self.batch_size_per_image = batch_size_per_image\n        self.positive_fraction = positive_fraction\n\n    def __call__(self, matched_idxs):\n        # type: (List[Tensor]) -&gt; Tuple[List[Tensor], List[Tensor]]\n        \"\"\"\n        Arguments:\n            matched idxs: \u951a\u70b9\u6807\u7b7e\n        Returns:\n            pos_idx (list[tensor]): \u88ab\u91c7\u5230\u7684\u6b63\u6837\u672c\n            neg_idx (list[tensor]): \u88ab\u91c7\u5230\u7684\u8d1f\u6837\u672c\n        \u4e3a\u6bcf\u4e2a\u56fe\u50cf\u968f\u673a\u91c7\u6837\u53c2\u4e0e\u635f\u5931\u8ba1\u7b97\u7684\u951a\u70b9\n        \"\"\"\n        pos_idx = []\n        neg_idx = []\n        # \u904d\u5386\u6bcf\u5f20\u56fe\u50cf\u7684matched_idxs\n        for matched_idxs_per_image in matched_idxs:\n            # &gt;= 1\u7684\u4e3a\u6b63\u6837\u672c(\u8fd9\u91cc\u6b63\u6837\u672c\u5176\u5b9e\u4e3a1)\n            # \u8fd9\u91cc\u7684torch.where\u529f\u80fd\u548cnonzero\u7c7b\u4f3c\uff0c\u8fd4\u56de\u975e\u96f6\u5143\u7d20\u7d22\u5f15\n            # \u6b63\u6837\u672c\u7684\u7d22\u5f15\n            positive = torch.where(torch.ge(matched_idxs_per_image, 1))[0]\n            # = 0\u7684\u4e3a\u8d1f\u6837\u672c\n            # \u8d1f\u6837\u672c\u7684\u7d22\u5f15\n            negative = torch.where(torch.eq(matched_idxs_per_image, 0))[0]\n\n            # \u6307\u5b9a\u6b63\u6837\u672c\u7684\u6570\u91cf\uff0c\u603b\u6570\u4e58\u4ee5\u6bd4\u4f8b\n            num_pos = int(self.batch_size_per_image * self.positive_fraction)\n            # \u5982\u679c\u6b63\u6837\u672c\u6570\u91cf\u4e0d\u591f\u5c31\u76f4\u63a5\u91c7\u7528\u6240\u6709\u6b63\u6837\u672c\n            num_pos = min(positive.numel(), num_pos)\n            # \u6307\u5b9a\u8d1f\u6837\u672c\u6570\u91cf\n            num_neg = self.batch_size_per_image - num_pos\n            # \u5982\u679c\u8d1f\u6837\u672c\u6570\u91cf\u4e0d\u591f\u5c31\u76f4\u63a5\u91c7\u7528\u6240\u6709\u8d1f\u6837\u672c\n            num_neg = min(negative.numel(), num_neg)\n            # .numel()\u8868\u793a\u8fd4\u56de\u5143\u7d20\u7684\u6570\u76ee\uff0ctorch.randperm\u8868\u793a\u8fd4\u56de\u4e00\u4e2a0\u5230n-1\u7684\u968f\u673a\u6570\u7ec4\uff0c\u8fd9\u91cc\u76f8\u5f53\u4e8e\u5bf9\u539f\u6b63\u8d1f\u6837\u672c\u8fdb\u884c\u6253\u4e71\n            # \u968f\u673a\u9009\u62e9\u6307\u5b9a\u6570\u91cf\u7684\u6b63\u8d1f\u6837\u672c\uff0c\u968f\u673a\u6392\u5e8f\uff0c\u4e4b\u540e\u9009\u53d6\u524dnum_\u4e2a\n            perm1 = torch.randperm(positive.numel(), device=positive.device)[:num_pos]\n            perm2 = torch.randperm(negative.numel(), device=negative.device)[:num_neg]\n            # \u88ab\u951a\u70b9\u7684\u7d22\u5f15\u4fe1\u606f\n            pos_idx_per_image = positive[perm1]\n            neg_idx_per_image = negative[perm2]\n\n            # \u4e3a\u6240\u6709\u7684\u951a\u70b9\u521b\u5efa\u63a9\u6a21\u56fe\n            pos_idx_per_image_mask = torch.zeros_like(\n                matched_idxs_per_image, dtype=torch.uint8\n            )\n            neg_idx_per_image_mask = torch.zeros_like(\n                matched_idxs_per_image, dtype=torch.uint8\n            )\n\n            # \u53ea\u6709\u5728\u88ab\u9009\u5230\u7684\u6b63\u6837\u672c\u5904\u8bbe\u7f6e\u4e3a1\n            pos_idx_per_image_mask[pos_idx_per_image] = 1\n            # \u540c\u4e0a\uff0c\u53ea\u6709\u5728\u88ab\u9009\u5230\u7684\u8d1f\u6837\u672c\u5904\u8bbe\u7f6e\u4e3a1\n            neg_idx_per_image_mask[neg_idx_per_image] = 1\n\n            pos_idx.append(pos_idx_per_image_mask)\n            neg_idx.append(neg_idx_per_image_mask)\n        # \u8fd4\u56de\u53c2\u4e0e\u635f\u5931\u8ba1\u7b97\u7684\u6b63\u8d1f\u6837\u672c\u63a9\u6a21\u56fe\n        return pos_idx, neg_idx\n</code></pre> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e742\u670813\u65e5</p>"},{"location":"detection/network/Faster_RCNN/structure/","title":"\u76ee\u6807\u68c0\u6d4b\uff1aFaster R-CNN\u7f51\u7edc\u7ed3\u6784","text":""},{"location":"detection/network/Faster_RCNN/structure/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aConference and Workshop on Neural Information Processing Systems 2015 (NIPS, 2015)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://proceedings.neurips.cc/paper/2015/file/14bfa6bb14875e45bba028a21ed38046-Paper.pdf</p> <p>\u7c7b\u578b\uff1a\u4e8c\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\uff08two-stage\uff09</p>"},{"location":"detection/network/Faster_RCNN/structure/#_2","title":"\u7b80\u4ecb","text":"<p>\u7f51\u7edc\u6846\u67b6\uff1a</p> <p> <p></p> <p></p> <p>\u6d41\u7a0b\u56fe\u539f\u521b\uff0c\u4f7f\u7528\u8bf7\u544a\u77e5</p>"},{"location":"detection/network/Faster_RCNN/structure/#_3","title":"\u4ee3\u7801","text":"<p>\u6ce8\uff1a\u6a21\u578b\u4ee3\u7801\u6765\u6e90\u4e8ePyTorch\u5b98\u65b9\u5b9e\u73b0\u7684Faster R-CNN\uff0c\u53ef\u7531\u5982\u4e0b\u51fd\u6570\u6307\u4ee4\u76f4\u63a5\u8c03\u53d6\uff1a</p> <pre><code>torchvision.models.detection.FasterRCNN()\n</code></pre> <p>\u53c2\u8003\u94fe\u63a5\uff1a</p> <ul> <li>https://www.bilibili.com/video/BV1of4y1m7nj</li> <li>https://github.com/WZMIAOMIAO/deep-learning-for-image-processing</li> </ul>"},{"location":"detection/network/Faster_RCNN/structure/#_4","title":"\u6574\u4f53\u6846\u67b6","text":"<pre><code># \u8fd9\u91cc\u4e3b\u8981\u5b9a\u4e49\u4e86\u7f51\u7edc\u7684\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b\uff0crpn\u3001roi\u7b49\u6a21\u5757\u7531\u53e6\u4e00\u4e2a\u5bf9\u8c61\u521b\u5efa\nclass FasterRCNNBase(nn.Module):\n    \"\"\"\n    Main class for Generalized R-CNN.\n\n    Arguments:\n        backbone (nn.Module):\n        rpn (nn.Module):\n        roi_heads (nn.Module): takes the features + the proposals from the RPN and computes\n            detections / masks from it.\n        transform (nn.Module): performs the data transformation from the inputs to feed into\n            the model\n    \"\"\"\n\n    def __init__(self, backbone, rpn, roi_heads, transform):\n        super(FasterRCNNBase, self).__init__()\n        # \u56fe\u7247\u9884\u5904\u7406\u65b9\u6cd5\n        self.transform = transform\n        # \u57fa\u5c42\u7684\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\n        self.backbone = backbone\n        # rpn\u6a21\u5757\n        self.rpn = rpn\n        # roi head\u6a21\u5757\n        self.roi_heads = roi_heads\n        # used only on torchscript mode\n        self._has_warned = False\n\n    @torch.jit.unused\n    def eager_outputs(self, losses, detections):\n        # type: (Dict[str, Tensor], List[Dict[str, Tensor]]) -&gt; Union[Dict[str, Tensor], List[Dict[str, Tensor]]]\n        # \u5982\u679c\u662f\u8bad\u7ec3\u9636\u6bb5\uff0c\u5219\u53ea\u8fd4\u56de\u635f\u5931\n        if self.training:\n            return losses\n        # \u5426\u5219\u53ea\u8fd4\u56de\u68c0\u6d4b\u7ed3\u679c\n        return detections\n\n    # \u524d\u5411\u4f20\u64ad\n    def forward(self, images, targets=None):  # \u4f20\u5165\uff1a\u56fe\u7247\u5217\u8868\u3001target\u5217\u8868(\u91cc\u9762\u662f\u5b57\u5178)\n        # type: (List[Tensor], Optional[List[Dict[str, Tensor]]]) -&gt; Tuple[Dict[str, Tensor], List[Dict[str, Tensor]]]\n        \"\"\"\n        Arguments:\n            images (list[Tensor]): images to be processed\n            targets (list[Dict[Tensor]]): ground-truth boxes present in the image (optional)\n\n        Returns:\n            result (list[BoxList] or dict[Tensor]): the output from the model.\n                During training, it returns a dict[Tensor] which contains the losses.\n                During testing, it returns list[BoxList] contains additional fields\n                like `scores`, `labels` and `mask` (for Mask R-CNN models).\n        \"\"\"\n        # \u5982\u679c\u6a21\u578b\u5904\u4e8e\u8bad\u7ec3\u9636\u6bb5\uff0c\u5219\u5fc5\u987b\u4f20\u5165\u6807\u7b7etargets\n        if self.training and targets is None:\n            raise ValueError(\"In training mode, targets should be passed\")\n\n        if self.training:\n            assert targets is not None\n            # \u8fdb\u4e00\u6b65\u5224\u65ad\u4f20\u5165\u7684target\u7684boxes\u53c2\u6570\u662f\u5426\u7b26\u5408\u89c4\u5b9a\n            for target in targets:\n                # \u83b7\u53d6\u8fb9\u754c\u6846\u53c2\u6570\uff0c\u5de6\u4e0a\u89d2\u548c\u53f3\u4e0b\u89d2\u4e24\u4e2a\u70b9\u5750\u6807\n                boxes = target[\"boxes\"]\n                # \u5224\u65ad\u8fb9\u754c\u6846\u662f\u4e0d\u662ftorch.Tensor\n                if isinstance(boxes, torch.Tensor):\n                    # \u5224\u65ad\u8fb9\u754c\u6846\u7b26\u4e0d\u7b26\u5408\u89c4\u5219\n                    if len(boxes.shape) != 2 or boxes.shape[-1] != 4:\n                        raise ValueError(\"Expected target boxes to be a tensor\"\n                                         \"of shape [N, 4], got {:}.\".format(\n                                          boxes.shape))\n                else:\n                    raise ValueError(\"Expected target boxes to be of type \"\n                                     \"Tensor, got {:}.\".format(type(boxes)))\n\n        original_image_sizes = torch.jit.annotate(List[Tuple[int, int]], [])\n        # \u6309\u4f20\u5165\u7684\u6bcf\u4e00\u5f20\u56fe\u7247\u904d\u5386\n        for img in images:\n            # \u540e\u4e24\u4e2a\u7ef4\u5ea6\u5e94\u8be5\u662f\u9ad8\u548c\u5bbd\uff0c\u5373\u56fe\u50cf\u7684\u5c3a\u5bf8\n            val = img.shape[-2:]\n            # \u56fe\u50cf\u5fc5\u987b\u662f\u4e8c\u7ef4\u7684\uff0c\u9632\u6b62\u8f93\u5165\u4e00\u4e2a\u4e00\u7ef4\u7684\u5411\u91cf\n            assert len(val) == 2\n            # \u5c06\u9ad8\u548c\u5bbd\u6dfb\u52a0\u5230\u53d8\u91cf\u4e2d\uff0c\u4e0b\u4e00\u6b65\u4f1a\u8fdb\u884c\u9884\u5904\u7406(\u56fe\u7247\u6309\u6bd4\u4f8b\u7f29\u653e\u5230\u4e00\u5b9a\u7684\u8303\u56f4\u4e2d)\uff0c\u4e4b\u540e\u5c06\u8f93\u51fa\u6620\u5c04\u56de\u539f\u56fe\u50cf\u4e2d\uff0c\u5c31\u9700\u8981\u8fd9\u4e2a\u53d8\u91cf\u4e86\n            original_image_sizes.append((val[0], val[1]))\n        # original_image_sizes = [img.shape[-2:] for img in images]\n        # \u9884\u5904\u7406\u4e4b\u540e\u5c31\u53d8\u6210\u4e86\u4e00\u4e2abatch\u4e86\n        images, targets = self.transform(images, targets)  # \u5bf9\u56fe\u50cf\u8fdb\u884c\u9884\u5904\u7406\n\n        # \u5982\u679c\u662ffpn\u7684\u8bdd\uff0c\u4f1a\u8f93\u51fa\u4e00\u7ec4\u7279\u5f81\u56fe\uff0c\u952e\u5206\u522b\u4e3a'0','1','2','3','pool'(\u9ed8\u8ba4\u60c5\u51b5\u4e0b)\uff0c\u503c\u4f9d\u6b21\u4e3a\u5377\u79ef\u7f51\u7edc\u6bcf\u4e2a\u9636\u6bb5\u8f93\u51fa\u7684\u7279\u5f81\u56fe\n        # \u5982\u679c\u4e0d\u5229\u4e8efpn\u7684\u8bdd\uff0c\u5219\u53ea\u8f93\u51fa\u4e00\u7ec4\u7279\u5f81\u56fe\n        features = self.backbone(images.tensors)  # \u5c06\u56fe\u50cf\u8f93\u5165backbone\u5f97\u5230\u7279\u5f81\u56fe\n        # \u82e5\u53ea\u5728\u4e00\u5c42\u7279\u5f81\u5c42\u4e0a\u9884\u6d4b\uff0c\u5c06feature\u653e\u5165\u6709\u5e8f\u5b57\u5178\u4e2d\uff0c\u5e76\u7f16\u53f7\u4e3a\u20180\u2019\u3002\u82e5\u5229\u7528FPN\uff0c\u5219\u5728\u591a\u5c42\u4e0a\u9884\u6d4b\uff0c\u8f93\u51fa\u672c\u8eab\u5c31\u4e3a\u5b57\u5178\u683c\u5f0f\n        if isinstance(features, torch.Tensor):\n            # \u6700\u7ec8\u5c31\u662f\u8981\u5c06\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u8f6c\u5316\u4e3a\u5b57\u5178\u683c\u5f0f\uff0c\u4fbf\u4e8e\u540e\u7eed\u8c03\u7528\n            features = OrderedDict([('0', features)])\n\n        # \u5c06\u7279\u5f81\u5c42\u7684\u7279\u5f81\u56fe\u4ee5\u53ca\u6807\u6ce8target\u4fe1\u606f\u4f20\u5165rpn\u4e2d\n        # proposals: List[Tensor], Tensor_shape: [num_proposals, 4]\n        # \u6bcf\u4e2aproposals\u662f\u7edd\u5bf9\u5750\u6807\uff0c\u4e14\u4e3a(x1, y1, x2, y2)\u683c\u5f0f\uff0c\u6570\u91cf\u4e3a\u9884\u5148\u8bbe\u5b9a\u597d\u7684(2000\u4e2a),proposal_losses\u4e3aRPN\u9636\u6bb5\u7684\u635f\u5931\n        # \u7edd\u5bf9\u5750\u6807:\u5bf9\u5e94\u4e8e\u539f\u56fe(\u9884\u5904\u7406\u540e\u7684\u56fe\u50cf)\u7684\u5750\u6807\uff0c\u5373\u4e0etargets\u4e2d\u7684\u5750\u6807\u76f8\u5bf9\u5e94\n        proposals, proposal_losses = self.rpn(images, features, targets)\n\n        # \u5c06rpn\u751f\u6210\u7684\u6570\u636e\u4ee5\u53ca\u6807\u6ce8target\u4fe1\u606f\u4f20\u5165fast rcnn\u540e\u534a\u90e8\u5206\n        # detections\u4e3a\u68c0\u6d4b\u5230\u7684\u76ee\u6807\uff0cdetector_losses\u4e3aFaster R-CNN\u540e\u534a\u90e8\u5206\u7684\u635f\u5931\n        detections, detector_losses = self.roi_heads(features, proposals, images.image_sizes, targets)\n\n        # \u5bf9\u7f51\u7edc\u7684\u9884\u6d4b\u7ed3\u679c\u8fdb\u884c\u540e\u5904\u7406\uff0c\u4e3b\u8981\u5c06bboxes\u8fd8\u539f\u5230\u539f\u56fe\u50cf\u5c3a\u5ea6\u4e0a\uff0c\u5373\u9884\u5904\u7406\u4e4b\u524d\u7684\u5c3a\u5ea6\n        detections = self.transform.postprocess(detections, images.image_sizes, original_image_sizes)\n        # \u8bb0\u5f55\u635f\u5931\n        losses = {}\n        losses.update(detector_losses)\n        losses.update(proposal_losses)\n\n        if torch.jit.is_scripting():\n            if not self._has_warned:\n                warnings.warn(\"RCNN always returns a (Losses, Detections) tuple in scripting\")\n                self._has_warned = True\n            return losses, detections\n        else:\n            # \u8fd4\u56deself.eager_outputs\u7684\u65b9\u6cd5\n            # \u5176\u5b9e\u5c31\u4e24\u70b9:\u5982\u679c\u662f\u8bad\u7ec3\u9636\u6bb5\uff0c\u5c31\u8fd4\u56de\u635f\u5931;\u5982\u679c\u662f\u6d4b\u8bd5\u9636\u6bb5\uff0c\u8fd4\u56de\u68c0\u6d4b\u7ed3\u679c\n            return self.eager_outputs(losses, detections)\n</code></pre>"},{"location":"detection/network/Faster_RCNN/structure/#_5","title":"\u6a21\u578b\u53c2\u6570\u521d\u59cb\u5316","text":"<p>\u53c2\u6570\u610f\u4e49\uff1a</p> <ul> <li><code>backbone</code>\uff1a\u4e3b\u5e72\u7279\u5f81\u63d0\u53d6\u7f51\u7edc</li> <li><code>num_classes</code>\uff1a\u6570\u636e\u96c6\u7c7b\u522b\u6570\u91cf</li> <li><code>min_size</code>\u3001<code>max_size</code>\uff1a\u56fe\u7247\u9884\u5904\u7406\u65f6\u9650\u5236\u7684\u6700\u5c0f\u5c3a\u5bf8\u548c\u6700\u5927\u5c3a\u5bf8</li> <li><code>image_mean</code>\u3001<code>image_std</code>\uff1a\u56fe\u7247\u6807\u51c6\u5316\u65f6\u4f7f\u7528\u7684\u5747\u503c\u548c\u65b9\u5dee</li> <li><code>rpn_anchor_generator</code>\uff1a\u951a\u70b9\u751f\u6210\u5668\uff0c\u7528\u4e8e\u751f\u6210\u951a\u70b9\u56fe</li> <li><code>rpn_head</code>\uff1aRPN\u68c0\u6d4b\u5934\uff0c\u7528\u4e8e\u68c0\u6d4b\u7279\u5f81\u56fe\u4e0a\u9884\u6d4b\u76ee\u6807\u7684\u6982\u7387\u548c\u56de\u5f52\u53c2\u6570</li> <li><code>rpn_pre_nms_top_n_train</code>\u3001<code>rpn_pre_nms_top_n_test</code>\uff1aRPN\u4e2d\uff0cNMS\u4e4b\u524d\uff0c\u6bcf\u4e2a\u9636\u6bb5(FPN\u6709\u591a\u4e2a\u9884\u6d4b\u7279\u5f81\u5c42)\u6240\u6700\u591a\u4fdd\u7559\u7684\u68c0\u6d4b\u76ee\u6807\u6570\u91cf\uff0c\u4e00\u4e2a\u8868\u793a\u8bad\u7ec3\u3001\u4e00\u4e2a\u8868\u793a\u6d4b\u8bd5\uff0c\u4e0b\u9762\u540c\u7406</li> <li><code>rpn_post_nms_top_n_train</code>\u3001<code>rpn_post_nms_top_n_test</code>\uff1aRPN\u4e2d\uff0cNMS\u540e\uff0c\u7efc\u5408\u6240\u6709\u9636\u6bb5\u6240\u4fdd\u7559\u7684\u68c0\u6d4b\u76ee\u6807\u6570\u91cf</li> <li><code>rpn_nms_thresh</code>\uff1aRPN\u4e2dNMS\u5904\u7406\u65f6\u4f7f\u7528\u7684IOU\u9608\u503c</li> <li><code>rpn_fg_iou_thresh</code>\u3001<code>rpn_bg_iou_thresh</code>\uff1aRPN\u8fc7\u7a0b\u4e2d\uff0c\u5212\u5206\u6b63\u8d1f\u6837\u672c\u65f6\u8bbe\u7f6e\u7684\u9608\u503c(IOU\u5927\u4e8e\u591a\u5c11\u89c6\u4e3a\u6b63\u6837\u672c\u3001\u5c0f\u4e8e\u591a\u5c11\u89c6\u4e3a\u8d1f\u6837\u672c)</li> <li><code>rpn_batch_size_per_image</code>\u3001<code>rpn_positive_fraction</code>\uff1aRPN\u8ba1\u7b97\u635f\u5931\u65f6\u91c7\u6837\u7684\u6837\u672c\u6570\u4ee5\u53ca\u6b63\u6837\u672c\u6240\u5360\u7684\u6bd4\u4f8b</li> <li><code>box_roi_pool</code>\uff1aROIPool\u6a21\u5757\uff0c\u76f8\u5f53\u4e8e\u5229\u7528RPN\u9884\u6d4b\u5f97\u5230\u7684\u76ee\u6807\u6846\u5c06\u7279\u5f81\u56fe\u8fdb\u884c\u88c1\u526a\uff0c\u518d\u653e\u5927\u5230\u6307\u5b9a\u5927\u5c0f</li> <li><code>box_head</code>\u3001<code>box_predictor</code>\uff1aROI\u4e2d\u7528\u4e8e\u9884\u6d4b\u7c7b\u522b\u6982\u7387\u548c\u56de\u5f52\u53c2\u6570\u7684\u6a21\u5757</li> <li><code>box_score_thresh</code>\uff1a\u7528\u4e8e\u79fb\u9664\u76ee\u6807\u6982\u7387\u4f4e\u4e8e\u6b64\u503c\u7684\u60c5\u51b5</li> <li><code>box_nms_thresh</code>\uff1aROI\u4e2dNMS\u5904\u7406\u7684IOU\u9608\u503c</li> <li><code>box_detections_per_img</code>\uff1aROI\u4e2d\u6700\u7ec8\u63d0\u53d6\u7684\u76ee\u6807\u6570\u91cf(\u6839\u636e\u76ee\u6807\u5b58\u5728\u7684\u6982\u7387\u6392\u5e8f\uff0c\u53d6\u524dn\u4e2a)</li> <li><code>box_fg_iou_thresh</code>\u3001<code>box_bg_iou_thresh</code>\uff1a\u548cRPN\u4e2d\u610f\u4e49\u7c7b\u4f3c\uff0c\u5224\u65adfast rcnn\u4e2d\u6b63\u8d1f\u6837\u672c\u65f6\u7684\u9608\u503c</li> <li><code>box_batch_size_per_image</code>\u3001<code>box_positive_fraction</code>\uff1a\u548cRPN\u4e2d\u610f\u4e49\u7c7b\u4f3c\uff0c\u8ba1\u7b97fast rcnn\u8bef\u5dee\u65f6\u91c7\u7528\u7684\u6837\u672c\u6570\u4ee5\u53ca\u6b63\u6837\u672c\u6240\u5360\u6bd4\u4f8b</li> </ul> <pre><code># \u521d\u59cb\u5316\u5404\u79cd\u6a21\u5757\nclass FasterRCNN(FasterRCNNBase):\n        def __init__(self, backbone, num_classes=None,  # num_classes\u68c0\u6d4b\u76ee\u6807\u7684\u7c7b\u522b\u4e2a\u6570\uff0c\u7c7b\u522b\u52a0\u80cc\u666f(N+1)\n                 # transform parameter\n                 # \u9884\u5904\u7406resize\u65f6\u9650\u5236\u56fe\u7247\u7684\u6700\u5c0f\u5c3a\u5bf8\u4e0e\u6700\u5927\u5c3a\u5bf8\n                 min_size=800, max_size=1333,\n                 # \u9884\u5904\u7406normalize\u65f6\u4f7f\u7528\u7684\u5747\u503c\u548c\u65b9\u5dee\n                 image_mean=None, image_std=None,\n                 # RPN parameters\n                 # rpn_anchor_generator\u7528\u4e8e\u751f\u6210\u951a\u70b9\u56fe\uff0crpn_head\u4e3arpn\u68c0\u6d4b\u5934\uff0c\u7528\u4e8e\u68c0\u6d4b\"\u5efa\u8bae\u533a\u57df\"\n                 rpn_anchor_generator=None, rpn_head=None,\n                 # FPN\u6709\u591a\u4e2a\u9884\u6d4b\u7279\u5f81\u5c42\uff0c\u6bcf\u5c42\u5728NMS\u524d\u90fd\u4fdd\u75592000\u4e2a\uff0c\u603b\u5171\u52a0\u8d77\u6765\u4e0a\u4e07\uff0c\u4e4b\u540e\u901a\u8fc7NMS\u4fdd\u75592000\u4e2a\n                 # \u8bad\u7ec3\u9636\u6bb5\u6bcf\u5c42\u9ed8\u8ba4\u4fdd\u75592000\u4e2a\uff0c\u6d4b\u8bd5\u9636\u6bb5\u9ed8\u8ba4\u6bcf\u5c42\u4fdd\u75591000\u4e2a\n                 rpn_pre_nms_top_n_train=2000, rpn_pre_nms_top_n_test=1000,\n                 # rpn\u4e2d\u5728nms\u5904\u7406\u540e\u4fdd\u7559\u7684proposal\u603b\u6570\uff0c\u6240\u6709\u9636\u6bb5\u7684proposal\u5408\u5e76\u8d77\u6765\n                 rpn_post_nms_top_n_train=2000, rpn_post_nms_top_n_test=1000,\n                 # rpn\u4e2d\u8fdb\u884cnms\u5904\u7406\u65f6\u4f7f\u7528\u7684iou\u9608\u503c\n                 rpn_nms_thresh=0.7,\n                 # rpn\u8ba1\u7b97\u635f\u5931\u65f6\uff0c\u91c7\u96c6\u6b63\u8d1f\u6837\u672c\u8bbe\u7f6e\u7684\u9608\u503c\n                 rpn_fg_iou_thresh=0.7, rpn_bg_iou_thresh=0.3,\n                 # rpn\u8ba1\u7b97\u635f\u5931\u65f6\u91c7\u6837\u7684\u6837\u672c\u6570\uff0c\u4ee5\u53ca\u6b63\u6837\u672c\u5360\u603b\u6837\u672c\u7684\u6bd4\u4f8b\uff0c\u9ed8\u8ba4\u6b63\u8d1f\u6837\u672c1:1\n                 rpn_batch_size_per_image=256, rpn_positive_fraction=0.5,\n                 rpn_score_thresh=0.0,\n                 # Box parameters\n                 # box_predictor\u7528\u4e8e\u9884\u6d4b\u7c7b\u522b\u6982\u7387\u548c\u8fb9\u754c\u6846\u56de\u5f52\u53c2\u6570\n                 box_roi_pool=None, box_head=None, box_predictor=None,\n                 # \u79fb\u9664\u4f4e\u76ee\u6807\u6982\u7387      fast rcnn\u4e2d\u8fdb\u884cnms\u5904\u7406\u7684\u9608\u503c   \u5bf9\u9884\u6d4b\u7ed3\u679c\u6839\u636escore\u6392\u5e8f\u53d6\u524d100\u4e2a\u76ee\u6807\n                 box_score_thresh=0.05, box_nms_thresh=0.5, box_detections_per_img=100,\n                 # fast rcnn\u8ba1\u7b97\u8bef\u5dee\u65f6\uff0c\u91c7\u96c6\u6b63\u8d1f\u6837\u672c\u8bbe\u7f6e\u7684\u9608\u503c\uff0c\u8fd9\u91cc\u9488\u5bf9\u7684\u662ffast rcnn\uff0c\u4e0a\u9762\u9488\u5bf9rpn\n                 box_fg_iou_thresh=0.5, box_bg_iou_thresh=0.5,\n                 # fast rcnn\u8ba1\u7b97\u8bef\u5dee\u65f6\u91c7\u6837\u7684\u6837\u672c\u6570\uff0c\u4ee5\u53ca\u6b63\u6837\u672c\u5360\u6240\u6709\u6837\u672c\u7684\u6bd4\u4f8b\uff0c\u4e0a\u9762\u90a3\u4e2a\u9488\u5bf9rpn\n                 box_batch_size_per_image=512, box_positive_fraction=0.25,\n                 bbox_reg_weights=None):\n\n        # \u4e3b\u5e72\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u5fc5\u987b\u5305\u542bout_channels(\u8f93\u51fa\u7279\u5f81\u56fe\u7684\u901a\u9053\u6570)\u8fd9\u4e2a\u5c5e\u6027\uff0c\u4fbf\u4e8e\u540e\u7eed\u7684\u8c03\u7528\n        if not hasattr(backbone, \"out_channels\"):\n            raise ValueError(\n                \"backbone should contain an attribute out_channels\"\n                \"specifying the number of output channels  (assumed to be the\"\n                \"same for all the levels\"\n            )\n\n        # \u5982\u679c\u4f20\u5165\u951a\u70b9\u751f\u6210\u5668\u6216\u8005roi pool\u6a21\u5757\u7684\u8bdd\uff0c\u5bf9\u8c61\u5fc5\u987b\u662f\u6307\u5b9a\u7684\u7c7b\n        assert isinstance(rpn_anchor_generator, (AnchorsGenerator, type(None)))\n        assert isinstance(box_roi_pool, (MultiScaleRoIAlign, type(None)))\n\n        if num_classes is not None:\n            if box_predictor is not None:\n                raise ValueError(\"num_classes should be None when box_predictor \"\n                                 \"is specified\")\n        else:\n            if box_predictor is None:\n                raise ValueError(\"num_classes should not be None when box_predictor \"\n                                 \"is not specified\")\n\n        # \u7ecf\u8fc7fpn\u540e\uff0c\u8f93\u51fa\u7279\u5f81\u56fe\u7684\u901a\u9053\u6570\uff0c\u5373\u8f93\u5165RPN\u6a21\u5757\u7279\u5f81\u56fe\u7684\u901a\u9053\u6570\n        out_channels = backbone.out_channels\n\n        # \u82e5anchor\u751f\u6210\u5668\u4e3a\u7a7a\uff0c\u5219\u81ea\u52a8\u751f\u6210\u9488\u5bf9resnet50_fpn\u7684anchor\u751f\u6210\u5668\n        if rpn_anchor_generator is None:\n            # \u5c0fsize\u9884\u6d4b\u5c0f\u76ee\u6807\uff0c\u5927size\u9884\u6d4b\u5927\u76ee\u6807\n            # \u539f\u8bba\u6587\u53ea\u6709(128,), (256,), (512,)\uff0c\u8fd9\u91cc\u591a\u4e86\u4e24\u4e2a\n            anchor_sizes = ((32,), (64,), (128,), (256,), (512,))\n            # \u6bd4\u7387\u5143\u7ec4\u7684\u5143\u7d20\u91cd\u590d5\u904d\uff0c\u6bcf\u4e2asize\u5747\u4e0eratios\u4e2d\u7684\u6bcf\u4e2a\u5143\u7d20\u505a\u5339\u914d\n            aspect_ratios = ((0.5, 1.0, 2.0),) * len(anchor_sizes)\n            # \u5f97\u5230\u951a\u70b9\u751f\u6210\u5668\n            rpn_anchor_generator = AnchorsGenerator(\n                anchor_sizes, aspect_ratios\n            )\n\n        # \u751f\u6210RPN\u901a\u8fc7\u6ed1\u52a8\u7a97\u53e3\u9884\u6d4b\u7f51\u7edc\u90e8\u5206\n        if rpn_head is None:\n            # \u521b\u5efa3*3\u7684\u5377\u79ef\u5c42\u548c1*1\u7684\u5377\u79ef\u5c42\n            rpn_head = RPNHead(\n                out_channels, rpn_anchor_generator.num_anchors_per_location()[0]\n            )\n\n        # \u9ed8\u8ba4rpn_pre_nms_top_n_train = 2000, rpn_pre_nms_top_n_test = 1000,\n        # \u9ed8\u8ba4rpn_post_nms_top_n_train = 2000, rpn_post_nms_top_n_test = 1000,\n        rpn_pre_nms_top_n = dict(training=rpn_pre_nms_top_n_train, testing=rpn_pre_nms_top_n_test)\n        rpn_post_nms_top_n = dict(training=rpn_post_nms_top_n_train, testing=rpn_post_nms_top_n_test)\n\n        # \u5b9a\u4e49\u6574\u4e2aRPN\u6846\u67b6\n        rpn = RegionProposalNetwork(\n            # \u951a\u70b9\u751f\u6210\u5668\uff0crpn\u68c0\u6d4b\u5934\n            rpn_anchor_generator, rpn_head,\n            # \u4f20\u5165\u5212\u5206\u524d\u666f\u4e0e\u80cc\u666f\u7684\u9608\u503c\uff1bfg\u524d\u666f\u76ee\u6807\uff0cbg\u80cc\u666f\u76ee\u6807\n            rpn_fg_iou_thresh, rpn_bg_iou_thresh,\n            # RPN\u8ba1\u7b97\u635f\u5931\u65f6\uff0c\u4f7f\u7528\u7684\u6837\u672c\u6570\u548c\u6b63\u6837\u672c\u5360\u6bd4\n            rpn_batch_size_per_image, rpn_positive_fraction,\n            # nms\u5904\u7406\u4e4b\u524d\uff0c\u9488\u5bf9\u6bcf\u4e2a\u7279\u5f81\u5c42\u4fdd\u7559\u7684\u76ee\u6807\u4e2a\u6570\uff0cnms\u4e4b\u540e\u6240\u6709\u7279\u5f81\u5c42\u76ee\u6807\u5269\u4f59\u7684\u603b\u6570\uff0cnms\u5904\u7406\u65f6\u7684\u9608\u503c\n            rpn_pre_nms_top_n, rpn_post_nms_top_n, rpn_nms_thresh,\n            score_thresh=rpn_score_thresh)\n\n        #  Multi-scale RoIAlign pooling \u7528\u4e8e\u88c1\u526a\u539f\u7279\u5f81\u56fe\n        if box_roi_pool is None:\n            box_roi_pool = MultiScaleRoIAlign(\n                # \u5bf9\u591a\u7ec4\u7279\u5f81\u56fe\u8fdb\u884c\u88c1\u526a\uff0c\u7528\u4e8e\u540e\u7eed\u7684\u9884\u6d4b\uff0c\u5b57\u5178\u7c7b\u578b\n                # \u5728\u54ea\u4e9b\u7279\u5f81\u5c42\u8fdb\u884croi pooling\uff0c\u8fd9\u91cc\u9ed8\u8ba4\u7528\u5230\u4e86RPN\u7279\u5f81\u91d1\u5b57\u5854\uff0c\u56e0\u6b64\u9700\u8981\u5bf9\u591a\u5c42\u8fdb\u884c\u88c1\u526a\n                # \u5982\u679c\u4e0d\u52a0RPN\u7279\u5f81\u91d1\u5b57\u5854\uff0c\u5219\u9700\u8981\u63d0\u524d\u5b9a\u4e49\u597dbox_roi_pool\uff0c\u5373\u53ea\u4f7f\u7528\u6700\u540e\u4e00\u5c42\n                featmap_names=['0', '1', '2', '3'],\n                # roi pooling\u4e4b\u540e\uff0c\u5f97\u5230\u7684\u7279\u5f81\u77e9\u9635\u90fd\u662f7*7\u7684\n                output_size=[7, 7],\n                # sampling_ratio\u8868\u793a\u91c7\u6837\u7387\n                sampling_ratio=2)\n\n        # fast RCNN\u4e2droi pooling\u540e\u7684\u5c55\u5e73\u5904\u7406\u4e24\u4e2a\u5168\u8fde\u63a5\u5c42\u90e8\u5206\n        if box_head is None:\n            # \u8fd4\u56de\u7279\u5f81\u56fe\u7684\u5c3a\u5bf8\uff0c\u9ed8\u8ba4\u7b49\u4e8e7\n            resolution = box_roi_pool.output_size[0]\n            representation_size = 1024\n            # \u7531\u4e24\u4e2a\u5168\u8fde\u63a5\u6784\u6210\n            box_head = TwoMLPHead(\n                out_channels * resolution ** 2,  # 256*7*7,\u901a\u9053\u6570\u3001\u957f\u3001\u5bbd\uff0c\u62c9\u4f38\u4f20\u5165\u5168\u8fde\u63a5\n                # \u9690\u85cf\u5c42\u4e2d\u9690\u85cf\u5355\u5143\u7684\u4e2a\u6570\uff0c\u4e5f\u662f\u8f93\u51fa\u7279\u5f81\u7684\u5c3a\u5bf8\u6570\n                representation_size\n            )\n\n        # \u5728box_head\u7684\u8f93\u51fa\u4e0a\u9884\u6d4b\u90e8\u5206\n        if box_predictor is None:\n            # \u8f93\u5165\u7279\u5f81\u7684\u5c3a\u5bf8\uff0c\u4e0ebox_head\u4e2d\u7684representation_size\u76f8\u5bf9\u5e94\n            representation_size = 1024\n            # \u7528\u4e8e\u9884\u6d4b\u7c7b\u522b\u5206\u6570\u548c\u76ee\u6807\u6846\u56de\u5f52\u53c2\u6570\uff0c\u8fd4\u56de\u4e24\u7ec4\u503c\n            box_predictor = FastRCNNPredictor(\n                representation_size,\n                num_classes)\n\n        # \u5c06roi pooling, box_head\u4ee5\u53cabox_predictor\u7ed3\u5408\u5728\u4e00\u8d77\n        roi_heads = RoIHeads(\n            # box_roi_pool\u8868\u793a\u5229\u7528\u9884\u6d4b\u7684\u6846\u88c1\u526a\u7279\u5f81\u56fe\u7684\u90e8\u5206\uff0cbox_head\u8868\u793a\u4e24\u4e2a\u5168\u8fde\u63a5\uff0cbox_predictor\u8868\u793a\u9884\u6d4b\u8fb9\u754c\u6846\u4ee5\u53ca\u7c7b\u522b\u7684\u6a21\u5757\n            box_roi_pool, box_head, box_predictor,\n            # 0.5  0.5 \u5212\u5206\u6b63\u8d1f\u6837\u672c\u9608\u503c\uff0c\u4e0erpn\u91cc\u9762\u7684\u7528\u6cd5\u7c7b\u4f3c\n            box_fg_iou_thresh, box_bg_iou_thresh,\n            # 512  0.25 \u8ba1\u7b97fast rcnn\u635f\u5931\u6240\u7528\u5230\u7684\u6837\u672c\u6570\u4ee5\u53ca\u6b63\u6837\u672c\u5360\u6bd4\n            box_batch_size_per_image, box_positive_fraction,\n            bbox_reg_weights,\n            # \u9884\u6d4b\u7ed3\u679c\u540e\u5904\u7406\uff0c\u4f7f\u7528\u7684\u9608\u503c\n            box_score_thresh, box_nms_thresh, box_detections_per_img)  # 0.05  0.5  100\n\n        # \u56fe\u50cf\u5747\u503c\u548c\u65b9\u5dee\uff0c\u7528\u4e8e\u9884\u5904\u7406\n        if image_mean is None:\n            image_mean = [0.485, 0.456, 0.406]\n        if image_std is None:\n            image_std = [0.229, 0.224, 0.225]\n\n        # \u5bf9\u6570\u636e\u8fdb\u884c\u6807\u51c6\u5316\uff0c\u7f29\u653e\uff0c\u6253\u5305\u6210batch\u7b49\u5904\u7406\u90e8\u5206\n        transform = GeneralizedRCNNTransform(min_size, max_size, image_mean, image_std)\n        # \u6700\u540e\u7ee7\u627f\u7236\u7c7b\n        super(FasterRCNN, self).__init__(backbone, rpn, roi_heads, transform)\n</code></pre> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e742\u670816\u65e5</p>"},{"location":"detection/network/YOLO/YOLOv3_SPP/","title":"YOLOv3-SPP","text":""},{"location":"detection/network/YOLO/YOLOv3_SPP/#_1","title":"\u7efc\u8ff0","text":"<p>\u8bba\u6587\u5730\u5740\uff1ahttps://arxiv.org/pdf/1804.02767v1.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/ultralytics/yolov3</p> <p>\u7c7b\u578b\uff1a\u4e00\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\uff08one-stage\uff09</p>"},{"location":"detection/network/YOLO/YOLOv3_SPP/#_2","title":"\u4ecb\u7ecd","text":"<p>\u2003\u2003\u7f51\u7edc\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u7ed3\u6784\u56fe\u539f\u521b\uff0c\u4f7f\u7528\u8bf7\u544a\u77e5</p> <p>\u6ce8\uff1a\u5377\u79ef\u5c42\u5177\u4f53\u7684\u53c2\u6570\u4fe1\u606f\u8bf7\u53c2\u8003\uff1ahttps://github.com/WZMIAOMIAO/deep-learning-for-image-processing/blob/master/pytorch_object_detection/yolov3_spp/yolov3spp.png</p>"},{"location":"detection/network/YOLO/YOLOv3_SPP/#_3","title":"\u7ec6\u8282","text":"<p>\u2003\u2003\u65b9\u4fbf\u8d77\u89c1\uff0c\u5c06\u548c\u524d\u666f\u7269\u4f53\u5339\u914d\u7684\u951a\u70b9\u7b80\u79f0\u4e3a\u524d\u666f\u951a\u70b9\uff0c\u53ea\u6709\u524d\u666f\u951a\u70b9\u6240\u5bf9\u5e94\u7684\u7f6e\u4fe1\u5ea6\u5206\u6570\u624d\u4e0d\u4e3a0\u3002</p> <p>\u7f51\u7edc\u7ed3\u6784</p> <ul> <li> <p>\u951a\u70b9\u5c3a\u5bf8\uff1a\u5728COCO\u6570\u636e\u96c6\u4e0a\u5229\u7528k-means\u805a\u7c7b\u7b97\u6cd5\u5c06\u951a\u70b9\u5316\u4e3a9\u4e2a\u7c07\uff0c(10,13), (16,30), (33,23), (30,61), (62,45), (59,119), (116,90), (156,198), (373,326)\uff0c\u5e76\u4e14\u5747\u5300\u5212\u5206\u52303\u7ec4\u9884\u6d4b\u7279\u5f81\u5c42\u4e0a\uff1b</p> </li> <li> <p>\u6bcf\u4e2a\u951a\u70b9\u8981\u9884\u6d4b(1+4+N)\u4e2a\u6570\u636e\uff0c\u5206\u522b\u7528\u4e8e\u8868\u793a\u524d\u666f\u7f6e\u4fe1\u5ea6\u3001\u56db\u4e2a\u5750\u6807\u6570\u636e\u7684\u504f\u79fb\u91cf\u3001\u7c7b\u522b\u9884\u6d4b\u5206\u6570\uff0c\u5176\u4e2d\u5728\u6d4b\u8bd5\u9636\u6bb5\uff0c\u5f53\u524d\u666f\u7f6e\u4fe1\u5ea6\u5927\u4e8e\u67d0\u4e2a\u9608\u503c\u65f6\uff0c\u8bf4\u660e\u5f53\u524d\u951a\u70b9\u4e0a\u6709\u524d\u666f\u7269\u4f53\uff0c\u540e\u7eed\u542f\u7528\u5750\u6807\u504f\u79fb\u91cf\u8ba1\u7b97\u8fb9\u754c\u6846\u5750\u6807\u4ee5\u53ca\u7c7b\u522b\u9884\u6d4b\u5206\u6570\u5f97\u5230\u7269\u4f53\u7c7b\u522b\uff1b</p> </li> <li>Backbone\u91c7\u7528Darknet53\u7f51\u7edc\u7ed3\u6784\uff0c\u548cResNet152\u76f8\u6bd4\uff0c\u7cbe\u5ea6\u7c7b\u4f3c\u4f46\u662f\u901f\u5ea6\u6bd4ResNet152\u5feb1\u500d\uff1b</li> <li>\u548c\u4e00\u822c\u7684\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u76f8\u6bd4\uff0cDarknet53\u4e2d\u629b\u5f03\u4e86\u6c60\u5316\u64cd\u4f5c\uff0c\u91c7\u7528\u6b65\u957f\u4e3a2\u7684\u5377\u79ef\u8fd0\u7b97\u5b9e\u73b0\u4e0b\u91c7\u6837\u529f\u80fd\uff0c\u5e76\u4e14\u6bcf\u4e2a\u6b8b\u5dee\u5757\u4e2d\uff0c\u5148\u75281\\times1\u7684\u5377\u79ef\u538b\u7f29channel\uff0c\u4e4b\u540e\u518d\u75283\\times3\u7684\u5377\u79ef\u6062\u590d\u901a\u9053\u6570\uff1b</li> <li>YOLOv3\u4e5f\u91c7\u7528\u4e86\u7279\u5f81\u91d1\u5b57\u5854\u4e2d\u81ea\u4e0a\u800c\u4e0b\u7684\u7ed3\u6784\uff0c\u5c06\u6d45\u5c42\u7279\u5f81\u4e0e\u6df1\u5c42\u7279\u5f81\u5408\u5e76\uff0c\u7528\u4e8e\u9884\u6d4b\u591a\u4e2a\u5c3a\u5ea6\u7684\u7269\u4f53\uff1b</li> <li>SPP\u6a21\u5757\u901a\u8fc7\u5c06\u591a\u4e2a\u5c3a\u5ea6\u4e0b\u7684\u6c60\u5316\u8fd0\u7b97\u7ed3\u679c\u76f8\u5408\u5e76\uff0c\u6709\u5229\u4e8e\u63d0\u5347\u7f51\u7edc\u7684\u611f\u53d7\u91ce\uff1b</li> <li>\u5bf9\u4e8e\u8f93\u51fa\u7684\u7f6e\u4fe1\u5ea6\u5206\u6570\uff0c\u9700\u8981\u5148\u7ecf\u8fc7\u4e00\u6b21sigmoid\u5f52\u4e00\u5316\u5904\u7406\uff08\u548c\u6b63\u5e38\u5bf9\u5206\u7c7b\u4efb\u52a1\u7684\u5904\u7406\u65b9\u5f0f\u4e00\u6837\uff09\u3002</li> </ul> <p>\u8bad\u7ec3\u9636\u6bb5</p> <ul> <li> <p>\u8bad\u7ec3\u6570\u636e\u7684\u9884\u5904\u7406\u4f7f\u7528mosaic\u589e\u5f3a\u548c\u4eff\u5c04\u53d8\u6362\uff1b</p> </li> <li> <p>\u8bad\u7ec3\u635f\u5931\u5305\u62ec\uff1a\u5bf9\u4e8e\u8fb9\u754c\u6846\u6570\u636e\u7684IoU\u635f\u5931\uff08\u53ef\u6539\u4e3aGIoU\uff09\u3001\u5bf9\u524d\u666f\u951a\u70b9\u7684\u5206\u7c7b\u635f\u5931\u4ee5\u53ca\u5206\u7c7b\u635f\u5931\uff08\u4e24\u4e2a\u5206\u7c7b\u635f\u5931\u5747\u7528\u4ea4\u53c9\u71b5\u5b9e\u73b0\uff09\u3002</p> </li> </ul> <p>\u6d4b\u8bd5\u9636\u6bb5</p> <ul> <li>batch\u8bbe\u4e3a1\uff0c\u5e76\u4e14\u5c06\u539f\u56fe\u7684\u5bbd\u3001\u9ad8\u586b\u5145\u81f332\u7684\u6574\u6570\u500d\uff0832\u4e3a\u9876\u5c42\u7279\u5f81\u56fe\u7684\u611f\u53d7\u91ce\uff09\uff1b</li> <li>\u7b5b\u9009\u51fa\u524d\u666f\u7f6e\u4fe1\u5ea6\u5927\u4e8e\u9884\u8bbe\u9608\u503c\u7684\u951a\u70b9\uff0c\u6839\u636e\u504f\u79fb\u91cf\u4ee5\u53ca\u7c7b\u522b\u5206\u6570\u5f97\u5230\u7269\u4f53\u8fb9\u754c\u6846\u5750\u6807\u4ee5\u53ca\u7c7b\u522b\u3002</li> </ul>"},{"location":"detection/network/YOLO/YOLOv3_SPP/#faster_r-cnn","title":"\u4e0eFaster R-CNN\u7684\u5dee\u5f02","text":"<p>\u951a\u70b9\u5339\u914d\u7b56\u7565\u4e0d\u540c</p> <p>\u2003\u2003YOLO\u4f1a\u591a\u4e00\u4e2a\u9884\u6d4b\u503c\uff0c\u7528\u4e8e\u9884\u6d4b\u524d\u666f\u7f6e\u4fe1\u5ea6\uff0c\u56e0\u6b64\u5bf9\u4e8e\u6bcf\u4e2a\u7269\u4f53\uff0cYOLO\u9996\u5148\u5339\u914d\u51fa\u5c5e\u4e8e\u54ea\u4e2a\u7f51\u683c\uff0c\u8ba1\u7b97\u51fa\u4e2d\u5fc3\u504f\u79fb\u91cf\uff0c\u518d\u5339\u914d\u51fa\u5c5e\u4e8e\u54ea\u4e2a\u951a\u70b9\uff0c\u5f97\u5230\u524d\u666f\u7f6e\u4fe1\u5ea6\u6807\u7b7e\uff0c\u6700\u540e\u518d\u8ba1\u7b97\u8fb9\u754c\u6846\u5bbd\u9ad8\u3002\uff08\u5177\u4f53\u6b65\u9aa4\u53ef\u89c1\u300a\u951a\u70b9-\u951a\u70b9\u5339\u914d\u300b\uff09</p> <p>\u6ce8\uff1aFaster R-CNN\u4e2d\u5229\u7528\u6574\u5f20\u7279\u5f81\u56fe\u4e0a\u7684\u6240\u6709\u951a\u70b9\u9884\u6d4b\uff0c\u56e0\u6b64\u9700\u8981\u9996\u5148\u6784\u5efa\u951a\u70b9\u56fe\uff0c\u627e\u51fa\u6240\u6709\u951a\u70b9\u5728\u539f\u56fe\u4e0a\u5bf9\u5e94\u7684\u5750\u6807\u6570\u636e\uff0c\u4e4b\u540e\u8ba1\u7b97\u6240\u6709\u951a\u70b9\u548c\u7269\u4f53\u8fb9\u754c\u6846\u4e4b\u95f4\u7684IoU\uff0c\u6839\u636eIoU\u5bf9\u951a\u70b9\u6253\u6807\u7b7e\uff0c\u7531\u4e8e\u6d89\u53ca\u6240\u6709\u951a\u70b9\u7684IOU\u8ba1\u7b97\uff0c\u56e0\u6b64\u8fd0\u7b97\u91cf\u8f83\u5927\uff0c\u76f8\u6bd4\u4e4b\u4e0bYOLO\u8fd0\u7b97\u91cf\u8f83\u5c0f\u3002Faster R-CNN\u4e2d\u4e00\u4e2a\u8fb9\u754c\u6846\u53ef\u80fd\u4f1a\u5339\u914d\u591a\u4e2a\u7279\u5f81\u6570\u636e\u4e0a\u7684\u951a\u70b9\uff08\u5339\u914d\u6240\u6709\u53ef\u80fd\u7684\u951a\u70b9\uff0c\u53ea\u8981IOU\u8db3\u591f\u5927\u5373\u53ef\uff0c\u4e0d\u7ba1\u5c5e\u4e8e\u54ea\u4e2a\u7279\u5f81\u70b9\uff0c\u6ca1\u6709\u201c\u4e2d\u5fc3\u201d\u8fd9\u4e00\u6982\u5ff5\uff09\u3002\u800cYOLO\u8bbe\u7f6e\u4e86\u7f51\u683c\u70b9\u8fd9\u4e00\u6982\u5ff5\uff0c\u6bcf\u4e2a\u7f51\u683c\u5bf9\u5e94\u4e00\u4e2a\u7279\u5f81\u70b9\uff0c\u6574\u4e2a\u9884\u6d4b\u7279\u5f81\u56fe\u4e2d\uff08\u5bf9\u4e8e\u6bcf\u5c42\u800c\u8a00\uff09\uff0c\u8be5\u7269\u4f53\u8fb9\u754c\u6846\u53ea\u4f1a\u5339\u914d\u4e00\u4e2a\u7f51\u683c\uff0c\u4e4b\u540e\u518d\u4ece\u8fd9\u4e00\u4e2a\u7f51\u683c\u4e0a\u627e\u9884\u8bbe\u951a\u70b9\uff0c\u627e\u6bd4\u8f83\u50cf\u7684\uff0c\u5927\u5927\u964d\u4f4e\u4e86\u951a\u70b9\u5339\u914d\u6570\u91cf\uff0c\u964d\u4f4e\u4e86\u8fd0\u7b97\u91cf\uff0c\u4f46\u540c\u65f6\u8fd9\u4e48\u64cd\u4f5c\u4f1a\u51cf\u5c0f\u5bb9\u9519\u7387\uff0c\u4ece\u800c\u95f4\u63a5\u964d\u4f4e\u68c0\u6d4b\u7cbe\u5ea6\u3002</p> <p>\u8fb9\u754c\u6846\u56de\u5f52\u7b56\u7565\u4e0d\u540c</p> <p>\u2003\u2003\u4f5c\u8005\u5728YOLOv2\u7684\u8bba\u6587\u4e2d\u6307\u51fa\u539f\u59cb\u7684\u8fb9\u754c\u6846\u56de\u5f52\u7b56\u7565\u7531\u4e8e\u6ca1\u6709\u9650\u5236\u504f\u79fb\u91cf\u7684\u53d6\u503c\u8303\u56f4\uff0c\u5bb9\u6613\u5bfc\u81f4\u4e2d\u5fc3\u70b9x,y\u53ef\u80fd\u4f1a\u9884\u6d4b\u5728\u56fe\u50cf\u7684\u4efb\u4f55\u4e00\u70b9\u4e0a\uff0c\u76f8\u5bf9\u4e8e\u5f53\u524d\u9884\u6d4b\u70b9\u4f1a\u4ea7\u751f\u8f83\u5927\u7684\u504f\u79fb\uff0c\u8fdb\u4e00\u6b65\u5bfc\u81f4\u8bad\u7ec3\u65f6\u7684\u4e0d\u7a33\u5b9a\u3002\u5bf9\u6b64\uff0c\u4f5c\u8005\u505a\u4e86\u6539\u8fdb\uff0c\u5c06\u6bcf\u4e2a\u9884\u6d4b\u7279\u5f81\u70b9\u89c6\u4e3a\u4e00\u4e2a\u7f51\u683c\uff0c\u5c06\u951a\u70b9\u4e2d\u5fc3\u7684\u504f\u79fb\u91cf\u6539\u4e3a\u7f51\u683c\u5de6\u4e0a\u89d2\u5750\u6807\u7684\u504f\u79fb\u91cf\uff0c\u5177\u4f53\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u5176\u4e2db_x,b_y,b_w,b_h\u8868\u793a\u8fb9\u754c\u6846\u7684\u56db\u4e2a\u5750\u6807\u6570\u636e\uff08\u2019xywh\u2019\u683c\u5f0f\uff09\uff0ct_x,t_y,t_w,t_h\u4f9d\u6b21\u8868\u793a\u56db\u4e2a\u5750\u6807\u6570\u636e\u7684\u504f\u79fb\u91cf\uff0cc_x,c_y\u8868\u793a\u7f51\u683c\u5de6\u4e0a\u89d2\u7684\u5750\u6807\uff0cp_w,p_h\u8868\u793a\u7f51\u683c\u4e0a\u5bf9\u5e94\u951a\u70b9\u7684\u5bbd\u9ad8\uff0c\\sigma(\\cdot)\u8868\u793a\\text{Sigmoid}\u5f52\u4e00\u5316\u51fd\u6570\uff0c\u53ef\u4ee5\u5c06\u504f\u79fb\u91cf\u9650\u5236\u5728(0,1)\u8303\u56f4\u5185\uff0c\u6539\u8fdb\u4e4b\u540e\u9884\u6d4b\u6846\u7684\u4e2d\u5fc3\u70b9\u88ab\u9650\u5236\u5728\u951a\u70b9\u4e2d\u5fc3\u70b9\u6240\u5728\u7684\u7f51\u683c\u5355\u5143\u5185\uff0c\u6709\u5229\u4e8e\u6a21\u578b\u7684\u6536\u655b\u3002</p> <p>\u6ce8\uff1a\u8fd9\u91cc\u4e00\u4e2a\u7279\u5f81\u70b9\u5bf9\u5e94\u4e00\u4e2a\u7f51\u683c\uff0c\u540c\u65f6\u4e00\u4e2a\u7279\u5f81\u70b9\u5bf9\u5e94\u591a\u4e2a\u951a\u70b9\uff0c\u56e0\u6b64\u4e00\u4e2a\u7f51\u683c\u4e5f\u5bf9\u5e94\u591a\u4e2a\u951a\u70b9\u3002</p>"},{"location":"detection/network/YOLO/YOLOv3_SPP/#_4","title":"\u6e90\u7801\u7b14\u8bb0","text":"<p>\u4ee3\u7801\u53c2\u8003\uff1a</p> <ul> <li>https://github.com/WZMIAOMIAO/deep-learning-for-image-processing/tree/master/pytorch_object_detection/yolov3_spp</li> <li>https://github.com/ultralytics/yolov3</li> </ul> <p>\u6ce8\uff1a</p> <ul> <li>\u56fe\u50cf\u9884\u5904\u7406\u7b56\u7565\u4e3b\u8981\u5305\u62ecmosaic\u589e\u5f3a\u548c\u4eff\u5c04\u53d8\u6362\uff1b</li> <li>\u4f20\u5165\u7684<code>targets</code>\u4e2d\u7684\u5750\u6807\u6570\u636e\u662f\u76f8\u5bf9\u5750\u6807\uff0c\u6570\u636e\u4ece0-1\u53d6\u503c\uff0c0\u8868\u793a\u56fe\u7247\u5de6\u4fa7\u3001\u4e0a\u4fa7\uff0c1\u8868\u793a\u56fe\u7247\u53f3\u4fa7\u3001\u4e0b\u4fa7\u3002\u56e0\u6b64\u5728\u7b49\u6bd4\u653e\u7f29\u56fe\u7247\u65f6\uff0c\u4e0d\u7528\u989d\u5916\u5904\u7406\u8fb9\u754c\u6846\u6570\u636e\uff0c\u53ea\u9700\u8981\u5c06\u76f8\u5bf9\u6570\u636e\u4e58\u4ee5\u7279\u5f81\u56fe\u3001\u539f\u56fe\u957f\u5bbd\uff0c\u5c31\u53ef\u4ee5\u5f97\u5230\u7269\u4f53\u5728\u7279\u5f81\u56fe\u3001\u539f\u56fe\u4e0a\u7684\u5750\u6807\uff1b</li> <li>\u5728\u8ba1\u7b97\u635f\u5931\u65f6\uff0c\u5bf9\u4e8e\u6bcf\u4e2a\u6240\u7b5b\u9009\u7684\u524d\u666f\u951a\u70b9\uff08\u5373\u7269\u4f53\u4e2d\u5fc3\u6240\u5904\u7684\u951a\u70b9\uff09\uff0c\u90fd\u5bf9\u5e94\u4e00\u4e2a\u6807\u7b7e\uff0c\u6807\u7b7e\u75313\u90e8\u5206\u7ec4\u6210\uff1a\u524d\u666f\u951a\u70b9\u7684\u5e8f\u53f7\uff08\u5373\u54ea\u4e2a\u951a\u70b9\u5bf9\u5e94\u5f53\u524d\u7269\u4f53\uff0c\u4f1a\u5229\u7528GIoU\u505a\u52a0\u6743\u5904\u7406\uff09\uff0c\u4e2d\u5fc3\u5750\u6807\u504f\u79fb\u91cf\uff0c\u8fb9\u754c\u6846\u5728\u7279\u5f81\u56fe\u4e0a\u7684\u5bbd\u9ad8\uff0c\u5176\u4e2d\u4e2d\u5fc3\u5750\u6807\u504f\u79fb\u91cf\u4e0e\u524d\u666f\u951a\u70b9\u5e8f\u53f7\u5177\u6709\u5bf9\u5e94\u5173\u7cfb\uff0c\u56e0\u6b64\u8fd9\u91cc\u9700\u8981\u5f97\u5230\u6bcf\u4e2a\u951a\u70b9\u7684\u7f6e\u4fe1\u5ea6\u3001\u9884\u6d4b\u6570\u636e\u7684\u4e2d\u5fc3\u5750\u6807<code>x\u3001y</code>\u7684\u504f\u79fb\u91cf\u4ee5\u53ca\u9884\u6d4b\u7684\u5bbd\u9ad8<code>w\u3001h</code>\uff1b</li> <li>\u5750\u6807\u504f\u79fb\u91cf\u5229\u7528GIoU\u635f\u5931\u4f18\u5316\uff0c\u5206\u7c7b\u635f\u5931\uff08\u5305\u62ec\u524d\u666f\u5206\u7c7b\uff09\u5229\u7528\u4ea4\u53c9\u71b5\u635f\u5931\u4f18\u5316\u3002</li> </ul>"},{"location":"detection/network/YOLO/YOLOv3_SPP/#_5","title":"\u7f51\u7edc\u7ed3\u6784","text":"<pre><code>class Darknet(nn.Module):\n    \"\"\"\n    YOLOv3 spp object detection model\n    \"\"\"\n    def __init__(self, cfg, img_size=(416, 416), verbose=False):\n        super(Darknet, self).__init__()\n        # \u8fd9\u91cc\u4f20\u5165\u7684img_size\u53ea\u5728\u5bfc\u51faONNX\u6a21\u578b\u65f6\u8d77\u4f5c\u7528\n        self.input_size = [img_size] * 2 if isinstance(img_size, int) else img_size\n        # \u89e3\u6790\u7f51\u7edc\u5bf9\u5e94\u7684.cfg\u6587\u4ef6\n        self.module_defs = parse_model_cfg(cfg)\n        # \u6839\u636e\u89e3\u6790\u7684\u7f51\u7edc\u7ed3\u6784\u4e00\u5c42\u4e00\u5c42\u53bb\u642d\u5efa\n        # self.module_list\u8868\u793a\u6784\u5efa\u7684\u6a21\u5757\uff1bself.routs\u7528\u4e8e\u8bb0\u5f55\u54ea\u4e9b\u5c42\u7684\u7279\u5f81\u56fe\u53ef\u80fd\u4f1a\u540e\u7eed\u88ab\u7528\u5230\n        # \u5982\u6b8b\u5dee\u7ed3\u6784\u7684\u7279\u5f81\u878d\u5408\uff0c\u6216\u7279\u5f81\u62fc\u63a5\uff08\u7c7b\u4f3cFPN\u7ed3\u6784\uff09\n        self.module_list, self.routs = create_modules(self.module_defs, img_size)\n        # \u83b7\u53d6\u6240\u6709YOLOLayer\u5c42\u7684\u7d22\u5f15\n        self.yolo_layers = get_yolo_layers(self)\n\n        # \u6253\u5370\u4e0b\u6a21\u578b\u7684\u4fe1\u606f\uff0c\u5982\u679cverbose\u4e3aTrue\u5219\u6253\u5370\u8be6\u7ec6\u4fe1\u606f\n        self.info(verbose) if not ONNX_EXPORT else None  # print model description\n\n    def forward(self, x, verbose=False):\n        return self.forward_once(x, verbose=verbose)\n\n    def forward_once(self, x, verbose=False):\n        # yolo_out\u6536\u96c6\u6bcf\u4e2ayolo_layer\u5c42\u7684\u8f93\u51fa\n        # out\u6536\u96c6\u6bcf\u4e2a\u6a21\u5757\u7684\u8f93\u51fa\n        yolo_out, out = [], []\n        if verbose:\n            print('0', x.shape)\n            str = \"\"\n        # \u904d\u5386\u7f51\u7edc\u4e2d\u6240\u6709\u7684\u6a21\u5757\n        for i, module in enumerate(self.module_list):\n            name = module.__class__.__name__\n            # \u5224\u65ad\u662f\u5426\u6267\u884c\u6b8b\u5dee\u6c42\u548c \u6216 \u7279\u5f81\u62fc\u63a5\n            if name in [\"WeightedFeatureFusion\", \"FeatureConcat\"]:  # sum, concat\n                if verbose:\n                    l = [i - 1] + module.layers  # layers\n                    sh = [list(x.shape)] + [list(out[i].shape) for i in module.layers]  # shapes\n                    str = ' &gt;&gt; ' + ' + '.join(['layer %g %s' % x for x in zip(l, sh)])\n                x = module(x, out)  # WeightedFeatureFusion(), FeatureConcat()\n            # \u9884\u6d4b\u5c42\u9884\u6d4b\uff0c\u9884\u6d4b\u7ed3\u679c\u5b58\u5165yolo_out\u4e2d\n            elif name == \"YOLOLayer\":\n                yolo_out.append(module(x))\n            else:  # run module directly, i.e. mtype = 'convolutional', 'upsample', 'maxpool', 'batchnorm2d' etc.\n                x = module(x)\n            # out\u4fdd\u5b58\u6bcf\u4e2a\u6a21\u5757\u7684\u8f93\u51fa\n            out.append(x if self.routs[i] else [])\n            if verbose:\n                print('%g/%g %s -' % (i, len(self.module_list), name), list(x.shape), str)\n                str = ''\n\n        if self.training:  # train\n            return yolo_out\n        elif ONNX_EXPORT:  # export\n            # x = [torch.cat(x, 0) for x in zip(*yolo_out)]\n            # return x[0], torch.cat(x[1:3], 1)  # scores, boxes: 3780x80, 3780x4\n            p = torch.cat(yolo_out, dim=0)\n\n            # # \u6839\u636eobjectness\u8651\u9664\u4f4e\u6982\u7387\u76ee\u6807\n            # mask = torch.nonzero(torch.gt(p[:, 4], 0.1), as_tuple=False).squeeze(1)\n            # # onnx\u4e0d\u652f\u6301\u8d85\u8fc7\u4e00\u7ef4\u7684\u7d22\u5f15\uff08pytorch\u592a\u7075\u6d3b\u4e86\uff09\n            # # p = p[mask]\n            # p = torch.index_select(p, dim=0, index=mask)\n            #\n            # # \u8651\u9664\u5c0f\u9762\u79ef\u76ee\u6807\uff0cw &gt; 2 and h &gt; 2 pixel\n            # # ONNX\u6682\u4e0d\u652f\u6301bitwise_and\u548call\u64cd\u4f5c\n            # mask_s = torch.gt(p[:, 2], 2./self.input_size[0]) &amp; torch.gt(p[:, 3], 2./self.input_size[1])\n            # mask_s = torch.nonzero(mask_s, as_tuple=False).squeeze(1)\n            # p = torch.index_select(p, dim=0, index=mask_s)  # width-height \u8651\u9664\u5c0f\u76ee\u6807\n            #\n            # if mask_s.numel() == 0:\n            #     return torch.empty([0, 85])\n\n            return p\n        else:  # inference or test\n            x, p = zip(*yolo_out)  # inference output, training output\n            x = torch.cat(x, 1)  # cat yolo outputs\n\n            return x, p\n\n    def info(self, verbose=False):\n        \"\"\"\n        \u6253\u5370\u6a21\u578b\u7684\u4fe1\u606f\n        :param verbose:\n        :return:\n        \"\"\"\n        torch_utils.model_info(self, verbose)\n\n\ndef get_yolo_layers(self):\n    \"\"\"\n    \u83b7\u53d6\u7f51\u7edc\u4e2d\u4e09\u4e2a\"YOLOLayer\"\u6a21\u5757\u5bf9\u5e94\u7684\u7d22\u5f15\n    :param self:\n    :return:\n    \"\"\"\n    return [i for i, m in enumerate(self.module_list) if m.__class__.__name__ == 'YOLOLayer']  # [89, 101, 113]\n</code></pre>"},{"location":"detection/network/YOLO/YOLOv3_SPP/#_6","title":"\u5b9a\u4e49\u6240\u6709\u6a21\u5757","text":"<pre><code>def create_modules(modules_defs: list, img_size):\n    \"\"\"\n    Constructs module list of layer blocks from module configuration in module_defs\n    :param modules_defs: \u901a\u8fc7.cfg\u6587\u4ef6\u89e3\u6790\u5f97\u5230\u7684\u6bcf\u4e2a\u5c42\u7ed3\u6784\u7684\u5217\u8868\n    :param img_size:\n    :return:\n    \"\"\"\n\n    img_size = [img_size] * 2 if isinstance(img_size, int) else img_size\n    # \u5220\u9664\u89e3\u6790cfg\u5217\u8868\u4e2d\u7684\u7b2c\u4e00\u4e2a\u914d\u7f6e(\u5bf9\u5e94[net]\u7684\u914d\u7f6e)\n    modules_defs.pop(0)  # cfg training hyperparams (unused)\n    output_filters = [3]  # input channels\uff0c\u7528\u4e8e\u5b58\u50a8\u6bcf\u4e2a\u5c42\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u901a\u9053\u6570\uff0c\u7b2c\u4e00\u5c42\u4e3a\u8f93\u5165\u5c42\uff0c\u76f8\u5f53\u4e8e\u662f\u56fe\u7247\uff0c\u901a\u9053\u6570\u4e3a3\n    module_list = nn.ModuleList()\n    # \u7edf\u8ba1\u54ea\u4e9b\u7279\u5f81\u5c42\u7684\u8f93\u51fa\u4f1a\u88ab\u540e\u7eed\u7684\u5c42\u4f7f\u7528\u5230(\u53ef\u80fd\u662f\u7279\u5f81\u878d\u5408\uff0c\u4e5f\u53ef\u80fd\u662f\u62fc\u63a5)\n    routs = []  # list of layers which rout to deeper layers\n    yolo_index = -1\n\n    # \u904d\u5386\u642d\u5efa\u6bcf\u4e2a\u5c42\u7ed3\u6784\uff0c\u9010\u4e00\u6784\u5efa\n    for i, mdef in enumerate(modules_defs):\n        modules = nn.Sequential()\n\n        if mdef[\"type\"] == \"convolutional\":\n            bn = mdef[\"batch_normalize\"]  # 1 or 0 / use or not\uff0c1\u8868\u793a\u4f7f\u7528BN\uff0c0\u8868\u793a\u4e0d\u4f7f\u7528\n            filters = mdef[\"filters\"] # \u5377\u79ef\u6838\u7684\u4e2a\u6570\uff0c\u5373\u5f53\u524d\u5377\u79ef\u5c42\u8f93\u51fa\u7684\u901a\u9053\u6570\n            k = mdef[\"size\"]  # kernel size\n            stride = mdef[\"stride\"] if \"stride\" in mdef else (mdef['stride_y'], mdef[\"stride_x\"])\n            if isinstance(k, int):\n                # mdef[\"pad\"]\u8868\u793a\u662f\u5426\u542f\u7528padding\n                modules.add_module(\"Conv2d\", nn.Conv2d(in_channels=output_filters[-1],\n                                                       out_channels=filters,\n                                                       kernel_size=k,\n                                                       stride=stride,\n                                                       padding=k // 2 if mdef[\"pad\"] else 0,\n                                                       bias=not bn))\n            else:\n                raise TypeError(\"conv2d filter size must be int type.\")\n\n            if bn:\n                modules.add_module(\"BatchNorm2d\", nn.BatchNorm2d(filters))\n            else:\n                # \u5982\u679c\u8be5\u5377\u79ef\u64cd\u4f5c\u6ca1\u6709bn\u5c42\uff0c\u610f\u5473\u7740\u8be5\u5c42\u4e3ayolo\u7684predictor\uff08\u9664\u4e86\u9884\u6d4b\u5c42\uff0c\u6240\u6709\u7684\u5377\u79ef\u5c42\u90fd\u63a5BN\u5c42\uff09\n                routs.append(i)  # detection output (goes into yolo layer)\n\n            if mdef[\"activation\"] == \"leaky\":  # \u548cBN\u4e00\u6837\uff0c\u6b63\u5e38\u7684\u5377\u79ef\u5c42\u90fd\u63a5leaky\n                modules.add_module(\"activation\", nn.LeakyReLU(0.1, inplace=True))\n            else:\n                pass\n\n        elif mdef[\"type\"] == \"BatchNorm2d\":\n            pass\n\n        # spp\u7ed3\u6784\uff0c\u591a\u4e2amaxpool\u5e76\u8054\n        elif mdef[\"type\"] == \"maxpool\":\n            k = mdef[\"size\"]  # kernel size\n            stride = mdef[\"stride\"]\n            modules = nn.MaxPool2d(kernel_size=k, stride=stride, padding=(k - 1) // 2)\n\n        elif mdef[\"type\"] == \"upsample\":\n            if ONNX_EXPORT:  # explicitly state size, avoid scale_factor\n                g = (yolo_index + 1) * 2 / 32  # gain\n                modules = nn.Upsample(size=tuple(int(x * g) for x in img_size))\n            else:\n                modules = nn.Upsample(scale_factor=mdef[\"stride\"])\n\n        # \u4e00\u4e2a\u503c\u65f6\u8868\u793a\u6307\u5411\u67d0\u4e00\u5c42\u7684\u8f93\u51fa\uff0c\u591a\u4e2a\u503c\u65f6\u8868\u793a\u62fc\u63a5\u591a\u5c42\u7684\u8f93\u51fa\n        # \u7528\u4e8e\u62fc\u63a5\u591a\u4e2a\u9884\u6d4b\u5c42\u7684\u7279\u5f81\u6570\u636e\uff0c\u7c7b\u4f3cFPN\u7ed3\u6784\n        elif mdef[\"type\"] == \"route\":  # [-2],  [-1,-3,-5,-6], [-1, 61]\n            layers = mdef[\"layers\"]\n            # +1\u8868\u793a\u52a0\u4e0a\u8f93\u5165\u5c42\u90a3\u4e2a\u5e8f\u53f7\n            # filters\u8868\u793a\u5f53\u524d\u5c42\u8f93\u51fa\u7279\u5f81\u56fe\u901a\u9053\u6570\uff0c\u6709\u62fc\u63a5\u64cd\u4f5c\u7684\u8bdd\u5c31\u8981\u5c06\u591a\u4e2a\u901a\u9053\u6570\u6c42\u548c\n            filters = sum([output_filters[l + 1 if l &gt; 0 else l] for l in layers])\n            # i\u8868\u793a\u5f53\u524d\u5c42\n            routs.extend([i + l if l &lt; 0 else l for l in layers]) # \u8bb0\u5f55\u4f7f\u7528\u54ea\u4e9b\u5c42\u7684\u8f93\u51fa\n            modules = FeatureConcat(layers=layers)\n\n        # \u76f8\u5f53\u4e8e\u662f\u6b8b\u5dee\u8fde\u63a5\n        elif mdef[\"type\"] == \"shortcut\":\n            # \u4e00\u822c\u662f\u4ee5\u524d\u9762\u6570\u7b2c\u4e09\u4e2a\u6a21\u5757\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u505a\u6b8b\u5dee\u8fde\u63a5\uff0c\u4e5f\u5c31\u662flayers=-3\n            layers = mdef[\"from\"]\n            # \u63d0\u53d6\u4e0a\u4e00\u5c42\u8f93\u51fa\u7279\u5f81\u7684\u7279\u5f81\u56fe\u901a\u9053\u6570\n            filters = output_filters[-1]\n            # routs.extend([i + l if l &lt; 0 else l for l in layers])\n            routs.append(i + layers[0])\n            modules = WeightedFeatureFusion(layers=layers, weight=\"weights_type\" in mdef)\n\n        elif mdef[\"type\"] == \"yolo\":\n            # \u4e5f\u5c31\u662f\u9884\u6d4b\u7279\u5f81\u5c42\n            yolo_index += 1  # \u8bb0\u5f55\u662f\u7b2c\u51e0\u4e2ayolo_layer [0, 1, 2]\n            stride = [32, 16, 8]  # \u9884\u6d4b\u7279\u5f81\u5c42\u5bf9\u5e94\u539f\u56fe\u7684\u7f29\u653e\u6bd4\u4f8b\uff0c\u76f8\u5f53\u4e8e\u611f\u53d7\u91ce\n\n            # anchor\u4e2a\u6570\u548c\u9884\u6d4b\u4e2a\u6570\u76f8\u5173\n            # mdef[\"anchors\"][mdef[\"mask\"]\u4f20\u5165\u7684\u662f\u5f53\u524d\u9884\u6d4b\u5c42\u7684\u951a\u70b9\u5bbd\u9ad8\u5c3a\u5bf8\n            modules = YOLOLayer(anchors=mdef[\"anchors\"][mdef[\"mask\"]],  # anchor list\n                                nc=mdef[\"classes\"],  # number of classes\n                                img_size=img_size,\n                                stride=stride[yolo_index])\n\n            # Initialize preceding Conv2d() bias (https://arxiv.org/pdf/1708.02002.pdf section 3.3)\n            try:\n                # \u5bf9\u9884\u6d4b\u5c42\u505a\u521d\u59cb\u5316\n                j = -1\n                # bias: shape(255,) \u7d22\u5f150\u5bf9\u5e94Sequential\u4e2d\u7684Conv2d\n                # view: shape(3, 85)\uff0c\u8fd9\u91ccb\u5c31\u76f8\u5f53\u4e8e\u63d0\u53d6\u4e86conv2d\u4e2d\u7684\u504f\u7f6e\u53c2\u6570\n                b = module_list[j][0].bias.view(modules.na, -1)\n                b.data[:, 4] += -4.5  # obj\n                b.data[:, 5:] += math.log(0.6 / (modules.nc - 0.99))  # cls (sigmoid(p) = 1/nc)\n                module_list[j][0].bias = torch.nn.Parameter(b.view(-1), requires_grad=True)\n            except Exception as e:\n                print('WARNING: smart bias initialization failure.', e)\n        else:\n            print(\"Warning: Unrecognized Layer Type: \" + mdef[\"type\"])\n\n        # Register module list and number of output filters\n        # \u5c06\u6784\u5efa\u7684\u9884\u6d4b\u6a21\u5757\u653e\u8fdb\u53bb\n        module_list.append(modules)\n        output_filters.append(filters)\n\n    routs_binary = [False] * len(modules_defs)\n    for i in routs:\n        # \u8fd9\u91ccrouts_binary\u7528\u4e8e\u7edf\u8ba1\u54ea\u4e9b\u7279\u5f81\u5c42\u7684\u8f93\u51fa\u4f1a\u88ab\u540e\u7eed\u7684\u5c42\u4f7f\u7528\u5230(\u53ef\u80fd\u662f\u7279\u5f81\u878d\u5408\uff0c\u4e5f\u53ef\u80fd\u662f\u62fc\u63a5)\n        # \u4f1a\u88ab\u7528\u5230\u7684\u8bbe\u4e3aTrue\n        routs_binary[i] = True\n    return module_list, routs_binary\n</code></pre>"},{"location":"detection/network/YOLO/YOLOv3_SPP/#_7","title":"\u5b9a\u4e49\u7279\u5f81\u878d\u5408\u64cd\u4f5c","text":"<p>\u5305\u62ec\u6b8b\u5dee\u7ed3\u6784\u7684\u878d\u5408\u3001\u7279\u5f81\u56fe\u7684\u62fc\u63a5</p> <pre><code>class FeatureConcat(nn.Module):\n    \"\"\"\n    \u5c06\u591a\u4e2a\u7279\u5f81\u77e9\u9635\u5728channel\u7ef4\u5ea6\u8fdb\u884cconcatenate\u62fc\u63a5\n    \"\"\"\n    def __init__(self, layers):\n        super(FeatureConcat, self).__init__()\n        self.layers = layers  # layer indices\n        # self.multiple\u7528\u4e8e\u5224\u65ad\u662f\u5408\u5e76\u591a\u4e2a\u8f93\u51fa\u7279\u5f81\u8fd8\u662f\u5f15\u51fa\u5f53\u524d\u8f93\u51fa\u5c42\n        self.multiple = len(layers) &gt; 1  # multiple layers flag\n\n    def forward(self, x, outputs):\n        # \u8fd9\u91cc\u7684outputs\u662f\u6b63\u5411\u4f20\u64ad\u65f6\u4f20\u5165\u7684\uff0c\u548c\u5b9a\u4e49\u7f51\u7edc\u65f6\u7684outputs\u4e0d\u4e00\u6837\n        return torch.cat([outputs[i] for i in self.layers], 1) if self.multiple else outputs[self.layers[0]]\n\n\nclass WeightedFeatureFusion(nn.Module):  # weighted sum of 2 or more layers https://arxiv.org/abs/1911.09070\n    \"\"\"\n    \u5c06\u591a\u4e2a\u7279\u5f81\u77e9\u9635\u7684\u503c\u8fdb\u884c\u878d\u5408(add\u64cd\u4f5c)\n    \"\"\"\n    def __init__(self, layers, weight=False):\n        super(WeightedFeatureFusion, self).__init__()\n        self.layers = layers  # layer indices\n        self.weight = weight  # apply weights boolean\n        self.n = len(layers) + 1  # number of layers \u878d\u5408\u7684\u7279\u5f81\u77e9\u9635\u4e2a\u6570\n        if weight: # \u9ed8\u8ba4\u4e0d\u989d\u5916\u8bbe\u7f6eweight\uff0c\u53ea\u4f5c\u7eaf\u52a0\u6cd5\n            self.w = nn.Parameter(torch.zeros(self.n), requires_grad=True)  # layer weights\n\n    def forward(self, x, outputs):\n        # Weights\n        if self.weight:\n            w = torch.sigmoid(self.w) * (2 / self.n)  # sigmoid weights (0-1)\n            x = x * w[0]\n\n        # Fusion\n        nx = x.shape[1]  # input channels\n        for i in range(self.n - 1):\n            # outputs\u8868\u793a\u7528\u4e8e\u878d\u5408\u7684\u7279\u5f81(\u4e00\u822c\u662f\u524d\u51e0\u5c42)\uff0cx\u8868\u793a\u5f53\u524d\u5c42\u7279\u5f81\n            a = outputs[self.layers[i]] * w[i + 1] if self.weight else outputs[self.layers[i]]  # feature to add\n            na = a.shape[1]  # feature channels\n\n            # Adjust channels\n            # \u6839\u636e\u76f8\u52a0\u7684\u4e24\u4e2a\u7279\u5f81\u77e9\u9635\u7684channel\u9009\u62e9\u76f8\u52a0\u65b9\u5f0f\n            if nx == na:  # same shape \u5982\u679cchannel\u76f8\u540c\uff0c\u76f4\u63a5\u76f8\u52a0\n                x = x + a  # \u4e00\u822c\u662f\u7528\u8fd9\u4e2a\u5206\u652f\uff0c\u76f4\u63a5\u76f8\u52a0\n            elif nx &gt; na:  # slice input \u5982\u679cchannel\u4e0d\u540c\uff0c\u5c06channel\u591a\u7684\u7279\u5f81\u77e9\u9635\u780d\u6389\u90e8\u5206channel\u4fdd\u8bc1\u76f8\u52a0\u7684channel\u4e00\u81f4\n                x[:, :na] = x[:, :na] + a  # or a = nn.ZeroPad2d((0, 0, 0, 0, 0, dc))(a); x = x + a\n            else:  # slice feature\n                x = x + a[:, :nx]\n\n        return x\n</code></pre>"},{"location":"detection/network/YOLO/YOLOv3_SPP/#_8","title":"\u5b9a\u4e49\u9884\u6d4b\u5c42","text":"<pre><code>class YOLOLayer(nn.Module):\n    \"\"\"\n    \u5bf9YOLO\u7684\u8f93\u51fa\u8fdb\u884c\u5904\u7406\n    \u6ce8\u610f:\u9884\u6d4b\u6570\u503c\u5df2\u7ecf\u7531YOLOLayer\u7684\u4e0a\u4e00\u5c42\u5b8c\u6210\uff0c\u5177\u4f53\u53ef\u89c1my_yolov3.cfg\u6587\u4ef6\n    YOLOLayer\u53ea\u662f\u7528\u4e8e\u751f\u6210\u7f51\u683c\u5750\u6807\u6570\u636e\uff0c\u5373\u951a\u70b9\u56fe\uff0c\u6d4b\u8bd5\u9636\u6bb5\u4e2d\uff0c\u951a\u70b9\u56fe\u548c\u4e0a\u4e00\u5c42\u9884\u6d4b\u7684\u6570\u636e\u7ed3\u5408\u53ef\u4ee5\u5f97\u5230\u771f\u5b9e\u5750\u6807\u6570\u636e\n    \"\"\"\n    def __init__(self, anchors, nc, img_size, stride):\n        super(YOLOLayer, self).__init__()\n        # anchors\u8868\u793a\u5f53\u524d\u9884\u6d4b\u5c42\u951a\u70b9\u7684\u5bbd\u9ad8\u5c3a\u5bf8\n        self.anchors = torch.Tensor(anchors)\n        self.stride = stride  # layer stride \u7279\u5f81\u56fe\u4e0a\u4e00\u6b65\u5bf9\u5e94\u539f\u56fe\u4e0a\u7684\u6b65\u8ddd [32, 16, 8]\n        self.na = len(anchors)  # \u951a\u70b9\u7684\u4e2a\u6570\n        self.nc = nc  # \u7c7b\u522b\u4e2a\u6570 number of classes (80) coco\u9ed8\u8ba480\n        self.no = nc + 5  # \u6bcf\u4e2a\u951a\u70b9\u5bf9\u5e94\u591a\u5c11\u4e2a\u8f93\u51fa\u6570\u636e\uff0c\u548c\u7c7b\u522b\u6570\u76f8\u5173number of outputs (85: x, y, w, h, obj, cls1, ...)\n        self.nx, self.ny, self.ng = 0, 0, (0, 0)  # initialize number of x, y gridpoints\n        # \u5c06anchors\u5927\u5c0f\u7f29\u653e\u5230grid\u5c3a\u5ea6\n        # \u4f20\u5165\u7684anchors\u90fd\u662f\u5728\u539f\u56fe\u4e0a\u7684\u5c3a\u5ea6\u6570\u636e\uff0c\u8fd9\u91cc\u9664\u4ee5self.stride\u8868\u660e\u8f6c\u4e3a\u5f53\u524d\u7279\u5f81\u56fe\u5c3a\u5ea6\n        self.anchor_vec = self.anchors / self.stride\n        # batch_size, na, grid_h, grid_w(\u7f51\u683c\u9ad8\u5bbd), wh,\n        # \u503c\u4e3a1\u7684\u7ef4\u5ea6\u5bf9\u5e94\u7684\u503c\u4e0d\u662f\u56fa\u5b9a\u503c\uff0c\u540e\u7eed\u64cd\u4f5c\u53ef\u6839\u636ebroadcast\u5e7f\u64ad\u673a\u5236\u81ea\u52a8\u6269\u5145\n        self.anchor_wh = self.anchor_vec.view(1, self.na, 1, 1, 2)\n        self.grid = None\n\n        if ONNX_EXPORT:\n            self.training = False\n            self.create_grids((img_size[1] // stride, img_size[0] // stride))  # number x, y grid points\n\n    def create_grids(self, ng=(13, 13), device=\"cpu\"):\n        \"\"\"\n        \u66f4\u65b0grids\u4fe1\u606f\u5e76\u751f\u6210\u65b0\u7684grids\u53c2\u6570\n        :param ng: \u7279\u5f81\u56fe\u5927\u5c0f\n        :param device:\n        :return:\n        \"\"\"\n        self.nx, self.ny = ng\n        self.ng = torch.tensor(ng, dtype=torch.float)\n\n        # build xy offsets \u6784\u5efa\u6bcf\u4e2acell\u5904\u7684anchor\u7684xy\u504f\u79fb\u91cf(\u5728feature map\u4e0a\u7684)\n        if not self.training:  # \u8bad\u7ec3\u6a21\u5f0f\u4e0d\u9700\u8981\u56de\u5f52\u5230\u6700\u7ec8\u9884\u6d4bboxes\n            # \u7f51\u683c\u7684x\u5750\u6807\u548cy\u5750\u6807\uff08\u6bcf\u4e2a\u7f51\u683c\u7684\u5de6\u4e0a\u89d2\u5750\u6807\uff0c\u6bcf\u4e2a\u683c\u5b50\u8868\u793a\u4e00\u4e2a\u50cf\u7d20\u70b9\uff0c\u56e0\u6b64\u8fd9\u91cc\u5750\u6807\u95f4\u8ddd\u4e3a1\uff09\n            yv, xv = torch.meshgrid([torch.arange(self.ny, device=device),\n                                     torch.arange(self.nx, device=device)])\n            # \u5c3a\u5bf8\u4e3a(batch_size, na, grid_h, grid_w, wh)\uff0cwh\u8868\u793axy\u5750\u6807\uff0c\u6709\u4e24\u4e2a\u503c\n            self.grid = torch.stack((xv, yv), 2).view((1, 1, self.ny, self.nx, 2)).float()\n\n        if self.anchor_vec.device != device:\n            self.anchor_vec = self.anchor_vec.to(device)\n            self.anchor_wh = self.anchor_wh.to(device)\n\n    # p\u8868\u793a\u9884\u6d4b\u7ed3\u679c\n    # \u8bad\u7ec3\u9636\u6bb5\u53ea\u9700\u8981\u8c03\u6574\u4e00\u4e0b\u5c3a\u5bf8\uff08\u6839\u636e\u951a\u70b9\u9884\u8bbe\u60c5\u51b5\u8c03\u6574\uff09\uff0c\u76f4\u63a5\u8fd4\u56de\u5373\u53ef\n    # \u6d4b\u8bd5\u9636\u6bb5\u9700\u8981\u548c\u951a\u70b9\u5750\u6807\u76f8\u7ed3\u5408\uff0c\u8ba1\u7b97\u5f97\u5230\u539f\u56fe\u4e0a\u7684\u7edd\u5bf9\u5750\u6807\u503c\n    def forward(self, p):\n        if ONNX_EXPORT:\n            bs = 1  # batch size\n        else:\n            # ny\uff0cnx\u5206\u522b\u8868\u793a\u9884\u6d4b\u7279\u5f81\u56fe\u7684\u9ad8\u5bbd\uff0c\u95f4\u63a5\u4f53\u73b0\u4e86\u53c2\u4e0e\u9884\u6d4b\u7684\u951a\u70b9\u6570\u91cf\n            # ny*nx*\u6bcf\u4e2a\u7279\u5f81\u70b9\u4e0a\u7684\u951a\u70b9\u6570\u91cf=\u951a\u70b9\u603b\u6570\uff0c\u5bf9\u5e94p\u7684\u7b2c\u4e8c\u7ef4\u5ea6\u5c3a\u5bf8\uff0c\u8fd9\u91cc\u4e3a75\n            bs, _, ny, nx = p.shape  # batch_size, predict_param(255), grid(13), grid(13)\n            if (self.nx, self.ny) != (nx, ny) or self.grid is None:  # fix no grid bug\n                # \u5148\u5c06\u7279\u5f81\u56fe\u5c3a\u5bf8\n                # \u6d4b\u8bd5\u9636\u6bb5\u4e2d\uff0c\u5229\u7528\u9884\u6d4b\u7279\u5f81\u56fe\u5c3a\u5bf8\u8ba1\u7b97\u7f51\u683c\u5e8f\u53f7\uff0c\u5b58\u5165self\u4e2d\uff0c\u540e\u7eed\u548c\u9884\u6d4b\u7ed3\u679c\u7ed3\u5408\uff0c\u751f\u6210\u8fb9\u754c\u6846\u5750\u6807\u503c\n                self.create_grids((nx, ny), p.device)\n\n        # view: (batch_size, 255, 13, 13) -&gt; (batch_size, 3, 85, 13, 13)\n        # permute: (batch_size, 3, 85, 13, 13) -&gt; (batch_size, 3, 13, 13, 85)\n        # [bs, anchor, grid, grid, xywh + obj + classes]\n        p = p.view(bs, self.na, self.no, self.ny, self.nx).permute(0, 1, 3, 4, 2).contiguous()  # prediction\n        # self.training=False\n        if self.training:\n            return p\n        elif ONNX_EXPORT:\n            # Avoid broadcasting for ANE operations\n            m = self.na * self.nx * self.ny  # 3*\n            ng = 1. / self.ng.repeat(m, 1)\n            grid = self.grid.repeat(1, self.na, 1, 1, 1).view(m, 2)\n            anchor_wh = self.anchor_wh.repeat(1, 1, self.nx, self.ny, 1).view(m, 2) * ng\n\n            p = p.view(m, self.no)\n            # xy = torch.sigmoid(p[:, 0:2]) + grid  # x, y\n            # wh = torch.exp(p[:, 2:4]) * anchor_wh  # width, height\n            # p_cls = torch.sigmoid(p[:, 4:5]) if self.nc == 1 else \\\n            #     torch.sigmoid(p[:, 5:self.no]) * torch.sigmoid(p[:, 4:5])  # conf\n            p[:, :2] = (torch.sigmoid(p[:, 0:2]) + grid) * ng  # x, y\n            p[:, 2:4] = torch.exp(p[:, 2:4]) * anchor_wh  # width, height\n            p[:, 4:] = torch.sigmoid(p[:, 4:])\n            p[:, 5:] = p[:, 5:self.no] * p[:, 4:5]\n            return p\n        else:\n            # inference \u6d4b\u8bd5\u6a21\u5f0f\uff0c\u9884\u6d4b\u7ed3\u679c\u548c\u7f51\u683c\u5750\u6807\u7ed3\u5408\uff0c\u5f97\u5230\u7edd\u5bf9\u5750\u6807\n            # [bs, anchor, grid, grid, xywh + obj + classes]\n            io = p.clone()  # inference output\n            # ...\u8868\u793a\u5176\u4ed6\u7ef4\u5ea6\u5747\u5168\u9009\n            # \u8ba1\u7b97\u5728feature map\u4e0a\u7684xy\u5750\u6807\n            # \u8fd9\u91cc\u4ee5\u53ca\u4e0b\u9762\u90fd\u662f\u5f97\u5230\u76f8\u5bf9\u5750\u6807\uff0c\u76f8\u5bf9\u4e8e\u7279\u5f81\u56fe\u5c3a\u5bf8\u7684\u5750\u6807\uff0c\u540e\u7eed\u518d\u4e58\u4ee5\u6b65\u957f\u5c31\u53ef\u4ee5\u5f97\u5230\u539f\u56fe\u4e0a\u7684\u7edd\u5bf9\u5750\u6807\n            io[..., :2] = torch.sigmoid(io[..., :2]) + self.grid  # xy\n            # \u8ba1\u7b97\u5728feature map\u4e0a\u7684wh\n            io[..., 2:4] = torch.exp(io[..., 2:4]) * self.anchor_wh  # wh yolo method\n            # \u6362\u7b97\u6620\u5c04\u56de\u539f\u56fe\u5c3a\u5ea6\uff0c\u8f6c\u6362\u6210\u539f\u56fe\u7684\u7edd\u5bf9\u5750\u6807\n            io[..., :4] *= self.stride\n            # \u5c06\u5206\u7c7b\u7ed3\u679c\u4f20\u5165sigmoid\uff0c\u8fd9\u91cc\u4e5f\u5305\u62ec\u524d\u666f\u7f6e\u4fe1\u5ea6\u5206\u7c7b\u7ed3\u679c\n            torch.sigmoid_(io[..., 4:])\n            return io.view(bs, -1, self.no), p  # view [1, 3, 13, 13, 85] as [1, 507, 85]\n</code></pre>"},{"location":"detection/network/YOLO/YOLOv3_SPP/#_9","title":"\u635f\u5931\u7684\u8ba1\u7b97","text":"<pre><code>def compute_loss(p, targets, model):  # predictions, targets, model\n    # \u4f20\u5165\u9884\u6d4b\u503c\u548c\u7269\u4f53\u6807\u7b7e\u6570\u636e\uff0c\u8fd9\u91cc\u6807\u7b7e\u542b\u56fe\u7247\u5e8f\u53f7(\u4e00\u4e2abatch\u5185\u90e8)\u3001\u7269\u4f53\u7c7b\u522b\u3001\u8fb9\u754c\u6846\u5750\u6807\u6570\u636e(\u76f8\u5bf9\u5750\u6807\uff0c\u6570\u503c\u8303\u56f4\u4ece0-1)\n    device = p[0].device\n    lcls = torch.zeros(1, device=device)  # Tensor(0)\n    lbox = torch.zeros(1, device=device)  # Tensor(0)\n    lobj = torch.zeros(1, device=device)  # Tensor(0)\n    # tcls\u8868\u793a\u7269\u4f53\u7c7b\u522b\n    # tbox\u8868\u793agt box\u76f8\u5bf9anchor\u7684x,y\u504f\u79fb\u91cf\u4ee5\u53caw,h(w,h\u4e0d\u662f\u504f\u79fb\u91cf\uff0c\u662f\u7279\u5f81\u56fe\u4e0a\u8fb9\u754c\u6846\u7684\u5bbd\u9ad8)\n    # indices\u8868\u793a\u5e8f\u53f7\uff0c\u5b58\u6709[\u56fe\u7247\u5e8f\u53f7\uff0c\u951a\u70b9\u5e8f\u53f7(\u5f53\u524d\u7269\u4f53\u548c\u7b2c\u51e0\u4e2a\u951a\u5730\u5339\u914d)\uff0c\u7f51\u683c\u5e8f\u53f7(\u5bf9\u5e94\u6a2a\u7eb5\u5750\u6807\u4e24\u4e2a\u6570\u636e)]\n    # anch\u5b58\u6709\u951a\u70b9\u5bbd\u9ad8\u5c3a\u5bf8(\u76f8\u5bf9\u4e8e\u7279\u5f81\u56fe\u800c\u8a00)\n    tcls, tbox, indices, anchors = build_targets(p, targets, model)  # targets\n    h = model.hyp  # hyperparameters\n    red = 'mean'  # Loss reduction (sum or mean)\n\n    # Define criteria\n    BCEcls = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h['cls_pw']], device=device), reduction=red)\n    BCEobj = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h['obj_pw']], device=device), reduction=red)\n\n    # class label smoothing https://arxiv.org/pdf/1902.04103.pdf eqn 3\n    cp, cn = smooth_BCE(eps=0.0)\n\n    # focal loss\n    g = h['fl_gamma']  # focal loss gamma\n    # fl_gamma\u5927\u4e8e0\u5c31\u8868\u793a\u4f7f\u7528focal loss\uff0c\u9ed8\u8ba4\u4e0d\u4f7f\u7528\n    if g &gt; 0:\n        BCEcls, BCEobj = FocalLoss(BCEcls, g), FocalLoss(BCEobj, g)\n\n    # per output\n    for i, pi in enumerate(p):  # layer index, layer predictions\n        b, a, gj, gi = indices[i]  # image_idx, anchor_idx, grid_y, grid_x\n        tobj = torch.zeros_like(pi[..., 0], device=device)  # target obj\n\n        nb = b.shape[0]  # number of positive samples\n        if nb:\n            # \u5bf9\u5e94\u5339\u914d\u5230\u6b63\u6837\u672c\u7684\u9884\u6d4b\u4fe1\u606f\n            ps = pi[b, a, gj, gi]  # prediction subset corresponding to targets\n\n            # GIoU \u8ba1\u7b97GIoU\u503c\n            # \u8ba1\u7b97\u9884\u6d4b\u7684x,y\u7684\u504f\u79fb\u91cf\n            pxy = ps[:, :2].sigmoid()\n            # \u7ed3\u5408\u951a\u70b9\u60c5\u51b5 \u8ba1\u7b97\u9884\u6d4b\u5f97\u5230\u7684w\u3001h\n            pwh = ps[:, 2:4].exp().clamp(max=1E3) * anchors[i]\n            pbox = torch.cat((pxy, pwh), 1)  # predicted box\n            # \u8ba1\u7b97giou\u503c\n            giou = bbox_iou(pbox.t(), tbox[i], x1y1x2y2=False, GIoU=True)  # giou(prediction, target)\n            lbox += (1.0 - giou).mean()  # giou loss\n\n            # Obj\n            # \u5229\u7528GIOU\u5bf9\u5339\u914d\u5230\u7684\u524d\u666f\u951a\u70b9\u52a0\u6743\u5904\u7406\uff0c\u8868\u793a\u76f8\u4ea4\u7684\u90e8\u5206\u8d8a\u5927\uff0c\u7f6e\u4fe1\u5ea6\u8d8a\u5927\n            tobj[b, a, gj, gi] = (1.0 - model.gr) + model.gr * giou.detach().clamp(0).type(tobj.dtype)  # giou ratio\n\n            # Class\uff0c\u53ea\u6709\u7c7b\u522b\u6570\u5927\u4e8e1\u65f6\uff0c\u624d\u542f\u7528\u5206\u7c7b\u5668\n            if model.nc &gt; 1:  # cls loss (only if multiple classes)\n                # \u5c06\u7c7b\u522b\u5e8f\u53f7\u8f6c\u4e3a\u72ec\u70ed\u7f16\u7801\n                t = torch.full_like(ps[:, 5:], cn, device=device)  # targets\n                t[range(nb), tcls[i]] = cp\n                # \u6bcf\u4e2a\u7c7b\u4f9d\u6b21\u505a\u4e8c\u5143\u4ea4\u53c9\u71b5\u635f\u5931\n                # 5:\u8868\u793a\u53ea\u63d0\u53d6\u7c7b\u522b\u9884\u6d4b\u5206\u6570\n                lcls += BCEcls(ps[:, 5:], t)  # BCE\n\n            # Append targets to text file\n            # with open('targets.txt', 'a') as file:\n            #     [file.write('%11.5g ' * 4 % tuple(x) + '\\n') for x in torch.cat((txy[i], twh[i]), 1)]\n        # \u7f6e\u4fe1\u5ea6\u635f\u5931\uff0c4\u8868\u793a\u53d6\u51fa\u7b2c\u4e94\u4e2a\u6570\u503c\uff0c\u5bf9\u5e94\u9884\u6d4b\u7684\u7f6e\u4fe1\u5ea6\n        # tobj\u662f\u7f6e\u4fe1\u5ea6\u6807\u7b7e\uff0c\u5927\u90e8\u5206\u6570\u662f0\uff0c\u524d\u666f\u951a\u70b9\u53d6\u503c\u8303\u56f4\u4e3a0-1\n        lobj += BCEobj(pi[..., 4], tobj)  # obj loss\n\n    # \u4e58\u4e0a\u6bcf\u79cd\u635f\u5931\u7684\u5bf9\u5e94\u6743\u91cd\n    lbox *= h['giou']\n    lobj *= h['obj']\n    lcls *= h['cls']\n\n    # loss = lbox + lobj + lcls\n    return {\"box_loss\": lbox,\n            \"obj_loss\": lobj,\n            \"class_loss\": lcls}\n</code></pre>"},{"location":"detection/network/YOLO/YOLOv3_SPP/#_10","title":"\u6807\u7b7e\u6570\u636e\u7684\u5339\u914d","text":"<pre><code>def build_targets(p, targets, model):\n    # Build targets for compute_loss(), input targets(image_idx,class,x,y,w,h)\n    nt = targets.shape[0]\n    tcls, tbox, indices, anch = [], [], [], []\n    gain = torch.ones(6, device=targets.device).long()  # normalized to gridspace gain\n\n    multi_gpu = type(model) in (nn.parallel.DataParallel, nn.parallel.DistributedDataParallel)\n    for i, j in enumerate(model.yolo_layers):  # j: [89, 101, 113]\n        # \u83b7\u53d6\u8be5yolo predictor\u5bf9\u5e94\u7684anchors\n        # \u6ce8\u610fanchor_vec\u662fanchors\u7f29\u653e\u5230\u5bf9\u5e94\u7279\u5f81\u5c42\u4e0a\u7684\u5c3a\u5ea6\uff0c\u56e0\u6b64\u8fd9\u91cc\u7684\u951a\u70b9\u5c3a\u5bf8\u662f\u76f8\u5bf9\u4e8e\u7279\u5f81\u56fe\u7684\u5c3a\u5bf8(\u7279\u5f81\u56fe\u4e0a\u6bcf\u4e2a\u50cf\u7d20\u70b9\u4e4b\u95f4\u7684\u8ddd\u79bb\u89c6\u4e3a1)\n        anchors = model.module.module_list[j].anchor_vec if multi_gpu else model.module_list[j].anchor_vec\n        # p[i].shape: [batch_size, 3, grid_h, grid_w, num_params]\n        # gain\u8868\u793a\u9884\u6d4b\u7279\u5f81\u5c42\u7684\u5c3a\u5bf8\uff0c\u540e\u7eed\u548ctargets\u4e2d\u50a8\u5b58\u7684\u76f8\u5bf9\u5750\u6807\u76f8\u4e58\uff0c\u4f1a\u5f97\u5230\u7279\u5f81\u56fe\u4e0a\u7684\u7edd\u5bf9\u5750\u6807\n        gain[2:] = torch.tensor(p[i].shape)[[3, 2, 3, 2]]  # xyxy gain\n        na = anchors.shape[0]  # number of anchors\uff0c\u9ed8\u8ba43\n        # [3] -&gt; [3, 1] -&gt; [3, nt]\n        at = torch.arange(na).view(na, 1).repeat(1, nt)  # anchor tensor, same as .repeat_interleave(nt)\n\n        # t\u8868\u793a\u7279\u5f81\u56fe\u4e0atarget\u7684\u7edd\u5bf9\u5750\u6807\uff0ctargets\u76f8\u5bf9\u5750\u6807\u4e58\u4ee5\u7279\u5f81\u56fe\u5c3a\u5bf8\u5f97\u5230\n        a, t, offsets = [], targets * gain, 0\n        # Match targets to anchors\uff0c\u5c06\u6807\u7b7e\u548c\u951a\u70b9\u505a\u5339\u914d\n        if nt:\n            # \u901a\u8fc7\u8ba1\u7b97anchor\u6a21\u677f\u4e0e\u6240\u6709target\u7684wh_iou\u6765\u5339\u914d\u6b63\u6837\u672c\n            # j: [3, nt] , iou_t = 0.20\n            # \u5982\u679c\u5b58\u5728target\u7684\u8bdd\uff0c\u8fd9\u91cc\u5148\u5c06target\u4e2d\u6240\u6709\u7684\u76ee\u6807\u4e0e\u951a\u70b9\u505a\u4e00\u6b21\u5339\u914d\n            # \u6bcf\u4e2a\u76ee\u6807\u5339\u914d\u4e00\u4e2a\u951a\u70b9\u6a21\u677f\uff0c\u5339\u914d\u51fa\u4e0e\u76ee\u6807\u8fb9\u754c\u6846\u5bbd\u9ad8\u6bd4\u4f8b\u50cf\u7684\u951a\u70b9\u6a21\u677f\n            # j\u91cc\u884c\u8868\u793a\u6bcf\u4e2a\u7279\u5f81\u4e0a\u7684\u951a\u70b9\u6570\u91cf\uff0c\u5217\u8868\u4e66target\u76ee\u6807\u6570\u91cf\n            # True\u6240\u5728\u7684\u884c\u8868\u793a\u4e0etarget\u76ee\u6807(\u6240\u5728\u7684\u5217)\u6240\u5339\u914d\u7684\u951a\u70b9\u6a21\u677f\u5e8f\u53f7\n            # \u6ce8\u610f\uff0c\u8fd9\u91cc\u53ea\u662f\u8bb2target\u548c\u951a\u70b9\u6a21\u677f\u5339\u914d\uff0c\u5e76\u4e0d\u4f1a\u5f97\u5230\u548c\u7f51\u683c\u4e2d\u7b2c\u51e0\u4e2a\u951a\u70b9\u5339\u914d\n            j = wh_iou(anchors, t[:, 4:6]) &gt; model.hyp['iou_t']  # iou(3,n) = wh_iou(anchors(3,2), gwh(n,2))\n            # t.repeat(na, 1, 1): [nt, 6] -&gt; [3, nt, 6]\n            # \u83b7\u53d6\u6b63\u6837\u672c\u5bf9\u5e94\u7684anchor\u6a21\u677f\u4e0etarget\u4fe1\u606f(\u5148\u7c97\u7565\u5c06\u5339\u914d\u7684\u951a\u70b9\u6a21\u677f\u8868\u793a\u4e3a\u6b63\u7c7b\u951a\u70b9)\n            # \u82e5\u4e00\u4e2a\u8fb9\u754c\u6846\u6807\u7b7e\u5339\u914d\u5230\u591a\u4e2a\u951a\u70b9\u6a21\u677f\uff0c\u5219\u5bf9\u5e94t\u4f1a\u88ab\u201c\u590d\u5236\u201d\u591a\u6b21\n            a, t = at[j], t.repeat(na, 1, 1)[j]  # filter\n\n        # Define\n        # long\u7b49\u4e8eto(torch.int64), \u6570\u503c\u5411\u4e0b\u53d6\u6574\n        # b\u3001c\u5206\u522b\u8868\u793a:\u56fe\u7247\u5e8f\u53f7image_idx(\u4e00\u4e2abatch\u5185\u7684\u5e8f\u53f7), \u7269\u4f53\u7c7b\u522bclass\n        b, c = t[:, :2].long().T\n        # target\u7684\u4e2d\u5fc3\u5750\u6807\uff0c\u7269\u4f53\u8fb9\u754c\u6846\u7684\u4e2d\u70b9\n        gxy = t[:, 2:4]  # grid xy\n        # \u7269\u4f53\u8fb9\u754c\u6846\u7684\u5bbd\u9ad8(\u76f8\u5bf9\u4e8e\u7279\u5f81\u56fe\u800c\u8a00)\n        gwh = t[:, 4:6]  # grid wh\n        # \u5339\u914dtargets\u6240\u5728\u7684grid cell\u5de6\u4e0a\u89d2\u5750\u6807\n        # \u4e0a\u4e0b\u53d6\u6574\uff0c\u5f97\u5230\u5de6\u4e0a\u89d2\u5750\u6807\n        gij = (gxy - offsets).long()\n        gi, gj = gij.T  # grid xy indices\n\n        # Append\n        # gain[3]: grid_h, gain[2]: grid_w\n        # image_idx, anchor_idx, grid indices(y, x)\n        indices.append((b, a, gj.clamp_(0, gain[3]-1), gi.clamp_(0, gain[2]-1)))\n        # gt box\u76f8\u5bf9anchor\u7684x,y\u504f\u79fb\u91cf\u4ee5\u53caw,h\n        tbox.append(torch.cat((gxy - gij, gwh), 1))\n        anch.append(anchors[a])  # anchors\n        tcls.append(c)  # class\n        if c.shape[0]:  # if any targets\n            # \u76ee\u6807\u7684\u6807\u7b7e\u6570\u503c\u4e0d\u80fd\u5927\u4e8e\u7ed9\u5b9a\u7684\u76ee\u6807\u7c7b\u522b\u6570\n            assert c.max() &lt; model.nc, 'Model accepts %g classes labeled from 0-%g, however you labelled a class %g. ' \\\n                                       'See https://github.com/ultralytics/yolov3/wiki/Train-Custom-Data' % (\n                                           model.nc, model.nc - 1, c.max())\n    # tcls\u8868\u793a\u7269\u4f53\u7c7b\u522b\n    # tbox\u8868\u793agt box\u76f8\u5bf9anchor\u7684x,y\u504f\u79fb\u91cf\u4ee5\u53caw,h(w,h\u4e0d\u662f\u504f\u79fb\u91cf\uff0c\u662f\u7279\u5f81\u56fe\u4e0a\u8fb9\u754c\u6846\u7684\u5bbd\u9ad8)\n    # indices\u8868\u793a\u5e8f\u53f7\uff0c\u5b58\u6709[\u56fe\u7247\u5e8f\u53f7\uff0c\u951a\u70b9\u5e8f\u53f7(\u5f53\u524d\u7269\u4f53\u548c\u7b2c\u51e0\u4e2a\u951a\u5730\u5339\u914d)\uff0c\u7f51\u683c\u5e8f\u53f7(\u524d\u666f\u951a\u70b9\u7684\u4f4d\u7f6e\uff0c\u5bf9\u5e94\u6a2a\u7eb5\u5750\u6807\u4e24\u4e2a\u6570\u636e)]\n    # anch\u5b58\u6709\u951a\u70b9\u5bbd\u9ad8\u5c3a\u5bf8(\u76f8\u5bf9\u4e8e\u7279\u5f81\u56fe\u800c\u8a00)\n    return tcls, tbox, indices, anch\n</code></pre> <p>\u8ba1\u7b97GIoU</p> <pre><code># \u8fd9\u91cc\u4f20\u5165\u4e2d\u5fc3\u5750\u6807\u7684\u504f\u79fb\u91cf\u3001\u4ee5\u53ca\u6bcf\u4e2a\u8fb9\u754c\u6846\u7684\u5bbd\u9ad8\n# \u7531\u4e8ebox1\u548cbox2\u5bf9\u5e94\u4f4d\u7f6e\u7684\u4e2d\u5fc3\u5750\u6807\u662f\u76f8\u540c\u7684\uff0c\u56e0\u6b64\u504f\u79fb\u91cf\u5728\u8fd9\u91cc\u53ef\u4ee5\u770b\u6210\u4e2d\u5fc3\u5750\u6807\ndef bbox_iou(box1, box2, x1y1x2y2=True, GIoU=False, DIoU=False, CIoU=False):\n    # Returns the IoU of box1 to box2. box1 is 4, box2 is nx4\n    box2 = box2.t()\n\n    # Get the coordinates of bounding boxes\n    if x1y1x2y2:  # x1, y1, x2, y2 = box1\n        b1_x1, b1_y1, b1_x2, b1_y2 = box1[0], box1[1], box1[2], box1[3]\n        b2_x1, b2_y1, b2_x2, b2_y2 = box2[0], box2[1], box2[2], box2[3]\n    else:  # transform from xywh to xyxy\n        b1_x1, b1_x2 = box1[0] - box1[2] / 2, box1[0] + box1[2] / 2\n        b1_y1, b1_y2 = box1[1] - box1[3] / 2, box1[1] + box1[3] / 2\n        b2_x1, b2_x2 = box2[0] - box2[2] / 2, box2[0] + box2[2] / 2\n        b2_y1, b2_y2 = box2[1] - box2[3] / 2, box2[1] + box2[3] / 2\n\n    # Intersection area\n    # \u8ba1\u7b97\u76f8\u4ea4\u533a\u57df\u7684\u9762\u79ef\n    inter = (torch.min(b1_x2, b2_x2) - torch.max(b1_x1, b2_x1)).clamp(0) * \\\n            (torch.min(b1_y2, b2_y2) - torch.max(b1_y1, b2_y1)).clamp(0)\n\n    # Union Area\n    # \u8ba1\u7b97\u76f8\u5e76\u533a\u57df\u7684\u9762\u79ef\uff0c\u4e24\u4e2a\u8fb9\u754c\u6846\u9762\u79ef\u76f8\u52a0\uff0c\u518d\u51cf\u53bb\u76f8\u4ea4\u7684\u9762\u79ef\uff0c\u7c7b\u4f3c\u5bb9\u65a5\u5b9a\u7406\n    w1, h1 = b1_x2 - b1_x1, b1_y2 - b1_y1\n    w2, h2 = b2_x2 - b2_x1, b2_y2 - b2_y1\n    union = (w1 * h1 + 1e-16) + w2 * h2 - inter\n\n    # \u5f97\u5230iou\u503c\n    iou = inter / union  # iou\n    if GIoU or DIoU or CIoU:\n        # \u8ba1\u7b97\u5927\u8fb9\u754c\u6846\u7684\u5bbd\u9ad8\uff0c\u8fdb\u4e00\u6b65\u8ba1\u7b97\u9762\u79ef\n        cw = torch.max(b1_x2, b2_x2) - torch.min(b1_x1, b2_x1)  # convex (smallest enclosing box) width\n        ch = torch.max(b1_y2, b2_y2) - torch.min(b1_y1, b2_y1)  # convex height\n        if GIoU:  # Generalized IoU https://arxiv.org/pdf/1902.09630.pdf\n            c_area = cw * ch + 1e-16  # convex area\n            # \u8fd4\u56deGIoU\n            return iou - (c_area - union) / c_area  # GIoU\n        if DIoU or CIoU:  # Distance or Complete IoU https://arxiv.org/abs/1911.08287v1\n            # convex diagonal squared \u8ba1\u7b97\u5bf9\u89d2\u7ebf\u7684\u5e73\u65b9\n            c2 = cw ** 2 + ch ** 2 + 1e-16\n            # centerpoint distance squared\n            # \u8ba1\u7b97\u4e24\u4e2a\u77e9\u5f62\u4e2d\u70b9\u7684\u6b27\u5f0f\u8ddd\u79bb\n            rho2 = ((b2_x1 + b2_x2) - (b1_x1 + b1_x2)) ** 2 / 4 + ((b2_y1 + b2_y2) - (b1_y1 + b1_y2)) ** 2 / 4\n            if DIoU:\n                # \u8fd4\u56deDIoU\u503c\n                return iou - rho2 / c2  # DIoU\n            elif CIoU:  # https://github.com/Zzh-tju/DIoU-SSD-pytorch/blob/master/utils/box/box_utils.py#L47\n                # \u989d\u5916\u8ba1\u7b97\u03b1\u548cv\u4e24\u4e2a\u53d8\u91cf\n                v = (4 / math.pi ** 2) * torch.pow(torch.atan(w2 / h2) - torch.atan(w1 / h1), 2)\n                with torch.no_grad():\n                    alpha = v / (1 - iou + v)\n                return iou - (rho2 / c2 + v * alpha)  # CIoU\n\n    return iou\n</code></pre> <p>\u521d\u6b65\u5b8c\u7a3f\u4e8e\uff1a2023\u5e742\u670815\u65e5</p> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u6307\u6b63\u3002</p>"},{"location":"detection/network/YOLO/YOLOv4/","title":"YOLOv4","text":""},{"location":"detection/network/YOLO/YOLOv4/#_1","title":"\u7efc\u8ff0","text":"<p>\u8bba\u6587\u5730\u5740\uff1ahttps://arxiv.org/pdf/2004.10934.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/Tianxiaomo/pytorch-YOLOv4</p> <p>\u7c7b\u578b\uff1a\u4e00\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\uff08one-stage\uff09</p>"},{"location":"detection/network/YOLO/YOLOv4/#_2","title":"\u7f51\u7edc\u7ed3\u6784","text":"<p>\u2003\u2003\u7f51\u7edc\u7ed3\u6784\u56fe\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u7ed3\u6784\u56fe\u539f\u521b\uff0c\u4f7f\u7528\u8bf7\u544a\u77e5</p> <p>\u6ce8\uff1a\u5377\u79ef\u5c42\u5177\u4f53\u53c2\u6570\u8bf7\u53c2\u8003\uff1ahttps://blog.csdn.net/qq_37541097/article/details/123229946</p>"},{"location":"detection/network/YOLO/YOLOv4/#_3","title":"\u6539\u8fdb\u70b9","text":""},{"location":"detection/network/YOLO/YOLOv4/#cspdarknet53","title":"CSPDarknet53","text":"<p>\u2003\u2003\u53c2\u8003\u300aCSPNet\u300b\u8bba\u6587\uff0c\u4f5c\u8005\u5728\u7279\u5f81\u63d0\u53d6\u7f51\u7edcDarknet53\u7684\u57fa\u7840\u4e0a\u5f15\u5165\u4e86CSP\u6a21\u5757\uff0c \u7528\u4e8e\u63d0\u5347\u7f51\u7edc\u7684\u7279\u5f81\u63d0\u53d6\u80fd\u529b\u3001\u964d\u4f4e\u8ba1\u7b97\u91cf\u5e76\u4e14\u964d\u4f4e\u5185\u5b58\u6d88\u8017\u3002\u5177\u4f53\u7684\u6765\u8bf4\uff0c\u5bf9\u4e8e\u6bcf\u4e2a\u9636\u6bb5\u7684\u5377\u79ef\uff08\u4ee5\u6bcf\u6b21\u4e0b\u91c7\u6837\u4f5c\u4e3a\u5377\u79ef\u9636\u6bb5\u7684\u5206\u5272\u70b9\uff09\uff0c\u90fd\u5f15\u5165\u4e00\u6b21CSP\u6a21\u5757\uff0c\u5f62\u6210\u65b0\u7684\u4e0b\u91c7\u6837\u6a21\u5757\uff08Down Sampling Block\uff09\u3002\u9996\u5148\u5229\u7528\u5377\u79ef\u6838\u4e3a1\\times1\u7684\u5377\u79ef\u5c06\u539f\u59cb\u7279\u5f81\u56fe\u5212\u5206\u4e3a\u4e24\u4efd\uff0c\u4e4b\u540e\u4e00\u4efd\u7ecf\u8fc7\u4e00\u7cfb\u5217\u7684\u7279\u5f81\u63d0\u53d6\u64cd\u4f5c\uff08\u5982\u4e0a\u56fe\u4e2d\u7684RCM\uff09\uff0c\u53e6\u4e00\u4efd\u4e0d\u53d8\uff0c\u6700\u540e\u4e24\u4efd\u52a0\u4ee5\u5408\u5e76\uff0c\u518d\u7ecf\u8fc7\u5377\u79ef\u6838\u4e3a1\\times1\u7684\u5377\u79ef\u5c42\u505a\u7279\u5f81\u878d\u5408\uff0c\u5145\u5206\u878d\u5408\u4e24\u4e2a\u5206\u652f\u7684\u7279\u5f81\u3002</p> <p> <p></p> <p></p>"},{"location":"detection/network/YOLO/YOLOv4/#pan","title":"PAN","text":"<p>\u2003\u2003\u6df1\u5c42\u7279\u5f81\u53ef\u4ee5\u4ee3\u8868\u56fe\u50cf\u7684\u6574\u4f53\u7279\u5f81\u54cd\u5e94\uff0c\u800c\u6d45\u5c42\u7279\u5f81\u66f4\u503e\u5411\u4e8e\u8868\u793a\u5c40\u90e8\u7684\u7eb9\u7406\u6a21\u5f0f\uff0c\u5728\u7279\u5f81\u91d1\u5b57\u5854\u4e2d\u5f15\u5165\u4e86\u81ea\u9876\u5411\u4e0b\u7684\u7ed3\u6784\uff0c\u901a\u8fc7\u5c06\u9876\u5c42\u8bed\u4e49\u4fe1\u606f\u4e30\u5bcc\u7684\u6df1\u5c42\u7279\u5f81\u5f80\u4e0b\u4f20\u64ad\uff0c\u4e30\u5bcc\u4e86\u6d45\u5c42\u7279\u5f81\u7684\u8bed\u4e49\u4fe1\u606f\uff0c\u589e\u5f3a\u4e86\u6d45\u5c42\u7279\u5f81\u7684\u5206\u7c7b\u6027\u80fd\u3002\u7531\u4e8e\u6d45\u5c42\u7279\u5f81\u5177\u6709\u826f\u597d\u7684\u5c40\u90e8\u5b9a\u4f4d\u80fd\u529b\uff0c\u56e0\u6b64\u5728\u8bba\u6587\u300aPAN\u300b\u4e2d\uff0c\u4f5c\u8005\u8fdb\u4e00\u6b65\u6784\u5efa\u4e86\u4e00\u4e2a\u81ea\u5e95\u5411\u4e0a\u7684\u7ed3\u6784\uff08\u5982\u4e0b\u56feb\uff09\u6240\u793a\uff0c\u901a\u8fc7\u5c06\u5e95\u5c42\u7684\u6d45\u5c42\u7279\u5f81\u5411\u4e0a\u4f20\u64ad\uff0c\u589e\u5f3a\u4e86\u6574\u4e2a\u7279\u5f81\u5c42\u6b21\u7684\u5b9a\u4f4d\u80fd\u529b\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u5728YOLOv4\u4e2d\u4e5f\u5f15\u5165\u4e86\u8fd9\u79cd\u7ed3\u679c\u3002</p> <p> <p></p> <p></p>"},{"location":"detection/network/YOLO/YOLOv4/#_4","title":"\u504f\u79fb\u91cf","text":"<p>\u672a\u5b8c\u5f85\u7eed\uff0c\u53ef\u53c2\u8003\uff1ahttps://blog.csdn.net/qq_37541097/article/details/123229946</p>"},{"location":"detection/program/IoU/","title":"\u8ba1\u7b97IoU","text":"<p>\u4ee3\u7801\u53c2\u8003\uff1a</p> <ul> <li>https://github.com/WZMIAOMIAO/deep-learning-for-image-processing/tree/master/pytorch_object_detection/yolov3_spp</li> <li>https://github.com/ultralytics/yolov3</li> </ul> <p>\u2003\u2003\u8f93\u5165\uff1a\u4e24\u7ec4\u8fb9\u754c\u6846\u5750\u6807\uff0c\u5982\u679c\u5750\u6807\u683c\u5f0f\u662f\u2019xyxy\u2019\u683c\u5f0f\uff0c\u5219<code>x1y1x2y2</code>\u4f20\u5165<code>True</code>\uff0c\u5982\u679c\u662f\u2019xywh\u2019\u683c\u5f0f\uff0c\u5219<code>x1y1x2y2</code>\u4f20\u5165<code>False</code></p> <p>\u2003\u2003\u8f93\u51fa\uff1a\u4e24\u7ec4\u8fb9\u754c\u6846\u4e4b\u95f4\u7684IoU\u6570\u503c</p> <p>\u2003\u2003\u5176\u4e2d<code>box1</code>\u4e0e<code>box2</code>\u7684\u5c3a\u5bf8\u9700\u76f8\u540c\uff0c\u5747\u4e3a[4,n]\uff0cn\u8868\u793a\u8fb9\u754c\u6846\u7684\u6570\u91cf\uff08\u5177\u6709\u4e00\u4e00\u5bf9\u5e94\u5173\u7cfb\uff09\uff0c\u8f93\u51fa\u53d8\u91cf<code>iou</code>\u4e3a\u4e00\u7ef4\u6570\u636e\uff0c\u5c3a\u5bf8\u4e3a<code>n</code>\uff0c\u8868\u793a<code>n</code>\u4e2a\u8fb9\u754c\u6846\u5bf9\u4e4b\u95f4\u7684IoU\u6570\u503c\u3002</p> <pre><code>def bbox_iou(box1, box2, x1y1x2y2=True, GIoU=False, DIoU=False, CIoU=False):\n    # Returns the IoU of box1 to box2. box1 is 4, box2 is nx4\n    box2 = box2.t()\n\n    # Get the coordinates of bounding boxes\n    if x1y1x2y2:  # x1, y1, x2, y2 = box1\n        b1_x1, b1_y1, b1_x2, b1_y2 = box1[0], box1[1], box1[2], box1[3]\n        b2_x1, b2_y1, b2_x2, b2_y2 = box2[0], box2[1], box2[2], box2[3]\n    else:  # transform from xywh to xyxy\n        b1_x1, b1_x2 = box1[0] - box1[2] / 2, box1[0] + box1[2] / 2\n        b1_y1, b1_y2 = box1[1] - box1[3] / 2, box1[1] + box1[3] / 2\n        b2_x1, b2_x2 = box2[0] - box2[2] / 2, box2[0] + box2[2] / 2\n        b2_y1, b2_y2 = box2[1] - box2[3] / 2, box2[1] + box2[3] / 2\n\n    # Intersection area\n    # \u8ba1\u7b97\u76f8\u4ea4\u533a\u57df\u7684\u9762\u79ef\n    inter = (torch.min(b1_x2, b2_x2) - torch.max(b1_x1, b2_x1)).clamp(0) * \\\n            (torch.min(b1_y2, b2_y2) - torch.max(b1_y1, b2_y1)).clamp(0)\n\n    # Union Area\n    # \u8ba1\u7b97\u76f8\u5e76\u533a\u57df\u7684\u9762\u79ef\uff0c\u4e24\u4e2a\u8fb9\u754c\u6846\u9762\u79ef\u76f8\u52a0\uff0c\u518d\u51cf\u53bb\u76f8\u4ea4\u7684\u9762\u79ef\uff0c\u7c7b\u4f3c\u5bb9\u65a5\u5b9a\u7406\n    w1, h1 = b1_x2 - b1_x1, b1_y2 - b1_y1\n    w2, h2 = b2_x2 - b2_x1, b2_y2 - b2_y1\n    union = (w1 * h1 + 1e-16) + w2 * h2 - inter\n\n    # \u5f97\u5230iou\u503c\n    iou = inter / union  # iou\n    if GIoU or DIoU or CIoU:\n        # \u8ba1\u7b97\u5927\u8fb9\u754c\u6846\u7684\u5bbd\u9ad8\uff0c\u8fdb\u4e00\u6b65\u8ba1\u7b97\u9762\u79ef\n        cw = torch.max(b1_x2, b2_x2) - torch.min(b1_x1, b2_x1)  # convex (smallest enclosing box) width\n        ch = torch.max(b1_y2, b2_y2) - torch.min(b1_y1, b2_y1)  # convex height\n        if GIoU:  # Generalized IoU https://arxiv.org/pdf/1902.09630.pdf\n            c_area = cw * ch + 1e-16  # convex area\n            # \u8fd4\u56deGIoU\n            return iou - (c_area - union) / c_area  # GIoU\n        if DIoU or CIoU:  # Distance or Complete IoU https://arxiv.org/abs/1911.08287v1\n            # convex diagonal squared \u8ba1\u7b97\u5bf9\u89d2\u7ebf\u7684\u5e73\u65b9\n            c2 = cw ** 2 + ch ** 2 + 1e-16\n            # centerpoint distance squared\n            # \u8ba1\u7b97\u4e24\u4e2a\u77e9\u5f62\u4e2d\u70b9\u7684\u6b27\u5f0f\u8ddd\u79bb\n            rho2 = ((b2_x1 + b2_x2) - (b1_x1 + b1_x2)) ** 2 / 4 + ((b2_y1 + b2_y2) - (b1_y1 + b1_y2)) ** 2 / 4\n            if DIoU:\n                # \u8fd4\u56deDIoU\u503c\n                return iou - rho2 / c2  # DIoU\n            elif CIoU:  # https://github.com/Zzh-tju/DIoU-SSD-pytorch/blob/master/utils/box/box_utils.py#L47\n                # \u989d\u5916\u8ba1\u7b97\u03b1\u548cv\u4e24\u4e2a\u53d8\u91cf\n                v = (4 / math.pi ** 2) * torch.pow(torch.atan(w2 / h2) - torch.atan(w1 / h1), 2)\n                with torch.no_grad():\n                    alpha = v / (1 - iou + v)\n                return iou - (rho2 / c2 + v * alpha)  # CIoU\n\n    return iou\n</code></pre> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u6307\u6b63</p> <p>\u521d\u6b65\u5b8c\u7a3f\u4e8e\uff1a2023\u5e742\u670816\u65e5</p>"},{"location":"detection/program/anchor_gen/","title":"\u951a\u70b9\u751f\u6210\u5668\u2014\u2014AnchorsGenerator","text":"<p>\u53c2\u8003\u94fe\u63a5\uff1a</p> <ul> <li>https://github.com/WZMIAOMIAO/deep-learning-for-image-processing</li> <li>https://github.com/pytorch/vision/tree/master/torchvision/models/detection</li> </ul> <p>\u7c7b\u521d\u59cb\u5316</p> <p>\u9700\u8981\u6307\u660e\u4e24\u7ec4\u53c2\u6570\uff1a</p> <ul> <li> <p><code>sizes</code>\uff1a\u951a\u70b9\u5c3a\u5ea6\uff0c\u5373\u6bcf\u4e2a\u951a\u70b9\u7684\u5927\u5c0f</p> </li> <li> <p><code>aspect_ratios</code>\uff1a\u951a\u70b9\u5bbd\u9ad8\u6bd4\u4f8b</p> </li> </ul> <p>\u6ce8\uff1a</p> <ul> <li> <p><code>sizes</code>\u4e0e<code>aspect_ratios</code>\u5177\u6709\u4e00\u4e00\u5bf9\u5e94\u7684\u5173\u7cfb\uff0c\u6bcf\u4e00\u4e2a\u5c3a\u5ea6\u5bf9\u5e94\u4e00\u4e2a\u6bd4\u4f8b\u3002\u5e76\u4e14\u5747\u4e3a<code>tuple</code>\u7c7b\u578b</p> </li> <li> <p><code>sizes</code>\u4e0e<code>aspect_ratios</code>\u4e00\u822c\u4e3a\u4e8c\u7ef4\u6570\u636e\uff0c\u5373\u6bcf\u4e2a\u5143\u7ec4\u6570\u636e\u4e5f\u540c\u6837\u662f\u5143\u7ec4\u7c7b\u578b\uff0c\u7b2c\u4e00\u5c42\u8868\u793a\u53c2\u4e0e\u9884\u6d4b\u7684\u7279\u5f81\u5c42\uff0c\u7b2c\u4e8c\u5c42\u8868\u793a\u5f53\u524d\u7279\u5f81\u5c42\u7684\u951a\u70b9\u5c3a\u5ea6\u3001\u6bd4\u4f8b\u4fe1\u606f</p> </li> </ul> <p>\u4f8b\u5982\uff1a</p> <pre><code>anchor_sizes = tuple((x, int(x * 2 ** (1.0 / 3)), int(x * 2 ** (2.0 / 3)))\n                     for x in [32, 64, 128, 256, 512])\naspect_ratios = ((0.5, 1.0, 2.0),) * len(anchor_sizes)\nanchor_generator = AnchorsGenerator(anchor_sizes, aspect_ratios)\n</code></pre> <p>\u8f93\u5165\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u4e0a\u56fe\u4e2d\u4e00\u5171\u75285\u5c42\u9884\u6d4b\u7279\u5f81\uff0c\u6bcf\u5c42\u7279\u5f81\u5c42\u4e0a\u7684\u951a\u70b9\u67093\u4e2a\u6bd4\u4f8b\u30013\u4e2a\u5c3a\u5ea6\uff08RetinaNet\u7f51\u7edc\u8bbe\u7f6e\uff09\u3002</p> <p>\u524d\u5411\u4f20\u64ad</p> <p>\u8f93\u5165\uff1a</p> <ul> <li> <p><code>image_list</code>\uff1a\u7528\u4e8e\u5f97\u5230\u56fe\u50cf\u5bbd\u9ad8\u5c3a\u5bf8\uff1b</p> </li> <li> <p><code>feature_maps</code>\uff1a<code>list</code>\u683c\u5f0f\uff0c\u7528\u4e8e\u5f97\u5230\u6bcf\u5c42\u9884\u6d4b\u7279\u5f81\u56fe\u7684\u5bbd\u9ad8\u5c3a\u5bf8\u3002</p> </li> </ul> <p>\u4f8b\u5982\uff1a</p> <pre><code>anchors = self.anchor_generator(images, features)\n</code></pre> <p>\u8f93\u51fa\uff1a</p> <ul> <li><code>anchors</code>\uff1a\u6240\u6709\u7684\u951a\u70b9\u5750\u6807\uff0c\u5c3a\u5bf8\u4e3a[N,4]\uff0c\u5176\u4e2dN\u8868\u793a\u951a\u70b9\u6570\u91cf</li> </ul>"},{"location":"detection/program/anchor_gen/#_1","title":"\u4ee3\u7801\u5b9e\u73b0","text":"<pre><code>from typing import List, Optional, Dict\n\nimport torch\nfrom torch import nn, Tensor\n\nfrom .image_list import ImageList\n\n\nclass AnchorsGenerator(nn.Module):\n    __annotations__ = {\n        \"cell_anchors\": Optional[List[torch.Tensor]],\n        \"_cache\": Dict[str, List[torch.Tensor]]\n    }\n    # sizes\u8868\u793aanchor\u7684\u5c3a\u5ea6\uff0c\u4ee3\u8868\u4e0d\u540c\u7684\u9884\u6d4b\u7279\u5f81\u5c42\uff0clen(sizes)==\u7279\u5f81\u5c42\u6570\n    def __init__(self, sizes=(128, 256, 512), aspect_ratios=(0.5, 1.0, 2.0)):\n        super(AnchorsGenerator, self).__init__()\n        # \u5224\u65ad\u662f\u4e0d\u662f\u6b63\u786e\u7684\u7c7b\u578b\n        if not isinstance(sizes[0], (list, tuple)):\n            # TODO change this\n            sizes = tuple((s,) for s in sizes)\n        if not isinstance(aspect_ratios[0], (list, tuple)):\n            aspect_ratios = (aspect_ratios,) * len(sizes)\n        # len(sizes)\u9700\u4e0e\u4e0elen(aspect_ratios)\u76f8\u7b49\uff0c\u5bf9\u5e94\u7279\u5f81\u5c42\u6570\u91cf\n        assert len(sizes) == len(aspect_ratios)\n        # \u5c3a\u5ea6\u4fe1\u606f\n        self.sizes = sizes\n        # \u6b64\u65f6aspect_ratios\u4e3a\u5217\u8868\u7c7b\u578b\uff0c\u91cc\u9762\u662flen(sizes)\u4e2a\u5143\u7ec4\uff0c\u5373\u6bcf\u4e2a\u7279\u5f81\u5c42\u5c3a\u5ea6\u5bf9\u5e94\u4e00\u4e2aratios\n        self.aspect_ratios = aspect_ratios\n        # \u951a\u70b9\u6a21\u677f\n        self.cell_anchors = None\n        # \u951a\u70b9\u56fe\u7f13\u5b58\n        self._cache = {}\n\n    # \u4f20\u5165scale\u5c3a\u5ea6\uff0c\u548c\u5bf9\u5e94\u7684aspect_ratios\n    def generate_anchors(self, scales, aspect_ratios, dtype=torch.float32, device=torch.device(\"cpu\")):\n        # type: (List[int], List[float], torch.dtype, torch.device) -&gt; Tensor\n        \"\"\"\n        compute anchor sizes\n        Arguments:\n            scales: sqrt(anchor_area)\n            aspect_ratios: h/w ratios\n            dtype: float32\n            device: cpu/gpu\n        \"\"\"\n        # \u5148\u8f6c\u5316\u6570\u636e,scales\u4e3a\u4e00\u4e2a\u6574\u6570\uff0c\u598232\uff0caspect_ratios\u4e3a\u6240\u6709\u7684\u5c3a\u5ea6(0.5,1,2)\n        scales = torch.as_tensor(scales, dtype=dtype, device=device)\n        aspect_ratios = torch.as_tensor(aspect_ratios, dtype=dtype, device=device)\n        # \u4fdd\u6301\u9762\u79ef\u4e0d\u53d8\u7684\u60c5\u51b5\u4e0b\uff0c\u8c03\u6574\u9ad8\u5bbd\u4e3a\u6307\u5b9a\u7684\u6bd4\u4f8b\n        # \u9700\u8981\u5148\u5f00\u6839\uff0c\u6b64\u65f6\u76f4\u63a5\u5f97\u5230\u9ad8\u6bd4\u4f8b\n        h_ratios = torch.sqrt(aspect_ratios)\n        # h_ratios\u53d6\u5230\u6570\u5f97\u5230\u5bbd\u6bd4\u4f8b\n        w_ratios = 1.0 / h_ratios\n\n        # [r1, r2, r3]' * [s1, s2, s3]\n        # number of elements is len(ratios)*len(scales)\n        # \u5f97\u5230\u951a\u70b9\u9ad8\u5bbd\u4fe1\u606f\uff0c\u9762\u79ef\u4e3ascale^2\u5927\u5c0f\uff0c\u4e0d\u53d8\uff0c\u5373\u7279\u5f81\u56fe\u4e0a\u4e00\u4e2a\u50cf\u7d20\u70b9\u5bf9\u5e94\u539f\u56fe\u7684\u9762\u79ef\u4e0d\u53d8\uff0c\n        # \u53ea\u662f\u539f\u6765\u6bcf\u4e2a\u50cf\u7d20\u70b9\u53ea\u80fd\u4ee3\u8868\u6b63\u65b9\u5f62\uff0c\u751f\u6210\u4e86\u951a\u70b9\u56fe\u4e4b\u540e\uff0c\u6bcf\u4e2a\u50cf\u7d20\u70b9\u5c31\u53ef\u4ee5\u4ee3\u8868\u77e9\u5f62\u4e86\uff0c\u77e9\u5f62\u9ad8\u5bbd\u6bd4\u4f8b\u7531aspect_ratios\u51b3\u5b9a\n        # \u6bcf\u4e2a\u7279\u5f81\u5c42\u4e00\u4e2a\u5c3a\u5ea6\uff0c\u4e09\u4e2a\u9ad8\u5bbd\u6bd4\u4f8b-&gt;\u4e00\u51713\u4e2a\u951a\u70b9\uff0c\u8fd9\u91ccws\u8868\u793a3\u4e2a\u951a\u70b9\u7684\u5bbd\uff0chs\u8868\u793a3\u4e2a\u951a\u70b9\u7684\u9ad8\n        ws = (w_ratios[:, None] * scales[None, :]).view(-1)\n        hs = (h_ratios[:, None] * scales[None, :]).view(-1)\n\n        # left-top, right-bottom coordinate relative to anchor center(0, 0)\n        # \u751f\u6210\u7684anchors\u6a21\u677f\u90fd\u662f\u4ee5\uff080, 0\uff09\u4e3a\u4e2d\u5fc3\u7684, shape [len(ratios)*len(scales), 4]\uff0c[\u951a\u70b9\u6570\u91cf\uff0c4]\n        # \u50cf\u7d20\u70b9\u653e\u4e8e\u4e2d\u95f4\uff0c\u53730,0\u8868\u793a\u4e2d\u5fc3\u50cf\u7d20\u70b9\uff0c\u800c\u5b9a\u4f4d\u951a\u70b9\u68c0\u6d4b\u6846\u7684\u5750\u6807\u4f4d\u4e8e0,0\u4e24\u4fa7\n        # \u56e0\u6b64\u8fd9\u91cc\u7684\u5750\u6807\u4e3a\u4e24\u8d1f\u4e24\u6b63\uff0c\u6700\u540e\u518d\u9664\u4ee52\n        base_anchors = torch.stack([-ws, -hs, ws, hs], dim=1) / 2\n        # round \u56db\u820d\u4e94\u5165\uff0c\u8fd4\u56de\u951a\u70b9\u6a21\u677f\n        return base_anchors.round()\n\n    # \u751f\u6210\u951a\u70b9\u6a21\u677f\uff0c\u5c3a\u5bf8\u4e3a(len(scales)*len(aspect_ratios),4)\uff0c\u4e00\u7ec4\u7279\u5f81\u56fe\u5bf9\u5e94\u4e00\u4e2ascales\uff0c\u800c\u4e00\u4e2ascale\u5bf9\u5e943\u4e2aratios\uff0c\u5373\u4e00\u822c\u4e3a(3,4)\n    def set_cell_anchors(self, dtype, device):\n        # type: (torch.dtype, torch.device) -&gt; None\n        # \u7b2c\u4e00\u6b21\u8c03\u7528set_cell_anchors\u65f6\uff0c\u6a21\u677f\u4e3a\u7a7a\uff0c\u9700\u8981\u7ee7\u7eed\u5f80\u4e0b\u8d70\uff0c\u521b\u5efa\u6a21\u677f\n        if self.cell_anchors is not None:\n            # \u5982\u679c\u4e0d\u662f\u7b2c\u4e00\u6b21\u8c03\u7528\uff0c\u5219\u5b58\u5728\u951a\u70b9\u6a21\u677f\uff0c\u76f4\u63a5\u8fd4\u56de\u5373\u53ef\n            cell_anchors = self.cell_anchors\n            assert cell_anchors is not None\n            # suppose that all anchors have the same device\n            # which is a valid assumption in the current state of the codebase\n            if cell_anchors[0].device == device:\n                return\n\n        # \u6839\u636e\u63d0\u4f9b\u7684sizes\u548caspect_ratios\u751f\u6210anchors\u6a21\u677f\n        # anchors\u6a21\u677f\u90fd\u662f\u4ee5(0, 0)\u4e3a\u4e2d\u5fc3\u7684anchor\u3002\u6a21\u677f\u4e3a\u5217\u8868\u7c7b\u578b\uff0c\u5217\u8868\u957f\u5ea6\u4e0e\u7279\u5f81\u5c42\u6570\u5339\u914d\u3002resnet50_fpn\u751f\u6210\u4e865\u4e2a\u5217\u8868\uff0c\u5747\u4e3a3*4\u7684\u6a21\u677f(\u4e09\u4e2a\u68c0\u6d4b\u6846\uff0c\u6bcf\u4e2a\u68c0\u6d4b\u6846\u56db\u4e2a\u5750\u6807)\n        cell_anchors = [\n            # \u5229\u7528generate_anchors\u51fd\u6570\u751f\u6210\n            self.generate_anchors(sizes, aspect_ratios, dtype, device)\n            # \u904d\u5386\u6240\u6709\u7684\u7279\u5f81\u5c42\uff0cresnet50_fpn\u4e2d\u5171\u67095\u4e2a\u7279\u5f81\u5c42\u53c2\u4e0e\u68c0\u6d4b\n            # \u5f97\u5230\u5bf9\u5e94\u7684size(\u5c3a\u5ea6\uff0c\u6b65\u957f)\u4e0easpect_ratios(\u5bf9\u5e94\u7684\u68c0\u6d4b\u6846\u9ad8\u5bbd\u6bd4\u4f8b)\n            # \u6bcf\u4e2a\u7279\u5f81\u56fe\u4e0a\u951a\u70b9\u56fe\u7684\u5c3a\u5bf8\u5747\u4e3a(\u951a\u70b9\u6570,4)\n            # \u6700\u7ec8\u5f97\u5230\u4e00\u4e2a\u5217\u8868\uff0c\u5217\u8868\u957f\u5ea6\u4ee3\u8868\u53c2\u4e0e\u68c0\u6d4b\u7684\u7279\u5f81\u5c42\u6570\u91cf\uff0c\u5217\u8868\u4e0a\u7684\u6570\u503c\u4e3a\u951a\u70b9\u6a21\u677f\u5750\u6807(\u4ee5\u951a\u70b9\u4e2d\u5fc3\u4e3a\u539f\u70b9\u7684\u5750\u6807)\n            for sizes, aspect_ratios in zip(self.sizes, self.aspect_ratios)\n        ]\n        # \u8d4b\u503c\u951a\u70b9\u6a21\u677f\uff0c\u8fd9\u91cc\u6a21\u677f\u7684\u9ad8\u5bbd\u5bf9\u5e94\u539f\u56fe\u5c3a\u5ea6\n        self.cell_anchors = cell_anchors\n\n    def num_anchors_per_location(self):\n        # \u8ba1\u7b97\u6bcf\u4e2a\u9884\u6d4b\u7279\u5f81\u5c42\u4e0a\u6bcf\u4e2a\u6ed1\u52a8\u7a97\u53e3\u7684\u9884\u6d4b\u76ee\u6807\u6570\n        return [len(s) * len(a) for s, a in zip(self.sizes, self.aspect_ratios)]\n\n    # For every combination of (a, (g, s), i) in (self.cell_anchors, zip(grid_sizes, strides), 0:2),\n    # output g[i] anchors that are s[i] distance apart in direction i, with the same dimensions as a.\n    def grid_anchors(self, grid_sizes, strides):\n        # type: (List[List[int]], List[List[Tensor]]) -&gt; List[Tensor]\n        \"\"\"\n        anchors position in grid coordinate axis map into origin image\n        \u8ba1\u7b97\u9884\u6d4b\u7279\u5f81\u56fe\u5bf9\u5e94\u539f\u59cb\u56fe\u50cf\u4e0a\u7684\u6240\u6709anchors\u7684\u5750\u6807\uff0c\u5373\u751f\u6210\u4e00\u5f20\u951a\u70b9\u56fe\n        Args:\n            grid_sizes: \u9884\u6d4b\u7279\u5f81\u77e9\u9635\u7684height\u548cwidth\n            strides: \u9884\u6d4b\u7279\u5f81\u77e9\u9635\u4e0a\u4e00\u6b65\u5bf9\u5e94\u539f\u59cb\u56fe\u50cf\u4e0a\u7684\u6b65\u8ddd\n        \"\"\"\n        # \u521d\u59cb\u5316\u951a\u70b9\u56fe\n        anchors = []\n        # \u951a\u70b9\u6a21\u677f\n        cell_anchors = self.cell_anchors\n        assert cell_anchors is not None\n\n        # \u904d\u5386\u6bcf\u4e2a\u9884\u6d4b\u7279\u5f81\u5c42\u7684grid_size\uff0cstrides\u548ccell_anchors\u3002\u7279\u5f81\u5c42\u4e0escale\u5339\u914d\uff0c\u800cscale\u4e0e\u951a\u70b9\u6a21\u677fcell_anchors\u4e00\u4e00\u5bf9\u5e94\n        for size, stride, base_anchors in zip(grid_sizes, strides, cell_anchors):\n            grid_height, grid_width = size  # \u8be5\u7279\u5f81\u5c42\u4ea7\u751f\u7684\u7279\u5f81\u56fe\u9ad8\u3001\u5bbd\n            stride_height, stride_width = stride  # \u5c3a\u5ea6\u4fe1\u606f\uff0c\u5373\u7279\u5f81\u56fe\u4e0a\u4e00\u4e2a\u50cf\u7d20\u70b9\u4ee3\u8868\u539f\u56fe\u591a\u5c11\u4e2a\u50cf\u7d20\u70b9(\u611f\u53d7\u91ce)\n            device = base_anchors.device\n\n            # For output anchor, compute [x_center, y_center, x_center, y_center]\n            # shape: [grid_width] \u5bf9\u5e94\u539f\u56fe\u4e0a\u7684x\u5750\u6807(\u5217)\uff0c\u6bcf\u9694stride_width\u4ea7\u751f\u4e00\u4e2a\u503c\n            shifts_x = torch.arange(0, grid_width, dtype=torch.float32, device=device) * stride_width\n            # shape: [grid_height] \u5bf9\u5e94\u539f\u56fe\u4e0a\u7684y\u5750\u6807(\u884c)\uff0c\u6bcf\u9694stride_height\u4ea7\u751f\u4e00\u4e2a\u503c\uff0c\u4e0b\u4e00\u884c\u7684y\u503c\u662f\u57fa\u4e8e\u4e0a\u4e00\u884c\u7684\n            shifts_y = torch.arange(0, grid_height, dtype=torch.float32, device=device) * stride_height\n\n            # \u8ba1\u7b97\u9884\u6d4b\u7279\u5f81\u77e9\u9635\u4e0a\u6bcf\u4e2a\u70b9\u5bf9\u5e94\u539f\u56fe\u4e0a\u7684\u5750\u6807(anchors\u6a21\u677f\u7684\u5750\u6807\u504f\u79fb\u91cf)\n            # torch.meshgrid\u51fd\u6570\u5206\u522b\u4f20\u5165\u884c\u5750\u6807\u548c\u5217\u5750\u6807\uff0c\u751f\u6210\u7f51\u683c\u884c\u5750\u6807\u77e9\u9635\u548c\u7f51\u683c\u5217\u5750\u6807\u77e9\u9635\n            # shape: [grid_height, grid_width]\n            shift_y, shift_x = torch.meshgrid(shifts_y, shifts_x)  # \u884c\u5217\u91cd\u590d\n            shift_x = shift_x.reshape(-1)  # \u62c9\u76f4\uff0c\u518d\u62fc\u63a5\uff0c\u4ece\u800c\u8868\u793a\u4e00\u5f20\u56fe\u4e2d\u6240\u6709\u7684\u70b9\n            shift_y = shift_y.reshape(-1)\n\n            # \u4e0b\u9762\u8ba1\u7b97anchors\u5750\u6807(xmin, ymin, xmax, ymax)\u5728\u539f\u56fe\u4e0a\u7684\u5750\u6807\u504f\u79fb\u91cf\n            # shape: [grid_width*grid_height, 4]\n            # \u8fd9\u91cc\u5f97\u5230\u6240\u6709\u70b9\u7684\u5750\u6807(\u7279\u5f81\u56fe\u4e0a\u7684\u70b9\u6620\u5c04\u5230\u539f\u56fe\u4e0a)\uff0c\u603b\u6570\u4e3a\u7279\u5f81\u56fe\u957f\u5bbd\u4e4b\u79ef\uff0c\u518d\u4e58\u4ee5len(scale)\uff0c\u4e00\u822c\u4e3a1\uff0c\u5373\u6bcf\u4e2a\u7279\u5f81\u5c42\u5bf9\u5e94\u4e00\u4e2ascale\n            # \u8fd9\u91cc\u76f8\u5f53\u4e8e\u5c06\u7279\u5f81\u56fe\u4e0a\u7684\u6240\u6709\u50cf\u7d20\u70b9\u6309\u7279\u5b9a\u7684\u95f4\u8ddd\u6620\u5c04\u5230\u539f\u56fe\u4e0a\uff0c\u5373\u5f97\u5230\u6bcf\u4e2a\u951a\u70b9\u68c0\u6d4b\u6846\u7684\u4e2d\u5fc3\u4f4d\u7f6e\n            shifts = torch.stack([shift_x, shift_y, shift_x, shift_y], dim=1)\n\n            # For every (base anchor, output anchor) pair,\n            # offset each zero-centered base anchor by the center of the output anchor.\n            # \u5c06anchors\u6a21\u677f\u4e0e\u539f\u56fe\u4e0a\u7684\u5750\u6807\u504f\u79fb\u91cf\u76f8\u52a0\u5f97\u5230\u539f\u56fe\u4e0a\u6240\u6709anchors\u7684\u5750\u6807\u4fe1\u606f(shape\u4e0d\u540c\u65f6\u4f1a\u4f7f\u7528\u5e7f\u64ad\u673a\u5236)\n            # \u4e0a\u9762\u5f97\u5230\u4e86\u6240\u6709\u951a\u70b9\u4e2d\u5fc3\u7684\u5750\u6807\uff0c\u800c\u951a\u70b9\u6a21\u677f\u6b63\u662f\u4ee50,0\u4e3a\u4e2d\u5fc3\uff0c\u4e24\u4e2a\u53d8\u91cf\u76f8\u52a0\uff0c\u6b63\u597d\u5f97\u5230\u4e86\u4ee5\u7279\u5f81\u56fe\u6bcf\u4e2a\u50cf\u7d20\u70b9\u4e3a\u4e2d\u5fc3\uff0c\u6620\u5c04\u5230\u539f\u56fe\u7684\u951a\u70b9\u68c0\u6d4b\u6846\u5750\u6807\n            # \u8fd9\u91cc\u5e94\u7528\u4e86\u5e7f\u64ad\u673a\u5236\uff0c\u951a\u70b9\u4e2d\u5fc3\u590d\u5236\u4e86w*h\u500d\uff0c\u951a\u70b9\u6a21\u677f\u590d\u5236\u4e863\u500d(\u4e09\u4e2a\u6a21\u677f\u5bf9\u5e94\u4e8e\u4e09\u79cd\u6bd4\u4f8b)\n            shifts_anchor = shifts.view(-1, 1, 4) + base_anchors.view(1, -1, 4)\n            # \u6700\u540e\u8f6c\u6362\u5f62\u72b6\uff0c\u5f97\u5230\u8be5\u7279\u5f81\u5c42\u4e2d\u6240\u6709\u7684\u951a\u70b9\u56fe\uff0c\u5373\u8be5\u7279\u5f81\u5c42\u4e0a\u5171\u6709w*h\u4e2a\u50cf\u7d20\u70b9\uff0c\u6bcf\u4e2a\u50cf\u7d20\u70b9\u5bf9\u5e943\u4e2a\u951a\u70b9\u68c0\u6d4b\u6846(\u6bd4\u4f8bratios\u6570\u91cf)\n            anchors.append(shifts_anchor.reshape(-1, 4))\n        # \u6700\u540e\u8fd4\u56de\u6240\u6709\u7684\u951a\u70b9\u56fe\n        return anchors  # List[Tensor(all_num_anchors, 4)]\n\n    def cached_grid_anchors(self, grid_sizes, strides):\n        # type: (List[List[int]], List[List[Tensor]]) -&gt; List[Tensor]\n        \"\"\"\u5c06\u8ba1\u7b97\u5f97\u5230\u7684\u6240\u6709anchors\u4fe1\u606f\u8fdb\u884c\u7f13\u5b58\"\"\"\n        key = str(grid_sizes) + str(strides)\n        # self._cache\u662f\u5b57\u5178\u7c7b\u578b\uff0c\u521d\u59cb\u5316\u4e3a\u7a7a\u5b57\u5178\n        if key in self._cache:\n            # \u5982\u679c\u4e4b\u524d\u8ba1\u7b97\u8fc7(\u7f13\u5b58\u91cc\u6709)\uff0c\u5219\u76f4\u63a5\u8fd4\u56de\u8ba1\u7b97\u597d\u7684\u5c31\u53ef\u4ee5\n            return self._cache[key]\n        # \u5982\u679c\u6ca1\u6709\uff0c\u5219\u8ba1\u7b97\u4e00\u4e2a\n        anchors = self.grid_anchors(grid_sizes, strides)\n        self._cache[key] = anchors\n        return anchors\n\n    def forward(self, image_list, feature_maps):\n        # type: (ImageList, List[Tensor]) -&gt; List[Tensor]\n        # feature_maps\u8868\u793a\u9884\u6d4b\u7279\u5f81\u5c42\uff0cimage_list\u8868\u793a\u56fe\u7247\n        # \u83b7\u53d6\u6bcf\u4e2a\u9884\u6d4b\u7279\u5f81\u5c42\u7684\u5c3a\u5bf8(height, width)\n        grid_sizes = list([feature_map.shape[-2:] for feature_map in feature_maps])\n\n        # \u83b7\u53d6\u8f93\u5165\u56fe\u50cf\u7684height\u548cwidth\n        image_size = image_list.tensors.shape[-2:]\n\n        # \u83b7\u53d6\u53d8\u91cf\u6570\u636e\u7c7b\u578b\u548c\u8bbe\u5907\u7c7b\u578b\n        dtype, device = feature_maps[0].dtype, feature_maps[0].device\n\n        # one step in feature map equate n pixel stride in origin image\n        # \u8ba1\u7b97\u7279\u5f81\u5c42\u4e0a\u7684\u4e00\u6b65\u7b49\u4e8e\u539f\u59cb\u56fe\u50cf\u4e0a\u7684\u6b65\u957f\uff0c\u5373\u611f\u53d7\u91ce\uff0c\u4e5f\u53eb\u5c3a\u5ea6\n        # \u56fe\u50cf\u5927\u5c0f\u9664\u4ee5\u7279\u5f81\u56fe\u5927\u5c0f\uff0c\u5f97\u5230\u5c3a\u5ea6(\u6574\u6570)\n        strides = [[torch.tensor(image_size[0] // g[0], dtype=torch.int64, device=device),\n                    torch.tensor(image_size[1] // g[1], dtype=torch.int64, device=device)] for g in grid_sizes]\n\n        # \u6839\u636e\u63d0\u4f9b\u7684sizes\u548caspect_ratios\u751f\u6210anchors\u6a21\u677f(\u4ee5\u50cf\u7d20\u70b9\u4e3a\u4e2d\u5fc3)\n        self.set_cell_anchors(dtype, device)\n\n        # \u8ba1\u7b97/\u8bfb\u53d6\u6240\u6709anchors\u7684\u5750\u6807\u4fe1\u606f\uff08\u8fd9\u91cc\u7684anchors\u4fe1\u606f\u662f\u6620\u5c04\u5230\u539f\u56fe\u4e0a\u7684\u6240\u6709anchors\u4fe1\u606f\uff0c\u4e0d\u662fanchors\u6a21\u677f\uff09\n        # \u5f97\u5230\u7684\u662f\u4e00\u4e2alist\u5217\u8868\uff0c\u5bf9\u5e94\u6bcf\u5f20\u9884\u6d4b\u7279\u5f81\u56fe\u6620\u5c04\u56de\u539f\u56fe\u7684anchors\u5750\u6807\u4fe1\u606f\n        # \u4f20\u5165\u7279\u5f81\u56fe\u5c3a\u5bf8\u548c\u5bf9\u5e94\u7684strides(\u7279\u5f81\u56fe\u4e0e\u539f\u56fe\u6bd4\u4f8b)\uff0c\u4f20\u56de\u951a\u70b9\u56fe(\u4e00\u4e2a\u5217\u8868\uff0c\u5bf9\u5e94\u4e8e\u4e0d\u540c\u7684\u7279\u5f81\u5c42)\n        anchors_over_all_feature_maps = self.cached_grid_anchors(grid_sizes, strides)\n\n        anchors = torch.jit.annotate(List[List[torch.Tensor]], [])\n        # \u8fd9\u91cc\u76f8\u5f53\u4e8e\u505a\u4e00\u4e2a\u91cd\u590d\uff0c\u5c06\u5f97\u5230\u7684\u951a\u70b9\u56fe\u91cd\u590dbatch\u6b21\n        for i, (image_height, image_width) in enumerate(image_list.image_sizes):\n            anchors_in_image = []\n            # \u8fd9\u91cc\u5176\u5b9e\u53ef\u4ee5\u76f4\u63a5append\u6dfb\u52a0\uff0c\u4e0d\u7528for\u5faa\u73af\u904d\u5386\n            for anchors_per_feature_map in anchors_over_all_feature_maps:\n                anchors_in_image.append(anchors_per_feature_map)\n            anchors.append(anchors_in_image)\n        # \u5c06\u6bcf\u4e00\u5f20\u56fe\u50cf\u7684\u6240\u6709\u9884\u6d4b\u7279\u5f81\u5c42\u7684anchors\u5750\u6807\u4fe1\u606f\u62fc\u63a5\u5728\u4e00\u8d77\n        # anchors\u662f\u4e2alist\uff0c\u6bcf\u4e2a\u5143\u7d20\u4e3a\u4e00\u5f20\u56fe\u50cf\u7684\u6240\u6709anchors\u4fe1\u606f\n        # \u5c06\u6bcf\u5f20\u56fe\u7247\u91cc\u7684\u951a\u70b9\u5750\u6807\u56fe\u5408\u5e76\u8d77\u6765\uff0c\u5f97\u5230\u7684\u5217\u8868\u957f\u5ea6\u4e0ebatch\u6570\u503c\u4e00\u81f4\uff0c\u76f8\u5f53\u4e8e\u5c06\u4e00\u5f20\u56fe\u4e2d\u6240\u6709\u7279\u5f81\u5c42\u7684\u951a\u70b9\u5750\u6807\u5408\u5e76\u8d77\u6765\u4e86\n        anchors = [torch.cat(anchors_per_image) for anchors_per_image in anchors]\n        # Clear the cache in case that memory leaks.\n        self._cache.clear()\n        # \u8fd4\u56de\u751f\u6210\u7684\u951a\u70b9\n        return anchors\n</code></pre> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u6307\u6b63</p> <p>\u521d\u6b65\u5b8c\u7a3f\u4e8e2023\u5e741\u670817\u65e5</p>"},{"location":"detection/program/anchor_match/","title":"\u951a\u70b9\u5339\u914d\u2014\u2014\u6e90\u7801\u7b14\u8bb0","text":""},{"location":"detection/program/anchor_match/#faster_r-cnn","title":"Faster R-CNN\u673a\u5236","text":"<p>\u53c2\u8003\u94fe\u63a5\uff1a</p> <ul> <li>https://github.com/WZMIAOMIAO/deep-learning-for-image-processing</li> <li>https://github.com/pytorch/vision/tree/master/torchvision/models/detection</li> </ul>"},{"location":"detection/program/anchor_match/#iou","title":"\u8ba1\u7b97\u951a\u70b9\u4e0e\u8fb9\u754c\u6846\u7684IoU\u503c","text":"<p>\u5177\u4f53\u6548\u679c\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>boxes1</code>\u3001<code>boxes2</code>\uff1a\u771f\u5b9e\u7269\u4f53\u8fb9\u754c\u6846\u4e0e\u951a\u70b9\u6846\uff0c\u5c3a\u5bf8\u5206\u522b\u4e3a[M, 4]\u548c[N, 4]\uff0c\u5176\u4e2dM\u8868\u793a\u5f53\u524d\u56fe\u7247\u7684\u524d\u666f\u6570\u91cf\uff0cN\u8868\u793a\u951a\u70b9\u6570\u91cf</li> </ul> <p>\u8f93\u51fa\uff1a</p> <ul> <li><code>iou</code>\uff1a\u6bcf\u4e2a\u951a\u70b9\u4e0e\u6bcf\u4e2a\u524d\u666f\u7684iou\u503c\uff0c\u5c3a\u5bf8\u4e3a[M,N]</li> </ul> <pre><code>def box_iou(boxes1, boxes2):\n    \"\"\"\n    Return intersection-over-union (Jaccard index) of boxes.\n    Both sets of boxes are expected to be in (x1, y1, x2, y2) format.\n    Arguments:\n        boxes1 (Tensor[N, 4])\n        boxes2 (Tensor[M, 4])\n    Returns:\n        iou (Tensor[N, M]): the NxM matrix containing the pairwise\n            IoU values for every element in boxes1 and boxes2\n    \"\"\"\n    # \u8ba1\u7b97\u6807\u7b7e\u8fb9\u754c\u6846\u533a\u57df\u9762\u79ef  # \u8ba1\u7b97\u951a\u70b9\u533a\u57df\u9762\u79ef\n    area1 = box_area(boxes1)\n    area2 = box_area(boxes2)\n\n    # \u4f9d\u6b21\u8ba1\u7b97\u5f97\u5230\u5de6\u4e0a\u89d2\u7684\u70b9\u5750\u6807\u548c\u53f3\u4e0b\u89d2\u7684\u70b9\u5750\u6807\n    # \u6ce8\u610f\u8fd9\u91cc\u4f1a\u5229\u7528\u5e7f\u64ad\u673a\u5236\u5bf9\u539f\u6570\u636e\u505a\u6269\u5145\uff0c\u5047\u8bbe\u6807\u7b7e\u8fb9\u754c\u6846\u4e3aN\uff0c\u951a\u70b9\u6570\u91cf\u4e3aM\uff0c\u4e0b\u9762\u4e24\u4e2a\u6570\u636e\u5c3a\u5bf8\u5747\u4e3a[N,M,2]\n    # \u76f8\u5f53\u4e8e\u5bf9\u4e0e\u6bcf\u4e2a\u6807\u7b7e\u8fb9\u754c\u6846\uff0c\u90fd\u4f1a\u4e00\u4e00\u5730\u548c\u6bcf\u4e2a\u951a\u70b9\u76f8\u5339\u914d\n    lt = torch.max(boxes1[:, None, :2], boxes2[:, :2])  # left-top [N,M,2]\n    rb = torch.min(boxes1[:, None, 2:], boxes2[:, 2:])  # right-bottom [N,M,2]\n    # \u5f97\u5230\u76f8\u4ea4\u9762\u79ef\u7684\u5bbd\u4e0e\u9ad8\uff0c\u6ce8\u610f\uff0c\u8fd9\u91cc\u6570\u636e\u5c3a\u5bf8\u4f9d\u65e7\u662f[N,M,2]\n    wh = (rb - lt).clamp(min=0)  # [N,M,2]\n    # \u9ad8\u5bbd\u505a\u4e58\u6cd5\uff0c\u5f97\u5230\u76f8\u4ea4\u533a\u57df\u7684\u9762\u79ef\n    inter = wh[:, :, 0] * wh[:, :, 1]  # [N,M]\n    # \u8ba1\u7b97IOU\u503c\uff0c\u4e24\u4e2a\u533a\u57df\u7684\u9762\u79ef\u76f8\u52a0\uff0c\u51cf\u53bb\u76f8\u4ea4\u7684\u9762\u79ef\u5f53\u505a\u5206\u6bcd\uff0c\u76f8\u4ea4\u7684\u9762\u79ef\u5f53\u505a\u5206\u5b50\n    iou = inter / (area1[:, None] + area2 - inter)\n    return iou\n</code></pre>"},{"location":"detection/program/anchor_match/#matcher","title":"\u751f\u6210\u5339\u914d\u7f16\u53f7\u2014\u2014Matcher","text":"<p>\u7c7b\u521d\u59cb\u5316</p> <p>\u9700\u6307\u660e\u4e09\u4e2a\u53c2\u6570\uff1a</p> <ul> <li><code>high_threshold</code>\uff1a\u524d\u666f\u9608\u503c\uff0c\u5927\u4e8e\u6b64\u503c\u89c6\u4e3a\u524d\u666f</li> <li><code>low_threshold</code>\uff1a\u80cc\u666f\u9608\u503c\uff0c\u5c0f\u4e8e\u6b64\u503c\u89c6\u4e3a\u80cc\u666f\uff0c\u5904\u4e8e\u4e2d\u95f4\u951a\u70b9\u4e0d\u53c2\u4e0e\u635f\u5931\u8ba1\u7b97</li> <li><code>allow_low_quality_matches</code>\uff1a\u662f\u5426\u542f\u7528\u7b2c\u4e8c\u5957\u5339\u914d\u65b9\u6848\uff0c\u9632\u6b62\u6709\u7684\u8fc7\u5c0f\u76ee\u6807\u6ca1\u6709\u951a\u70b9\u6765\u5339\u914d</li> </ul> <p>\u6ce8\uff1a</p> <ul> <li>\u76ee\u6807\u8fc7\u5c0f\u7684\u8bdd\uff0ciou\u53ef\u80fd\u5f88\u5c0f\uff0c\u5982\u679c\u6b64\u65f6\u5f53\u524d\u76ee\u6807\u6700\u5927\u7684iou\u503c\u4e5f\u5c0f\u4e8ehigh_threshold\uff0c\u5219\u9700\u8be5\u76ee\u6807\u4e0d\u4f1a\u6709\u5339\u914d\u7684\u951a\u70b9\uff0c\u8bad\u7ec3\u65f6\u5c31\u4f1a\u5ffd\u7565\u8be5\u76ee\u6807\uff1b</li> <li>\u7b2c\u4e8c\u5957\u5339\u914d\u65b9\u6848\uff1a\u4ece\u524d\u666f\u76ee\u6807\u51fa\u53d1\uff0c\u6cbf\u951a\u70b9\u65b9\u5411\u627e\u51fa\u6bcf\u4e2a\u524d\u666f\u76ee\u6807\u6700\u5927\u7684iou\u503c\u4ee5\u53ca\u5bf9\u5e94\u7684\u951a\u70b9\uff0c\u5c06\u5bf9\u5e94\u7684\u951a\u70b9\u5339\u914d\u7f16\u53f7\u8bbe\u7f6e\u4e3a\u8be5\u524d\u666f\u76ee\u6807\u7f16\u53f7\u3002</li> </ul> <pre><code>class Matcher(object):\n    BELOW_LOW_THRESHOLD = -1\n    BETWEEN_THRESHOLDS = -2\n\n    __annotations__ = {\n        'BELOW_LOW_THRESHOLD': int,\n        'BETWEEN_THRESHOLDS': int,\n    }\n\n    def __init__(self, high_threshold, low_threshold, allow_low_quality_matches=False):\n        # type: (float, float, bool) -&gt; None\n        \"\"\"\n        Args:\n            high_threshold (float): \u5927\u4e8e\u6b64\u503c\u89c6\u4e3a\u524d\u666f\n            low_threshold (float): \u5c0f\u4e8e\u6b64\u503c\u89c6\u4e3a\u80cc\u666f\uff0c\u5904\u4e8e\u4e2d\u95f4\u951a\u70b9\u4e0d\u53c2\u4e0e\u635f\u5931\u8ba1\u7b97\n            allow_low_quality_matches (bool): if True, produce additional matches\n                for predictions that have only low-quality match candidates. See\n                set_low_quality_matches_ for more details.\n        \"\"\"\n        # \u89c6\u4e3a\u80cc\u666f\u951a\u70b9\n        self.BELOW_LOW_THRESHOLD = -1\n        # \u89c6\u4e3a\u4e22\u5f03\u7684\u951a\u70b9\n        self.BETWEEN_THRESHOLDS = -2\n        assert low_threshold &lt;= high_threshold\n        # \u5224\u65ad\u524d\u666f\u548c\u80cc\u666f\u7684\u9608\u503c\n        self.high_threshold = high_threshold  # 0.7\n        self.low_threshold = low_threshold    # 0.3\n        # \u662f\u5426\u542f\u7528\u7b2c\u4e8c\u5957\u5339\u914d\u65b9\u6848\uff0c\u5373\u5bf9\u6bcf\u4e2a\u7269\u4f53IOU\u503c\u6700\u5927\u7684\u951a\u70b9\u4e5f\u5339\u914d\u8fdb\u6765\uff0c\u5373\u4f7fIOU\u503c\u4e5f\u5f88\u5c0f\n        # \u9632\u6b62\u6709\u7684\u5bf9\u8c61\u4e0e\u6240\u4ee5\u951a\u70b9IOU\u503c\u6700\u5927\u7684\u4e5f\u4e0d\u52300.7\uff0c\u5bfc\u81f4\u6b64\u76ee\u6807\u6ca1\u6709\u5bf9\u5e94\u7684\u951a\u70b9\n        self.allow_low_quality_matches = allow_low_quality_matches\n\n    # \u6b63\u5411\u4f20\u64ad\n    def __call__(self, match_quality_matrix):\n        \"\"\"\n        \u8ba1\u7b97anchors\u4e0e\u6bcf\u4e2agtboxes\u5339\u914d\u7684iou\u6700\u5927\u503c\uff0c\u5e76\u8bb0\u5f55\u7d22\u5f15\uff0c\n        iou&lt;low_threshold\u7d22\u5f15\u503c\u4e3a-1\uff0c low_threshold&lt;=iou&lt;high_threshold\u7d22\u5f15\u503c\u4e3a-2\n        Args:\n            match_quality_matrix (Tensor[float]): an MxN tensor\uff0cM\u4e2a\u5730\u9762\u771f\u5b9e\u6807\u7b7e\u548cN\u4e2a\u951a\u70b9\u4e4b\u95f4\u7684IOU\u77e9\u9635\n        Returns:\n            matches (Tensor[int64]): \u5c3a\u5bf8\u4e3a N\uff0c\u5982\u679c\u4e3a\u524d\u666f\uff0c\u5219\u5bf9\u5e94\u503c\u4e3a[0, M - 1]\uff0c\u5982\u679c\u4e3a\u80cc\u666f\uff0c\u5219\u5bf9\u5e94\u503c\u4e3a-1\uff0c\u5982\u679c\u662f\u88ab\u4e22\u5f03\u7684\u6570\u636e\uff0c\u5219\u503c\u4e3a-2\n        \"\"\"\n        if match_quality_matrix.numel() == 0:\n            # empty targets or proposals not supported during training\n            if match_quality_matrix.shape[0] == 0:\n                raise ValueError(\n                    \"No ground-truth boxes available for one of the images \"\n                    \"during training\")\n            else:\n                raise ValueError(\n                    \"No proposal boxes available for one of the images \"\n                    \"during training\")\n\n        # M x N \u7684\u6bcf\u4e00\u5217\u4ee3\u8868\u4e00\u4e2aanchors\u4e0e\u6240\u6709gt\u7684\u5339\u914diou\u503c\n        # \u8fd9\u91cc\u8868\u793a\u5bf9\u4e8e\u6bcf\u4e2a\u951a\u70b9\u6765\u8bf4(dim=0)\uff0c\u5bfb\u627e\u6700\u5339\u914d\u7684\u7269\u4f53\u6846(\u91cd\u5408\u5ea6\u6700\u9ad8\uff0cIOU\u6700\u5927)\n        # matched_vals\u4ee3\u8868\u6bcf\u5217\u7684\u6700\u5927\u503c\uff0c\u5373\u6bcf\u4e2aanchors\u4e0e\u6240\u6709gt\u5339\u914d\u7684\u6700\u5927iou\u503c,matches\u8868\u793a\u5bf9\u5e94\u6700\u5927\u503c\u6240\u5728\u7684\u7d22\u5f15\n        matched_vals, matches = match_quality_matrix.max(dim=0)  # the dimension to reduce.\n        if self.allow_low_quality_matches:\n            # \u5982\u679c\u9700\u8981\u542f\u7528\u7b2c\u4e8c\u5957\u5339\u914d\u65b9\u6848\u7684\u8bdd(\u5177\u4f53\u89c1\u4e0b\u9762)\uff0c\u514b\u9686\u4e00\u4efd\u6700\u5927\u503c\u7684\u7d22\u5f15\n            all_matches = matches.clone()\n        else:\n            all_matches = None\n\n        # \u8ba1\u7b97iou\u5c0f\u4e8elow_threshold\u7684\u7d22\u5f15\n        below_low_threshold = matched_vals &lt; self.low_threshold\n        # \u8ba1\u7b97iou\u5728low_threshold\u4e0ehigh_threshold\u4e4b\u95f4\u7684\u7d22\u5f15\u503c  \u5f97\u5230IOU\u5927\u4e8e0.3\uff0c\u5c0f\u4e8e0.7\u7684\u951a\u70b9\n        between_thresholds = (matched_vals &gt;= self.low_threshold) &amp; (\n            matched_vals &lt; self.high_threshold\n        )\n        # iou\u5c0f\u4e8elow_threshold\u7684matches\u7d22\u5f15\u7f6e\u4e3a-1\uff0c\u8bbe\u7f6e\u4e3a\u8d1f\u7684\u6837\u672c\n        matches[below_low_threshold] = self.BELOW_LOW_THRESHOLD  # -1\n        # iou\u5728[low_threshold, high_threshold]\u4e4b\u95f4\u7684matches\u7d22\u5f15\u7f6e\u4e3a-2\uff0c\u4e22\u5f03\u7684\u90e8\u5206\n        matches[between_thresholds] = self.BETWEEN_THRESHOLDS    # -2\n        # IOU\u5927\u4e8e0.7\u7684\u90e8\u5206\u4e0d\u505a\u5904\u7406\uff0c\u6570\u503c\u5373\u8868\u793a\u6240\u5339\u914d\u7684\u5bf9\u8c61\u5e8f\u53f7\n        # \u662f\u5426\u542f\u7528\u7b2c\u4e00\u4e2a\u5339\u914d\u51c6\u5219\u3002\u5373\u4e0e\u5f53\u524d\u76ee\u6807\u6846IOU\u6700\u5927\u7684\u4e5f\u88ab\u8bbe\u7f6e\u4e3a\u5c5e\u4e8e\u8be5\u7269\u4f53\uff0c\u5373\u4f7fIOU\u503c\u6bd4\u8f83\u4f4e\n        # \u9632\u6b62\u7269\u4f53A\u56e0\u4e3a\u6240\u6709\u7684\u951a\u70b9IOU\u90fd\u4f4d\u4e8e0.3\u52300.7\u4e4b\u95f4\uff0c\u800c\u4e0d\u88ab\u68c0\u6d4b\u5230\n        if self.allow_low_quality_matches:\n            assert all_matches is not None\n            self.set_low_quality_matches_(matches, all_matches, match_quality_matrix)\n\n        return matches\n</code></pre> <p>\u7b2c\u4e8c\u5957\u5339\u914d\u65b9\u6848</p> <p>\u9632\u6b62\u6709\u7684\u8fc7\u5c0f\u76ee\u6807\u6ca1\u6709\u951a\u70b9\u6765\u5339\u914d</p> <pre><code>def set_low_quality_matches_(self, matches, all_matches, match_quality_matrix):\n    \"\"\"\n    Produce additional matches for predictions that have only low-quality matches.\n    Specifically, for each ground-truth find the set of predictions that have\n    maximum overlap with it (including ties); for each prediction in that set, if\n    it is unmatched, then match it to the ground-truth with which it has the highest\n    quality value.\n    \"\"\"\n    # \u5bf9\u4e8e\u6bcf\u4e2agt boxes\u5bfb\u627e\u4e0e\u5176iou\u6700\u5927\u7684anchor\uff0c\n    # \u5bf9\u4e8e\u6bcf\u4e2a\u6807\u7b7e\u6846gt\uff0c\u6c42\u5f97\u6700\u5339\u914d\u7684\u951a\u70b9\u6846\uff0chighest_quality_foreach_gt\u4e3a\u5339\u914d\u5230\u7684\u6700\u5927iou\u503c\uff0c\u6ce8\u610f\u8fd9\u91ccdim\u8bbe\u4e3a1\n    highest_quality_foreach_gt, _ = match_quality_matrix.max(dim=1)\n    # torch.where\u53ea\u4f20\u5165\u67e5\u8be2\u6761\u4ef6\u65f6\uff0c\u529f\u80fd\u4e0etorch.nonzero\u4e00\u6837\n    # \u5bfb\u627e\u6bcf\u4e2agt boxes\u4e0e\u5176iou\u6700\u5927\u7684anchor\u7d22\u5f15\uff0c\u4e00\u4e2agt\u5339\u914d\u5230\u7684\u6700\u5927iou\u53ef\u80fd\u6709\u591a\u4e2aanchor\n    # \u5bfb\u627e\u975e\u96f6\u90e8\u5206\uff0c\u8fd4\u56de\u975e\u96f6\u5750\u6807\uff0c\u8fd9\u91cc\u7684\u5750\u6807\u6bd4\u8f83\u7279\u6b8a\uff0c\u5177\u4f53\u53ef\u4ee5\u53bb\u770btorch.nonzero\u5b66\u4e60\u7b14\u8bb0\n    gt_pred_pairs_of_highest_quality = torch.where(\n        torch.eq(match_quality_matrix, highest_quality_foreach_gt[:, None])\n    )\n    # gt_pred_pairs_of_highest_quality[:, 0]\u4ee3\u8868\u662f\u5bf9\u5e94\u7684gt index(\u4e0d\u9700\u8981)\n    pre_inds_to_update = gt_pred_pairs_of_highest_quality[1]\n    # \u4fdd\u7559\u8be5anchor\u5339\u914dgt\u6700\u5927iou\u7684\u7d22\u5f15\uff0c\u5373\u4f7fiou\u4f4e\u4e8e\u8bbe\u5b9a\u7684\u9608\u503c\n    # \u628amatches\u66f4\u65b0\u4e00\u904d\n    matches[pre_inds_to_update] = all_matches[pre_inds_to_update]  \n</code></pre>"},{"location":"detection/program/anchor_match/#yolo","title":"YOLO\u673a\u5236","text":"<p>\u4ee3\u7801\u53c2\u8003\u94fe\u63a5\uff1a</p> <ul> <li>https://github.com/WZMIAOMIAO/deep-learning-for-image-processing/tree/master/pytorch_object_detection/yolov3_spp</li> <li>https://github.com/ultralytics/yolov3</li> </ul> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>p</code>\uff1a\u7f51\u7edc\u7684\u9884\u6d4b\u6570\u636e\uff1b</li> <li><code>targets</code>\uff1a\u6807\u7b7e\u6570\u636e\uff1b</li> <li><code>model</code>\uff1a\u68c0\u6d4b\u6a21\u578b\uff0c\u7528\u4e8e\u63d0\u53d6\u951a\u70b9\u6570\u636e\u3002</li> </ul> <p>\u4f8b\u5982\uff1a</p> <p> <p></p> <p></p> <p>\u8f93\u51fa\uff1a</p> <ul> <li> <p><code>tcls</code>\uff1a\u524d\u666f\u951a\u70b9\u5bf9\u5e94\u7684\u7269\u4f53\u7c7b\u522b\uff1b</p> </li> <li> <p><code>tbox</code>\uff1agt box\u76f8\u5bf9anchor\u7684x,y\u504f\u79fb\u91cf\u4ee5\u53caw,h\uff08w,h\u4e0d\u662f\u504f\u79fb\u91cf\uff0c\u662f\u7279\u5f81\u56fe\u4e0a\u8fb9\u754c\u6846\u7684\u5bbd\u9ad8\uff09\uff1b</p> </li> <li> <p><code>indices</code>\uff1a\u56fe\u7247\u5e8f\u53f7\uff0c\u5b58\u6709[\u56fe\u7247\u5e8f\u53f7\uff0c\u951a\u70b9\u5e8f\u53f7\uff08\u5f53\u524d\u7269\u4f53\u548c\u7b2c\u51e0\u4e2a\u951a\u5730\u5339\u914d\uff09\uff0c\u7f51\u683c\u5e8f\u53f7\uff08\u524d\u666f\u951a\u70b9\u7684\u4f4d\u7f6e\uff0c\u5bf9\u5e94\u6a2a\u7eb5\u5750\u6807\u4e24\u4e2a\u6570\u636e\uff09]\uff0c\u951a\u70b9\u5e8f\u53f7\u7528\u4e8e\u540e\u7eed\u751f\u6210\u7f6e\u4fe1\u5ea6\u6807\u7b7e\uff0c\u7f51\u683c\u5e8f\u53f7\u53c8\u53ef\u4ee5\u770b\u4e3a\u951a\u70b9\u7684\u4e2d\u5fc3\u5750\u6807\uff1b</p> </li> <li> <p><code>anch</code>\uff1a\u951a\u70b9\u7684\u5bbd\u9ad8\u5c3a\u5bf8\uff08\u76f8\u5bf9\u4e8e\u7279\u5f81\u56fe\u800c\u8a00\uff09\u3002\uff08<code>tbox</code>\u3001<code>indices</code>\u3001<code>anch</code>\u7ed3\u5408\u53ef\u53cd\u5e94\u7269\u4f53\u7684\u8fb9\u754c\u6846\u4f4d\u7f6e\uff09</p> </li> </ul> <p> <p></p> <p></p> <pre><code>def build_targets(p, targets, model):\n    # Build targets for compute_loss(), input targets(image_idx,class,x,y,w,h)\n    nt = targets.shape[0]\n    tcls, tbox, indices, anch = [], [], [], []\n    gain = torch.ones(6, device=targets.device).long()  # normalized to gridspace gain\n\n    multi_gpu = type(model) in (nn.parallel.DataParallel, nn.parallel.DistributedDataParallel)\n    for i, j in enumerate(model.yolo_layers):  # j: [89, 101, 113]\n        # \u83b7\u53d6\u8be5yolo predictor\u5bf9\u5e94\u7684anchors\n        # \u6ce8\u610fanchor_vec\u662fanchors\u7f29\u653e\u5230\u5bf9\u5e94\u7279\u5f81\u5c42\u4e0a\u7684\u5c3a\u5ea6\uff0c\u56e0\u6b64\u8fd9\u91cc\u7684\u951a\u70b9\u5c3a\u5bf8\u662f\u76f8\u5bf9\u4e8e\u7279\u5f81\u56fe\u7684\u5c3a\u5bf8(\u7279\u5f81\u56fe\u4e0a\u6bcf\u4e2a\u50cf\u7d20\u70b9\u4e4b\u95f4\u7684\u8ddd\u79bb\u89c6\u4e3a1)\n        anchors = model.module.module_list[j].anchor_vec if multi_gpu else model.module_list[j].anchor_vec\n        # p[i].shape: [batch_size, 3, grid_h, grid_w, num_params]\n        # gain\u8868\u793a\u9884\u6d4b\u7279\u5f81\u5c42\u7684\u5c3a\u5bf8\uff0c\u540e\u7eed\u548ctargets\u4e2d\u50a8\u5b58\u7684\u76f8\u5bf9\u5750\u6807\u76f8\u4e58\uff0c\u4f1a\u5f97\u5230\u7279\u5f81\u56fe\u4e0a\u7684\u7edd\u5bf9\u5750\u6807\n        gain[2:] = torch.tensor(p[i].shape)[[3, 2, 3, 2]]  # xyxy gain\n        na = anchors.shape[0]  # number of anchors\uff0c\u9ed8\u8ba43\n        # [3] -&gt; [3, 1] -&gt; [3, nt]\n        at = torch.arange(na).view(na, 1).repeat(1, nt)  # anchor tensor, same as .repeat_interleave(nt)\n\n        # t\u8868\u793a\u7279\u5f81\u56fe\u4e0atarget\u7684\u7edd\u5bf9\u5750\u6807\uff0ctargets\u76f8\u5bf9\u5750\u6807\u4e58\u4ee5\u7279\u5f81\u56fe\u5c3a\u5bf8\u5f97\u5230\n        a, t, offsets = [], targets * gain, 0\n        # Match targets to anchors\uff0c\u5c06\u6807\u7b7e\u548c\u951a\u70b9\u505a\u5339\u914d\n        if nt:\n            # \u901a\u8fc7\u8ba1\u7b97anchor\u6a21\u677f\u4e0e\u6240\u6709target\u7684wh_iou\u6765\u5339\u914d\u6b63\u6837\u672c\n            # j: [3, nt] , iou_t = 0.20\n            # \u5982\u679c\u5b58\u5728target\u7684\u8bdd\uff0c\u8fd9\u91cc\u5148\u5c06target\u4e2d\u6240\u6709\u7684\u76ee\u6807\u4e0e\u951a\u70b9\u505a\u4e00\u6b21\u5339\u914d\n            # \u6bcf\u4e2a\u76ee\u6807\u5339\u914d\u4e00\u4e2a\u951a\u70b9\u6a21\u677f\uff0c\u5339\u914d\u51fa\u4e0e\u76ee\u6807\u8fb9\u754c\u6846\u5bbd\u9ad8\u6bd4\u4f8b\u50cf\u7684\u951a\u70b9\u6a21\u677f\n            # j\u91cc\u884c\u8868\u793a\u6bcf\u4e2a\u7279\u5f81\u4e0a\u7684\u951a\u70b9\u6570\u91cf\uff0c\u5217\u8868\u4e66target\u76ee\u6807\u6570\u91cf\n            # True\u6240\u5728\u7684\u884c\u8868\u793a\u4e0etarget\u76ee\u6807(\u6240\u5728\u7684\u5217)\u6240\u5339\u914d\u7684\u951a\u70b9\u6a21\u677f\u5e8f\u53f7\n            # \u6ce8\u610f\uff0c\u8fd9\u91cc\u53ea\u662f\u8bb2target\u548c\u951a\u70b9\u6a21\u677f\u5339\u914d\uff0c\u5e76\u4e0d\u4f1a\u5f97\u5230\u548c\u7f51\u683c\u4e2d\u7b2c\u51e0\u4e2a\u951a\u70b9\u5339\u914d\n            j = wh_iou(anchors, t[:, 4:6]) &gt; model.hyp['iou_t']  # iou(3,n) = wh_iou(anchors(3,2), gwh(n,2))\n            # t.repeat(na, 1, 1): [nt, 6] -&gt; [3, nt, 6]\n            # \u83b7\u53d6\u6b63\u6837\u672c\u5bf9\u5e94\u7684anchor\u6a21\u677f\u4e0etarget\u4fe1\u606f(\u5148\u7c97\u7565\u5c06\u5339\u914d\u7684\u951a\u70b9\u6a21\u677f\u8868\u793a\u4e3a\u6b63\u7c7b\u951a\u70b9)\n            # \u82e5\u4e00\u4e2a\u8fb9\u754c\u6846\u6807\u7b7e\u5339\u914d\u5230\u591a\u4e2a\u951a\u70b9\u6a21\u677f\uff0c\u5219\u5bf9\u5e94t\u4f1a\u88ab\u201c\u590d\u5236\u201d\u591a\u6b21\n            a, t = at[j], t.repeat(na, 1, 1)[j]  # filter\n\n        # Define\n        # long\u7b49\u4e8eto(torch.int64), \u6570\u503c\u5411\u4e0b\u53d6\u6574\n        # b\u3001c\u5206\u522b\u8868\u793a:\u56fe\u7247\u5e8f\u53f7image_idx(\u4e00\u4e2abatch\u5185\u7684\u5e8f\u53f7), \u7269\u4f53\u7c7b\u522bclass\n        b, c = t[:, :2].long().T\n        # target\u7684\u4e2d\u5fc3\u5750\u6807\uff0c\u7269\u4f53\u8fb9\u754c\u6846\u7684\u4e2d\u70b9\n        gxy = t[:, 2:4]  # grid xy\n        # \u7269\u4f53\u8fb9\u754c\u6846\u7684\u5bbd\u9ad8(\u76f8\u5bf9\u4e8e\u7279\u5f81\u56fe\u800c\u8a00)\n        gwh = t[:, 4:6]  # grid wh\n        # \u5339\u914dtargets\u6240\u5728\u7684grid cell\u5de6\u4e0a\u89d2\u5750\u6807\n        # \u4e0a\u4e0b\u53d6\u6574\uff0c\u5f97\u5230\u5de6\u4e0a\u89d2\u5750\u6807\n        gij = (gxy - offsets).long()\n        gi, gj = gij.T  # grid xy indices\n\n        # Append\n        # gain[3]: grid_h, gain[2]: grid_w\n        # image_idx, anchor_idx, grid indices(y, x)\n        indices.append((b, a, gj.clamp_(0, gain[3]-1), gi.clamp_(0, gain[2]-1)))\n        # gt box\u76f8\u5bf9anchor\u7684x,y\u504f\u79fb\u91cf\u4ee5\u53caw,h\n        tbox.append(torch.cat((gxy - gij, gwh), 1))\n        anch.append(anchors[a])  # anchors\n        tcls.append(c)  # class\n        if c.shape[0]:  # if any targets\n            # \u76ee\u6807\u7684\u6807\u7b7e\u6570\u503c\u4e0d\u80fd\u5927\u4e8e\u7ed9\u5b9a\u7684\u76ee\u6807\u7c7b\u522b\u6570\n            assert c.max() &lt; model.nc, 'Model accepts %g classes labeled from 0-%g, however you labelled a class %g. ' \\\n                                       'See https://github.com/ultralytics/yolov3/wiki/Train-Custom-Data' % (\n                                           model.nc, model.nc - 1, c.max())\n    # tcls\u8868\u793a\u7269\u4f53\u7c7b\u522b\n    # tbox\u8868\u793agt box\u76f8\u5bf9anchor\u7684x,y\u504f\u79fb\u91cf\u4ee5\u53caw,h(w,h\u4e0d\u662f\u504f\u79fb\u91cf\uff0c\u662f\u7279\u5f81\u56fe\u4e0a\u8fb9\u754c\u6846\u7684\u5bbd\u9ad8)\n    # indices\u8868\u793a\u5e8f\u53f7\uff0c\u5b58\u6709[\u56fe\u7247\u5e8f\u53f7\uff0c\u951a\u70b9\u5e8f\u53f7(\u5f53\u524d\u7269\u4f53\u548c\u7b2c\u51e0\u4e2a\u951a\u5730\u5339\u914d)\uff0c\u7f51\u683c\u5e8f\u53f7(\u524d\u666f\u951a\u70b9\u7684\u4f4d\u7f6e\uff0c\u5bf9\u5e94\u6a2a\u7eb5\u5750\u6807\u4e24\u4e2a\u6570\u636e)]\n    # anch\u5b58\u6709\u951a\u70b9\u5bbd\u9ad8\u5c3a\u5bf8(\u76f8\u5bf9\u4e8e\u7279\u5f81\u56fe\u800c\u8a00)\n    return tcls, tbox, indices, anch\n</code></pre> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u6307\u6b63</p> <p>\u4fee\u6539\u4e8e\uff1a2023\u5e742\u670816\u65e5</p>"},{"location":"detection/program/regression/","title":"\u53c2\u6570\u7f16\u7801\u4e0e\u89e3\u7801\u2014\u2014\u6e90\u7801\u7b14\u8bb0","text":""},{"location":"detection/program/regression/#_2","title":"\u4ecb\u7ecd","text":"<p>\u2003\u2003\u5728\u7b97\u6cd5Faster R-CNN\u3001RetinaNet\u4e2d\uff0c\u5b9e\u73b0\u8fb9\u754c\u6846\u7f16\u7801\u548c\u56de\u5f52\u53c2\u6570\u89e3\u7801\u7684\u8fc7\u7a0b\uff0c\u5047\u8bbex_a,y_a,w_a,h_a\u4e3a\u951a\u70b9\u7edd\u5bf9\u5750\u6807\uff0cx,y,w,h\u4e3a\u7269\u4f53\u8fb9\u754c\u6846\u5750\u6807\uff0ct_x,t_y,t_w,t_h\u4e3a\u5404\u4e2a\u5750\u6807\u6570\u636e\u7684\u56de\u5f52\u53c2\u6570\uff1a</p> <ul> <li>\u8fb9\u754c\u6846\u7f16\u7801\uff1a\u8fb9\u754c\u6846\u5750\u6807-&gt;\u56de\u5f52\u53c2\u6570</li> </ul>  t_x=\\frac{x-x_a}{w_a},t_y=\\frac{y-y_a}{h_a},t_w=\\log{\\frac{w}{w_a}},t_h=\\log{\\frac{h}{h_a}}  <ul> <li>\u56de\u5f52\u53c2\u6570\u89e3\u7801\uff1a\u56de\u5f52\u53c2\u6570-&gt;\u8fb9\u754c\u6846\u5750\u6807</li> </ul>  x=w_a*t_x+x_a,y=t_y*h_a+y_a,w=w_a*e^{t_w},h=h_a*e^{t_h}"},{"location":"detection/program/regression/#_3","title":"\u4ee3\u7801\u5b9e\u73b0","text":"<p>\u53c2\u8003\u94fe\u63a5\uff1a</p> <ul> <li>https://github.com/WZMIAOMIAO/deep-learning-for-image-processing</li> <li>https://github.com/pytorch/vision/tree/master/torchvision/models/detection</li> </ul> <p>\u7c7b\u521d\u59cb\u5316</p> <p>\u9700\u8981\u6307\u660e\u4e24\u4e2a\u53d8\u91cf\uff1a</p> <ul> <li><code>weights</code>\uff1a\u56de\u5f52\u53c2\u6570\u7684\u6743\u91cd\u5206\u5e03</li> <li><code>bbox_xform_clip</code>\uff1a\u56de\u5f52\u53c2\u6570\u7684\u6700\u5927\u503c</li> </ul> <p>\u6ce8\uff1a</p> <ul> <li><code>weights</code>\u53c2\u6570\u5176\u5b9e\u662f\u7528\u6765\u5bf9\u8fb9\u6846\u56de\u5f52\u5f97\u5230\u7684\u504f\u79fb\u503c\u505a\u6807\u51c6\u5316\u7684\uff0c\u4ee5\u63d0\u9ad8\u6a21\u578b\u7cbe\u5ea6\uff08\u9ed8\u8ba4\u504f\u79fb\u91cf\u5747\u503c\u4e3a0\uff0c\u65b9\u5dee\u9700\u8981\u81ea\u5df1\u8bbe\u7f6e\uff09\u3002\u5982\u679c\u662f\u4e00\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\uff0c\u5219\u90fd\u8bbe\u7f6e\u4e3a1\u5373\u53ef\uff0c\u5982\u679c\u662f\u4e8c\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\uff0c\u5219\u4e24\u4e2a\u9636\u6bb5\u7684<code>weights</code>\u8bbe\u7f6e\u901a\u5e38\u4e0d\u540c\uff0c\u56e0\u4e3a\u7b2c\u4e8c\u9636\u6bb5\u662f\u57fa\u4e8e\u7b2c\u4e00\u9636\u6bb5\u505a\u9884\u6d4b\uff0c\u56e0\u6b64\u7b2c\u4e8c\u9636\u6bb5\u65b9\u5dee\u66f4\u5c0f\uff0cFaster R-CNN\u4e2d\u7b2c\u4e00\u9636\u6bb5\u5747\u4e3a1\uff0c\u7b2c\u4e8c\u9636\u6bb5\u8bbe\u7f6e\u4e3a[10,10,5,5]\u3002\u53c2\u8003\u94fe\u63a5\uff1ahttps://blog.csdn.net/u014311125/article/details/117750396</li> </ul> <p>\u7f16\u7801\u8fc7\u7a0b\u2014\u2014encode</p> <p>\u4f20\u5165\uff1a\u951a\u70b9\u5750\u6807\u3001\u8fb9\u754c\u6846\u5750\u6807</p> <p>\u8fd4\u56de\uff1a\u56de\u5f52\u53c2\u6570</p> <p>\u89e3\u7801\u8fc7\u7a0b\u2014\u2014decode</p> <p>\u4f20\u5165\uff1a\u951a\u70b9\u5750\u6807\u3001\u56de\u5f52\u53c2\u6570</p> <p>\u8fd4\u56de\uff1a\u8fb9\u754c\u6846\u5750\u6807</p> <pre><code>class BoxCoder(object):\n    \"\"\"\n    This class encodes and decodes a set of bounding boxes into\n    the representation used for training the regressors.\n    \"\"\"\n\n    def __init__(self, weights, bbox_xform_clip=math.log(1000. / 16)):\n        # type: (Tuple[float, float, float, float], float) -&gt; None\n        \"\"\"\n        Arguments:\n            weights (4-element tuple)\n            bbox_xform_clip (float)\n        \"\"\"\n        # RPN\u4e2d\u4e3a[1,1,1,1], fastrcnn\u4e2d\u4e3a[10,10,5,5]\n        self.weights = weights\n        # \u56de\u5f52\u9ad8\u5bbd\u53c2\u6570\u7684\u4e0a\u754c\n        self.bbox_xform_clip = bbox_xform_clip\n\n    # \u89e3\u7801\n    def decode(self, rel_codes, boxes):\n        # type: (Tensor, List[Tensor]) -&gt; Tensor\n        \"\"\"\n        Args:\n            rel_codes: \u8fb9\u754c\u6846\u56de\u5f52\u53c2\u6570\n            boxes: \u951a\u70b9\u6846\u5750\u6807(\u5de6\u4e0a\u3001\u53f3\u4e0b)\n        Returns:\n            pred_boxes: \u8fb9\u754c\u6846\u5750\u6807\u6570\u636e\n        \"\"\"\n        assert isinstance(boxes, (list, tuple))\n        assert isinstance(rel_codes, torch.Tensor)\n        # \u6bcf\u5f20\u56fe\u7247\u7684\u951a\u70b9\u4e2a\u6570\u3002\u7531\u4e8e\u56fe\u7247\u5c3a\u5bf8\u662f\u4e0d\u5b9a\u7684\uff0c\u5373\u7279\u5f81\u56fe\u5c3a\u5bf8\u4e0d\u56fa\u5b9a\uff0c\u56e0\u6b64\u951a\u70b9\u6570\u91cf\u4e5f\u662f\u4e0d\u5b9a\u7684\n        boxes_per_image = [b.size(0) for b in boxes]\n        # \u5c06\u4e00\u4e2abatch\u91cc\u7684\u6240\u6709\u951a\u70b9boxes\u62fc\u63a5\u5728\u4e00\u8d77\uff0cconcat_boxes\u5c3a\u5bf8:[\u56fe\u7247\u4e2d\u951a\u70b9\u603b\u6570*batch, 4]\n        concat_boxes = torch.cat(boxes, dim=0)\n        # \u6c42\u951a\u70b9\u603b\u6570\uff0c\u4e5f\u53ef\u4ee5\u76f4\u63a5\u8c03\u53d6concat_boxes.shape[0]\n        box_sum = 0\n        for val in boxes_per_image:\n            box_sum += val\n        # \u5c06\u9884\u6d4b\u7684bbox\u56de\u5f52\u53c2\u6570\u5e94\u7528\u5230\u5bf9\u5e94anchors\u4e0a\u5f97\u5230\u9884\u6d4bbbox\u7684\u5750\u6807\u3002\n        # \u6ce8\u610f\uff0c\u9884\u6d4b\u7684\u90fd\u662f\u56de\u5f52\u53c2\u6570\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7ed3\u5408\u951a\u70b9\u5750\u6807\u6846\u5f97\u5230\u9884\u6d4b\u7684\u5750\u6807\n        pred_boxes = self.decode_single(\n            rel_codes, concat_boxes\n        )\n\n        # \u9632\u6b62pred_boxes\u4e3a\u7a7a\u65f6\u5bfc\u81f4reshape\u62a5\u9519\n        if box_sum &gt; 0:\n            pred_boxes = pred_boxes.reshape(box_sum, -1, 4)\n        # \u8fd4\u56de\u8fb9\u754c\u6846\u5750\u6807\n        return pred_boxes\n\n    # \u89e3\u7801\u51fd\u6570\n    def decode_single(self, rel_codes, boxes):\n        \"\"\"\n        \u5229\u7528\u9884\u6d4b\u7684\u56de\u5f52\u53c2\u6570\u4e0e\u951a\u70b9\u505a\u8fd0\u7b97\uff0c\u5f97\u5230\u6700\u7ec8\u7269\u4f53\u771f\u5b9e\u7684\u8fb9\u754c\u6846\uff0c\u76f8\u5f53\u4e8e\u4e00\u4e2a\u89e3\u7801\u64cd\u4f5c\n        \u9996\u5148\u5c06\u56de\u5f52\u53c2\u6570\u4fe1\u606f\u4e0e\u951a\u70b9\u4fe1\u606f\u8f6c\u5316\u6210\u4e2d\u5fc3\u5750\u6807\u4fe1\u606f\u548c\u5bbd\u9ad8\u4fe1\u606f\uff0c\u4e4b\u540e\u518d\u505a\u89e3\u7801\uff0c\n        \u5f97\u5230\u771f\u5b9e\u8fb9\u754c\u6846\u7684\u4e2d\u5fc3\u70b9\u548c\u5bbd\u9ad8\uff0c\u6700\u540e\u518d\u8f6c\u5316\u4e3a\u5de6\u4e0a\u89d2\u548c\u53f3\u4e0b\u89d2\u4e24\u4e2a\u5750\u6807\u4fe1\u606f\n        Arguments:\n            rel_codes (Tensor): encoded boxes (\u8fb9\u754c\u6846\u56de\u5f52\u53c2\u6570)\n            boxes (Tensor): reference boxes (anchors/proposals\u951a\u70b9\u4fe1\u606f)\n        \"\"\"\n        boxes = boxes.to(rel_codes.dtype)\n\n        # xmin, ymin, xmax, ymax\n        # anchors/proposals\u5bbd\u5ea6\n        widths = boxes[:, 2] - boxes[:, 0]\n        # anchors/proposals\u9ad8\u5ea6\n        heights = boxes[:, 3] - boxes[:, 1]\n        # anchors/proposals\u4e2d\u5fc3x\u5750\u6807\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        # anchors/proposals\u4e2d\u5fc3y\u5750\u6807\n        ctr_y = boxes[:, 1] + 0.5 * heights\n        # RPN\u4e2d\u4e3a[1,1,1,1], fastrcnn\u4e2d\u4e3a[10,10,5,5]\n        wx, wy, ww, wh = self.weights\n        # \u9884\u6d4banchors/proposals\u7684\u4e2d\u5fc3\u5750\u6807x\u56de\u5f52\u53c2\u6570\n        dx = rel_codes[:, 0::4] / wx\n        # \u9884\u6d4banchors/proposals\u7684\u4e2d\u5fc3\u5750\u6807y\u56de\u5f52\u53c2\u6570\n        dy = rel_codes[:, 1::4] / wy\n        # \u9884\u6d4banchors/proposals\u7684\u5bbd\u5ea6\u56de\u5f52\u53c2\u6570\n        dw = rel_codes[:, 2::4] / ww\n        # \u9884\u6d4banchors/proposals\u7684\u9ad8\u5ea6\u56de\u5f52\u53c2\u6570\n        dh = rel_codes[:, 3::4] / wh\n\n        # limit max value, prevent sending too large values into torch.exp()\n        # self.bbox_xform_clip=math.log(1000. / 16)   4.135\n        # \u9650\u5236\u4e0a\u9650\n        dw = torch.clamp(dw, max=self.bbox_xform_clip)\n        dh = torch.clamp(dh, max=self.bbox_xform_clip)\n        # \u5229\u7528\u516c\u5f0f\u8ba1\u7b97\u8fb9\u754c\u6846\u7684\u4e2d\u5fc3\u5750\u6807\u4ee5\u53ca\u5bbd\u9ad8\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n        # \u5f97\u5230\u5de6\u4e0a\u89d2\u548c\u53f3\u4e0b\u89d2\uff0c\u8fd9\u91cc\u65b0\u521b\u5efa\u4e860.5\uff0c\u8bbe\u5907\u548c\u6570\u636e\u7c7b\u578b\u9700\u4e00\u81f4\n        # xmin \n        pred_boxes1 = pred_ctr_x - torch.tensor(0.5, dtype=pred_ctr_x.dtype, device=pred_w.device) * pred_w\n        # ymin\n        pred_boxes2 = pred_ctr_y - torch.tensor(0.5, dtype=pred_ctr_y.dtype, device=pred_h.device) * pred_h\n        # xmax\n        pred_boxes3 = pred_ctr_x + torch.tensor(0.5, dtype=pred_ctr_x.dtype, device=pred_w.device) * pred_w\n        # ymax\n        pred_boxes4 = pred_ctr_y + torch.tensor(0.5, dtype=pred_ctr_y.dtype, device=pred_h.device) * pred_h\n        # \u5c06\u6240\u6709\u7684\u8fb9\u754c\u6846\u5750\u6807\u70b9\u5408\u5e76\n        pred_boxes = torch.stack((pred_boxes1, pred_boxes2, pred_boxes3, pred_boxes4), dim=2).flatten(1)\n        # \u8fd4\u56de\u6240\u6709\u7684\u8fb9\u754c\u6846\u5750\u6807\u70b9\n        return pred_boxes\n\n    # \u7f16\u7801\n    def encode(self, reference_boxes, proposals):\n        # type: (List[Tensor], List[Tensor]) -&gt; List[Tensor]\n        \"\"\"\n        \u7ed3\u5408anchors\u548c\u4e0e\u4e4b\u5bf9\u5e94\u7684gt\u8ba1\u7b97regression\u53c2\u6570\n        Args:\n            reference_boxes: List[Tensor] \u6bcf\u4e2aproposal/anchor\u5bf9\u5e94\u7684gt_boxes\n            proposals: List[Tensor] anchors/proposals\n\n        Returns: \u6bcf\u4e2a\u951a\u70b9\u5bf9\u5e94\u7684\u56de\u5f52\u53c2\u6570regression parameters \n\n        \"\"\"\n        # \u7edf\u8ba1\u6bcf\u5f20\u56fe\u50cf\u7684anchors\u4e2a\u6570\uff0c\u65b9\u4fbf\u540e\u9762\u62fc\u63a5\u5728\u4e00\u8d77\u5904\u7406\u540e\u5728\u5206\u5f00\n        # reference_boxes\u548cproposal\u6570\u636e\u7ed3\u6784\u76f8\u540c\n        boxes_per_image = [len(b) for b in reference_boxes]\n        reference_boxes = torch.cat(reference_boxes, dim=0)  # \u6bcf\u4e2a\u951a\u70b9\u5bf9\u5e94\u7684\u76ee\u6807\u8fb9\u754c\u6846\u5408\u5e76\n        proposals = torch.cat(proposals, dim=0)  # \u951a\u70b9\u5408\u5e76\n\n        # \u8fd9\u91cc\u76f8\u5f53\u4e8e\u89e3\u7801\u7684\u9006\u8fd0\u7b97\n        targets = self.encode_single(reference_boxes, proposals)\n        # \u5206\u79bb\uff0c\u5206\u6210batch\n        return targets.split(boxes_per_image, 0)  \n\n    # \u7f16\u7801\u51fd\u6570\n    def encode_single(self, reference_boxes, proposals):\n        \"\"\"\n        \u5bf9\u6bcf\u4e2a\u951a\u70b9\u4e0a\u7684\u8fb9\u754c\u6846\u8fdb\u884c\u7f16\u7801\uff0c\u5f97\u5230\u5bf9\u5e94\u7684\u56de\u5f52\u53c2\u6570\n        Arguments:\n            reference_boxes (Tensor): \u6bcf\u4e2a\u951a\u70b9\u5bf9\u5e94\u7684\u76ee\u6807\u8fb9\u754c\u6846\n            proposals (Tensor): \u951a\u70b9\n        \"\"\"\n        dtype = reference_boxes.dtype\n        device = reference_boxes.device\n        # \u8f6c\u5316\u6210tensor\uff0c\u6570\u636e\u7c7b\u578b\u4e0e\u8bbe\u5907\u7c7b\u578b\u90fd\u76f8\u540c\n        # RPN\u4e2d\u4e3a[1, 1, 1, 1], fastrcnn\u4e2d\u4e3a[10, 10, 5, 5]\n        weights = torch.as_tensor(self.weights, dtype=dtype, device=device)\n        targets = encode_boxes(reference_boxes, proposals, weights)\n\n        return targets\n</code></pre> <p>\u5176\u4e2d<code>encode_boxes</code>\u51fd\u6570\u4e3a\uff1a</p> <pre><code>def encode_boxes(reference_boxes, proposals, weights):\n    # type: (torch.Tensor, torch.Tensor, torch.Tensor) -&gt; torch.Tensor\n    \"\"\"\n    \u5229\u7528\u951a\u70b9\u4fe1\u606f\u548c\u8fb9\u754c\u6846\u4fe1\u606f\u7f16\u7801\u5f97\u5230\u56de\u5f52\u53c2\u6570\n    \u5728\u516c\u5f0f\u4e2d\u53c2\u4e0e\u8ba1\u7b97\u7684\u4e3a\u77e9\u5f62\u6846\u7684\u5bbd\u3001\u9ad8\u3001\u4e2d\u5fc3\u5750\u6807\n    \u56e0\u6b64\u9700\u8981\u5148\u505a\u8f6c\u6362\uff0c\u7136\u540e\n\n    Arguments:\n        reference_boxes (Tensor): reference boxes(gt)\u951a\u70b9\u53c2\u8003\u7684\u8fb9\u754c\u6846\n        proposals (Tensor): boxes to be encoded(anchors)\u951a\u70b9\n        weights: \u6743\u91cd\n    \"\"\"\n\n    # perform some unpacking to make it JIT-fusion friendly\n    wx = weights[0]\n    wy = weights[1]\n    ww = weights[2]\n    wh = weights[3]\n    # \u951a\u70b9\u7684\u5750\u6807\u503c\n    proposals_x1 = proposals[:, 0].unsqueeze(1) \n    proposals_y1 = proposals[:, 1].unsqueeze(1)\n    proposals_x2 = proposals[:, 2].unsqueeze(1)\n    proposals_y2 = proposals[:, 3].unsqueeze(1)\n    # \u7528\u4e8e\u53c2\u8003\u7684\u76ee\u6807\u8fb9\u754c\u6846\u5750\u6807\u503c\n    reference_boxes_x1 = reference_boxes[:, 0].unsqueeze(1)  \n    reference_boxes_y1 = reference_boxes[:, 1].unsqueeze(1)\n    reference_boxes_x2 = reference_boxes[:, 2].unsqueeze(1)\n    reference_boxes_y2 = reference_boxes[:, 3].unsqueeze(1)\n\n    # \u8ba1\u7b97\u951a\u70b9\u5bbd\u3001\u9ad8\u3001\u4e2d\u5fc3\u5750\u6807\n    ex_widths = proposals_x2 - proposals_x1  \n    ex_heights = proposals_y2 - proposals_y1\n\n    ex_ctr_x = proposals_x1 + 0.5 * ex_widths \n    ex_ctr_y = proposals_y1 + 0.5 * ex_heights\n    # \u4e0e\u951a\u70b9\u4e00\u6837\uff0c\u8ba1\u7b97\u53c2\u8003\u8fb9\u754c\u6846\u5bbd\u3001\u9ad8\u3001\u4e2d\u5fc3\u5750\u6807\n    gt_widths = reference_boxes_x2 - reference_boxes_x1\n    gt_heights = reference_boxes_y2 - reference_boxes_y1\n    gt_ctr_x = reference_boxes_x1 + 0.5 * gt_widths\n    gt_ctr_y = reference_boxes_y1 + 0.5 * gt_heights\n    # \u5229\u7528\u516c\u5f0f\u5f97\u5230\u56de\u5f52\u53c2\u6570\uff0c\u5206\u522b\u5bf9\u5e94\u4e8e\u4e2d\u5fc3\u5750\u6807\u3001\u5bbd\u3001\u9ad8\n    # \u56e0\u6b64\u6700\u7ec8\u9884\u6d4b\u65f6\u5f97\u5230\u7684\u56de\u5f52\u53c2\u6570\u4e5f\u662f\u5bf9\u5e94\u4e8e\u4e2d\u5fc3\u5750\u6807\u3001\u5bbd\u3001\u9ad8\n    targets_dx = wx * (gt_ctr_x - ex_ctr_x) / ex_widths\n    targets_dy = wy * (gt_ctr_y - ex_ctr_y) / ex_heights\n    targets_dw = ww * torch.log(gt_widths / ex_widths)\n    targets_dh = wh * torch.log(gt_heights / ex_heights)\n    # \u5c06\u56db\u4e2a\u56de\u5f52\u53c2\u6570\u5408\u5e76\n    targets = torch.cat((targets_dx, targets_dy, targets_dw, targets_dh), dim=1)\n    return targets\n</code></pre> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u6307\u6b63</p> <p>\u521d\u6b65\u5b8c\u7a3f\u4e8e\uff1a2023\u5e741\u670817\u65e5</p>"},{"location":"detection/program/train/","title":"\u76ee\u6807\u68c0\u6d4b\u2014\u2014\u8bad\u7ec3\u7a0b\u5e8f","text":"<p>\u53c2\u8003\u94fe\u63a5\uff1a</p> <ul> <li>https://www.bilibili.com/video/BV1of4y1m7nj</li> <li>https://github.com/WZMIAOMIAO/deep-learning-for-image-processing</li> </ul>"},{"location":"detection/program/train/#_2","title":"\u6570\u636e\u96c6\u7684\u8bfb\u53d6","text":"<pre><code>class VOCDataSet(Dataset):\n    \"\"\"\u8bfb\u53d6\u89e3\u6790PASCAL VOC2007/2012\u6570\u636e\u96c6\"\"\"\n\n    def __init__(self, voc_root, year=\"2012\", transforms=None, txt_name: str = \"train.txt\"):\n        assert year in [\"2007\", \"2012\"], \"year must be in ['2007', '2012']\"\n        # \u5f97\u5230\u6570\u636e\u96c6\u6839\u8def\u5f84\n        self.root = os.path.join(voc_root, \"VOCdevkit\", f\"VOC{year}\")\n        # \u56fe\u50cf\u6839\u76ee\u5f55\uff0c\u5b58\u6709\u6240\u6709\u56fe\u50cf\u7684\u76ee\u5f55\n        self.img_root = os.path.join(self.root, \"JPEGImages\")\n        # \u6ce8\u91ca\u6839\u76ee\u5f55\uff0c\u5b58\u6709\u6240\u6709xml\u6587\u4ef6\u7684\u76ee\u5f55\n        self.annotations_root = os.path.join(self.root, \"Annotations\")\n\n        # read train.txt or val.txt file\uff0c\u8bfb\u53d6\u5b58\u6709\u6240\u6709\u56fe\u7247\u540d\u79f0\u7684txt\u6587\u4ef6\n        txt_path = os.path.join(self.root, \"ImageSets\", \"Main\", txt_name)\n        assert os.path.exists(txt_path), \"not found {} file.\".format(txt_name)\n        # \u904d\u5386\u8bfb\u53d6\u5230\u7684txt\u6587\u4ef6\n        with open(txt_path) as read:\n            # .strip()\u53bb\u6389\u6362\u884c\u7b26\uff0c\u8fd9\u91cc\u8bfb\u53d6\u6240\u6709xml\u7684\u5730\u5740\uff0c\u50a8\u5b58\u6210\u4e00\u4e2a\u5217\u8868\n            self.xml_list = [os.path.join(self.annotations_root, line.strip() + \".xml\")\n                             for line in read.readlines() if len(line.strip()) &gt; 0]\n\n        # check file\uff0cxml\u4e2a\u6570\u5fc5\u987b\u5927\u4e8e0\n        assert len(self.xml_list) &gt; 0, \"in '{}' file does not find any information.\".format(txt_path)\n        for xml_path in self.xml_list:\n            # \u68c0\u67e5\u6bcf\u4e2axml\u5730\u5740\u662f\u5426\u5b58\u5728\n            assert os.path.exists(xml_path), \"not found '{}' file.\".format(xml_path)\n        # read class_indict\n        # \u8bfb\u53d6\u7c7b\u522b\u4fe1\u606f\n        json_file = './pascal_voc_classes.json'\n        # \u68c0\u67e5\u50a8\u5b58\u7c7b\u522b\u7684json\u6587\u4ef6\u662f\u5426\u5b58\u5728\n        assert os.path.exists(json_file), \"{} file not exist.\".format(json_file)\n        json_file = open(json_file, 'r')\n        # \u5f97\u5230\u7c7b\u522b\u5217\u8868\n        self.class_dict = json.load(json_file)\n        json_file.close()\n        # \u6570\u636e\u9884\u5904\u7406\u64cd\u4f5c\n        self.transforms = transforms\n\n    def __len__(self):\n        return len(self.xml_list)\n\n    def __getitem__(self, idx):\n        # read xml\uff0c\u6839\u636e\u5e8f\u53f7idx\uff0c\u5f97\u5230xml\u8def\u5f84\n        xml_path = self.xml_list[idx]\n        # \u6253\u5f00\u6587\u4ef6\n        with open(xml_path) as fid:\n            xml_str = fid.read()\n        xml = etree.fromstring(xml_str)\n        # \u5f97\u5230\u5b57\u5178\u683c\u5f0f\u7684\u6807\u7b7e\u6570\u636e\n        data = self.parse_xml_to_dict(xml)[\"annotation\"]\n        # \u5f97\u5230\u56fe\u7247\u8def\u5f84\n        img_path = os.path.join(self.img_root, data[\"filename\"])\n        # \u8bfb\u53d6\u56fe\u7247\n        image = Image.open(img_path)\n        # \u89c4\u5b9a\u56fe\u7247\u683c\u5f0f\n        if image.format != \"JPEG\":\n            raise ValueError(\"Image '{}' format not JPEG\".format(img_path))\n        # \u521d\u59cb\u5316\u5b58\u50a8\u6807\u7b7e\u4fe1\u606f\u7684\u53d8\u91cf\n        boxes = []\n        labels = []\n        iscrowd = []\n        assert \"object\" in data, \"{} lack of object information.\".format(xml_path)\n        for obj in data[\"object\"]:\n            # \u5f97\u5230\u8fb9\u754c\u6846\u5750\u6807\n            xmin = float(obj[\"bndbox\"][\"xmin\"])\n            xmax = float(obj[\"bndbox\"][\"xmax\"])\n            ymin = float(obj[\"bndbox\"][\"ymin\"])\n            ymax = float(obj[\"bndbox\"][\"ymax\"])\n\n            # \u8fdb\u4e00\u6b65\u68c0\u67e5\u6570\u636e\uff0c\u6709\u7684\u6807\u6ce8\u4fe1\u606f\u4e2d\u53ef\u80fd\u6709w\u6216h\u4e3a0\u7684\u60c5\u51b5\uff0c\u8fd9\u6837\u7684\u6570\u636e\u4f1a\u5bfc\u81f4\u8ba1\u7b97\u56de\u5f52loss\u4e3anan\n            if xmax &lt;= xmin or ymax &lt;= ymin:\n                print(\"Warning: in '{}' xml, there are some bbox w/h &lt;=0\".format(xml_path))\n                continue\n            # \u5b58\u50a8\u8fb9\u754c\u6846\u5750\u6807\u4fe1\u606f\n            boxes.append([xmin, ymin, xmax, ymax])\n            # \u5f97\u5230\u7c7b\u522b\n            labels.append(self.class_dict[obj[\"name\"]])\n            # difficult\u4e3a1\u8868\u793a\u68c0\u6d4b\u6bd4\u8f83\u96be\uff0c\u4e3a0\u8868\u793a\u68c0\u6d4b\u6bd4\u8f83\u5bb9\u6613\n            if \"difficult\" in obj:\n                iscrowd.append(int(obj[\"difficult\"]))\n            else:\n                iscrowd.append(0)\n\n        # \u5c06\u6240\u6709\u6570\u636e\u8f6c\u5316\u4e3atensor\u683c\u5f0f\n        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n        labels = torch.as_tensor(labels, dtype=torch.int64)\n        iscrowd = torch.as_tensor(iscrowd, dtype=torch.int64)\n        image_id = torch.tensor([idx])\n        # \u8ba1\u7b97\u8fb9\u754c\u6846\u533a\u57df\u9762\u79ef\n        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n        # \u5c06\u6807\u7b7e\u6570\u636e\u8f6c\u5316\u4e3a\u5b57\u5178\u683c\u5f0f\uff0c\u4fbf\u4e8e\u540e\u7eed\u8c03\u7528\n        target = {}\n        target[\"boxes\"] = boxes\n        target[\"labels\"] = labels\n        target[\"image_id\"] = image_id\n        target[\"area\"] = area\n        target[\"iscrowd\"] = iscrowd\n        # \u9884\u5904\u7406\u64cd\u4f5c\n        if self.transforms is not None:\n            # target\u4e5f\u9700\u8981\u505atransforms\n            image, target = self.transforms(image, target)\n        # \u8fd4\u56de\u8bfb\u5230\u7684\u56fe\u7247\u548c\u76f8\u5e94\u7684\u6807\u7b7e\n        return image, target\n</code></pre> <p>\u5c06xml\u6587\u4ef6\u89e3\u6790\u6210\u5b57\u5178\u5f62\u5f0f\u7684\u6570\u636e</p> <pre><code>def parse_xml_to_dict(self, xml):\n    \"\"\"\n    \u5c06xml\u6587\u4ef6\u89e3\u6790\u6210\u5b57\u5178\u5f62\u5f0f\uff0c\u53c2\u8003tensorflow\u7684recursive_parse_xml_to_dict\n    Args:\n        xml: xml tree obtained by parsing XML file contents using lxml.etree\n\n    Returns:\n        Python dictionary holding XML contents.\n    \"\"\"\n    # \u5982\u679c\u904d\u5386\u5230\u5e95\u5c42\uff0c\u76f4\u63a5\u8fd4\u56detag\u5bf9\u5e94\u7684\u4fe1\u606f\n    if len(xml) == 0:\n        return {xml.tag: xml.text}\n\n    result = {}\n    for child in xml:\n        # \u9012\u5f52\u904d\u5386\u6807\u7b7e\u4fe1\u606f\n        child_result = self.parse_xml_to_dict(child)\n        if child.tag != 'object':\n            # \u5982\u679c\u4e0d\u662fobject\u4fe1\u606f\uff0c\u5219\u76f4\u63a5\u8d4b\u503c\u5373\u53ef\uff0c\u9ed8\u8ba4\u81ea\u52a8\u521b\u5efa\u5b57\u5178\n            result[child.tag] = child_result[child.tag]\n        else:\n            # \u56e0\u4e3aobject\u53ef\u80fd\u6709\u591a\u4e2a\uff0c\u6240\u4ee5\u9700\u8981\u653e\u5165\u5217\u8868\u91cc\n            # \u5982\u679c\u5b57\u5178\u4e0d\u5b58\u5728object\u952e\uff0c\u5219\u65b0\u5efa\u4e00\u4e2a\n            if child.tag not in result:\n                result[child.tag] = []\n            # \u4f20\u5165object\u5217\u8868\u4e2d\n            result[child.tag].append(child_result[child.tag])\n    # \u8fd4\u56de\u5b57\u5178\u683c\u5f0f\u7684\u6807\u7b7e\n    return {xml.tag: result}\n</code></pre>"},{"location":"detection/program/train/#_3","title":"\u6570\u636e\u91c7\u6837","text":"<p>\u5c06\u8bad\u7ec3\u96c6\u56fe\u7247\u6309\u9ad8\u5bbd\u6bd4\u4f8b\u5212\u5206\uff0c\u5728\u540c\u4e00\u6279\u6b21\u4e2d\u53ea\u91c7\u76f8\u540c\u533a\u95f4\u5185\u7684\u56fe\u7247</p> <pre><code>class GroupedBatchSampler(BatchSampler):\n    \"\"\"\n    Wraps another sampler to yield a mini-batch of indices.\n    It enforces that the batch only contain elements from the same group.\n    It also tries to provide mini-batches which follows an ordering which is\n    as close as possible to the ordering from the original sampler.\n    Arguments:\n        sampler (Sampler): Base sampler.\n        group_ids (list[int]): If the sampler produces indices in range [0, N),\n            `group_ids` must be a list of `N` ints which contains the group id of each sample.\n            The group ids must be a continuous set of integers starting from\n            0, i.e. they must be in the range [0, num_groups).\n        batch_size (int): Size of mini-batch.\n    \"\"\"\n    def __init__(self, sampler, group_ids, batch_size):\n        if not isinstance(sampler, Sampler):\n            raise ValueError(\n                \"sampler should be an instance of \"\n                \"torch.utils.data.Sampler, but got sampler={}\".format(sampler)\n            )\n        # \u968f\u673a\u91c7\u6837\u5668\n        self.sampler = sampler\n        # \u56fe\u50cf\u5206\u7ec4\u7d22\u5f15\n        self.group_ids = group_ids\n        # batch size\n        self.batch_size = batch_size\n\n    def __iter__(self):\n        # \u521d\u59cb\u5316\u5b57\u5178\uff0c\u503c\u7684\u6570\u636e\u7c7b\u578b\u4e3a\u5217\u8868\u683c\u5f0f\n        buffer_per_group = defaultdict(list)\n        samples_per_group = defaultdict(list)\n\n        num_batches = 0\n        # \u968f\u673a\u5f97\u5230\u4e00\u4e2a\u5e8f\u53f7\n        for idx in self.sampler:\n            # \u5f97\u5230\u88ab\u91c7\u6837\u56fe\u50cf\u7684\u533a\u95f4\u5206\u7ec4\u60c5\u51b5\n            group_id = self.group_ids[idx]\n            # \u952e\u4e3a\u5206\u7ec4\u6807\u7b7e\uff0c\u503c\u4e3a\u56fe\u7247\u5e8f\u53f7\u7ec4\u6210\u7684\u5217\u8868\n            buffer_per_group[group_id].append(idx)\n            samples_per_group[group_id].append(idx)\n            # \u5982\u679c\u5f53\u524d\u91c7\u6837\u56fe\u7247\u6240\u5728\u7684\u533a\u95f4\u4e2d\uff0c\u56fe\u7247\u603b\u6570\u5df2\u7ecf\u8fbe\u5230batch size\u5927\u5c0f\uff0c\u5373\u6ee1\u8db3\u4e00\u4e2a\u6279\u6b21\n            if len(buffer_per_group[group_id]) == self.batch_size:\n                # \u5219\u5c06\u8be5\u533a\u95f4\u76ee\u524d\u7684\u56fe\u7247\u6253\u5305\u6210\u4e00\u4e2a\u53ef\u8fed\u4ee3\u7684\u5bf9\u8c61\uff0c\u540e\u9762\u4f1a\u8fdb\u5165\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684for\u5faa\u73af\n                yield buffer_per_group[group_id]\n                # batch\u6570\u91cf\u52a0\u4e00\n                num_batches += 1\n                # \u4e4b\u540e\u5220\u53bb\u8be5\u533a\u95f4\u4e2d\u5df2\u7ecf\u8bad\u7ec3\u8fc7\u7684\u56fe\u7247\n                del buffer_per_group[group_id]\n            assert len(buffer_per_group[group_id]) &lt; self.batch_size\n\n        \"\"\"\n        \u76ee\u524d\u5df2\u7ecf\u5c06\u6240\u6709\u56fe\u7247\u904d\u5386\u5b8c\u4e86\uff0c\u4f46\u662f\u6bcf\u4e2a\u533a\u95f4\u4e2d\u53ef\u80fd\u8fd8\u7559\u6709\u90e8\u5206\u56fe\u7247\u672a\u53c2\u52a0\u8bad\u7ec3(\u6570\u76ee\u4e0d\u591f\u6784\u6210\u4e00\u4e2abatch)\n        \u56e0\u6b64batch\u7684\u603b\u6570\u8fbe\u4e0d\u5230\u671f\u671b\u7684\u8981\u6c42\uff0c\u8fd9\u91cc\u9700\u8981\u5bf9\u90e8\u5206\u7ec4\u4e2d\u7684\u56fe\u7247\u505a\u6269\u5145\uff0c\u5229\u7528\u4e4b\u524d\u8bad\u7ec3\u8fc7\u7684\u56fe\u7247\u6765\u6269\u5145\u5f53\u524d\u7ec4\u5185\u7684\u56fe\u7247\n        \u4ece\u800c\u6784\u6210\u4e00\u4e2abatch\u6765\u8bad\u7ec3\u7f51\u7edc\u3002\n        \u8fd9\u91cc\u6269\u5145\u7ec4\u5185\u5269\u4f59\u56fe\u7247\u6570\u91cf\u591a\u7684\u533a\u95f4\u5206\u7ec4\uff0c\u5e76\u4e0d\u662f\u5bf9\u6240\u6709\u5206\u7ec4\u90fd\u6269\u5145\uff0c\u53ea\u8981batch\u6570\u91cf\u6ee1\u8db3\u671f\u671b\u7684\u6570\u91cf\u5c31\u53ef\u4ee5\n        \"\"\"\n\n        # \u671f\u671b\u7684batch\u6570\u91cf\n        expected_num_batches = len(self)\n        # \u671f\u671b\u7684\u51cf\u53bb\u5df2\u7ecf\u5f97\u5230\u7684\uff0c\u8fd9\u91cc\u5f97\u5230\u8fd8\u5dee\u591a\u5c11batch\n        num_remaining = expected_num_batches - num_batches\n        if num_remaining &gt; 0:\n            # \u6309\u76ee\u524d\u6bcf\u4e2a\u533a\u95f4\u5185\u5269\u4f59\u56fe\u7247\u7684\u6570\u91cf\u6765\u904d\u5386\uff0c\u5148\u6269\u5145\u7ec4\u5185\u56fe\u7247\u6570\u91cf\u5269\u4f59\u591a\u7684\u5206\u7ec4\n            for group_id, _ in sorted(buffer_per_group.items(),\n                                      key=lambda x: len(x[1]), reverse=True):\n                # remaining\u8868\u793a\u5f53\u524d\u5206\u7ec4\u8fd8\u5dee\u591a\u5c11\u5f20\u56fe\u7247\u53ef\u4ee5\u7ec4\u6210\u4e00\u4e2abatch\n                remaining = self.batch_size - len(buffer_per_group[group_id])\n                # \u8fd9\u91cc\u8868\u793a\u5c06\u4e4b\u524d\u8bad\u7ec3\u8fc7\u7684\u6570\u636e\u590d\u5236\u51e0\u904d\uff0c\u4ece\u800c\u4fdd\u8bc1samples_from_group_id\u4e2d\u81f3\u5c11\u6709remaining\u4e2a\u6570\u636e\n                samples_from_group_id = _repeat_to_at_least(samples_per_group[group_id], remaining)\n                # .extend\u8868\u793a\u6269\u5c55\u539f\u5217\u8868\uff0c\u76f4\u63a5\u9009\u53d6\u524dremaining\u4e2aid\u5373\u53ef\n                buffer_per_group[group_id].extend(samples_from_group_id[:remaining])\n                # \u518d\u6b21\u68c0\u67e5\u662f\u5426\u53ef\u4ee5\u6784\u6210\u4e00\u4e2abatch size\n                assert len(buffer_per_group[group_id]) == self.batch_size\n                # \u6253\u5305\u6210\u4e00\u4e2abatch\uff0c\u53c2\u4e0e\u8bad\u7ec3\n                yield buffer_per_group[group_id]\n                num_remaining -= 1\n                # \u5982\u679cbatch\u6570\u91cf\u8fbe\u5230\u671f\u671b\u7684\u6570\u91cf\u4e86\uff0c\u5219\u8df3\u51fa\u5faa\u73af\n                if num_remaining == 0:\n                    break\n        assert num_remaining == 0\n\n    def __len__(self):\n        # batch\u603b\u6570\uff0c\u6837\u672c\u6570\u9664\u4ee5batch size\n        return len(self.sampler) // self.batch_size\n</code></pre> <p>\u91cd\u590d\u8db3\u591f\u591a\u7684\u6b21\u6570</p> <pre><code>def _repeat_to_at_least(iterable, n):\n    # math.ceil\u8868\u793a\u4e0a\u53d6\u6574\u64cd\u4f5c\n    repeat_times = math.ceil(n / len(iterable))\n    # repeat\u8868\u793a\u5c06iterable\u91cd\u590drepeat_times\u904d\uff0c\u4e4b\u540e\u5229\u7528chain.from_iterable\u8f6c\u5316\u4e3a\u53ef\u8fed\u4ee3\u7684\u5bf9\u8c61\n    repeated = chain.from_iterable(repeat(iterable, repeat_times))\n    # \u5229\u7528list\u65b9\u6cd5\u8f6c\u5316\u4e3alist\u683c\u5f0f\u7684\u6570\u636e\n    # \u76f8\u5f53\u4e8e\u590d\u5236repeat_times\u904diterable\uff0c\u4e4b\u540e\u518d\u5c06\u590d\u5236\u7684\u5217\u8868\u62fc\u63a5\u8d77\u6765\n    return list(repeated)\n</code></pre>"},{"location":"detection/program/train/#_4","title":"\u6309\u5bbd\u9ad8\u6bd4\u4f8b\u5bf9\u56fe\u7247\u5206\u7ec4","text":"<pre><code>def create_aspect_ratio_groups(dataset, k=0):\n    # \u8ba1\u7b97\u6240\u6709\u6570\u636e\u96c6\u4e2d\u7684\u56fe\u7247width/height\u6bd4\u4f8b\n    aspect_ratios = compute_aspect_ratios(dataset)\n    # \u5c06[0.5, 2]\u533a\u95f4\u5212\u5206\u62102*k\u7b49\u4efd\uff0c2k+1\u4e2a\u70b9\uff0c\u8fd9\u91cc\u5212\u62102k\u4e2a\u533a\u95f4\uff0c\u540e\u7eed\u518d\u52a0\u4e0a0\u52300.5\uff0c\u4e0e2\u5230inf(\u6b63\u65e0\u7a77)\uff0c\u4e00\u5171\u5f97\u52302(k+1)\u4e2a\u533a\u95f4\n    bins = (2 ** np.linspace(-1, 1, 2 * k + 1)).tolist() if k &gt; 0 else [1.0]\n\n    # \u7edf\u8ba1\u6240\u6709\u56fe\u50cf\u6bd4\u4f8b\u5728bins\u533a\u95f4\u4e2d\u7684\u4f4d\u7f6e\u7d22\u5f15\uff0c\u8fd4\u56de\u7684\u662f\u533a\u95f4\u7d22\u5f15\n    groups = _quantize(aspect_ratios, bins)\n    # count number of elements per group\n    # \u7edf\u8ba1\u6bcf\u4e2a\u533a\u95f4\u7684\u9891\u6b21\uff0c\u5373\u5f97\u5230\u6bcf\u4e2a\u533a\u95f4\u4e2d\u7684\u56fe\u50cf\u6570\u91cf\n    counts = np.unique(groups, return_counts=True)[1]\n    # \u533a\u95f4\u5212\u5206\u60c5\u51b5\uff0c\u4ece0\u5230\u6b63\u65e0\u7a77\n    fbins = [0] + bins + [np.inf]\n    print(\"Using {} as bins for aspect ratio quantization\".format(fbins))\n    print(\"Count of instances per bin: {}\".format(counts))\n    return groups\n</code></pre>"},{"location":"detection/program/train/#_5","title":"\u8ba1\u7b97\u5bbd\u9ad8\u6bd4\u4f8b","text":"<pre><code>def compute_aspect_ratios(dataset, indices=None):\n    # hasattr\u51fd\u6570\u7528\u4e8e\u5224\u65ad\u5bf9\u8c61\u662f\u5426\u5305\u542b\u5bf9\u5e94\u7684\u5c5e\u6027\uff0c\u4e3b\u8981\u7528\u5230\u8fd9\u4e2a\u5206\u652f\n    if hasattr(dataset, \"get_height_and_width\"):\n        return _compute_aspect_ratios_custom_dataset(dataset, indices)\n\ndef _compute_aspect_ratios_custom_dataset(dataset, indices=None):\n    if indices is None:\n        indices = range(len(dataset))\n    # \u521d\u59cb\u5316\u50a8\u5b58\u5bbd\u9ad8\u6bd4\u4f8b\u7684\u53d8\u91cf\n    aspect_ratios = []\n    # \u904d\u5386\u6240\u6709\u56fe\u7247\n    for i in indices:\n        # \u5229\u7528\u5b9a\u4e49\u597d\u7684get_height_and_width\u6765\u83b7\u53d6\u56fe\u7247\u9ad8\u3001\u5bbd\n        height, width = dataset.get_height_and_width(i)\n        # \u8ba1\u7b97\u6bd4\u4f8b\n        aspect_ratio = float(width) / float(height)\n        aspect_ratios.append(aspect_ratio)\n    # \u8fd4\u56de\u5f97\u5230\u7684\u6bd4\u4f8b\n    return aspect_ratios\n</code></pre> <p>\u5f97\u5230\u56fe\u7247\u5c3a\u5bf8</p> <pre><code># \u8ba1\u7b97\u56fe\u7247\u9ad8\u5bbd\uff0c\u7528\u4e8e\u540e\u7eed\u8ba1\u7b97\u56fe\u7247\u9ad8\u5bbd\u6bd4\u4f8b\uff0c\u9488\u5bf9\u6bd4\u4f8b\u6765\u91c7\u6837\u8fdb\u884c\u8bad\u7ec3\ndef get_height_and_width(self, idx):\n    # \u8bfb\u53d6xml\u6587\u4ef6\n    xml_path = self.xml_list[idx]\n    with open(xml_path) as fid:\n        xml_str = fid.read()\n    xml = etree.fromstring(xml_str)\n    # \u8f6c\u5316\u4e3a\u5b57\u5178\u683c\u5f0f\n    data = self.parse_xml_to_dict(xml)[\"annotation\"]\n    # \u76f4\u63a5\u8bfb\u53d6size\u4e2d\u7684\u9ad8\u3001\u5bbd\u6570\u503c\n    data_height = int(data[\"size\"][\"height\"])\n    data_width = int(data[\"size\"][\"width\"])\n    # \u4f9d\u6b21\u8fd4\u56de\u9ad8\u3001\u5bbd\n    return data_height, data_width\n</code></pre>"},{"location":"detection/program/train/#_6","title":"\u5206\u7ec4","text":"<p>\u6309\u56fe\u7247\u5bbd\u9ad8\u6bd4\u4f8b\u4e0e\u533a\u95f4\u8282\u70b9\u5206\u7ec4</p> <pre><code>def _quantize(x, bins):\n    bins = copy.deepcopy(bins)\n    # \u5c06\u5212\u5206\u533a\u95f4\u7684\u70b9\u8fdb\u884c\u6392\u5e8f\n    bins = sorted(bins)\n    # bisect_right\uff1a\u5bfb\u627ey\u5143\u7d20\u6309\u987a\u5e8f\u5e94\u8be5\u6392\u5728bins\u4e2d\u54ea\u4e2a\u5143\u7d20\u7684\u53f3\u8fb9\uff0c\u8fd4\u56de\u7684\u662f\u533a\u95f4\u7d22\u5f15\n    # \u8fd9\u91cc\u76f8\u5f53\u4e8e\u505a\u4e86\u4e00\u4e2a\u904d\u5386\uff0c\u904d\u5386x\u4e2d\u7684\u6240\u6709\u5143\u7d20\uff0c\u5f97\u5230\u6bcf\u4e2ax\u5e94\u8be5\u4f4d\u4e8e\u54ea\u4e2a\u533a\u95f4\n    quantized = list(map(lambda y: bisect.bisect_right(bins, y), x))\n    return quantized\n</code></pre>"},{"location":"detection/program/train/#_7","title":"\u8bad\u7ec3\u8fc7\u7a0b","text":"<pre><code>def main(parser_data):\n    # \u5982\u679c\u663e\u5361\u53ef\u7528\uff0c\u5219\u4f7f\u7528GPU\u8bad\u7ec3\uff0c\u5426\u5219\u4f7f\u7528CPU\u8bad\u7ec3\n    device = torch.device(parser_data.device if torch.cuda.is_available() else \"cpu\")\n    print(\"Using {} device training.\".format(device.type))\n\n    # \u7528\u6765\u4fdd\u5b58\u8bad\u7ec3\u65e5\u5fd7\n    results_file = \"results{}.txt\".format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n    # \u6570\u636e\u9884\u5904\u7406\u64cd\u4f5c\uff0c\u8bad\u7ec3\u9636\u6bb5\u591a\u4e00\u4e2a\u968f\u673a\u6c34\u5e73\u7ffb\u8f6c\u64cd\u4f5c\n    data_transform = {\n        \"train\": transforms.Compose([transforms.ToTensor(),\n                                     transforms.RandomHorizontalFlip(0.5)]),\n        \"val\": transforms.Compose([transforms.ToTensor()])\n    }\n    # \u6570\u636e\u6839\u76ee\u5f55\n    VOC_root = parser_data.data_path\n    # \u68c0\u67e5\u8be5\u76ee\u5f55\u662f\u5426\u5b58\u5728\n    if os.path.exists(os.path.join(VOC_root, \"VOCdevkit\")) is False:\n        raise FileNotFoundError(\"VOCdevkit dose not in path:'{}'.\".format(VOC_root))\n\n    # \u52a0\u8f7d\u6570\u636e\u96c6\n    # VOCdevkit -&gt; VOC2012 -&gt; ImageSets -&gt; Main -&gt; train.txt\n    train_dataset = VOCDataSet(VOC_root, \"2012\", data_transform[\"train\"], \"train.txt\")\n    train_sampler = None\n\n    # \u662f\u5426\u6309\u56fe\u7247\u76f8\u4f3c\u9ad8\u5bbd\u6bd4\u91c7\u6837\u56fe\u7247\u7ec4\u6210batch\n    # \u4f7f\u7528\u7684\u8bdd\u80fd\u591f\u51cf\u5c0f\u8bad\u7ec3\u65f6\u6240\u9700GPU\u663e\u5b58\uff0c\u9ed8\u8ba4\u4f7f\u7528\n    if args.aspect_ratio_group_factor &gt;= 0:\n        # \u5148\u521d\u59cb\u5316\u4e00\u4e2a\u968f\u673a\u7684\u91c7\u6837\u5668\n        train_sampler = torch.utils.data.RandomSampler(train_dataset)\n        # \u7edf\u8ba1\u6240\u6709\u56fe\u50cf\u9ad8\u5bbd\u6bd4\u4f8b\u5728bins\u533a\u95f4\u4e2d\u7684\u4f4d\u7f6e\u7d22\u5f15\n        # args.aspect_ratio_group_factor\u9ed8\u8ba4\u4e3a3\uff0c\u8868\u793a\u5c06\u56fe\u50cf\u6570\u636e\u7684\u9ad8\u5bbd\u6bd4\u4f8b\u5212\u5206\u62102(k+1)\u4e2a\u533a\u95f4\n        group_ids = create_aspect_ratio_groups(train_dataset, k=args.aspect_ratio_group_factor)\n        # \u6bcf\u6279batch\u5728\u91c7\u6837\u56fe\u7247\u65f6\uff0c\u5747\u4ece\u540c\u4e00\u9ad8\u5bbd\u6bd4\u4f8b\u7684\u533a\u95f4\u4e2d\u91c7\u6837\n        train_batch_sampler = GroupedBatchSampler(train_sampler, group_ids, args.batch_size)\n\n    # batch size\n    batch_size = parser_data.batch_size\n    # \u5f97\u5230cpu\u7ebf\u7a0b\uff0c\u6ce8\u610f\u8fd9\u91cc\u7684\u7ebf\u7a0b\u6570\u91cf\u5fc5\u987b\u5c0f\u4e8e\u7b49\u4e8ebatch size\u7684\u5927\u5c0f\n    nw = min([os.cpu_count(), batch_size if batch_size &gt; 1 else 0, 8])  # number of workers\n    print('Using %g dataloader workers' % nw)\n    if train_sampler:\n        # \u5982\u679c\u6309\u7167\u56fe\u7247\u9ad8\u5bbd\u6bd4\u91c7\u6837\u56fe\u7247\uff0cdataloader\u4e2d\u9700\u8981\u4f7f\u7528batch_sampler\uff0c\u5373\u4e4b\u524d\u5b9a\u4e49\u597d\u7684\u91c7\u6837\u7b56\u7565\n        # \u6ce8\u610f\u8fd9\u91cc\u7684collate_fn\u662f\u81ea\u5b9a\u4e49\u7684\uff0c\u56e0\u4e3a\u8bfb\u53d6\u7684\u6570\u636e\u5305\u62ecimage\u548ctargets\uff0c\u4e0d\u80fd\u76f4\u63a5\u4f7f\u7528\u9ed8\u8ba4\u7684\u65b9\u6cd5\u5408\u6210batch\n        train_data_loader = torch.utils.data.DataLoader(train_dataset,\n                                                        batch_sampler=train_batch_sampler,\n                                                        pin_memory=True,\n                                                        num_workers=nw,\n                                                        collate_fn=train_dataset.collate_fn)\n    else:\n        # \u5982\u679c\u4e0d\u6309\u957f\u5bbd\u6bd4\u4f8b\u76f8\u4f3c\u5ea6\u91c7\u6837\u7684\u8bdd\uff0c\u5219\u9ed8\u8ba4\u4f7f\u7528\u968f\u673a\u91c7\u6837\u7b56\u7565\n        train_data_loader = torch.utils.data.DataLoader(train_dataset,\n                                                        batch_size=batch_size,\n                                                        shuffle=True,\n                                                        pin_memory=True,\n                                                        num_workers=nw,\n                                                        collate_fn=train_dataset.collate_fn)\n\n    # \u52a0\u8f7d\u6d4b\u8bd5\u6570\u636e\n    # VOCdevkit -&gt; VOC2012 -&gt; ImageSets -&gt; Main -&gt; val.txt\n    val_dataset = VOCDataSet(VOC_root, \"2012\", data_transform[\"val\"], \"val.txt\")\n    # \u52a0\u8f7d\u6d4b\u8bd5\u6570\u636e\u7531\u4e8e\u662f\u4e00\u5f20\u4e00\u5f20\u8fdb\u884c\u6d4b\u8bd5\uff0c\u56e0\u6b64\u4e0d\u9700\u8981\u4fee\u6539\u91c7\u6837\u7b56\u7565\n    val_data_set_loader = torch.utils.data.DataLoader(val_dataset,\n                                                      batch_size=1,\n                                                      shuffle=False,\n                                                      pin_memory=True,\n                                                      num_workers=nw,\n                                                      collate_fn=val_dataset.collate_fn)\n\n    # \u521b\u5efa\u6a21\u578b\uff0c\u6ce8\u610f\u8fd9\u91cc\u5206\u7c7b\u6570\u8981+1\uff0c\u5e8f\u53f7\u4e3a0\u65f6\u8868\u793a\u80cc\u666f\n    model = create_model(num_classes=parser_data.num_classes + 1)\n    # \u5c06\u6a21\u578b\u653e\u5165\u7279\u5b9a\u7684\u50a8\u5b58\u8bbe\u5907\n    model.to(device)\n\n    # \u5b9a\u4e49\u4f18\u5316\u5668\n    params = [p for p in model.parameters() if p.requires_grad]\n    optimizer = torch.optim.SGD(params, lr=0.005,\n                                momentum=0.9, weight_decay=0.0005)\n    # \u68af\u5ea6\u7f29\u653e\uff0c\u9632\u6b62\u51fa\u73b0\u68af\u5ea6\u4e0b\u6ea2\u7684\u73b0\u8c61\uff0c\u7531\u4e8e\u5b58\u50a8\u5c0f\u6570\u70b9\u7684\u4f4d\u6570\u6709\u9650\uff0c\u5982\u679c\u68af\u5ea6\u8fc7\u5c0f\u5219\u5bb9\u6613\u56db\u820d\u4e94\u5165\u5f97\u52300\n    # \u8fd9\u91cc\u5c31\u5bf9\u6bcf\u4e2a\u68af\u5ea6\u4e58\u4e0a\u4e00\u4e2a\u7f29\u653e\u56e0\u5b50\uff0c\u653e\u5927\u68af\u5ea6\u4ece\u800c\u9632\u6b62\u4e0b\u6ea2\uff0c\u9ed8\u8ba4\u4e0d\u7528\u68af\u5ea6\u7f29\u653e\n    scaler = torch.cuda.amp.GradScaler() if args.amp else None\n\n    # \u5b66\u4e60\u7387\u8870\u51cf\u7b56\u7565\n    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n                                                   step_size=3,\n                                                   gamma=0.33)\n\n    # \u5982\u679c\u6307\u5b9a\u4e86\u4e0a\u6b21\u8bad\u7ec3\u4fdd\u5b58\u7684\u6743\u91cd\u6587\u4ef6\u5730\u5740\uff0c\u5219\u63a5\u7740\u4e0a\u6b21\u7ed3\u679c\u63a5\u7740\u8bad\u7ec3\n    if parser_data.resume != \"\":\n        # \u52a0\u8f7d\u6a21\u578b\u53c2\u6570\u3001\u4f18\u5316\u5668\u7b49\u53c2\u6570\n        checkpoint = torch.load(parser_data.resume, map_location='cpu')\n        model.load_state_dict(checkpoint['model'])\n        optimizer.load_state_dict(checkpoint['optimizer'])\n        lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n        parser_data.start_epoch = checkpoint['epoch'] + 1\n        if args.amp and \"scaler\" in checkpoint:\n            scaler.load_state_dict(checkpoint[\"scaler\"])\n        print(\"the training process from epoch{}...\".format(parser_data.start_epoch))\n\n    train_loss = []\n    learning_rate = []\n    val_map = []\n    # \u5f00\u59cb\u904d\u5386\u6570\u636e\uff0c\u8fdb\u884c\u8bad\u7ec3\n    for epoch in range(parser_data.start_epoch, parser_data.epochs):\n        # \u8bad\u7ec3\u4e00\u4e2aepoch\n        # \u8fd4\u56de\u5e73\u5747\u635f\u5931\u548c\u5f53\u524d\u7684\u5b66\u4e60\u7387\n        mean_loss, lr = utils.train_one_epoch(model, optimizer, train_data_loader,\n                                              device=device, epoch=epoch,\n                                              print_freq=50, warmup=True,\n                                              scaler=scaler)\n        # \u8bb0\u5f55\u8bad\u7ec3\u635f\u5931\n        train_loss.append(mean_loss.item())\n        # \u8bb0\u5f55\u5b66\u4e60\u7387\n        learning_rate.append(lr)\n        # \u66f4\u65b0\u5b66\u4e60\u7387(\u8fd9\u91cc\u4e0e\u5b66\u4e60\u7387\u4e0b\u964d\u7b56\u7565\u6709\u5173)\n        lr_scheduler.step()\n        # \u6d4b\u8bd5\u6a21\u578b\n        coco_info = utils.evaluate(model, val_data_set_loader, device=device)\n\n        # \u5c06\u8bad\u7ec3\u65e5\u5fd7\u5199\u5165txt\u6587\u4ef6\n        with open(results_file, \"a\") as f:\n            # \u5199\u5165\u7684\u6570\u636e\u5305\u62eccoco\u6307\u6807\u8fd8\u6709loss\u548clearning rate\n            result_info = [str(round(i, 4)) for i in coco_info + [mean_loss.item()]] + [str(round(lr, 6))]\n            txt = \"epoch:{} {}\".format(epoch, '  '.join(result_info))\n            f.write(txt + \"\\n\")\n        # \u66f4\u65b0\u6a21\u578bmAP\u6570\u636e\n        val_map.append(coco_info[1])  # pascal mAP\n\n        # save weights\uff0c\u4fdd\u5b58\u5404\u79cd\u6743\u91cd\u53c2\u6570\uff0c\u6a21\u578b\u3001\u4f18\u5316\u5668\u3001\u5b66\u4e60\u7387\n        save_files = {\n            'model': model.state_dict(),\n            'optimizer': optimizer.state_dict(),\n            'lr_scheduler': lr_scheduler.state_dict(),\n            'epoch': epoch}\n        if args.amp:\n            save_files[\"scaler\"] = scaler.state_dict()\n        torch.save(save_files, \"./save_weights/resNetFpn-model-{}.pth\".format(epoch))\n\n    # \u635f\u5931\u3001\u5b66\u4e60\u7387\u6298\u7ebf\u56fe\n    if len(train_loss) != 0 and len(learning_rate) != 0:\n        from plot_curve import plot_loss_and_lr\n        plot_loss_and_lr(train_loss, learning_rate)\n\n    # mAP\u6298\u7ebf\u56fe\n    if len(val_map) != 0:\n        from plot_curve import plot_map\n        plot_map(val_map)\n</code></pre> <p>\u52a0\u8f7d\u6a21\u578b\uff1a</p> <pre><code>def create_model(num_classes):\n    # \u6ce8\u610f\uff0c\u8fd9\u91cc\u7684backbone\u9ed8\u8ba4\u4f7f\u7528\u7684\u662fFrozenBatchNorm2d\uff0c\u5373\u4e0d\u4f1a\u53bb\u66f4\u65b0bn\u53c2\u6570\n    # \u76ee\u7684\u662f\u4e3a\u4e86\u9632\u6b62batch_size\u592a\u5c0f\u5bfc\u81f4\u6548\u679c\u66f4\u5dee(\u5982\u679c\u663e\u5b58\u5f88\u5c0f\uff0c\u5efa\u8bae\u4f7f\u7528\u9ed8\u8ba4\u7684FrozenBatchNorm2d)\n    # \u5982\u679cGPU\u663e\u5b58\u5f88\u5927\u53ef\u4ee5\u8bbe\u7f6e\u6bd4\u8f83\u5927\u7684batch_size\u5c31\u53ef\u4ee5\u5c06norm_layer\u8bbe\u7f6e\u4e3a\u666e\u901a\u7684BatchNorm2d\n    # trainable_layers\u5305\u62ec['layer4', 'layer3', 'layer2', 'layer1', 'conv1']\n    # \u8fd9\u91cc3\u8868\u793a\u53ea\u8bad\u7ec3\u540e\u4e09\u4e2a\u9636\u6bb5\u7684\u53c2\u6570['layer4', 'layer3', 'layer2']\uff0c5\u4ee3\u8868\u5168\u90e8\u8bad\u7ec3\n    backbone = resnet50_fpn_backbone(norm_layer=torch.nn.BatchNorm2d,\n                                     trainable_layers=3)\n    # \u8bad\u7ec3\u81ea\u5df1\u6570\u636e\u96c6\u65f6\u4e0d\u8981\u4fee\u6539\u8fd9\u91cc\u768491\uff0c\u4fee\u6539\u7684\u662f\u4f20\u5165\u7684num_classes\u53c2\u6570\n    # \u56e0\u4e3a\u8981\u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u56e0\u6b64\u9700\u8981\u521d\u59cb\u5316\u6307\u5b9a\u7c7b\u522b\u6570\u91cf\u7684\u6a21\u578b\n    model = FasterRCNN(backbone=backbone, num_classes=91)\n\n    # \u8f7d\u5165\u9884\u8bad\u7ec3\u6a21\u578b\u6743\u91cd\uff0c\u6743\u91cd\u4e0b\u8f7d\u5730\u5740:\n    # https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n    weights_dict = torch.load(\"./backbone/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\", map_location='cpu')\n    # \u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\n    missing_keys, unexpected_keys = model.load_state_dict(weights_dict, strict=False)\n    if len(missing_keys) != 0 or len(unexpected_keys) != 0:\n        print(\"missing_keys: \", missing_keys)\n        print(\"unexpected_keys: \", unexpected_keys)\n    # \u4e4b\u540e\u4fee\u6539roi_head\u4e2d\u7684\u68c0\u6d4b\u5934\uff0c\u4e3b\u8981\u66ff\u6362\u5206\u7c7b\u6a21\u5757\uff0c\u66ff\u6362\u4e3a\u6307\u5b9a\u7684\u7c7b\u522b\u53c2\u6570\n    # \u5f97\u5230\u5206\u7c7b\u6a21\u5757\u8f93\u5165\u7684\u901a\u9053\u6570\u91cf\n    in_features = model.roi_heads.box_predictor.cls_score.in_features\n    # \u66ff\u6362roi_head\u4e2d\u7684\u5206\u7c7b\u6a21\u5757\n    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n    # \u8fd4\u56de\u5b9a\u4e49\u597d\u7684\u6a21\u578b\n    return model\n</code></pre>"},{"location":"detection/program/train/#epoch","title":"\u8bad\u7ec3\u5355\u4e2aepoch","text":"<pre><code># \u8bad\u7ec3\u4e00\u4e2aepoch\ndef train_one_epoch(model, optimizer, data_loader, device, epoch,\n                    print_freq=50, warmup=False, scaler=None):\n    # \u6a21\u578b\u6539\u4e3a\u8bad\u7ec3\u6a21\u5f0f\n    model.train()\n    # \u65e5\u5fd7\n    metric_logger = utils.MetricLogger(delimiter=\"  \")\n    metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value:.6f}'))\n    header = 'Epoch: [{}]'.format(epoch)\n\n    lr_scheduler = None\n    # \u5f53\u8bad\u7ec3\u7b2c\u4e00\u8f6e\uff08epoch=0\uff09\u65f6\uff0c\u542f\u7528warmup\u8bad\u7ec3\u65b9\u5f0f\uff0c\u53ef\u7406\u89e3\u4e3a\u70ed\u8eab\u8bad\u7ec3\n    if epoch == 0 and warmup is True:  \n        warmup_factor = 1.0 / 1000\n        warmup_iters = min(1000, len(data_loader) - 1)\n\n        lr_scheduler = utils.warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor)\n\n    mloss = torch.zeros(1).to(device)  # mean losses\n    for i, [images, targets] in enumerate(metric_logger.log_every(data_loader, print_freq, header)):\n        # \u5c06\u56fe\u7247\u548c\u6807\u7b7e\u653e\u5165\u6307\u5b9a\u7684\u5b58\u50a8\u8bbe\u5907(cpu or gpu)\uff0c\u4e4b\u540e\u8f6c\u5316\u4e3a\u5217\u8868\u683c\u5f0f\n        images = list(image.to(device) for image in images)  \n        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n        # \u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\u4e0a\u4e0b\u6587\u7ba1\u7406\u5668\uff0c\u5982\u679c\u5728CPU\u73af\u5883\u4e2d\u4e0d\u8d77\u4efb\u4f55\u4f5c\u7528\n        with torch.cuda.amp.autocast(enabled=scaler is not None):\n            # \u5f97\u5230\u6a21\u578b\u635f\u5931\n            loss_dict = model(images, targets)\n            # \u6240\u6709\u6a21\u5757\u7684\u635f\u5931\u6c42\u548c\n            losses = sum(loss for loss in loss_dict.values())  \n\n        # reduce losses over all GPUs for logging purpose\n        # \u591a\u5361\u8bad\u7ec3\u65f6\u8fd9\u4e00\u884c\u6709\u7528\n        loss_dict_reduced = utils.reduce_dict(loss_dict)\n        losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n        # \u63d0\u53d6\u635f\u5931\u6570\u503c\n        loss_value = losses_reduced.item()\n        # \u8bb0\u5f55\u8bad\u7ec3\u635f\u5931\n        mloss = (mloss * i + loss_value) / (i + 1)  # update mean losses\n        # \u5f53\u8ba1\u7b97\u7684\u635f\u5931\u4e3a\u65e0\u7a77\u5927\u65f6\u505c\u6b62\u8bad\u7ec3\n        if not math.isfinite(loss_value):\n            print(\"Loss is {}, stopping training\".format(loss_value))\n            print(loss_dict_reduced)\n            sys.exit(1)\n\n        optimizer.zero_grad()\n        # \u5982\u679c\u6709\u68af\u5ea6\u7f29\u653e\u64cd\u4f5c\u7684\u8bdd\uff0c\u5c31\u8d70\u8fd9\u4e00\u6b65\n        if scaler is not None:\n            scaler.scale(losses).backward()\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            # \u53cd\u5411\u4f20\u64ad\uff0c\u66f4\u65b0\u53c2\u6570\n            losses.backward()\n            optimizer.step()\n        # \u7b2c\u4e00\u8f6e\u4f7f\u7528warmup\u8bad\u7ec3\u65b9\u5f0f\n        if lr_scheduler is not None:\n            lr_scheduler.step()\n\n        metric_logger.update(loss=losses_reduced, **loss_dict_reduced)\n        now_lr = optimizer.param_groups[0][\"lr\"]\n        metric_logger.update(lr=now_lr)\n    # \u8fd4\u56de\u5e73\u5747\u635f\u5931\u548c\u5f53\u524d\u7684\u5b66\u4e60\u7387\n    return mloss, now_lr\n</code></pre> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e742\u670816\u65e5</p>"},{"location":"detection/program/data_augment/affine/","title":"\u6570\u636e\u589e\u5f3a\u2014\u2014\u4eff\u5c04\u53d8\u6362","text":""},{"location":"detection/program/data_augment/affine/#_2","title":"\u4ecb\u7ecd","text":"<p>\u2003\u2003\u5e38\u7528\u4e8e\u56fe\u50cf\u7684\u6570\u636e\u589e\u5e7f\uff0c\u6269\u5145\u8bad\u7ec3\u6570\u636e\uff0c\u5305\u62ec\uff1a\u65cb\u8f6c\u3001\u5e73\u79fb\u3001\u7f29\u653e\u3001\u9519\u5207\u3002</p> <p>\u6548\u679c\u56fe</p> <p> <p></p> <p></p>"},{"location":"detection/program/data_augment/affine/#_3","title":"\u4ee3\u7801\u5b9e\u73b0","text":"<p>\u53c2\u8003\u94fe\u63a5\uff1a</p> <ul> <li>https://github.com/WZMIAOMIAO/deep-learning-for-image-processing/tree/master/pytorch_object_detection/yolov3_spp</li> <li>https://github.com/ultralytics/yolov3</li> </ul> <p>\u6ce8\uff1a</p> <ul> <li> <p>\u8fd9\u91cc\u7684\u4eff\u5c04\u53d8\u6362\u4e0d\u4ec5\u53ef\u4ee5\u5bf9\u56fe\u7247\u505a\u53d8\u5316\uff0c\u4e5f\u53ef\u4ee5\u5bf9\u76f8\u5e94\u7684\u8fb9\u754c\u6846\u5750\u6807\u505a\u53d8\u6362\uff0c\u5982\u679c\u4ec5\u5bf9\u56fe\u7247\u505a\u53d8\u6362\u7684\u8bdd\uff0c\u53ef\u4ee5\u5229\u7528<code>torchvision.transforms.RandomAffine</code>\u51fd\u6570\u5b9e\u73b0\uff1b</p> </li> <li> <p>\u4f20\u5165\u56fe\u50cf\u548c\u6807\u7b7e\u6570\u636e\uff0c\u683c\u5f0f\u5747\u4e3a<code>ndarray</code>\uff0c\u6807\u7b7e<code>targets</code>\u5c3a\u5bf8\u4e3a(n,5)\uff0cn\u8868\u793a\u7269\u4f53\u6570\u91cf\uff0c5\u8868\u793a\u7c7b\u522b\u52a0\u56db\u4e2a\u5750\u6807\u6570\u636e\uff1b</p> </li> <li> <p>\u8fd9\u91cc\u7684<code>targets</code>\u662f\u76f8\u5bf9\u4e8e\u539f\u56fe\u7684\u7edd\u5bf9\u5750\u6807\uff0c\u5e76\u4e14\u5750\u6807\u683c\u5f0f\u4e3a\u2019xyxy\u2018\u3002</p> </li> </ul> <pre><code>def random_affine(img, targets=(), degrees=10, translate=.1, scale=.1, shear=10, border=0):\n    \"\"\"\u968f\u673a\u65cb\u8f6c\uff0c\u7f29\u653e\uff0c\u5e73\u79fb\u4ee5\u53ca\u9519\u5207\"\"\"\n    # torchvision.transforms.RandomAffine(degrees=(-10, 10), translate=(.1, .1), scale=(.9, 1.1), shear=(-10, 10))\n    # https://medium.com/uruvideo/dataset-augmentation-with-random-homographies-a8f4b44830d4\n    # \u8fd9\u91cc\u53ef\u4ee5\u53c2\u8003\u535a\u6587: https://blog.csdn.net/qq_37541097/article/details/119420860\n    # targets = [cls, xyxy]\n\n    # \u6700\u7ec8\u8f93\u51fa\u7684\u56fe\u50cf\u5c3a\u5bf8\uff0c\u7b49\u4e8eimg4.shape / 2\n    height = img.shape[0] + border * 2\n    width = img.shape[1] + border * 2\n\n    # Rotation and Scale\n    # \u751f\u6210\u65cb\u8f6c\u4ee5\u53ca\u7f29\u653e\u77e9\u9635\n    R = np.eye(3)  # \u751f\u6210\u5bf9\u89d2\u9635\n    a = random.uniform(-degrees, degrees)  # \u968f\u673a\u65cb\u8f6c\u89d2\u5ea6\n    s = random.uniform(1 - scale, 1 + scale)  # \u968f\u673a\u7f29\u653e\u56e0\u5b50\n    R[:2] = cv2.getRotationMatrix2D(angle=a, center=(img.shape[1] / 2, img.shape[0] / 2), scale=s)\n\n    # Translation\n    # \u751f\u6210\u5e73\u79fb\u77e9\u9635\n    T = np.eye(3)\n    T[0, 2] = random.uniform(-translate, translate) * img.shape[0] + border  # x translation (pixels)\n    T[1, 2] = random.uniform(-translate, translate) * img.shape[1] + border  # y translation (pixels)\n\n    # Shear\n    # \u751f\u6210\u9519\u5207\u77e9\u9635\n    S = np.eye(3)\n    S[0, 1] = math.tan(random.uniform(-shear, shear) * math.pi / 180)  # x shear (deg)\n    S[1, 0] = math.tan(random.uniform(-shear, shear) * math.pi / 180)  # y shear (deg)\n\n    # Combined rotation matrix\n    M = S @ T @ R  # ORDER IS IMPORTANT HERE!!\n    if (border != 0) or (M != np.eye(3)).any():  # image changed\n        # \u8fdb\u884c\u4eff\u5c04\u53d8\u5316\n        img = cv2.warpAffine(img, M[:2], dsize=(width, height), flags=cv2.INTER_LINEAR, borderValue=(114, 114, 114))\n\n    # Transform label coordinates\n    n = len(targets)\n    if n:\n        # warp points\n        xy = np.ones((n * 4, 3))\n        xy[:, :2] = targets[:, [1, 2, 3, 4, 1, 4, 3, 2]].reshape(n * 4, 2)  # x1y1, x2y2, x1y2, x2y1\n        # [4*n, 3] -&gt; [n, 8]\n        xy = (xy @ M.T)[:, :2].reshape(n, 8)\n\n        # create new boxes\n        # \u5bf9transform\u540e\u7684bbox\u8fdb\u884c\u4fee\u6b63(\u5047\u8bbe\u53d8\u6362\u540e\u7684bbox\u53d8\u6210\u4e86\u83f1\u5f62\uff0c\u6b64\u65f6\u8981\u4fee\u6b63\u6210\u77e9\u5f62)\n        x = xy[:, [0, 2, 4, 6]]  # [n, 4]\n        y = xy[:, [1, 3, 5, 7]]  # [n, 4]\n        xy = np.concatenate((x.min(1), y.min(1), x.max(1), y.max(1))).reshape(4, n).T  # [n, 4]\n\n        # reject warped points outside of image\n        # \u5bf9\u5750\u6807\u8fdb\u884c\u88c1\u526a\uff0c\u9632\u6b62\u8d8a\u754c\n        xy[:, [0, 2]] = xy[:, [0, 2]].clip(0, width)\n        xy[:, [1, 3]] = xy[:, [1, 3]].clip(0, height)\n        w = xy[:, 2] - xy[:, 0]\n        h = xy[:, 3] - xy[:, 1]\n\n        # \u8ba1\u7b97\u8c03\u6574\u540e\u7684\u6bcf\u4e2abox\u7684\u9762\u79ef\n        area = w * h\n        # \u8ba1\u7b97\u8c03\u6574\u524d\u7684\u6bcf\u4e2abox\u7684\u9762\u79ef\n        area0 = (targets[:, 3] - targets[:, 1]) * (targets[:, 4] - targets[:, 2])\n        # \u8ba1\u7b97\u6bcf\u4e2abox\u7684\u6bd4\u4f8b\n        ar = np.maximum(w / (h + 1e-16), h / (w + 1e-16))  # aspect ratio\n        # \u9009\u53d6\u957f\u5bbd\u5927\u4e8e4\u4e2a\u50cf\u7d20\uff0c\u4e14\u8c03\u6574\u524d\u540e\u9762\u79ef\u6bd4\u4f8b\u5927\u4e8e0.2\uff0c\u4e14\u6bd4\u4f8b\u5c0f\u4e8e10\u7684box\n        i = (w &gt; 4) &amp; (h &gt; 4) &amp; (area / (area0 * s + 1e-16) &gt; 0.2) &amp; (ar &lt; 10)\n\n        targets = targets[i]\n        targets[:, 1:5] = xy[i]\n\n    return img, targets\n</code></pre> <p>\u521d\u6b65\u5b8c\u7a3f\u4e8e2023\u5e742\u670814\u65e5</p>"},{"location":"detection/program/data_augment/mosaic/","title":"\u6570\u636e\u589e\u5f3a\u2014\u2014mosaic\u589e\u5f3a","text":""},{"location":"detection/program/data_augment/mosaic/#_1","title":"\u4ecb\u7ecd","text":"<p>\u2003\u2003\u5c06\u56db\u5f20\u56fe\u7247\u4ee5\u968f\u673a\u7f29\u653e\u3001\u968f\u673a\u88c1\u51cf\u3001\u968f\u673a\u6392\u5e03\u7684\u65b9\u5f0f\u62fc\u63a5\u5728\u4e00\u8d77\uff0c\u7ec4\u6210\u4e00\u5f20\u56fe\u7247\u3002</p> <p>\u4f18\u70b9\uff1a</p> <ul> <li>\u589e\u52a0\u4e86\u56fe\u7247\u6570\u636e\u7684\u591a\u6837\u6027\uff0c\u4e30\u5bcc\u4e86\u80cc\u666f\u4fe1\u606f\uff1b</li> <li>\u589e\u52a0\u4e86\u56fe\u7247\u4e2d\u76ee\u6807\u7684\u4e2a\u6570\uff1b</li> <li>\u95f4\u63a5\u63d0\u9ad8\u4e86batch\u6570\u91cf\uff0c\u6709\u5229\u4e8e\u5728BN\u8fd0\u7b97\u65f6\u66f4\u597d\u5730\u7edf\u8ba1\u5168\u5c40\u7684\u5747\u503c\u65b9\u5dee\u3002</li> </ul> <p> <p></p> <p></p> <p>\u6b65\u9aa4\uff1a</p> <ul> <li>\u9996\u5148\u5c06\u6bcf\u5f20\u56fe\u50cf\u4f9d\u6b21\u7b49\u6bd4\u7f29\u653e\uff0c\u5c06\u5bbd\u3001\u9ad8\u4e2d\u8f83\u5927\u7684\u6570\u503c\u653e\u5927\u5230\u9884\u8bbe\u7684\u5c3a\u5bf8\uff1b</li> <li>\u751f\u6210\u4e00\u5f20mosaic\u56fe\u50cf\uff0c\u5c3a\u5bf8\u4e3a\u9884\u8bbe\u5c3a\u5bf8\u76842\u500d\uff0c\u5e76\u4e14\u968f\u673a\u5728mosaic\u56fe\u50cf\u4e2d\u5fc3\u9644\u8fd1\u751f\u6210\u62fc\u63a5\u4e2d\u5fc3\u70b9\uff08\u56db\u5f20\u56fe\u7247\u7684\u516c\u5171\u4ea4\u70b9\uff09\uff1b</li> <li>\u6839\u636e\u62fc\u63a5\u4e2d\u5fc3\u70b9\u4f9d\u6b21\u505a\u62fc\u63a5\u64cd\u4f5c\uff0c\u5220\u9664\u8d8a\u754c\u7684\u56fe\u50cf\u6570\u636e\uff1b</li> <li>\u6839\u636e\u62fc\u63a5\u4e2d\u5fc3\u4f9d\u6b21\u5bf9\u6bcf\u4e2a\u56fe\u7247\u7684\u8fb9\u754c\u6846\u6807\u7b7e\u505a\u8c03\u6574\uff0c\u6700\u540e\u5408\u5e76\u6210\u4e00\u5f20\u56fe\u7684\u6807\u7b7e\u3002</li> </ul> <p>\u6ce8\uff1a</p> <ul> <li>\u5f15\u5165mosaic\u589e\u5f3a\u540e\uff0c\u8f93\u51fa\u56fe\u50cf\u7684\u5c3a\u5bf8\u5df2\u88ab\u89c4\u5b9a\u597d\uff0c\u7edf\u4e00\u4e86\u56fe\u50cf\u6570\u636e\u7684\u5c3a\u5bf8\u5927\u5c0f\uff0c\u540c\u4e00\u6279\u6b21\u4e0b\u7684\u6570\u636e\u53ef\u4ee5\u76f4\u63a5\u6267\u884c\u6253\u5305\u5904\u7406\uff0c\u4e0d\u7528\u518d\u4ecebatch\u5185\u90e8\u6267\u884c\u4e00\u6b21\u653e\u7f29\uff08\u5982\uff1aFaster R-CNN\u6e90\u7801\u4e2d\u7684\u64cd\u4f5c\uff09\uff1b</li> <li>mosaic\u589e\u5f3a\u53ea\u7528\u4e8e\u8bad\u7ec3\u9636\u6bb5\uff0c\u6d4b\u8bd5\u9636\u6bb5\u4e0d\u9700\u8981\u589e\u5f3a\uff0c\u53ea\u9700\u8981\u5c06\u56fe\u7247\u653e\u5927\u81f3\u9876\u5c42\u7279\u5f81\u56fe\u611f\u53d7\u91ce\u7684\u6574\u6570\u500d\uff0c\u9632\u6b62\u4e0b\u91c7\u6837\u8fc7\u7a0b\u4e2d\u4e22\u5931\u6570\u636e\uff0c\u53ef\u4ee5\u75280\u586b\u5145\u3002</li> </ul>"},{"location":"detection/program/data_augment/mosaic/#_2","title":"\u4ee3\u7801\u5b9e\u73b0","text":"<p>\u53c2\u8003\u94fe\u63a5\uff1a</p> <ul> <li>https://github.com/WZMIAOMIAO/deep-learning-for-image-processing/tree/master/pytorch_object_detection/yolov3_spp</li> <li>https://github.com/ultralytics/yolov3</li> </ul> <p>\u6ce8\uff1a</p> <ul> <li> <p>\u4f20\u5165\u5f53\u524d\u8fed\u4ee3\u5230\u7684\u56fe\u50cf\u7d22\u5f15\uff0c\u4f20\u51famosaic\u589e\u5f3a\u540e\u7684\u56fe\u50cf\u6570\u636e\u548c\u8fb9\u754c\u6846\u6807\u7b7e\uff1b</p> </li> <li> <p>\u4ee3\u7801\u5f15\u81eaYolov3\uff0c\u8bfb\u53d6\u5230\u7684\u8fb9\u754c\u6846\u6807\u7b7e\u4e3a\u539f\u56fe\u4e0a\u7684\u76f8\u5bf9\u5750\u6807\uff0c\u683c\u5f0f\u4e3a\u2019xywh\u2019\uff0c\u5e76\u4e14\u5bf9\u539f\u56fe\u6267\u884c\u7684\u662f\u7b49\u6bd4\u653e\u5927\uff0c\u4e0d\u6539\u53d8\u5bbd\u9ad8\u6bd4\u4f8b\u3002</p> </li> </ul> <pre><code>def load_mosaic(self, index):\n    \"\"\"\n    \u5c06\u56db\u5f20\u56fe\u7247\u62fc\u63a5\u5728\u4e00\u5f20\u56fe\u50cf\u4e2d\n    :param self:\n    :param index: \u5f53\u524d\u8fed\u4ee3\u5230\u7684\u56fe\u50cf\u7d22\u5f15\n    \"\"\"\n    # loads images in a mosaic\n\n    labels4 = []  # \u62fc\u63a5\u56fe\u50cf\u7684label\u4fe1\u606f\n    # self.img_size\u4e3a\u9884\u8bbe\u7684\u56fe\u50cf\u6700\u5927\u5c3a\u5bf8\n    s = self.img_size\n    # \u968f\u673a\u521d\u59cb\u5316\u62fc\u63a5\u56fe\u50cf\u7684\u4e2d\u5fc3\u70b9\u5750\u6807\n    xc, yc = [int(random.uniform(s * 0.5, s * 1.5)) for _ in range(2)]  # mosaic center x, y\n    # \u518d\u4ecedataset\u4e2d\u968f\u673a\u5bfb\u627e\u4e09\u5f20\u56fe\u50cf\uff0c\u5c06\u7d22\u5f15\u62fc\u8d77\u6765\u5f97\u5230indices\n    indices = [index] + [random.randint(0, len(self.labels) - 1) for _ in range(3)]  # 3 additional image indices\n    # \u904d\u5386\u56db\u5f20\u56fe\u50cf\u8fdb\u884c\u62fc\u63a5\n    for i, index in enumerate(indices):\n        # load image \u8bfb\u53d6\u56fe\u7247\u6570\u636e\uff0c\u5e76\u4e14\u7b49\u6bd4\u653e\u5927\u5230\u5408\u9002\u7684\u5c3a\u5bf8(\u6ce8\u610f\u8981\u6267\u884c\u7b49\u6bd4\u653e\u5927)\n        # \u4f8b\u5982:\u5c06\u56fe\u7247\u9ad8\u3001\u5bbd\u4e2d\u6700\u5927\u7684\u4e00\u4fa7\u653e\u5927\u4e3aself.img_size(\u9884\u8bbe\u597d\u7684)\n        img, _, (h, w) = load_image(self, index)\n\n        # \u4f9d\u6b21\u5c06\u56db\u5f20\u56fe\u7247\u8d4b\u503c\u5230img4\u4e2d\uff0c\u505a\u4e00\u4e2a\u62fc\u63a5\n        if i == 0:  # top left\n            # \u521b\u5efa\u9a6c\u8d5b\u514b\u56fe\u50cf\n            img4 = np.full((s * 2, s * 2, img.shape[2]), 114, dtype=np.uint8)  # base image with 4 tiles\n            # \u8ba1\u7b97\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\u7684\u5750\u6807\u4fe1\u606f(\u5c06\u56fe\u50cf\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d)\n            x1a, y1a, x2a, y2a = max(xc - w, 0), max(yc - h, 0), xc, yc  # xmin, ymin, xmax, ymax (large image)\n            # \u8ba1\u7b97\u622a\u53d6\u7684\u56fe\u50cf\u533a\u57df\u4fe1\u606f(\u4ee5xc,yc\u4e3a\u7b2c\u4e00\u5f20\u56fe\u50cf\u7684\u53f3\u4e0b\u89d2\u5750\u6807\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\uff0c\u4e22\u5f03\u8d8a\u754c\u7684\u533a\u57df)\n            x1b, y1b, x2b, y2b = w - (x2a - x1a), h - (y2a - y1a), w, h  # xmin, ymin, xmax, ymax (small image)\n        elif i == 1:  # top right\n            # \u8ba1\u7b97\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\u7684\u5750\u6807\u4fe1\u606f(\u5c06\u56fe\u50cf\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d)\n            x1a, y1a, x2a, y2a = xc, max(yc - h, 0), min(xc + w, s * 2), yc\n            # \u8ba1\u7b97\u622a\u53d6\u7684\u56fe\u50cf\u533a\u57df\u4fe1\u606f(\u4ee5xc,yc\u4e3a\u7b2c\u4e8c\u5f20\u56fe\u50cf\u7684\u5de6\u4e0b\u89d2\u5750\u6807\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\uff0c\u4e22\u5f03\u8d8a\u754c\u7684\u533a\u57df)\n            x1b, y1b, x2b, y2b = 0, h - (y2a - y1a), min(w, x2a - x1a), h\n        elif i == 2:  # bottom left\n            # \u8ba1\u7b97\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\u7684\u5750\u6807\u4fe1\u606f(\u5c06\u56fe\u50cf\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d)\n            x1a, y1a, x2a, y2a = max(xc - w, 0), yc, xc, min(s * 2, yc + h)\n            # \u8ba1\u7b97\u622a\u53d6\u7684\u56fe\u50cf\u533a\u57df\u4fe1\u606f(\u4ee5xc,yc\u4e3a\u7b2c\u4e09\u5f20\u56fe\u50cf\u7684\u53f3\u4e0a\u89d2\u5750\u6807\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\uff0c\u4e22\u5f03\u8d8a\u754c\u7684\u533a\u57df)\n            x1b, y1b, x2b, y2b = w - (x2a - x1a), 0, max(xc, w), min(y2a - y1a, h)\n        elif i == 3:  # bottom right\n            # \u8ba1\u7b97\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\u7684\u5750\u6807\u4fe1\u606f(\u5c06\u56fe\u50cf\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d)\n            x1a, y1a, x2a, y2a = xc, yc, min(xc + w, s * 2), min(s * 2, yc + h)\n            # \u8ba1\u7b97\u622a\u53d6\u7684\u56fe\u50cf\u533a\u57df\u4fe1\u606f(\u4ee5xc,yc\u4e3a\u7b2c\u56db\u5f20\u56fe\u50cf\u7684\u5de6\u4e0a\u89d2\u5750\u6807\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\uff0c\u4e22\u5f03\u8d8a\u754c\u7684\u533a\u57df)\n            x1b, y1b, x2b, y2b = 0, 0, min(w, x2a - x1a), min(y2a - y1a, h)\n\n        # \u5c06\u622a\u53d6\u7684\u56fe\u50cf\u533a\u57df\u586b\u5145\u5230\u9a6c\u8d5b\u514b\u56fe\u50cf\u7684\u76f8\u5e94\u4f4d\u7f6e\n        img4[y1a:y2a, x1a:x2a] = img[y1b:y2b, x1b:x2b]  # img4[ymin:ymax, xmin:xmax]\n        # \u8ba1\u7b97pad\uff0c\u7528\u4e8e\u8c03\u6574\u8fb9\u754c\u6846\u5750\u6807\n        # \u56fe\u50cf\u8fb9\u754c\u4e0e\u9a6c\u8d5b\u514b\u8fb9\u754c\u7684\u8ddd\u79bb\uff0c\u5982\u679c\u56fe\u50cf\u8d85\u8fc7\u4e86\u9a6c\u8d5b\u514b\u8fb9\u754c\uff0c\u5219\u89c6\u4e3a\u8d8a\u754c\uff0c\u8d8a\u754c\u7684\u60c5\u51b5\u4e3a\u8d1f\u503c\n        padw = x1a - x1b\n        padh = y1a - y1b\n\n        # Labels \u83b7\u53d6\u5bf9\u5e94\u62fc\u63a5\u56fe\u50cf\u7684labels\u4fe1\u606f\n        # [class_index, x_center, y_center, w, h]\n        x = self.labels[index]\n        labels = x.copy()  # \u6df1\u62f7\u8d1d\uff0c\u9632\u6b62\u4fee\u6539\u539f\u6570\u636e\n        if x.size &gt; 0:  # Normalized xywh to pixel xyxy format\n            # \u8ba1\u7b97\u6807\u6ce8\u6570\u636e\u5728\u9a6c\u8d5b\u514b\u56fe\u50cf\u4e2d\u7684\u5750\u6807\uff0c\u4e58\u4ee5w\u548ch\u662f\u4e3a\u4e86\u5c06\u7edd\u5bf9\u5750\u6807\u5316\u4e3a\u76f8\u5bf9\u5750\u6807\uff0c\u4e4b\u540e\u518d\u52a0\u4e0a\u4e0a\u8ff0\u8ba1\u7b97\u7684\u8ddd\u79bb\uff0c\u5f97\u5230\u6700\u540e\u7684\u5750\u6807\u6570\u636e\n            labels[:, 1] = w * (x[:, 1] - x[:, 3] / 2) + padw   # xmin\n            labels[:, 2] = h * (x[:, 2] - x[:, 4] / 2) + padh   # ymin\n            labels[:, 3] = w * (x[:, 1] + x[:, 3] / 2) + padw   # xmax\n            labels[:, 4] = h * (x[:, 2] + x[:, 4] / 2) + padh   # ymax\n        labels4.append(labels)\n\n    # Concat/clip labels \u5c06\u56db\u5f20\u56fe\u50cf\u7684\u8fb9\u754c\u6846\u6807\u7b7e\u62fc\u63a5\u5230\u4e00\u5757\n    if len(labels4):\n        labels4 = np.concatenate(labels4, 0)\n        # \u8bbe\u7f6e\u4e0a\u4e0b\u9650\u9632\u6b62\u8d8a\u754c\n        np.clip(labels4[:, 1:], 0, 2 * s, out=labels4[:, 1:])\n\n    # \u8fd4\u56de\u589e\u5f3a\u540e\u7684\u56fe\u7247\n    return img4, labels4\n\n# \u52a0\u8f7d\u56fe\u7247\ndef load_image(self, index):\n    # loads 1 image from dataset, returns img, original hw, resized hw\n    img = self.imgs[index]\n    # \u5982\u679c\u4e4b\u524d\u6ca1\u8bfb\u53d6\u8fc7\uff0c\u5219\u91cd\u65b0\u8bfb\u4e00\u904d\n    if img is None:  # not cached\n        path = self.img_files[index]\n        img = cv2.imread(path)  # BGR\n        assert img is not None, \"Image Not Found \" + path\n        h0, w0 = img.shape[:2]  # orig hw\n        # img_size \u8bbe\u7f6e\u7684\u662f\u9884\u5904\u7406\u540e\u8f93\u51fa\u7684\u56fe\u7247\u5c3a\u5bf8\n        r = self.img_size / max(h0, w0)  # resize image to img_size\n        # \u5c06\u56fe\u7247\u9ad8\u3001\u5bbd\u4e2d\u6700\u5927\u7684\u4e00\u4fa7\u653e\u5927\u4e3aself.img_size\uff0c\u6ce8\u610f\u8981\u6267\u884c\u7b49\u6bd4\u653e\u5927\n        if r != 1:  # if sizes are not equal\n            interp = cv2.INTER_AREA if r &lt; 1 and not self.augment else cv2.INTER_LINEAR\n            img = cv2.resize(img, (int(w0 * r), int(h0 * r)), interpolation=interp)\n        return img, (h0, w0), img.shape[:2]  # img, hw_original, hw_resized\n    else:\n        return self.imgs[index], self.img_hw0[index], self.img_hw[index]  # img, hw_original, hw_resized\n</code></pre> <p>\u521d\u6b65\u5b8c\u7a3f\u4e8e\uff1a2023\u5e742\u670814\u65e5</p>"},{"location":"domain_adaptive/domain_dataset/","title":"\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u6570\u636e\u96c6\u6c47\u603b","text":""},{"location":"domain_adaptive/domain_dataset/#cityscapesfoggy_cityscapes","title":"Cityscapes\u4e0eFoggy Cityscapes","text":""},{"location":"domain_adaptive/domain_dataset/#_2","title":"\u6570\u636e\u96c6\u4ecb\u7ecd","text":"<p> Cityscapes\u4e3a\u65e0\u4eba\u9a7e\u9a76\u73af\u5883\u4e0b\u7684\u8bed\u4e49\u5206\u5272\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u89c6\u89c9\u7b97\u6cd5\u5728\u57ce\u5e02\u573a\u666f\u4e0b\u8bed\u4e49\u7406\u89e3\u65b9\u9762\u7684\u6027\u80fd\uff0c\u5171\u5305\u542b3475\u5f20\u8bad\u7ec3\u96c6\u3001500\u5f20\u9a8c\u8bc1\u96c6\u30011525\u5f20\u6d4b\u8bd5\u96c6\u3002</p> <p>\u2003\u2003Cityscapes\u6570\u636e\u96c6\u66f4\u8be6\u7ec6\u7684\u8bb2\u89e3\u5730\u5740\u53ef\u53c2\u8003\uff1a</p> <ul> <li>https://github.com/mcordts/cityscapesScripts</li> <li>https://blog.csdn.net/zz2230633069/article/details/84591532</li> </ul> <p> Foggy Cityscapes\u7531\u8bba\u6587\u300aSemantic Foggy Scene Understanding with Synthetic Data\u300b\u63d0\u51fa(\u8bba\u6587\u94fe\u63a5)\uff0c\u4e0eCityscapes\u6570\u636e\u76f8\u6bd4\u573a\u666f\u4ee5\u53ca\u5185\u5bb9\u5747\u76f8\u540c\uff0c\u4ec5\u4ec5\u589e\u52a0\u4e86\u96fe\u5316\u6548\u679c\uff0c\u56e0\u6b64\u53ef\u4ee5\u5171\u4eab\u4e00\u4e2a\u6807\u7b7e\u3002</p> <p>\u2003\u2003Cityscapes\u4e2d1\u5f20\u56fe\u7247\u5bf9\u5e94Foggy Cityscapes\u4e2d3\u5f20\u56fe\u7247\uff0c\u6bcf\u5f20\u56fe\u7247\u5bf9\u5e94\u4e00\u4e2a\\beta\u503c\uff0c\\beta\u5206\u522b\u4e3a0.005\u30010.01\u30010.02\uff0c\u5177\u4f53\u53ef\u53c2\u8003\u8bba\u6587\u4e2dFoggy Cityscapes\u7684\u5408\u6210\u65b9\u6cd5\u3002</p> <p></p> <p>\u2003\u2003Cityscapes\u76f8\u5f53\u4e8e\u6674\u5929\u6570\u636e\uff0cFoggy Cityscapes\u76f8\u5f53\u4e8e\u96fe\u5929\u6570\u636e\uff0c\u7531\u4e8e\u4e24\u4e2a\u6570\u636e\u96c6\u4ec5\u5728\u5929\u6c14\u60c5\u51b5\u4e0a\u5177\u6709\u5dee\u5f02\uff0c\u56e0\u6b64\u4e24\u4e2a\u6570\u636e\u96c6\u7684\u7ec4\u5408\u5e38\u7528\u4e8e\u57df\u9002\u5e94\u65b9\u5411\u7684\u7814\u7a76\u3002</p>"},{"location":"domain_adaptive/domain_dataset/#_3","title":"\u4e0b\u8f7d\u5730\u5740","text":"<p>\u2003\u2003\u5b98\u65b9\u4e0b\u8f7d\u5730\u5740\uff1ahttps://www.cityscapes-dataset.com/downloads</p> <p>Cityscapes\u56fe\u7247\u6570\u636e</p> <p> <p></p> <p></p> <p>Cityscapes\u6807\u7b7e\u6570\u636e</p> <p> <p></p> <p></p> <p>\u6807\u7b7e\u4e3a\u8bed\u4e49\u5206\u5272\u683c\u5f0f\u7684\u6807\u7b7e\uff0c\u5982\u679c\u7528\u4e8e\u76ee\u6807\u68c0\u6d4b\u7684\u8bdd\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u505a\u8f6c\u6362</p> <p>Foggy Cityscapes\u56fe\u7247\u6570\u636e</p> <p> <p></p> <p></p>"},{"location":"domain_adaptive/domain_dataset/#xml","title":"\u5c06\u6807\u7b7e\u8f6c\u5316\u4e3axml\u683c\u5f0f","text":"<p>\u2003\u2003\u5c06\u539f\u59cb\u7684\u8bed\u4e49\u5206\u5272\u6807\u7b7e\u8f6c\u5316\u4e3a\u76ee\u6807\u68c0\u6d4b\u6807\u7b7e\uff0c\u6ce8\u610f\u8fd9\u91cc\u5c06train\u4f5c\u4e3a\u8bad\u7ec3\u96c6\uff0c\u5c06val\u4f5c\u4e3a\u9a8c\u8bc1\u96c6\uff0c\u5c06test\u820d\u5f03(\u65e0\u6807\u7b7e\uff0c\u65e0\u6cd5\u9a8c\u8bc1)</p> <p>\u53c2\u8003\u94fe\u63a5\uff1ahttps://github.com/hamzarawal/cityscapes-to-voc</p> <p>\u53c2\u6570\u521d\u59cb\u5316</p> <pre><code># \u5bfc\u5165\u4f7f\u7528\u5230\u7684\u5e93\nfrom pascal_voc_writer import Writer\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport json\nimport glob\nimport time\nfrom shutil import move, copy\n\n# \u56fe\u7247\u6570\u636e\u6839\u76ee\u5f55\uff0c\u5373leftImg8bit\u6587\u4ef6\u6240\u5728\u7684\u76ee\u5f55\ncityscapes_dir = '.'\n# VOC\u6807\u7b7e\u5b58\u50a8\u76ee\u5f55\nsave_path = './cityscapes_voc_annotations/'\n# \u6807\u7b7e\u76ee\u5f55\uff0c\u8fd9\u91cc\u5c06leftImg8bit\u6587\u4ef6\u4e0egtFine\u6587\u4ef6\u653e\u81f3\u540c\u4e00\u76ee\u5f55\u4e0b\ncityscapes_dir_gt = os.path.join(cityscapes_dir, 'gtFine')\n\n# \u521b\u5efa\u5b57\u5178\u683c\u5f0f\u6570\u636e\uff0c\u952e\u4e3a\u539f\u59cb\u6807\u7b7e\u7684label\u540d\u79f0\uff0c\u503c\u4e3a\u671f\u671b\u7684VOC\u683c\u5f0flabel\u540d\u79f0\n# \u5f97\u5230\u671f\u671b\u63d0\u53d6\u7684\u7c7b\u522b\uff0c\u4e00\u822c\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u4e2d\uff0c\u53ea\u63d0\u53d6\u5982\u4e0b\u516b\u7c7b\nclasses = {'bicycle':'bicycle', 'bus':'bus', 'car':'car', 'motorcycle':'mcycle', \n               'person':'person', 'rider': 'rider', 'train':'train', 'truck':'truck'}\nclasses_keys = list(classes.keys())\n</code></pre> <p>\u521b\u5efa\u76ee\u5f55\u7684\u51fd\u6570</p> <pre><code>def make_dir(path):\n    # \u9996\u5148\u5224\u65ad\u662f\u5426\u5b58\u5728\u76ee\u5f55\n    if not os.path.isdir(path):\n        os.makedirs(path)\n</code></pre> <p>\u5c06\u591a\u8fb9\u5f62\u8f6c\u5316\u4e3a\u77e9\u5f62\u8fb9\u754c\u6846</p> <pre><code># \u5229\u7528\u77e9\u5f62\u5c06\u4e0d\u89c4\u5219\u5f62\u72b6\u6846\u8d77\u6765\ndef polygon_to_bbox(polygon):\n    x_coordinates, y_coordinates = zip(*polygon)\n    # \u5f97\u5230\u5750\u6807\u7684\u6700\u503c\uff0c\u5373\u5bf9\u5e94\u8fb9\u754c\u6846\u4e24\u4e2a\u5750\u6807\u70b9\n    return [min(x_coordinates), min(y_coordinates), max(x_coordinates), max(y_coordinates)]\n</code></pre> <p>\u5f97\u5230VOC\u6807\u7b7e\u4fe1\u606f</p> <p>\u8bfb\u53d6\u539f\u59cb\u6807\u7b7ejson\uff0c\u8ba1\u7b97\u5f97\u5230\u5bf9\u8c61\u7c7b\u522b\u4ee5\u53ca\u8fb9\u754c\u6846\u5750\u6807</p> <pre><code>def read_json(file):\n\n    # \u7528\u4e8e\u5224\u65ad\u56fe\u50cf\u4e2d\u662f\u5426\u6709\u671f\u671b\u7684\u7c7b\u522b(\u5373\u4e0a\u9762\u5b9a\u4e49\u7684classes)\n    # \u5982\u679c\u6ca1\u6709\u671f\u671b\u7684\u7c7b\u522b\uff0c\u5219\u4e0d\u5bf9\u8be5\u56fe\u50cf\u751f\u6210xml\u6587\u4ef6\n    relevant_file = False\n\n    data = []\n    with open(file, 'r') as f:\n        # \u52a0\u8f7djson\u6587\u4ef6\n        file_data = json.load(f)\n        # \u904d\u5386\u56fe\u50cf\u4e2d\u6240\u6709\u7684\u7269\u4f53\n        for object in file_data['objects']:\n            # \u5f97\u5230\u7c7b\u522b\u6807\u7b7e\u548c\u591a\u8fb9\u5f62\u5750\u6807\u70b9\n            label, polygon = object['label'], object['polygon']\n\n            # \u5f53\u7269\u4f53\u7c7b\u522b\u4e0e\u671f\u671b\u5b58\u50a8\u7684\u7c7b\u522b\u4e00\u81f4\u65f6\uff0c\u624d\u5c06\u8be5\u6570\u636e\u5b58\u50a8\u4e0b\u6765\n            if label in classes_keys:\n                # \u8f6c\u6362\u6570\u636e\u7c7b\u578b\uff0c\u8f6c\u6362\u4e3anumpy\u683c\u5f0f\n                polygon = np.array([x for x in polygon])\n                # \u5f97\u5230\u8fb9\u754c\u6846\u5750\u6807\n                bbox = polygon_to_bbox(polygon)\n                # \u5b58\u50a8\u7269\u4f53\u7c7b\u522b\u4ee5\u53ca\u8fb9\u754c\u6846\n                data.append([classes[label]]+bbox)\n\n        # \u5982\u679c\u5728\u56fe\u50cf\u4e2d\u627e\u5230\u76f8\u5173\u7684\u5bf9\u8c61\uff0c\u5c06\u6807\u5fd7\u8bbe\u7f6e\u4e3aTrue\uff0c\u8868\u793a\u751f\u6210xml\u6587\u4ef6\n        if data:\n            relevant_file = True\n\n    return data, relevant_file\n</code></pre> <p>\u4e3a\u56fe\u7247\u521b\u5efaxml\u6587\u4ef6</p> <pre><code>def save_xml(img_path, img_shape, data, save_path):\n    # \u521d\u59cb\u5316\u7c7b\n    writer = Writer(img_path,img_shape[0], img_shape[1])\n    # \u904d\u5386data\uff0c\u5199\u5165\u6570\u636e\n    for element in data:\n        writer.addObject(element[0],element[1],element[2],element[3],element[4])\n    # \u4fdd\u5b58xml\n    writer.save(save_path) \n</code></pre> <p>\u4e3b\u7a0b\u5e8f</p> <p>\u751f\u6210Annotations\u6587\u4ef6\uff0c\u5373\u5b58\u6709xml\u6807\u7b7e\u4fe1\u606f\u7684\u6587\u4ef6</p> <pre><code># \u521d\u59cb\u5316\u4e09\u4e2a\u50a8\u5b58\u8def\u5f84\u7684\u53d8\u91cf\n# \u6709\u6548\u7684\u56fe\u7247\uff0c\u5373\u6240\u6709\u7528\u4e8e\u8bad\u7ec3\u548c\u9a8c\u8bc1\u7684\u56fe\u7247\nvalid_files = []\n# \u7528\u4e8e\u8bad\u7ec3\u7684\u56fe\u7247\ntrainval_files = []\n# \u7528\u4e8e\u6d4b\u8bd5\u7684\u56fe\u7247\ntest_files = []\n\n# VOC\u6839\u76ee\u5f55\nann_dir = os.path.join(save_path, 'VOC2007','Annotations')\n# \u5982\u679c\u76ee\u6807\u76ee\u5f55\u4e0d\u5b58\u5728\uff0c\u5219\u521b\u5efa\u76ee\u5f55\nmake_dir(ann_dir)\n\nstart = time.time()\n# \u6309train\u3001val\u3001test\u904d\u5386\nfor category in os.listdir(cityscapes_dir_gt):\n\n    # \u4e0d\u4e3atest\u6570\u636e\u751f\u6210\u6807\u7b7e\n    if category == 'test': continue\n    # \u904d\u5386\u57ce\u5e02\u4fe1\u606f\n    for city in os.listdir(os.path.join(cityscapes_dir_gt, category)):\n\n        # \u5f97\u5230\u6240\u6709\u7684json\u6587\u4ef6\u8def\u5f84\uff0c\u8fd4\u56de\u4e00\u4e2a\u53ef\u904d\u5386\u7684\u53d8\u91cf\n        files = glob.glob(os.path.join(cityscapes_dir, 'gtFine', category, city)+'/*.json')\n\n        # \u904d\u5386\u6240\u6709json\u6587\u4ef6\u8def\u5f84\n        for file in files:\n            # \u8fd4\u56de\u5f97\u5230\u7684\u56fe\u7247\u6807\u7b7e\u6570\u636e\uff0c\u4ee5\u53ca\u5224\u65ad\u8be5\u56fe\u7247\u662f\u5426\u542b\u6709\u671f\u671b\u7684\u7c7b\u522b\u5bf9\u8c61\n            data, relevant_file = read_json(file)\n            # \u5982\u679c\u8be5\u56fe\u6709\u671f\u671b\u7684\u7269\u4f53\uff0c\u5219\u521b\u5efaxml\u6587\u4ef6\n            # \u8fd9\u91cc\u4e5f\u53ef\u4ee5\u901a\u8fc7\u5224\u65addata\u662f\u5426\u975e\u7a7a\u5b9e\u73b0\n            if relevant_file:\n                # \u5f97\u5230\u56fe\u7247\u6807\u7b7e\n                base_filename = os.path.basename(file)[:-21]\n                # \u901a\u8fc7\u5408\u5e76\uff0c\u5f97\u5230xml\u5b58\u50a8\u8def\u5f84\n                xml_filepath = os.path.join(ann_dir, base_filename + '_leftImg8bit.xml')\n                # \u5f97\u5230\u56fe\u7247\u540d\u79f0\n                img_name = base_filename+'_leftImg8bit.png'\n                # \u5f97\u5230\u56fe\u7247\u8def\u5f84\n                img_path = os.path.join(cityscapes_dir, 'leftImg8bit', category, city, base_filename+'_leftImg8bit.png')\n                # \u8bfb\u53d6\u56fe\u7247\uff0c\u4e4b\u540e\u5f97\u5230\u56fe\u7247\u5c3a\u5bf8\n                img_shape = plt.imread(img_path).shape\n                # \u4fdd\u5b58\u6240\u6709\u56fe\u7247\u7684\u8def\u5f84(\u8bad\u7ec3+\u9a8c\u8bc1)\n                valid_files.append([img_path, img_name])\n\n                # \u4fdd\u5b58\u8bad\u7ec3\u96c6\u4e0e\u9a8c\u8bc1\u96c6\uff0c\u8fd9\u91cc\u5206\u522b\u5f97\u5230\u4e24\u4e2a\u53d8\u91cf\n                trainval_files.append(img_name[:-4]) if category == 'train' else test_files.append(img_name[:-4])\n\n                # \u4fdd\u5b58xml\u683c\u5f0f\u7684\u6807\u7b7ex\n                save_xml(img_path, img_shape, data, xml_filepath)\n            else:\n                print(file)\nend = time.time() - start\nprint('Total Time taken: ', end)\n</code></pre> <p>\u751f\u6210JPEGImages\u6587\u4ef6\uff0c\u5373\u5b58\u6709\u6240\u6709\u56fe\u7247\u7684\u6587\u4ef6</p> <p>\u6ce8\u610f\uff1a\u7531\u4e8e\u671f\u671b\u63d0\u53d6\u7684\u7c7b\u522b\u53ef\u80fd\u4e0d\u662f\u539f\u6570\u636e\u96c6\u4e2d\u6240\u6709\u7684\u7c7b\u522b\uff0c\u56e0\u6b64\u6700\u7ec8\u5f97\u5230\u7684\u56fe\u7247\u53ef\u80fd\u4f1a\u5c11\u4e8e2975+500=3475\u5f20\uff0c\u82e5\u6309\u4e0a\u8ff0\u516b\u79cd\u7c7b\u522b\u63d0\u53d6\u7684\u8bdd\uff0c\u6700\u540e\u4f1a\u5f97\u52302965+492=3457\u5f20\u56fe\u7247</p> <pre><code># \u521b\u5efa\u76ee\u5f55\nimages_savepath = os.path.join(save_path, 'VOC2007', 'JPEGImages')\nmake_dir(images_savepath)\n\nstart = time.time()\n# \u904d\u5386\u4e4b\u524d\u5f97\u5230\u7684\u56fe\u7247\u8def\u5f84\nfor file in valid_files:\n    # \u590d\u5236\u56fe\u7247\n    copy(file[0], os.path.join(images_savepath, file[1]))\nend = time.time() - start\nprint('Total Time taken: ', end)\n</code></pre> <p>\u751f\u6210ImageSets\u6587\u4ef6\uff0c\u5373\u5b58\u6709\u5212\u5206\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\u4fe1\u606f\u7684\u6587\u4ef6</p> <pre><code># \u521b\u5efa\u76ee\u5f55\ntextfiles_savepath = os.path.join(save_path, 'VOC2007', 'ImageSets', 'Main')\nmake_dir(textfiles_savepath)\n\ntrainval_files_wr = [x + '\\n' for x in trainval_files]\ntest_files_wr = [x + '\\n' for x in test_files]\n# \u5206\u522b\u53d8\u91cf\uff0c\u5e76\u4e14\u5199\u5165txt\u6587\u4ef6\nwith open(os.path.join(textfiles_savepath, 'trainval.txt'), 'w') as f:\n    f.writelines(trainval_files_wr)\n\nwith open(os.path.join(textfiles_savepath, 'test.txt'), 'w') as f:\n    f.writelines(test_files_wr)\n</code></pre> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e742\u67086\u65e5</p>"},{"location":"domain_adaptive/question/","title":"\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u95ee\u9898\u8bb0\u5f55","text":""},{"location":"domain_adaptive/question/#_2","title":"\u672a\u89e3\u51b3","text":""},{"location":"domain_adaptive/question/#htcn","title":"HTCN","text":"<p>1\u3001IWAT-I\u6a21\u5757\u4e2d\u7684\u63d2\u503c\u5177\u4f53\u6307\u7684\u4ec0\u4e48\uff1f</p> <p>\u2003\u20033.2\u5c0f\u8282\u524d\u534a\u90e8\u5206\u4e00\u76f4\u5728\u63d0\u63d2\u503c\u64cd\u4f5c\u7684\u597d\u5904\uff0c\u4f46\u662f\u6574\u4e2a3.2\u5c0f\u8282\u548c\u5bf9\u5e94\u7684\u6e90\u7801\u90fd\u6ca1\u6709\u63d0\u5230\u662f\u600e\u4e48\u5b9e\u65bd\u7684\u63d2\u503c\uff0c\u8bfb\u7b2c\u4e8c\u904d\u7684\u65f6\u5019\u6211\u611f\u89c9\u53ef\u80fd\u662f\u540e\u97623.4\u8282\u91cc\u9762\u7684\u5c40\u90e8\u7279\u5f81\u63a9\u7801\u662f\u63d2\u503c\uff0c\u4f46\u4e3a\u4ec0\u4e48\u548cCycle GAN\u6709\u5173\uff1f</p> <p>\u2003\u2003\u5df2\u7ecf\u7ed9\u4f5c\u8005\u53d1\u90ae\u4ef6\u54a8\u8be2\u4e86\uff0c\u6b63\u5728\u7b49\u5f85\u56de\u590d\u2014\u20142022\u5e742\u670811\u65e5</p> <p>\u95ee\uff1aWhere is the interpolation method reflected in IWAT-I? It is mentioned that the interpolation is implemented with CycleGAN in paper, but I didn\u2019t seem to find a description of interpolation in the section 3.2 or in the code. Whether \u201clocal feature mask\u201d which is mentioned in section3.4 is an interpolation operation in IWAT-I?</p> <p>2\u30013.4\u5c0f\u8282\u4e2d\u7684\u201dmore transferable\u201d\u8be5\u5982\u4f55\u7406\u89e3\uff1f</p> <p>\u2003\u2003\u539f\u6587\u201dthe less uncertainty regions are more transferable\u201d\uff0c\u8fd9\u91cc\u7684\u201cmore transferable\u201d\u8be5\u5982\u4f55\u7406\u89e3\uff1f\u5177\u4f53\u6307\u7684\u662f\u6a21\u578b\u66f4\u5bb9\u6613\u5728\u4e24\u4e2a\u9886\u57df\u4e0a\u4ea7\u751f\u76f8\u4f3c\u7279\u5f81\u7684\u524d\u666f(\u5373\u7279\u5f81\u5177\u6709\u57df\u4e0d\u53d8\u6027)\uff0c\u8fd8\u662f\u66f4\u5bb9\u6613\u4ea7\u751f\u4e0d\u76f8\u4f3c\u7279\u5f81\u7684\u80cc\u666f(\u5373\u7279\u5f81\u968f\u57df\u53d8\u5316\u800c\u53d8\u5316)\uff1f\u5982\u679c\u662f\u524d\u8005\u7684\u8bdd\uff0c\u90a3\u5982\u4f55\u548c\u540e\u9762\u7684\u635f\u5931\u8054\u7cfb\u8d77\u6765\uff1f</p> <p>\u2003\u2003\u6309\u76f4\u89c2\u610f\u4e49\u6765\u8bb2\u7684\u8bdd\uff0c\u4e0d\u786e\u5b9a\u6027\u8d8a\u4f4e\uff0c\u8d8a\u5bb9\u6613\u5224\u65ad\u9886\u57df\u5f52\u5c5e\uff0c\u5373\u4f20\u5165\u57df\u5206\u7c7b\u5668\u4e4b\u524d\u7684\u7279\u5f81\u8d8a\u4e0d\u76f8\u4f3c\uff0c\u5373\u7279\u5f81\u968f\u57df\u7684\u53d8\u5316\u800c\u53d8\u5316\uff0c\u56e0\u6b64\u5e94\u8be5\u662f\u80cc\u666f\u3002\u4f46\u662f\uff0c\u5982\u679cv_i\u8d8a\u4f4e\u8d8a\u4ee3\u8868\u6613\u533a\u5206\u7684\u80cc\u666f\u7684\u8bdd\uff0c\u90a3\u4e48\u518d\u770b\u540e\u9762\u8ba1\u7b97\u6743\u91cd\u7684\u516c\u5f0f\uff0c\u6b63\u597d\u548c3.2\u5c0f\u8282\u91cc\u6743\u91cd\u8ba1\u7b97\u516c\u5f0f\u76f8\u53cd\uff0c3.2\u91cc\u5bf9\u56fe\u50cf\u7ea7\u7279\u5f81\u52a0\u6743\u7684\u65f6\u5019\uff0c\u4e0d\u786e\u5b9a\u6027\u8d8a\u9ad8\uff0c\u5373\u8d8a\u4e0d\u5bb9\u6613\u5224\u65ad\u9886\u57df\u7684\u5f52\u5c5e\u65f6\uff0c\u6743\u91cd\u8d8a\u5927\uff0c\u8fd9\u91cc\u53ef\u4ee5\u7406\u89e3\u4e3a\u5f3a\u8c03\u57df\u76f8\u4f3c\u6027\u9ad8\u7684\u56fe\u50cf\uff1b\u4f46\u8fd9\u91cc\u5bf9\u5c40\u90e8\u533a\u57df\u7279\u5f81\u52a0\u6743\u7684\u65f6\u5019\uff0c\u4e0d\u786e\u5b9a\u6027\u8d8a\u4f4e\uff0c\u6743\u91cd\u8d8a\u5927\uff0c\u5e94\u8be5\u662f\u8981\u52a0\u5f3a\u80cc\u666f\u7684\u6743\u91cd\uff0c\u6291\u5236\u524d\u666f\u6743\u91cd\uff0c\u4e3a\u4ec0\u4e48\u8981\u8fd9\u4e48\u505a\uff1f</p> <p>\u2003\u2003\u662f\u4e0d\u662f\u548c\u524d\u9762\u7684\u63d2\u503c\u6709\u5173\u7cfb\uff1f3.2\u5c0f\u8282\u4e2d\u7684\u63d2\u503c\u6a21\u5757\u5c31\u662f\u60f3\u8ba9\u6e90\u57df\u6570\u636e\u53d8\u5f97\u50cf\u76ee\u6807\u57df\uff0c\u8ba9\u76ee\u6807\u57df\u6570\u636e\u53d8\u5f97\u50cf\u6e90\u57df\uff0c\u4ece\u800c\u586b\u5145\u6e90\u57df\u548c\u76ee\u6807\u57df\u4e4b\u95f4\u7684\u7a7a\u9699\uff0c\u8fdb\u4e00\u6b65\u89e3\u51b3\u6e90\u504f\u7f6e\u95ee\u9898\u3002\u5982\u679c3.4\u5c0f\u8282\u4e2d\u7684\u5c40\u90e8\u7279\u5f81\u63a9\u7801\u5c31\u662f3.2\u5c0f\u8282\u91cc\u7684\u63d2\u503c\u64cd\u4f5c\uff0c\u90a3\u4e48\u53ef\u4ee5\u8fd9\u4e48\u7406\u89e3\uff1a\u901a\u8fc7\u8fd9\u91cc\u5bf9\u539f\u6d45\u5c42\u7279\u5f81\u8fdb\u884c\u91cd\u65b0\u52a0\u6743\uff0c\u6291\u5236\u96be\u4ee5\u5224\u65ad\u9886\u57df\u5f52\u5c5e\u533a\u57df\u7684\u7279\u5f81\u6743\u91cd\uff0c\u63d0\u9ad8\u5bb9\u6613\u5224\u65ad\u9886\u57df\u5f52\u5c5e\u533a\u57df\u7684\u7279\u5f81\u6743\u91cd\uff0c\u6765\u5408\u6210\u65b0\u7684\u6570\u636e\uff0c\u4ee5\u65b0\u7684\u89d2\u5ea6\u8bad\u7ec3\u57df\u5206\u7c7b\u5668\uff0c\u4f46\u8fd9\u4e48\u7406\u89e3\u611f\u89c9\u5728\u903b\u8f91\u4e0a\u8fd8\u662f\u6709\u70b9\u4e0d\u4e25\u8c28\u3002</p> <p>\u2003\u2003\u5df2\u7ecf\u7ed9\u4f5c\u8005\u53d1\u90ae\u4ef6\u54a8\u8be2\u4e86\uff0c\u6b63\u5728\u7b49\u5f85\u56de\u590d\u2014\u20142022\u5e742\u670811\u65e5</p> <p>\u95ee\uff1aHow to understand this sentence\u201dless uncertainty regions are more transferable\u201d in section 3.4?</p>"},{"location":"domain_adaptive/question/#_3","title":"\u5df2\u89e3\u51b3","text":""},{"location":"domain_adaptive/question/#mega-cda","title":"MeGA-CDA","text":"<p>1\u3001\u57fa\u4e8e\u5ea6\u91cf\u5b66\u4e60\u7684\u76f8\u4f3c\u6027\u8ba1\u7b97\u65b9\u6cd5\u5c11\u4e00\u4e2a\u635f\u5931\u6765\u4f18\u5316</p> <p>\u2003\u2003\u6587\u4e2d\u63d0\u5230\u4e86\u6700\u5927\u5316\\Theta_t(F_t)^{(h,w)}\u548c\\Theta^k_t(\\hat{F}^k_t)^{(h,w)}\u4e4b\u95f4\u7684\u4f59\u5f26\u76f8\u4f3c\u6027\uff0c\u4ee5\u53ca\u6700\u5c0f\u5316\u4e0d\u76f8\u5173\u7c7b\u522b\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\uff0c\u4f46\u662f\u5e76\u6ca1\u6709\u63d0\u5230\u600e\u4e48\u5b9e\u65bd\uff0c\u800c\u4e14\u8fd9\u4e00\u90e8\u5206\u4e5f\u6ca1\u6709\u63d0\u5230\u5982\u4f55\u5bf9\u8be5\u90e8\u5206\u72ec\u7acb\u7684\u7f51\u7edc\u8fdb\u884c\u8bad\u7ec3\uff0c\u53ea\u63d0\u51fa\u4e86\u5229\u7528\u6e90\u57df\u6570\u636e\u7684\u8fb9\u754c\u6846\u4fe1\u606f\u6765\u5b9a\u4f4d\u7279\u5b9a\u7c7b\u522b\u7684\u7279\u5f81\uff0c\u6211\u611f\u89c9\u8fd9\u91cc\u5e94\u8be5\u518d\u52a0\u4e00\u4e2a\u989d\u5916\u7684\u635f\u5931\u51fd\u6570\uff0c\u6bd4\u5982\uff1a $$ \\mathcal L_{sim}^k=\\mu\u00b7\\sum_{k'\\neq k,k'\\in K} Sim(\\Theta_t(F_{s_k}),\\Theta^{k'}_t(\\hat{F}^{k'}_{s_k}))-Sim(\\Theta_t(F_{s_k}),\\Theta^k_t(\\hat{F}^k_{s_k})) $$  \u5176\u4e2d\uff0c\\mu\u8868\u793a\u63a7\u5236\u4e0d\u76f8\u5173\u7c7b\u522b\u635f\u5931\u548c\u76f8\u5173\u7c7b\u522b\u635f\u5931\u4e4b\u95f4\u76f8\u5bf9\u91cd\u8981\u6027\u7684\u6743\u91cd\uff0c\\mathcal L_{sim}^k\u8868\u793a\u7b2ck\u7c7b\u6a21\u5757\u7684\u76f8\u4f3c\u6027\u635f\u5931\uff0cF_{s_k}\u8868\u793a\u6e90\u57df\u6570\u636e\u4e2d\uff0c\u7b2ck\u7c7b\u7269\u4f53\u7684\u7279\u5f81\uff0c\u53ef\u4ee5\u5229\u7528\u6807\u7b7e\u8fb9\u754c\u6846\u5bf9\u539f\u7279\u5f81\u8fdb\u884c\u88c1\u526a\u5f97\u5230\uff0c\\hat{F}^{k'}_{s_k}\u8868\u793a\u7279\u5f81F_{s_k}\u67e5\u8be2\u7b2ck'\u7c7b\u7684\u8bb0\u5fc6\u6a21\u5757\u5f97\u5230\u7684\u68c0\u7d22\u7279\u5f81\uff0c\\Theta^{k'}_t(\u00b7)\u8868\u793a\u7b2ck'\u7c7b\u8bb0\u5fc6\u6a21\u5757\u540e\u7684\u5377\u79ef\u5c42\u3002\u540c\u4e00\u4e2a\u7279\u5f81\u8fdb\u5165\u4e0d\u540c\u8bb0\u5fc6\u6a21\u5757\u5f97\u5230\u4e0d\u540c\u7684\u68c0\u7d22\u7279\u5f81\uff0c\u5728\u5df2\u77e5\u8be5\u7279\u5f81\u5c5e\u4e8e\u7c7b\u522bk\u7684\u60c5\u51b5\u4e0b\uff0c\u8fdb\u5165k\u7c7b\u8bb0\u5fc6\u6a21\u5757\u5f97\u5230\u7684\u68c0\u7d22\u7279\u5f81\u5e94\u8be5\u4e0e\u539f\u7279\u5f81\u76f8\u4f3c\u5ea6\u9ad8\uff0c\u8fdb\u5165k'\u7c7b\u8bb0\u5fc6\u6a21\u5757\u5f97\u5230\u7684\u68c0\u7d22\u7279\u5f81\u5e94\u8be5\u4e0e\u539f\u7279\u5f81\u76f8\u4f3c\u5ea6\u4f4e\uff0c\u4e0a\u8ff0\u635f\u5931\u6b63\u597d\u53ef\u4ee5\u8fbe\u5230\u8fd9\u4e2a\u6548\u679c\uff0c\u4f46\u53ea\u662f\u7b80\u5355\u5730\u6784\u9020\u4e86\u4e00\u4e0b\uff0c\u5b9e\u9645\u7684\u6548\u679c\u8fd8\u6ca1\u6709\u5f97\u5230\u9a8c\u8bc1\u3002</p> <p>\u2003\u2003\u5df2\u7ecf\u53d1\u90ae\u4ef6\u54a8\u8be2\u4e86\uff0c\u6b63\u5728\u7b49\u5f85\u56de\u590d\u2014\u20142022\u5e742\u67084\u65e5</p> <p>Is it necessary to design an additional loss function that is not mentioned in the article to monitor the training of this network during implementation? How to realize the maximize(or minimize) cosine similarity which is mentioned in the paper?</p> <p>\u2003\u2003\u5df2\u56de\u590d\uff0c\u8bba\u6587\u786e\u5b9e\u5c11\u63d0\u4e00\u4e2a\u635f\u5931\uff0c\u4f46\u5e76\u6ca1\u6709\u7ed9\u51fa\u635f\u5931\u8ba1\u7b97\u516c\u5f0f\uff0c\u53ea\u662f\u7b80\u5355\u4e00\u63d0\u9700\u8981\u4e00\u4e2a\u635f\u5931\uff0c\u56de\u590d\u5185\u5bb9\uff1a</p> <p>Yes, it is necessary to integrate the cosine similarity loss function because in learned similarity we fuse memory read features with encoder features and we generated a category mask upon passing through some convolution layers. Hence, to effectively train the category segmentation network we exploit this cosine similarity loss:</p> <p><pre><code>F.cosine_similarity(feat1, feat2).abs().mean().\n</code></pre> \u56de\u590d\u65f6\u95f4\uff1a2022\u5e742\u67088\u65e5</p> <p>\u2003\u2003\u4ece\u4f5c\u8005\u7ed9\u7684\u4ee3\u7801\u6765\u770b\uff0c\u8fd9\u4e2a\u635f\u5931\u548c\u6211\u7406\u89e3\u7684\u5dee\u4e0d\u591a\uff0c\u90fd\u662f\u76f4\u63a5\u5229\u7528\u4f59\u5f26\u76f8\u4f3c\u5ea6\u4f5c\u4e3a\u635f\u5931\u3002</p> <p>2\u3001\u8bba\u6587\u4e2d\u7684\u7d27\u5bc6\u5ea6\u635f\u5931\u548c\u552f\u4e00\u6027\u635f\u5931\u53ef\u80fd\u6709\u70b9\u95ee\u9898</p> <p>\u2003\u2003\u672c\u8bba\u6587\u7d27\u5bc6\u5ea6\u635f\u5931\uff0c\u6309\u8bb0\u5fc6\u5355\u5143\u904d\u5386\uff0c\u5e76\u4e14\u627e\u51fa\u4e0e\u8bb0\u5fc6\u5355\u5143\u6700\u76f8\u4f3c\u7684\u7279\u5f81\u5411\u91cf\u6c42\u8ddd\u79bb\uff0c\u5982\u679c\u662f\u8fd9\u6837\u7684\u8bdd\uff0c\u5c31\u8981\u7528\u76f8\u4f3c\u5ea6\u77e9\u9635p\u6c42\u6700\u76f8\u4f3c\u7684\u7279\u5f81\u5411\u91cf\uff1a $$ \\mathcal L_{cmp}=\\sum^{N_m}_{j=1}||m_j-g_{s_k}^p||_2 $$  \u2003\u2003\u4f46\u6211\u611f\u89c9\u8fd9\u91cc\u9519\u4e86\uff0c\u539f\u8bba\u6587\u91cc\u9762(\u300aLearning Memory-guided Normality for Anomaly Detection\u300b)\u662f\u6309\u67e5\u8be2\u7279\u5f81\u904d\u5386\uff0c\u5373\u904d\u5386\u50cf\u7d20\u70b9\u7684\u7279\u5f81\u5411\u91cf\uff0c\u6700\u7ec8\u7684\u76ee\u7684\u662f\u8ba9\u7f51\u7edc\u4ea7\u751f\u7684\u67e5\u8be2\u7279\u5f81(\u5373\u50cf\u7d20\u7279\u5f81)\u8bb0\u5fc6\u6a21\u5757\u4e2d\u7684\u8bb0\u5fc6\u5355\u5143\u5f7c\u6b64\u9760\u8fd1\uff0c\u6211\u611f\u89c9\u8fd9\u624d\u662f\u5bf9\u7684\uff0c\u56e0\u4e3a\u8bb0\u5fc6\u6a21\u5757\u662f\u72ec\u7acb\u4e8e\u7f51\u7edc\u4e4b\u5916\u7684\u6570\u636e\uff0c\u4e0d\u80fd\u76f4\u63a5\u5bf9\u5176\u64cd\u4f5c\uff0c\u53ea\u80fd\u901a\u8fc7\u6539\u53d8\u63d0\u53d6\u5230\u7684\u7279\u5f81\u6765\u95f4\u63a5\u5f71\u54cd\u8bb0\u5fc6\u6a21\u5757\u4e2d\u7684\u6570\u636e\uff0c\u56e0\u6b64\u8fd9\u91cc\u5e94\u8be5\u662f\u8ba9\u67e5\u8be2\u7279\u5f81\u5f80\u8bb0\u5fc6\u6a21\u5757\u91cc\u5b58\u50a8\u7684\u7279\u5f81\u9760\u8fd1\uff0c\u800c\u4e0d\u662f\u8ba9\u8bb0\u5fc6\u6a21\u5757\u91cc\u7684\u6570\u636e\u9760\u8fd1\u67e5\u8be2\u7279\u5f81\uff0c\u6240\u4ee5\u8fd9\u91cc\u5e94\u8be5\u662f\u6309\u67e5\u8be2\u7279\u5f81\u904d\u5386\uff0c\u5373\u6309\u7279\u5f81\u56fe\u4e2d\u7684\u50cf\u7d20\u70b9\u904d\u5386\u3002</p> <p>\u4fee\u6539\u540e\uff1a</p> <p>\u2003\u2003\u635f\u5931\u6309\u67e5\u8be2\u7279\u5f81\u904d\u5386\uff0c\u5bf9\u5e94\u7684\u8bb0\u5fc6\u5355\u5143\u4e3a\u4e0e\u5f53\u524d\u67e5\u8be2\u7279\u5f81\u6700\u8fd1\u7684\u8bb0\u5fc6\u5355\u5143\uff0c\u56e0\u6b64\u5c31\u8981\u4f7f\u7528\u76f8\u4f3c\u5ea6\u77e9\u9635q\u6765\u6c42\u6700\u76f8\u4f3c\u7684\u8bb0\u5fc6\u5355\u5143\uff0c\u4ee5\u6e90\u57df\u56fe\u7247\u7279\u5f81g_s\u4e3a\u4f8b\uff1a $$ \\mathcal L_{cmp}=\\sum_{i=1}^{N_k}||m_p-g^i_{s_k}||_2 $$  \u5176\u4e2d\uff0cN_k\u8868\u793a\u8be5\u7279\u5f81\u56fe\u4e2d\u5c5e\u4e8e\u7b2ck\u7c7b\u5bf9\u8c61\u7279\u5f81\u5411\u91cf\u7684\u4e2a\u6570\uff0c\u7d22\u5f15p\u662fg^i\u7684\u4e00\u4e2a\u51fd\u6570\uff0c\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ p=\\mathop{\\arg\\max}_{j\\in N_m}\\quad q^{(i,j)} $$  \u8fd9\u91cc\u540c\u6837\u53ea\u5229\u7528\u6e90\u57df\u56fe\u50cf\u7684\u7b2ck\u7c7b\u88c1\u526a\u7279\u5f81\u6765\u8ba1\u7b97\u635f\u5931\uff0c\u800c\u5728\u8bb0\u5fc6\u8bfb\u53d6\u7684\u8fc7\u7a0b\u4e2dq\u662f\u9488\u5bf9\u6240\u6709\u50cf\u7d20\u70b9\u7684\uff0c\u56e0\u6b64\u5728\u8ba1\u7b97\u8fd9\u91cc\u7684\u6b63\u5219\u5316\u635f\u5931\u65f6\uff0c\u9700\u8981\u91cd\u65b0\u5bf9\u7b2ck\u7c7b\u7684\u88c1\u526a\u7279\u5f81\u8ba1\u7b97\u4e00\u6b21q\u3002</p> <p>\u2003\u2003\u4e0b\u9762\u7684\u4e00\u81f4\u6027\u635f\u5931\u540c\u6837\u4e5f\u9519\u4e86\uff0c\u4fee\u6539\u540e\uff1a $$ \\mathcal L_{unq}=\\sum_{i=1}^{N_k}[||m_p-g^i_{s_k}||_2-||m_n-g^i_{s_k}||_2+\\alpha]_+ $$  \u5176\u4e2d\uff0c\u7d22\u5f15n\u4e5f\u662fg^i\u7684\u4e00\u4e2a\u51fd\u6570\uff0c\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ n=\\mathop{\\arg\\max}_{j\\in N_m,j\\neq p}\\quad q^{(i,j)} $$  \u2003\u2003\u4e0a\u8ff0\u4fee\u6539\u7ed3\u679c\u5747\u662f\u6309\u7167\u63d0\u51fa\u8fd9\u4e24\u79cd\u635f\u5931\u7684\u8bba\u6587\u91cc\u9762\u7684\u5f62\u5f0f\u4fee\u6539\u7684\u3002</p> <p>\u2003\u2003\u5df2\u7ecf\u53d1\u90ae\u4ef6\u54a8\u8be2\u4e86\uff0c\u6b63\u5728\u7b49\u5f85\u56de\u590d\u2014\u20142022\u5e742\u67085\u65e5</p> <p>In your paper, the calculation of compactness loss is the sum of all memory elements N_m. But in quotation 34, the calculation of compactness loss is the sum of all feature vector N_k. And the summation forms don\u2019t correspond. Why did you change the loss function, and how does it benefit network optimization?</p> <p>\u2003\u2003\u56de\u590d\u5185\u5bb9\uff1a</p> <p>Greetings for the day; Regarding your question, Compactness loss essentially tries to keep the query features and features in the memory bank close to one another. So for a given input feature, it finds the closest memory item and applies MSE loss between them.</p> <p>Regarding the codebase for the memory network, I followed the \u201cLearning Memory-guided Normality for Anomaly Detection\u201d paper and their codebase https://github.com/cvlab-yonsei/MNAD. So the Compactness loss we used in our work is the same as in the above paper.</p> <p>\u56de\u590d\u65f6\u95f4\uff1a2022\u5e742\u670810\u65e5</p> <p>\u56de\u590d\u7684\u540e\u534a\u6bb5\u8bf4\u5230\u8be5\u635f\u5931\u4e0e\u539f\u8bba\u6587\u4e2d\u635f\u5931\u4e00\u81f4\uff0c\u56e0\u6b64\u6211\u611f\u89c9\u6211\u7684\u731c\u60f3\u6ca1\u9519\u3002</p>"},{"location":"domain_adaptive/question/#cst-mcd","title":"CST-MCD","text":"<p>\u2003\u2003\u8bba\u6587\u4e2d\u7684MCD\u6a21\u5757\u539f\u7406\u8fd8\u4e0d\u662f\u5f88\u61c2\uff0c\u6587\u4e2d\u4e5f\u6ca1\u6709\u7ec6\u8bb2\uff0c\u53ea\u662f\u76f4\u63a5\u5c06\u8be5\u6a21\u5757\u5f15\u7528\u8fc7\u6765\u4e86\uff0c\u8fd8\u5f97\u770b\u770b\u539f\u6587\u7406\u89e3\u4e00\u4e0b\uff1a\u300aMaximum Classifier Discrepancy for Unsupervised Domain Adaptation\u300b\u2014\u20142022\u5e742\u670819\u65e5</p> <p>\u2003\u2003\u770b\u5b8c\u539f\u6587\u53d1\u73b0\u8fd9\u79cd\u65b9\u6cd5\u8981\u6bd4\u4f20\u7edf\u5229\u7528\u57df\u5224\u522b\u5668\u5bf9\u9f50\u7279\u5f81\u8981\u9ad8\u6548\u5f88\u591a\uff0c\u4f46\u662f\u539f\u8bba\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u53ea\u9488\u5bf9\u4e8e\u5206\u7c7b\u4efb\u52a1\uff0c\u4e0d\u9002\u7528\u4e8e\u76ee\u6807\u68c0\u6d4b\uff0c\u800c\u8fd9\u7bc7\u8bba\u6587\u6210\u529f\u5730\u5c06\u8be5\u601d\u60f3\u5f15\u7528\u5230\u4e86\u76ee\u6807\u68c0\u6d4b\u4e2d\uff08\u5c06RPN\u548cRPC\u89c6\u4e3a\u4e24\u4e2a\u4e8c\u5206\u7c7b\u5668\uff0c\u533a\u5206\u524d\u666f\u80cc\u666f\uff09\uff0c\u786e\u5b9e\u6709\u5f88\u591a\u5730\u65b9\u503c\u5f97\u5b66\u4e60\u4e00\u4e0b\uff0c\u300aMCD\u8bba\u6587\u7b14\u8bb0\u300b\u2014\u20142022\u5e742\u670826\u65e5</p>"},{"location":"domain_adaptive/question/#atf","title":"ATF","text":"<p>1\u30013.3\u5c0f\u8282\u91cc\u600e\u4e48\u5229\u7528\u4e3b\u7f51\u7edc\u7684\u635f\u5931\u76d1\u63a7\u8f85\u52a9\u7f51\u7edc\uff1f</p> <p>\u2003\u2003\u539f\u6587\u8fd9\u53e5\u8bdd\u8be5\u5982\u4f55\u7406\u89e3\u2014\u2014\u201cIn our implementation, the detection loss for the chief net is reused for the  supervision of the ancillary net\u201d\u3002\u5982\u679c\u7528\u4e3b\u7f51\u635f\u5931\u76d1\u63a7\u8f85\u52a9\u7f51\u635f\u5931\u7684\u8bdd\uff0c\u662f\u4e0d\u662f\u9700\u8981\u6dfb\u52a0\u4e00\u4e2aKL\u6563\u5ea6\u635f\u5931\u6765\u5b9e\u73b0\u76d1\u63a7\u529f\u80fd\uff1f</p> <p>2\u30013.3\u5c0f\u8282\u91cc\u600e\u4e48\u5229\u7528\u8f85\u52a9\u7f51\u7edc\u8c03\u6574\u4e3b\u7f51\u7edc\uff1f</p> <p>\u2003\u2003\u8f85\u52a9\u7f51\u7edc\u53ea\u63a5\u89e6\u6e90\u57df\u6570\u636e\uff0c\u4e0d\u63a5\u89e6\u76ee\u6807\u57df\u6570\u636e\uff0c\u4e0d\u4f1a\u53d7\u5230\u76ee\u6807\u57df\u56fe\u50cf\u5bf9\u9f50\u65f6\u7684\u8d1f\u9762\u5f71\u54cd\uff0c\u56e0\u6b64\u5728\u7f51\u7edc\u8bad\u7ec3\u7684\u8fc7\u7a0b\u4e2d\u8f85\u52a9\u7f51\u7edc\u53ef\u4ee5\u5c06\u6e90\u57df\u671f\u671b\u635f\u5931\\epsilon_S\u964d\u5230\u6700\u4f4e\u3002\u4f46\u662f\u5728\u5b9e\u9645\u7684\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\uff0c\u76ee\u6807\u57df\u56fe\u50cf\u4e0d\u7ecf\u8fc7\u8f85\u52a9\u7f51\u7edc\uff0c\u53ea\u7ecf\u8fc7\u4e3b\u7f51\u7edc\uff0c\u53ea\u5229\u7528\u4e3b\u7f51\u7edc\u8fdb\u884c\u9884\u6d4b\uff0c\u8fd9\u91cc\u4e3a\u4ec0\u4e48\u8981\u964d\u4f4e\u8f85\u52a9\u7f51\u7edc\u7684\u6e90\u57df\u671f\u671b\u635f\u5931\uff1f\u53ea\u770b\u6e90\u7801\u7684\u8bdd\uff0c\u4e3b\u7f51\u7edc\u548c\u8f85\u52a9\u7f51\u7edc\u662f\u4e24\u4e2a\u76f8\u4e92\u72ec\u7acb\u7684\u7f51\u7edc\uff0c\u5e76\u6ca1\u6709\u635f\u5931\u5c06\u4ed6\u4eec\u52a0\u4ee5\u8054\u7cfb\uff0c\u5982\u679c\u662f\u8fd9\u6837\u7684\u8bdd\uff0c\u964d\u4f4e\u8f85\u52a9\u7f51\u7edc\u7684\u6e90\u57df\u671f\u671b\u635f\u5931\u53c8\u6709\u4ec0\u4e48\u610f\u4e49\uff1f\u662f\u4e0d\u662f\u4e3b\u7f51\u548c\u4e2d\u95f4\u5b58\u5728\u67d0\u79cd\u5173\u7cfb\uff0c\u53ef\u4ee5\u901a\u8fc7\u964d\u4f4e\u8f85\u52a9\u7f51\u7edc\u7684\u539f\u671f\u671b\u635f\u5931\u6765\u95f4\u63a5\u964d\u4f4e\u4e3b\u7f51\u7edc\u7684\u671f\u671b\u635f\u5931\uff1f\u800c3.3\u5c0f\u8282\u7b2c\u4e8c\u6bb5\u53c8\u7a81\u7136\u63d0\u5230\u5229\u7528\u8f85\u52a9\u7f51\u7edc\u8c03\u8282\u4e3b\u7f51\u7edc\u5f97\u5230\u7684\u7279\u5f81\uff0c\u4f46\u662f\u6ca1\u6709\u8be6\u7ec6\u8bf4\u660e\uff0c\u6216\u8bb8\u8bba\u6587\u91cc\u4f1a\u6709\u4e00\u4e9b\u9057\u6f0f\uff1f\u800c\u4e14\u8bba\u6587\u91cc\u8fd8\u63d0\u5230\u4e86\u8f85\u52a9\u7f51\u7edc\u53ef\u4ee5\u751f\u6210\u8f85\u52a9\u7684\u76ee\u6807\u7279\u5f81\uff0c\u4f1a\u4e0d\u4f1a\u548c\u8fd9\u4e2a\u6709\u5173\uff1f</p> <p>\u2003\u2003\u4e0a\u9762\u4e24\u4e2a\u95ee\u9898\u5df2\u7ecf\u7ed9\u4f5c\u8005\u53d1\u90ae\u4ef6\u54a8\u8be2\u4e86\uff0c\u6b63\u5728\u7b49\u5f85\u56de\u590d\u2014\u20142022\u5e743\u670823\u65e5</p> <p>\u2460In section 3.3, you mentioned using the detection loss for the chief net to supervise the ancillary net. Does a new loss need to be added to implement this supervisory function?</p> <p>\u2461How to understand \u201cthe ancillary net adjusts the features learned by the target stream of the chief net\u201d in section 3.3. As far as I know, the parameters of the chief network and the parameters of the ancillary network are independent of each other, so how to realize the training of the chief network guided by the auxiliary network?</p> <p>\u2003\u2003\u56de\u590d\u5185\u5bb9\uff1a</p> <p>Thanks for your questions. In the part you presented, we want to explain how the ancillary net improves the adaptability of the model, and how ancillary target samples improve the adjust the decision boundary of the detector. The above two points are the motivation of our work.</p> <p>First, the same detection losses are implemented on both the chief and ancillary net. Both two nets share the same detector for the training such that they are also restricted by the same detector. Therefore, the feature distribution of the two nets becomes similar.</p> <p>Second, features from the chief and ancillary nets are also aligned during the training phase, such that the feature distribution of the ancillary net is similar to the chief net (target domain). So we think the features of the ancillary net can help to adjust the decision boundary of the detector. So that the detector can adapt to the target domain better.</p> <p>If you want more implementation details, the code of our paper is available on:He-Zhenwei/ATF: The code of our ECCV paper: Domain Adaptive Object Detection via Asymmetric Tri-way Faster-RCNN (github.com)</p> <p>\u56de\u590d\u65f6\u95f4\uff1a2022\u5e743\u670823\u65e5\uff08\u4f5c\u8005\u633a\u597d\u7684\uff0c\u534a\u4e2a\u591a\u5c0f\u65f6\u5c31\u7ed9\u6211\u56de\u590d\u4e86\uff09</p> <p>\u2003\u2003\u4ece\u4f5c\u8005\u7684\u56de\u590d\u53ef\u4ee5\u53d1\u73b0\uff0c\u5176\u5b9e\u4e3b\u7f51\u548c\u8f85\u52a9\u7f51\u7edc\u76f4\u63a5\u662f\u6709\u8054\u7cfb\u7684\uff0c\u5e76\u975e\u5b8c\u5168\u72ec\u7acb\uff0c\u901a\u8fc7\u57df\u9002\u5e94\u635f\u5931\u6765\u5c06\u4e24\u4e2a\u7f51\u7edc\u7684\u53c2\u6570\u8054\u7cfb\u8d77\u6765\uff08\u8fd9\u4e00\u5757\u8fd8\u9700\u8981\u597d\u597d\u7406\u89e3\u4e00\u4e0b\uff09\uff0c\u5229\u7528\u5bf9\u6297\u635f\u5931\u5bf9\u9f50\u4e24\u4e2a\u7f51\u7edc\u7684\u7279\u5f81\u5206\u5e03\u3002\u8f85\u52a9\u7f51\u7edc\u4e2d\u6e90\u57df\u7684\u671f\u671b\u98ce\u9669\\epsilon_S\u6700\u4f4e\u65f6\uff0c\u8f85\u52a9\u7f51\u7edc\u6240\u63d0\u53d6\u7684\u7279\u5f81\u5177\u6709\u7ed3\u6784\u6027\u7684\u533a\u522b\uff0c\u4e4b\u540e\u518d\u901a\u8fc7\u57df\u9002\u5e94\u635f\u5931\u95f4\u63a5\u5730\u5c06\u8fd9\u79cd\u63d0\u53d6\u7ed3\u6784\u6027\u533a\u522b\u7279\u5f81\u7684\u80fd\u529b\u8f6c\u79fb\u5230\u4e3b\u7f51\u7edc\u4e2d\uff08\u6267\u884c\u7279\u5f81\u5bf9\u9f50\u64cd\u4f5c\uff09\uff0c\u4ece\u800c\u63d0\u5347\u68c0\u6d4b\u5668\u7684\u7279\u5f81\u63d0\u53d6\u80fd\u529b\uff0c\u8fdb\u4e00\u6b65\u8c03\u6574\u5176\u5224\u5b9a\u8fb9\u754c\uff0c\u6700\u7ec8\u4f7f\u68c0\u6d4b\u5668\u66f4\u597d\u5730\u9002\u5e94\u76ee\u6807\u57df\u3002</p> <p>\u6ce8\uff1a\u4e0a\u8ff0\u5bf9\u539f\u6587\u90e8\u5206\u7684\u7406\u89e3\u4ee5\u53ca\u4fee\u6539\u610f\u89c1\u4ec5\u662f\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u6307\u6b63</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e743\u670823\u65e5</p>"},{"location":"domain_adaptive/sum_domain/","title":"\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u5c0f\u7ed3","text":"<p>\u7531\u4e8e\u6240\u770b\u7684\u8bba\u6587\u76f8\u5bf9\u6709\u9650\uff0c\u56e0\u6b64\u603b\u7ed3\u7684\u65b9\u6cd5\u53ef\u80fd\u4e0d\u5168\u9762\uff0c\u656c\u8bf7\u8c05\u89e3\u3002</p> <p>\u6ce8\uff1a\u5168\u6587\u539f\u521b\uff0c\u672a\u7ecf\u5141\u8bb8\uff0c\u7981\u6b62\u8f6c\u8f7d\uff01</p>"},{"location":"domain_adaptive/sum_domain/#_2","title":"\u6982\u8ff0","text":"<p>\u2003\u2003\u867d\u7136\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u7684\u7814\u7a76\u5df2\u7ecf\u53d6\u5f97\u4e86\u76f8\u5f53\u53ef\u89c2\u7684\u8fdb\u5c55\uff0c\u4f46\u662f\u4f20\u7edf\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u7684\u68c0\u6d4b\u6027\u80fd\u5f80\u5f80\u4f1a\u53d7\u5230\u8bad\u7ec3\u6570\u636e\u5206\u5e03\u7684\u7ea6\u675f\uff0c\u5728\u6d4b\u8bd5\u65f6\uff0c\u53ea\u6709\u6d4b\u8bd5\u6570\u636e\u548c\u8bad\u7ec3\u6570\u636e\u5206\u5e03\u4e00\u81f4\u65f6\uff0c\u68c0\u6d4b\u5668\u7684\u68c0\u6d4b\u6027\u80fd\u624d\u80fd\u8fbe\u5230\u6700\u597d\u3002\u4f46\u662f\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u76ee\u6807\u68c0\u6d4b\u5bb9\u6613\u9762\u4e34\u6765\u81ea\u89c6\u70b9\u3001\u5916\u89c2\u3001\u80cc\u666f\u3001\u5149\u7167\u4ee5\u53ca\u56fe\u50cf\u8d28\u91cf\u7b49\u65b9\u9762\u7684\u5de8\u5927\u5dee\u5f02\uff0c\u53ef\u80fd\u4f1a\u5bfc\u81f4\u8bad\u7ec3\u6570\u636e\u548c\u6d4b\u8bd5\u6570\u636e\u4e4b\u95f4\u5206\u5e03\u4e0d\u4e00\u81f4\uff0c\u5373\u9886\u57df\u504f\u79fb\u95ee\u9898\uff0c\u4ece\u800c\u5f71\u54cd\u68c0\u6d4b\u5668\u7684\u68c0\u6d4b\u6027\u80fd\u3002\u4ee5\u81ea\u52a8\u9a7e\u9a76\u4e3a\u4f8b\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u8bad\u7ec3\u6570\u636e\u5f80\u5f80\u662f\u5728\u6674\u6717\u7684\u5929\u6c14\u4e0b\u6536\u96c6\u7684\uff0c\u4f46\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u4e0d\u53ef\u907f\u514d\u5730\u4f1a\u9047\u5230\u96fe\u5929\u3001\u96e8\u5929\u7b49\u60c5\u51b5\uff0c\u6b64\u7c7b\u590d\u6742\u7684\u5929\u6c14\u5c06\u4f1a\u4e25\u91cd\u5f71\u54cd\u6c7d\u8f66\u5bf9\u524d\u65b9\u7269\u4f53\u7684\u68c0\u6d4b\uff0c\u4e0d\u5229\u4e8e\u5206\u6790\u5f53\u524d\u7684\u8def\u51b5\uff0c\u6700\u7ec8\u4f1a\u5f71\u54cd\u884c\u9a76\u65f6\u7684\u51b3\u7b56\u3002</p> <p> <p></p> <p></p> <p>\u2003\u2003\u9488\u5bf9\u8fd9\u79cd\u8bad\u7ec3\u6570\u636e\u4e0e\u6d4b\u8bd5\u6570\u636e\u5206\u5e03\u4e0d\u4e00\u81f4\uff0c\u5373\u9886\u57df\u504f\u79fb\u7684\u95ee\u9898\uff0c\u4e00\u79cd\u5e38\u89c1\u7684\u89e3\u51b3\u65b9\u6cd5\u5c31\u662f\u9886\u57df\u81ea\u9002\u5e94\u7b97\u6cd5\uff08\u7b80\u79f0\u57df\u9002\u5e94\uff09\uff0c\u901a\u8fc7\u5bf9\u9f50\u4e24\u4e2a\u9886\u57df\u7684\u7279\u5f81\u5206\u5e03\uff0c\u8ba9\u6a21\u578b\u5728\u4e24\u4e2a\u9886\u57df\u56fe\u50cf\u4e0a\u63d0\u53d6\u76f8\u540c\u7684\u7279\u5f81\uff0c\u4f7f\u6a21\u578b\u53ef\u4ee5\u9002\u5e94\u89c6\u89c9\u4e0a\u4e0d\u540c\u4e8e\u8bad\u7ec3\u6570\u636e\u9886\u57df\u7684\u65b0\u9886\u57df\u6570\u636e\uff0c\u4f8b\u5982\uff1a\u5229\u7528\u6674\u5929\u6570\u636e\u8bad\u7ec3\u7684\u68c0\u6d4b\u6a21\u578b\u4e5f\u53ef\u4ee5\u5f88\u597d\u5730\u5e94\u7528\u5230\u96fe\u5929\u4e0b\u7684\u76ee\u6807\u68c0\u6d4b\u573a\u666f\u3002</p> <p>\u2003\u2003\u7b80\u5355\u6765\u8bf4\uff0c\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u53ef\u4ee5\u6982\u62ec\u4e3a\uff1a\u5229\u7528\u9886\u57dfA\u7684\u56fe\u7247\u548c\u6807\u7b7e\u3001\u9886\u57dfB\u7684\u56fe\u7247\u8bad\u7ec3\u6a21\u578b\uff0c\u6d4b\u8bd5\u6a21\u578b\u5728\u9886\u57dfB\u4e0a\u7684\u76ee\u6807\u68c0\u6d4b\u6027\u80fd\uff0c\u5176\u4e2dA\u3001B\u53ef\u4ee5\u5206\u522b\u8868\u793a\u6674\u5929\u548c\u96fe\u5929\u3002</p>"},{"location":"domain_adaptive/sum_domain/#_3","title":"\u65b9\u6cd5\u5c0f\u7ed3","text":""},{"location":"domain_adaptive/sum_domain/#_4","title":"\u4e3b\u8981\u601d\u8def","text":"<p>\u2003\u2003\u57df\u9002\u5e94\u7b97\u6cd5\u7684\u7814\u7a76\u76ee\u6807\u7528\u4e00\u53e5\u8bdd\u6765\u6982\u62ec\u5c31\u662f\uff1a\u5bf9\u9f50\u6e90\u57df\u548c\u76ee\u6807\u57df\u7684\u7279\u5f81\u5206\u5e03\uff0c\u4f7f\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u5728\u9762\u5bf9\u4e0d\u540c\u9886\u57df\u4e0b\u7684\u8f93\u5165\u56fe\u50cf\u65f6\uff0c\u53ef\u4ee5\u63d0\u53d6\u5230\u201c\u5c3d\u53ef\u80fd\u76f8\u540c\u7684\u7279\u5f81\u201d\uff0c\u5373\u57df\u4e0d\u53d8\u7684\u7279\u5f81\uff0c\u8fdb\u4e00\u6b65\u68c0\u6d4b\u5668\u5229\u7528\u57df\u4e0d\u53d8\u7684\u7279\u5f81\u8fdb\u884c\u7269\u4f53\u68c0\u6d4b\u3002</p> <p>\u2003\u2003\u5728\u57df\u9002\u5e94\u4e2d\uff0c\u4e00\u79cd\u5178\u578b\u7684\u65b9\u6cd5\u5c31\u662f\u5229\u7528\u5bf9\u6297\u5b66\u4e60\u6765\u8fdb\u884c\u9886\u57df\u5bf9\u9f50\u3002\u5728\u5bf9\u6297\u5b66\u4e60\u4efb\u52a1\u4e2d\uff0c\u6700\u6838\u5fc3\u7684\u5c31\u662f\u9274\u522b\u635f\u5931L_D\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u4ee5\u51cf\u5c0f\u9274\u522b\u635f\u5931L_D\u4e3a\u76ee\u7684\u53bb\u4f18\u5316\u9274\u522b\u5668\uff0c\u4ece\u800c\u63d0\u5347\u81ea\u5df1\u7684\u9274\u522b\u80fd\u529b\uff0c\u540c\u65f6\u4ee5\u76f8\u53cd\u7684\u65b9\u5f0f\u8bad\u7ec3\u751f\u6210\u5668\uff0c\u4ee5\u589e\u5927\u9274\u522b\u635f\u5931L_D\u4e3a\u76ee\u7684\u53bb\u4f18\u5316\u751f\u6210\u5668\uff0c\u671f\u671b\u751f\u6210\u5668\u6240\u751f\u6210\u7684\u56fe\u50cf\u53ef\u4ee5\u9a97\u8fc7\u9274\u522b\u5668\uff0c\u8fdb\u4e00\u6b65\u95f4\u63a5\u63d0\u5347\u81ea\u5df1\u7684\u56fe\u7247\u751f\u6210\u80fd\u529b\u3002</p> <p>\u2003\u2003\u53c2\u8003\u5bf9\u6297\u5b66\u4e60\u7684\u601d\u8def\uff0c\u5728\u57df\u9002\u5e94\u7b97\u6cd5\u7684\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4e5f\u6709\u4e24\u4e2a\u4efb\u52a1\uff1a\u5f97\u5230\u597d\u7684\u57df\u5206\u7c7b\u5668\uff0c\u53ef\u4ee5\u6b63\u786e\u5224\u65ad\u4e00\u5f20\u56fe\u5c5e\u4e8e\u54ea\u4e2a\u9886\u57df\uff1b\u5e76\u4e14\u8ba9CNN\u4ea7\u751f\u4e0a\u8ff0\u57df\u5206\u7c7b\u5668\u96be\u4ee5\u9274\u522b\u9886\u57df\u5f52\u5c5e\u7684\u7279\u5f81\uff0c\u4e5f\u5c31\u662f\u8ba9\u4e24\u7ec4\u7279\u5f81\u5145\u5206\u5bf9\u9f50\uff0c\u751f\u6210\u57df\u4e0d\u53d8\u7279\u5f81\uff0c\u4ece\u800c\u9a97\u8fc7\u57df\u5206\u7c7b\u5668\uff0c\u8fd9\u91cc\u53ef\u4ee5\u628a\u57df\u5206\u7c7b\u5668\u548cCNN\u5206\u522b\u770b\u6210\u9274\u522b\u5668\u548c\u751f\u6210\u5668\u3002\u5bf9\u4e8e\u6700\u4f18\u7684\u57df\u5206\u7c7b\u5668\uff0c\u9762\u5bf9\u4e0d\u540c\u9886\u57df\u7684\u56fe\u7247\u7279\u5f81\uff0c\u5206\u7c7b\u5668\u53ef\u4ee5\u5f88\u597d\u5730\u505a\u51fa\u51b3\u7b56\uff0c\u5982\u679c\u6b64\u65f6\u5bf9\u4e8e\u4e00\u7ec4\u7279\u5f81\uff0c\u5206\u7c7b\u5668\u96be\u4ee5\u505a\u51fa\u51b3\u7b56\uff0c\u8bf4\u660e\u8be5\u7279\u5f81\u5df2\u7ecf\u4e0d\u5177\u6709\u539f\u9886\u57df\u7684\u7279\u70b9\uff0c\u5c5e\u4e8e\u4e2d\u548c\u4e86\u4e24\u4e2a\u9886\u57df\u7279\u70b9\u7684\u65b0\u7279\u5f81\uff0c\u6211\u4eec\u6700\u7ec8\u7684\u76ee\u7684\u5c31\u662f\u8ba9CNN\u53ef\u4ee5\u63d0\u53d6\u5230\u8fd9\u79cd\u7279\u5f81\u3002</p> <p>\u6ce8\uff1a\u96be\u4ee5\u505a\u51fa\u51b3\u7b56\u5e94\u8be5\u5bf9\u5e94\u4e24\u4e2a\u9884\u6d4b\u6982\u7387\u90fd\u63a5\u8fd10.5\uff08\u57df\u5206\u7c7b\u5668\u662f\u4e8c\u5206\u7c7b\uff09\uff0c\u5982\u679c\u662f\u5b8c\u5168\u9519\u8bef\u7684\u9884\u6d4b\uff0c\u6bd4\u5982S\u57df\u56fe\u7247\u9884\u6d4b\u4e3aS\u57df\u7684\u6982\u7387\u63a5\u8fd10\u3001\u9884\u6d4b\u4e3aT\u57df\u7684\u6982\u7387\u63a5\u8fd11\uff0c\u5219\u8bf4\u660e\u7f51\u7edc\u7684\u4f18\u5316\u8fc7\u7a0b\u6709\u95ee\u9898\u3002</p> <p>\u2003\u2003\u5bf9\u6b64\u9700\u8981\u989d\u5916\u505a\u4e24\u6b65\u64cd\u4f5c\uff1a\u5728\u539f\u59cb\u76ee\u6807\u68c0\u6d4b\u7f51\u7edc\u4e2d\u5f15\u51fa\u4e00\u4e2a\u65b0\u7684\u5206\u652f\u2014\u2014\u57df\u5206\u7c7b\u5668\uff0c\u4ee5\u63d0\u53d6\u5230\u7684\u7279\u5f81\u4f5c\u4e3a\u8f93\u5165\uff0c\u5224\u65ad\u8be5\u7279\u5f81\u5c5e\u4e8e\u54ea\u4e2a\u9886\u57df\uff0c\u540c\u65f6\u518d\u8bbe\u8ba1\u57df\u5206\u7c7b\u635f\u5931\uff08\u5bf9\u5e94\u9274\u522b\u635f\u5931\uff09\uff0c\u8be5\u635f\u5931\u4ee5\u76f8\u53cd\u7684\u65b9\u5f0f\u4f18\u5316\u57df\u5206\u7c7b\u5668\u548cCNN\uff0c\u4ee5\u964d\u4f4e\u5206\u7c7b\u635f\u5931\u7684\u76ee\u7684\u4f18\u5316\u5206\u7c7b\u5668\uff0c\u4ee5\u63d0\u9ad8\u5206\u7c7b\u635f\u5931\u7684\u76ee\u7684\u4f18\u5316CNN\uff0c\u5728\u63d0\u5347\u57df\u5206\u7c7b\u5668\u5206\u7c7b\u80fd\u529b\u7684\u540c\u65f6\u4fc3\u8fdbCNN\u63d0\u53d6\u57df\u4e0d\u53d8\u7279\u5f81\uff0c\u4e8c\u8005\u76f8\u4e92\u4fc3\u8fdb\uff0c\u5171\u540c\u4f18\u5316\u3002\u5728\u5b9e\u73b0\u8fc7\u7a0b\u4e2d\uff0c\u6700\u5e38\u7528\u7684\u65b9\u6cd5\u5c31\u662f\u68af\u5ea6\u53cd\u8f6c\u6cd5\uff0c\u5c06\u68af\u5ea6\u53cd\u8f6c\u5c42\uff08GRL\uff09\u5d4c\u5165CNN\u4e2d\uff0c\u68af\u5ea6\u56de\u4f20\u5230\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u65f6\u505a\u4e00\u6b21\u53cd\u8f6c\uff0c\u53d8\u4e3a\u539f\u6765\u7684\u76f8\u53cd\u6570\uff0c\u4ece\u800c\u5b9e\u73b0\u53cd\u8f6c\u4f18\u5316\u76ee\u7684\u7684\u4f5c\u7528\u3002</p> <p>\u2003\u2003\u8bba\u6587\u300aDA Faster\u300b\u9996\u5148\u63d0\u51fa\u4e86\u57fa\u4e8eFaster R-CNN\u7684\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\uff0c\u8bbe\u8ba1\u4e86\u56fe\u50cf\u7ea7\u522b\u7684\u81ea\u9002\u5e94\u6a21\u5757\u548c\u5b9e\u4f8b\u7ea7\u522b\u7684\u81ea\u9002\u5e94\u6a21\u5757\uff0c\u5176\u4e2d\uff0c\u5728\u56fe\u50cf\u7ea7\u522b\u7684\u81ea\u9002\u5e94\u6a21\u5757\u4e2d\uff0c\u63d0\u53d6\u4e3b\u5e72\u7f51\u7edc\u6700\u540e\u4e00\u5c42\u7684\u7279\u5f81\uff0c\u9010\u50cf\u7d20\u70b9\u5224\u65ad\u9886\u57df\u5f52\u5c5e\uff0c\u5728\u5b9e\u4f8b\u7ea7\u81ea\u9002\u5e94\u6a21\u5757\u4e2d\uff0c\u63d0\u53d6ROI Pooling\u6240\u5f97\u5230\u7684\u5b9e\u4f8b\u7279\u5f81\uff0c\u9010\u5b9e\u4f8b\u5224\u65ad\u9886\u57df\u5f52\u5c5e\uff0c\u4e24\u79cd\u57df\u5206\u7c7b\u635f\u5931\u4ece\u4e24\u4e2a\u89d2\u5ea6\u4f18\u5316\u7f51\u7edc\u3002\u540c\u65f6\u8fd8\u8bbe\u8ba1\u4e86\u4e00\u81f4\u6027\u6b63\u5219\u5316\u635f\u5931\uff0c\u7528\u4e8e\u9f13\u52b1\u4e0d\u540c\u6c34\u5e73\u7684\u57df\u5206\u7c7b\u5668\u5177\u6709\u4e00\u81f4\u7684\u9886\u57df\u9884\u6d4b\u7ed3\u679c\uff0c\u4ece\u800c\u63d0\u9ad8\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002</p> <p> <p></p> <p></p> <p>\u6ce8\uff1a\u50cf\u7d20\u7ea7\u522b\u7684\u9886\u57df\u5bf9\u9f50\u6a21\u5757\u548c\u5b9e\u4f8b\u7ea7\u522b\u7684\u9886\u57df\u5bf9\u9f50\u6a21\u5757\u662f\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u4e2d\u5e38\u7528\u7684\u57fa\u7840\u6a21\u5757\uff0c\u540e\u9762\u7684\u5f88\u591a\u7b97\u6cd5\u90fd\u5c06\u8fd9\u79cd\u5bf9\u9f50\u65b9\u6cd5\u4f5c\u4e3a\u6700\u57fa\u672c\u7684\u7279\u5f81\u5bf9\u9f50\u7b56\u7565\uff0c\u5e76\u4e14\u5728\u6b64\u57fa\u7840\u4e0a\u505a\u6539\u8fdb\u3002</p> <p>\u2003\u2003\u9886\u57df\u5bf9\u9f50\u6a21\u5757\u7684\u5f15\u5165\u867d\u7136\u53ef\u4ee5\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u63d0\u5347\u7f51\u7edc\u63d0\u53d6\u8de8\u57df\u4e0d\u53d8\u7279\u5f81\u7684\u80fd\u529b\u3001\u7f13\u89e3\u9886\u57df\u5dee\u5f02\u5bfc\u81f4\u7684\u95ee\u9898\uff0c\u4f46\u4e5f\u4f1a\u5e26\u6765\u4e00\u4e2a\u95ee\u9898\u2014\u2014\u5bb9\u6613\u626d\u66f2\u539f\u59cb\u6570\u636e\u7684\u7279\u5f81\u5206\u5e03\uff0c\u7834\u574f\u4e24\u4e2a\u9886\u57df\u4e4b\u95f4\u7684\u7ed3\u6784\u6027\u533a\u522b\u7279\u5f81\uff0c\u4ece\u800c\u964d\u4f4e\u6a21\u578b\u7684\u68c0\u6d4b\u6027\u80fd\uff0c\u6700\u76f4\u63a5\u7684\u4f53\u73b0\u5c31\u662fRPN\u6a21\u5757\u4e0d\u80fd\u5f88\u597d\u5730\u6839\u636eCNN\u6240\u63d0\u53d6\u7684\u7279\u5f81\u5224\u65ad\u524d\u666f\u951a\u70b9\u548c\u80cc\u666f\u951a\u70b9\u3002\u901a\u4fd7\u6765\u8bb2\uff0c\u5f53\u53ea\u7528\u5e26\u6709\u771f\u5b9e\u6807\u7b7e\u7684\u6e90\u57df\u8bad\u7ec3\u7f51\u7edc\u65f6\uff0c\u7f51\u7edc\u5728\u6807\u7b7e\u7684\u76d1\u7763\u4e0b\uff0c\u53ef\u4ee5\u63d0\u53d6\u8fa8\u522b\u6027\u660e\u663e\u7684\u6e90\u57df\u7279\u5f81\uff0c\u4f46\u5f53\u5f15\u5165\u65e0\u6807\u7b7e\u7684\u76ee\u6807\u57df\u6570\u636e\u65f6\uff0c\u4e3a\u4e86\u7b26\u5408\u57df\u5206\u7c7b\u635f\u5931\u7684\u76ee\u7684\uff0c\u6a21\u578b\u5728\u5f3a\u5236\u5bf9\u9f50\uff08\u6df7\u6dc6\uff09\u4e24\u4e2a\u9886\u57df\u7279\u5f81\u7684\u540c\u65f6\uff0c\u53ef\u80fd\u4f1a\u727a\u7272\u6a21\u578b\u7684\u7279\u5f81\u63d0\u53d6\u80fd\u529b\uff0c\u8fdb\u4e00\u6b65\u964d\u4f4e\u6a21\u578b\u7684\u68c0\u6d4b\u6027\u80fd\u3002</p> <p>\u2003\u2003\u4e3a\u4e86\u65b9\u4fbf\u8d77\u89c1\uff0c\u4e0b\u6587\u4e2d\u5c06\u7f51\u7edc\u4ea7\u751f\u57df\u4e0d\u53d8\u7279\u5f81\u7684\u80fd\u529b\u7b80\u79f0\u4e3a\u53ef\u8f6c\u79fb\u6027\uff0c\u8f6c\u79fb\u6027\u8d8a\u5f3a\uff0c\u8868\u793a\u6a21\u578b\u5728\u8be5\u533a\u57df\u8d8a\u5bb9\u6613\u8de8\u57df\u4ea7\u751f\u76f8\u540c\u7684\u7279\u5f81\uff0c\u5c06\u7f51\u7edc\u5bf9\u7269\u4f53\u7684\u68c0\u6d4b\u80fd\u529b\u7b80\u79f0\u4e3a\u53ef\u8fa8\u522b\u6027\uff0c\u53ef\u8fa8\u522b\u6027\u8d8a\u5f3a\uff0c\u8868\u660e\u6a21\u578b\u6240\u63d0\u53d6\u7684\u7279\u5f81\u8d8a\u5177\u6709\u7c7b\u522b\u8fa8\u8bc6\u5ea6\uff0c\u5373\u6a21\u578b\u5bf9\u7269\u4f53\u68c0\u6d4b\u7684\u80fd\u529b\u8d8a\u5f3a\uff0c\u5e73\u8861\u7f51\u7edc\u53ef\u8f6c\u79fb\u6027\u4e0e\u53ef\u8fa8\u522b\u6027\u4e8c\u8005\u4e4b\u95f4\u7684\u77db\u76fe\u662f\u4f18\u5316\u57df\u9002\u5e94\u7b97\u6cd5\u7684\u6839\u672c\u65b9\u5411\u3002</p>"},{"location":"domain_adaptive/sum_domain/#_5","title":"\u5dee\u5f02\u5bf9\u9f50","text":"<p>\u2003\u2003\u4f20\u7edf\u7684\u5bf9\u9f50\u7f51\u7edc\u6267\u884c\u7684\u662f\u65e0\u5dee\u5f02\u7684\u5bf9\u9f50\uff0c\u4e5f\u5c31\u662f\u4ee5\u76f8\u540c\u7684\u5bf9\u9f50\u89c4\u5219\u6765\u5f3a\u5236\u5bf9\u9f50\u6240\u6709\u7279\u5f81\u6570\u636e\u7684\u9886\u57df\u5dee\u5f02\uff0c\u4f46\u73b0\u5b9e\u5e94\u7528\u4e2d\uff0c\u6267\u884c\u7c7b\u4f3c\u65e0\u5dee\u522b\u7684\u5bf9\u9f50\u7b56\u7565\u53ef\u80fd\u4f1a\u635f\u5bb3\u6a21\u578b\u7684\u68c0\u6d4b\u6027\u80fd\uff0c\u56e0\u4e3a\u7279\u5f81\u6570\u636e\u7684\u76f8\u5bf9\u91cd\u8981\u6027\u4e0d\u540c\uff0c\u5e76\u4e14\u4e0d\u540c\u7c7b\u522b\u7684\u7269\u4f53\u4e5f\u5305\u542b\u4e0d\u540c\u7684\u7279\u5f81\u4fe1\u606f\uff0c\u56e0\u6b64\u6211\u4eec\u9700\u8981\u5bf9\u4e0d\u540c\u7684\u7279\u5f81\u6570\u636e\u6267\u884c\u201d\u5dee\u5f02\u5bf9\u9f50\u201c\u3002</p> <p>\u2003\u2003\u7279\u5f81\u6570\u636e\u5bf9\u9f50\u7684\u5dee\u5f02\u6700\u76f4\u63a5\u4f53\u73b0\u5728\u57df\u5206\u7c7b\u635f\u5931\u7684\u4e0d\u540c\u4e0a\uff0c\u5bf9\u4e8e\u8f83\u5c0f\u7684\u9886\u57df\u504f\u79fb\uff0c\u76ee\u6807\u57df\u6837\u672c\u7279\u5f81\u9760\u8fd1\u6e90\u57df\u6837\u672c\u7279\u5f81\uff0c\u57df\u5206\u7c7b\u5668\u5f80\u5f80\u5f88\u96be\u505a\u51fa\u5224\u65ad\uff0c\u5e76\u4e14\u8fd9\u4e9b\u533a\u57df\u4f1a\u5e72\u6270\u76ee\u6807\u68c0\u6d4b\u5668\u7684\u6027\u80fd\uff0c\u9700\u8981\u6267\u884c\u5f3a\u5bf9\u9f50\uff1b\u5bf9\u4e8e\u6bd4\u8f83\u5927\u7684\u9886\u57df\u504f\u79fb\uff0c\u76ee\u6807\u57df\u6837\u672c\u7279\u5f81\u8fdc\u79bb\u6e90\u57df\u6837\u672c\u7279\u5f81\uff0c\u5982\u573a\u666f\u5206\u5e03\u6216\u8005\u5929\u6c14\u7684\u5dee\u5f02\uff0c\u57df\u5206\u7c7b\u5668\u5f80\u5f80\u5f88\u597d\u5224\u65ad\u9886\u57df\u5f52\u5c5e\uff0c\u56e0\u6b64\u8fd9\u4e9b\u533a\u57df\u5bf9\u68c0\u6d4b\u6027\u80fd\u7684\u5e72\u6270\u8f83\u4f4e\uff0c\u5bf9\u6b64\uff0c\u5982\u679c\u4ee5\u76f8\u540c\u7684\u89c4\u5219\u5f3a\u5236\u5bf9\u9f50\u5dee\u5f02\u5927\u7684\u533a\u57df\uff0c\u4f1a\u635f\u5bb3\u6a21\u578b\u7684\u68c0\u6d4b\u6027\u80fd\u3002\u6211\u4eec\u671f\u671b\u7f51\u7edc\u53ef\u4ee5\u91cd\u70b9\u5173\u6ce8\u5177\u6709\u5c0f\u9886\u57df\u504f\u79fb\u7684\u6837\u672c\uff0c\u8fd9\u4e9b\u533a\u57df\u5177\u6709\u76f8\u4f3c\u7684\u7279\u5f81\u5206\u5e03\uff0c\u5e76\u4e14\u5ffd\u7565\u9886\u57df\u504f\u79fb\u5927\u7684\u6837\u672c\uff0c\u5bf9\u6b64\u5728Strong-Weak\u7b97\u6cd5\u4e2d\uff0c\u4f5c\u8005\u5f15\u5165\u7126\u70b9\u635f\u5931\uff08Focal loss\uff09\uff0c\u6839\u636e\u5206\u7c7b\u7684\u96be\u6613\u7a0b\u5ea6\u5bf9\u6700\u521d\u7684\u5168\u5c40\u57df\u5206\u7c7b\u635f\u5931\u505a\u52a0\u6743\u5904\u7406\uff0c\u5c06\u66f4\u591a\u7684\u6743\u91cd\u8d4b\u4e88\u96be\u4ee5\u5206\u7c7b\u7684\u6837\u672c\u4e0a\uff0c\u5e76\u4e14\u964d\u4f4e\u6613\u5206\u7c7b\u6837\u672c\u7684\u57df\u5206\u7c7b\u635f\u5931\u3002</p>"},{"location":"domain_adaptive/sum_domain/#_6","title":"\u524d\u666f\u5bf9\u9f50","text":"<p>\u2003\u2003\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u5728\u68c0\u6d4b\u7269\u4f53\u7684\u65f6\u5019\uff0c\u9700\u8981\u5bf9\u7269\u4f53\u5b9e\u73b0\u5b9a\u4f4d\u529f\u80fd\uff0c\u56e0\u6b64\u8981\u7740\u91cd\u8003\u8651\u524d\u666f\u533a\u57df\u7684\u7279\u5f81\u4fe1\u606f\uff0c\u4e0d\u540c\u9886\u57df\u4e4b\u95f4\u7684\u524d\u666f\u8981\u6bd4\u80cc\u666f\u5171\u4eab\u66f4\u591a\u7684\u5171\u540c\u7279\u5f81\uff0c\u56e0\u6b64\u7740\u91cd\u51f8\u663e\u524d\u666f\u533a\u57df\u4fe1\u606f\u7684\u91cd\u8981\u6027\u5bf9\u63d0\u5347\u6a21\u578b\u7684\u8de8\u57df\u68c0\u6d4b\u6027\u80fd\u6709\u91cd\u8981\u7684\u5f71\u54cd\u3002</p> <p>\u2003\u2003\u5728Faster R-CNN\u4e2d\uff0cRPN\u6a21\u5757\u5c31\u5145\u5f53\u68c0\u6d4b\u524d\u666f\u533a\u57df\u7684\u4f5c\u7528\uff08\u5176\u5b9eRPN\u6a21\u5757\u4e5f\u662f\u4e00\u79cd\u6ce8\u610f\u529b\u673a\u5236\uff09\uff0c\u5728Coarse-to-Fine\u7b97\u6cd5\u4e2d\uff0c\u4f5c\u8005\u5c31\u5229\u7528\u4e86\u8fd9\u4e00\u7279\u6027\uff0c\u9996\u5148\u63d0\u53d6RPN\u6a21\u5757\u8f93\u51fa\u7684\u7279\u5f81\u56fe\uff0c\u6cbf\u901a\u9053\u65b9\u5411\u76f8\u52a0\u5f97\u5230\u7a7a\u95f4\u6ce8\u610f\u529b\u56fe\uff0c\u56fe\u4e0a\u7684\u6570\u636e\u5206\u5e03\u8868\u793a\u4e86\u7279\u5f81\u7684\u7a7a\u95f4\u5206\u5e03\uff0c\u6700\u540e\u5229\u7528\u8be5\u56fe\u5bf9\u7279\u5f81\u6570\u636e\u7684\u5bf9\u9f50\u635f\u5931\u505a\u52a0\u6743\u5904\u7406\uff0c\u589e\u5927\u524d\u666f\u533a\u57df\u7684\u5bf9\u9f50\u635f\u5931\uff0c\u63d0\u9ad8\u4f18\u5316\u529b\u5ea6\uff0cCST-MCD\u7b97\u6cd5\u4e5f\u7528\u5230\u4e86\u8fd9\u4e00\u601d\u60f3\u3002</p> <p> <p></p> <p></p> <p>\u2003\u2003\u9664\u4e86\u4e0a\u8ff0\u5bf9\u524d\u666f\u533a\u57df\u7684\u663e\u5f0f\u5b9a\u4f4d\uff0c\u8fd8\u6709\u4e00\u79cd\u65b9\u6cd5\u5c31\u662f\u9690\u5f0f\u5b9a\u4f4d\uff0c\u7528\u4e8e\u95f4\u63a5\u63d0\u5347\u6a21\u578b\u7684\u5b9a\u4f4d\u80fd\u529b\uff0c\u800c\u975e\u76f4\u63a5\u5f97\u5230\u5b9a\u4f4d\u7ed3\u679c\u3002\u7531\u4e8e\u5206\u7c7b\u7f51\u7edc\u5177\u6709\u4e00\u5b9a\u7684\u5f31\u5b9a\u4f4d\u80fd\u529b\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u5b9a\u4f4d\u524d\u666f\u7684\u7269\u4f53\u533a\u57df\uff0c\u56e0\u6b64\u53ef\u4ee5\u501f\u52a9\u5206\u7c7b\u5668\u6765\u8ba9\u7f51\u7edc\u4ece\u56fe\u50cf\u7684\u6574\u4f53\u5b66\u4e60\u5bf9\u8c61\u7ea7\u6982\u5ff5\uff0c\u63d0\u5347\u524d\u666f\u5b9a\u4f4d\u7684\u80fd\u529b\uff0c\u5728ICR-CCR\u7b97\u6cd5\u4e2d\uff0c\u4f5c\u8005\u5728\u68c0\u6d4b\u5668\u7684\u4e3b\u5e72\u7f51\u7edc\u6dfb\u52a0\u4e86\u4e00\u4e2a\u591a\u6807\u7b7e\u5206\u7c7b\u5668\u5206\u652f\uff0c\u5e76\u4e14\u5229\u7528\u6e90\u57df\u56fe\u50cf\u8bad\u7ec3\u8be5\u5206\u7c7b\u5668\uff0c\u968f\u7740\u5206\u7c7b\u5668\u7684\u4f18\u5316\uff0c\u7f51\u7edc\u53ef\u4ee5\u5b66\u4e60\u80fd\u591f\u6fc0\u6d3b\u5bf9\u8c61\u76f8\u5173\u533a\u57df\u7684\u7c7b\u522b\u7279\u5f81\uff0c\u964d\u4f4e\u4e86\u5339\u914d\u80cc\u666f\u533a\u57df\u7684\u98ce\u9669\u3002\u53e6\u5916\uff0c\u5f15\u5165\u7684\u591a\u5206\u7c7b\u5668\u6b63\u597d\u53ef\u4ee5\u548c\u68c0\u6d4b\u5668\u7684\u5206\u7c7b\u6a21\u5757\u76f8\u4e92\u4fc3\u8fdb\uff0c\u4e8c\u8005\u540c\u65f6\u5177\u6709\u9884\u6d4b\u56fe\u50cf\u4e2d\u7269\u4f53\u7c7b\u522b\u7684\u80fd\u529b\uff0c\u56e0\u6b64\u53ef\u4ee5\u7ed3\u5408\u4e8c\u8005\u7684\u9884\u6d4b\u7ed3\u679c\uff0c\u5f97\u5230\u524d\u666f\u5b9e\u4f8b\u68c0\u6d4b\u7684\u96be\u6613\u7a0b\u5ea6\uff0c\u5229\u7528\u96be\u6613\u7a0b\u5ea6\u5bf9\u5b9e\u4f8b\u7684\u57df\u5206\u7c7b\u635f\u5931\u505a\u52a0\u6743\uff0c\u63d0\u9ad8\u96be\u68c0\u6d4b\u5b9e\u4f8b\u7684\u5bf9\u9f50\u529b\u5ea6\uff0c\u8fdb\u4e00\u6b65\u63d0\u5347\u6a21\u578b\u9886\u57df\u9002\u5e94\u80fd\u529b\u3002</p>"},{"location":"domain_adaptive/sum_domain/#_7","title":"\u7c7b\u522b\u5bf9\u9f50","text":"<p>\u2003\u2003\u5728\u76ee\u6807\u68c0\u6d4b\u7f51\u7edc\u4e2d\uff0c\u901a\u5e38\u6709\u591a\u79cd\u7c7b\u578b\u7684\u68c0\u6d4b\u5bf9\u8c61\uff0c\u5e76\u4e14\u6bcf\u4e2a\u7c7b\u522b\u90fd\u6709\u81ea\u5df1\u7684\u6570\u636e\u5206\u5e03\uff0c\u4f46\u662f\u4ee5\u5f80\u7684\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u5ffd\u7565\u4e86\u8fd9\u4e00\u95ee\u9898\uff0c\u6267\u884c\u7684\u5927\u591a\u90fd\u662f\u4e0d\u8003\u8651\u7c7b\u522b\u7684\u7279\u5f81\u5bf9\u9f50\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5bb9\u6613\u5bfc\u81f4\u7c7b\u4e4b\u95f4\u7279\u5f81\u7684\u6df7\u6dc6\uff0c\u8fdb\u4e00\u6b65\u7834\u574f\u7f51\u7edc\u7279\u5f81\u7684\u53ef\u8fa8\u522b\u6027\uff0c\u5f71\u54cd\u6a21\u578b\u7684\u68c0\u6d4b\u6027\u80fd\u3002\u5229\u7528\u5bf9\u8c61\u7684\u7c7b\u522b\u4fe1\u606f\u53ef\u4ee5\u8fdb\u4e00\u6b65\u7ec6\u5316\u5148\u524d\u7684\u7279\u5f81\u9002\u5e94\uff0c\u5bf9\u6bcf\u4e2a\u7c7b\u522b\u6267\u884c\u4e0d\u540c\u7684\u7279\u5f81\u9002\u5e94\u6709\u52a9\u4e8e\u4fdd\u6301\u6a21\u578b\u539f\u672c\u7684\u7279\u5f81\u63d0\u53d6\u80fd\u529b\u3002</p> <p>\u2003\u2003\u60f3\u8981\u6267\u884c\u7c7b\u76f8\u5173\u7684\u5bf9\u9f50\uff0c\u4e00\u79cd\u6700\u7b80\u5355\u7684\u601d\u8def\u5c31\u662f\u4e3a\u6bcf\u4e2a\u7c7b\u522b\u5355\u72ec\u8bbe\u7acb\u4e00\u4e2a\u57df\u5206\u7c7b\u5668\u3002\u4f46\u662f\u7531\u4e8e\u76ee\u6807\u57df\u7f3a\u5c11\u8fb9\u754c\u6846\u4ee5\u53ca\u7c7b\u522b\u6807\u7b7e\uff0c\u65e0\u6cd5\u5b9a\u4f4d\u76ee\u6807\u57df\u4e2d\u7684\u7c7b\u522b\u5b9e\u4f8b\u7279\u5f81\uff0c\u56e0\u6b64\u5982\u4f55\u5229\u7528\u76ee\u6807\u57df\u56fe\u7247\u4f18\u5316\u7c7b\u76f8\u5173\u7684\u57df\u5206\u7c7b\u5668\u5c31\u6210\u4e86\u6700\u5927\u7684\u95ee\u9898\uff0c\u7f3a\u5c11\u76ee\u6807\u57df\u7c7b\u522b\u7279\u5f81\uff0c\u4e0d\u80fd\u76f4\u63a5\u4f18\u5316\u57df\u5206\u7c7b\u5668\u3002\u5728\u7b97\u6cd5MeGA-CDA\u4e2d\uff0c\u4f5c\u8005\u8bbe\u8ba1\u4e86\u8bb0\u5fc6\u6a21\u5757\u6765\u5b58\u50a8\u4e0d\u540c\u7c7b\u522b\u5bf9\u8c61\u7684\u539f\u578b\u7279\u5f81\uff0c\u8fd9\u4e9b\u539f\u578b\u7279\u5f81\u53ef\u4ee5\u5f88\u597d\u5730\u63cf\u8ff0\u4e0d\u540c\u7c7b\u522b\u7269\u4f53\u7684\u7279\u70b9\uff0c\u53ea\u5229\u7528\u6e90\u57df\u4e2d\u7684\u7c7b\u522b\u7279\u5f81\u6570\u636e\u53bb\u66f4\u65b0\u8bb0\u5fc6\u6a21\u5757\u4e2d\u7684\u539f\u578b\u7279\u5f81\uff0c\u5c06\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u7c7b\u76f8\u5173\u7279\u5f81\u5199\u5165\u8bb0\u5fc6\u6a21\u5757\u3002\u5b9e\u9645\u5e94\u7528\u65f6\u53d6\u51fa\u8bb0\u5fc6\u6a21\u5757\u4e2d\u7684\u539f\u578b\u7279\u5f81\uff0c\u518d\u7ed3\u5408\u56fe\u50cf\u7279\u5f81\u5f97\u5230\u7c7b\u522b\u6ce8\u610f\u529b\u56fe\uff0c\u7528\u4e8e\u5b9a\u4f4d\u6307\u5b9a\u7c7b\u522b\u7684\u7279\u5f81\u6570\u636e\uff0c\u6700\u540e\u5229\u7528\u8fd9\u4e9b\u7279\u5f81\u4f18\u5316\u7c7b\u76f8\u5173\u7684\u57df\u5206\u7c7b\u5668\u3002</p> <p> <p></p> <p></p> <p>\u2003\u2003\u4e3a\u4e86\u907f\u514d\u7531\u4e8e\u7f3a\u5c11\u76ee\u6807\u57df\u6807\u7b7e\u6240\u5e26\u6765\u7684\u4f18\u5316\u95ee\u9898\uff0c\u4e00\u4e9b\u7b97\u6cd5\u5e76\u6ca1\u6709\u76f4\u63a5\u9009\u62e9\u4e3a\u6bcf\u4e2a\u7c7b\u522b\u5355\u72ec\u8bbe\u7acb\u57df\u5206\u7c7b\u5668\uff0c\u800c\u662f\u91c7\u7528\u5176\u4ed6\u7684\u7279\u5f81\u5bf9\u9f50\u65b9\u6cd5\u3002\u4f8b\u5982\u5728Coarse-to-Fine\u4e2d\uff0c\u4f5c\u8005\u53c2\u8003\u539f\u578b\u7f51\u7edc\uff0c\u5728\u4e24\u4e2a\u9886\u57df\u4e2d\u4f9d\u6b21\u4e3a\u6bcf\u4e2a\u5b9e\u4f8b\u7c7b\u522b\u5355\u72ec\u8bbe\u7acb\u4e86\u4e00\u4e2a\u539f\u578b\uff08\u4e00\u5171\u67092\\times K\u4e2a\u539f\u578b\uff09\uff0c\u7b80\u5355\u6765\u8bf4\u5c31\u662f\u201c\u7c7b\u522b\u7279\u5f81\u201d\uff0c\u5e76\u4e14\u91c7\u7528\u201c\u52a8\u91cf\u66f4\u65b0\u6cd5\u201d\u66f4\u65b0\u539f\u578b\uff0c\u6700\u540e\u6bcf\u4e2a\u539f\u578b\u53ef\u4ee5\u5f88\u597d\u5730\u8868\u793a\u6307\u5b9a\u9886\u57df\u6307\u5b9a\u7c7b\u522b\u7684\u7279\u5f81\u3002\u5728\u6bcf\u6b21\u8fed\u4ee3\u4f18\u5316\u7684\u8fc7\u7a0b\u4e2d\uff0c\u5bf9\u9886\u57df\u4e4b\u95f4\u7684\u539f\u578b\u7279\u5f81\u9010\u7c7b\u522b\u505al_2\u635f\u5931\uff0c\u51cf\u5c0f\u9886\u57df\u4e4b\u95f4\u7279\u5f81\u7684\u8ddd\u79bb\uff0c\u8fdb\u4e00\u6b65\u5b9e\u73b0\u7c7b\u522b\u7279\u5f81\u5bf9\u9f50\u3002</p> <p>\u6ce8\uff1a</p> <ul> <li>MeGA-CDA\u7b97\u6cd5\u4e2d\u7684\u539f\u578b\u7279\u5f81\u53ea\u9700\u8981\u6709\u7279\u5b9a\u7684\u7c7b\u522b\u4fe1\u606f\u5373\u53ef\uff0c\u540e\u7eed\u8fd8\u4f1a\u518d\u548c\u9886\u57df\u7279\u5f81\u76f8\u7ed3\u5408\uff0c\u751f\u6210\u6ce8\u610f\u529b\u56fe\uff1bCoarse-to-Fine\u4e2d\u7684\u539f\u578b\u7279\u5f81\u4e0d\u4ec5\u9700\u8981\u5177\u6709\u7c7b\u522b\u4fe1\u606f\uff0c\u8fd8\u9700\u8981\u6709\u6307\u5b9a\u7684\u9886\u57df\u4fe1\u606f\uff0c\u56e0\u6b64\u8bbe\u7acb\u4e86\u4e24\u7ec4\u539f\u578b\uff0c\u8ba9\u540c\u7c7b\u7684\u539f\u578b\u4e0d\u65ad\u9760\u8fd1\uff0c\u4ece\u800c\u5bf9\u9f50\u4e24\u4e2a\u9886\u57df\u7684\u7c7b\u522b\u7279\u5f81\u6570\u636e\uff0c\u6ce8\u610f\u533a\u522b\uff1b</li> <li>\u7531\u4e8e\u76ee\u6807\u57df\u7f3a\u5c11\u6807\u7b7e\uff0c\u5728Coarse-to-Fine\u7b97\u6cd5\u4e2d\uff0c\u91c7\u7528\u7f51\u7edc\u9884\u6d4b\u7684\u8fb9\u754c\u6846\u6765\u88c1\u526a\u5b9e\u4f8b\u7279\u5f81\uff0c\u56e0\u6b64\u8fd9\u91cc\u6240\u7528\u7684\u88c1\u526a\u8fb9\u754c\u6846\u53c8\u6210\u4f2a\u6807\u7b7e\uff0c\u4f2a\u6807\u7b7e\u4e5f\u662f\u4e00\u4e2a\u4f18\u5316\u601d\u8def\uff0c\u5177\u4f53\u89c1\u4e0b\u4e00\u8282\u3002</li> </ul>"},{"location":"domain_adaptive/sum_domain/#_8","title":"\u4f2a\u6807\u7b7e","text":"<p>\u2003\u2003\u5c06\u76ee\u6807\u57df\u56fe\u7247\u4f20\u5165\u68c0\u6d4b\u7f51\u7edc\u5f97\u5230\u9884\u6d4b\u7ed3\u679c\uff0c\u7531\u4e8e\u76ee\u6807\u57df\u6570\u636e\u6ca1\u6709\u6807\u6ce8\uff0c\u56e0\u6b64\u65e0\u6cd5\u786e\u5b9a\u7f51\u7edc\u9884\u6d4b\u5f97\u5230\u7684\u8fb9\u754c\u6846\u662f\u5426\u7cbe\u51c6\uff0c\u5bf9\u4e8e\u8fd9\u79cd\u9884\u6d4b\u7ed3\u679c\uff0c\u79f0\u4e3a\u201c\u4f2a\u6807\u7b7e\u201d\u3002\u6b63\u662f\u56e0\u4e3a\u76ee\u6807\u57df\u6570\u636e\u65e0\u6807\u6ce8\uff0c\u56e0\u6b64\u5927\u591a\u6570\u7b97\u6cd5\u90fd\u9009\u62e9\u4e22\u5f03\u4f2a\u6807\u7b7e\u8fd9\u4e00\u53d8\u91cf\uff0c\u4e0d\u4f1a\u8003\u8651\u7528\u76ee\u6807\u57df\u56fe\u7247\u7684\u9884\u6d4b\u7ed3\u679c\u6765\u8bad\u7ec3\u7f51\u7edc\u7684\u68c0\u6d4b\u6027\u80fd\uff0c\u5ffd\u7565\u4e86\u76ee\u6807\u57df\u6837\u672c\u548c\u6a21\u578b\u51b3\u7b56\u8fb9\u754c\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u6a21\u578b\u4e3a\u4e86\u8ba9\u4e24\u4e2a\u9886\u57df\u7684\u7279\u5f81\u5206\u5e03\u5c3d\u53ef\u80fd\u76f8\u4f3c\uff0c\u7279\u5f81\u63d0\u53d6\u5668\u4f1a\u5728\u51b3\u7b56\u8fb9\u754c\u9644\u8fd1\u751f\u6210\u6a21\u7cca\u7684\u7279\u5f81\uff0c\u4f1a\u635f\u5bb3\u7f51\u7edc\u5bf9\u8fa8\u8bc6\u529b\u7279\u5f81\u7684\u63d0\u53d6\uff0c\u8fd9\u4e5f\u662f\u5bfc\u81f4\u57df\u9002\u5e94\u6a21\u578b\u5728\u76ee\u6807\u57df\u6570\u636e\u4e0a\u53ef\u8fa8\u522b\u6027\u964d\u4f4e\u7684\u4e00\u4e2a\u91cd\u8981\u7684\u539f\u56e0\u3002</p> <p>\u2003\u2003\u867d\u7136\u76ee\u6807\u57df\u7684\u7f51\u7edc\u9884\u6d4b\u7ed3\u679c\u4e0d\u80fd\u76f4\u63a5\u7528\u4e8e\u4f18\u5316\u68c0\u6d4b\u6a21\u578b\uff0c\u4f46\u662f\u6211\u4eec\u53ef\u4ee5\u6316\u6398\u7f51\u7edc\u5404\u4e2a\u6a21\u5757\u7684\u9690\u542b\u5173\u7cfb\uff0c\u5efa\u7acb\u4f18\u5316\u201c\u6865\u6881\u201d\u3002\u5728\u7b97\u6cd5CST-MCD\u4e2d\uff0c\u4f5c\u8005\u6307\u51faFaster R-CNN\u4e2d\u7684RPN\u6a21\u5757\u548cRPC\u6a21\u5757\u5177\u6709\u4e00\u5b9a\u7684\u8054\u7cfb\uff08RPC\u6a21\u5757\u662f\u6307\u7b2c\u4e8c\u4e2a\u9636\u6bb5\u7684\u9884\u6d4b\u6a21\u5757\uff09\uff0c\u4e8c\u8005\u7684\u9884\u6d4b\u5e94\u8be5\u5177\u6709\u4e00\u81f4\u6027\uff0c\u5373\u524d\u666f\u80cc\u666f\u7684\u9884\u6d4b\u7ed3\u679c\u5e94\u8be5\u4e00\u81f4\uff0c\u56e0\u6b64\u53ef\u4ee5\u7528\u4e00\u4e2a\u6a21\u5757\u7684\u8f93\u51fa\u5f53\u6210\u4f2a\u6807\u7b7e\uff0c\u53bb\u8bad\u7ec3\u53e6\u4e00\u4e2a\u6a21\u5757\uff0c\u540c\u65f6\u8fd8\u5229\u7528\u4f2a\u6807\u7b7e\u7684\u201c\u53ef\u4fe1\u5ea6\u201d\u5bf9\u68c0\u6d4b\u635f\u5931\u505a\u4e86\u4e00\u4e2a\u52a0\u6743\u5904\u7406\uff0c\u63d0\u5347\u9ad8\u7f6e\u4fe1\u5ea6\u7684\u635f\u5931\u6743\u91cd\u3002\uff08\u8fd9\u91cc\u5bf9\u68c0\u6d4b\u6027\u80fd\u7684\u8bad\u7ec3\u7b56\u7565\u540c\u65f6\u9002\u7528\u4e8e\u6e90\u57df\u548c\u76ee\u6807\u57df\u56fe\u50cf\uff09</p> <p>\u6ce8\uff1a\u524d\u80cc\u666f\u6982\u7387\u8d8a\u8d8b\u4e8e0.5\uff0c\u5c31\u8d8a\u4e0d\u53ef\u4fe1\u3002</p> <p>\u2003\u2003\u5728\u57df\u9002\u5e94\u5206\u7c7b\u7b97\u6cd5\u4e2d\uff0c\u4e5f\u53ef\u4ee5\u5229\u7528\u4f2a\u6807\u7b7e\u53bb\u63d0\u5347\u6a21\u578b\u7684\u53ef\u8fa8\u522b\u6027\u3002\u5bf9\u4e8e\u6e90\u57df\u7684\u56fe\u7247\uff0c\u7531\u4e8e\u5177\u6709\u771f\u5b9e\u6807\u7b7e\uff0c\u56e0\u6b64\u6a21\u578b\u7684\u51b3\u7b56\u9762\u53ef\u4ee5\u5f88\u597d\u5730\u5212\u5206\u4e0d\u540c\u7684\u7c7b\u522b\u7279\u5f81\uff0c\u7f51\u7edc\u8f93\u51fa\u5177\u6709\u786e\u5b9a\u6027\uff08\u8f93\u51fa\u7ed3\u679c\u662f\u552f\u4e00\u7684\uff09\uff0c\u4f46\u5bf9\u4e8e\u76ee\u6807\u57df\u56fe\u50cf\u5219\u4e0d\u662f\u8fd9\u6837\uff0c\u7531\u4e8e\u5177\u6709\u9886\u57df\u5dee\u5f02\uff0c\u6a21\u578b\u5f80\u5f80\u4e0d\u5bb9\u6613\u5224\u5b9a\u56fe\u50cf\u7c7b\u522b\uff0c\u7f51\u7edc\u7684\u8f93\u51fa\u5177\u6709\u4e0d\u786e\u5b9a\u6027\uff0c\u5bf9\u6b64\uff0c\u5982\u679c\u60f3\u8981\u4f7f\u6a21\u578b\u53ef\u4ee5\u5f88\u597d\u5730\u8bc6\u522b\u76ee\u6807\u57df\u56fe\u7247\uff0c\u5219\u53ef\u4ee5\u8ba9\u6a21\u578b\u7684\u8f93\u51fa\u4ece\u4e0d\u786e\u5b9a\u7684\u8f6c\u4e3a\u786e\u5b9a\u7684\uff0c\u8fd9\u5c31\u662f\u7b97\u6cd5MCD\u7684\u6838\u5fc3\u601d\u60f3\u3002\u9996\u5148\u6784\u5efa\u4e24\u4e2a\u76f8\u540c\u7684\u5206\u7c7b\u5668\uff0c\u5c06\u540c\u4e00\u5f20\u56fe\u4f20\u5165\u4e24\u4e2a\u5206\u7c7b\u5668\uff0c\u5229\u7528\u5206\u7c7b\u7ed3\u679c\u4e4b\u95f4\u7684\u5dee\u5f02\uff08\u5982l_1\u8ddd\u79bb\uff09\u6765\u4f18\u5316\u7f51\u7edc\u7684\u8de8\u57df\u8bc6\u522b\u6027\u80fd\uff0c\u540c\u65f6\uff0c\u4e3a\u4e86\u4e0d\u8ba9\u4e24\u4e2a\u51b3\u7b56\u9762\u91cd\u5408\uff0cCNN\u548c\u5206\u7c7b\u5668\u4ee5\u76f8\u53cd\u7684\u65b9\u5f0f\u8bad\u7ec3\uff0c\u9f13\u52b1\u5206\u7c7b\u5668\u5f97\u5230\u4e0d\u540c\u7684\u5206\u7c7b\u7ed3\u679c\uff0c\u4ee5\u4e00\u79cd\u5bf9\u6297\u7684\u65b9\u5f0f\u8bad\u7ec3\uff08\u548cGRL\u7c7b\u4f3c\uff09\u3002\u8be5\u7b97\u6cd5\u8003\u8651\u4e86\u76ee\u6807\u57df\u6837\u672c\u548c\u51b3\u7b56\u8fb9\u754c\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u56e0\u6b64\u6709\u52a9\u4e8e\u7279\u5f81\u63d0\u53d6\u5668\u5728\u76ee\u6807\u57df\u4e0a\u751f\u6210\u8fa8\u8bc6\u529b\u7279\u5f81\u3002</p> <p>\u6ce8\uff1a\u5dee\u5f02\u635f\u5931\u7684\u5f15\u5165\u4e3b\u8981\u662f\u4e3a\u4e86\u63d0\u5347\u6a21\u578b\u63d0\u53d6\u5224\u522b\u7279\u5f81\u7684\u80fd\u529b\uff0c\u56e0\u6b64\u4ee5\u7f29\u5c0f\u5206\u7c7b\u8ddd\u79bb\u4e3a\u76ee\u7684\u53bb\u4f18\u5316CNN\u624d\u662f\u7b97\u6cd5\u7684\u6838\u5fc3</p> <p>\u2003\u2003\u7b97\u6cd5CST-MCD\u4e2d\u4e5f\u7528\u5230\u4e86MCD\u7c7b\u4f3c\u7684\u601d\u60f3\uff0c\u5982\u4e0a\u9762\u6240\u63d0\uff0c\u5728Faster R-CNN\u4e2d\uff0cRPN\u548cRPC\u4e24\u4e2a\u6a21\u5757\u53ef\u4ee5\u770b\u6210\u4e24\u4e2a\u76f8\u540c\u7684\u951a\u70b9\u5206\u7c7b\u5668\uff0c\u7528\u4e8e\u9884\u6d4b\u951a\u70b9\u5c5e\u4e8e\u524d\u666f\u7c7b\u522b\u8fd8\u662f\u80cc\u666f\u7c7b\u522b\uff0c\u56e0\u6b64\u53ef\u4ee5\u5c06MCD\u4e2d\u7684\u8ddd\u79bb\u635f\u5931\u5e94\u7528\u5230\u76ee\u6807\u68c0\u6d4b\u4e2d\uff0c\u8fdb\u4e00\u6b65\u63d0\u5347\u6a21\u578b\u7684\u53ef\u8fa8\u522b\u6027\u3002\u540c\u65f6\u8fd9\u91cc\u8fd8\u964d\u4f4e\u4e86\u9ad8\u7f6e\u4fe1\u5ea6\u4f2a\u6807\u7b7e\u951a\u70b9\u7684\u635f\u5931\u6743\u91cd\uff0c\u76f8\u5f53\u4e8e\u5bf9MCD\u7b97\u6cd5\u7684\u6539\u8fdb\uff0c\u9ad8\u7f6e\u4fe1\u5ea6\u4f2a\u6807\u7b7e\u5bf9\u5e94\u7684\u533a\u57df\u5f80\u5f80\u662f\u8de8\u57df\u68c0\u6d4b\u6548\u679c\u597d\u7684\u533a\u57df\uff0c\u6b64\u65f6\u5206\u7c7b\u5668\u5f88\u5bb9\u6613\u5f97\u5230\u76f8\u540c\u7684\u7ed3\u679c\uff0c\u5982\u679c\u518d\u5f3a\u5236\u653e\u5927\u5206\u7c7b\u5668\u7684\u5dee\u5f02\uff0c\u5bb9\u6613\u635f\u5bb3\u6a21\u578b\u6027\u80fd\uff0c\u56e0\u6b64\u9700\u8981\u964d\u4f4e\u6b64\u65f6\u7684\u4f18\u5316\u529b\u5ea6\uff0c\u8fd9\u4e5f\u662f\u5bf9\u6297\u7f51\u7edc\u4e2d\u5e38\u7528\u7684\u8bad\u7ec3\u7b56\u7565\uff0c\u7528\u4e8e\u7f13\u89e3\u8bad\u7ec3\u540e\u671f\u751f\u6210\u5668\u4e0e\u9274\u522b\u5668\u4e4b\u95f4\u7684\u4f18\u5316\u77db\u76fe\u3002</p> <p>\u2003\u2003\u9664\u4e86\u5229\u7528\u4f2a\u6807\u7b7e\u63d0\u5347\u6a21\u578b\u7684\u53ef\u8fa8\u522b\u6027\uff0c\u8fd8\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63d0\u5347\u53ef\u8f6c\u79fb\u6027\uff0c\u4e5f\u5c31\u662f\u548c\u57df\u5206\u7c7b\u5206\u652f\u76f8\u7ed3\u5408\u3002\u4f8b\u5982\u524d\u9762\u63d0\u5230\u7684Coarse-to-Fine\u3001DA Faster\u7b97\u6cd5\uff0c\u7528\u4f2a\u6807\u7b7e\u88c1\u526a\u5b9e\u4f8b\u7279\u5f81\uff0c\u4e0d\u8fc7\u548cCST-MCD\u4e0d\u4e00\u6837\uff0c\u8fd9\u4e9b\u7b97\u6cd5\u53ea\u7528\u4e8e\u4f18\u5316\u7279\u5f81\u7684\u5bf9\u9f50\u8fc7\u7a0b\uff0c\u4e0d\u4f18\u5316\u6a21\u578b\u7684\u68c0\u6d4b\u6027\u80fd\u3002\u5e76\u4e14\u524d\u9762\u63d0\u5230\u7684ICR-CCR\u7b97\u6cd5\u4e2d\u5206\u7c7b\u4e00\u81f4\u6027\u7684\u601d\u60f3\u4e5f\u501f\u52a9\u4f2a\u6807\u7b7e\u8fd9\u4e00\u9014\u5f84\u5b9e\u73b0\uff0c\u5728\u76ee\u6807\u57df\u4e2d\uff0c\u5229\u7528\u591a\u5206\u7c7b\u5668\u4e0eRPC\u6a21\u5757\u4e4b\u95f4\u7684\u5206\u7c7b\u4e00\u81f4\u6027\uff0c\u5f97\u5230\u6bcf\u4e2a\u5b9e\u4f8b\u7684\u9884\u6d4b\u96be\u6613\u7a0b\u5ea6\uff0c\u8fdb\u4e00\u6b65\u518d\u6839\u636e\u96be\u6613\u5ea6\u5bf9\u57df\u5206\u7c7b\u635f\u5931\u505a\u52a0\u6743\u5904\u7406\uff08\u540c\u65f6\u4e5f\u9002\u7528\u4e8e\u6e90\u57df\uff09\u3002</p> <p>\u2003\u2003\u603b\u7684\u6765\u8bf4\uff0c\u867d\u7136\u76ee\u6807\u57df\u6ca1\u6709\u771f\u5b9e\u6807\u7b7e\uff0c\u4f46\u76ee\u6807\u57df\u7684\u7f51\u7edc\u9884\u6d4b\u6570\u636e\u8fd8\u662f\u53ef\u4ee5\u7528\u6765\u4f18\u5316\u7f51\u7edc\u7684\uff0c\u5c24\u5176\u662f\u5bf9\u6a21\u578b\u53ef\u8fa8\u522b\u6027\u7684\u63d0\u5347\u5177\u6709\u5f88\u5927\u7684\u5e2e\u52a9\uff0c\u6838\u5fc3\u601d\u8def\u5c31\u662f\u8981\u8ba9\u76ee\u6807\u57df\u6570\u636e\u7684\u68c0\u6d4b\u7ed3\u679c\u53c2\u4e0e\u5230\u7f51\u7edc\u7684\u4f18\u5316\u8fc7\u7a0b\u4e2d\uff0c\u5373\u53c2\u4e0e\u635f\u5931\u8ba1\u7b97\uff0c\u53ea\u4e0d\u8fc7\u4e0d\u80fd\u76f4\u63a5\u50cf\u6e90\u57df\u90a3\u6837\u76f4\u63a5\u4f18\u5316\uff0c\u9700\u8981\u5bfb\u627e\u6a21\u578b\u4e4b\u95f4\u7684\u9690\u542b\u5173\u7cfb\uff0c\u5efa\u7acb\u4f18\u5316\u6a21\u578b\u3002\uff08\u8fd9\u91cc\u7684\u9690\u542b\u5173\u7cfb\u5305\u62ec\u7f51\u7edc\u5185\u90e8\u7684\u8054\u7cfb\uff0c\u4e5f\u5305\u62ec\u65b0\u5f15\u5165\u7684\u6a21\u5757\u4e0e\u539f\u7f51\u7edc\u4e4b\u95f4\u7684\u8054\u7cfb\uff09</p>"},{"location":"domain_adaptive/sum_domain/#_9","title":"\u5176\u4ed6\u65b9\u6cd5","text":"<p>\u2003\u2003\u5728\u4ee5\u5f80\u5927\u591a\u6570\u7684\u57df\u9002\u5e94\u7b97\u6cd5\u4e2d\uff0c\u76ee\u6807\u68c0\u6d4b\u7f51\u7edc\u7684\u68c0\u6d4b\u6027\u80fd\u5f88\u5927\u7a0b\u5ea6\u4e0a\u4f9d\u8d56\u4e8e\u6e90\u57df\u6570\u636e\uff0c\u56e0\u4e3a\u53ea\u6709\u6e90\u57df\u6570\u636e\u6709\u8fb9\u754c\u6846\u6807\u7b7e\uff0c\u56e0\u6b64\u7eaf\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\uff08\u4e0d\u52a0\u57df\u9002\u5e94\u5206\u652f\uff09\u5728\u68c0\u6d4b\u6e90\u57df\u56fe\u50cf\u6570\u636e\u65f6\uff0c\u53ef\u4ee5\u8fbe\u5230\u6700\u4f18\u7684\u6027\u80fd\uff0c\u6240\u63d0\u53d6\u7684\u7279\u5f81\u6700\u5177\u6709\u8fa8\u522b\u6027\u3002\u57df\u9002\u5e94\u635f\u5931\u7684\u5f15\u5165\uff0c\u4f7f\u5f97\u7f51\u7edc\u5728\u63d0\u53d6\u56fe\u50cf\u7684\u7279\u5f81\u65f6\uff0c\u8ba9\u76ee\u6807\u57df\u7684\u7279\u5f81\u5411\u6e90\u57df\u9760\u62e2\uff0c\u540c\u65f6\u8ba9\u6e90\u57df\u7684\u7279\u5f81\u4e5f\u5411\u76ee\u6807\u57df\u9760\u62e2\uff0c\u8fd9\u4e5f\u662f\u7279\u5f81\u5bf9\u9f50\u7684\u4e3b\u8981\u601d\u60f3\uff0c\u95ee\u9898\u5c31\u51fa\u5728\u540e\u8005\uff0c\u5f3a\u5236\u5c06\u53ef\u9760\u7684\u6e90\u57df\u7279\u5f81\u5411\u4e0d\u53ef\u9760\u7684\u76ee\u6807\u57df\u7279\u5f81\u8fdb\u884c\u5bf9\u9f50\uff0c\u5bb9\u6613\u6253\u4e71\u521d\u59cb\u76ee\u6807\u68c0\u6d4b\u7f51\u7edc\u5b66\u4e60\u5230\u7684\u8fa8\u8bc6\u6027\u7279\u5f81\uff08\u4e3b\u8981\u6307\u9488\u5bf9\u6e90\u57df\u7684\u8fa8\u8bc6\u7279\u5f81\uff09\uff0c\u5f15\u8d77\u6e90\u57df\u7279\u5f81\u5d29\u6e83\u7684\u98ce\u9669\uff0c\u8fdb\u4e00\u6b65\u5e72\u6270\u76ee\u6807\u68c0\u6d4b\u7f51\u7edc\u7684\u68c0\u6d4b\u6027\u80fd\uff0c\u8fd9\u4e5f\u662f\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u4e2d\u5bfc\u81f4\u6a21\u578b\u53ef\u8fa8\u522b\u6027\u964d\u4f4e\u7684\u4e00\u4e2a\u91cd\u8981\u539f\u56e0\u3002</p> <p>\u2003\u2003\u5728\u7b97\u6cd5ATF\u4e2d\uff0c\u4f5c\u8005\u4e3a\u4e86\u6d88\u9664\u5bf9\u9f50\u6e90\u57df\u7279\u5f81\u6240\u5e26\u6765\u7684\u8d1f\u9762\u5f71\u54cd\uff0c\u5355\u72ec\u8bbe\u7f6e\u4e86\u4e00\u4e2a\u8f85\u52a9\u7f51\u7edc\u7528\u4e8e\u63d0\u53d6\u7279\u5f81\uff0c\u5176\u4e2d\u4e3b\u7f51\u7edc\u548c\u8f85\u52a9\u7f51\u7edc\u540c\u65f6\u5229\u7528\u6e90\u57df\u7684\u56fe\u7247\u8bad\u7ec3\u76ee\u6807\u68c0\u6d4b\u6027\u80fd\uff0c\u5728\u8ba1\u7b97\u57df\u5206\u7c7b\u635f\u5931\u65f6\uff0c\u5206\u522b\u5c06\u76ee\u6807\u57df\u56fe\u7247\u548c\u6e90\u57df\u56fe\u7247\u4f20\u5165\u4e3b\u7f51\u7edc\u548c\u8f85\u52a9\u7f51\u7edc\uff0c\u5c06\u5f97\u5230\u7684\u7279\u5f81\u56fe\u518d\u5206\u522b\u4f20\u5165\u540c\u4e00\u4e2a\u57df\u5206\u7c7b\u5668\uff0c\u5206\u522b\u6267\u884c\u5bf9\u9f50\uff0c\u4e3b\u7f51\u548c\u8f85\u52a9\u7f51\u7edc\u901a\u8fc7\u540c\u4e00\u4e2a\u57df\u5206\u7c7b\u5668\u505a\u8054\u7cfb\u3002\u8fd9\u79cd\u8bbe\u8ba1\uff0c\u53ef\u4ee5\u53ea\u8ba9\u76ee\u6807\u57df\u7279\u5f81\u5411\u6e90\u57df\u9760\u62e2\uff0c\u4e0d\u6539\u53d8\u7f51\u7edc\u5bf9\u6e90\u57df\u7279\u5f81\u539f\u6709\u7684\u53ef\u5224\u522b\u6027\uff0c\u56e0\u6b64\u53ef\u4ee5\u5f88\u597d\u5730\u548c\u6e90\u57df\u4e0a\u7684\u76ee\u6807\u68c0\u6d4b\u7f51\u7edc\u76f8\u7ed3\u5408\u3002</p> <p> <p></p> <p></p>"},{"location":"domain_adaptive/sum_domain/#_10","title":"\u53c2\u8003\u7b97\u6cd5","text":"<ul> <li>MeGA-CDA: MeGA-CDA: Memory Guided Attention for Category-Aware Unsupervised Domain Adaptive Object Detection, CVPR 2021.</li> <li>Coarse-to-Fine: Cross-domain Object Detection through Coarse-to-Fine Feature Adaptation, CVPR 2020.</li> <li>ICR-CCR: Exploring Categorical Regularization for Domain Adaptive Object Detection, CVPR 2020.</li> <li>CST-MCD: Collaborative Training between Region Proposal Localization and Classification for Domain Adaptive Object Detection, ECCV 2020.</li> <li>ATF: Domain Adaptive Object Detection via Asymmetric Tri-way Faster-RCNN, ECCV 2020.</li> <li>Strong-Weak: Strong-Weak Distribution Alignment for Adaptive Object Detection, CVPR 2019.</li> <li>DA Faster: Domain Adaptive Faster R-CNN for Object Detection in the Wild, CVPR 2018.</li> <li>MCD: Maximum Classifier Discrepancy for Unsupervised Domain Adaptation, CVPR 2018.</li> <li>Focal Loss: Focal Loss for Dense Object Detection, ICCV 2017.</li> <li>GRL: Domain-Adversarial Training of Neural Networks, JMLR 2016.</li> </ul> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u6307\u6b63\u3002</p> <p>\u521d\u6b65\u5b8c\u7a3f\u4e8e\uff1a2023\u5e742\u670810\u65e5</p>"},{"location":"domain_adaptive/sum_domain_year/","title":"\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u6c47\u603b","text":"<p>\u6ce8\uff1a\u5982\u975e\u7279\u6b8a\u8bf4\u660e\uff0c\u6e90\u7801\u5747\u4e3aPyTorch\u7248\u672c</p>"},{"location":"domain_adaptive/sum_domain_year/#2018","title":"2018","text":""},{"location":"domain_adaptive/sum_domain_year/#cvpr","title":"CVPR","text":"<p>DA Faster R-CNN</p> <p> <p></p> <p></p> <p>\u7b80\u4ecb\uff1a\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u89e3\u51b3\u8de8\u57df\u76ee\u6807\u68c0\u6d4b\u95ee\u9898\u7684\u57df\u9002\u5e94Faster R-CNN\u7b97\u6cd5\uff0c\u53ef\u4ee5\u5b9e\u73b0\u5728\u4e0d\u4f7f\u7528\u4efb\u4f55\u9644\u52a0\u6807\u8bb0\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u83b7\u5f97\u65b0\u9886\u57df\u9c81\u68d2\u6027\u7684\u68c0\u6d4b\u5668\u3002\u4f5c\u8005\u5728\u5bf9\u8de8\u57df\u76ee\u6807\u68c0\u6d4b\u7406\u8bba\u5206\u6790\u7684\u57fa\u7840\u4e0a\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u56fe\u50cf\u7ea7\u81ea\u9002\u5e94\u7ec4\u4ef6\u548c\u5b9e\u4f8b\u7ea7\u81ea\u9002\u5e94\u7ec4\u4ef6\u6765\u7f13\u89e3\u7531\u57df\u504f\u79fb\u5f15\u8d77\u7684\u6a21\u578b\u6027\u80fd\u4e0b\u964d\u7684\u95ee\u9898\uff0c\u4e24\u4e2a\u7ec4\u4ef6\u7684\u8bad\u7ec3\u90fd\u662f\u57fa\u4e8e\\mathcal H\u6563\u5ea6\u7684\u5bf9\u6297\u6027\u8bad\u7ec3\u7684\uff0c\u5e76\u4e14\u4f5c\u8005\u8fd8\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u4e00\u81f4\u6027\u6b63\u5219\u5316\u5668\uff0c\u7528\u4e8e\u8fdb\u4e00\u6b65\u5b66\u4e60\u4e00\u4e2a\u57df\u4e0d\u53d8\u7684RPN\u7ec4\u4ef6\u3002</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_Domain_Adaptive_Faster_CVPR_2018_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/yuhuayc/da-faster-rcnn</p> <p>\u8bba\u6587\u7b14\u8bb0\u94fe\u63a5\u3001\u6e90\u7801\u7b14\u8bb0\u94fe\u63a5</p>"},{"location":"domain_adaptive/sum_domain_year/#2019","title":"2019","text":""},{"location":"domain_adaptive/sum_domain_year/#cvpr_1","title":"CVPR","text":"<p>Strong-Weak</p> <p> <p></p> <p></p> <p>\u7b80\u4ecb\uff1a\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5c40\u90e8\u5bf9\u9f50\u548c\u5f31\u5168\u5c40\u5bf9\u9f50\u7684\u65e0\u76d1\u7763\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\uff0c\u4e3b\u8981\u7684\u8d21\u732e\u5c31\u662f\u8bbe\u8ba1\u4e86\u4e00\u79cd\u5f31\u5bf9\u9f50\u6a21\u5757\uff0c\u5c06\u5bf9\u6297\u635f\u5931\u96c6\u4e2d\u5728\u5168\u5c40\u76f8\u4f3c\u7684\u56fe\u50cf\u4e0a\uff0c\u8fdc\u79bb\u5168\u5c40\u4e0d\u76f8\u4f3c\u7684\u56fe\u50cf\uff0c\u5e76\u4e14\u9488\u5bf9\u7279\u5f81\u56fe\u4e0a\u5c40\u90e8\u7684\u611f\u53d7\u91ce\u533a\u57df\u8bbe\u8ba1\u4e86\u5f3a\u5c40\u90e8\u5bf9\u9f50\u6a21\u5757\u3002\u901a\u8fc7\u5b9e\u9a8c\u5206\u6790\u5f97\u5230\uff0c\u8be5\u7b97\u6cd5\u7684\u6027\u80fd\u8981\u4f18\u4e8e\u73b0\u6709\u7684\u57df\u9002\u5e94\u68c0\u6d4b\u7b97\u6cd5\u3002</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content_CVPR_2019/papers/Saito_Strong-Weak_Distribution_Alignment_for_Adaptive_Object_Detection_CVPR_2019_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/VisionLearningGroup/DA_Detection</p> <p>\u8bba\u6587\u7b14\u8bb0\u94fe\u63a5\u3001\u6e90\u7801\u7b14\u8bb0\u94fe\u63a5</p>"},{"location":"domain_adaptive/sum_domain_year/#2020","title":"2020","text":""},{"location":"domain_adaptive/sum_domain_year/#cvpr_2","title":"CVPR","text":"<p>Coarse-to-Fine</p> <p> <p></p> <p></p> <p>\u7b80\u4ecb\uff1a\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7531\u7c97\u5230\u7ec6\u7684\u7279\u5f81\u81ea\u9002\u5e94\u7b97\u6cd5\u6765\u89e3\u51b3\u8de8\u57df\u76ee\u6807\u68c0\u6d4b\u95ee\u9898\uff0c\u8be5\u7b97\u6cd5\u4e3b\u8981\u6709\u4e24\u4e2a\u6a21\u5757\u6784\u6210\u2014\u2014ART\u548cPSA\uff0c\u524d\u8005\u5229\u7528\u6ce8\u610f\u529b\u673a\u5236\u4ee5\u7c7b\u522b\u4e0d\u53ef\u77e5\u7684\u65b9\u5f0f\u6784\u9020\u524d\u666f\u533a\u57df\uff0c\u5e76\u4e14\u5728\u9886\u57df\u7279\u5f81\u5bf9\u9f50\u65f6\u7a81\u51fa\u524d\u666f\u533a\u57df\u7684\u91cd\u8981\u6027\uff0c\u540e\u8005\u5229\u7528\u539f\u578b\u5728\u8bed\u4e49\u5c42\u9762(\u5373\u7ed3\u5408\u4e86\u7c7b\u522b\u4fe1\u606f)\u5bf9\u524d\u666f\u8fdb\u884c\u7ec6\u7c92\u5ea6\u7684\u8c03\u6574\uff0c\u5bf9\u6bcf\u4e2a\u7c7b\u522b\u6267\u884c\u4e0d\u540c\u7684\u5bf9\u9f50\u3002</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content_CVPR_2020/papers/Zheng_Cross-domain_Object_Detection_through_Coarse-to-Fine_Feature_Adaptation_CVPR_2020_paper.pdf</p> <p>\u8bba\u6587\u7b14\u8bb0\u94fe\u63a5</p> <p>ICR-CCR</p> <p> <p></p> <p></p> <p>\u8bba\u6587\u5730\u5740\uff1a\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8eDA Faster\u7684\u5206\u7c7b\u6b63\u5219\u5316\u6846\u67b6\uff0c\u4ee5\u63d0\u9ad8\u68c0\u6d4b\u6a21\u578b\u7684\u81ea\u9002\u5e94\u80fd\u529b\u3002\u5177\u4f53\u7684\u6765\u8bf4\uff0c\u4f5c\u8005\u5229\u7528\u4e86\u591a\u6807\u7b7e\u5206\u7c7b\u7f51\u7edc\u7684\u5f31\u5b9a\u4f4d\u80fd\u529b\u548c\u56fe\u50cf\u7ea7\u9884\u6d4b\u4e0e\u5b9e\u4f8b\u7ea7\u9884\u6d4b\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\uff0c\u901a\u8fc7\u8ba9\u7f51\u7edc\u805a\u7126\u4e8e\u5bf9\u9f50\u7269\u4f53\u76f8\u5173\u7684\u5c40\u90e8\u533a\u57df\u7279\u5f81\u548c\u96be\u5bf9\u9f50\u7684\u5b9e\u4f8b\u7279\u5f81\u6765\u8fdb\u4e00\u6b65\u63d0\u5347\u6a21\u578b\u7684\u9886\u57df\u81ea\u9002\u5e94\u80fd\u529b\u3002http://openaccess.thecvf.com/content_CVPR_2020/papers/Xu_Exploring_Categorical_Regularization_for_Domain_Adaptive_Object_Detection_CVPR_2020_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/Megvii-Nanjing/CR-DA-DET</p> <p>\u8bba\u6587\u7b14\u8bb0\u94fe\u63a5\u3001\u6e90\u7801\u7b14\u8bb0\u94fe\u63a5</p> <p>HTCN</p> <p> <p></p> <p></p> <p>\u7b80\u4ecb\uff1a\u672c\u6587\u4e3a\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u9886\u57df\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u7ea7\u53ef\u8f6c\u79fb\u6821\u51c6\u7f51\u7edc(HTCN)\uff0c\u901a\u8fc7\u63a2\u7d22\u4e0d\u540c\u5c40\u90e8\u533a\u57df\u3001\u56fe\u50cf\u548c\u5b9e\u4f8b\u7684\u53ef\u8f6c\u79fb\u6027\u6765\u534f\u8c03\u5bf9\u6297\u6027\u9002\u5e94\u4e2d\u53ef\u8f6c\u79fb\u6027\u548c\u53ef\u8fa8\u522b\u6027\u4e4b\u95f4\u7684\u6f5c\u5728\u77db\u76fe\u3002</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content_CVPR_2020/papers/Chen_Harmonizing_Transferability_and_Discriminability_for_Adapting_Object_Detectors_CVPR_2020_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/chaoqichen/HTCN</p> <p>\u8bba\u6587\u7b14\u8bb0\u94fe\u63a5\u3001\u6e90\u7801\u7b14\u8bb0\u94fe\u63a5</p>"},{"location":"domain_adaptive/sum_domain_year/#eccv","title":"ECCV","text":"<p>CST-MCD</p> <p> <p></p> <p></p> <p>\u7b80\u4ecb\uff1a\u672c\u6587\u9996\u6b21\u63ed\u793a\u4e86\u4e8c\u9636\u6bb5\u68c0\u6d4b\u5668(\u5982Faster RCNN)\u4e2d\u7684RPN\u3001RPC\u6a21\u5757\u5728\u9762\u4e34\u5927\u7684\u9886\u57df\u95f4\u9699\u65f6\u4f1a\u8868\u73b0\u51fa\u663e\u8457\u4e0d\u540c\u7684\u53ef\u8f6c\u79fb\u6027\uff08\u9886\u57df\u9002\u5e94\u80fd\u529b\uff09\uff0c\u57fa\u4e8e\u4e0a\u8ff0\u89c2\u5bdf\uff0c\u4f5c\u8005\u4e3aRPN\u4e0eRPC\u8bbe\u8ba1\u4e86\u534f\u540c\u81ea\u8bad\u7ec3\u7b56\u7565\uff0c\u8ba9\u4ed6\u4eec\u91cd\u70b9\u5173\u6ce8\u5177\u6709\u9ad8\u7f6e\u4fe1\u5ea6\u7684ROI\u3002\u53e6\u5916\uff0c\u8fd8\u8bbe\u8ba1\u4e86\u4e00\u79cd\u6700\u5927\u5dee\u5f02\u5206\u7c7b\u5668\uff0c\u901a\u8fc7\u6709\u6548\u5730\u5229\u7528\u4f4e\u7f6e\u4fe1\u5ea6\u7684ROI\u6765\u8fdb\u4e00\u6b65\u63d0\u9ad8\u68c0\u6d4b\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123630086.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/uitrbn/CST_DA_detection</p> <p>\u8bba\u6587\u7b14\u8bb0\u94fe\u63a5\u3001\u6e90\u7801\u7b14\u8bb0\u94fe\u63a5</p> <p>ATF</p> <p> <p></p> <p></p> <p>\u7b80\u4ecb\uff1a\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u975e\u5bf9\u79f0\u4e09\u8def\u7f51\u7edc\u6765\u89e3\u51b3\u65e0\u76d1\u7763\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u4e2d\u53c2\u6570\u5171\u4eab\u5f15\u8d77\u7684\u6e90\u57df\u7279\u5f81\u5931\u63a7\u95ee\u9898\uff0c\u4e3b\u8981\u5c31\u662f\u5728\u7f51\u7edc\u4e2d\u65b0\u52a0\u5165\u4e86\u4e00\u4e2a\u7531\u6e90\u57df\u6807\u7b7e\u76d1\u7763\u8bad\u7ec3\u7684\u8f85\u52a9\u7f51\u7edc\uff0c\u8be5\u7f51\u7edc\u53c2\u6570\u548c\u4e3b\u7f51\u7edc\u53c2\u6570\u76f8\u4e92\u72ec\u7acb\u3002\u6a21\u578b\u4e3b\u8981\u6709\u4e24\u5927\u8d21\u732e\uff1a\u2460\u5728\u53c2\u6570\u5171\u4eab\u7684\u7f51\u7edc\u4e2d\uff0c\u57df\u5dee\u5f02\u96be\u4ee5\u6d88\u9664\uff0c\u56e0\u6b64\u63d0\u51fa\u4e86\u975e\u5bf9\u79f0\u7684\u7f51\u7edc\u7ed3\u6784\u6765\u589e\u5f3a\u68c0\u6d4b\u5668\u7684\u8bad\u7ec3\uff0c\u8fd9\u79cd\u4e0d\u5bf9\u79f0\u6027\u53ef\u4ee5\u5f88\u597d\u5730\u7f13\u89e3\u6e90\u57df\u548c\u76ee\u6807\u57df\u4e4b\u95f4\u6807\u8bb0\u4e0d\u516c\u5e73\u6240\u5e26\u6765\u7684\u95ee\u9898\uff1b\u2461\u6240\u63d0\u51fa\u7684\u8f85\u52a9\u7f51\u7edc\u4f7f\u5f97\u6e90\u57df\u7279\u5f81\u5206\u5e03\u53ef\u4ee5\u4fdd\u6301\u7ed3\u6784\u533a\u5206\u6027\uff0c\u5f88\u5927\u7a0b\u5ea6\u4e0a\u63d0\u9ad8\u4e86\u76ee\u6807\u57df\u7279\u5f81\u7684\u53ef\u9760\u6027\u3002</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123690307.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/He-Zhenwei/ATF</p> <p>\u8bba\u6587\u7b14\u8bb0\u94fe\u63a5\u3001\u6e90\u7801\u7b14\u8bb0\u94fe\u63a5</p>"},{"location":"domain_adaptive/sum_domain_year/#2021","title":"2021","text":""},{"location":"domain_adaptive/sum_domain_year/#cvpr_3","title":"CVPR","text":"<p>MeGA-CDA</p> <p> <p></p> <p></p> <p>\u7b80\u4ecb\uff1a\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u7684\u7c7b\u522b\u7279\u5f81\u5bf9\u9f50\u65b9\u6cd5\uff0c\u5177\u4f53\u5730\u6765\u8bf4\uff0c\u901a\u8fc7\u6784\u5efa\u7c7b\u5224\u522b\u5668\u6765\u5c06\u7c7b\u522b\u4fe1\u606f\u7eb3\u5165\u9886\u57df\u5bf9\u9f50\u7684\u8fc7\u7a0b\u4e2d\u3002\u4e3a\u4e86\u514b\u670d\u7f3a\u4e4f\u76ee\u6807\u57df\u7c7b\u522b\u7279\u5f81\u6240\u4ea7\u751f\u7684\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u7531\u8bb0\u5fc6\u5f15\u5bfc\u7684\u6ce8\u610f\u529b\u673a\u5236\uff0c\u8be5\u673a\u5236\u53ef\u4ee5\u751f\u6210\u7c7b\u522b\u7279\u5b9a\u7684\u6ce8\u610f\u529b\u56fe\u6765\u5c06\u4e3b\u5e72\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u5f97\u5230\u7684\u7279\u5f81\u5206\u914d\u5230\u4e0d\u540c\u7684\u7c7b\u5224\u522b\u5668\u4e2d\u3002\u901a\u8fc7\u5bf9\u9f50\u7c7b\u522b\u7279\u5f81\uff0c\u53ef\u4ee5\u51cf\u8f7b\u7531\u5168\u5c40\u7279\u5f81\u5bf9\u9f50\u5f15\u8d77\u7684\u9886\u57df\u8d1f\u8fc1\u79fb\u95ee\u9898\uff0c\u8fdb\u4e00\u6b65\u63d0\u5347\u6a21\u578b\u7684\u9886\u57df\u9002\u5e94\u80fd\u529b\u3002</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttp://openaccess.thecvf.com/content/CVPR2021/papers/VS_MeGA-CDA_Memory_Guided_Attention_for_Category-Aware_Unsupervised_Domain_Adaptive_Object_CVPR_2021_paper.pdf</p> <p>\u8bba\u6587\u7b14\u8bb0\u94fe\u63a5\u3001\u6e90\u7801\u7b14\u8bb0\u94fe\u63a5</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e743\u670819\u65e5</p>"},{"location":"domain_adaptive/code/ATF2/","title":"\u57df\u9002\u5e94\uff1aATF","text":""},{"location":"domain_adaptive/code/ATF2/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aEuropean Conference on Computer Vision 2020 (ECCV 20)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123690307.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/He-Zhenwei/ATF</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b</p>"},{"location":"domain_adaptive/code/ATF2/#_2","title":"\u7f51\u7edc\u7ed3\u6784","text":""},{"location":"domain_adaptive/code/ATF2/#_3","title":"\u7f51\u7edc\u6a21\u5757\u521d\u59cb\u5316","text":"<pre><code>class _fasterRCNN(nn.Module):\n    \"\"\" faster RCNN \"\"\"\n\n    def __init__(self, classes, class_agnostic):\n        super(_fasterRCNN, self).__init__()\n        self.classes = classes\n        self.n_classes = len(classes)\n        self.class_agnostic = class_agnostic\n        # loss\n        self.RCNN_loss_cls = 0\n        self.RCNN_loss_bbox = 0\n\n        # define rpn\n        # \u5b9a\u4e49RPN\u6a21\u5757\n        self.RCNN_rpn = _RPN(self.dout_base_model)\n        # \u8fd9\u4e2a\u6a21\u5757\u540e\u9762\u6ca1\u7528\u5230\uff0c\u5e94\u8be5\u662f\u591a\u5b9a\u4e49\u7684\n        self.RCNN_rpn_t = _RPN(self.dout_base_model)\n        # \u7b5b\u9009ROI Head\u4e2d\u7684proposals\uff0c\u53ea\u5728\u6e90\u57df\u7684\u8bad\u7ec3\u9636\u6bb5\u6267\u884c\n        self.RCNN_proposal_target = _ProposalTargetLayer(self.n_classes)\n        # \u5b9a\u4e49\u4e09\u79cdROI Pooling\u64cd\u4f5c\n        self.RCNN_roi_pool = _RoIPooling(cfg.POOLING_SIZE, cfg.POOLING_SIZE, 1.0 / 16.0)\n        self.RCNN_roi_align = RoIAlignAvg(cfg.POOLING_SIZE, cfg.POOLING_SIZE, 1.0 / 16.0)\n        self.grid_size = cfg.POOLING_SIZE * 2 if cfg.CROP_RESIZE_WITH_MAX_POOL else cfg.POOLING_SIZE\n        self.RCNN_roi_crop = _RoICrop()\n        # \u5b9a\u4e49\u4e09\u4e2a\u9636\u6bb5\u7684\u56fe\u50cf\u7ea7\u57df\u5206\u7c7b\u5668\n        self.RCNN_imageDA_3 = _ImageDA(256)\n        self.RCNN_imageDA_4 = _ImageDA(512)\n        self.RCNN_imageDA = _ImageDA(self.dout_base_model)\n        # \u5b9a\u4e49\u5b9e\u4f8b\u7ea7\u57df\u5206\u7c7b\u5668\n        self.RCNN_instanceDA = _InstanceDA()\n</code></pre> <p>\u8865\u5145</p> <p>\u57fa\u4e8eresnet101\u7684\u6a21\u5757\u521d\u59cb\u5316</p> <pre><code>  def _init_modules(self):\n    resnet = resnet101()\n\n    if self.pretrained == True:\n      print(\"Loading pretrained weights from %s\" %(self.model_path))\n      state_dict = torch.load(self.model_path)\n      resnet.load_state_dict({k:v for k,v in state_dict.items() if k in resnet.state_dict()})\n\n    # Build resnet.\n    self.conv3 = nn.Sequential(resnet.conv1, resnet.bn1,resnet.relu,\n      resnet.maxpool,resnet.layer1)\n    self.conv34 = nn.Sequential(resnet.layer2)\n    self.conv45 = nn.Sequential(resnet.layer3)\n    self.RCNN_base = nn.Sequential(resnet.conv1, resnet.bn1,resnet.relu,\n      resnet.maxpool,resnet.layer1,resnet.layer2,resnet.layer3)\n\n    self.RCNN_top = nn.Sequential(resnet.layer4)\n\n    self.RCNN_cls_score = nn.Linear(2048, self.n_classes)\n    if self.class_agnostic:\n      self.RCNN_bbox_pred = nn.Linear(2048, 4)\n    else:\n      self.RCNN_bbox_pred = nn.Linear(2048, 4 * self.n_classes)\n\n    # Fix blocks\n    for p in self.RCNN_base[0].parameters(): p.requires_grad=False\n    for p in self.RCNN_base[1].parameters(): p.requires_grad=False\n\n    assert (0 &lt;= cfg.RESNET.FIXED_BLOCKS &lt; 4)\n    if cfg.RESNET.FIXED_BLOCKS &gt;= 3:\n      for p in self.RCNN_base[6].parameters(): p.requires_grad=False\n    if cfg.RESNET.FIXED_BLOCKS &gt;= 2:\n      for p in self.RCNN_base[5].parameters(): p.requires_grad=False\n    if cfg.RESNET.FIXED_BLOCKS &gt;= 1:\n      for p in self.RCNN_base[4].parameters(): p.requires_grad=False\n\n    def set_bn_fix(m):\n      classname = m.__class__.__name__\n      if classname.find('BatchNorm') != -1:\n        for p in m.parameters(): p.requires_grad=False\n\n    self.RCNN_base.apply(set_bn_fix)\n    self.RCNN_top.apply(set_bn_fix)\n</code></pre>"},{"location":"domain_adaptive/code/ATF2/#_4","title":"\u524d\u5411\u4f20\u64ad","text":"<pre><code>   def forward(self, im_data, im_info, gt_boxes, num_boxes, need_backprop,\n                tgt_im_data, tgt_im_info, tgt_gt_boxes, tgt_num_boxes, tgt_need_backprop):\n        \"\"\"\n        im_data: \u4e00\u5f20\u6e90\u57df\u56fe\u50cf\n        im_info: \u6e90\u57df\u56fe\u7247\u957f\u5bbd\u4fe1\u606f\n        gt_boxes: \u6e90\u57df\u56fe\u50cf\u6807\u7b7e\u8fb9\u754c\u6846\n        num_boxes: \u6e90\u57df\u56fe\u50cf\u6807\u7b7e\u6846\u6570\u91cf\n        need_backprop: \u9886\u57df\u6807\u7b7e\uff0c\u6e90\u57df\u6570\u636e\u5bf9\u5e94\u8bbe\u4e3a1\n        tgt_im_data: \u4e00\u5f20\u76ee\u6807\u57df\u56fe\u50cf\n        tgt_im_info: \u76ee\u6807\u57df\u56fe\u7247\u957f\u5bbd\u4fe1\u606f\n        tgt_gt_boxes: \u76ee\u6807\u57df\u8fb9\u754c\u6846\u6807\u7b7e (\u6b64\u53d8\u91cf\u662f\u968f\u673a\u521d\u59cb\u5316\u7684\uff0c\u56e0\u4e3a\u76ee\u6807\u57df\u65e0\u6807\u7b7e)\n        tgt_num_boxes: \u76ee\u6807\u57df\u6807\u7b7e\u6846\u6570\u91cf (\u540c\u4e0a\uff0c\u968f\u673a\u521d\u59cb\u5316\u7684\u6570\u636e)\n        tgt_need_backprop:\u9886\u57df\u6807\u7b7e\uff0c\u76ee\u6807\u57df\u6570\u636e\u5bf9\u5e94\u8bbe\u4e3a0\n        \"\"\"\n\n        assert need_backprop.detach() == 1 and tgt_need_backprop.detach() == 0\n        # \u9996\u5148\u5904\u7406\u6e90\u57df\u6570\u636e\n        # \u5206\u522b\u5f97\u5230\u8f93\u5165\u6570\u636e\u7684\u4fe1\u606f\n        batch_size = im_data.size(0)\n        im_info = im_info.data  # (size1,size2, image ratio(new image / source image) )\n        gt_boxes = gt_boxes.data\n        num_boxes = num_boxes.data\n\n        need_backprop = need_backprop.data\n\n        # feed image data to base model to obtain base feature map\n        # \u5c06\u56fe\u7247\u4f9d\u6b21\u4f20\u5165\u7279\u5f81\u63d0\u53d6\u5c42\uff0c\u5f97\u5230\u4e0d\u540c\u9636\u6bb5\u7684\u7279\u5f81\u56fe\n        # \u5176\u4e2d\uff0c\u540e\u7f00\u662fs\u7684\u8868\u793aChief Net\n        conv3_feat = self.conv3_s(im_data)\n        conv4_feat = self.conv34_s(conv3_feat)\n        base_feat = self.conv45_s(conv4_feat)\n        # \u540e\u7f00\u662ft\u7684\u8868\u793aAncillary Net\n        conv3_feat_t = self.conv3_t(im_data)\n        conv4_feat_t = self.conv34_t(conv3_feat_t)\n        base_feat_t = self.conv45_t(conv4_feat_t)\n\n        # feed base feature map tp RPN to obtain rois\n        # \u5c06\u7279\u5f81\u56fe\u4f9d\u6b21\u4f20\u5165RPN\u4e2d\uff0c\u5f97\u5230proposals(\u533a\u57df\u5efa\u8bae\u6846)\u548crpn loss(rpn\u635f\u5931)\n        # \u8fd9\u91cc\u5f97\u5230\u7684proposals\u662f\u7ecf\u8fc7RPN\u6a21\u5757\u4e2d\u7b5b\u9009\u540e\u7684proposals\n        # \u5373\u5148\u6839\u636e\u9884\u6d4b\u5206\u6570\u7b5b\u9009\u524dXX\u4e2a\uff0c\u4e4b\u540e\u7ecf\u8fc7NMS\u7b5b\u9009\uff0c\u6700\u540e\u518d\u6839\u636e\u9884\u6d4b\u5206\u6570\u7b5b\u9009\u524dXX\u4e2a\uff0c\u548c\u540e\u9762ROI Head\u7684\u7b5b\u9009\u4e0d\u540c\n        self.RCNN_rpn.train()\n        rois_domain, rpn_loss_cls1, rpn_loss_bbox1, _ = self.RCNN_rpn(base_feat, im_info, gt_boxes, num_boxes)\n        rois_domain_t, rpn_loss_cls2, rpn_loss_bbox2, _ = self.RCNN_rpn(base_feat_t, im_info, gt_boxes, num_boxes)\n        # \u4e24\u79cd\u635f\u5931\u5206\u522b\u76f8\u52a0\uff0c\u5f97\u5230rpn\u6700\u7ec8\u7684\u5206\u7c7b\u635f\u5931\u548c\u8fb9\u754c\u6846\u56de\u5f52\u635f\u5931\n        rpn_loss_cls = rpn_loss_cls1 + rpn_loss_cls2\n        rpn_loss_bbox = rpn_loss_bbox1 + rpn_loss_bbox2\n\n        # if it is training phrase, then use ground trubut bboxes for refining\n        # \u5982\u679c\u662f\u8bad\u7ec3\u9636\u6bb5\uff0c\u5219\u9700\u8981\u5bf9\u6bcf\u4e2aproposal\u6253\u4e0a\u6807\u7b7e\uff0c\u5e76\u4e14\u7b5b\u9009\u7279\u5b9a\u6b63\u8d1f\u6837\u672c\u6bd4\u4f8b\u7684proposals\u4f20\u5165roi head\u6a21\u5757\n        # \u8fd9\u91cc\u7684\u7b5b\u9009\u64cd\u4f5c\u662fROI Head\u4e2d\u7684\u7b5b\u9009(\u7b5b\u9009\u7279\u5b9a\u6b63\u8d1f\u6837\u672c\uff0c\u7528\u4e8e\u8ba1\u7b97roi\u635f\u5931)\uff0c\u548c\u4e0a\u9762RPN\u4e2d\u7684\u7b5b\u9009\u4e0d\u540c(\u4e00\u5171\u4f1a\u7ecf\u8fc7\u4e24\u6b21\u7b5b\u9009)\n        if self.training:\n            # \u5f97\u5230\u7b5b\u9009\u540e\u7684proposals\n            roi_data = self.RCNN_proposal_target(rois_domain, gt_boxes, num_boxes)\n            rois, rois_label, rois_target, rois_inside_ws, rois_outside_ws = roi_data\n            # \u4f7f\u6570\u636e\u53d8\u4e3a\u5f20\u91cf\u683c\u5f0f-&gt;\u53ef\u5bfc\n            rois_label = Variable(rois_label.view(-1).long())\n            rois_target = Variable(rois_target.view(-1, rois_target.size(2)))\n            rois_inside_ws = Variable(rois_inside_ws.view(-1, rois_inside_ws.size(2)))\n            rois_outside_ws = Variable(rois_outside_ws.view(-1, rois_outside_ws.size(2)))\n            # \u5bf9Ancillary Net\u4e2d\u7684proposals\u6267\u884c\u540c\u6837\u7684\u64cd\u4f5c\n            roi_data_t = self.RCNN_proposal_target(rois_domain_t, gt_boxes, num_boxes)\n            rois_t, rois_label_t, rois_target_t, rois_inside_ws_t, rois_outside_ws_t = roi_data_t\n\n            rois_label_t = Variable(rois_label_t.view(-1).long())\n            rois_target_t = Variable(rois_target_t.view(-1, rois_target_t.size(2)))\n            rois_inside_ws_t = Variable(rois_inside_ws_t.view(-1, rois_inside_ws_t.size(2)))\n            rois_outside_ws_t = Variable(rois_outside_ws_t.view(-1, rois_outside_ws_t.size(2)))\n\n        else:\n            # \u6d4b\u8bd5\u9636\u6bb5\u7684\u8bdd\u4e0d\u8fdb\u884c\u7b5b\u9009\u3001\u6253\u6807\u7b7e\uff0c\u5c06\u6240\u6709\u7684proposals\u90fd\u4f20\u5165roi head\n            rois_label = None\n            rois_target = None\n            rois_inside_ws = None\n            rois_outside_ws = None\n            rpn_loss_cls = 0\n            rpn_loss_bbox = 0\n\n        # \u9009\u62e9\u4e0d\u540c\u7684roi pooling\u64cd\u4f5c\uff0c\u5f97\u5230pooling features(\u533a\u57df\u7279\u5f81)\n        # \u4e0b\u9762\u8fd9\u4e00\u5757\u53ea\u5bf9\u7b5b\u9009\u540e\u7684proposals\u6267\u884croi pooling\u64cd\u4f5c\uff0c\u7528\u4e8e\u8ba1\u7b97roi\u56de\u5f52\u635f\u5931\u548c\u5206\u7c7b\u635f\u5931\n        if cfg.POOLING_MODE == 'crop':\n            grid_xy = _affine_grid_gen(rois.view(-1, 5), base_feat.size()[2:], self.grid_size)\n            grid_yx = torch.stack([grid_xy.data[:, :, :, 1], grid_xy.data[:, :, :, 0]], 3).contiguous()\n            pooled_feat = self.RCNN_roi_crop(base_feat, Variable(grid_yx).detach())\n            if cfg.CROP_RESIZE_WITH_MAX_POOL:\n                pooled_feat = F.max_pool2d(pooled_feat, 2, 2)\n\n            grid_xy_t = _affine_grid_gen(rois_t.view(-1, 5), base_feat_t.size()[2:], self.grid_size)\n            grid_yx_t = torch.stack([grid_xy_t.data[:, :, :, 1], grid_xy_t.data[:, :, :, 0]], 3).contiguous()\n            pooled_feat_t = self.RCNN_roi_crop(base_feat_t, Variable(grid_yx_t).detach())\n            if cfg.CROP_RESIZE_WITH_MAX_POOL:\n                pooled_feat_t = F.max_pool2d(pooled_feat_t, 2, 2)\n\n        elif cfg.POOLING_MODE == 'align':\n            pooled_feat = self.RCNN_roi_align(base_feat, rois.view(-1, 5))\n            pooled_feat_t = self.RCNN_roi_align(base_feat_t, rois_t.view(-1, 5))\n        elif cfg.POOLING_MODE == 'pool':\n            pooled_feat = self.RCNN_roi_pool(base_feat, rois.view(-1, 5))\n            pooled_feat_t = self.RCNN_roi_pool(base_feat_t, rois_t.view(-1, 5))\n\n        # \u4e0b\u9762\u5bf9rpn\u6a21\u5757\u5f97\u5230\u7684\u6240\u6709proposals\u6267\u884croi pooling\u64cd\u4f5c\uff0c\u7528\u4e8e\u8ba1\u7b97\u5b9e\u4f8b\u7ea7\u7279\u5f81\u5bf9\u9f50\u635f\u5931\n        # \u8fd9\u91cc\u7684proposals\u662f\u7ecf\u8fc7RPN\u6a21\u5757\u5185\u90e8\u5bf9\u951a\u70b9\u7684\u7b5b\u9009\u5f97\u5230\u7684\u533a\u57df\n        # \u6ce8\u610f\uff0c\u540e\u9762\u53ea\u7528\u5230\u4e86\u8f85\u52a9\u7f51\u7edc\u7684proposals\uff0c\u4e3b\u7f51\u4e2d\u7684\u6e90\u57df\u5206\u652f\u4e0d\u53c2\u4e0e\u57df\u9002\u5e94\u635f\u5931\u7684\u8ba1\u7b97\n        if cfg.POOLING_MODE == 'crop':\n            grid_xy = _affine_grid_gen(rois_domain.view(-1, 5), base_feat.size()[2:], self.grid_size)\n            grid_yx = torch.stack([grid_xy.data[:, :, :, 1], grid_xy.data[:, :, :, 0]], 3).contiguous()\n            pooled_feat_domain = self.RCNN_roi_crop(base_feat, Variable(grid_yx).detach())\n            if cfg.CROP_RESIZE_WITH_MAX_POOL:\n                pooled_feat_domain = F.max_pool2d(pooled_feat, 2, 2)\n\n            grid_xy_t = _affine_grid_gen(rois_domain_t.view(-1, 5), base_feat_t.size()[2:], self.grid_size)\n            grid_yx_t = torch.stack([grid_xy_t.data[:, :, :, 1], grid_xy_t.data[:, :, :, 0]], 3).contiguous()\n            pooled_feat_domain_t = self.RCNN_roi_crop(base_feat_t, Variable(grid_yx_t).detach())\n            if cfg.CROP_RESIZE_WITH_MAX_POOL:\n                pooled_feat_domain_t = F.max_pool2d(pooled_feat_t, 2, 2)\n        elif cfg.POOLING_MODE == 'align':\n            pooled_feat_domain = self.RCNN_roi_align(base_feat, rois_domain.view(-1, 5))\n            pooled_feat_domain_t = self.RCNN_roi_align(base_feat_t, rois_domain_t.view(-1, 5))\n        elif cfg.POOLING_MODE == 'pool':\n            pooled_feat_domain = self.RCNN_roi_pool(base_feat, rois_domain.view(-1, 5))\n            pooled_feat_domain_t = self.RCNN_roi_pool(base_feat_t, rois_domain_t.view(-1, 5))\n\n        # feed pooled features to top model\n        # \u5c06\u533a\u57df\u7279\u5f81\u4f20\u5165\u7f51\u7edc\u6700\u540e\u4e00\u4e2a\u9636\u6bb5\uff0c\u63d0\u53d6\u76f8\u5e94\u7684\u7279\u5f81(\u5982resnet\u4e2d\u7684layer4)\n        # \u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u5171\u5212\u5206\u4e3a\u56db\u4e2a\u9636\u6bb5\uff0cRPN\u524d\u6267\u884c\u4e09\u4e2a\u9636\u6bb5\uff0cRPN\u540e\u6267\u884c\u6700\u540e\u4e00\u4e2a\u9636\u6bb5\n        # \u5bf9\u4e09\u7ec4\u533a\u57df\u7279\u5f81\u4f9d\u6b21\u6267\u884c\u76f8\u540c\u7684\u64cd\u4f5c(Chief Net\u3001Ancillary Net\u4ee5\u53ca\u7528\u4e8e\u8ba1\u7b97\u5b9e\u4f8b\u7ea7\u7279\u5f81\u5bf9\u9f50\u635f\u5931\u7684proposals)\n        pooled_feat_s = self._head_to_tail(pooled_feat)\n        pooled_feat_t = self._head_to_tail(pooled_feat_t)\n\n        pooled_feat_domain_t = self._head_to_tail(pooled_feat_domain_t)\n\n        # \u9884\u6d4b\u8fb9\u754c\u6846\u4fe1\u606f\n        bbox_pred = self.RCNN_bbox_pred(pooled_feat_s)\n        bbox_pred_t = self.RCNN_bbox_pred(pooled_feat_t)\n        if self.training and not self.class_agnostic:\n            # select the corresponding columns according to roi labels\n            # ROI\u68c0\u6d4b\u5934\u4e3a\u6bcf\u4e2a\u951a\u70b9\u5747\u9884\u6d4b\u4e00\u7ec4\u56de\u5f52\u53c2\u6570\uff0c\u4e00\u7ec4\u56de\u5f52\u53c2\u6570\u5305\u62ec\u6240\u6709\u7c7b\u522b\u7684\u56de\u5f52\u8fb9\u754c\u6846\n            # \u5373\u6bcf\u4e2a\u951a\u70b9\u5bf9\u5e94num_classes * 4\u4e2a\u6570\u636e\n            # \u8fd9\u91cc\u6839\u636elabel\u6807\u7b7e\u4fe1\u606f\uff0c\u9009\u51fa\u7279\u5b9a\u7c7b\u522b\u7684\u56de\u5f52\u53c2\u6570\u53c2\u4e0e\u8ba1\u7b97\u56de\u5f52\u635f\u5931\n            bbox_pred_view = bbox_pred.view(bbox_pred.size(0), int(bbox_pred.size(1) / 4), 4)\n            bbox_pred_select = torch.gather(bbox_pred_view, 1,\n                                            rois_label.view(rois_label.size(0), 1, 1).expand(rois_label.size(0), 1, 4))\n            bbox_pred = bbox_pred_select.squeeze(1)\n\n            bbox_pred_view_t = bbox_pred_t.view(bbox_pred_t.size(0), int(bbox_pred_t.size(1) / 4), 4)\n            bbox_pred_select_t = torch.gather(bbox_pred_view_t, 1,\n                                              rois_label_t.view(rois_label_t.size(0), 1, 1).expand(rois_label_t.size(0),\n                                                                                                   1, 4))\n            bbox_pred_t = bbox_pred_select_t.squeeze(1)\n\n        # compute object classification probability\n        # \u9884\u6d4b\u7c7b\u522b\u6982\u7387\n        cls_score = self.RCNN_cls_score(pooled_feat_s)\n        cls_score_t = self.RCNN_cls_score(pooled_feat_t)\n        # \u6d4b\u8bd5\u7684\u65f6\u5019\u53ea\u5229\u7528Chief Net\u7f51\u7edc\u7684\u5206\u652f\u8fdb\u884c\u6d4b\u8bd5\uff0c\u56e0\u6b64\u53ea\u9700\u8981\u5bf9\u4e00\u4e2a\u9884\u6d4b\u6267\u884csoftmax\n        cls_prob = F.softmax(cls_score, 1)\n\n        RCNN_loss_cls = 0\n        RCNN_loss_bbox = 0\n\n        if self.training:\n            # \u4f9d\u6b21\u8ba1\u7b97\u5206\u7c7b\u635f\u5931\u548c\u8fb9\u754c\u6846\u56de\u5f52\u635f\u5931\n            # classification loss\n            RCNN_loss_cls_s = F.cross_entropy(cls_score, rois_label)\n            RCNN_loss_cls_t = F.cross_entropy(cls_score_t, rois_label_t)\n            RCNN_loss_cls = RCNN_loss_cls_s + RCNN_loss_cls_t\n\n            # bounding box regression L1 loss\n            RCNN_loss_bbox_s = _smooth_l1_loss(bbox_pred, rois_target, rois_inside_ws, rois_outside_ws)\n            RCNN_loss_bbox_t = _smooth_l1_loss(bbox_pred_t, rois_target_t, rois_inside_ws_t, rois_outside_ws_t)\n            RCNN_loss_bbox = RCNN_loss_bbox_s + RCNN_loss_bbox_t\n\n        # \u6d4b\u8bd5\u9636\u6bb5\u53ea\u5229\u7528Chief Net\u7f51\u7edc\u5206\u652f\u5f97\u5230\u7684\u9884\u6d4b\u6570\u636e\n        cls_prob = cls_prob.view(batch_size, rois_t.size(1), -1)\n        bbox_pred = bbox_pred.view(batch_size, rois_t.size(1), -1)\n\n        # \u540e\u9762\u6267\u884c\u5bf9\u76ee\u6807\u57df\u6570\u636e\u7684\u64cd\u4f5c\n        \"\"\" =================== for target ==========================\"\"\"\n        # \u5f97\u5230\u8f93\u5165\u6570\u636e\uff0c\u53d8\u91cf\u6240\u4ee3\u8868\u7684\u542b\u4e49\u4e0e\u6e90\u57df\u6570\u636e\u7c7b\u4f3c\n        tgt_batch_size = tgt_im_data.size(0)\n        tgt_im_info = tgt_im_info.data  # (size1,size2, image ratio(new image / source image) )\n        tgt_gt_boxes = tgt_gt_boxes.data\n        tgt_num_boxes = tgt_num_boxes.data\n        tgt_need_backprop = tgt_need_backprop.data\n\n        # feed image data to base model to obtain base feature map\n        # \u5c06\u76ee\u6807\u57df\u6570\u636e\u4f20\u5165Chief Net\u7f51\u7edc\uff0c\u4f9d\u6b21\u63d0\u53d6\u7279\u5f81\n        tgt_conv3_feat = self.conv3_s(tgt_im_data)\n        tgt_conv4_feat = self.conv34_s(tgt_conv3_feat)\n        tgt_base_feat = self.conv45_s(tgt_conv4_feat)\n\n        # feed base feature map tp RPN to obtain rois\n        # \u5c06\u7279\u5f81\u56fe\u4f20\u5165RPN\u6a21\u5757\uff0c\u5f97\u5230proposals\n        self.RCNN_rpn.eval()\n        cfg.TEST.RPN_POST_NMS_TOP_N = rois_domain.size(1)\n        tgt_rois, tgt_rpn_loss_cls, tgt_rpn_loss_bbox, tgt_anchor_score = \\\n            self.RCNN_rpn(tgt_base_feat, tgt_im_info, tgt_gt_boxes, tgt_num_boxes)\n\n        tgt_rois_label = torch.ones(tgt_rois.size(1))\n\n        # if it is training phrase, then use ground trubut bboxes for refining\n\n        tgt_rois_label = None\n        tgt_rois_target = None\n        tgt_rois_inside_ws = None\n        tgt_rois_outside_ws = None\n        tgt_rpn_loss_cls = 0\n        tgt_rpn_loss_bbox = 0\n\n        tgt_rois = Variable(tgt_rois)\n        # do roi pooling based on predicted rois\n        # \u5229\u7528proposals\u5bf9\u539f\u7279\u5f81\u56fe\u6267\u884croi pooling\u64cd\u4f5c\n        if cfg.POOLING_MODE == 'crop':\n            tgt_grid_xy = _affine_grid_gen(tgt_rois.view(-1, 5), tgt_base_feat.size()[2:], self.grid_size)\n            tgt_grid_yx = torch.stack([tgt_grid_xy.data[:, :, :, 1], tgt_grid_xy.data[:, :, :, 0]], 3).contiguous()\n            tgt_pooled_feat = self.RCNN_roi_crop(tgt_base_feat, Variable(tgt_grid_yx).detach())\n            if cfg.CROP_RESIZE_WITH_MAX_POOL:\n                tgt_pooled_feat = F.max_pool2d(tgt_pooled_feat, 2, 2)\n        elif cfg.POOLING_MODE == 'align':\n            tgt_pooled_feat = self.RCNN_roi_align(tgt_base_feat, tgt_rois.view(-1, 5))\n        elif cfg.POOLING_MODE == 'pool':\n            tgt_pooled_feat = self.RCNN_roi_pool(tgt_base_feat, tgt_rois.view(-1, 5))\n\n        # feed pooled features to top model\n        # \u5c06pooling\u5f97\u5230\u7684\u7279\u5f81\u4f20\u5165\u7f51\u7edc\u6700\u540e\u7684\u9636\u6bb5\uff0c\u4e0e\u6e90\u57df\u4f5c\u7528\u7c7b\u4f3c\n        tgt_pooled_feat = self._head_to_tail(tgt_pooled_feat)\n        # \u9884\u6d4b\u5206\u7c7b\u5206\u6570\uff0c\u4f46\u540e\u9762\u6ca1\u6709\u7528\u5230\n        tgt_cls_score = self.RCNN_cls_score(tgt_pooled_feat)\n        # \u540e\u7eed\u6ca1\u7528\u5230\u8fd9\u4e2a\u53d8\u91cf\uff0c\u56e0\u4e3a\u8bad\u7ec3\u9636\u6bb5\u7684\u76ee\u6807\u57df\u6570\u636e\u65e0\u6807\u7b7e\n        tgt_cls_prob = F.softmax(tgt_cls_score, 1)\n\n        # \u8ba1\u7b97\u57df\u9002\u5e94\u635f\u5931\uff0c\u9996\u5148\u8ba1\u7b97\u6e90\u57df\u6570\u636e\u7684\u57df\u9002\u5e94\u635f\u5931\n        # \u6ce8\u610f\uff0c\u8fd9\u91cc\u57df\u9002\u5e94\u635f\u5931\u53ea\u5229\u7528\u8f85\u52a9\u7f51\u4e2d\u7684\u6e90\u57df\u7279\u5f81\u548c\u4e3b\u7f51\u4e2d\u7684\u76ee\u6807\u57df\u7279\u5f81\u8ba1\u7b97\n        # \u4e3b\u7f51\u4e2d\u7684\u6e90\u57df\u7279\u5f81\u4e0d\u53c2\u4e0e\u57df\u9002\u5e94\u635f\u5931\u7684\u8ba1\u7b97\n        \"\"\"  DA loss   \"\"\"\n        # \u521d\u59cb\u5316\u635f\u5931\u53d8\u91cf\n        # DA LOSS\n        # \u6e90\u57df\u57df\u9002\u5e94\u635f\u5931\n        DA_img_loss_cls = 0\n        DA_ins_loss_cls = 0\n        # \u76ee\u6807\u57df\u57df\u9002\u5e94\u635f\u5931\n        tgt_DA_img_loss_cls = 0\n        tgt_DA_ins_loss_cls = 0\n\n        # \u4e09\u4e2a\u9636\u6bb5\u7684\u56fe\u50cf\u7ea7\u9886\u57df\u5bf9\u9f50\n        # DA conv3 \u9488\u5bf9conv3\u7684\u57df\u9002\u5e94\u6a21\u5757\n        # \u4f9d\u6b21\u8fd4\u56de\u9886\u57df\u9884\u6d4b\u5206\u6570\u548c\u5bf9\u5e94\u7684\u6807\u7b7e\n        conv3_score, conv3_label = self.RCNN_imageDA_3(conv3_feat_t, need_backprop)\n        # \u9884\u6d4b\u5206\u6570\u7ecf\u8fc7\u4e00\u5c42softmax\u3002\u5176\u5b9e\u8fd9\u91cc\u4e0d\u7ecf\u8fc7softmax\u4e5f\u884c\uff0c\u76f4\u63a5\u4f20\u5165\u4ea4\u53c9\u71b5\u635f\u5931\n        conv3_prob = F.log_softmax(conv3_score, dim=1)\n        # \u8ba1\u7b97\u635f\u5931\uff0c\u9884\u6d4b\u5206\u6570\u7ecf\u8fc7\u4e86softmax\uff0c\u518d\u5229\u7528nll_loss\u8ba1\u7b97\u635f\u5931\n        DA_img_loss_conv3 = F.nll_loss(conv3_prob, conv3_label, ignore_index=-1)\n\n        # conv4\u548cconv5\u4e24\u4e2a\u9636\u6bb5\u7684\u56fe\u50cf\u7ea7\u57df\u9002\u5e94\u6a21\u5757\u6d41\u7a0b\u4e0econv3\u7c7b\u4f3c\n        # DA conv4\n        conv4_score, conv4_label = self.RCNN_imageDA_4(conv4_feat_t, need_backprop)\n\n        conv4_prob = F.log_softmax(conv4_score, dim=1)\n        DA_img_loss_conv4 = F.nll_loss(conv4_prob, conv4_label, ignore_index=-1)\n\n        # DA conv5\n        base_score, base_label = self.RCNN_imageDA(base_feat_t, need_backprop)\n\n        base_prob = F.log_softmax(base_score, dim=1)\n        DA_img_loss_conv5 = F.nll_loss(base_prob, base_label, ignore_index=-1)\n        # \u6c42\u548c\u5f97\u5230\u603b\u7684\u56fe\u50cf\u7ea7\u57df\u9002\u5e94\u635f\u5931\n        DA_img_loss_cls = DA_img_loss_conv3 + DA_img_loss_conv4 + DA_img_loss_conv5\n\n        # instance DA \u8ba1\u7b97\u5b9e\u4f8b\u7ea7\u57df\u9002\u5e94\u635f\u5931\n        # \u5f97\u5230\u5b9e\u4f8b\u7ea7\u9886\u57df\u9884\u6d4b\u5206\u6570\u548c\u5bf9\u5e94\u7684\u6807\u7b7e\n        instance_sigmoid, same_size_label = self.RCNN_instanceDA(pooled_feat_domain_t, need_backprop)\n        # \u521d\u59cb\u5316\u635f\u5931\u51fd\u6570\n        instance_loss = nn.BCELoss()\n        # \u8ba1\u7b97\u635f\u5931\n        DA_ins_loss_cls = instance_loss(instance_sigmoid, same_size_label)\n\n        # \u8ba1\u7b97\u76ee\u6807\u57df\u6570\u636e\u7684\u57df\u9002\u5e94\u635f\u5931\uff0c\u6d41\u7a0b\u4e0e\u6e90\u57df\u7c7b\u4f3c\n        \"\"\"  ************** target loss ****************  \"\"\"\n\n        # DA conv3 target\n        tgt_conv3_score, tgt_conv3_label = \\\n            self.RCNN_imageDA_3(tgt_conv3_feat, tgt_need_backprop)\n\n        tgt_conv3_prob = F.log_softmax(tgt_conv3_score, dim=1)\n        tgt_DA_img_loss_conv3 = F.nll_loss(tgt_conv3_prob, tgt_conv3_label, ignore_index=-1)\n\n        # DA conv4 target\n        tgt_conv4_score, tgt_conv4_label = \\\n            self.RCNN_imageDA_4(tgt_conv4_feat, tgt_need_backprop)\n\n        tgt_conv4_prob = F.log_softmax(tgt_conv4_score, dim=1)\n        tgt_DA_img_loss_conv4 = F.nll_loss(tgt_conv4_prob, tgt_conv4_label, ignore_index=-1)\n\n        # DA conv5 target\n        tgt_base_score, tgt_base_label = \\\n            self.RCNN_imageDA(tgt_base_feat, tgt_need_backprop)\n\n        tgt_base_prob = F.log_softmax(tgt_base_score, dim=1)\n        tgt_DA_img_loss_conv5 = F.nll_loss(tgt_base_prob, tgt_base_label, ignore_index=-1)\n        tgt_DA_img_loss_cls = tgt_DA_img_loss_conv3 + tgt_DA_img_loss_conv4 + tgt_DA_img_loss_conv5\n\n        # instance_target\n        tgt_instance_sigmoid, tgt_same_size_label = \\\n            self.RCNN_instanceDA(tgt_pooled_feat, tgt_need_backprop)\n        tgt_instance_loss = nn.BCELoss()\n\n        tgt_DA_ins_loss_cls = tgt_instance_loss(tgt_instance_sigmoid, tgt_same_size_label)\n        # \u8fd4\u56de\u6570\u636e\n        return rois_t, cls_prob, bbox_pred, rpn_loss_cls, rpn_loss_bbox, RCNN_loss_cls, RCNN_loss_bbox, rois_label_t, \\\n               DA_img_loss_cls, tgt_DA_img_loss_cls, DA_ins_loss_cls, tgt_DA_ins_loss_cls\n</code></pre>"},{"location":"domain_adaptive/code/ATF2/#_5","title":"\u57df\u9002\u5e94\u6a21\u5757","text":"<p>\u8fd9\u4e24\u4e2a\u6a21\u578b\u90fd\u53c2\u8003DA Faster\u4e2d\u7684\u57df\u9002\u5e94\u6a21\u5757</p>"},{"location":"domain_adaptive/code/ATF2/#_6","title":"\u56fe\u50cf\u7ea7\u57df\u5206\u7c7b\u5668","text":"<pre><code>class _ImageDA(nn.Module):\n    def __init__(self, dim):\n        super(_ImageDA, self).__init__()\n        self.dim = dim\n        # \u5b9a\u4e49\u597d\u5377\u79ef\u5c42\u4ee5\u53ca\u6fc0\u6d3b\u5c42\n        self.Conv1 = nn.Conv2d(self.dim, 512, kernel_size=1, stride=1, bias=False)\n        self.Conv2 = nn.Conv2d(512, 2, kernel_size=1, stride=1, bias=False)\n        self.reLu = nn.ReLU(inplace=False)\n        # \u5b9a\u4e49\u6807\u7b7e\u751f\u6210\u5668\n        self.LabelResizeLayer = ImageLabelResizeLayer()\n\n    def forward(self, x, need_backprop):\n        # \u5957\u4e00\u4e2a\u68af\u5ea6\u53cd\u8f6c\u6a21\u5757\n        x = grad_reverse(x, need_backprop)\n        # conv1-&gt;relu-&gt;conv2\n        x = self.reLu(self.Conv1(x))\n        x = self.Conv2(x)\n        # \u751f\u6210\u5bf9\u5e94\u7684\u6807\u7b7e\n        label = self.LabelResizeLayer(x, need_backprop)\n        return x, label\n</code></pre>"},{"location":"domain_adaptive/code/ATF2/#_7","title":"\u5b9e\u4f8b\u7ea7\u57df\u5206\u7c7b\u5668","text":"<pre><code>class _InstanceDA(nn.Module):\n    def __init__(self):\n        super(_InstanceDA, self).__init__()\n        # \u5b9a\u4e49\u597d\u7ebf\u6027\u56de\u5f52\u5c42\u3001\u6fc0\u6d3b\u5c42\u3001dropout\u5c42\n        self.dc_ip1 = nn.Linear(4096, 1024)\n        self.dc_relu1 = nn.ReLU()\n        self.dc_drop1 = nn.Dropout(p=0.5)\n\n        self.dc_ip2 = nn.Linear(1024, 1024)\n        self.dc_relu2 = nn.ReLU()\n        self.dc_drop2 = nn.Dropout(p=0.5)\n\n        self.clssifer = nn.Linear(1024, 1)\n        # \u5b9a\u4e49\u6807\u7b7e\u751f\u6210\u5668\n        self.LabelResizeLayer = InstanceLabelResizeLayer()\n\n    def forward(self, x, need_backprop):\n        # \u5957\u4e00\u4e2a\u68af\u5ea6\u53cd\u8f6c\u6a21\u5757\n        x = grad_reverse(x, need_backprop)\n        # fc-&gt;relu-&gt;dropout\n        x = self.dc_drop1(self.dc_relu1(self.dc_ip1(x)))\n        x = self.dc_drop2(self.dc_relu2(self.dc_ip2(x)))\n        # sigmoid\u5f52\u4e00\u5316\u64cd\u4f5c\n        x = F.sigmoid(self.clssifer(x))\n        # \u751f\u6210\u5bf9\u5e94\u7684\u6807\u7b7e\n        label = self.LabelResizeLayer(x, need_backprop)\n        return x, label\n</code></pre> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e743\u670819\u65e5</p>"},{"location":"domain_adaptive/code/CST-MCD2/","title":"\u57df\u9002\u5e94\uff1aCST-MCD","text":""},{"location":"domain_adaptive/code/CST-MCD2/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aEuropean Conference on Computer Vision 2020 (ECCV 20)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123630086.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/uitrbn/CST_DA_detection</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b</p>"},{"location":"domain_adaptive/code/CST-MCD2/#_2","title":"\u7f51\u7edc\u7ed3\u6784","text":"<p>\u7a0b\u5e8f\u4f4d\u4e8e\uff1aCST_DA_detection-master\\lib\\model\\faster_rcnn\\faster_rcnn.py</p>"},{"location":"domain_adaptive/code/CST-MCD2/#_3","title":"\u53c2\u6570\u521d\u59cb\u5316","text":"<pre><code>class _fasterRCNN(nn.Module):\n    \"\"\" faster RCNN \"\"\"\n\n    def __init__(self, classes, class_agnostic):\n        super(_fasterRCNN, self).__init__()\n        self.classes = classes\n        self.n_classes = len(classes)\n        self.class_agnostic = class_agnostic\n        # loss\n        self.RCNN_loss_cls = 0\n        self.RCNN_loss_bbox = 0\n\n        # define rpn\n        # RPN\u6a21\u5757\n        self.RCNN_rpn = _RPN(self.dout_base_model)\n        # \u4e3a\u6e90\u57df\u6570\u636e\u6bcf\u4e2aproposal\u6253\u6807\u7b7e\uff0c\u5e76\u4e14\u7b5b\u9009\u7279\u5b9a\u6bd4\u4f8b\u7684\u6b63\u8d1fproposal\u6837\u672c\n        self.RCNN_proposal_target = _ProposalTargetLayer(self.n_classes)\n        # \u7b5b\u9009\u76ee\u6807\u57df\u4e2d\u7684proposal\uff0c\u76f4\u63a5\u9009\u53d6\u524d256\u4e2a\u63d0\u8bae\u6846\n        self.RCNN_proposal_target_for_target = _ProposalTargetLayerForTarget(self.n_classes)\n        # ROI pooling\u6a21\u5757\n        self.RCNN_roi_pool = _RoIPooling(cfg.POOLING_SIZE, cfg.POOLING_SIZE, 1.0 / 16.0)\n        self.RCNN_roi_align = RoIAlignAvg(cfg.POOLING_SIZE, cfg.POOLING_SIZE, 1.0 / 16.0)\n\n        self.grid_size = cfg.POOLING_SIZE * 2 if cfg.CROP_RESIZE_WITH_MAX_POOL else cfg.POOLING_SIZE\n        self.RCNN_roi_crop = _RoICrop()\n\n        # local discriminator\n        from lib.model.faster_rcnn.vgg16 import vgg16\n        from lib.model.faster_rcnn.resnet import resnet101\n        # \u5c40\u90e8\u7279\u5f81\u5bf9\u9f50\u6a21\u5757\uff0c\u5bf9\u4e8e\u4e0d\u540c\u7684\u4e3b\u5e72\u7f51\u7edc\u521d\u59cb\u5316\u4e0d\u540c\u7684\u8f93\u5165\u7279\u5f81\u901a\u9053\u6570\n        if isinstance(self, vgg16):\n            self.local_discriminator = LocalDiscriminator(256)\n        else:\n            self.local_discriminator = LocalDiscriminator(512)\n        # \u5c40\u90e8\u5bf9\u9f50\u6a21\u5757\u7684\u635f\u5931\n        self.local_loss_layer = LossForLocal()\n\n        # cls entropy minimization CLS\u8bad\u7ec3\uff0c\u5373\u76ee\u6807\u57df\u4e2dRPC\u6a21\u5757\u7684\u635f\u5931\n        self.loss_rpn_cls_layer = LossForRPNCLS(5)\n\n        # generate rpn target for pl box RPN\u8bad\u7ec3\uff0c\u76ee\u6807\u57df\u4e2dRPN\u6a21\u5757\u7684\u635f\u5931\n        self.rpn_training_target = RPN_training_target()\n\n        # minimize discrepancy MCD\u635f\u5931\n        self.loss_for_discrepancy = LossForDiscrepancy()\n</code></pre>"},{"location":"domain_adaptive/code/CST-MCD2/#_4","title":"\u524d\u5411\u4f20\u64ad","text":"<p>\u6ce8\uff1a\u7531\u4e8e\u76ee\u6807\u57df\u7f3a\u5c11\u6807\u7b7e\uff0c\u56e0\u6b64\u5728\u76ee\u6807\u57df\u56fe\u7247\u7684\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u65e0\u6cd5\u7b5b\u9009\u51fa\u7279\u5b9a\u6bd4\u4f8b\u7684\u6b63\u8d1f\u6837\u672c\u53c2\u4e0e\u8bad\u7ec3\uff0c\u6e90\u7801\u4e2d\u76f4\u63a5\u6309\u5206\u6570\u6392\u5e8f\uff0c\u9009\u53d6\u4e86\u524d256\u4e2a\u3002</p> <pre><code># domain_label\u6e90\u57df\u8868\u793a1\uff0c\u76ee\u6807\u57df\u8868\u793a0\n    def forward(self, im_data, im_info, gt_boxes, num_boxes, domain_label, imdb=None):\n\n        if not global_variable.ProcessDontCare and global_variable.ImdbIsKitti:\n            # ignore dontcare when imdb is kitti\n            # pdb.set_trace()\n            gt_boxes[gt_boxes[:, :, -1] == 3] = 0\n            gt_boxes = torch.cat((gt_boxes[gt_boxes[:, :, -1] != 0], gt_boxes[gt_boxes[:, :, -1] == 0]), 0).view(1, -1,\n                                                                                                                 5)\n\n        global counter\n        # \u5f97\u5230batch size\u5c3a\u5bf8\n        batch_size = im_data.size(0)\n        #\n        im_info = im_info.data\n        gt_boxes = gt_boxes.data\n        num_boxes = num_boxes.data\n\n        # \u5c06\u56fe\u50cf\u4f20\u5165\u57fa\u7ebf\u7f51\u7edc\u8fdb\u884c\u63d0\u53d6\u7279\u5f81\uff0c\u8fd9\u91cc\u5206\u4e3a\u4e86\u4e24\u4e2a\u9636\u6bb5\n        # \u4ee5resnet\u4e3a\u4f8b\uff0c\u7b2c\u4e00\u9636\u6bb5(base1)\u662f\u5f00\u59cb\u5230layer3\uff0c\u7b2c\u4e8c\u9636\u6bb5(base2)\u662flayer4\n        # \u7b2c\u4e00\u9636\u6bb5\u7684\u8f93\u51fa\u4e3b\u8981\u7528\u4e8e\u5c40\u90e8\u7279\u5f81\u5bf9\u9f50\uff0c\u5373\u6587\u4e2d\u76843.4\u5c0f\u8282\n        local_base_feat = self.RCNN_base1(im_data)\n        base_feat = self.RCNN_base2(local_base_feat)\n\n        # \u5c06\u7279\u5f81\u4f20\u5165RPN\u6a21\u5757\uff0c\u5f97\u5230\u611f\u5174\u8da3\u7684\u533a\u57df\uff0c\u6839\u636e\u56fe\u7247\u9886\u57df\u7684\u4e0d\u540c\uff0c\u4f1a\u8fd4\u56de\u4e0d\u540c\u7684\u7ed3\u679c\n        if domain_label == 1:  # source\n            # \u4f9d\u6b21\u8fd4\u56de\u533a\u57df\u5efa\u8baeproposal\u3001rpn\u5206\u7c7b(\u524d\u540e\u666f)\u3001rpn\u56de\u5f52\u635f\u5931\u3001proposal\u5bf9\u5e94\u7684\u9884\u6d4b\u5206\u6570(\u5df2\u5207\u65ad\u68af\u5ea6)\u3001\u5e26\u6709\u68af\u5ea6\u7684\u524d\u666f\u9884\u6d4b\u5206\u6570(\u4e3b\u8981\u7528\u4e8e\u8ba1\u7b97\u5c40\u90e8\u5bf9\u9f50\u6a21\u5757\u7684\u6743\u91cd)\n            rois_before, rpn_loss_cls, rpn_loss_bbox, roi_scores_before, rpn_cls_prob = self.RCNN_rpn(base_feat,\n                                                                                                      im_info, gt_boxes,\n                                                                                                      num_boxes,\n                                                                                                      domain_label)\n        elif domain_label == 0:  # target\n            # rpn_cls_score\u8868\u793arpn\u4e2d\u53c2\u4e0e\u635f\u5931\u8ba1\u7b97\u7684\u524d\u540e\u666f\u9884\u6d4b\u5206\u6570(\u6309\u7279\u5b9a\u6b63\u8d1f\u6837\u672c\u6bd4\u4f8b\u7b5b\u9009\u540e\u7684\u5206\u6570)\n            # rpn_cls_score_reshape\u8868\u793areshape\u540e\u7684\u9884\u6d4b\u5206\u6570\uff0c\u5c3a\u5bf8\u4e3a[\u951a\u70b9\u6570\u91cf\uff0c2],2\u4ee3\u8868\u524d\u540e\u666f\u5206\u6570\n            # rpn_bbox_pred\u8868\u793arpn\u9884\u6d4b\u7684\u8fb9\u754c\u6846\u56de\u5f52\u53c2\u6570\n            # roi_scores_with_grad\u8868\u793a\u5e26\u6709\u68af\u5ea6\u7684proposal\u5206\u6570\n            rois_before, rpn_loss_cls, rpn_loss_bbox, roi_scores_before, \\\n            rpn_cls_score, rpn_cls_score_reshape, batch_size, rpn_bbox_pred, rpn_cls_prob, roi_scores_with_grad \\\n                = self.RCNN_rpn(base_feat, im_info, gt_boxes, num_boxes, domain_label)\n\n        # if it is training phase, then use ground truth bboxes for refining\n        if self.training:\n            # \u5728\u5c40\u90e8\u5bf9\u9f50\u4e4b\u524d\uff0c\u5148\u5c06\u7279\u5f81\u4f20\u5165\u68af\u5ea6\u53cd\u8f6c\u5c42\n            reversed_local_feat = ReverseLayerF.apply(local_base_feat, 0.5)\n            # \u5c06\u6d45\u5c42\u7279\u5f81\u4f20\u5165\u5c40\u90e8\u57df\u5206\u7c7b\u5668(\u50cf\u7d20\u7ea7\u522b)\uff0c\u5f97\u5230\u9886\u57df\u9884\u6d4b\u56fe\n            local_dis_output, _ = self.local_discriminator(reversed_local_feat)\n            # \u4f7f\u7528heat map global loss\n            # \u5c06\u57df\u5206\u7c7b\u5668\u7ed3\u679c\u3001\u9886\u57df\u6807\u7b7e\u3001\u524d\u666f\u9884\u6d4b\u56fe(\u5bf9\u5e94\u8bba\u6587\u4e2dfi)\u4f20\u5165local_loss_layer\uff0c\u8ba1\u7b97\u57df\u5206\u7c7b\u635f\u5931\uff0c\u4e0e\u8bba\u6587\u516c\u5f0f11\u300112\u5bf9\u5e94\n            domain_cls_loss = self.local_loss_layer(local_dis_output, domain_label, rpn_cls_prob)\n            # local_dis_output_0\u7f51\u7edc\u4e2d\u540e\u9762\u6ca1\u6709\u7528\u5230\uff0c\u76f4\u63a5\u5728\u6700\u540e\u8fd4\u56de\u4e86\n            local_dis_output_0 = local_dis_output.mean()\n\n            # rpn filter and rpn target for cls and reg calculation\n            if domain_label == 1:  # source\n                # \u6e90\u57df\u6570\u636e\uff0c\u4e3a\u6bcf\u4e2aproposal\u5206\u914d\u7c7b\u522b\u6807\u7b7e\u548c\u56de\u5f52\u53c2\u6570\uff0c\u5e76\u4e14\u5bf9\u951a\u70b9\u8fdb\u884c\u7b5b\u9009(\u6309\u7279\u5b9a\u7684\u6b63\u8d1f\u6837\u672c\u6bd4\u4f8b\u7b5b\u9009)\uff0c\u7b5b\u9009\u51fa\u53c2\u4e0eRPC\u635f\u5931\u8ba1\u7b97\u7684proposal\n                roi_data = self.RCNN_proposal_target(rois_before, gt_boxes, num_boxes)\n                # rois\u8868\u793a\u53c2\u4e0eROI Pooling\u7684\u533a\u57df\u3001rois_label\u8868\u793a\u533a\u57df\u7c7b\u522b\u3001rois_target\u8868\u793a\u533a\u57df\u5bf9\u5e94\u7684\u56de\u5f52\u53c2\u6570\n                rois, rois_label, rois_target, rois_inside_ws, rois_outside_ws = roi_data\n            else:  # target\n                # \u76ee\u6807\u57df\u6570\u636e\uff0c\u7531\u4e8e\u76ee\u6807\u57df\u6570\u636e\u7f3a\u5c11\u6807\u7b7e\uff0c\u56e0\u6b64\u65e0\u6cd5\u5bf9\u9884\u6d4b\u7684ROI\u8fdb\u884c\u7b5b\u9009\uff0c\u56e0\u6b64\u76ee\u6807\u57df\u76f4\u63a5\u9009\u53d6\u524d256\u4e2a\u951a\u70b9\u5bf9\u5e94\u7684roi\u89c6\u4e3aproposal\n                # \u6309\u9884\u6d4b\u5206\u6570\u6392\u5e8f\uff0c\u5bf9\u9884\u6d4b\u5206\u6570\u5148\u6267\u884c\u4e86nms\uff0c\u6267\u884c\u540e\u5f97\u5230\u7684\u6570\u636e\u4e3a\u6392\u5e8f\u540e\u7684\u6570\u636e\uff0c\u518d\u9009\u53d6\u524d256\u4e2a\u53c2\u4e0eRPC\u7684\u8fd0\u7b97\uff0c\u5bf9\u5e94\u4e0b\u9762\u7684roi\n                roi_data = self.RCNN_proposal_target_for_target(rois_before, gt_boxes, num_boxes, roi_scores_before,\n                                                                roi_scores_with_grad)\n                # roi_scores\u8868\u793aroi\u5bf9\u5e94\u7684\u9884\u6d4b\u5206\u6570\uff0c\u7528\u4e8e\u8ba1\u7b97\u76ee\u6807\u57df\u6570\u636e\u7684RPC\u635f\u5931(\u8d77\u5230\u52a0\u6743\u7684\u4f5c\u7528)\uff0c\u8fd9\u91cc\u5df2\u7ecf\u5207\u65ad\u68af\u5ea6\u4e86\n                # roi_scores_grad\u8868\u793a\u5e26\u6709\u68af\u5ea6\u7684roi\u9884\u6d4b\u5206\u6570\uff0c\u7528\u4e8e\u8ba1\u7b97MDC\u635f\u5931\n                # \u76ee\u6807\u57df\u6837\u672c\u65e0\u6cd5\u5229\u7528rois_label\u3001rois_target\uff0c\u56e0\u4e3a\u6ca1\u6709\u6807\u7b7e\n                rois, rois_label, rois_target, rois_inside_ws, rois_outside_ws, roi_scores, roi_scores_grad = roi_data\n\n            rois_label = Variable(rois_label.view(-1).long())\n            rois_target = Variable(rois_target.view(-1, rois_target.size(2)))\n            rois_inside_ws = Variable(rois_inside_ws.view(-1, rois_inside_ws.size(2)))\n            rois_outside_ws = Variable(rois_outside_ws.view(-1, rois_outside_ws.size(2)))\n        else:\n            rois_label = None\n            rois_target = None\n            rois_inside_ws = None\n            rois_outside_ws = None\n            rpn_loss_cls = 0\n            rpn_loss_bbox = 0\n            domain_cls_loss = 0\n            local_dis_output_0 = 0\n        # \u5982\u679c\u662f\u8bad\u7ec3\u9636\u6bb5\uff0c\u5219\u9009\u62e9\u4e4b\u524d\u7b5b\u9009\u597d\u7684roi\uff1b\u5982\u679c\u662f\u6d4b\u8bd5\u9636\u6bb5\uff0c\u5219\u6ca1\u6cd5\u8fdb\u884c\u7b5b\u9009\uff0c\u76f4\u63a5\u5229\u7528\u7b5b\u9009\u524d\u7684roi\n        rois = Variable(rois) if self.training else Variable(rois_before)\n        # do roi pooling based on predicted rois\n        # \u4e0d\u540c\u7b56\u7565\u7684ROI Pooling\n        if cfg.POOLING_MODE == 'crop':\n            # pdb.set_trace()\n            # pooled_feat_anchor = _crop_pool_layer(base_feat, rois.view(-1, 5))\n            grid_xy = _affine_grid_gen(rois.view(-1, 5), base_feat.size()[2:], self.grid_size)\n            grid_yx = torch.stack([grid_xy.data[:, :, :, 1], grid_xy.data[:, :, :, 0]], 3).contiguous()\n            pooled_feat = self.RCNN_roi_crop(base_feat, Variable(grid_yx).detach())\n            if cfg.CROP_RESIZE_WITH_MAX_POOL:\n                pooled_feat = F.max_pool2d(pooled_feat, 2, 2)\n        elif cfg.POOLING_MODE == 'align':\n            pooled_feat = self.RCNN_roi_align(base_feat, rois.view(-1, 5))\n        elif cfg.POOLING_MODE == 'pool':\n            pooled_feat = self.RCNN_roi_pool(base_feat, rois.view(-1, 5))\n\n        # feed pooled features to top model\uff0c\u5f97\u5230\u6bcf\u4e2a\u533a\u57df\u7684\u7279\u5f81\n        pooled_feat = self._head_to_tail(pooled_feat)\n\n        # compute bbox offset\n        # \u9884\u6d4bRPC\u4e2d\u8fb9\u754c\u6846\u56de\u5f52\u53c2\u6570\n        bbox_pred = self.RCNN_bbox_pred(pooled_feat)\n        if self.training and not self.class_agnostic:\n            # select the corresponding columns according to roi labels\n            bbox_pred_view = bbox_pred.view(bbox_pred.size(0), int(bbox_pred.size(1) / 4), 4)\n            bbox_pred_select = torch.gather(bbox_pred_view, 1,\n                                            rois_label.view(rois_label.size(0), 1, 1).expand(rois_label.size(0), 1, 4))\n            bbox_pred = bbox_pred_select.squeeze(1)\n\n        # compute object classification probability\n        # \u9884\u6d4b\u7c7b\u522b\u5206\u6570\n        cls_score = self.RCNN_cls_score(pooled_feat)\n        cls_prob = F.softmax(cls_score, 1)\n\n        rpn_cls_align_loss = 0\n\n        # \u76ee\u6807\u57df\u6570\u636e\u7684\u8bad\u7ec3\u9636\u6bb5\n        if domain_label == 0 and self.training:\n            # cls entropy minimization CLS\uff0c\u7528\u4e8e\u8bad\u7ec3RPC\u6a21\u5757\u7684\u6700\u5c0f\u71b5\u503c\u635f\u5931\uff0c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f(4)\n            # \u4f20\u5165\u9884\u6d4b\u7684\u7c7b\u522b\u5206\u6570\u3001roi\u5206\u6570(\u5373RPN\u9884\u6d4b\u7684proposal\u5206\u6570)\n            rpn_cls_align_loss = self.loss_rpn_cls_layer(cls_score, roi_scores.squeeze())\n\n        RCNN_loss_cls = 0\n        RCNN_loss_bbox = 0\n        # \u6e90\u57df\u6570\u636e\u7684\u8bad\u7ec3\u9636\u6bb5\n        if self.training and domain_label == 1:\n            # classification loss\uff0c\u5206\u7c7b\u635f\u5931\n            if global_variable.ProcessDontCare:\n                RCNN_loss_cls = F.cross_entropy(cls_score, rois_label, weight=torch.FloatTensor([1, 1, 1, 0]).cuda())\n            else:\n                RCNN_loss_cls = F.cross_entropy(cls_score, rois_label)\n\n            # \u8fb9\u754c\u6846\u56de\u5f52\u635f\u5931\n            RCNN_loss_bbox = _smooth_l1_loss(bbox_pred, rois_target, rois_inside_ws, rois_outside_ws)\n\n        cls_prob = cls_prob.view(batch_size, rois.size(1), -1)\n        bbox_pred = bbox_pred.view(batch_size, rois.size(1), -1)\n\n        # \u76ee\u6807\u57df\u7684\u8bad\u7ec3\u9636\u6bb5\n        if domain_label == 0 and self.training:\n\n            # weight version\uff0c\u4f20\u5165proposal(\u7b5b\u9009\u540e\u7684roi)\u4ee5\u53ca\u5bf9\u5e94\u7684\u7c7b\u522b\u9884\u6d4b\u5206\u6570\n            # \u5229\u7528RPC\u7684\u9884\u6d4b\u7ed3\u679c\u5bf9RPN\u4e2d\u7684\u9884\u6d4b\u6253\u6807\u7b7e\n            gt_boxes, gt_num, gf_boxes, gf_num, gt_score, gf_score = generate_boxes_from_cls_score(rois, cls_prob, imdb)\n            counter += 1\n            if gt_num &gt; 0 and gf_num &gt; 0:\n                gt_boxes = gt_boxes.cuda()\n                gf_boxes = gf_boxes.cuda()\n                # \u8ba1\u7b97\u76ee\u6807\u57df\u4e2dRPN\u7684\u5206\u7c7b\u635f\u5931\u548c\u8fb9\u754c\u6846\u56de\u5f52\u635f\u5931\n                rpn_loss_cls, rpn_loss_bbox = self.rpn_training_target(gt_boxes, im_info, num_boxes, domain_label,\n                                                                       gf_boxes, rpn_cls_score, rpn_cls_score_reshape,\n                                                                       batch_size, rpn_bbox_pred, gt_score, gf_score)\n            else:\n                print(\"gt num : {}, gf num : {}\".format(gt_num, gf_num))\n                rpn_loss_cls = 0\n                rpn_loss_bbox = 0\n        # \u76ee\u6807\u57df\u7684\u8bad\u7ec3\u9636\u6bb5\n        if domain_label == 0 and self.training:\n            # \u8ba1\u7b97MDC\u635f\u5931\uff0c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f10\uff0c\u8f93\u5165RPC\u4e2d\u7684\u7c7b\u522b\u9884\u6d4b\u5206\u6570\u548cRPN\u4e2d\u7684\u524d\u540e\u666f\u9884\u6d4b\u5206\u6570\n            # \u4f9d\u6b21\u5f97\u5230\u4e24\u79cd\u635f\u5931\uff0c\u5206\u522b\u5bf9\u5e94\u4e8e\u7279\u5f81\u63d0\u53d6\u5668F(\u6700\u5c0f\u5316MDC)\uff0c\u548cRPN\u3001RPC\u4e2d\u7684\u5206\u7c7b\u6a21\u5757(\u6700\u5927\u5316MDC)\n            discrepancy_loss_min, discrepancy_loss_max = self.loss_for_discrepancy(cls_score, roi_scores_grad.squeeze())\n        else:\n            discrepancy_loss_min = 0\n            discrepancy_loss_max = 0\n\n        return rois, cls_prob, bbox_pred, rpn_loss_cls, rpn_loss_bbox, RCNN_loss_cls, RCNN_loss_bbox, rois_label, domain_cls_loss, local_dis_output_0, rpn_cls_align_loss, discrepancy_loss_min, discrepancy_loss_max\n</code></pre>"},{"location":"domain_adaptive/code/CST-MCD2/#_5","title":"\u50cf\u7d20\u7ea7\u57df\u5206\u7c7b\u5668","text":"<p>\u9488\u5bf9\u5c40\u90e8\u7279\u5f81\u5bf9\u9f50</p> <pre><code># \u50cf\u7d20\u7ea7\u522b\u7684\u5c40\u90e8\u57df\u5206\u7c7b\u5668\nclass LocalDiscriminator(nn.Module):\n    def __init__(self, in_channels):\n        super(LocalDiscriminator, self).__init__()\n        # \u4f9d\u6b21\u5b9a\u4e49\u4e09\u5c42\u5377\u79ef\uff0c\u6700\u540e\u4e00\u5c42\u8f93\u51fa\u901a\u9053\u6570\u4e3a1\n        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=256, kernel_size=1, stride=1, padding=0)\n        self.conv2 = nn.Conv2d(in_channels=256, out_channels=128, kernel_size=1, stride=1, padding=0)\n        self.conv3 = nn.Conv2d(in_channels=128, out_channels=1, kernel_size=1, stride=1, padding=0)\n\n    def forward(self, input):\n        # \u4f9d\u6b21\u7ecf\u8fc7\u5377\u79ef\uff0crelu\n        x = input\n        x = self.conv1(x)\n        x = F.relu(x)\n        x = self.conv2(x)\n        x = F.relu(x)\n        # context_vector\u540e\u9762\u6ca1\u7528\u5230\n        context_vector = x.detach()\n        x = self.conv3(x)\n        # \u6700\u540e\u7ecf\u8fc7sigmoid\u5f52\u4e00\u5316\u64cd\u4f5c\uff0c\u5f97\u5230\u9884\u6d4b\u6982\u7387\n        x = F.sigmoid(x)\n        # \u8fd4\u56de\u9884\u6d4b\u6982\u7387\n        return x, context_vector\n</code></pre>"},{"location":"domain_adaptive/code/CST-MCD2/#_6","title":"\u635f\u5931\u51fd\u6570","text":""},{"location":"domain_adaptive/code/CST-MCD2/#rpc","title":"RPC\u534f\u540c\u81ea\u8bad\u7ec3\u635f\u5931","text":"<pre><code># RPC\u6a21\u5757\u534f\u540c\u8bad\u7ec3\u635f\u5931\nclass LossForRPNCLS(nn.Module):\n    def __init__(self, power):\n        super(LossForRPNCLS, self).__init__()\n        # \u5b9a\u4e49\u53c2\u6570lambda\uff0c\u5bf9\u5e94\u516c\u5f0f6\u4e2d\u7684\u6307\u6570\uff0c\u9ed8\u8ba45\n        self.power = power\n\n    def forward(self, cls_score, roi_score):\n        # \u4e0b\u8ff0\u4e09\u884c\u4ee3\u7801\u76f8\u5f53\u4e8e\u8ba1\u7b97\u516c\u5f0f(6)\n        # \u6309roi_score\u4e0e0.5\u7684\u76f8\u5bf9\u5927\u5c0f\u5206\u5f00\u8ba1\u7b97\uff0c\u76f8\u5f53\u4e8e\u5c06\u516c\u5f0f(6)\u4e2d\u7684\u7edd\u5bf9\u503c\u62c6\u5f00\n        factor_bigger_half = (2 * roi_score - 1).pow(self.power)\n        factor_smaller_half = (1 - 2 * roi_score).pow(self.power)\n        factor = (roi_score &gt; 0.5).float() * factor_bigger_half + (roi_score &lt;= 0.5).float() * factor_smaller_half\n        # \u5f97\u5230\u6743\u91cdfw\uff0c\u6ce8\u610f\u8fd9\u91cc\u5207\u65ad\u4e86\u68af\u5ea6\uff0c\u5373\u8fd9\u4e2a\u635f\u5931\u53ea\u7528\u4e8e\u66f4\u65b0RPC\u6a21\u5757\uff0c\u4e0d\u66f4\u65b0RPN\u6a21\u5757\n        factor = factor.detach()\n        # \u8ba1\u7b97\u71b5\u503c\uff0c\u5bf9\u5e94\u8bba\u6587\u4e2d\u516c\u5f0f(5)\u2014\u2014\u6982\u7387\u4e58\u4ee5\u5bf9\u6570\u6982\u7387\n        ent = F.softmax(cls_score, dim=1) * F.log_softmax(cls_score, dim=1)\n        ent = -1.0 * ent.sum(dim=1)\n        # \u6743\u91cd\u4e0e\u71b5\u503c\u76f8\u4e58\uff0c\u5f97\u5230\u516c\u5f0f(4)\n        return ent * factor\n</code></pre>"},{"location":"domain_adaptive/code/CST-MCD2/#mcd","title":"MCD\u635f\u5931","text":"<pre><code># \u8ba1\u7b97MDC\u635f\u5931\nclass LossForDiscrepancy(nn.Module):\n    def __init__(self):\n        super(LossForDiscrepancy, self).__init__()\n\n    def forward(self, cls_score, roi_score):\n        # \u5c06\u5206\u6570\u7ecf\u8fc7\u4e00\u5c42softmax\u5f52\u4e00\u5316\u64cd\u4f5c\n        cls_prob = F.softmax(cls_score, 1)\n        # \u8ba1\u7b97\u6743\u91cd\uff0c\u5bf9\u5e94\u8bba\u6587\u4e2d\u516c\u5f0f9\n        weight = torch.min(2 * torch.min(1 - cls_prob[:, 0], cls_prob[:, 0]),\n                           2 * torch.min(roi_score[:], 1 - roi_score[:]))\n        # \u5207\u65ad\u6743\u91cd\u6240\u5e26\u6765\u7684\u68af\u5ea6\uff0c\u8868\u660eMDC\u635f\u5931\u4ea7\u751f\u7684\u68af\u5ea6\u4e0d\u4f1a\u4ece\u6743\u91cdweight\u4f20\u5165\u5230RPN\u548cRPC\u4e2d\n        weight = weight.detach()\n        # \u6743\u91cd\u5f00\u5e73\u65b9\u5904\u7406\uff0c\u8fd9\u91cc2\u5bf9\u5e94\u8bba\u6587\u91cc\u7684lambda\n        weight = weight.pow(2)\n        # \u8ba1\u7b97\u635f\u5931\uff0c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f10\n        loss_to_min = (1 - cls_prob[:, 0] - roi_score[:]).abs() * weight\n        # \u6ce8\u610f\u8fd9\u4e2a\u53d6\u8d1f\u503c\u7684\u635f\u5931\u7528\u4e8e\u66f4\u65b0RPN\u548cRPC\u4e2d\u7684\u524d\u540e\u666f\u5206\u7c7b\u6a21\u5757\uff0c\u56e0\u4e3a\u5206\u7c7b\u6a21\u5757\u9700\u8981\u6700\u5927\u5316\u8be5\u635f\u5931\uff0c\u56e0\u6b64\u9700\u8981\u4e58\u4e00\u4e2a\u8d1f\u503c\n        # \u8fd9\u91cc\u4e5f\u53ef\u4ee5\u5229\u7528\u68af\u5ea6\u53cd\u8f6c\u5c42\u5b9e\u73b0\n        loss_to_max = -(1 - cls_prob[:, 0] - roi_score[:]).abs() * weight\n        # \u4f9d\u6b21\u8fd4\u56de\u4e24\u79cd\u635f\u5931\uff0c\u5206\u522b\u5bf9\u5e94\u4e8e\u7279\u5f81\u63d0\u53d6\u5668F(\u6700\u5c0f\u5316MDC)\uff0c\u548cRPN\u3001RPC\u4e2d\u7684\u5206\u7c7b\u6a21\u5757(\u6700\u5927\u5316MDC)\n        return loss_to_min, loss_to_max\n</code></pre>"},{"location":"domain_adaptive/code/CST-MCD2/#_7","title":"\u5c40\u90e8\u5bf9\u9f50\u635f\u5931","text":"<pre><code># \u5c40\u90e8\u5bf9\u9f50\u6a21\u5757\u7684\u635f\u5931\nclass LossForLocal(nn.Module):\n    def __init__(self):\n        super(LossForLocal, self).__init__()\n\n    def forward(self, input, domain, heat_map=None):\n        y = input\n        if domain == 1:\n            # \u6e90\u57df\u6570\u636e\n            loss = y.pow(2)\n        elif domain == 0:\n            # \u76ee\u6807\u57df\u6570\u636e\n            loss = (1 - y).pow(2)\n        else:\n            raise Exception(\"domain label must be consistent in one batch\")\n        if heat_map is None:\n            return loss\n        else:\n            # \u8fd9\u91cc\u53d6\u51fa\u6240\u6709\u951a\u70b9\u7684\u524d\u666f\u5206\u6570\u9884\u6d4b\u56fe\uff0c\u6ce8\u610f\u8981\u5207\u65ad\u68af\u5ea6\uff0c\u8fd9\u91cc\u76849\u8868\u793a\u7279\u5f81\u56fe\u4e2d\u6bcf\u4e2a\u50cf\u7d20\u70b9\u4f1a\u5bf9\u5e949\u4e2a\u951a\u70b9\n            heat_map = heat_map[0][9:, :, :].detach()\n            # \u6240\u6709\u5206\u6570\u56fe\u6cbf\u7b2c\u4e00\u7ef4\u5ea6\u6c42\u548c\uff0c\u4e4b\u540e\u7ef4\u5ea6\u8f6c\u5316\u4e3a\u4e8c\u7ef4\n            heat_map = heat_map.sum(0).cpu().view(heat_map.shape[1], heat_map.shape[2]).numpy()\n            # \u5c06\u9884\u6d4b\u56fe\u5c3a\u5bf8\u8c03\u6574\u4e3a\u4e0e\u635f\u5931\u76f8\u540c\u7684\u5c3a\u5bf8\n            heat_map = resize(heat_map, (loss.shape[2], loss.shape[3]))\n            # \u9884\u6d4b\u56fe\u6570\u636e\u4e0e\u635f\u5931\u4e58\u79ef\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u5bf9\u6297\u635f\u5931\n            return loss * torch.FloatTensor(heat_map).view(1, 1, heat_map.shape[0], heat_map.shape[1]).cuda()\n</code></pre> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e742\u670818\u65e5</p>"},{"location":"domain_adaptive/code/DAFaster2/","title":"\u57df\u9002\u5e94\uff1aDA Faster R-CNN","text":""},{"location":"domain_adaptive/code/DAFaster2/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aIEEE Conference on Computer Vision and Pattern Recognition 2018 (CVPR, 2018)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_Domain_Adaptive_Faster_CVPR_2018_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/yuhuayc/da-faster-rcnn\uff08caffe\uff09\u3001https://github.com/krumo/Domain-Adaptive-Faster-RCNN-PyTorch\uff08PyTorch\uff09</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b</p>"},{"location":"domain_adaptive/code/DAFaster2/#_2","title":"\u7f51\u7edc\u7ed3\u6784","text":"<p>\u6574\u4f53\u7ed3\u6784\u4e0eFaster R-CNN\u5dee\u4e0d\u591a\uff0c\u4e3b\u8981\u662f\u6dfb\u52a0\u4e86\u57df\u9002\u5e94\u6a21\u5757\u4ee5\u53caDA\u635f\u5931\u7684\u8ba1\u7b97</p> <pre><code>class GeneralizedRCNN(nn.Module):\n    \"\"\"\n    Main class for Generalized R-CNN. Currently supports boxes and masks.\n    It consists of three main parts:\n    - backbone\n    - rpn\n    - heads: takes the features + the proposals from the RPN and computes\n        detections / masks from it.\n    \"\"\"\n\n    def __init__(self, cfg):\n        super(GeneralizedRCNN, self).__init__()\n\n        self.backbone = build_backbone(cfg)\n        self.rpn = build_rpn(cfg)\n        self.roi_heads = build_roi_heads(cfg)\n        # \u57df\u9002\u5e94\u6a21\u5757\n        self.da_heads = build_da_heads(cfg)\n\n    def forward(self, images, targets=None):\n        \"\"\"\n        Arguments:\n            images (list[Tensor] or ImageList): images to be processed\n            targets (list[BoxList]): ground-truth boxes present in the image (optional)\n\n        Returns:\n            result (list[BoxList] or dict[Tensor]): the output from the model.\n                During training, it returns a dict[Tensor] which contains the losses.\n                During testing, it returns list[BoxList] contains additional fields\n                like `scores`, `labels` and `mask` (for Mask R-CNN models).\n\n        \"\"\"\n        if self.training and targets is None:\n            raise ValueError(\"In training mode, targets should be passed\")\n        images = to_image_list(images)\n        features = self.backbone(images.tensors)\n        proposals, proposal_losses = self.rpn(images, features, targets)\n        da_losses = {}\n        if self.roi_heads:\n            x, result, detector_losses, da_ins_feas, da_ins_labels = self.roi_heads(features, proposals, targets)\n            if self.da_heads:\n                # \u8ba1\u7b97DA\u57df\u5206\u7c7b\u5bf9\u6297\u635f\u5931\n                da_losses = self.da_heads(features, da_ins_feas, da_ins_labels, targets)\n        else:\n            # RPN-only models don't have roi_heads\n            x = features\n            result = proposals\n            detector_losses = {}\n\n        if self.training:\n            losses = {}\n            losses.update(detector_losses)\n            losses.update(proposal_losses)\n            losses.update(da_losses)\n            return losses\n\n        return result\n</code></pre>"},{"location":"domain_adaptive/code/DAFaster2/#_3","title":"\u57df\u9002\u5e94\u6a21\u5757","text":"<pre><code>class DomainAdaptationModule(torch.nn.Module):\n    \"\"\"\n    Module for Domain Adaptation Component. Takes feature maps from the backbone and instance\n    feature vectors, domain labels and proposals. Works for both FPN and non-FPN.\n    \"\"\"\n\n    def __init__(self, cfg):\n        super(DomainAdaptationModule, self).__init__()\n\n        self.cfg = cfg.clone()\n\n        stage_index = 4\n        stage2_relative_factor = 2 ** (stage_index - 1)\n        res2_out_channels = cfg.MODEL.RESNETS.RES2_OUT_CHANNELS\n        num_ins_inputs = cfg.MODEL.ROI_BOX_HEAD.MLP_HEAD_DIM if cfg.MODEL.BACKBONE.CONV_BODY.startswith('V') else res2_out_channels * stage2_relative_factor\n\n        self.resnet_backbone = cfg.MODEL.BACKBONE.CONV_BODY.startswith('R')\n        # \u5e73\u5747\u6c60\u5316\uff0c\u7528\u4e8e\u538b\u7f29\u7279\u5f81\n        self.avgpool = nn.AvgPool2d(kernel_size=7, stride=7)\n        # \u5404\u4e2a\u635f\u5931\u7684\u6743\u91cd\n        self.img_weight = cfg.MODEL.DA_HEADS.DA_IMG_LOSS_WEIGHT\n        self.ins_weight = cfg.MODEL.DA_HEADS.DA_INS_LOSS_WEIGHT\n        self.cst_weight = cfg.MODEL.DA_HEADS.DA_CST_LOSS_WEIGHT\n        # \u8fd9\u91cc\u6743\u91cd\u4f20\u5165-0.1\uff0c\u8d1f\u6570\u8868\u793a\u68af\u5ea6\u53cd\u8f6c\uff0c0.1\u8868\u793a\u6700\u7ec8\u7684\u635f\u5931\u51fd\u6570\u53d8\u4e3a0.1\u500d\uff0c\u4e0e\u539f\u6587\u03bb\u7684\u8bbe\u7f6e\u6709\u5173\uff0c\u5177\u4f53\u8bf7\u770bGradientScalarLayer\u7c7b\n        self.grl_img = GradientScalarLayer(-1.0*self.cfg.MODEL.DA_HEADS.DA_IMG_GRL_WEIGHT)  # \u8fd9\u91cc\u4e58\u4ee5-1\uff0c\u8868\u793a\u7528\u4e8e\u68af\u5ea6\u53d6\u53cd\n        self.grl_ins = GradientScalarLayer(-1.0*self.cfg.MODEL.DA_HEADS.DA_INS_GRL_WEIGHT)\n        # \u8fd9\u91cc\u9ed8\u8ba4\u4e58\u4ee50.1\uff0c\u540c\u4e0a\u8868\u793a\u56de\u4f20\u68af\u5ea6\u7684\u65f6\u5019\u68af\u5ea6\u53d8\u4e3a0.1\uff0c\u4e0e\u4e0a\u9762\u4e0d\u540c\u7684\u662f\u8fd9\u91cc\u662f\u6b63\u6570\uff0c\u68af\u5ea6\u4e0d\u505a\u53cd\u8f6c\n        # \u8fd9\u91cc\u4e3b\u8981\u7528\u4e8e\u8ba1\u7b97\u6b63\u5219\u5316\u635f\u5931\n        self.grl_img_consist = GradientScalarLayer(1.0*self.cfg.MODEL.DA_HEADS.DA_IMG_GRL_WEIGHT)\n        self.grl_ins_consist = GradientScalarLayer(1.0*self.cfg.MODEL.DA_HEADS.DA_INS_GRL_WEIGHT)\n        # \u7279\u5f81\u56fe\u901a\u9053\u6570\n        in_channels = cfg.MODEL.BACKBONE.OUT_CHANNELS\n        # \u5b9a\u4e49\u56fe\u7247\u7ea7\u57df\u5206\u7c7b\u5668\n        self.imghead = DAImgHead(in_channels)\n        # \u5b9a\u4e49\u5b9e\u4f8b\u7ea7\u57df\u5206\u7c7b\u5668\n        self.inshead = DAInsHead(num_ins_inputs)\n        # \u5b9a\u4e49DA\u635f\u5931\u51fd\u6570\n        self.loss_evaluator = make_da_heads_loss_evaluator(cfg)\n    # img_features\u6574\u5f20\u56fe\u7247\u7279\u5f81\u3001da_ins_feature\u5b9e\u4f8b\u7ea7\u56fe\u7247\u7279\u5f81\u3001da_ins_labels\u5b9e\u4f8b\u7ea7\u57df\u6807\u7b7e\n\n    def forward(self, img_features, da_ins_feature, da_ins_labels, targets=None):\n        \"\"\"\n        Arguments:\n            img_features (list[Tensor]): features computed from the images that are\n                used for computing the predictions.\n            da_ins_feature (Tensor): instance-level feature vectors\n            da_ins_labels (Tensor): domain labels for instance-level feature vectors\n            targets (list[BoxList): ground-truth boxes present in the image (optional)\n\n        Returns:\n            losses (dict[Tensor]): the losses for the model during training. During\n                testing, it is an empty dict.\n        \"\"\"\n        if self.resnet_backbone:\n            da_ins_feature = self.avgpool(da_ins_feature)  # \u8fd9\u91cc\u628a\u9884\u6d4b\u5230\u7684\u76ee\u6807\u7684\u7279\u5f81\u62c9\u4f38\n        # \u5c06\u5f97\u5230\u7684\u7279\u5f81\u62c9\u76f4\uff0c\u5c3a\u5bf8\u4e3a(batch*ROI\u68c0\u6d4b\u5934\uff0c\u901a\u9053\u6570\u91cf)\n        da_ins_feature = da_ins_feature.view(da_ins_feature.size(0), -1)  # \u62c9\u76f4\n        # \u8fd9\u91cc\u5c06\u7279\u5f81\u56fe\u5957\u5165grl_img\uff0c\u8868\u793a\u68af\u5ea6\u53cd\u8f6c\uff0c\u5e76\u4e14\u4e58\u4ee50.1\uff0c\u5c06\u56fe\u50cf\u7ea7\u7279\u5f81\u548c\u5b9e\u4f8b\u7ea7\u7279\u5f81\u5747\u505a\u4e00\u4e2a\u53cd\u8f6c\n        img_grl_fea = [self.grl_img(fea) for fea in img_features]\n        ins_grl_fea = self.grl_ins(da_ins_feature)\n        # \u8fd9\u91cc\u5c06\u7279\u5f81\u5957\u5165grl_img_consist\uff0c\u68af\u5ea6\u53d8\u4e3a0.1\u3002\u540c\u4e0a\uff0c\u5c06\u4e24\u4e2a\u7ea7\u522b\u7684\u7279\u5f81\u5747\u5957\u8fdb\u53bb\n        img_grl_consist_fea = [self.grl_img_consist(fea) for fea in img_features]\n        ins_grl_consist_fea = self.grl_ins_consist(da_ins_feature)\n        # \u7ecf\u8fc7\u56fe\u7247\u7ea7\u57df\u5206\u7c7b\u5668\uff0c\u5f97\u5230\u9884\u6d4b\u7ed3\u679c\n        da_img_features = self.imghead(img_grl_fea)\n        # \u7ecf\u8fc7\u5b9e\u4f8b\u7ea7\u57df\u5206\u7c7b\u5668\uff0c\u5f97\u5230\u9884\u6d4b\u7ed3\u679c\n        da_ins_features = self.inshead(ins_grl_fea)\n        # da_img_consist_features\u548cda_ins_consist_features\u7528\u4e8e\u8ba1\u7b97\u6b63\u5219\u5316\u635f\u5931\uff0c\u68af\u5ea6\u65e0\u9700\u53cd\u8f6c\n        da_img_consist_features = self.imghead(img_grl_consist_fea)\n        da_ins_consist_features = self.inshead(ins_grl_consist_fea)\n        # \u6c42\u6b63\u5219\u5316\u635f\u5931\u65f6\uff0c\u9884\u6d4b\u6982\u7387\u9700\u8981\u5148\u7ecf\u8fc7\u4e00\u4e2asigmoid\n        da_img_consist_features = [fea.sigmoid() for fea in da_img_consist_features]\n        da_ins_consist_features = da_ins_consist_features.sigmoid()\n        if self.training:\n            # \u4f9d\u6b21\u5c06\u68af\u5ea6\u53cd\u8f6c\u540e\u7684\u57df\u5206\u7c7b\u5668\u5206\u7c7b\u7ed3\u679c\u3001\u68af\u5ea6\u53cd\u8f6c\u524d\u7684\u57df\u5206\u7c7b\u5668\u5206\u7c7b\u7ed3\u679c\u3001\u5b9e\u4f8b\u7ea7\u6807\u7b7e\u3001\u603b\u6807\u7b7e\u4f20\u5165\u635f\u5931\u51fd\u6570\uff0c\u5f97\u5230DA\u635f\u5931\n            da_img_loss, da_ins_loss, da_consistency_loss = self.loss_evaluator(\n                da_img_features, da_ins_features, da_img_consist_features, da_ins_consist_features, da_ins_labels, targets\n            )\n            losses = {}\n            if self.img_weight &gt; 0:\n                losses[\"loss_da_image\"] = self.img_weight * da_img_loss\n            if self.ins_weight &gt; 0:\n                losses[\"loss_da_instance\"] = self.ins_weight * da_ins_loss\n            if self.cst_weight &gt; 0:\n                losses[\"loss_da_consistency\"] = self.cst_weight * da_consistency_loss\n            return losses\n        return {}\n</code></pre>"},{"location":"domain_adaptive/code/DAFaster2/#_4","title":"\u56fe\u50cf\u7ea7\u57df\u5206\u7c7b\u5668","text":"<p>\u4e00\u7ec4\u7279\u5f81\u56fe\u751f\u6210\u4e00\u5f20\u56fe</p> <pre><code>class DAImgHead(nn.Module):\n    \"\"\"\n    Adds a simple Image-level Domain Classifier head\n    \u56fe\u50cf\u7ea7\u57df\u5206\u7c7b\u5668\n    \"\"\"\n\n    def __init__(self, in_channels):\n        \"\"\"\n        Arguments:\n            in_channels (int): number of channels of the input feature\n        \"\"\"\n        super(DAImgHead, self).__init__()\n        # \u7279\u5f81\u56fe\u7ecf\u8fc7\u4e24\u5c42\u5377\u79ef\uff0c\u53d8\u4e3a\u4e00\u5f20\u56fe\uff0c\u901a\u9053\u6570\u4e3a1\n        # \u8be5\u56fe\u4e0a\u7684\u6570\u636e\u8868\u793a\u7279\u5f81\u56fe\u6bcf\u4e2a\u4f4d\u7f6e\u7684\u9886\u57df\u5206\u7c7b\u60c5\u51b5\n        self.conv1_da = nn.Conv2d(in_channels, 512, kernel_size=1, stride=1)\n        self.conv2_da = nn.Conv2d(512, 1, kernel_size=1, stride=1)\n        # \u5377\u79ef\u5c42\u53c2\u6570\u521d\u59cb\u5316\n        for l in [self.conv1_da, self.conv2_da]:\n            torch.nn.init.normal_(l.weight, std=0.001)\n            torch.nn.init.constant_(l.bias, 0)\n    # \u524d\u5411\u4f20\u64ad\u8fc7\u7a0b\n    def forward(self, x):\n        img_features = []\n        # \u4f9d\u6b21\u7ecf\u8fc7:\u5377\u79ef\u5c421-&gt;relu-&gt;\u5377\u79ef\u5c422\uff0c\u751f\u6210\u4e00\u5f20\u56fe\n        # \u6309\u7279\u5f81\u5c42\u6570\u904d\u5386(FPN\u5229\u7528\u4e86\u591a\u5c42\u7279\u5f81\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b)\n        for feature in x:\n            t = F.relu(self.conv1_da(feature))\n            img_features.append(self.conv2_da(t))\n        # \u8fd4\u56de\u57df\u5206\u7c7b\u56fe\uff0c\u6bcf\u5c42\u5747\u5f97\u5230\u4e00\u4e2a\u56fe\n        return img_features\n</code></pre>"},{"location":"domain_adaptive/code/DAFaster2/#_5","title":"\u5b9e\u4f8b\u7ea7\u57df\u5206\u7c7b\u5668","text":"<p>\u6bcf\u4e2a\u5b9e\u4f8b\u751f\u6210\u4e00\u4e2a\u6570</p> <pre><code>class DAInsHead(nn.Module):\n    \"\"\"\n    Adds a simple Instance-level Domain Classifier head\n    \u5b9e\u4f8b\u7ea7\u57df\u5206\u7c7b\u5668\n    \"\"\"\n\n    def __init__(self, in_channels):\n        \"\"\"\n        Arguments:\n            in_channels (int): number of channels of the input feature\n        \"\"\"\n        super(DAInsHead, self).__init__()\n        # \u5b9a\u4e49\u4e09\u4e2a\u7ebf\u6027\u56de\u5f52\u5c42\uff0c\u6700\u540e\u8f93\u51fa\u4e00\u4e2a\u503c\uff0c\u8868\u793a\u8be5\u5b9e\u4f8b\u7684\u9886\u57df\u5206\u7c7b\u60c5\u51b5\n        self.fc1_da = nn.Linear(in_channels, 1024)\n        self.fc2_da = nn.Linear(1024, 1024)\n        self.fc3_da = nn.Linear(1024, 1)\n        # \u521d\u59cb\u5316\u7ebf\u6027\u56de\u5f52\u5c42\u53c2\u6570\n        for l in [self.fc1_da, self.fc2_da]:\n            nn.init.normal_(l.weight, std=0.01)\n            nn.init.constant_(l.bias, 0)\n        nn.init.normal_(self.fc3_da.weight, std=0.05)\n        nn.init.constant_(self.fc3_da.bias, 0)\n\n    def forward(self, x):\n        # \u8f93\u5165\u7684\u7279\u5f81x\u5df2\u7ecf\u88ab\u62c9\u4f38\u6210\u4e00\u4e2a\u5411\u91cf\n        # \u7279\u5f81x\u4f9d\u6b21\u7ecf\u8fc7fc\u3001relu\u3001dropout\n        # \u6bcf\u4e2a\u5b9e\u4f8b\u5747\u751f\u6210\u4e00\u4e2a\u6570\n        x = F.relu(self.fc1_da(x))\n        x = F.dropout(x, p=0.5, training=self.training)\n\n        x = F.relu(self.fc2_da(x))\n        x = F.dropout(x, p=0.5, training=self.training)\n\n        x = self.fc3_da(x)\n        # \u8fd4\u56de\u57df\u5206\u7c7b\u6982\u7387\n        return x\n</code></pre>"},{"location":"domain_adaptive/code/DAFaster2/#grl","title":"GRL\u6a21\u5757","text":"<p>\u68af\u5ea6\u53cd\u8f6c\u6a21\u5757\uff0c\u9886\u57df\u5206\u7c7b\u635f\u5931\u4ea7\u751f\u7684\u68af\u5ea6\u4f20\u5230\u7279\u5f81\u63d0\u53d6\u7f51\u683c\u65f6\u9700\u8981\u505a\u4e00\u4e2a\u53cd\u8f6c\uff0c\u5373\u53d8\u4e3a\u8d1f\u6570</p> <pre><code>class GradientScalarLayer(torch.nn.Module):\n    def __init__(self, weight):\n        super(GradientScalarLayer, self).__init__()\n        self.weight = weight\n\n    def forward(self, input):\n        return gradient_scalar(input, self.weight)\n\ngradient_scalar = _GradientScalarLayer.apply\n\nclass _GradientScalarLayer(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, input, weight):\n        ctx.weight = weight\n        return input.view_as(input)\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        grad_input = grad_output.clone()\n        # \u53cd\u5411\u4f20\u64ad\u8fc7\u7a0b\u4e2d\uff0c\u68af\u5ea6\u4f20\u5230\u8fd9\u4e00\u5c42\u65f6\uff0c\u4f1a\u4e0e\u53c2\u6570weight\u76f8\u4e58\n        # \u5982\u679c\u6b64\u65f6weight\u4e3a\u8d1f\u6570\uff0c\u5219\u68af\u5ea6\u53d8\u4e3a\u539f\u6765\u7684\u8d1f\u6570\n        return ctx.weight*grad_input, None\n</code></pre>"},{"location":"domain_adaptive/code/DAFaster2/#da","title":"DA\u635f\u5931","text":"<pre><code>class DALossComputation(object):\n    \"\"\"\n    This class computes the DA loss.\n    \"\"\"\n\n    def __init__(self, cfg):\n        self.cfg = cfg.clone()\n        resolution = cfg.MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION\n        scales = cfg.MODEL.ROI_BOX_HEAD.POOLER_SCALES\n        sampling_ratio = cfg.MODEL.ROI_BOX_HEAD.POOLER_SAMPLING_RATIO\n        pooler = Pooler(\n            output_size=(resolution, resolution),\n            scales=scales,\n            sampling_ratio=sampling_ratio,\n        )\n\n        self.pooler = pooler\n        self.avgpool = nn.AvgPool2d(kernel_size=resolution, stride=resolution)\n\n    def prepare_masks(self, targets):\n        masks = []\n        for targets_per_image in targets:\n            is_source = targets_per_image.get_field('is_source')\n            mask_per_image = is_source.new_ones(1, dtype=torch.uint8) if is_source.any() else is_source.new_zeros(1, dtype=torch.uint8)\n            masks.append(mask_per_image)\n        return masks\n\n    def __call__(self, da_img, da_ins, da_img_consist, da_ins_consist, da_ins_labels, targets):\n        \"\"\"\n        Arguments:\n            da_img (list[Tensor]) \u7528\u4e8e\u8ba1\u7b97\u56fe\u7247\u7ea7\u57df\u5206\u7c7b\u5668\u635f\u5931\n            da_img_consist (list[Tensor]) \u7528\u4e8e\u8ba1\u7b97\u6b63\u5219\u5316\u635f\u5931\n            da_ins (Tensor) \u7528\u4e8e\u8ba1\u7b97\u5b9e\u4f8b\u7ea7\u57df\u5206\u7c7b\u5668\u635f\u5931\n            da_ins_consist (Tensor) \u7528\u4e8e\u8ba1\u7b97\u6b63\u5219\u5316\u635f\u5931\n            da_ins_labels (Tensor) \u7528\u4e8e\u8ba1\u7b97\u5b9e\u4f8b\u7ea7\u57df\u5206\u7c7b\u5668\u635f\u5931\n            targets (list[BoxList])\n\n        Returns:\n            da_img_loss (Tensor)\n            da_ins_loss (Tensor)\n            da_consist_loss (Tensor)\n        \"\"\"\n\n        masks = self.prepare_masks(targets)\n        masks = torch.cat(masks, dim=0)\n\n        da_img_flattened = []\n        da_img_labels_flattened = []\n        # for each feature level, permute the outputs to make them be in the\n        # same format as the labels. Note that the labels are computed for\n        # all feature levels concatenated, so we keep the same representation\n        # for the image-level domain alignment\n        # \u6309\u7279\u5f81\u5c42\u6570\u904d\u5386\n        for da_img_per_level in da_img:\n            # \u5f97\u5230\u7279\u5f81\u56fe\u5c3a\u5bf8\n            N, A, H, W = da_img_per_level.shape\n            # \u8f6c\u6362\u7ef4\u5ea6\uff0c\u901a\u9053\u7ef4\u5ea6\u79fb\u5230\u6700\u540e\n            da_img_per_level = da_img_per_level.permute(0, 2, 3, 1)\n            # \u521d\u59cb\u5316\u6807\u7b7e\n            da_img_label_per_level = torch.zeros_like(da_img_per_level, dtype=torch.float32)\n            # \u5982\u679c\u56fe\u7247\u6765\u81ea\u76ee\u6807\u57df\uff0c\u5219\u6807\u7b7e\u8bbe\u7f6e\u4e3a1\n            da_img_label_per_level[masks, :] = 1\n            # \u56fe\u50cf\u7ea7\u9884\u6d4b\u62c9\u76f4\uff0c\u4ece\u4e00\u5f20\u56fe\u62c9\u503c\u4e3a\u4e00\u4e2a\u5411\u91cf\n            da_img_per_level = da_img_per_level.reshape(N, -1)\n            da_img_label_per_level = da_img_label_per_level.reshape(N, -1)\n            # \u50a8\u5b58\u9884\u6d4b\u548c\u6807\u7b7e\uff0c\u7528\u4e8e\u540e\u7eed\u7684\u635f\u5931\u8ba1\u7b97\n            da_img_flattened.append(da_img_per_level)\n            da_img_labels_flattened.append(da_img_label_per_level)\n        # \u5408\u5e76\u6570\u636e\n        da_img_flattened = torch.cat(da_img_flattened, dim=0)\n        da_img_labels_flattened = torch.cat(da_img_labels_flattened, dim=0)\n        # \u8ba1\u7b97\u56fe\u50cf\u7ea7\u57df\u5206\u7c7b\u5668\u635f\u5931\n        da_img_loss = F.binary_cross_entropy_with_logits(\n            da_img_flattened, da_img_labels_flattened\n        )\n        # \u8ba1\u7b97\u5b9e\u4f8b\u7ea7\u57df\u5206\u7c7b\u5668\u635f\u5931\n        da_ins_loss = F.binary_cross_entropy_with_logits(\n            torch.squeeze(da_ins), da_ins_labels.type(torch.cuda.FloatTensor)\n        )\n        # \u8ba1\u7b97\u6b63\u5219\u5316\u635f\u5931\n        da_consist_loss = consistency_loss(da_img_consist, da_ins_consist, da_ins_labels, size_average=True)\n\n        return da_img_loss, da_ins_loss, da_consist_loss\n</code></pre>"},{"location":"domain_adaptive/code/DAFaster2/#_6","title":"\u6b63\u5219\u5316\u635f\u5931","text":"<pre><code>def consistency_loss(img_feas, ins_fea, ins_labels, size_average=True):\n    \"\"\"\n    Consistency regularization as stated in the paper\n    `Domain Adaptive Faster R-CNN for Object Detection in the Wild`\n    L_cst = \\sum_{i,j}||\\frac{1}{|I|}\\sum_{u,v}p_i^{(u,v)}-p_{i,j}||_2\n    \"\"\"\n    loss = []\n    # \u5b9e\u4f8b\u7ea7\u9884\u6d4b\u6570\u91cf\uff0c\u68c0\u6d4b\u5934\u6570\u91cf\u4e58\u4ee5batch\n    len_ins = ins_fea.size(0)\n    # \u7b2c\u4e00\u4e2a\u8868\u793a\u5b9e\u4f8b\u6765\u81ea\u76ee\u6807\u57df\u7684\u6570\u91cf(ins_labels\u975e\u96f6)\u3001\u7b2c\u4e8c\u4e2a\u8868\u793a\u6765\u6e90\u57df\u7684\u6570\u91cf\n    intervals = [torch.nonzero(ins_labels).size(0), len_ins - torch.nonzero(ins_labels).size(0)]\n    # \u6309\u7279\u5f81\u5c42\u6570\u904d\u5386\n    for img_fea_per_level in img_feas:\n        # \u5f97\u5230\u56fe\u50cf\u7ea7\u9884\u6d4b(\u4e00\u5f20\u56fe)\u7684\u5c3a\u5bf8\uff0cN\u8868\u793abatch\n        N, A, H, W = img_fea_per_level.shape\n        # \u6c42\u5f97\u56fe\u50cf\u7ea7\u9884\u6d4b\u7684\u5e73\u5747\u503c\uff0c\u5f97\u5230\u4e24\u4e2a\u5747\u503c\n        img_fea_per_level = torch.mean(img_fea_per_level.reshape(N, -1), 1)\n        img_feas_per_level = []\n        # \u8fd9\u91cc\u9650\u5236\u4e86\u8bad\u7ec3batch\u4e3a2\uff0c\u4e00\u5f20\u6e90\u57df\u56fe\u50cf\uff0c\u4e00\u5f20\u76ee\u6807\u57df\u56fe\u50cf\n        # \u5177\u4f53\u8bf7\u770b\u8bba\u6587\u4e2d\u5b9e\u65bd\u7ec6\u8282\n        assert N==2, \\\n            \"only batch size=2 is supported for consistency loss now, received batch size: {}\".format(N)\n        # \u6309batch\u904d\u5386\n        for i in range(N):\n            # \u5c06\u5747\u503c\u590d\u5236\uff0c\u6709\u51e0\u4e2a\u5bf9\u5e94\u9886\u57df\u7684\u5b9e\u4f8b\u7ea7\u5c31\u5c06\u5747\u503c\u590d\u5236\u51e0\u6b21(\u6309\u9886\u57df\u6570\u91cf\u590d\u5236\u7684)\n            img_fea_mean = img_fea_per_level[i].view(1, 1).repeat(intervals[i], 1)\n            img_feas_per_level.append(img_fea_mean)\n        # \u5408\u5e76\u4e4b\u524d\u590d\u5236\u7684\u5747\u503c\n        img_feas_per_level = torch.cat(img_feas_per_level, dim=0)\n        # \u5747\u503c\u4e0e\u9886\u57df\u9884\u6d4b\u503c\u505a\u5dee\uff0c\u53d6\u7edd\u5bf9\u503c\u3002\u4f46\u8bba\u6587\u7528\u7684\u662fl2\u8ddd\u79bb(\u6b27\u6c0f\u8ddd\u79bb)\u3001\u6e90\u7801\u7528\u7684l1\u8ddd\u79bb(\u7edd\u5bf9\u503c\u8ddd\u79bb)\n        loss_per_level = torch.abs(img_feas_per_level - ins_fea)\n        loss.append(loss_per_level)\n    # \u5408\u5e76\u518d\u53d6\u5747\u503c\uff0c\u5f97\u5230\u6700\u540e\u7684\u635f\u5931\n    loss = torch.cat(loss, dim=1)\n    if size_average:\n        return loss.mean()\n    return loss.sum()\n</code></pre> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u7b80\u4ecb\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u5927\u5bb6\u6279\u8bc4\u6307\u6b63\u3002</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e741\u670827\u65e5</p>"},{"location":"domain_adaptive/code/HTCN2/","title":"\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u2014\u2014HTCN","text":""},{"location":"domain_adaptive/code/HTCN2/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aIEEE Conference on Computer Vision and Pattern Recognition 2020 (CVPR, 2020)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content_CVPR_2020/papers/Chen_Harmonizing_Transferability_and_Discriminability_for_Adapting_Object_Detectors_CVPR_2020_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/chaoqichen/HTCN</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b</p>"},{"location":"domain_adaptive/code/HTCN2/#_2","title":"\u7f51\u7edc\u7ed3\u6784","text":"<p>\u4f5c\u8005\u5e94\u8be5\u662f\u5728\u4ee3\u7801Strong-Weak Distribution Alignment\u7684\u57fa\u7840\u4e0a\u6539\u7684</p> <pre><code>class _fasterRCNN(nn.Module):\n    \"\"\" faster RCNN \"\"\"\n\n    def __init__(self, classes, class_agnostic, lc, gc, la_attention=False, mid_attention=False):\n        super(_fasterRCNN, self).__init__()\n        self.classes = classes\n        self.n_classes = len(classes)\n        self.class_agnostic = class_agnostic\n        # \u635f\u5931\n        self.RCNN_loss_cls = 0\n        self.RCNN_loss_bbox = 0\n        # \u4e0b\u9762\u56db\u4e2a\u53d8\u91cf\u90fd\u9ed8\u8ba4True\n        self.lc = lc\n        self.gc = gc\n        self.la_attention = la_attention\n        self.mid_attention = mid_attention\n        # RPN\u6a21\u5757\n        self.RCNN_rpn = _RPN(self.dout_base_model)\n        self.RCNN_proposal_target = _ProposalTargetLayer(self.n_classes)\n        # ROI\u6a21\u5757\n        self.RCNN_roi_pool = ROIPool((cfg.POOLING_SIZE, cfg.POOLING_SIZE), 1.0 / 16.0)\n        self.RCNN_roi_align = ROIAlign((cfg.POOLING_SIZE, cfg.POOLING_SIZE), 1.0 / 16.0, 0)\n\n\n    def forward(self, im_data, im_info, gt_boxes, num_boxes, target=False, eta=1.0):\n        batch_size = im_data.size(0)\n\n        im_info = im_info.data\n        gt_boxes = gt_boxes.data\n        num_boxes = num_boxes.data\n\n        # \u5c06\u56fe\u50cf\u6570\u636e\u4f20\u5165\u6d45\u5c42\u7f51\u7edc(\u5bf9\u5e94\u8bba\u6587G1)\uff0c\u63d0\u53d6\u6d45\u5c42\u7279\u5f81\n        base_feat1 = self.RCNN_base1(im_data)\n        if self.lc:\n            # \u5c06\u6d45\u5c42\u7279\u5f81\u4f20\u5165\u50cf\u7d20\u70b9\u7ea7\u7684\u57df\u5206\u7c7b\u5668(\u5bf9\u5e94\u8bba\u6587D1)\uff0c\u9010\u50cf\u7d20\u70b9\u9884\u6d4b\u9886\u57df\u5206\u6570\uff0c\u8fd4\u56de\u4e00\u5f20\u57df\u5206\u7c7b\u56fe\n            # \u6ce8\u610f\u5728\u4f20\u5165\u4e4b\u524d\uff0c\u9700\u8981\u5148\u7ecf\u8fc7\u4e00\u5c42\u68af\u5ea6\u53cd\u8f6c\u5c42\n            d_pixel, _ = self.netD_pixel(grad_reverse(base_feat1, lambd=eta))\n            # if not target:\n            # \u8fd9\u91cc\u5f97\u5230\u6d45\u5c42\u7279\u5f81\u5411\u91cf\uff0c\u4e3b\u8981\u662f\u5229\u7528\u57df\u5206\u7c7b\u5668\u91cc\u9762\u7684\u4e24\u5c42\u5377\u79ef\n            # \u7528\u4e8e\u540e\u7eed\u8ba1\u7b97\u4e0a\u4e0b\u6587\u5411\u91cf\uff0c\u6ce8\u610f\u8fd9\u91cc\u8981\u5207\u65ad\u68af\u5ea6\n            _, feat_pixel = self.netD_pixel(base_feat1.detach())\n        else:\n            d_pixel = self.netD_pixel(grad_reverse(base_feat1, lambd=eta))\n\n        if self.la_attention:\n            # \u5c06\u9884\u6d4b\u5230\u7684\u9886\u57df\u5206\u6570\u56fe\u548c\u7279\u5f81\u56fe\u4f20\u5165local_attention\u51fd\u6570\uff0c\u5f97\u5230\u7ecf\u8fc7\u5c40\u90e8\u7279\u5f81\u63a9\u6a21\u5904\u7406\u540e\u7684\u7279\u5f81\uff0c\u5373\u5bf9\u6d45\u5c42\u7279\u5f81\u8fdb\u884c\u52a0\u6743\n            # \u6ce8\u610f\u8fd9\u91cc\u9884\u6d4b\u5206\u6570\u53d8\u91cf\u9700\u8981\u5207\u65ad\u68af\u5ea6\uff0c\u9632\u6b62\u540e\u7eed\u7684\u64cd\u4f5c\u5f71\u54cd\u57df\u5206\u7c7b\u5668\u7684\u8bad\u7ec3\n            base_feat1 = local_attention(base_feat1, d_pixel.detach())\n        # \u518d\u5c06\u5904\u7406\u540e\u7684\u7279\u5f81\u4f20\u5165\u4e2d\u5c42\u7f51\u7edc(\u5bf9\u5e94\u8bba\u6587G2)\uff0c\u63d0\u53d6\u4e2d\u5c42\u7279\u5f81\n        base_feat2 = self.RCNN_base2(base_feat1)\n        if self.gc:\n            # \u5c06\u4e2d\u5c42\u7279\u5f81\u4f20\u5165\u4e2d\u5c42\u57df\u5206\u7c7b\u5668(\u5bf9\u5e94\u8bba\u6587D2)\uff0c\u9884\u6d4b\u9886\u57df\u5206\u6570\uff0c\u4e00\u5171\u4fe9\u5206\u6570\uff0c\u5206\u522b\u8868\u793a\u8be5\u56fe\u5c5e\u4e8e\u4e24\u4e2a\u9886\u57df\u7684\u7f6e\u4fe1\u5ea6\n            domain_mid, _ = self.netD_mid(grad_reverse(base_feat2, lambd=eta))\n            # if not target:\n            # \u8fd9\u91cc\u548c\u6d45\u5c42\u7279\u5f81\u5904\u7406\u65b9\u6cd5\u4e00\u6837\uff0c\u5148\u5207\u65ad\u68af\u5ea6\uff0c\u7136\u540e\u5f97\u5230\u4e2d\u5c42\u7279\u5f81\u5411\u91cf\uff0c\u7528\u4e8e\u540e\u7eed\u8ba1\u7b97\u4e0a\u4e0b\u6587\u5411\u91cf\n            _, feat_mid = self.netD_mid(base_feat2.detach())\n        else:\n            domain_mid = self.netD_mid(grad_reverse(base_feat2, lambd=eta))\n\n        if self.mid_attention:\n            # \u5c06\u5f97\u5230\u7684\u9886\u57df\u5206\u6570\u548c\u4e2d\u5c42\u7279\u5f81\u4f20\u5165middle_attention\u51fd\u6570\uff0c\u8ba1\u7b97gi\uff0c\u5373\u5bf9\u4e2d\u5c42\u7279\u5f81\u8fdb\u884c\u52a0\u6743\uff0c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f1\u30012\n            # \u8fd9\u91cc\u9886\u57df\u9884\u6d4b\u5206\u6570\u540c\u6837\u4e5f\u8981\u5207\u65ad\u68af\u5ea6\uff0c\u7528\u4e8e\u4fdd\u62a4\u57df\u5206\u7c7b\u5668\u7684\u8bad\u7ec3\n            base_feat2 = middle_attention(base_feat2, domain_mid.detach())\n        # \u5c06\u4e2d\u5c42\u7279\u5f81\u4f20\u5165\u6df1\u5c42\u7f51\u7edc\uff0c\u5f97\u5230\u6df1\u5c42\u7279\u5f81\uff0c\u5373\u6700\u7ec8\u7684\u7279\u5f81\u56fe\n        base_feat = self.RCNN_base3(base_feat2)\n        if self.gc:\n            # \u5c06\u6df1\u5c42\u7279\u5f81\u4f20\u5165\u6df1\u5c42\u57df\u5206\u7c7b\u5668\uff0c\u5bf9\u5e94\u8bba\u6587D3\uff0c\u5f97\u5230\u4e24\u4e2a\u9886\u57df\u9884\u6d4b\u5206\u6570\n            domain_p, _ = self.netD(grad_reverse(base_feat, lambd=eta))\n            # \u8fd9\u91cc\u548c\u524d\u4e24\u6b21\u4e00\u6837\uff0c\u5f97\u5230\u6df1\u5c42\u7279\u5f81\uff0c\u7528\u4e8e\u8ba1\u7b97\u4e0a\u4e0b\u6587\u5411\u91cf\n            _, feat = self.netD(base_feat.detach())\n        else:\n            domain_p = self.netD(grad_reverse(base_feat, lambd=eta))\n\n        # feed base feature map tp RPN to obtain rois\n        # \u5c06\u7279\u5f81\u4f20\u5165RPN\u6a21\u5757\uff0c\u5f97\u5230\u611f\u5174\u8da3\u7684\u533a\u57df\n        rois, rpn_loss_cls, rpn_loss_bbox = self.RCNN_rpn(base_feat, im_info, gt_boxes, num_boxes)\n\n        # if it is training phrase, then use ground trubut bboxes for refining\n        if self.training:\n            roi_data = self.RCNN_proposal_target(rois, gt_boxes, num_boxes)\n            rois, rois_label, rois_target, rois_inside_ws, rois_outside_ws = roi_data\n\n            rois_label = Variable(rois_label.view(-1).long())\n            rois_target = Variable(rois_target.view(-1, rois_target.size(2)))\n            rois_inside_ws = Variable(rois_inside_ws.view(-1, rois_inside_ws.size(2)))\n            rois_outside_ws = Variable(rois_outside_ws.view(-1, rois_outside_ws.size(2)))\n        else:\n            rois_label = None\n            rois_target = None\n            rois_inside_ws = None\n            rois_outside_ws = None\n            rpn_loss_cls = 0\n            rpn_loss_bbox = 0\n\n        rois = Variable(rois)\n        # do roi pooling based on predicted rois\n\n        if cfg.POOLING_MODE == 'align':\n            pooled_feat = self.RCNN_roi_align(base_feat, rois.view(-1, 5))\n        elif cfg.POOLING_MODE == 'pool':\n            pooled_feat = self.RCNN_roi_pool(base_feat, rois.view(-1, 5))\n\n        # feed pooled features to top model\n        pooled_feat = self._head_to_tail(pooled_feat)\n\n        feat_pixel = feat_pixel.view(1, -1).repeat(pooled_feat.size(0), 1)\n        feat_mid = feat_mid.view(1, -1).repeat(pooled_feat.size(0), 1)\n        feat = feat.view(1, -1).repeat(pooled_feat.size(0), 1)\n        # \u5148\u5c06\u524d\u4e09\u7ec4\u7279\u5f81\u5411\u91cf\u5408\u5e76\n        feat = torch.cat((feat_mid, feat), 1)\n        feat = torch.cat((feat_pixel, feat), 1)\n        # \u5c06\u5408\u5e76\u5411\u91cf\u548c\u5b9e\u4f8b\u533a\u57df\u5411\u91cf\u4f20\u5165RandomLayer\uff0c\u6267\u884c\u968f\u673a\u5316\u64cd\u4f5c\uff0c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f(5)\n        # \u6b64\u65f6\u4f20\u5165\u7684feat\u957f\u5ea6\u4e3a384(128*3),pooled_feat\u4e3a2048(\u4ee5resnet\u4e3a\u4f8b)\n        feat_random = self.RandomLayer([pooled_feat, feat])\n        # \u5b9e\u4f8b\u7ea7\u57df\u5206\u7c7b\u5668\uff0c\u5bf9\u9f50\u6bcf\u4e2a\u5b9e\u4f8b\u7684\u7279\u5f81\uff0c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f(6)\n        d_ins = self.netD_da(grad_reverse(feat_random, lambd=eta))\n        # \u5982\u679c\u662f\u76ee\u6807\u57df\u56fe\u50cf\u7684\u8bdd\uff0c\u5219\u76f4\u63a5\u8fd4\u56de\u56db\u4e2a\u57df\u5206\u7c7b\u5668\u7ed3\u679c\u5c31\u884c\uff0c\u53ea\u8ba1\u7b97\u5bf9\u6297\u635f\u5931\n        # \u5426\u5219\u9700\u8981\u7ee7\u7eed\u5f80\u4e0b\u8d70\uff0c\u8fdb\u4e00\u6b65\u8ba1\u7b97\u8fb9\u754c\u6846\u56de\u5f52\u53c2\u6570\uff0c\u8ba1\u7b97\u76ee\u6807\u68c0\u6d4b\u635f\u5931\n        if target:\n            return d_pixel, domain_p, domain_mid, d_ins\n        # \u76f4\u63a5\u5bf9\u7279\u5f81\u8fdb\u884c\u62fc\u63a5\uff0c\u8fd9\u91cc\u53c2\u8003\u7b97\u6cd5Strong-Weak Distribution Alignment\uff0c\u5229\u7528\u4e86\u4e0a\u4e0b\u6587\u7279\u5f81\u6765\u589e\u5f3a\u68c0\u6d4b\u5668\u7684\u6027\u80fd\n        pooled_feat = torch.cat((feat, pooled_feat), 1)\n        # \u4e4b\u540e\u8ba1\u7b97\u8fb9\u754c\u6846\u56de\u5f52\u53c2\u6570\n        bbox_pred = self.RCNN_bbox_pred(pooled_feat)\n        # \u8ba1\u7b97\u8fb9\u754c\u6846\u56de\u5f52\u635f\u5931\n        if self.training and not self.class_agnostic:\n            bbox_pred_view = bbox_pred.view(bbox_pred.size(0), int(bbox_pred.size(1) / 4), 4)\n            bbox_pred_select = torch.gather(bbox_pred_view, 1,\n                                            rois_label.view(rois_label.size(0), 1, 1).expand(rois_label.size(0), 1, 4))\n            bbox_pred = bbox_pred_select.squeeze(1)\n\n        # \u8ba1\u7b97\u7c7b\u522b\u6982\u7387\n        cls_score = self.RCNN_cls_score(pooled_feat)\n        cls_prob = F.softmax(cls_score, 1)\n\n        RCNN_loss_cls = 0\n        RCNN_loss_bbox = 0\n        # \u8ba1\u7b97\u5206\u7c7b\u635f\u5931\n        if self.training:\n            # classification loss\n            RCNN_loss_cls = F.cross_entropy(cls_score, rois_label)\n\n            # bounding box regression L1 loss\n            RCNN_loss_bbox = _smooth_l1_loss(bbox_pred, rois_target, rois_inside_ws, rois_outside_ws)\n\n        cls_prob = cls_prob.view(batch_size, rois.size(1), -1)\n        bbox_pred = bbox_pred.view(batch_size, rois.size(1), -1)\n        # \u6700\u540e\u8fd4\u56de\u76f8\u5173\u53d8\u91cf\n        return rois, cls_prob, bbox_pred, rpn_loss_cls, rpn_loss_bbox, RCNN_loss_cls, RCNN_loss_bbox, rois_label, d_pixel, domain_p, domain_mid, d_ins  # ,diff\n</code></pre>"},{"location":"domain_adaptive/code/HTCN2/#_3","title":"\u57df\u5206\u7c7b\u5668","text":"<p>\u68af\u5ea6\u53cd\u8f6c\u5c42</p> <pre><code>class GradReverse(Function):\n    def __init__(self, lambd):\n        self.lambd = lambd\n\n    def forward(self, x):\n        # \u524d\u5411\u4f20\u64ad\u4e0d\u505a\u5904\u7406\n        return x.view_as(x)\n\n    def backward(self, grad_output):\n        # \u53ea\u4fee\u6539\u53cd\u5411\u4f20\u64ad\uff0c\u591a\u4e58\u4ee5-1\n        return (grad_output * -self.lambd)\n\ndef grad_reverse(x, lambd=1.0):\n    return GradReverse(lambd)(x)\n</code></pre> <p>\u50cf\u7d20\u7ea7\u57df\u5206\u7c7b\u5668</p> <p>\u5bf9\u5e94\u8bba\u6587D_1</p> <pre><code># \u5bf9\u6d45\u5c42\u7279\u5f81\u6267\u884c\u9886\u57df\u5206\u7c7b\u7684\u57df\u5206\u7c7b\u5668\uff0c\u50cf\u7d20\u7ea7\u522b\uff0c\u6309\u50cf\u7d20\u70b9\u5bf9\u9f50\n# \u8fd9\u91cc\u4e0eSW\u91cc\u7684\u51fd\u6570\u7c7b\u4f3c\nclass netD_pixel(nn.Module):\n    def __init__(self, context=False):\n        super(netD_pixel, self).__init__()\n        # \u5b9a\u4e49\u597d\u5377\u79ef\u5c42\uff0c\u901a\u9053\u6570\u4f9d\u6b21\u964d\u4f4e\uff0c\u6ce8\u610f\uff0c\u8fd9\u91cc\u5377\u79ef\u6838\u5747\u4e3a1*1\n        self.conv1 = nn.Conv2d(256, 256, kernel_size=1, stride=1,\n                               padding=0, bias=False)\n        self.conv2 = nn.Conv2d(256, 128, kernel_size=1, stride=1,\n                               padding=0, bias=False)\n        # \u6700\u540e\u4e00\u5c42\u901a\u9053\u6570\u53d8\u4e3a1\n        self.conv3 = nn.Conv2d(128, 1, kernel_size=1, stride=1,\n                               padding=0, bias=False)\n        # \u5224\u65ad\u540e\u7eed\u662f\u5426\u9700\u8981\u8ba1\u7b97\u4e0a\u4e0b\u6587\u5411\u91cf\uff0c\u9ed8\u8ba4True\n        self.context = context\n        #\u521d\u59cb\u5316\u53c2\u6570\n        self._init_weights()\n\n    def _init_weights(self):\n        def normal_init(m, mean, stddev, truncated=False):\n            \"\"\"\n            weight initalizer: truncated normal and random normal.\n            \"\"\"\n            if truncated:\n                m.weight.data.normal_().fmod_(2).mul_(stddev).add_(mean)  # not a perfect approximation\n            else:\n                m.weight.data.normal_(mean, stddev)\n\n        normal_init(self.conv1, 0, 0.01)\n        normal_init(self.conv2, 0, 0.01)\n        normal_init(self.conv3, 0, 0.01)\n\n    def forward(self, x):\n        # \u4f9d\u6b21\u7ecf\u8fc7conv1-&gt;relu-&gt;conv2-&gt;relu\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        if self.context:\n            # \u5982\u679c\u7528\u5230\u4e0a\u4e0b\u6587\u7684\u8bdd\uff0c\u5219\u8fd8\u9700\u8981\u8fd4\u56de\u6d45\u5c42\u7279\u5f81\u5411\u91cf\n            # \u5411\u91cf\u957f\u5ea6\u4e3a128\n            feat = F.avg_pool2d(x, (x.size(2), x.size(3)))\n            # \u7ecf\u8fc7\u6700\u540e\u4e00\u5c42\u5377\u79ef\uff0c\u5f97\u5230\u9884\u6d4b\u56fe\n            x = self.conv3(x)\n            # \u8fd4\u56de\u9884\u6d4b\u5206\u6570\u56fe\u548c\u7279\u5f81\u5411\u91cf\n            return F.sigmoid(x), feat\n        else:\n            x = self.conv3(x)\n            return F.sigmoid(x)\n</code></pre> <p>\u4e2d\u5c42\u57df\u5206\u7c7b\u5668</p> <p>\u5bf9\u5e94\u8bba\u6587D_2</p> <pre><code># \u5bf9\u4e2d\u5c42\u7279\u5f81\u8fdb\u884c\u9886\u57df\u5206\u7c7b\u7684\u57df\u5206\u7c7b\u5668\uff0c\u8f93\u51fa\u4e24\u4e2a\u503c\n# \u548cSW\u91cc\u9762\u7684\u5168\u5c40\u7279\u5f81\u5bf9\u9f50\u6a21\u5757\u7c7b\u4f3c\nclass netD_mid(nn.Module):\n    def __init__(self, context=False):\n        super(netD_mid, self).__init__()\n        # \u5b9a\u4e49\u597d\u5377\u79ef\uff0c\u6807\u51c6\u5316\u5c42\uff0c\u7ebf\u6027\u56de\u5f52\u5c42\n        # \u4e0e\u50cf\u7d20\u7ea7\u57df\u5206\u7c7b\u5668\u7684\u533a\u522b\u5728\u4e8e\uff0c\u8fd9\u91cc\u5377\u79ef\u6838\u5c3a\u5bf8\u4e3a3*3\uff0c\u5e76\u4e14\u6b65\u957f\u4e3a2\uff0c\u586b\u5145\u4e3a1\n        # \u5e76\u4e14\u6700\u540e\u7ecf\u8fc7\u7ebf\u6027\u56de\u5f52\uff0c\u8fd4\u56de\u4e24\u4e2a\u503c\n        self.conv1 = conv3x3(512, 512, stride=2)\n        self.bn1 = nn.BatchNorm2d(512)\n        self.conv2 = conv3x3(512, 128, stride=2)\n        self.bn2 = nn.BatchNorm2d(128)\n        self.conv3 = conv3x3(128, 128, stride=2)\n        self.bn3 = nn.BatchNorm2d(128)\n        self.fc = nn.Linear(128, 2)\n        self.context = context\n\n    def forward(self, x):\n        # \u6309\u987a\u5e8f\u7ecf\u8fc7\u5377\u79ef\u3001\u6807\u51c6\u5316\u3001relu\u3001dropout\n        x = F.dropout(F.relu(self.bn1(self.conv1(x))), training=self.training)\n        x = F.dropout(F.relu(self.bn2(self.conv2(x))), training=self.training)\n        x = F.dropout(F.relu(self.bn3(self.conv3(x))), training=self.training)\n        # \u62c9\u4f38\u6210\u5411\u91cf\uff0c\u4fbf\u4e8e\u540e\u7eed\u4f20\u5165\u7ebf\u6027\u56de\u5f52\n        x = F.avg_pool2d(x, (x.size(2), x.size(3)))\n        x = x.view(-1, 128)\n        if self.context:\n            # \u4fdd\u5b58\u5411\u91cf\uff0c\u7528\u4e8e\u540e\u7eed\u8ba1\u7b97\u4e0a\u4e0b\u6587\u7279\u5f81\uff0c\u5411\u91cf\u957f\u5ea6\u4e3a128\n            feat = x\n        x = self.fc(x)\n        if self.context:\n            return x, feat\n        else:\n            return x\n</code></pre> <p>\u6df1\u5c42\u57df\u5206\u7c7b\u5668</p> <p>\u5bf9\u5e94\u8bba\u6587D_3\uff0c\u8fd9\u91cc\u5b9a\u4e49\u65b9\u6cd5\u4e0e\u4e2d\u5c42\u57df\u5206\u7c7b\u5668\u5dee\u4e0d\u591a\uff0c\u53ea\u662f\u4fee\u6539\u4e86\u901a\u9053\u6570</p> <pre><code># \u5bf9\u9ad8\u5c42\u7279\u5f81\u8fdb\u884c\u9886\u57df\u5206\u7c7b\u7684\u57df\u5206\u7c7b\u5668\uff0c\u8f93\u51fa\u4e24\u4e2a\u503c\nclass netD(nn.Module):\n    def __init__(self, context=False):\n        super(netD, self).__init__()\n        self.conv1 = conv3x3(1024, 512, stride=2)\n        self.bn1 = nn.BatchNorm2d(512)\n        self.conv2 = conv3x3(512, 128, stride=2)\n        self.bn2 = nn.BatchNorm2d(128)\n        self.conv3 = conv3x3(128, 128, stride=2)\n        self.bn3 = nn.BatchNorm2d(128)\n        self.fc = nn.Linear(128, 2)\n        self.context = context\n\n    def forward(self, x):\n        x = F.dropout(F.relu(self.bn1(self.conv1(x))), training=self.training)\n        x = F.dropout(F.relu(self.bn2(self.conv2(x))), training=self.training)\n        x = F.dropout(F.relu(self.bn3(self.conv3(x))), training=self.training)\n        x = F.avg_pool2d(x, (x.size(2), x.size(3)))\n        x = x.view(-1, 128)\n        if self.context:\n            # \u7279\u5f81\u5411\u91cf\u957f\u5ea6\u4e3a128\n            feat = x\n        x = self.fc(x)\n        if self.context:\n            return x, feat\n        else:\n            return x\n</code></pre> <p>\u5b9e\u4f8b\u7ea7\u57df\u5206\u7c7b\u5668</p> <p>\u5bf9\u5e94CA-ILA\u6a21\u5757\u4e2d\u7684\u57df\u5206\u7c7b\u5668\uff0c\u5bf9\u68c0\u6d4b\u5230\u7684\u6bcf\u4e2a\u5b9e\u4f8b\u8fdb\u884c\u9886\u57df\u5206\u7c7b</p> <pre><code># \u5b9e\u4f8b\u7ea7\u57df\u5206\u7c7b\u5668\uff0c\u5bf9\u68c0\u6d4b\u5230\u7684\u5b9e\u4f8b\u6267\u884c\u9886\u57df\u5206\u7c7b\uff0c\u6700\u540e\u8f93\u51fa\u4e24\u4e2a\u503c\nclass netD_da(nn.Module):\n    def __init__(self, feat_d):\n        super(netD_da, self).__init__()\n        # \u5b9a\u4e49\u597d\u7ebf\u6027\u56de\u5f52\u548c\u6807\u51c6\u5316\u5c42\n        # \u6700\u540e\u8f93\u51fa\u4e24\u4e2a\u503c\n        self.fc1 = nn.Linear(feat_d, 100)\n        self.bn1 = nn.BatchNorm1d(100)\n        self.fc2 = nn.Linear(100, 100)\n        self.bn2 = nn.BatchNorm1d(100)\n        self.fc3 = nn.Linear(100, 2)\n\n    def forward(self, x):\n        # \u4f9d\u6b21\u7ecf\u8fc7fc-&gt;bn-&gt;relu-&gt;dropout\n        x = F.dropout(F.relu(self.bn1(self.fc1(x))), training=self.training)\n        x = F.dropout(F.relu(self.bn2(self.fc2(x))), training=self.training)\n        x = self.fc3(x)\n        # \u8fd4\u56de\u9884\u6d4b\u7ed3\u679c\n        return x  # [256, 2]\uff0c\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u8868\u793a\u5b9e\u4f8b\u4e2a\u6570\n</code></pre>"},{"location":"domain_adaptive/code/HTCN2/#_4","title":"\u7279\u5f81\u52a0\u6743\u6a21\u5757","text":"<p>\u6d45\u5c42\u7279\u5f81\u52a0\u6743</p> <p>\u5bf9\u5e94\u8bba\u6587\u91cc\u7684\u5c40\u90e8\u7279\u5f81\u63a9\u6a21\u6a21\u5757</p> <pre><code>def local_attention(features, d):\n    # features.size() =  [1, 256, h, w] \u7279\u5f81\u56fe\u5c3a\u5bf8\n    # d.size() = [1, 1, h, w]  \u6d45\u5c42\u7279\u5f81\u7684\u9886\u57df\u9884\u6d4b\u5206\u6570\n    # \u9650\u5236d\u5927\u5c0f(1e-6\u52301\u4e4b\u95f4)\uff0c\u9632\u6b62\u51fa\u73b0\u96f6\u7684\u60c5\u51b5\n    d = d.clamp(1e-6, 1)\n    # \u8ba1\u7b97\u4fe1\u606f\u71b5H\uff0c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f1\n    H = - (d * d.log() + (1 - d) * (1 - d).log())\n    # \u8ba1\u7b97\u6743\u91cd\n    w = 1 - H\n    # \u5bf9\u6d45\u5c42\u7279\u5f81\u56fe\u8fdb\u884c\u52a0\u6743\uff0c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f2\n    features_new = (1 + w) * features\n\n    return features_new\n</code></pre> <p>\u4e2d\u5c42\u7279\u5f81\u52a0\u6743</p> <p>\u5bf9\u5e94\u8bba\u6587\u91cc\u7684IWAT-I\u6a21\u5757</p> <pre><code>def middle_attention(features, d):\n    # d.size() = [1,2]\n    # \u6c42\u4fe1\u606f\u71b5\n    _, H = self_entropy(d, softmax=True)\n    # \u5bf9\u4e2d\u5c42\u7279\u5f81\u8fdb\u884c\u52a0\u6743\n    features_new = (1 + H) * features\n\n    return features_new\n</code></pre> <p>\u8ba1\u7b97\u4fe1\u606f\u71b5</p> <pre><code>def self_entropy(prob, softmax):\n    # prob.size() = [N, C(2)]   C: Number of categories\n    # \u7531\u4e8e\u57df\u5206\u7c7b\u5668\u662f\u76f4\u63a5\u8f93\u51fa\u9884\u6d4b\u5206\u6570\uff0c\u6ca1\u6709\u7ecf\u8fc7\u5f52\u4e00\u5316\n    # \u56e0\u6b64\u8fd9\u91cc\u9996\u5148\u9700\u8981\u7ecf\u8fc7softmax\u5f52\u4e00\u5316\n    if softmax:\n        prob = F.softmax(prob, 1)\n    # \u9650\u5236\u9884\u6d4b\u5206\u6570\u7684\u5927\u5c0f\uff0c\u9632\u6b62\u51fa\u73b00\n    prob = prob.clamp(1e-6, 1)\n    log_prob = torch.log(prob)\n    # \u8ba1\u7b97\u4fe1\u606f\u71b5\n    H = - torch.sum(prob * log_prob, dim=1)  # [N]\n    # \u4e3a\u4ec0\u4e48\u8981\u8ba1\u7b97\u5747\u503c\uff1f\u5bf9\u540c\u4e00\u4e2abatch\u91cc\u56fe\u50cf\u7684\u4fe1\u606f\u71b5\u6c42\u5747\u503c\uff1f\n    H_mean = H.mean()\n\n    return H, H_mean\n</code></pre>"},{"location":"domain_adaptive/code/HTCN2/#_5","title":"\u968f\u673a\u5316\u64cd\u4f5c","text":"<pre><code># \u4e3b\u5e72\u7f51\u7edc\u4ee5resnet\u4e3a\u4f8b\nclass RandomLayer(nn.Module):\n    def __init__(self, input_dim_list=[], output_dim=1024):\n        super(RandomLayer, self).__init__()\n        # input_dim_list\u9ed8\u8ba4[2048,384]\n        self.input_num = len(input_dim_list)  # 2\n        # output_dim\u9ed8\u8ba41024\n        self.output_dim = output_dim\n        # \u751f\u6210\u4e24\u4e2a\u968f\u673a\u77e9\u9635\uff0c\u5bf9\u5e94\u8bba\u6587\u4e2dR1:[384,1024],R2:[2048,1024]\n        self.random_matrix = [torch.rand(input_dim_list[i], output_dim) for i in range(self.input_num)]\n\n    def forward(self, input_list):\n        # \u4f9d\u6b21\u505a\u77e9\u9635\u4e58\u79effc*R1-&gt;[batch,1024],f_{ins}*R2-&gt;[batch,1024]\n        return_list = [torch.mm(input_list[i], self.random_matrix[i]) for i in range(self.input_num)]\n        # \u8fd9\u91cc\u8868\u793a\u4e24\u4e2a\u6570\u505a\u9664\u6cd5\uff0c\u5206\u6bcd\u4e3a\u5206\u4e4b\u6839d\uff0c\u5206\u5b50\u4e3a\u516c\u5f0f(5)\u7684\u7b2c\u4e00\u9879\n        return_tensor = return_list[0] / math.pow(float(self.output_dim), 1.0 / len(return_list))\n        for single in return_list[1:]:\n            # \u7136\u540e\u518d\u904d\u5386\u505a\u70b9\u4e58\uff0c\u4f46\u8fd9\u91cc\u53ea\u904d\u5386\u4e00\u6b21\n            return_tensor = torch.mul(return_tensor, single)\n        # \u5176\u5b9e\u5b8c\u5168\u53ef\u4ee5\u5148\u505a\u70b9\u4e58\uff0c\u7136\u540e\u518d\u9664\u4ee5\u6839d\n        # \u8fd4\u56de\u968f\u673a\u5904\u7406\u540e\u7684\u7279\u5f81\n        return return_tensor\n\n    def cuda(self):\n        super(RandomLayer, self).cuda()\n        # \u5c06\u6570\u636e\u4f20\u5165\u663e\u5361\u4e2d\n        self.random_matrix = [val.cuda() for val in self.random_matrix]\n</code></pre> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u5927\u5bb6\u6279\u8bc4\u6307\u6b63</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e742\u670810\u65e5</p>"},{"location":"domain_adaptive/code/ICR-CCR2/","title":"\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\uff1aICR-CCR","text":""},{"location":"domain_adaptive/code/ICR-CCR2/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u4e0e\u65f6\u95f4\uff1aIEEE Conference on Computer Vision and Pattern Recognition 2020 (CVPR, 2020)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttp://openaccess.thecvf.com/content_CVPR_2020/papers/Xu_Exploring_Categorical_Regularization_for_Domain_Adaptive_Object_Detection_CVPR_2020_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/Megvii-Nanjing/CR-DA-DET</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b</p> <p>\u8fd9\u91cc\u4ee5\u5728Domain Adaptive Faster R-CNN\u7b97\u6cd5\u4e2d\u5f15\u5165\u6b63\u5219\u5316\u5668\u4e3a\u4f8b\uff0c\u7f51\u7edc\u7ed3\u6784\u8def\u5f84\uff1a</p> <p>CR-DA-DET-master\\DA_Faster_ICR_CCR\\lib\\model\\roi_align\\faster_rcnn.py</p>"},{"location":"domain_adaptive/code/ICR-CCR2/#_2","title":"\u591a\u6807\u7b7e\u5206\u7c7b\u5668","text":"<p>\u8fd9\u91cc\u5176\u5b9e\u5c31\u76f8\u5f53\u4e8e\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42\uff0c\u7528\u4e8e\u9884\u6d4b\u7c7b\u522b\u5206\u6570</p> <pre><code># \u76f8\u5bf9\u4e8e\u539f\u59cbFaster R-CNN\uff0c\u65b0\u5b9a\u4e49\u4e86\u4e24\u4e2a\u5c42\n# \u5168\u5c40\u5e73\u5747\u6c60\u5316\uff0c\u7528\u4e8e\u5c06\u7279\u5f81\u56fe\u62c9\u4f38\u6210\u4e00\u4e2a\u5411\u91cf\nself.avg_pool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n# 1*1\u7684\u5377\u79ef\uff0c\u7528\u4e8e\u9884\u6d4b\u7c7b\u522b\u5206\u6570\uff0c\u4e0enn.Linear\u4f5c\u7528\u4e00\u81f4\nself.conv_lst = nn.Conv2d(self.dout_base_model, self.n_classes - 1, 1, 1, 0)\n</code></pre> <p>\u8ba1\u7b97\u5206\u7c7b\u5668\u7684\u6807\u7b7ecls_lb\uff0c\u4ee3\u7801\u4f4d\u4e8e\uff1a</p> <p>CR-DA-DET-master\\DA_Faster_ICR_CCR\\lib\\roi_da_data_layer\\minibatch.py</p> <pre><code># \u8fd9\u91cc\u4f20\u5165\u7684array\u4e3a\u6e90\u57df\u6570\u636e\u4e2d\u7684\u5bf9\u8c61\u7c7b\u522b\u6807\u7b7e\ndef gt_classes2cls_lb_onehot(array):\n    # \u5148\u521d\u59cb\u5316\u6807\u7b7e\n    cls_lb = np.zeros((num_classes - 1,), np.float32)\n    # \u904d\u5386\u6240\u6709\u7684\u5bf9\u8c61\u7c7b\u522b\n    for i in array:\n        # \u5229\u7528\u7d22\u5f15\u5bf9cls_lb\u8d4b\u503c\n        # \u7531\u4e8e\u5bf9\u8c61\u7c7b\u522b\u662f\u4ece1\u5f00\u59cb\u7684(0\u8868\u793a\u80cc\u666f)\uff0c\u56e0\u6b64\u591a\u6807\u7b7e\u5206\u7c7b\u5668\u7684\u9884\u6d4b\u7c7b\u522b\u6570\u91cf\u8981\u6bd4ROI\u9884\u6d4b\u5b9e\u4f8b\u7684\u7c7b\u522b\u6570\u91cf\u5c111\n        # \u5bf9\u5e94\u7d22\u5f15\u8981\u51cf1\n        cls_lb[i - 1] = 1\n    return cls_lb\n</code></pre>"},{"location":"domain_adaptive/code/ICR-CCR2/#icr","title":"ICR\u6a21\u5757","text":"<p>\u56e0\u4e3a\u53ea\u6709\u6e90\u57df\u6570\u636e\u6709\u56fe\u50cf\u7c7b\u522b\u6807\u7b7e\uff0c\u56e0\u6b64ICR\u635f\u5931\u53ea\u9488\u5bf9\u6e90\u57df\u6570\u636e</p> <pre><code># \u5c06\u6e90\u57df\u6570\u636e\u4f20\u5165\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\uff0c\u63d0\u53d6\u7279\u5f81\nbase_feat = self.RCNN_base(im_data)\n# \u5c06\u6e90\u57df\u4e2d\u7684\u56fe\u50cf\u7279\u5f81\u4f20\u5165\u591a\u6807\u7b7e\u5206\u7c7b\u5668\u9884\u6d4b\u5206\u6570\uff0c\u7528\u4e8e\u8ba1\u7b97ICR\u635f\u5931\ncls_feat = self.conv_lst(self.avg_pool(base_feat)).squeeze(-1).squeeze(-1)\n# BCEWithLogitsLoss\u548c\u4e8c\u5143\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\u5dee\u4e0d\u591a\uff0c\u53ea\u662f\u591a\u4e86\u4e00\u4e2asigmoid\uff0c\u5373\u8f93\u5165\u5148\u7ecf\u8fc7sigmoid\uff0c\u518d\u8ba1\u7b97\u635f\u5931\n# \u8fd9\u91ccim_cls_lb\u8868\u793a\u6807\u7b7ey^c\n# \u8ba1\u7b97\u6e90\u57df\u56fe\u50cf\u4e2dICR\u6b63\u5219\u5316\u5668\u635f\u5931\nimg_cls_loss = nn.BCEWithLogitsLoss()(cls_feat, im_cls_lb)\n</code></pre>"},{"location":"domain_adaptive/code/ICR-CCR2/#ccr","title":"CCR\u6a21\u5757","text":"<p>\u524d\u7f6e\u5de5\u4f5c</p> <p>\u2003\u2003\u8fd9\u91cc\u53ea\u5217\u51fa\u4e86\u4e3b\u8981\u7684\u4ee3\u7801\uff0c\u6ce8\u610f\uff1a\u4ee3\u7801\u4e2d\u5e26\u6709\u524d\u7f6e<code>tgt</code>\u7684\u53d8\u91cf\u8868\u793a\u5bf9\u5e94\u4e8e\u76ee\u6807\u57df\u6570\u636e\u7684\u53d8\u91cf\uff0c\u5982<code>tgt_base_feat</code>\u8868\u793a\u7531\u76ee\u6807\u57df\u56fe\u50cf\u751f\u6210\u7684\u7279\u5f81\u56fe\uff0c\u800c<code>base_feat</code>\u8868\u793a\u7531\u6e90\u57df\u56fe\u50cf\u751f\u6210\u7684\u7279\u5f81\u56fe\u3002</p> <pre><code># \u5c06\u76ee\u6807\u57df\u6570\u636e\u4f20\u5165\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u63d0\u53d6\u7279\u5f81\ntgt_base_feat = self.RCNN_base(tgt_im_data)\n# \u5c06\u76ee\u6807\u57df\u56fe\u50cf\u7279\u5f81\u4f20\u5165\u591a\u6807\u7b7e\u5206\u7c7b\u5668\uff0c\u5f97\u5230\u7684\u9884\u6d4b\u5206\u6570\u7528\u4e8e\u8ba1\u7b97CCR\u635f\u5931\ntgt_image_cls_feat = (\n    self.conv_lst(self.avg_pool(tgt_base_feat)).squeeze(-1).squeeze(-1)\n)\n# \u5c06\u5206\u6570\u7ecf\u8fc7sigmoid\u51fd\u6570\ntgt_image_cls_feat = F.sigmoid(tgt_image_cls_feat[0]).detach()\n\n# RPN\u6a21\u5757\nself.RCNN_rpn.eval()\n(\n    tgt_rois,\n    tgt_rpn_loss_cls,\n    tgt_rpn_loss_bbox,\n    tgt_rois_binary_score,\n) = self.RCNN_rpn(\n    tgt_base_feat, tgt_im_info, tgt_gt_boxes, tgt_num_boxes, need_cls_score=True\n)\n# ROI Pooling\u6a21\u5757\ntgt_pooled_feat = self.RCNN_roi_crop(\n                tgt_base_feat, Variable(tgt_grid_yx).detach()\n             )\nif cfg.CROP_RESIZE_WITH_MAX_POOL:\n    tgt_pooled_feat = F.max_pool2d(tgt_pooled_feat, 2, 2)\ntgt_pooled_feat = self._head_to_tail(tgt_pooled_feat)\n\n# \u5c06\u5f97\u5230\u7684\u5b9e\u4f8b\u533a\u57df\u7279\u5f81\u4f20\u5165\u68c0\u6d4b\u5668\u4e2d\u7684\u5206\u7c7b\u7f51\u7edc\uff0c\u7528\u4e8e\u9884\u6d4b\u7c7b\u522b\u5206\u6570\ntgt_cls_score = self.RCNN_cls_score(tgt_pooled_feat).detach()\n# \u5c06\u9884\u6d4b\u5206\u6570\u4f20\u5165softmax\uff0c\u5f97\u5230\u9884\u6d4b\u6982\u7387\ntgt_prob = F.softmax(tgt_cls_score, 1).detach()\n# \u63d0\u53d6\u51fa\u9884\u6d4b\u6982\u7387\u503c\u6700\u5927\u7684\u7d22\u5f15\uff0c\u770b\u4f5c\u8be5\u5b9e\u4f8b\u7684\u7c7b\u522b\ntgt_pre_label = tgt_prob.argmax(1).detach()\n</code></pre> <p>\u635f\u5931\u7684\u8ba1\u7b97</p> <p>\u2003\u2003CCR\u635f\u5931\u4e3b\u8981\u662f\u8ba1\u7b97\u4e8c\u5143\u4ea4\u53c9\u71b5\u635f\u5931\u7684\u6743\u91cdd_j\uff0c\u5e76\u4e14\u53ea\u9488\u5bf9\u76ee\u6807\u57df\u6570\u636e\u7684\u524d\u666f\u5b9e\u4f8b\uff0c\u5bf9\u4e8e\u6e90\u57df\u6570\u636e\u548c\u76ee\u6807\u57df\u6570\u636e\u4e2d\u7684\u80cc\u666f\u5b9e\u4f8b\uff0cd_j\u5747\u8bbe\u7f6e\u4e3a1\u3002</p> <pre><code># \u8fd9\u91cc\u8868\u793a\u6743\u91cdd_j\ntarget_weight = []\n#  \u6309\u9884\u6d4b\u5230\u7684\u5b9e\u4f8b(\u76ee\u6807)\u8fdb\u884c\u904d\u5386\nfor i in range(len(tgt_pre_label)):\n    # \u5f97\u5230\u7b2ci\u4e2a\u76ee\u6807\u7684\u9884\u6d4b\u6807\u7b7e\n    label_i = tgt_pre_label[i].item()\n    # 0\u8868\u793a\u80cc\u666f\uff0c\u5982\u679c\u8be5\u7269\u4f53\u975e\u80cc\u666f\u7684\u8bdd\uff0c\u5c31\u8ba1\u7b97d_j\n    if label_i &gt; 0:\n        # \u8fd9\u91cc\u8868\u793a\u8ba1\u7b97d_j\uff0c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f(5)\n        # tgt_image_cls_feat\u8868\u793a\u591a\u6807\u7b7e\u5206\u7c7b\u5668\u9884\u6d4b\u7684\u5206\u6570\uff0c\u5bf9\u5e94\u8bba\u6587\u91cc\u7684p_j\n        # tgt_prob\u8868\u793aROI Head\u5bf9\u5b9e\u4f8b\u7684\u5206\u7c7b\u7ed3\u679c\n        diff_value = torch.exp(\n            weight_value\n            * torch.abs(tgt_image_cls_feat[label_i - 1] - tgt_prob[i][label_i])\n        ).item()\n        # \u5b58\u50a8\u5f97\u5230\u7684d_j\n        target_weight.append(diff_value)\n    # \u5982\u679c\u8be5\u7269\u4f53\u662f\u80cc\u666f\u7684\u8bdd\uff0c\u5219d_j=0\uff0c\u5373\u6743\u91cd\u4e0d\u53d8\n    else:\n        target_weight.append(1.0)\n# \u521d\u59cb\u5316\u4e8c\u5143\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u5c06\u4e0a\u9762\u5f97\u5230\u7684\u6743\u91cdd_j\u653e\u8fdb\u53bb\ntgt_instance_loss = nn.BCELoss(\n    weight=torch.Tensor(target_weight).view(-1, 1).cuda()\n)\n# \u8ba1\u7b97\u76ee\u6807\u57df\u56fe\u50cf\u4e2d\uff0c\u5f15\u5165\u4e86CCR\u7684\u5b9e\u4f8b\u7ea7\u5bf9\u6297\u635f\u5931\ntgt_DA_ins_loss_cls = tgt_instance_loss(\n    tgt_instance_sigmoid, tgt_same_size_label\n)\n</code></pre> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u5927\u5bb6\u6279\u8bc4\u6307\u6b63</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e742\u67089\u65e5</p>"},{"location":"domain_adaptive/code/MeGA-CDA2/","title":"\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\uff1aMeGA-CDA","text":""},{"location":"domain_adaptive/code/MeGA-CDA2/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u4e0e\u65f6\u95f4\uff1aIEEE Conference on Computer Vision and Pattern Recognition 2021 (CVPR, 2021)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttp://openaccess.thecvf.com/content/CVPR2021/papers/VS_MeGA-CDA_Memory_Guided_Attention_for_Category-Aware_Unsupervised_Domain_Adaptive_Object_CVPR_2021_paper.pdf</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b</p> <p>\u2003\u2003\u4f5c\u8005\u6ca1\u6709\u516c\u5f00\u6e90\u7801\uff0c\u4f46\u662f\u901a\u8fc7\u9605\u8bfb\u8bba\u6587\u53ef\u4ee5\u53d1\u73b0\u8be5\u7b97\u6cd5\u4e3b\u8981\u7531\u4e24\u4e2a\u81ea\u9002\u5e94\u7ed3\u6784\u7ec4\u6210\uff0c\u5206\u522b\u662f\u5168\u5c40\u7279\u5f81\u5bf9\u9f50(\u5168\u5c40\u5224\u522b\u5668)\uff0c\u4ee5\u53ca\u7c7b\u76f8\u5173\u7279\u5f81\u5bf9\u9f50(\u7c7b\u5224\u522b\u5668)\uff0c\u800c\u5168\u5c40\u5224\u522b\u5668\u4e0e\u7b97\u6cd5Domain Adaptive Faster R-CNN\u4e2d\u7684\u5168\u5c40\u7279\u5f81\u5bf9\u9f50\u6a21\u5757\u4e00\u81f4\uff0c\u53ef\u4ee5\u53c2\u8003\u8bba\u6587\u7b14\u8bb0(\u94fe\u63a5)\u3002\u800c\u7c7b\u5224\u522b\u5668\u4e3b\u8981\u5c31\u5728\u4e8e\u8bb0\u5fc6\u7f51\u7edc\uff0c\u8fd9\u91cc\u7684\u8bb0\u5fc6\u7f51\u7edc\u53c2\u8003\u7684\u8bba\u6587\u300aLearning Memory-guided Normality for Anomaly Detection\u300b\uff0c\u5bf9\u5e94\u6e90\u7801\u5730\u5740\u4e3a\uff1ahttps://github.com/cvlab-yonsei/MNAD\uff0c\u8fd9\u91cc\u4e3b\u8981\u8bb0\u5f55\u4e00\u4e0b\u8bb0\u5fc6\u7f51\u7edc\u76f8\u5173\u7684\u4ee3\u7801\u3002</p>"},{"location":"domain_adaptive/code/MeGA-CDA2/#_2","title":"\u7f51\u7edc\u7ed3\u6784","text":"<pre><code>class Memory(nn.Module):\n    def __init__(self, memory_size, feature_dim, key_dim,  temp_update, temp_gather):\n        super(Memory, self).__init__()\n        # Constants\n        # \u6bcf\u4e2a\u8bb0\u5fc6\u6a21\u5757\u4e2d\u8bb0\u5fc6\u5355\u5143\u7684\u4e2a\u6570\uff0c\u5373Nm\n        self.memory_size = memory_size\n        # \u7279\u5f81\u56fe\u901a\u9053\u6570\n        self.feature_dim = feature_dim\n        # \u540e\u9762\u4e09\u4e2a\u53d8\u91cf\u540e\u7eed\u90fd\u6ca1\u7528\u5230\uff0c\u53ef\u4ee5\u4e0d\u7528\u7ba1\n        self.key_dim = key_dim\n        self.temp_update = temp_update\n        self.temp_gather = temp_gather\n\n    # keys\u8868\u793a\u8bb0\u5fc6\u5355\u5143\uff0cquery\u8868\u793a\u8f93\u51fa\u7684\u7279\u5f81\n    def forward(self, query, keys, train=True):\n        # \u5f97\u5230\u67e5\u8be2\u7279\u5f81\u7684\u5c3a\u5bf8\uff0c\u4f46\u662f\u540e\u7eed\u6ca1\u6709\u7528\u5230\n        batch_size, dims, h, w = query.size()  # b, c, h, w\n        # \u5f52\u4e00\u5316\u65b9\u6cd5\uff0c\u9ed8\u8ba4L2\u5f52\u4e00\u5316\n        # \u8fd9\u91cc\u7684\u5f52\u4e00\u5316\u65b9\u6cd5\u6709\u6ca1\u6709\u7528\u8fd8\u9700\u8981\u8fdb\u4e00\u6b65\u9a8c\u8bc1\n        # \u5f02\u5e38\u68c0\u6d4b\u90a3\u7bc7\u8bba\u6587\u63d0\u5230\u4e86\uff0c\u4f46\u662f\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u90a3\u7bc7\u8bba\u6587\u6ca1\u6709\u63d0\u5230\uff0c\n        query = F.normalize(query, dim=1)\n        # \u8f6c\u6362\u7ef4\u5ea6\uff0c\u8f6c\u6362\u540e\u7ef4\u5ea6\u4e3a(b, h, w, c)\n        query = query.permute(0, 2, 3, 1)\n\n        # \u8bad\u7ec3\u9636\u6bb5\n        if train:\n            # \u8ba1\u7b97\u635f\u5931\uff0c\u4f20\u5165\u7279\u5f81\u548c\u8bb0\u5fc6\u6a21\u5757\uff0c\u5f97\u5230\u5206\u79bb\u635f\u5931(\u552f\u4e00\u6027\u635f\u5931)\u548c\u7d27\u5bc6\u5ea6\u635f\u5931\n            separateness_loss, compactness_loss = self.gather_loss(query, keys, train)\n            # \u8bfb\u64cd\u4f5c\uff0c\u8fd4\u56de\u68c0\u7d22\u7279\u5f81\u3001\u76f8\u4f3c\u5ea6\u77e9\u9635p\u548c\u76f8\u4f3c\u5ea6\u77e9\u9635q\n            updated_query, softmax_score_query, softmax_score_memory = self.read(query, keys)\n            # \u5199\u64cd\u4f5c\uff0c\u8fd4\u56de\u66f4\u65b0\u540e\u7684\u8bb0\u5fc6\u6a21\u5757\n            updated_memory = self.update(query, keys, train)\n            # \u4f9d\u6b21\u8fd4\u56de\u68c0\u7d22\u7279\u5f81\u3001\u66f4\u65b0\u540e\u7684\u8bb0\u5fc6\u6a21\u5757\u3001\u76f8\u4f3c\u5ea6\u77e9\u9635p\u3001\u76f8\u4f3c\u5ea6\u77e9\u9635q\u3001\u5206\u79bb\u635f\u5931\u3001\u7d27\u5bc6\u5ea6\u635f\u5931\n            return updated_query, updated_memory, softmax_score_query, softmax_score_memory, separateness_loss, compactness_loss\n\n        # \u6d4b\u8bd5\u9636\u6bb5\uff0c\u4e0e\u8bad\u7ec3\u9636\u6bb5\u7c7b\u4f3c\uff0c\u53ea\u662f\u7f3a\u5c11\u5199\u64cd\u4f5c\uff0c\u5373\u6d4b\u8bd5\u9636\u6bb5\u4e0d\u5bf9\u8bb0\u5fc6\u6a21\u5757\u8fdb\u884c\u66f4\u65b0\n        else:\n            # \u8ba1\u7b97\u635f\u5931\uff0c\n            compactness_loss, query_re, top1_keys, keys_ind = self.gather_loss(query,keys, train)\n            # \u8bfb\u64cd\u4f5c\n            updated_query, softmax_score_query,softmax_score_memory = self.read(query, keys)\n            # \u6d4b\u8bd5\u9636\u6bb5\u4e0d\u5bf9\u8bb0\u5fc6\u6a21\u5757\u8fdb\u884c\u66f4\u65b0\uff0c\u76f4\u63a5\u8d4b\u503c\u5373\u53ef\n            updated_memory = keys\n            return updated_query, updated_memory, softmax_score_query, softmax_score_memory, query_re, top1_keys,keys_ind, compactness_loss\n</code></pre>"},{"location":"domain_adaptive/code/MeGA-CDA2/#_3","title":"\u8ba1\u7b97\u76f8\u4f3c\u77e9\u9635","text":"<pre><code>def get_score(self, mem, query):\n    # \u4f20\u5165\u8bb0\u5fc6\u6a21\u5757\u548c\u7279\u5f81\n    # \u5f97\u5230\u67e5\u8be2\u7279\u5f81\u7684\u5c3a\u5bf8\uff0c\u8fd9\u91ccd\u8868\u793a\u901a\u9053\u6570\n    bs, h, w, d = query.size()\n    # \u5f97\u5230\u8bb0\u5fc6\u6a21\u5757\u7684\u5c3a\u5bf8\uff0c\u8fd9\u91ccm\u8868\u793a\u8bb0\u5fc6\u5355\u5143\u7684\u6570\u91cf\uff0cd\u8868\u793a\u901a\u9053\u6570\n    m, d = mem.size()\n    # \u77e9\u9635\u76f8\u4e58\uff0c\u5bf9\u5e94\u8bba\u6587\u4e2dm_j*g_s^i\uff0c\u5373\u516c\u5f0f3\u30018\u4e2d\u7684exp\u5185\u90e8\u77e9\u9635\u4e58\u79ef\u7684\u64cd\u4f5c(\u975e\u70b9\u4e58)\n    # \u8fd4\u56de\u5c3a\u5bf8\u4e3a(b,h,w,d)\u7684\u6570\u7ec4\n    score = torch.matmul(query, torch.t(mem))\n    # \u6539\u53d8\u5f62\u72b6\uff0c\u4ee5\u5199\u64cd\u4f5c\u4e3a\u4f8b\uff0c\u6539\u53d8\u540e\u5c3a\u5bf8\u4e3a(b*Ns,Nm)\uff0c\u5373Nk*Nm\uff0cNk\u4e3a\u8868\u793a\u7279\u5b9a\u7c7b\u522b\u7684\u50cf\u7d20\u70b9\u6570\u91cf(\u5229\u7528\u6807\u7b7e\u88c1\u526a\u51fa\u6765\u7684)\n    # \u4ee5\u4e8c\u7ef4\u77e9\u9635\u7684\u89c6\u89d2\u66f4\u5bb9\u6613\u7406\u89e3\uff0c\u6bcf\u4e00\u884c\u8868\u793a\u5355\u4e2ags,\u6240\u6709\u884c\u5408\u5e76\u8d77\u6765\u8868\u793aGk\n    # \u6bcf\u4e00\u5217\u8868\u793a\u5355\u4e2a\u8bb0\u5fc6\u5355\u5143mj\uff0c\u6240\u6709\u7684\u5217\u5408\u5e76\u8d77\u6765\u8868\u793aMk\n    score = score.view(bs*h*w, m)\n    # \u6cbf\u5217\u8fdb\u884c\u5f52\u4e00\u5316\uff0c\u5373\u5206\u6bcd\u89c6\u6240\u6709\u7684\u7279\u5f81\u5411\u91cfgs\u4e3a\u6574\u4f53\uff0c\u5373\u5bf9\u96c6\u5408Gk\u4e2d\u6240\u6709\u7279\u5f81\u6c42\u548c-&gt;\u8ba1\u7b97p\n    score_query = F.softmax(score, dim=0)\n    # \u6cbf\u884c\u8fdb\u884c\u5f52\u4e00\u5316\uff0c\u5373\u5206\u6bcd\u89c6\u6240\u6709\u7684\u8bb0\u5fc6\u5355\u5143mj\u4e3a\u6574\u4f53\uff0c\u5373\u5bf9Nm\u4e2d\u7684\u6240\u6709\u8bb0\u5fc6\u5355\u5143\u6c42\u548c-&gt;\u8ba1\u7b97q\n    score_memory = F.softmax(score, dim=1)\n    # \u5206\u522b\u5bf9\u5e94\u8bba\u6587\u4e2d\u7684p,q\n    return score_query, score_memory\n</code></pre>"},{"location":"domain_adaptive/code/MeGA-CDA2/#_4","title":"\u8ba1\u7b97\u635f\u5931","text":"<pre><code># \u8ba1\u7b97\u635f\u5931\ndef gather_loss(self, query, keys, train):\n    batch_size, h, w, dims = query.size()  # b X h X w X d\n    if train:\n        # \u5b9a\u4e49\u4e09\u5143\u8fb9\u754c\u635f\u5931\uff0c\u7528\u4e8e\u8ba1\u7b97\u5206\u79bb\u635f\u5931\n        loss = torch.nn.TripletMarginLoss(margin=1.0)\n        # \u5b9a\u4e49mse\u635f\u5931\uff0c\u7528\u4e8e\u8ba1\u7b97\u7d27\u5bc6\u5ea6\u635f\u5931\n        loss_mse = torch.nn.MSELoss()\n        # \u5f97\u5230\u76f8\u4f3c\u5ea6\u77e9\u9635p\u3001q\uff0c\u4e24\u4e2a\u77e9\u9635\u5c3a\u5bf8\u5747\u4e3a:\u7279\u5f81\u5411\u91cf\u6570\u91cf*\u8bb0\u5fc6\u5355\u5143\u6570\u91cf\n        softmax_score_query, softmax_score_memory = self.get_score(keys, query)\n        # \u6539\u53d8\u4f20\u5165\u7279\u5f81\u7684\u5f62\u72b6\uff0c\u5c06\u901a\u9053C\u5355\u72ec\u53d8\u6210\u4e00\u4e2a\u7ef4\u5ea6\uff0c\u7b2c\u4e00\u7ef4\u5ea6\u76f8\u5f53\u4e8eN_k\uff0c\u5373\u96c6\u5408G_k\u4e2d\u7279\u5f81\u5411\u91cf\u7684\u6570\u91cf\uff0c\u4fbf\u4e8e\u540e\u7eed\u8ba1\u7b97\n        query_reshape = query.contiguous().view(batch_size*h*w, dims)\n        # \u9009\u51fa\u76f8\u4f3c\u5ea6\u77e9\u9635\u4e2d\u6700\u76f8\u4f3c\u7684\u524d\u4e24\u4e2a\uff0c\u8fd9\u91cc\u4ee5\u7b2c\u4e8c\u7ef4\u5ea6(\u6cbf\u884c)\u627e\u6700\u503c\uff0c\u56e0\u6b64\u8fd4\u56de\u7684\u662f\u4e0e\u5f53\u524d\u7279\u5f81\u6700\u76f8\u4f3c\u7684\u8bb0\u5fc6\u5355\u5143\u6807\u7b7e\n        _, gathering_indices = torch.topk(softmax_score_memory, 2, dim=1)\n        # \u5229\u7528\u7d22\u5f15\u6765\u5f97\u5230\u4e0e\u5f53\u524d\u5411\u91cf\u76f8\u6bd4\uff0c\u6700\u76f8\u4f3c\u7684\u548c\u7b2c\u4e8c\u76f8\u4f3c\u7684\u8bb0\u5fc6\u5355\u5143\n        pos = keys[gathering_indices[:, 0]]\n        neg = keys[gathering_indices[:, 1]]\n        # \u8ba1\u7b97\u635f\u5931\n        top1_loss = loss_mse(query_reshape, pos.detach())\n        gathering_loss = loss(query_reshape, pos.detach(), neg.detach())\n        # \u552f\u4e00\u6027\u635f\u5931\u3001\u7d27\u5bc6\u5ea6\u635f\u5931\n        return gathering_loss, top1_loss\n    else:\n        # \u6d4b\u8bd5\u8fc7\u7a0b\uff0c\u53ea\u8ba1\u7b97\u7d27\u5bc6\u5ea6\u635f\u5931\n        loss_mse = torch.nn.MSELoss()\n        # \u4e0e\u8bad\u7ec3\u4e00\u6837\uff0c\u8ba1\u7b97\u76f8\u4f3c\u6027\u77e9\u9635\n        softmax_score_query, softmax_score_memory = self.get_score(keys, query)\n        # \u6539\u53d8\u5f62\u72b6\n        query_reshape = query.contiguous().view(batch_size*h*w, dims)\n        # \u6c42\u4e0e\u5f53\u524d\u7279\u5f81\u5411\u91cf\u76f8\u6bd4\uff0c\u6700\u76f8\u4f3c\u8bb0\u5fc6\u5355\u5143\u7684\u7d22\u5f15\n        _, gathering_indices = torch.topk(softmax_score_memory, 1, dim=1)\n        # \u8ba1\u7b97\u635f\u5931\n        gathering_loss = loss_mse(query_reshape, keys[gathering_indices].squeeze(1).detach())\n        return gathering_loss, query_reshape, keys[gathering_indices].squeeze(1).detach(), gathering_indices[:,0]\n</code></pre>"},{"location":"domain_adaptive/code/MeGA-CDA2/#_5","title":"\u5199\u64cd\u4f5c","text":"<pre><code># \u5199\u64cd\u4f5c\uff0c\u4f20\u5165\u67e5\u8be2\u7279\u5f81\uff0c\u8bb0\u5fc6\u6a21\u5757\uff0c\u662f\u5426\u5904\u4e8e\u8bad\u7ec3\u9636\u6bb5\ndef update(self, query, keys, train):\n    # \u5f97\u5230\u67e5\u8be2\u7279\u5f81\u7684\u5c3a\u5bf8\n    batch_size, h, w, dims = query.size()  # b X h X w X d\n    # \u5f97\u5230\u7279\u5f81\u548c\u8bb0\u5fc6\u6a21\u5757\u7684\u76f8\u4f3c\u77e9\u9635p\u548cq\uff0c\u4e24\u4e2a\u77e9\u9635\u5c3a\u5bf8\u5747\u4e3aNk*Nm\uff0c\u5373\u7279\u5f81\u5411\u91cf\u6570\u91cf*\u8bb0\u5fc6\u5355\u5143\u6570\u91cf\n    softmax_score_query, softmax_score_memory = self.get_score(keys, query)\n    # \u5c06\u7279\u5f81\u62c9\u4f38\uff0c\u62c9\u4f38\u6210(Ns*b,C)\u7684\u5f62\u72b6\uff0c\u7b2c\u4e00\u7ef4\u5ea6\u8868\u793aG_k\n    query_reshape = query.contiguous().view(batch_size * h * w, dims)\n    # \u5f97\u5230\u4e0e\u5f53\u524d\u67e5\u8be2\u7279\u5f81\u5411\u91cf\u76f8\u6bd4\uff0c\u6700\u76f8\u4f3c\u7684\u8bb0\u5fc6\u5355\u5143\u7d22\u5f15\uff0c\u8fd9\u91cc\u53ea\u5728\u5f02\u5e38\u68c0\u6d4b\u90a3\u91cc\u7528\u5230\u4e86\uff0c\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u6ca1\u7528\u5230\n    _, gathering_indices = torch.topk(softmax_score_memory, 1, dim=1)\n    # updating_indices\u540e\u7eed\u672a\u7528\u5230\n    _, updating_indices = torch.topk(softmax_score_query, 1, dim=0)\n\n    # \u4f9d\u6b21\u4f20\u5165\u8bb0\u5fc6\u6a21\u5757\u3001\u4e24\u4e2a\u7d22\u5f15\u3001\u76f8\u4f3c\u5ea6\u77e9\u9635p\u3001\u67e5\u8be2\u7279\u5f81\u3001\u662f\u5426\u5904\u4e8e\u8bad\u7ec3\u9636\u6bb5\n    query_update = self.get_update_query(keys, gathering_indices, updating_indices, softmax_score_query,\n                                         query_reshape, train)\n    # MeGA-CDA\u4e2d\u6ca1\u6709\u6807\u51c6\u5316\u7684\u64cd\u4f5c\uff0c\u56e0\u6b64\u53ef\u4ee5\u7701\u53bbF.normalize\uff0c\u76f4\u63a5\u76f8\u52a0\u5c31\u53ef\u4ee5\n    updated_memory = F.normalize(query_update + keys, dim=1)\n\n    return updated_memory.detach()\n</code></pre> <p>\u8ba1\u7b97\u8bb0\u5fc6\u6a21\u5757\u7684\u66f4\u65b0\u91cf</p> <pre><code>def get_update_query(self, mem, max_indices, update_indices, score, query, train):\n    # \u5f97\u5230\u8bb0\u5fc6\u6a21\u5757\u7684\u5c3a\u5bf8\uff0cm\u5bf9\u5e94\u8bb0\u5fc6\u5355\u5143\u6570\u91cf\uff0cd\u5bf9\u5e94\u901a\u9053\u6570\n    m, d = mem.size()\n    if train:\n        # \u521d\u59cb\u5316\u4e00\u4e2a\u65b0\u7684\u8bb0\u5fc6\u6a21\u5757\uff0c\u8fd9\u91cc\u7528\u4e8e\u5b58\u50a8\u8bb0\u5fc6\u6a21\u5757\u66f4\u65b0\u7684\u90e8\u5206\n        query_update = torch.zeros((m, d)).cuda()\n        # \u6309\u8bb0\u5fc6\u5355\u5143\u987a\u5e8f\u904d\u5386\n        for i in range(m):\n            # \u8fd9\u91cc\u662f\u5229\u7528\u76f8\u4f3c\u5ea6\u6700\u5927\u7684\u7279\u5f81\u8fdb\u884c\u66f4\u65b0\n            # \u800c\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u4e2d\u76f4\u63a5\u5229\u7528\u6e90\u57df\u7c7b\u522b\u7279\u5f81\u8fdb\u884c\u66f4\u65b0\n            idx = torch.nonzero(max_indices.squeeze(1) == i)\n            a, _ = idx.size()\n            if a != 0:\n                # \u8fd9\u91cc\u5f02\u5e38\u68c0\u6d4b\u4e2d\u5bf9\u76f8\u4f3c\u77e9\u9635\u505a\u4e86\u91cd\u6574\uff0c\u4f46\u662f\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u4e2d\u6ca1\u6709\u8fd9\u4e00\u6b65(\u6c42\u6700\u5927\u503c\u518d\u505a\u9664\u6cd5)\uff0c\u76f4\u63a5\u4e58\u79ef\u6c42\u548c\u5373\u53ef\n                query_update[i] = torch.sum(((score[idx, i] / torch.max(score[:, i])) * query[idx].squeeze(1)), dim=0)\n            else:\n                query_update[i] = 0 \n\n        return query_update\n</code></pre>"},{"location":"domain_adaptive/code/MeGA-CDA2/#_6","title":"\u8bfb\u64cd\u4f5c","text":"<pre><code># \u8bfb\u64cd\u4f5c\uff0c\u4f20\u5165\u67e5\u8be2\u7279\u5f81\u548c\u8bb0\u5fc6\u6a21\u5757\ndef read(self, query, updated_memory):\n    # \u5f97\u5230\u67e5\u8be2\u7279\u5f81\u7684\u5c3a\u5bf8\n    batch_size, h, w, dims = query.size()  # b X h X w X d\n    # \u5f97\u5230\u76f8\u4f3c\u5ea6\u77e9\u9635p\u548cq\n    softmax_score_query, softmax_score_memory = self.get_score(updated_memory, query)\n    # \u6539\u53d8\u5f62\u72b6\uff0c\u7b2c\u4e00\u7ef4\u5ea6\u76f8\u5f53\u4e8eG_k\u603b\u4f53\n    query_reshape = query.contiguous().view(batch_size*h*w, dims)\n    # \u76f8\u4f3c\u5ea6\u77e9q\u9635\u548c\u8bb0\u5fc6\u6a21\u5757\u505a\u4e58\u79ef\uff0c\u518d\u6c42\u548c\uff0c\u5f97\u5230\u68c0\u7d22\u7279\u5f81\uff0c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f(9)\n    concat_memory = torch.matmul(softmax_score_memory.detach(), updated_memory)  # (b X h X w) X d\n    # MeGA-CDA\u8bba\u6587\u4e2d\u6ca1\u6709\u62fc\u63a5\u8fd9\u4e00\u6b65,\u53ef\u4ee5\u5220\u53bb\n    updated_query = torch.cat((query_reshape, concat_memory), dim=1)  # (b X h X w) X 2d\n    # \u5c06\u68c0\u7d22\u7279\u5f81\u5f62\u72b6\u53d8\u4e3a\u4e4b\u524d\u7684\u5f62\u72b6\n    updated_query = updated_query.view(batch_size, h, w, 2*dims)\n    # \u7ef4\u5ea6\u4e5f\u76f8\u5e94\u53d8\u56de\u53bb\n    updated_query = updated_query.permute(0, 3, 1, 2)\n    # \u4f9d\u6b21\u8fd4\u56de\u68c0\u7d22\u7279\u5f81\uff0cp\uff0cq\n    return updated_query, softmax_score_query, softmax_score_memory\n</code></pre> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u6307\u6b63</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e742\u67086\u65e5</p>"},{"location":"domain_adaptive/code/Strong-Weak2/","title":"\u57df\u9002\u5e94\uff1aStrong-Weak","text":""},{"location":"domain_adaptive/code/Strong-Weak2/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aIEEE Conference on Computer Vision and Pattern Recognition 2019 (CVPR, 2019)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttp://openaccess.thecvf.com/content_CVPR_2019/papers/Saito_Strong-Weak_Distribution_Alignment_for_Adaptive_Object_Detection_CVPR_2019_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/VisionLearningGroup/DA_Detection</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b</p> <p>\u6ce8\uff1a\u8fd9\u91cc\u53ea\u5bf9\u57df\u9002\u5e94\u76f8\u5173\u7684\u90e8\u5206\u505a\u4e86\u6ce8\u91ca</p>"},{"location":"domain_adaptive/code/Strong-Weak2/#_2","title":"\u7f51\u7edc\u7ed3\u6784","text":"<pre><code>class _fasterRCNN(nn.Module):\n    \"\"\" faster RCNN \"\"\"\n    def __init__(self, classes, class_agnostic,lc,gc):\n        super(_fasterRCNN, self).__init__()\n        self.classes = classes\n        self.n_classes = len(classes)\n        self.class_agnostic = class_agnostic\n        # loss\n        self.RCNN_loss_cls = 0\n        self.RCNN_loss_bbox = 0\n        self.lc = lc\n        self.gc = gc\n        # define rpn\n        self.RCNN_rpn = _RPN(self.dout_base_model)\n        self.RCNN_proposal_target = _ProposalTargetLayer(self.n_classes)\n        self.RCNN_roi_pool = _RoIPooling(cfg.POOLING_SIZE, cfg.POOLING_SIZE, 1.0/16.0)\n        self.RCNN_roi_align = RoIAlignAvg(cfg.POOLING_SIZE, cfg.POOLING_SIZE, 1.0/16.0)\n\n        self.grid_size = cfg.POOLING_SIZE * 2 if cfg.CROP_RESIZE_WITH_MAX_POOL else cfg.POOLING_SIZE\n        self.RCNN_roi_crop = _RoICrop()\n\n    def forward(self, im_data, im_info, gt_boxes, num_boxes, target=False, eta=1.0):\n        batch_size = im_data.size(0)\n\n        im_info = im_info.data\n        gt_boxes = gt_boxes.data\n        num_boxes = num_boxes.data\n\n        # feed image data to base model to obtain base feature map\n        # \u6570\u636e\u4f20\u5165\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u524d\u534a\u6bb5\uff0c\u5f97\u5230\u6d45\u5c42\u7279\u5f81\n        base_feat1 = self.RCNN_base1(im_data)\n        # self.netD_pixel\u4e0eself.netD\u90fd\u5728resnet_global_local.py\u6587\u4ef6\u91cc\n        # \u5206\u522b\u5bf9\u5e94\u6d45\u5c42\u7279\u5f81\u5bf9\u9f50\u548c\u6df1\u5c42\u7279\u5f81\u5bf9\u9f50\n        # self.lc\u8868\u793a\u52a0\u5165\u4e86\u521d\u7ea7\u5bf9\u9f50\u6a21\u5757\u540e\uff0c\u662f\u5426\u6dfb\u52a0\u4e0a\u4e0b\u6587\u6b63\u5219\u5316\u9879\n        if self.lc:\n            # \u7279\u5f81\u5728\u5bf9\u9f50\u4e4b\u524d\u8981\u5148\u5957\u4e00\u4e2a\u68af\u5ea6\u53cd\u8f6c\u6a21\u5757\uff0c\u5373\u8fd9\u91cc\u7684grad_reverse\n            # d_pixel\u8868\u793a\u4e00\u5f20\u6d45\u5c42\u7279\u5f81\u5bf9\u9f50\u56fe(\u5bf9\u7279\u5f81\u56fe\u4e0a\u5143\u7d20\u9886\u57df\u7684\u9884\u6d4b)\uff0c\u901a\u9053\u6570\u4e3a1\n            # \u5373\u6bcf\u4e2a\u4f4d\u7f6e\u53ea\u751f\u6210\u4e00\u4e2a\u5143\u7d20\uff0c\u8d8b\u5411\u4e8e1\u8868\u793a\u76ee\u6807\u57df\uff0c\u8d8b\u5411\u4e8e0\u8868\u793a\u6e90\u57df\n            d_pixel, _ = self.netD_pixel(grad_reverse(base_feat1, lambd=eta))\n            # print(d_pixel)\n            if not target:\n                # \u5982\u679c\u8be5\u6570\u636e\u4e0d\u662f\u76ee\u6807\u57df\u7684\u6570\u636e\uff0c\u5219\u518d\u5f97\u5230\u7279\u5f81\u5411\u91cf\uff0c\u8fd9\u91cc\u5411\u91cf\u957f\u5ea6\u4e3a128(\u7ecf\u8fc7\u4e86\u4e24\u5c42\u5377\u79ef\u4ee5\u53ca\u4e00\u5c42\u5168\u5c40\u5e73\u5747\u6c60\u5316)\n                # \u4e3a\u4ec0\u4e48\u8981\u5207\u65ad\u68af\u5ea6\uff1f\n                _, feat_pixel = self.netD_pixel(base_feat1.detach())\n        else:\n            # \u5982\u679c\u4e0d\u52a0\u4e0a\u4e0b\u6587\u6b63\u5219\u5316\u9879\u7684\u8bdd\uff0c\u5219\u53ea\u5f97\u7279\u5f81\u5bf9\u9f50\u56fe\u5373\u53ef\n            d_pixel = self.netD_pixel(grad_reverse(base_feat1, lambd=eta))\n        # \u6d45\u5c42\u7279\u5f81\u4f20\u5165\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u540e\u534a\u6bb5\uff0c\u5f97\u5230\u6df1\u5c42\u7279\u5f81\n        base_feat = self.RCNN_base2(base_feat1)\n        # \u662f\u5426\u6dfb\u52a0\u4e0a\u4e0b\u6587\u6b63\u5219\u5316\u5668\n        if self.gc:\n            # domain_p\u4e3a\u4e24\u4e2a\u6570\uff0c\u4e24\u4e2a\u6570\u5206\u522b\u8868\u793a\u56fe\u50cf\u662f\u6e90\u57df\u7684\u7f6e\u4fe1\u5ea6\u548c\u76ee\u6807\u57df\u7684\u7f6e\u4fe1\u5ea6\n            # \u8fd9\u91cc\u4e0e\u6d45\u5c42\u7279\u5f81\u5bf9\u9f50\u4e0d\u540c\uff0c\u8fd9\u91cc\u662f\u4fe9\u6570\uff0c\u6d45\u5c42\u7279\u5f81\u5bf9\u9f50\u8fd4\u56de\u4e00\u5f20\u56fe\n            domain_p, _ = self.netD(grad_reverse(base_feat, lambd=eta))\n            if target:\n                # \u5982\u679c\u662f\u76ee\u6807\u57df\u56fe\u50cf\uff0c\u5219\u53ea\u8fd4\u56de\u4e24\u4e2a\u7279\u5f81\u5bf9\u9f50\u56fe\uff0c\u7528\u4e8e\u8ba1\u7b97\u57df\u5206\u7c7b\u635f\u5931\n                # \u76ee\u6807\u57df\u56fe\u50cf\u65e0\u5750\u6807\uff0c\u56e0\u6b64\u65e0\u6cd5\u8ba1\u7b97faster r-cnn\u635f\u5931\uff0c\u53ea\u80fd\u8ba1\u7b97\u57df\u5206\u7c7b\u635f\u5931\n                return d_pixel, domain_p\n            # \u518d\u5f97\u5230\u7279\u5f81\u5411\u91cf\uff0c\u8fd9\u91cc\u5411\u91cf\u957f\u5ea6\u4e5f\u4e3a128\n            _, feat = self.netD(base_feat.detach())\n        else:\n            # \u5982\u679c\u4e0d\u52a0\u4e0a\u4e0b\u6587\u6b63\u5219\u5316\u5668\u7684\u8bdd\uff0c\u5219\u65e0\u9700\u8ba1\u7b97\u7279\u5f81\u5411\u91cf\n            domain_p = self.netD(grad_reverse(base_feat, lambd=eta))\n            if target:\n                return d_pixel,domain_p\n        # feed base feature map tp RPN to obtain rois\n        # RPN\u6a21\u5757\n        rois, rpn_loss_cls, rpn_loss_bbox = self.RCNN_rpn(base_feat, im_info, gt_boxes, num_boxes)\n\n        # if it is training phrase, then use ground trubut bboxes for refining\n        if self.training:\n            roi_data = self.RCNN_proposal_target(rois, gt_boxes, num_boxes)\n            rois, rois_label, rois_target, rois_inside_ws, rois_outside_ws = roi_data\n\n            rois_label = Variable(rois_label.view(-1).long())\n            rois_target = Variable(rois_target.view(-1, rois_target.size(2)))\n            rois_inside_ws = Variable(rois_inside_ws.view(-1, rois_inside_ws.size(2)))\n            rois_outside_ws = Variable(rois_outside_ws.view(-1, rois_outside_ws.size(2)))\n        else:\n            rois_label = None\n            rois_target = None\n            rois_inside_ws = None\n            rois_outside_ws = None\n            rpn_loss_cls = 0\n            rpn_loss_bbox = 0\n\n        rois = Variable(rois)\n        # do roi pooling based on predicted rois\n        # ROI\u6a21\u5757\n        if cfg.POOLING_MODE == 'crop':\n            # pdb.set_trace()\n            # pooled_feat_anchor = _crop_pool_layer(base_feat, rois.view(-1, 5))\n            grid_xy = _affine_grid_gen(rois.view(-1, 5), base_feat.size()[2:], self.grid_size)\n            grid_yx = torch.stack([grid_xy.data[:,:,:,1], grid_xy.data[:,:,:,0]], 3).contiguous()\n            pooled_feat = self.RCNN_roi_crop(base_feat, Variable(grid_yx).detach())\n            if cfg.CROP_RESIZE_WITH_MAX_POOL:\n                pooled_feat = F.max_pool2d(pooled_feat, 2, 2)\n        elif cfg.POOLING_MODE == 'align':\n            pooled_feat = self.RCNN_roi_align(base_feat, rois.view(-1, 5))\n        elif cfg.POOLING_MODE == 'pool':\n            pooled_feat = self.RCNN_roi_pool(base_feat, rois.view(-1,5))\n\n        # feed pooled features to top model\n        pooled_feat = self._head_to_tail(pooled_feat)\n        # feat_pixel = torch.zeros(feat_pixel.size()).cuda()\n        # \u5982\u679c\u4f7f\u7528\u4e0a\u4e0b\u6587\u6b63\u5219\u5316\u5668\u7684\u8bdd\uff0c\u5219\u9700\u8981\u5c06\u4e09\u4e2a\u7279\u5f81\u5411\u91cf\u8fdb\u884c\u62fc\u63a5\n        if self.lc:\n            feat_pixel = feat_pixel.view(1, -1).repeat(pooled_feat.size(0), 1)\n            pooled_feat = torch.cat((feat_pixel, pooled_feat), 1)\n        if self.gc:\n            feat = feat.view(1, -1).repeat(pooled_feat.size(0), 1)\n            pooled_feat = torch.cat((feat, pooled_feat), 1)\n            # compute bbox offset\n\n        # compute bbox offset\n        # \u9884\u6d4b\u56de\u5f52\u53c2\u6570\n        bbox_pred = self.RCNN_bbox_pred(pooled_feat)\n        if self.training and not self.class_agnostic:\n            bbox_pred_view = bbox_pred.view(bbox_pred.size(0), int(bbox_pred.size(1) / 4), 4)\n            bbox_pred_select = torch.gather(bbox_pred_view, 1, rois_label.view(rois_label.size(0), 1, 1).expand(rois_label.size(0), 1, 4))\n            bbox_pred = bbox_pred_select.squeeze(1)\n\n        # compute object classification probability\n        # \u9884\u6d4b\u7c7b\u522b\n        cls_score = self.RCNN_cls_score(pooled_feat)\n        cls_prob = F.softmax(cls_score, 1)\n\n        RCNN_loss_cls = 0\n        RCNN_loss_bbox = 0\n\n        if self.training:\n            # \u8ba1\u7b97faster rcnn\u635f\u5931\n            # classification loss\n            RCNN_loss_cls = F.cross_entropy(cls_score, rois_label)\n            # bounding box regression L1 loss\n            RCNN_loss_bbox = _smooth_l1_loss(bbox_pred, rois_target, rois_inside_ws, rois_outside_ws)\n\n        cls_prob = cls_prob.view(batch_size, rois.size(1), -1)\n        bbox_pred = bbox_pred.view(batch_size, rois.size(1), -1)\n\n        return rois, cls_prob, bbox_pred, rpn_loss_cls, rpn_loss_bbox, RCNN_loss_cls, RCNN_loss_bbox, rois_label,d_pixel, domain_p\n</code></pre>"},{"location":"domain_adaptive/code/Strong-Weak2/#_3","title":"\u68af\u5ea6\u53cd\u8f6c\u6a21\u5757","text":"<pre><code>class GradReverse(Function):\n    def __init__(self, lambd):\n        self.lambd = lambd\n\n    def forward(self, x):\n        return x.view_as(x)\n\n    def backward(self, grad_output):\n        #pdb.set_trace()\n        # \u5f53\u53cd\u5411\u4f20\u64ad\u4f20\u64ad\u5230\u8fd9\u91cc\u7684\u65f6\u5019\uff0c\u68af\u5ea6\u53d6\u8d1f\u6570\n        return (grad_output * -self.lambd) \n\n\ndef grad_reverse(x, lambd=1.0):\n    return GradReverse(lambd)(x)\n</code></pre>"},{"location":"domain_adaptive/code/Strong-Weak2/#_4","title":"\u5c40\u90e8\u7279\u5f81\u5bf9\u9f50\u6a21\u5757","text":"<p>\u4e00\u7ec4\u7279\u5f81\u56fe\u751f\u6210\u4e00\u5f20\u56fe</p> <pre><code>class netD_pixel(nn.Module):\n\n    def __init__(self, context=False):\n        super(netD_pixel, self).__init__()\n        # \u5b9a\u4e49\u4e09\u5c42\u5377\u79ef\u5c42\uff0c\u8fd9\u91cc\u5377\u79ef\u5c42\u6838\u5747\u4e3a1\uff0c\u4e0e\u6df1\u5c42\u7279\u5f81\u5bf9\u9f50\u4e0d\u540c\n        self.conv1 = nn.Conv2d(256, 256, kernel_size=1, stride=1,\n                  padding=0, bias=False)\n        self.conv2 = nn.Conv2d(256, 128, kernel_size=1, stride=1,\n                               padding=0, bias=False)\n        self.conv3 = nn.Conv2d(128, 1, kernel_size=1, stride=1,\n                               padding=0, bias=False)\n        # \u662f\u5426\u52a0\u5165\u4e0a\u4e0b\u6587\u6b63\u5219\u5316\u5668\n        self.context = context\n        # \u521d\u59cb\u5316\u53c2\u6570\n        self._init_weights()\n\n    def _init_weights(self):\n\n      def normal_init(m, mean, stddev, truncated=False):\n        \"\"\"\n        weight initalizer: truncated normal and random normal.\n        \"\"\"\n        # x is a parameter\n        if truncated:\n          m.weight.data.normal_().fmod_(2).mul_(stddev).add_(mean)  # not a perfect approximation\n        else:\n          m.weight.data.normal_(mean, stddev)\n          #m.bias.data.zero_()\n\n      normal_init(self.conv1, 0, 0.01)\n      normal_init(self.conv2, 0, 0.01)\n      normal_init(self.conv3, 0, 0.01)\n\n    def forward(self, x):\n        # \u524d\u5411\u4f20\u64ad\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        if self.context:\n          # \u76f8\u5f53\u4e8e\u4e00\u4e2a\u5168\u5c40\u5e73\u5747\u6c60\u5316\u64cd\u4f5c\uff0c\u5c06\u7279\u5f81\u56fe\u53d8\u4e3a\u7279\u5f81\u5411\u91cf\n          feat = F.avg_pool2d(x, (x.size(2), x.size(3)))\n          # \u7279\u5f81\u56fe\u518d\u7ecf\u8fc7conv3\uff0c\u53d8\u4e3a\u4e00\u5c42\u56fe\u7247\uff0c\u79f0\u4e3a\u7279\u5f81\u5bf9\u9f50\u56fe\n          x = self.conv3(x)\n          # \u7279\u5f81\u5bf9\u9f50\u56fe\u7ecf\u8fc7sigmoid\u5f52\u4e00\u5316\n          return F.sigmoid(x),feat\n        else:\n          # \u5982\u679c\u4e0d\u5f15\u5165\u4e0a\u4e0b\u6587\u6b63\u5219\u5316\u5668\u7684\u8bdd\uff0c\u5219\u53ea\u8fd4\u56de\u7279\u5f81\u5bf9\u9f50\u56fe\n          x = self.conv3(x)\n          return F.sigmoid(x)\n</code></pre>"},{"location":"domain_adaptive/code/Strong-Weak2/#_5","title":"\u5168\u5c40\u7279\u5f81\u5bf9\u9f50\u6a21\u5757","text":"<p>\u4e00\u7ec4\u7279\u5f81\u751f\u6210\u4e24\u4e2a\u6570\uff0c\u5206\u522b\u4ee3\u8868\u8be5\u56fe\u662f\u6e90\u57df\u7684\u7f6e\u4fe1\u5ea6\u8fd8\u662f\u76ee\u6807\u57df\u7684\u7f6e\u4fe1\u5ea6</p> <pre><code>class netD(nn.Module):\n    def __init__(self,context=False):\n        super(netD, self).__init__()\n        # \u6ce8\u610fconv3x3\u4e3a\u5377\u79ef\u6838\u5c3a\u5bf8\u4e3a3\uff0c\u586b\u5145\u4e3a1\u7684\u5377\u79ef\u64cd\u4f5c\n        # \u8fd9\u91cc\u5b9a\u4e49\u4e86\u4e09\u5c42\u5377\u79ef\uff0c\u5377\u79ef\u6b65\u5e45\u8bbe\u7f6e\u4e3a2\n        # \u5e76\u4e14\u4f9d\u6b21\u5b9a\u4e49\u4e09\u5c42\u6807\u51c6\u5316\u5c42\n        self.conv1 = conv3x3(1024, 512, stride=2)\n        self.bn1 = nn.BatchNorm2d(512)\n        self.conv2 = conv3x3(512, 128, stride=2)\n        self.bn2 = nn.BatchNorm2d(128)\n        self.conv3 = conv3x3(128, 128, stride=2)\n        self.bn3 = nn.BatchNorm2d(128)\n        # \u5b9a\u4e49\u4e00\u5c42\u5168\u8fde\u63a5\u5c42\uff0c\u56de\u5f52\u51fa\u4e24\u4e2a\u6570\uff0c\u5206\u522b\u4ee3\u8868\u8be5\u56fe\u662f\u6e90\u57df\u7684\u7f6e\u4fe1\u5ea6\u8fd8\u662f\u76ee\u6807\u57df\u7684\u7f6e\u4fe1\u5ea6\n        self.fc = nn.Linear(128,2)\n        self.context = context\n        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n\n    def forward(self, x):\n        # \u4f9d\u6b21\u7ecf\u8fc7\u5377\u79ef\u3001\u6807\u51c6\u5316\u3001relu\u3001dropout\n        x = F.dropout(F.relu(self.bn1(self.conv1(x))),training=self.training)\n        x = F.dropout(F.relu(self.bn2(self.conv2(x))),training=self.training)\n        x = F.dropout(F.relu(self.bn3(self.conv3(x))),training=self.training)\n        # \u7ecf\u8fc7\u5168\u5c40\u5e73\u5747\u6c60\u5316\uff0c\u65b9\u4fbf\u540e\u7eed\u4f20\u5165\u5168\u8fde\u63a5\u5c42\n        x = F.avg_pool2d(x, (x.size(2),x.size(3)))\n        x = x.view(-1,128)\n        if self.context:\n          # \u5982\u679c\u6dfb\u52a0\u4e0a\u4e0b\u6587\u6b63\u5219\u5316\u5668\u7684\u8bdd\uff0c\u5219\u4fdd\u5b58\u6b64\u65f6\u7684\u7279\u5f81\u5411\u91cf\n          feat = x\n        x = self.fc(x)\n        if self.context:\n          return x,feat\n        else:\n          return x\n</code></pre> <p>conv3x3\u6a21\u5757</p> <pre><code>def conv3x3(in_planes, out_planes, stride=1):\n  \"3x3 convolution with padding\"\n  return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n           padding=1, bias=False)\n</code></pre>"},{"location":"domain_adaptive/code/Strong-Weak2/#_6","title":"\u8ba1\u7b97\u57df\u5206\u7c7b\u5668\u635f\u5931","text":"<pre><code># domain label\n# \u5982\u679c\u662f\u76ee\u6807\u57df\u7684\u8bdd\uff0c\u53ea\u9700\u8981\u5c06zeros\u6539\u4e3aones\u5373\u53ef\uff0c\u5373\u6807\u7b7e\u4e3a1\ndomain_s = Variable(torch.zeros(out_d.size(0)).long().cuda())\n# \u8ba1\u7b97\u5f3a\u5f31\u635f\u5931\n# global alignment loss\n# out_d\u8868\u793a\u6df1\u5c42\u7279\u5f81\u8f93\u51fa\u7684\u4e24\u4e2a\u9886\u57df\u7f6e\u4fe1\u5ea6\ndloss_s = 0.5 * FL(out_d, domain_s)\n# local alignment loss\n# out_d_pixel\u8868\u793a\u6d45\u5c42\u7279\u5f81\u5bf9\u9f50\u56fe\ndloss_s_p = 0.5 * torch.mean(out_d_pixel ** 2)\n</code></pre>"},{"location":"domain_adaptive/code/Strong-Weak2/#fl","title":"FL\u635f\u5931","text":"<pre><code>class FocalLoss(nn.Module):\n    r\"\"\"\n        This criterion is a implemenation of Focal Loss, which is proposed in\n        Focal Loss for Dense Object Detection.\n\n            Loss(x, class) = - \\alpha (1-softmax(x)[class])^gamma \\log(softmax(x)[class])\n\n        The losses are averaged across observations for each minibatch.\n        Args:\n            alpha(1D Tensor, Variable) : the scalar factor for this criterion\n            gamma(float, double) : gamma &gt; 0; reduces the relative loss for well-classi\ufb01ed examples (p &gt; .5),\n                                   putting more focus on hard, misclassi\ufb01ed examples\n            size_average(bool): size_average(bool): By default, the losses are averaged over observations for each minibatch.\n                                However, if the field size_average is set to False, the losses are\n                                instead summed for each minibatch.\n    \"\"\"\n\n    def __init__(self, class_num, alpha=None, gamma=2, size_average=True, sigmoid=False, reduce=True):\n        super(FocalLoss, self).__init__()\n        if alpha is None:\n            # alpha\u9ed8\u8ba4\u8bbe\u7f6e\u4e3a1\n            self.alpha = Variable(torch.ones(class_num, 1) * 1.0)\n        else:\n            if isinstance(alpha, Variable):\n                self.alpha = alpha\n            else:\n                self.alpha = Variable(alpha)\n        # self.gamma\u8868\u793aFL\u51fd\u6570\u4e2d\u7684\u03b3\uff0c\u5373\u6307\u6570\n        self.gamma = gamma\n        self.class_num = class_num\n        # \u662f\u5426\u53d6\u5747\u503c\n        self.size_average = size_average\n        # \u5f52\u4e00\u5316\u7b56\u7565\n        self.sigmoid = sigmoid\n        self.reduce = reduce\n\n    def forward(self, inputs, targets):\n        # batch\u6570\u91cf\n        N = inputs.size(0)\n        C = inputs.size(1)\n        if self.sigmoid:\n            # \u5c06\u8f93\u51fa\u7684\u7f6e\u4fe1\u5ea6\u7ecf\u8fc7sigmoid\u5f52\u4e00\u5316\u64cd\u4f5c\n            P = F.sigmoid(inputs)\n            # \u5982\u679c\u662f\u6e90\u57df\u6570\u636e\n            if targets == 0:\n                # \u6e90\u57df\u6570\u636ep_t=1-p\uff0c\u8fd9\u91ccprobs\u8868\u793a\u8bba\u6587\u4e2d\u7684p_t\n                probs = 1 - P\n                log_p = probs.log()\n                # \u8ba1\u7b97\u6e90\u57df\u4e2d\u7684FL\u635f\u5931\uff0c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f(5)\n                batch_loss = - (torch.pow((1 - probs), self.gamma)) * log_p\n            # \u5982\u679c\u662f\u76ee\u6807\u57df\u6570\u636e\n            if targets == 1:\n                # \u76ee\u6807\u57df\u4e2d\uff0cp_t=p\n                probs = P\n                log_p = probs.log()\n                # \u8ba1\u7b97\u76ee\u6807\u57df\u4e2d\u7684FL\u635f\u5931\uff0c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f(6)\n                batch_loss = - (torch.pow((1 - probs), self.gamma)) * log_p\n        else:\n            # softmax\u5f52\u4e00\u5316\u7b56\u7565\uff0c\u7ecf\u8fc7softmax\u5f52\u4e00\u5316\u4e4b\u540e\uff0c\u4e24\u4e2a\u503c\u548c\u4e3a1\uff0c\u771f\u6b63\u610f\u4e49\u4e0a\u53d8\u4e3a\u6982\u7387\n            # \u56e0\u6b64p_t\u7b49\u4e8e\u5bf9\u5e94\u4f4d\u7f6e\u4e0a\u7684\u6570\u503c\uff0c\u7701\u53bb\u4e861-p\u8fd9\u4e00\u6b65\u9aa4\n            P = F.softmax(inputs)\n            # \u521b\u5efa\u4e00\u4e2a\u4e0einputs\u5c3a\u5bf8\u76f8\u540c\u7684\u5168\u96f6\u6570\u7ec4\n            class_mask = inputs.data.new(N, C).fill_(0)\n            # \u53d8\u4e3a\u5f20\u91cf\uff0c\u53ef\u5bfc\n            class_mask = Variable(class_mask)\n            # \u6807\u7b7e\u62c9\u4f38\n            ids = targets.view(-1, 1)\n            # \u6cbf\u7b2c\u4e00\u7ef4\u5ea6\u5bf9\u53d8\u91cfclass_mask\u7d22\u5f15\uff0c\u5c06\u6807\u7b7e\u4f4d\u7f6e\u7684\u5143\u7d20\u8bbe\u7f6e\u4e3a1\n            # \u5982\u679c\u662f\u6e90\u57df\u56fe\u50cf\uff0c\u6807\u7b7e\u4e3a0\uff0c\u5219\u5c06\u7b2c\u4e00\u5217\u5143\u7d20\u8bbe\u7f6e\u4e3a1\n            class_mask.scatter_(1, ids.data, 1.)\n\n            if inputs.is_cuda and not self.alpha.is_cuda:\n                self.alpha = self.alpha.cuda()\n            alpha = self.alpha[ids.data.view(-1)]\n            # P * class_mask\u8868\u793a\u63d0\u53d6\u671f\u671b\u7684\u9884\u6d4b\u503c\uff0c\u5373\u5982\u679c\u6807\u7b7e\u4e3a\u6e90\u57df\uff0c\u5219\u63d0\u53d6\u6e90\u57df\u9884\u6d4b\u7684\u7f6e\u4fe1\u5ea6\n            # \u4e4b\u540e\u5728\u7b2c\u4e00\u7ef4\u5ea6\u6c42\u548c\uff0c\u62c9\u4f38\uff0c\u5f97\u5230p_t\n            # \u5982\u679c\u53ea\u9884\u6d4b\u4e86\u4e00\u79cd\u6df1\u5c42\u7279\u5f81\uff0c\u5219\u53ef\u7701\u7565\u6c42\u548c\u8fd9\u4e00\u6b65\n            probs = (P * class_mask).sum(1).view(-1, 1)\n            # \u6c42\u5bf9\u6570\n            log_p = probs.log()\n            # \u6c42FL\u635f\u5931\uff0c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f(4)\n            batch_loss = -alpha * (torch.pow((1 - probs), self.gamma)) * log_p\n\n        if not self.reduce:\n            return batch_loss\n        # \u8fd4\u56de\u5e73\u5747\u635f\u5931\u6216\u6c42\u548c\u635f\u5931\n        if self.size_average:\n            loss = batch_loss.mean()\n        else:\n            loss = batch_loss.sum()\n        return loss\n</code></pre> <p>\u6ce8\uff1a\u4ee5\u4e0a\u5185\u5bb9\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c2\u70b9\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u5927\u5bb6\u6279\u8bc4\u6307\u6b63</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e741\u670827\u65e5</p>"},{"location":"domain_adaptive/paper/ATF1/","title":"\u57df\u9002\u5e94\uff1aATF","text":""},{"location":"domain_adaptive/paper/ATF1/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aEuropean Conference on Computer Vision 2020 (ECCV 20)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123690307.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/He-Zhenwei/ATF</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b</p>"},{"location":"domain_adaptive/paper/ATF1/#_2","title":"\u4e3b\u8981\u601d\u60f3","text":"<p>\u2003\u2003\u968f\u7740\u65e0\u76d1\u7763\u9886\u57df\u81ea\u9002\u5e94\u6280\u672f\u7684\u53d1\u5c55\uff0c\u901a\u8fc7\u5c06\u77e5\u8bc6\u4ece\u8bed\u4e49\u76f8\u5173\u7684\u6e90\u57df\u8fc1\u79fb\u5230\u76ee\u6807\u57df\u6765\u51cf\u8f7b\u9886\u57df\u504f\u79fb\u95ee\u9898\u6210\u4e3a\u4e86\u53ef\u80fd\uff0c\u76ee\u524d\u5927\u591a\u6570\u8de8\u57df\u6a21\u578b\u90fd\u662f\u4f7f\u7528\u8fc1\u79fb\u5b66\u4e60\u7684\u601d\u60f3\u6765\u5b66\u4e60\u9886\u57df\u4e0d\u53d8\u7684\u7279\u5f81(domain invariant features)\uff0c\u5373\u5bf9\u4e8e\u4e0d\u540c\u9886\u57df\u7684\u56fe\u7247\uff0c\u8ba9\u7279\u5f81\u63d0\u53d6\u5668\u5f97\u5230\u57df\u4e0d\u53d8\u7684\u7279\u5f81\u8868\u793a\uff0c\u8fdb\u4e00\u6b65\u4f7f\u6e90\u57df\u6570\u636e\u548c\u76ee\u6807\u57df\u6570\u636e\u4ea7\u751f\u8db3\u591f\u7684\u6df7\u6dc6\uff0c\u4ece\u800c\u8ba9\u68c0\u6d4b\u5668\u5177\u6709\u57df\u4e0d\u53d8\u7684\u7279\u6027\u3002\u4f46\u5f3a\u5236\u4f7f\u7279\u5f81\u5177\u6709\u57df\u4e0d\u53d8\u7684\u7279\u6027\u4f1a\u4e0d\u53ef\u907f\u514d\u5730\u626d\u66f2\u539f\u59cb\u6570\u636e\u7684\u7279\u5f81\u5206\u5e03\uff0c\u4ece\u800c\u7834\u574f\u4e24\u4e2a\u9886\u57df\u4e4b\u95f4\u7684\u7ed3\u6784\u6027\u533a\u522b\u7279\u5f81(structural discrimination)\uff08\u7c7b\u5185\u7d27\u5bc6\u6027(compactness)\u548c\u7c7b\u95f4\u53ef\u533a\u5206\u6027(separability)\uff09\u3002</p> <p>\u2003\u2003\u4e0a\u8ff0\u7c7b\u4f3c\u7684\u95ee\u9898\u540c\u6837\u53d1\u751f\u5728\u8de8\u57df\u76ee\u6807\u68c0\u6d4b\u4e2d\uff0c\u6a21\u578b\u7684\u8bad\u7ec3\u53ea\u80fd\u4f9d\u9760\u5177\u6709\u6807\u7b7e\u7684\u6e90\u57df\u6570\u636e\u548c\u4e0d\u5177\u6709\u6807\u7b7e\u7684\u76ee\u6807\u57df\u6570\u636e\uff0c\u56e0\u6b64\u6240\u5b66\u7684\u6e90\u57df\u7279\u5f81\u5177\u6709\u533a\u522b\u6027\u548c\u53ef\u9760\u6027\uff0c\u800c\u76ee\u6807\u57df\u7684\u7279\u5f81\u5e38\u5e38\u662f\u8106\u5f31\u5e76\u4e14\u4e0d\u53ef\u9760\u7684\u3002\u5927\u591a\u6570\u73b0\u6709\u7684\u6a21\u578b\uff08\u5982DA Faster\u3001SW Faster\uff09\u9ed8\u8ba4\u6e90\u57df\u6570\u636e\u548c\u76ee\u6807\u57df\u6570\u636e\u7684\u8bad\u7ec3\u5171\u4eab\u540c\u4e00\u4e2a\u7f51\u7edc\uff0c\u4f46\u662f\u5f3a\u5236\u5c06\u53ef\u9760\u7684\u6e90\u57df\u7279\u5f81\u5411\u4e0d\u53ef\u9760\u7684\u76ee\u6807\u57df\u7279\u5f81\u8fdb\u884c\u5bf9\u9f50\u53ef\u80fd\u4f1a\u589e\u52a0\u6e90\u57df\u7279\u5f81\u5d29\u6e83\u7684\u98ce\u9669\uff0c\u5e76\u4e14\u6700\u7ec8\u6076\u5316\u6a21\u578b\u5bf9\u56fe\u7247\u7ed3\u6784\u6027\u533a\u522b\u7279\u5f81\u7684\u63d0\u53d6\u80fd\u529b\uff0c\u8fdb\u4e00\u6b65\u5f71\u54cd\u68c0\u6d4b\u5668\u7684\u9884\u6d4b\uff0c\u6362\u53e5\u8bdd\u8bf4\u5f53\u53ea\u7528\u5e26\u6709\u6807\u7b7e\u7684\u6e90\u57df\u8bad\u7ec3\u7f51\u7edc\u65f6\uff0c\u7f51\u7edc\u5728\u6807\u7b7e\u7684\u76d1\u7763\u4e0b\uff0c\u53ef\u4ee5\u63d0\u53d6\u6e90\u57df\u6570\u636e\u533a\u522b\u6027\u660e\u663e\u7684\u7279\u5f81\uff0c\u4f46\u5f53\u5f15\u5165\u65e0\u6807\u7b7e\u7684\u76ee\u6807\u57df\u6570\u636e\u65f6\uff0c\u4e3a\u4e86\u964d\u4f4e\u76ee\u6807\u57df\u6570\u636e\u7684\u57df\u5206\u7c7b\u635f\u5931\uff0c\u6a21\u578b\u53ef\u80fd\u4f1a\u4ee5\u727a\u7272\u63d0\u53d6\u6e90\u57df\u6570\u636e\u7279\u5f81\u7684\u80fd\u529b\u4e3a\u4ee3\u4ef7\uff0c\u4ece\u800c\u6df7\u6dc6\u6a21\u578b\u5bf9\u6e90\u57df\u6570\u636e\u7684\u68c0\u6d4b\u3002\u57df\u9002\u5e94\u7406\u8bba(\u8bba\u6587\u94fe\u63a5)\u8868\u660e\uff0c\u76ee\u6807\u57df\u7684\u98ce\u9669\\epsilon_T(h)\u7684\u4e0a\u9650\u7531\u6e90\u57df\u98ce\u9669\\epsilon_S(h)\u3001\u9886\u57df\u5dee\u5f02d_A\u4ee5\u53ca\u4e24\u4e2a\u57df\u7406\u60f3\u53c2\u6570h^*\u4e4b\u95f4\u7684\u5171\u4eab\u8bef\u5dee\\lambda=\\epsilon_T(h^*)+\\epsilon_S(h^*)\u6784\u6210\uff0c\u4ee5\u5f80\u7684\u7b97\u6cd5\u5927\u591a\u4e13\u6ce8\u4e8e\u964d\u4f4ed_A\u6765\u63d0\u5347\u6a21\u578b\u5728\u76ee\u6807\u57df\u7684\u68c0\u6d4b\u6027\u80fd\uff0c\u5ffd\u7565\u4e86\u6e90\u98ce\u9669\\epsilon_S(h)\u589e\u52a0\u5f15\u8d77\u7684\u8d1f\u9762\u5f71\u54cd\u3002\u7efc\u4e0a\u6709\u6548\u5730\u63a7\u5236\u6e90\u98ce\u9669\\epsilon_S(h)\uff0c\u907f\u514d\u6e90\u57df\u7279\u5f81\u5d29\u6e83\u5bf9\u4e8e\u57df\u81ea\u9002\u5e94\u68c0\u6d4b\u5668\u6027\u80fd\u7684\u63d0\u5347\u5c24\u4e3a\u91cd\u8981\u3002</p> <p>\u2003\u2003\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e0d\u5bf9\u79f0\u7684\u4e09\u8def\u7ed3\u6784(Asymmetric Tri-way structure)\uff0c\u7528\u4e8e\u589e\u5f3aFaster RCNN\u7684\u53ef\u8f6c\u79fb\u6027\uff0c\u56e0\u6b64\u53c8\u53ebATF\u7ed3\u6784\u3002\u8be5\u6a21\u578b\u4e3b\u8981\u7531\u4e24\u4e2a\u6a21\u5757\u6784\u6210\u2014\u2014\u4e3b\u7f51\u7edc\u548c\u8f85\u52a9\u7f51\u7edc\u3002\u8f85\u52a9\u7f51\u7edc\u4ec5\u7531\u5e26\u6709\u6807\u7b7e\u7684\u6e90\u57df\u6570\u636e\u8bad\u7ec3\uff0c\u5e76\u4e14\u548c\u4e3b\u7f51\u7edc\u53c2\u6570\u72ec\u7acb\uff0c\u56e0\u6b64\u8fd9\u79cd\u4e0d\u5bf9\u79f0\u6027\u53ef\u4ee5\u5f88\u5927\u7a0b\u5ea6\u4e0a\u907f\u514d\u6e90\u5d29\u6e83\u548c\u9886\u57df\u8f6c\u79fb\u65f6\u7684\u7279\u5f81\u5931\u771f\u3002\u4f5c\u8005\u7684\u6a21\u578b\u503e\u5411\u4e8e\u4fdd\u7559\u6e90\u57df\u7279\u5f81\u7684\u533a\u5206\u6027\uff0c\u540c\u65f6\u5f15\u5bfc\u76ee\u6807\u7279\u5f81\u7684\u7ed3\u6784\u8f6c\u79fb\u3002</p> <p> <p></p> <p></p>"},{"location":"domain_adaptive/paper/ATF1/#_3","title":"\u65b9\u6cd5","text":"<p>\u2003\u2003\u4e3a\u4e86\u65b9\u4fbf\u8d77\u89c1\uff0c\u5c06\u5e26\u6709\u6807\u7b7e\u7684\u6e90\u57df\u6570\u636e\u8868\u793a\u4e3aD_s=\\{(x^s_i,b^s_i,y^s_I)\\}^{n_S}_i\uff0c\u5176\u4e2dx_i^s\u8868\u793a\u56fe\u7247\uff0cb_i^s\u8868\u793a\u5bf9\u5e94\u7684\u8fb9\u754c\u6846\u4fe1\u606f\uff0cy^s_i\u8868\u793a\u7c7b\u522b\u6807\u7b7e\uff0cn_s\u8868\u793a\u6837\u672c\u6570\u91cf\uff1b\u6ca1\u6709\u6807\u7b7e\u7684\u76ee\u6807\u57df\u6570\u636e\u8868\u793a\u4e3aD_t=\\{(x_i^t)\\}_i^{n_t}\uff0c\u5176\u4e2dn_t\u8868\u793a\u6837\u672c\u7684\u6570\u91cf\u3002\u4efb\u52a1\u603b\u4f53\u76ee\u6807\u4e3a\u5c06\u8bed\u4e49\u77e5\u8bc6\u4eceD_s\u8f6c\u79fb\u5230D_t\uff0c\u4ece\u800c\u4f7f\u6a21\u578b\u53ef\u4ee5\u6210\u529f\u5730\u68c0\u6d4b\u6e90\u57df\u6570\u636e\u3002</p>"},{"location":"domain_adaptive/paper/ATF1/#_4","title":"\u7f51\u7edc\u7ed3\u6784","text":"<p>\u2003\u2003ATF\u6a21\u578b\u4e3b\u8981\u57fa\u4e8eFaster RCNN\u68c0\u6d4b\u6846\u67b6\uff0c\u5177\u4f53\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u56fe\u7247\u4f20\u5165\u7f51\u7edc\u65f6\u9996\u5148\u7ecf\u8fc7\u4e24\u4e2a\u5377\u79ef\u5757\uff0c\u4e4b\u540e\u4f1a\u6709\u4e09\u4e2a\u5206\u652f\uff0c\u524d\u4e24\u4e2a\u6a59\u8272\u5206\u652f\u79f0\u4e3a\u4e3b\u7f51\u7edc\uff0c\u5e76\u4e14\u4e24\u4e2a\u5206\u652f\u5171\u4eab\u540c\u4e00\u7ec4\u53c2\u6570\u3002\u4ece\u6e90\u57df\u6570\u636e\u548c\u76ee\u6807\u57df\u6570\u636e\u5f97\u5230\u7684\u7279\u5f81\u4f9d\u6b21\u4f20\u5165\u524d\u4e24\u4e2a\u5206\u652f\u3002\u7b2c\u4e09\u4e2a\u84dd\u8272\u7684\u5206\u652f\u79f0\u4e3a\u8f85\u52a9\u7f51\u7edc\uff0c\u53c2\u6570\u4e0e\u4e3b\u7f51\u7edc\u7684\u53c2\u6570\u76f8\u4e92\u72ec\u7acb\uff0c\u53ea\u5728\u8bad\u7ec3\u9636\u6bb5\u5c06\u6e90\u57df\u6570\u636e\u5f97\u5230\u7684\u7279\u5f81\u4f20\u5165\u8f85\u52a9\u7f51\u7edc\u3002\u7f51\u7edc\u7ed3\u6784\u4e2d\u4e09\u4e2a\u5206\u652f\u5171\u540c\u4f7f\u7528\u540c\u4e00\u4e2aRPN\u6a21\u5757\uff0c\u4e4b\u540e\u5c06\u5f97\u5230\u7684\u63d0\u8bae\u533a\u57df(proposals)\u4f20\u5165ROI Align\u5c42\u6765\u6c47\u96c6\u6240\u6709\u7684\u7279\u5f81\uff0c\u6700\u540e\u518d\u6839\u636e\u6240\u5f97\u7684\u7279\u5f81\u5f97\u5230\u68c0\u6d4b\u7ed3\u679c\u3002</p> <p>\u2003\u2003\u4e0e\u4f20\u7edf\u7684\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u4e00\u6837\uff0c\u5728\u8bad\u7ec3\u9636\u6bb5\u8fd8\u5f15\u5165\u4e86\u5bf9\u6297\u5b66\u4e60\u7b56\u7565\uff0c\u901a\u8fc7\u5728\u4e3b\u7f51\u548c\u8f85\u52a9\u7f51\u7edc\u4e4b\u95f4\u5efa\u7acb\u57df\u5206\u7c7b\u5668\u6765\u5bf9\u9f50\u9886\u57df\u4e4b\u95f4\u7684\u7279\u5f81\u5206\u5e03\uff0c\u4ece\u800c\u63d0\u9ad8\u6a21\u578b\u7684\u57df\u9002\u5e94\u80fd\u529b\u3002\u7f51\u7edc\u6574\u4f53\u635f\u5931\u7531\u4e24\u90e8\u5206\u6784\u6210\uff1a\u2460\u4e3b\u7f51\u76ee\u6807\u57df\u5206\u652f\u4ee5\u53ca\u8f85\u52a9\u7f51\u7edc\u4e2d\u7684\u9886\u57df\u5bf9\u6297\u6df7\u6dc6\u635f\u5931(Dac)\uff0c\u5229\u7528\u9886\u57df\u6807\u7b7e\u76d1\u7763\uff0c\u7528\u4e8e\u7ea6\u675f\u9886\u57df\u5dee\u5f02d_A\uff1b\u2461\u4e3b\u7f51\u6e90\u57df\u5206\u652f\u4ee5\u53ca\u8f85\u52a9\u7f51\u7edc\u4e2d\u7684\u68c0\u6d4b\u635f\u5931(Det)\uff0c\u5229\u7528\u6e90\u57df\u56fe\u50cf\u8fb9\u754c\u6846\u6807\u7b7e\u76d1\u7763\uff0c\u7528\u4e8e\u7ea6\u675f\u6e90\u57df\u98ce\u9669\\epsilon_S(h)\u3002</p>"},{"location":"domain_adaptive/paper/ATF1/#_5","title":"\u4e3b\u7f51\u539f\u7406","text":"<p>\u2003\u2003\u9886\u57df\u5dee\u5f02\u662f\u5bfc\u81f4\u8de8\u57df\u76ee\u6807\u68c0\u6d4b\u5668\u6027\u80fd\u4e0b\u964d\u7684\u9996\u8981\u56e0\u7d20\uff0c\u548c\u4ee5\u5f80\u7684\u7b97\u6cd5\u7c7b\u4f3c\uff0c\u4e3a\u4e86\u964d\u4f4e\u5dee\u5f02d_A\uff0c\u4f5c\u8005\u5f15\u5165\u4e86\u9886\u57df\u5bf9\u6297\u6df7\u6dc6\u673a\u5236\uff0c\u5728\u4e3b\u7f51\u7edc(\u76ee\u6807\u77e5\u8bc6)\u548c\u8f85\u52a9\u7f51\u7edc(\u6e90\u77e5\u8bc6)\u4e4b\u95f4\u67b6\u8d77\u4e00\u5ea7\u6865\u6881\u3002\u4e3a\u4e86\u8ba9\u8f85\u52a9\u7f51\u7edc\u4e2d\u7684\u7279\u5f81\u5206\u5e03\u548c\u4e3b\u7f51\u7edc\u4e2d\u76ee\u6807\u57df\u5206\u652f\u7684\u7279\u5f81\u5206\u5e03\u7c7b\u4f3c\uff0c\u4f5c\u8005\u5f15\u5165\u4e86\u56fe\u50cf\u7ea7\u7279\u5f81\u5bf9\u9f50\uff08\u5168\u5c40\uff09\u548c\u5b9e\u4f8b\u7ea7\u7279\u5f81\u5bf9\u9f50\uff08\u5c40\u90e8\uff09\uff0c\u8fd9\u91cc\u4e0eDA Faster\u4e2d\u7c7b\u4f3c\u3002</p> <p> \u5168\u5c40\u9886\u57df\u5bf9\u9f50\uff1a\u5168\u5c40\u5bf9\u9f50\u5728\u7f51\u7edc\u4e2d\u6307\u5bfc\u4f4e\u6c34\u5e73\u5377\u79ef\u5757\u4e0a\u7684\u7279\u5f81\u5bf9\u9f50\uff0c\u5047\u8bbe\u4e3b\u7f51\u7edc\u548c\u8f85\u52a9\u7f51\u7edc\u4e2d\u7b2ck^{th}\u4e2a\u5377\u79ef\u5757\u4f9d\u6b21\u8868\u793a\u4e3aF_c(x^t_i,\\theta^k_c)\u548cF_a(x^s_i,\\theta^k_a)\uff0c\u5176\u4e2d\\theta^k_c\u548c\\theta^k_a\u8868\u793a\u5bf9\u5e94\u5377\u79ef\u5757\u7684\u53c2\u6570\uff0c\u5047\u8bbe\u4e8c\u5143\u9886\u57df\u6807\u7b7e\u8868\u793a\u4e3ad\uff0c\u5bf9\u4e8e\u6e90\u4e8e\u6570\u636ed=1\uff0c\u5bf9\u4e8e\u76ee\u6807\u57df\u6570\u636ed=0\uff0c\u7b2ck\u4e2a\u5377\u79ef\u5757\u7684\u5168\u5c40\u9886\u57df\u5bf9\u9f50\u635f\u5931\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ \\mathcal L^k_{G-Dac}=-\\sum_{u,v}((1-d)\\log{(D_k(F_c(x^t_i,\\theta^k_c)^{(u,v)},\\theta^k_d))}+d\\log{(D_k(F_a(x^s_i,\\theta^k_a)^{(u,v)},\\theta^k_d))}) $$  \u5176\u4e2d(u,v)\u8868\u793a\u7279\u5f81\u56fe\u4e0a\u76f8\u5e94\u7684\u5143\u7d20\uff0cD_k\u8868\u793a\u7b2ck\u4e2a\u5377\u79ef\u5757\u7684\u9886\u57df\u5224\u522b\u5668\uff0c\\theta^k_d\u8868\u793a\u76f8\u5e94\u5224\u522b\u5668\u7684\u53c2\u6570\u3002\u548c\u73b0\u6709\u7684\u7b97\u6cd5\u4e00\u6837\uff0c\u8ba9\u5224\u522b\u5668D\u8bd5\u56fe\u6700\u5c0f\u5316\u8be5\u635f\u5931\uff0c\u4e4b\u540e\u5229\u7528\u68af\u5ea6\u53cd\u8f6c\u5c42(GRL)\uff0c\u8ba9\u4e3b\u7f51\u7edcF_c\u548c\u8f85\u52a9\u7f51\u7edcF_a\u6700\u5927\u5316\u8be5\u635f\u5931\uff0c\u5b9e\u9a8c\u4e2d\u7f51\u7edc\u8ba9\u540e\u4e09\u4e2a\u5377\u79ef\u5757\u5747\u5d4c\u5165\u5168\u5c40\u9886\u57df\u5bf9\u9f50\u6a21\u5757\u3002</p> <p> \u5c40\u90e8\u9886\u57df\u5bf9\u9f50\uff1a\u4e3a\u4e86\u8fdb\u4e00\u6b65\u5bf9\u9f50\u5c40\u90e8\u5b9e\u4f8b\u7ea7\u8de8\u57df\u7279\u5f81\uff0c\u4f5c\u8005\u53c8\u5f15\u5165\u4e86\u5b9e\u4f8b\u7ea7\u9886\u57df\u5224\u522b\u5668\u3002\u7ecf\u8fc7ROI-Align\u6c47\u96c6\u7684\u7279\u5f81\u4ee3\u8868\u56fe\u50cf\u7684\u5c40\u90e8\u90e8\u5206\uff0c\u5305\u62ec\u524d\u666f\u4e0e\u80cc\u666f\uff0c\u5047\u8bbe\u8f85\u52a9\u7f51\u7edc\u7684Pooling\u7279\u5f81\u8868\u793a\u4e3af_a\uff0c\u4e3b\u7f51\u7edc\u7684\u7279\u5f81\u8868\u793a\u4e3af_c\uff0c\u5c40\u90e8\u9886\u57df\u5bf9\u9f50\u635f\u5931\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ \\mathcal L_{L-Dac}=-\\frac1N\\sum_{n}((1-d)\\log{(D_l(F_l(f^n_c,\\theta_f),\\theta_d))}+d\\log{(D_l(F_l(f_a^n,\\theta_f),\\theta_d))}) $$  \u5176\u4e2dD_l\u8868\u793a\u4e3a\u5c40\u90e8\u9886\u57df\u5224\u522b\u5668\uff0cF_l\u8868\u793a\u4e3a\u5c40\u90e8\u4e3b\u5e72\u7f51\u7edc\uff08\u5bf9\u5e94\u4e3b\u5e72\u7f51\u7edc\u7684\u6700\u540e\u4e00\u4e2a\u9636\u6bb5\uff09\uff0c\\theta_l\u548c\\theta_d\u4f9d\u6b21\u8868\u793a\u4e3a\u4e3b\u5e72\u7f51\u7edc\u548c\u5224\u522b\u5668\u7684\u53c2\u6570\uff0c\u548c\u5168\u5c40\u9886\u57df\u5bf9\u9f50\u4e00\u6837\uff0c\u4f7f\u7528\u68af\u5ea6\u53cd\u8f6c\u5c42\u6765\u5b9e\u73b0\u4e3b\u5e72\u7f51\u7edc\u548c\u57df\u5224\u522b\u5668\u7684\u5bf9\u6297\u8bad\u7ec3\u3002</p>"},{"location":"domain_adaptive/paper/ATF1/#_6","title":"\u8f85\u52a9\u7f51\u7edc\u539f\u7406","text":"<p>\u2003\u2003\u5982\u4e0a\u6587\u6240\u8ba8\u8bba\uff0c\u8bbe\u7acb\u8f85\u52a9\u7f51\u7edc\u6700\u4e3b\u8981\u7684\u76ee\u7684\u5c31\u662f\u8fdb\u4e00\u6b65\u7ea6\u675f\u6e90\u57df\u98ce\u9669\\epsilon_S\u3002\u7531\u4e8e\u6e90\u57df\u4e2d\u6bcf\u4e2a\u56fe\u7247\u90fd\u6709\u5bf9\u5e94\u7684\u5bf9\u8c61\u7c7b\u522b\u548c\u8fb9\u754c\u6846\u4fe1\u606f\u6807\u7b7e\uff0c\u56e0\u6b64\u5355\u72ec\u8bad\u7ec3\u6e90\u57df\u6570\u636e\u7684\u8bdd\uff0c\u6e90\u57df\u98ce\u9669\\epsilon_S\u53ef\u4ee5\u964d\u5230\u6700\u4f4e\uff08\u53d7\u5230\u5206\u7c7b\u635f\u5931\u548c\u56de\u5f52\u635f\u5931\u7684\u7ea6\u675f\uff09\uff0c\u4f46\u76ee\u6807\u57df\u6570\u636e\u6ca1\u6709\u6807\u7b7e\u4fe1\u606f\u6765\u7ea6\u675f\uff0c\u800c\u4e3b\u7f51\u7edc\u4e2d\u4e24\u4e2a\u5206\u652f\u7684\u53c2\u6570\u662f\u5171\u4eab\u7684\uff0c\u56e0\u6b64\u4e3b\u7f51\u7edc\u4e2d\u5bf9\u5e94\u7684\u6e90\u57df\u5206\u652f\u5bb9\u6613\u53d7\u5230\u76ee\u6807\u57df\u6570\u636e\u7684\u8d1f\u9762\u5f71\u54cd\u3002\u5bf9\u6b64\uff0c\u4f5c\u8005\u5355\u72ec\u8bbe\u7f6e\u4e86\u8f85\u52a9\u7f51\u7edc\uff0c\u7528\u4e8e\u72ec\u7acb\u5730\u7ea6\u675f\u6e90\u57df\u98ce\u9669\uff0c\u5e76\u4e14\u5728\u5b9e\u9a8c\u4e2d\uff0c\u4e3b\u7f51\u7edc\u7684\u68c0\u6d4b\u635f\u5931\u5c06\u88ab\u91cd\u65b0\u7528\u4e8e\u8f85\u52a9\u7f51\u7edc\u7684\u76d1\u63a7\u3002</p> <p>\u2003\u2003\u7efc\u4e0a\u6240\u8ff0\uff0c\u8f85\u52a9\u7f51\u7edc\u88ab\u8bad\u7ec3\u4ee5\u751f\u6210\u4e0e\u4e3b\u7f51\u7edc\u76ee\u6807\u57df\u5206\u652f\u5177\u6709\u76f8\u4f3c\u5206\u5e03\u7684\u7279\u5f81\uff0c\u5e76\u4e14\u8f85\u52a9\u7f51\u7edc\u8fd8\u901a\u8fc7\u9886\u57df\u5bf9\u6297\u635f\u5931\u6765\u8c03\u6574\u7531\u4e3b\u7f51\u7edc\u76ee\u6807\u57df\u5206\u652f\u5b66\u4e60\u5230\u7684\u7279\u5f81\uff0c\u901a\u8fc7\u5bf9\u9f50\u4e24\u4e2a\u7f51\u7edc\u4e4b\u95f4\u7684\u7279\u5f81\u5206\u5e03\uff0c\u6765\u4f7f\u4e3b\u7f51\u7edc\u9002\u5e94\u6e90\u57df\u6570\u636e\u8bad\u7ec3\u7684\u68c0\u6d4b\u5668\uff0c\u6362\u53e5\u8bdd\u8bf4\uff0c\u9886\u57df\u5bf9\u6297\u635f\u5931\u76f8\u5f53\u4e8e\u4e3b\u7f51\u7edc\u548c\u8f85\u52a9\u7f51\u7edc\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u8f85\u52a9\u7f51\u7edc\u901a\u8fc7\u8be5\u8054\u7cfb\u6765\u6307\u5bfc\u4e3b\u7f51\u7edc\u7279\u5f81\u63d0\u53d6\u80fd\u529b\u7684\u5b66\u4e60\uff0c\u8c03\u6574\u4e3b\u7f51\u7edc\u63d0\u53d6\u5230\u7684\u7279\u5f81\uff0c\u8fdb\u4e00\u6b65\u8c03\u6574\u4e3b\u7f51\u7edc\u7684\u5224\u5b9a\u8fb9\u754c\u3002\u540c\u65f6\uff0c\u8f85\u52a9\u7f51\u7edc\u8fd8\u53d7\u5230\u6e90\u68c0\u6d4b\u5668\u4e2d\u5206\u7c7b\u635f\u5931\u548c\u56de\u5f52\u635f\u5931\u7684\u9650\u5236\uff0c\u4f7f\u5176\u5bf9\u6e90\u57df\u6570\u636e\u53ef\u4ee5\u63d0\u53d6\u533a\u5206\u5ea6\u8f83\u9ad8\u7684\u7279\u5f81\u3002\u56e0\u6b64\uff0c\u901a\u8fc7\u57df\u5bf9\u9f50\u548c\u6e90\u98ce\u9669\u6700\u5c0f\u5316\uff0c\u7528\u4e8e\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u7684\u671f\u671b\u98ce\u9669\u53ef\u4ee5\u6709\u6548\u5730\u88ab\u9650\u5236\u3002\u6ce8\u610f\uff0c\u5728\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\uff0c\u76ee\u6807\u57df\u56fe\u50cf\u4e0d\u7ecf\u8fc7\u8f85\u52a9\u7f51\u7edc\uff0c\u53ea\u7ecf\u8fc7\u4e3b\u7f51\u7edc\uff0c\u53ea\u5229\u7528\u4e3b\u7f51\u7edc\u5bf9\u7269\u4f53\u7684\u7c7b\u522b\u548c\u5750\u6807\u4fe1\u606f\u8fdb\u884c\u9884\u6d4b\u3002</p>"},{"location":"domain_adaptive/paper/ATF1/#_7","title":"\u8bad\u7ec3\u635f\u5931","text":"<p>\u2003\u2003\u975e\u5bf9\u79f0\u4e09\u8defFaster-RCNN(ATF)\u7f51\u7edc\u7684\u4f18\u5316\u4e3b\u8981\u7531\u4e24\u4e2a\u635f\u5931\u51fd\u6570\u6765\u5b8c\u6210\uff0c\u57fa\u4e8e\u6e90\u57df\u6570\u636e\u7684\u68c0\u6d4b\u635f\u5931\u548c\u9886\u57df\u5bf9\u9f50\u635f\u5931\uff0c\u4e3b\u7f51\u7edc\u548c\u8f85\u52a9\u7f51\u7edc\u7684\u68c0\u6d4b\u635f\u5931\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ \\mathcal L_{Det}=\\mathcal L_{cls}(x^s_i,b^s_i,y^s_i)+\\mathcal L_{reg}(x^s_i,b^s_i,y^s_i) $$  \u5176\u4e2d\\mathcal L_{cls}\u8868\u793a\u57fa\u4e8esoftmax\u7684\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\\mathcal L_{reg}\u8868\u793a\u5e73\u6ed1L_1\u635f\u5931\uff0c\u4e24\u4e2a\u6807\u51c6\u7684\u68c0\u6d4b\u635f\u5931\u5171\u540c\u7528\u4e8e\u7ea6\u675f\u6e90\u57df\u98ce\u9669\u3002\u603b\u635f\u5931\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ \\mathcal L_{ATF}=\\mathcal L_{Det}+\\alpha(\\mathcal L_{L-Dac}+\\sum^5_{k=3}\\mathcal L^k_{G-Dac}) $$  \u5176\u4e2d\\alpha\u8868\u793a\u7528\u4e8e\u6743\u8861\u9886\u57df\u5bf9\u9f50\u635f\u5931\u7684\u6743\u91cd\u53c2\u6570\u3002</p>"},{"location":"domain_adaptive/paper/ATF1/#map","title":"mAP\u5bf9\u6bd4","text":"<p>Cityscape \\rightarrow FoggyCityscape</p> <p> <p></p> <p></p>"},{"location":"domain_adaptive/paper/ATF1/#_8","title":"\u603b\u7ed3","text":"<p>\u2003\u2003\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u975e\u5bf9\u79f0\u4e09\u8def\u7f51\u7edc\u6765\u89e3\u51b3\u65e0\u76d1\u7763\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u4e2d\u53c2\u6570\u5171\u4eab\u5f15\u8d77\u7684\u6e90\u57df\u7279\u5f81\u5931\u63a7\u95ee\u9898\uff0c\u4e3b\u8981\u5c31\u662f\u5728\u7f51\u7edc\u4e2d\u65b0\u52a0\u5165\u4e86\u4e00\u4e2a\u7531\u6e90\u57df\u6807\u7b7e\u76d1\u7763\u8bad\u7ec3\u7684\u8f85\u52a9\u7f51\u7edc\uff0c\u8be5\u7f51\u7edc\u53c2\u6570\u548c\u4e3b\u7f51\u7edc\u53c2\u6570\u76f8\u4e92\u72ec\u7acb\u3002\u6a21\u578b\u4e3b\u8981\u6709\u4e24\u5927\u8d21\u732e\uff1a\u2460\u5728\u53c2\u6570\u5171\u4eab\u7684\u7f51\u7edc\u4e2d\uff0c\u57df\u5dee\u5f02\u96be\u4ee5\u6d88\u9664\uff0c\u56e0\u6b64\u63d0\u51fa\u4e86\u975e\u5bf9\u79f0\u7684\u7f51\u7edc\u7ed3\u6784\u6765\u589e\u5f3a\u68c0\u6d4b\u5668\u7684\u8bad\u7ec3\uff0c\u8fd9\u79cd\u4e0d\u5bf9\u79f0\u6027\u53ef\u4ee5\u5f88\u597d\u5730\u7f13\u89e3\u6e90\u57df\u548c\u76ee\u6807\u57df\u4e4b\u95f4\u6807\u8bb0\u4e0d\u516c\u5e73\u6240\u5e26\u6765\u7684\u95ee\u9898\uff1b\u2461\u6240\u63d0\u51fa\u7684\u8f85\u52a9\u7f51\u7edc\u4f7f\u5f97\u6e90\u57df\u7279\u5f81\u5206\u5e03\u53ef\u4ee5\u4fdd\u6301\u7ed3\u6784\u533a\u5206\u6027\uff0c\u5f88\u5927\u7a0b\u5ea6\u4e0a\u63d0\u9ad8\u4e86\u76ee\u6807\u57df\u7279\u5f81\u7684\u53ef\u9760\u6027\u3002</p> <p>\u6ce8\uff1a\u4ee5\u4e0a\u5185\u5bb9\u4ec5\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u89c2\u70b9\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u5927\u5bb6\u6279\u8bc4\u6307\u6b63\u3002</p> <p>\u521d\u6b65\u5b8c\u7a3f\uff1a2022\u5e743\u670820\u65e5</p>"},{"location":"domain_adaptive/paper/CST-MCD1/","title":"\u57df\u9002\u5e94\uff1aCST-MCD","text":""},{"location":"domain_adaptive/paper/CST-MCD1/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aEuropean Conference on Computer Vision 2020 (ECCV 20)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123630086.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/uitrbn/CST_DA_detection</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b</p>"},{"location":"domain_adaptive/paper/CST-MCD1/#_2","title":"\u4e3b\u8981\u601d\u60f3","text":"<p>\u2003\u2003\u76ee\u524d\u5927\u591a\u6570\u89e3\u51b3\u9886\u57df\u504f\u79fb\u95ee\u9898\u7684\u7b97\u6cd5\u90fd\u662f\u57fa\u4e8e\u5bf9\u6297\u8bad\u7ec3\u7b56\u7565\u8bbe\u8ba1\u7684\uff0c\u901a\u8fc7\u8bbe\u8ba1\u57df\u5206\u7c7b\u5668\u6a21\u5757\uff0c\u518d\u7ed3\u5408\u5bf9\u6297\u635f\u5931\u6765\u5bf9\u9f50\u6574\u4e2a\u56fe\u50cf\u7684\u7279\u5f81\u8868\u793a\uff0c\u8fd9\u79cd\u65b9\u6cd5\u7684\u6709\u6548\u6027\u6700\u65e9\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u5f97\u5230\u4e86\u9a8c\u8bc1\uff0c\u6700\u8fd1\u4e5f\u88ab\u5e94\u7528\u5230\u4e86\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u4e2d\uff0c\u5982\uff1aDA Faster\u3001Strong-Weak\u7b49\u7b49\u3002\u4f46\u662f\u4e0d\u540c\u4e8e\u5206\u7c7b\u4efb\u52a1\uff0c\u5927\u591a\u6570\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u901a\u5e38\u6bd4\u8f83\u590d\u6742\uff0c\u5c24\u5176\u662f\u4e8c\u9636\u6bb5\u68c0\u6d4b\u7b97\u6cd5\uff0c\u4ec5\u4ec5\u8c03\u6574\u4e3b\u5e72\u7f51\u7edc\u7684\u5168\u5c40\u7279\u5f81\u662f\u8fdc\u8fdc\u4e0d\u591f\u7684\uff0c\u9700\u8981\u5bf9RPN\u7684\u8f6c\u79fb\u6027\u505a\u8fdb\u4e00\u6b65\u7814\u7a76\u3002\uff08\u8f6c\u79fb\u6027\u4e5f\u79f0\u9886\u57df\u9002\u5e94\u80fd\u529b\uff09</p> <p>\u2003\u2003RPN\u6a21\u5757\u7684\u53ef\u8f6c\u79fb\u6027\u5bf9\u4e8e\u4e8c\u9636\u6bb5\u7684\u68c0\u6d4b\u5668\u975e\u5e38\u91cd\u8981\uff0c\u800c\u4ec5\u5bf9\u4e3b\u5e72\u7f51\u7edc\u5f97\u5230\u7684\u7279\u5f81\u6267\u884c\u5bf9\u9f50\u65e0\u6cd5\u4f7fRPN\u6a21\u5757\u5177\u6709\u6709\u6548\u7684\u9886\u57df\u9002\u5e94\u6027\u3002\u4e00\u4e2a\u4e8c\u9636\u6bb5\u7684\u76ee\u6807\u68c0\u6d4b\u5668\u901a\u5e38\u53ef\u4ee5\u5212\u5206\u4e3a\u4e09\u4e2a\u6a21\u5757\uff1a\u4e3b\u5e72\u7f51\u7edc\u3001RP N\u4ee5\u53ca\u533a\u57df\u5206\u7c7b\u5668(\u540e\u9762\u68c0\u6d4bRPC)\u3002\u9762\u5bf9\u8f83\u5927\u7684\u9886\u57df\u504f\u79fb\uff0c\u4f5c\u8005\u53d1\u73b0RPN\u548cRPC\u5c55\u73b0\u51fa\u4e86\u4e0d\u540c\u7684\u53ef\u8f6c\u79fb\u6027\uff0cRPC\u901a\u5e38\u53ef\u4ee5\u5c55\u793a\u51fa\u66f4\u597d\u5730\u6548\u679c\u3002\u4f5c\u8005\u5bf9\u4e24\u4e2a\u6a21\u5757\u7684\u9002\u5e94\u80fd\u529b\u505a\u4e86\u8fdb\u4e00\u6b65\u7684\u53ef\u89c6\u5316\u7814\u7a76\uff0c\u5177\u4f53\u7ed3\u679c\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u5176\u4e2d\uff0c\u201d\u53ea\u6709\u6e90\u57df\u201d\u8868\u793a\u76f4\u63a5\u5c06\u5728Sim10k\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\u5e94\u7528\u5230Cityscapes\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\u6027\u80fd\uff0c\u53d60.5\u4f5c\u4e3aIOU\u7684\u9608\u503c\uff0c\u5206\u522b\u8ba1\u7b97RPN\u4e0eRPC\u7684\u53ec\u56de\u7387\u3002\u5f88\u660e\u663e\u53ef\u4ee5\u53d1\u73b0RPC\u7684\u6027\u80fd\u8981\u6bd4RPN\u7684\u6027\u80fd\u597d\uff0c\u66f4\u91cd\u8981\u7684\u662f\uff0c\u7ecf\u8fc7\u8c03\u6574\u4e4b\u540e\uff0coracle(\u7eff\u6761)\u548c\u7eaf\u6e90\u57df\u6a21\u578b(\u7ea2\u6761)\u76f8\u6bd4\uff0c\u4e0b\u964d\u7684\u6027\u80fd\u66f4\u5c11\uff0c\u8bf4\u660eRPN\u6bd4RPC\u66f4\u5bb9\u6613\u53d7\u5230\u57df\u95f4\u9699\u7684\u5f71\u54cd\u3002\u7136\u800c\uff0c\u5982\u679cRPN\u4e0d\u80fd\u63d0\u4f9b\u8d28\u91cf\u8f83\u9ad8\u7684\u5efa\u8bae\u533a\u57df\uff0c\u5219RPC\u7684\u6027\u80fd\u4e5f\u4f1a\u53d7\u5230\u5f71\u54cd\uff0c\u56e0\u6b64\u63d0\u9ad8RPN\u6a21\u5757\u7684\u9886\u57df\u9002\u5e94\u80fd\u529b\u5bf9\u63d0\u9ad8\u6574\u4e2a\u68c0\u6d4b\u5668\u7684\u68c0\u6d4b\u6027\u80fd\u5177\u6709\u91cd\u8981\u7684\u4f5c\u7528\u3002\u6240\u8c13RPN\u7684\u9886\u57df\u9002\u5e94\u80fd\u529b\u4e5f\u79f0\u4e3aRPN\u6a21\u5757\u5728\u4e0d\u540c\u9886\u57df\u4e0b\u53d1\u73b0\u5bf9\u8c61\u76ee\u6807\u7684\u80fd\u529b\uff0c\u4e5f\u5c31\u662f\u51c6\u786e\u5730\u5c06\u5b58\u5728\u5bf9\u8c61\u7684\u951a\u70b9\u9884\u6d4b\u4e3a\u524d\u666f\u3001\u5c06\u4e0d\u5b58\u5728\u5bf9\u8c61\u7684\u951a\u70b9\u9884\u6d4b\u4e3a\u80cc\u666f\u7684\u80fd\u529b\u3002</p> <p>\u2003\u2003\u53e6\u4e00\u65b9\u9762\uff0c\u5728\u67d0\u4e9b\u4e8c\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\u5668\u4e2d\uff08\u5982Faster RCNN\uff09\uff0cRPN\u548cRPC\u4e4b\u95f4\u6ca1\u6709\u68af\u5ea6\u6d41\uff0c\u56e0\u6b64\u8fd9\u4e24\u4e2a\u6a21\u5757\u4e5f\u53ef\u4ee5\u88ab\u770b\u505a\u662f\u4e3b\u5e72\u7f51\u7edc\u7684\u4e24\u4e2a\u5206\u652f\uff0c\u5982\u679c\u6211\u4eec\u8ba4\u4e3aRPN\u662f\u4e00\u79cd\u524d\u666f\u3001\u80cc\u666f\u5206\u7c7b\u5668\uff0c\u90a3\u4e48\u5b83\u53ef\u4ee5\u88ab\u770b\u505a\u662f\u5bf9\u7279\u5f81\u56fe\u4e0a\u6bcf\u4e2a\u951a\u70b9\u8fdb\u884c\u7c97\u7565\u548c\u5feb\u901f\u5206\u7c7b\u7684RPC\u3002\u7c7b\u4f3c\u7684\uff0c\u5982\u679c\u6211\u4eec\u5c06RPC\u8f93\u51fa\u7684\u524d\u666f\u3001\u80cc\u666f\u5206\u6570\u76f8\u52a0\uff0c\u90a3\u4e48\u5b83\u53ef\u4ee5\u88ab\u770b\u505a\u662f\u4e00\u4e2a\u7cbe\u7ec6\u5e76\u4e14\u6709\u9009\u62e9\u6027\u7684RPN\u3002\u57fa\u4e8e\u4e0a\u8ff0\u8ba8\u8bba\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u5728RPN\u548cRPC\u4e4b\u95f4\u4f7f\u7528\u534f\u540c\u8bad\u7ec3\u7684\u57df\u9002\u5e94\u65b9\u6cd5\uff0c\u5b83\u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u63a8\u5e7f\u5230\u5176\u4ed6\u7684\u4e8c\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\u5668\u4e2d\u3002\u5177\u4f53\u7684\u6765\u8bf4\uff0c\u9996\u5148\u5728RPN\u548cRPC\u4e4b\u95f4\u5e94\u7528\u534f\u540c\u81ea\u8bad\u7ec3\u7b56\u7565(collaborative self-training)\uff0c\u901a\u8fc7\u5229\u7528\u4e00\u65b9\u7f6e\u4fe1\u5ea6\u9ad8\u7684\u8f93\u51fa\u6765\u8bad\u7ec3\u53e6\u4e00\u65b9\uff1b\u53e6\u5916\uff0c\u4f5c\u8005\u8fd8\u5f15\u5165\u4e86focal loss\u6765\u5bf9\u7f6e\u4fe1\u5ea6\u9ad8\u7684ROI\u65bd\u52a0\u66f4\u591a\u7684\u6743\u91cd\uff0c\u5e76\u4e14\u901a\u8fc7\u53bb\u9664\u9608\u503c\u9009\u62e9\u6765\u63d0\u9ad8\u7a33\u5b9a\u6027\u3002\u7b2c\u4e8c\uff0cROI\u4e2d\u7f6e\u4fe1\u5ea6\u8f83\u4f4e\u7684\u533a\u57df\u53ef\u4ee5\u7528\u6765\u8ba1\u7b97RPN\u548cRPC\u4e4b\u95f4\u524d\u666f\u3001\u80cc\u666f\u7684\u9884\u6d4b\u5dee\u5f02\uff0c\u4e3a\u4e86\u63d0\u9ad8\u68c0\u6d4b\u5668\u7684\u8f6c\u79fb\u6027\uff0c\u4ee5\u6700\u5c0f\u5316\u8be5\u5dee\u5f02\u4e3a\u76ee\u6807\u8bad\u7ec3\u4e3b\u5e72\u7f51\u7edc\uff0c\u800c\u4ee5\u6700\u5927\u5316\u8be5\u5dee\u5f02\u4e3a\u76ee\u6807\u8bad\u7ec3RPN\u548cRPC\u7684\u5206\u7c7b\u6a21\u5757\u3002</p>"},{"location":"domain_adaptive/paper/CST-MCD1/#_3","title":"\u65b9\u6cd5","text":""},{"location":"domain_adaptive/paper/CST-MCD1/#_4","title":"\u7f51\u7edc\u7ed3\u6784","text":"<p>\u2003\u2003\u7ed9\u5b9a\u5e26\u6709\u6807\u7b7e\u7684\u6e90\u57df\u6570\u636e\u548c\u4e0d\u5e26\u6709\u6807\u7b7e\u7684\u76ee\u6807\u57df\u6570\u636e\uff0c\u76ee\u7684\u5c31\u662f\u4e3a\u4e86\u8bad\u7ec3\u4e00\u4e2a\u5728\u76ee\u6807\u57df\u6570\u636e\u96c6\u4e0a\u68c0\u6d4b\u6027\u80fd\u826f\u597d\u7684\u76ee\u6807\u68c0\u6d4b\u5668\u3002\u4f20\u7edf\u7684\u65b9\u6cd5\u4e2d\uff0c\u7279\u5f81\u7ea7\u7684\u57df\u9002\u5e94\u65b9\u6cd5\u5c1d\u8bd5\u5728\u4e24\u4e2a\u9886\u57df\u6570\u636e\u4e0a\u63d0\u53d6\u5177\u6709\u57df\u4e0d\u53d8\u6027(domain-invariant)\u7684\u7279\u5f81\uff0c\u53ea\u9488\u5bf9\u4e3b\u5e72\u7f51\u7edc\u8bbe\u8ba1\u76f8\u5173\u7684\u9002\u5e94\u7b97\u6cd5\uff0c\u5ffd\u7565\u4e86\u5176\u4ed6\u6a21\u5757\u7684\u81ea\u9002\u5e94\uff0c\u5982RPN\u3001RPC\u3002</p> <p>\u2003\u2003\u4f5c\u8005\u63d0\u51fa\u7684\u7f51\u7edc\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\u3002\u5de6\u4e0a\u89d2\u7684\u84dd\u8272\u533a\u57df\u8868\u793aFaster RCNN\u6a21\u5757\uff0c\u5176\u4e2dRPN\u751f\u6210ROI\uff0c\u5e76\u4e14\u5c06\u5176\u9001\u5230RPC\u4e2d\u7528\u4e8eROI-pooling\u3002\u4e0b\u4fa7\u7684\u9ec4\u8272\u533a\u57df\u8868\u793a\u50cf\u7d20\u7ea7\u522b\u7684\u57df\u5224\u522b\u5668\uff0c\u7528\u4e8e\u5224\u65ad\u8f93\u5165\u7279\u5f81\u6765\u81ea\u54ea\u4e2a\u9886\u57df\uff0c\u4ee5\u4e3b\u5e72\u7f51\u7edc\u4e2d\u7684\u7279\u5f81\u4e3a\u8f93\u5165\uff0c\u5e76\u4e14\u8f93\u51fa\u4e00\u5f20\u5c3a\u5bf8\u4e0e\u8f93\u5165\u76f8\u540c\u7684\u9886\u57df\u9884\u6d4b\u56fe\uff0c\u53e6\u5916\uff0cRPN\u7684\u9884\u6d4b\u5c06\u4f1a\u7528\u4e8e\u7a81\u51fa\u524d\u666f\u951a\u70b9\u7684\u57df\u5206\u7c7b\u635f\u5931\u3002\u53f3\u4e0a\u89d2\u7684\u7ea2\u8272\u533a\u57df\u4e3b\u8981\u7531\u4e24\u4e2a\u6a21\u5757\u6784\u6210\u2014\u2014\u534f\u540c\u81ea\u8bad\u7ec3\u65b9\u6848(collaborative self-training scheme)\u548cRPN\u3001RPC\u4e4b\u95f4\u7684\u5dee\u5f02\u6700\u5927\u5316/\u6700\u5c0f\u5316\u6a21\u5757(MCD)\uff0c\u5177\u6709RPN(RPC)\u9ad8\u7f6e\u4fe1\u5ea6\u7684ROI\u7528\u4e8e\u8bad\u7ec3RPC(RPN)\uff0c\u800c\u5177\u6709\u4f4e\u7f6e\u4fe1\u5ea6\u7684ROI\u5c06\u7528\u4e8e\u5dee\u5f02\u4f18\u5316\u3002\u5bf9\u4e8e\u534f\u540c\u8bad\u7ec3\uff0cROI\u7f6e\u4fe1\u5ea6\u6c34\u5e73\u8d8a\u9ad8\uff0c\u5728\u8ba1\u7b97\u635f\u5931\u51fd\u6570\u65f6\u7ed9\u4e88\u7684\u6743\u91cd\u5c31\u8d8a\u5927\uff1b\u800c\u5bf9\u4e8eMCD\u521a\u597d\u76f8\u53cd\uff0cROI\u7f6e\u4fe1\u5ea6\u6c34\u5e73\u8d8a\u4f4e\uff0c\u6837\u672c\u7684\u6743\u91cd\u5c31\u8d8a\u5927\u3002</p> <p> <p></p> <p></p>"},{"location":"domain_adaptive/paper/CST-MCD1/#_5","title":"\u534f\u540c\u81ea\u8bad\u7ec3","text":"<p>\u2003\u2003\u5927\u90e8\u5206\u4e09\u9636\u6bb5\u68c0\u6d4b\u5668\u53ef\u4ee5\u5206\u4e3a\u4e09\u4e2a\u6a21\u5757\uff1a\u4e3b\u5e72\u7f51\u7edcF\u3001RPN\u4ee5\u53caRPC\u3002F\u4e3b\u8981\u7528\u4e8e\u63d0\u53d6\u8f93\u5165\u56fe\u50cf\u7684\u7279\u5f81\uff0c\u5e76\u4e14\u8f93\u51fa\u7279\u5f81\u56fe\uff1bRPN\u4e3b\u8981\u4ee5\u7279\u5f81\u4f5c\u4e3a\u8f93\u5165\uff0c\u8f93\u51fa\u6bcf\u4e2a\u951a\u70b9\u7684\u524d/\u80cc\u666f\u9884\u6d4b\u5206\u6570\uff0c\u5e76\u4e14ROI pooling\u6a21\u5757\u7528\u4e8e\u63d0\u53d6\u524d\u666f\u6982\u7387\u9ad8\u7684\u951a\u70b9\u7279\u5f81\uff0c\u5e76\u4e14\u8fdb\u4e00\u6b65\u5c06\u5176\u4f20\u9001\u5230RPC\u4e2d\uff1bRPC\u6a21\u5757\u5bf9\u8fb9\u754c\u6846\u7684\u5927\u5c0f\u548c\u4f4d\u7f6e\u6267\u884c\u7c7b\u522b\u9884\u6d4b\u548c\u56de\u5f52\u3002</p> <p>\u2003\u2003\u867d\u7136RPC\u57fa\u4e8eRPN\u6a21\u5757\u7684\u7ed3\u679c\u6267\u884c\u533a\u57df\u7684\u5206\u7c7b\u548c\u56de\u5f52\uff0c\u4f46\u662f\u5b83\u4e0d\u4f1a\u5728\u8bad\u7ec3\u671f\u95f4\u5c06\u68af\u5ea6\u53cd\u5411\u4f20\u64ad\u5230RPN\u4e2d\u3002\u5728\u5c06\u7ed3\u679c\u4f20\u5165RPC\u4e4b\u524d\uff0cRPN\u4f1a\u5c06\u67d0\u4e9b\u524d\u666f\u6982\u7387\u4f4e\u7684\u951a\u70b9\u8fc7\u6ee4\u6389\uff0c\u5982\u679c\u5c06\u8fd9\u4e2a\u8fc7\u6ee4\u64cd\u4f5c\u79fb\u9664\uff0c\u5e76\u4e14\u8ba9RPN\u6a21\u5757\u5728\u6bcf\u4e2a\u951a\u70b9\u5904\u6267\u884cROI pooling\u64cd\u4f5c\uff0c\u5219RPC\u6a21\u5757\u53ef\u4ee5\u88ab\u7b49\u540c\u4e8eRPN\u3002\u7406\u60f3\u60c5\u51b5\u4e0b\uff0cRPN\u6a21\u5757\u4e0eRPC\u6a21\u5757\u5e94\u8be5\u5177\u6709\u4e00\u81f4\u6027\uff0c\u6362\u53e5\u8bdd\u8bf4\uff0c\u540c\u4e00\u4e2a\u951a\u70b9\u5728RPC\u4e2d\u5982\u679c\u5177\u6709\u8f83\u9ad8\u7684\u80cc\u666f\u7c7b\u522b\u5206\u6570\uff0c\u5219\u5728RPN\u4e2d\u5bf9\u5e94\u4f1a\u6709\u8f83\u4f4e\u7684\u524d\u666f\u6982\u7387\uff1b\u540c\u6837\u7684\uff0c\u5982\u679c\u4e00\u4e2a\u951a\u70b9\u5177\u6709\u8f83\u9ad8\u7684\u975e\u80cc\u666f\u7c7b\u522b\u9884\u6d4b\u5206\u6570\uff0c\u5219\u5728RPN\u4e2d\u5bf9\u5e94\u4f1a\u6709\u8f83\u9ad8\u7684\u524d\u666f\u6982\u7387\u3002</p> <p>\u2003\u2003\u672c\u6587\u7684\u52a8\u673a\u5c31\u662f\u5145\u5206\u5229\u7528RPN\u6a21\u5757\u7684\u9886\u57df\u81ea\u9002\u5e94\u80fd\u529b\u6765\u63d0\u9ad8\u6a21\u578b\u5728\u76ee\u6807\u9886\u57df\u7684\u76ee\u6807\u68c0\u6d4b\u6027\u80fd\u3002\u5047\u8bbe\u6e90\u57df\u6570\u636e\u8868\u793a\u4e3a\\{X_s,Y_s\\}\uff0cx_s\\in X_s\u4e3a\u6e90\u57df\u7684\u56fe\u50cf\u6570\u636e\uff0cy_s\\in Y_s\u4e3a\u5bf9\u5e94\u7684\u6807\u7b7e\uff0c\u76ee\u6807\u57df\u6570\u636e\u8868\u793a\u4e3a\\{X_t\\}\uff0cx_t\\in X_t\u4e3a\u76ee\u6807\u57df\u7684\u56fe\u50cf\u6570\u636e\u3002\u5bf9\u4e8e\u6e90\u57df\u56fe\u50cfx_s\uff0c\u5c06Faster RCNN\u7684\u8bad\u7ec3\u635f\u5931\u8868\u793a\u4e3a\uff1a $$ L_{det}=L_{rpn}(x_s,y_s)+L_{cls}(x_s,y_s) $$  \u2003\u2003\u7531\u4e8e\u76ee\u6807\u57df\u56fe\u50cf\u7f3a\u5c11\u76f8\u5e94\u7684\u6807\u7b7e\uff0c\u56e0\u6b64\u4f5c\u8005\u901a\u8fc7\u5229\u7528\u4e00\u4e2a\u6a21\u5757\u7684\u8f93\u51fa\u6765\u8bad\u7ec3\u53e6\u4e00\u4e2a\u6a21\u5757\uff0c\u4ece\u800c\u8fbe\u5230\u76f8\u4e92\u8bad\u7ec3RPN\u548cRPC\u4e24\u4e2a\u6a21\u5757\u7684\u4f5c\u7528\u3002\u7ed9\u5b9a\u4e00\u5f20\u76ee\u6807\u57df\u56fe\u50cfx_t\uff0c\u9996\u5148\u7ecf\u8fc7\u4e3b\u5e72\u7f51\u7edcF\u63d0\u53d6\u76f8\u5e94\u7684\u7279\u5f81f_t\uff0c\u4e4b\u540eRPN\u6a21\u5757\u5229\u7528f_t\u9884\u6d4b\u6bcf\u4e2a\u951a\u70b9\u7684\u5206\u6570s_{rpn}(\u5373\u524d\u666f\u548c\u80cc\u666f\u6982\u7387)\uff0c\u4ece\u800c\u5f97\u5230ROI\uff0c\u8fdb\u4e00\u6b65\u5c06ROI\u4f20\u5165RPC\u6a21\u5757\u8f93\u51fa\u7c7b\u522b\u6982\u7387\u5206\u5e03s_{cls}(\u5305\u62ec\u80cc\u666f\u5728\u5185\u7684\u7c7b\u522b)\u3002\u5bf9\u4e8e\u6bcf\u4e2a\u5e26\u6709\u9ad8\u7f6e\u4fe1\u5ea6s_{cls}\u7684ROI\uff0c\u4f5c\u8005\u91cd\u65b0\u5229\u7528\u4ed6\u4eec\u6765\u66f4\u65b0RPN\u7684\u635f\u5931\uff1a $$ L_{rpn_t}=f_w(s_{cls})L_{rpn}(x_t,\\hat{y}_t) $$  \u5176\u4e2df_w\u53ef\u4ee5\u88ab\u5b9a\u4e49\u4e3a\u4efb\u4f55\u968f\u7740s_{cls}\u5bf9\u524d\u666f/\u80cc\u666f\u5206\u7c7b\u7684\u4e0d\u786e\u5b9a\u6027\u589e\u52a0\u800c\u51cf\u5c11\u7684\u51fd\u6570\uff0c\u4f5c\u8005\u5728\u5b9e\u9a8c\u4e2d\u5b9a\u4e49\u4e3a\uff1a $$ f_w(s_{cls})=(|1-2s^{bg}_{cls}|)^{\\lambda} $$  \u5176\u4e2d\uff0cs^{bg}_{cls}\u8868\u793a\u4e3as_{cls}\u4e2d\u7684\u80cc\u666f\u5206\u6570\uff0c\\lambda\u8868\u793a\u4e3a\u63a7\u5236\u4f4e\u7f6e\u4fe1\u5ea6\u6837\u672c\u7684\u6743\u91cd\uff0c\u5b9e\u9a8c\u4e2d\u4f5c\u8005\u8bbe\u4e3a5\u3002\u5f53\u524d\u666f\u5206\u6570\u548c\u80cc\u666f\u5206\u6570\u5747\u5404\u8d8b\u5411\u4e8e0.5\u65f6\uff0c\u5206\u7c7b\u7684\u4e0d\u786e\u5b9a\u6027\u5c31\u8d8a\u5927\uff0c\u8d8a\u4e0d\u5bb9\u6613\u5224\u65ad\u8be5\u951a\u70b9\u5230\u5e95\u5c5e\u4e8e\u524d\u666f\u8fd8\u662f\u80cc\u666f\uff0c\u6b64\u65f6f_w\u5c31\u4f1a\u8d8b\u5411\u4e8e0\uff0c\u8fdb\u4e00\u6b65\u6291\u5236RPN\u5728\u8be5\u951a\u70b9\u4e0a\u7684\u635f\u5931\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\\hat{y}_t\u8868\u793a\u5305\u542b\u9ad8\u7f6e\u4fe1\u5ea6s_{cls}\u7684ROI\u4f2a\u6807\u7b7e\uff0c\u5305\u62ec\u524d\u666f\u548c\u80cc\u666f\u533a\u57df\u63d0\u8bae\uff08\u5373\u5c06RPC\u4e2d\u7684\u9ad8\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u7ed3\u679c\u5f53\u505aRPN\u4e2d\u7684\u53c2\u8003\u6807\u7b7e\uff09\uff0c\u5b83\u5e76\u4e0d\u9700\u8981\u5305\u542b\u56fe\u50cf\u4e2d\u7684\u6bcf\u4e2a\u5bf9\u8c61\uff0c\u4e5f\u4e0d\u9700\u8981\u5305\u542b\u7279\u5b9a\u7684\u7c7b\u3002\u5728Faster RCNN\u4e2d\uff0cRPN\u4ee5\u4e00\u79cd\u9009\u62e9\u6027\u7684\u65b9\u5f0f\u88ab\u8bad\u7ec3\uff0c\u5047\u8bbe\u7279\u5f81\u63d0\u53d6\u5668\u7684\u524d\u5411\u4f20\u64ad\u5f97\u5230\u5c3a\u5bf8\u4e3aH\\times W\u7684\u7279\u5f81\u56fe\uff0c\u4e00\u822c\u4f1a\u6709H\\times W\\times9\u4e2a\u951a\u70b9\u548c\u4e00\u4e2a\u5c3a\u5bf8\u76f8\u540c\u7684\u9884\u6d4b\u56fe\u3002\u5728RPN\u635f\u5931L_{rpn}\u7684\u8ba1\u7b97\u4e2d\u4ec5\u53c2\u8003\u4e86\u4e00\u5c0f\u90e8\u5206\u951a\u70b9\uff0c\u5e76\u4e14\u5728\u6ca1\u6709\u989d\u5916\u5904\u7406\u7684\u60c5\u51b5\u4e0b\uff0c\u4e22\u5931\u4e00\u90e8\u5206\u6807\u7b7e\u4e0d\u4f1a\u635f\u5bb3RPN\u7684\u6027\u80fd\u3002</p> <p>\u2003\u2003\u53e6\u4e00\u65b9\u9762\uff0c\u53ef\u4ee5\u5728RPC\u6a21\u5757\u6267\u884c\u7c7b\u4f3c\u7684\u64cd\u4f5c\uff0c\u56e0\u4e3aRPN\u4e3b\u8981\u5173\u6ce8\u4e8e\u524d\u666f\u548c\u80cc\u666f\u7684\u5206\u7c7b\uff0c\u5e76\u4e0d\u4f1a\u63d0\u4f9b\u951a\u70b9\u7c7b\u522b\u7ea7\u7684\u4f2a\u6807\u7b7e\uff0c\u56e0\u6b64\u4f5c\u8005\u4e3aRPC\u6a21\u5757\u91c7\u7528\u71b5\u6700\u5c0f\u5316\u8bad\u7ec3\u7b56\u7565(entropy minimization\uff0c\u8bba\u6587\u94fe\u63a5)\uff0c\u5e76\u4e14\u5728\u635f\u5931\u8ba1\u7b97\u7684\u8fc7\u7a0b\u4e2d\u81ea\u9002\u5e94\u5730\u7ed9\u9ad8\u7f6e\u4fe1\u5ea6\u6837\u672c\u5206\u914d\u8f83\u9ad8\u7684\u6743\u91cd\u3002\u57fa\u4e8e\u71b5\u6700\u5c0f\u5316\u7b56\u7565\uff0cRPC\u88ab\u8bad\u7ec3\u4e3a\u8f93\u51fa\u5177\u6709\u9ad8\u7f6e\u4fe1\u5ea6\u7684\u7c7b\u522b\u5206\u6570s_{cls}\uff08\u5373\u4e0d\u786e\u5b9a\u6027\u6700\u5c0f\uff09\uff0c\u540c\u65f6\u5728RPN\u4e2d\u5177\u6709\u8f83\u9ad8\u7684\u524d\u666f\u9884\u6d4b\u5206\u6570s_{rpn}\uff0c\u4e0eRPN\u6a21\u5757\u7c7b\u4f3c\uff0c\u8be5\u6a21\u5757\u635f\u5931\u53ef\u4ee5\u5b9a\u4e49\u4e3a\uff1a $$ L_{cls_t}=f_w(s_{rpn})E(s_{cls})\\\\ E(s_{cls})=-\\sum_{c\\in C}s^c_{cls}log(s^c_{cls})\\\\ f_w(s_{rpn})=|1-2s^{fg}_{rpn}|^{\\lambda} $$  \u5176\u4e2d\uff0cC\u8868\u793a\u5305\u62ec\u80cc\u666f\u5728\u5185\u7684\u6240\u6709\u7c7b\u522b\u6570\u91cf\uff0cs^c_{cls}\u8868\u793as_{cls}\u4e2d\u7c7b\u522b\u4e3ac\u7684\u9884\u6d4b\u6982\u7387\uff0cs_{rpn}^{fg}\u8868\u793aRPN\u6a21\u5757\u4e2d\u8f93\u51fa\u7684\u524d\u666f\u6982\u7387\u3002</p> <p>\u6ce8\uff1a\u5728\u6e90\u7801\u4e2d\uff0c\u8ba1\u7b97\u5b8cf_w\u4e4b\u540e\u6709\u4e00\u884c\u5207\u9664\u68af\u5ea6\u7684\u4ee3\u7801\u6307\u4ee4\uff0c\u8868\u660e\u8fd9\u91cc\u5728\u8ba1\u7b97\u6743\u91cd\u65f6\u53ea\u53d6\u6570\u503c\uff0c\u53ea\u6539\u53d8\u635f\u5931\u7684\u5927\u5c0f\uff0c\u56e0\u6b64\u540e\u9762\u56de\u4f20\u68af\u5ea6\u7684\u65f6\u5019\uff0c\u68af\u5ea6\u4e0d\u4f1a\u6cbf\u7740\u6743\u91cd\u7684\u8ba1\u7b97\u8fc7\u7a0b\u56de\u4f20\u5230\u5bf9\u5e94\u7684\u6a21\u5757\u4e2d\uff0c\u5373RPN\u635f\u5931\u7684\u56de\u5f52\u4e2d\uff0c\u68af\u5ea6\u4e0d\u4f1a\u6cbf\u7740\u6743\u91cd\u7684\u65b9\u5411\u53bb\u5f71\u54cdRPC\u6a21\u5757\uff0c\u4e5f\u5c31\u662fRPN\u6a21\u5757\u7684\u635f\u5931\u53ea\u4f1a\u5f71\u54cdRPN\u6a21\u5757\uff0c\u4e0d\u4f1a\u5f71\u54cdRPC\u6a21\u5757\uff0cRPC\u6a21\u5757\u7684\u635f\u5931\u540c\u7406\u3002</p>"},{"location":"domain_adaptive/paper/CST-MCD1/#_6","title":"\u6700\u5927\u5dee\u5f02\u5206\u7c7b\u5668","text":"<p>\u2003\u2003\u5982\u4e0a\u6587\u6240\u8868\u8ff0\u7684\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6bcf\u4e2aROI\u6240\u8ba1\u7b97\u7684\u635f\u5931\u9879\u90fd\u4f1a\u4e58\u4ee5\u4e00\u4e2a\u81ea\u9002\u5e94\u7684\u6743\u91cd\uff0cRPN\u66f4\u65b0\u7684\u6743\u91cd\u503c\u53d6\u51b3\u4e8eRPC\u5206\u652f\u76f8\u5173\u8f93\u51fa\u7684\u5206\u6570\uff0c\u53cd\u4e4b\u4ea6\u7136\uff0c\u5177\u4f53\u53d8\u5316\u53ef\u89c1\u4e0b\u56fe\u84dd\u8272\u66f2\u7ebf\uff0c\u5f53ROI\u7684\u5206\u7c7b\u9884\u6d4b\u6982\u7387\u8d8a\u8d8b\u5411\u4e8e0.5\uff0c\u5373\u5206\u7c7b\u7684\u4e0d\u786e\u5b9a\u6027\u56e0\u7d20\u8d8a\u5927\u65f6\uff0c\u76f8\u5e94\u7684\u635f\u5931\u6743\u91cd\u8d8a\u5c0f\uff0c\u53cd\u4e4b\u635f\u5931\u6743\u91cd\u8d8a\u5927\uff0c\u901a\u8fc7\u8bbe\u8ba1\u6743\u91cd\u65b9\u7a0b\u6765\u6307\u5bfc\u6a21\u578b\u7684\u8bad\u7ec3\u4e3b\u8981\u5173\u6ce8\u7f6e\u4fe1\u5ea6\u9ad8\u7684ROI\u533a\u57df\u3002</p> <p> <p></p> <p></p> <p>\u2003\u2003\u9664\u6b64\u4e4b\u5916\uff0c\u4f5c\u8005\u8fd8\u5f15\u5165\u4e86\u4e00\u4e2a\u6700\u5927\u5dee\u5f02\u5206\u7c7b\u5668(maximizing discrepancy classifier, MCD)(\u8bba\u6587\u94fe\u63a5\uff0c\u8bba\u6587\u7b14\u8bb0\u94fe\u63a5)\uff0c\u6307\u51fa\u4e86\u5e26\u6709\u4f4e\u7f6e\u4fe1\u5ea6\u7684ROI\u4e5f\u53ef\u4ee5\u88ab\u6709\u6548\u5730\u5229\u7528\u6765\u63d0\u9ad8\u6a21\u578b\u7684\u9002\u5e94\u6027\u3002MCD\u6700\u5f00\u59cb\u88ab\u7528\u6765\u89e3\u51b3\u56fe\u50cf\u5206\u7c7b\u4e2d\u7684\u57df\u9002\u5e94\u95ee\u9898\uff0c\u901a\u8fc7\u5229\u7528\u7279\u5b9a\u4e8e\u4efb\u52a1(task-specific)\u7684\u5206\u7c7b\u5668\u53bb\u5bf9\u9f50\u6e90\u57df\u548c\u76ee\u6807\u57df\u7684\u5206\u5e03\u3002\u539f\u6587\u4e2d\u9996\u5148\u5c06\u5206\u7c7b\u7f51\u7edc\u5206\u6210\u7279\u5f81\u63d0\u53d6\u5668\u548c\u5206\u7c7b\u5668\uff0c\u5e76\u4e14\u518d\u590d\u5236\u4e00\u4efd\u5206\u7c7b\u5668\u3002\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u4e24\u4e2a\u5206\u7c7b\u5668\u5b66\u4e60\u6700\u5927\u5316\u5b83\u4eec\u4e4b\u95f4\u7684\u9884\u6d4b\u5dee\u5f02\uff0c\u540c\u65f6\u7279\u5f81\u63d0\u53d6\u5668\u8bd5\u56fe\u6700\u5c0f\u5316\u9884\u6d4b\u4e4b\u95f4\u7684\u5dee\u5f02\uff08\u5bf9\u6297\u8bad\u7ec3\uff0c\u6709\u70b9\u7c7b\u4f3c\u4e00\u822c\u57df\u5224\u522b\u5668\u7684\u635f\u5931\uff0c\u4f46\u8fd9\u91cc\u76f4\u63a5\u5c06\u5206\u7c7b\u5668\u505a\u4e3a\u5224\u522b\u5668\uff0c\u6ca1\u6709\u65b0\u52a0\u9886\u57df\u5224\u522b\u5668\uff09\u3002MCD\u7406\u8bba\u6307\u51fa\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u548c\u6700\u5927\u5316\u4e8c\u8005\u7684\u5dee\u5f02\uff0c\u6a21\u578b\u7684\u8f6c\u79fb\u6027(transferability)\u53ef\u4ee5\u6709\u6548\u7684\u5f97\u5230\u63d0\u5347\uff0c\u5373\u6709\u6548\u7684\u63d0\u5347\u6a21\u578b\u7684\u9886\u57df\u9002\u5e94\u80fd\u529b\u3002\u4f5c\u8005\u5728\u672c\u6587\u4e2d\u5c06\u4e24\u4e2a\u9636\u6bb5\u7684\u5206\u7c7b\u5668\u63d0\u53d6\u51fa\u6765\uff0c\u7528\u4e8e\u6784\u6210MCD\u6a21\u5757\uff0c\u8fdb\u4e00\u6b65\u8865\u5145\u4e86\u534f\u540c\u81ea\u8bad\u7ec3\u8fc7\u7a0b\u3002</p> <p>\u2003\u2003\u5177\u4f53\u5730\u6765\u8bf4\uff0c\u4f5c\u8005\u5c06RPN\u548cRPC\u89c6\u4e3a\u4e24\u4e2a\u524d\u666f\u3001\u80cc\u666f\u5206\u7c7b\u5668\uff0c\u5e76\u4e14\u4ee5\u4e0d\u540c\u7a0b\u5ea6\u7684\u6743\u91cd\u5bf9\u5b83\u4eec\u6267\u884c\u52a0\u6743\u64cd\u4f5c\u3002\u5982\u4e0a\u56fe\u7ea2\u8272\u66f2\u7ebf\u6240\u793a\uff0c\u5bf9\u4e8e\u5177\u6709\u4f4e\u7f6e\u4fe1\u5ea6\u7684ROI\u6a21\u5757\u5728MCD\u635f\u5931\u8ba1\u7b97\u7684\u8fc7\u7a0b\u4e2d\u5206\u914d\u8f83\u9ad8\u7684\u6743\u91cd\uff0cRPN\u4e0eRPC\u4e4b\u95f4\u7684\u5dee\u5f02\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ s^{fg}_{cls}=\\sum_{c\\in C}s^c_{cls}\\\\ L_{discrepancy}(s_{cls},s_{rpn})=|s^{fg}_{cls}-s^{fg}_{rpn}| $$  \u5176\u4e2d\uff0cC\u8868\u793a\u524d\u666f\u7c7b\u522b\u6570\u91cf\uff0cL_{discrepancy}\u8868\u793aRPN\u4e0eRPC\u4e4b\u95f4\u5bf9\u524d\u666f\u9884\u6d4b\u7684\u5dee\u5f02\uff0c\u5373\u5c06\u4e00\u4e2a\u951a\u70b9\u9884\u6d4b\u4e3a\u524d\u666f\u7684\u6982\u7387\u505a\u5dee\u3002\u4e4b\u540e\u5b9a\u4e49\u6743\u91cd\u65b9\u7a0b\u4e3a\uff1a $$ f_w(s_{cls},s_{rpn})=(2min(|s^{fg}_{cls}|,|1-s^{fg}_{cls}|,|s^{fg}_{rpn}|,|1-s^{fg}_{rpn}|))^{\\lambda} $$ f_w(s_{cls},s_{rpn})\uff0c\u5f53s_{cls}^{fg}\u4e0es_{rpn}^{fg}\u5747\u5904\u4e8e0.5\u5de6\u53f3\uff0c\u5373\u4e24\u4e2a\u6a21\u5757\u5bf9\u8be5\u951a\u70b9\u5747\u5177\u6709\u8f83\u5927\u7684\u4e0d\u786e\u5b9a\u6027\u9884\u6d4b\u65f6\uff0c\u4f1a\u5f97\u5230\u8f83\u5927\u7684\u6743\u91cd\uff1b\u5f53\u4e24\u4e2a\u6a21\u5757\u5bf9\u8be5\u951a\u70b9\u7684\u9884\u6d4b\u6709\u4e00\u4e2a\u8d8b\u5411\u4e8e1\u6216\u80050\uff0c\u5219\u4f1a\u5f97\u5230\u8f83\u5c0f\u7684\u6743\u91cd\u3002\u8fd9\u91cc\u5728MCD\u7684\u635f\u5931\u4e2d\u5f15\u5165\u6743\u91cd\u662f\u4e3a\u4e86\u51cf\u8f7bRPN\u9884\u6d4b\u7684\u566a\u70b9\u6240\u5e26\u6765\u7684\u8d1f\u9762\u5f71\u54cd\uff1a $$ L_{MCD}=f_w(s_{cls},s_{rpn})L_{discrepancy}(s_{cls},s_{rpn}) $$  \u5728\u4f18\u5316MCD\u635f\u5931\u7684\u8fc7\u7a0b\u4e2d\uff0c\u7279\u5f81\u63d0\u53d6\u5668F\u5c1d\u8bd5\u6700\u5c0f\u5316\u8be5\u635f\u5931\uff0c\u800cRPN\u4e0eRPC\u5c1d\u8bd5\u6700\u5927\u5316\u8be5\u635f\u5931\u3002</p> <p>\u6ce8\u610f\uff1a\u5728\u8ba1\u7b97MCD\u635f\u5931\u65f6\uff0c\u4f7f\u7528\u7684\u4e24\u4e2a\u5206\u6570\u5747\u662f\u672a\u5207\u65ad\u68af\u5ea6\u7684\u5206\u6570\uff0c\u56e0\u6b64\u8fd9\u91ccMCD\u635f\u5931\u4f1a\u901a\u8fc7RPN\u548cRPC\u7684\u4e24\u4e2a\u9884\u6d4b\u5206\u6570\u6765\u4f18\u5316\u4e24\u4e2a\u6a21\u5757\u7684\u53c2\u6570\uff0c\u4f46\u5728\u8ba1\u7b97\u6743\u91cd\u65f6\u4e0e\u4e4b\u524d\u7684\u60c5\u51b5\u4e00\u6837\uff0c\u90fd\u5207\u65ad\u4e86\u68af\u5ea6\uff0c\u8868\u660e\u8fd9\u91cc\u7684\u6743\u91cd\u53ea\u8d77\u5230\u589e\u52a0\u6216\u51cf\u5c11\u635f\u5931\u7684\u4f5c\u7528\uff0c\u635f\u5931\u4ea7\u751f\u7684\u68af\u5ea6\u5e76\u4e0d\u4f1a\u6cbf\u7740\u6743\u91cd\u7684\u8ba1\u7b97\u8fc7\u7a0b\u53bb\u5f71\u54cdRPN\u4e0eRPC\u3002</p> <p>\u2003\u2003\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u6bcf\u4e2a\u66f2\u7ebf\u8868\u793a\u4e00\u4e2a\u7279\u5b9a\u7684\u5206\u7c7b\u5668\u51b3\u7b56\u8fb9\u754c\uff0c\u4e0e\u5206\u7c7b\u51b3\u7b56\u9762\u76f8\u4ea4\u7684\u6570\u636e\u5f80\u5f80\u662f\u76ee\u6807\u57df\u4e2d\u7684\u6570\u636e\uff0c\u8fd9\u91cc\u5047\u8bbe\u4e24\u4e2a\u51b3\u7b56\u9762\u53ef\u4ee5\u6b63\u786e\u5730\u533a\u5206\u6e90\u57df\u6570\u636e\uff08\u56e0\u4e3a\u6e90\u57df\u6570\u636e\u6709\u6807\u7b7e\uff0c\u56e0\u6b64\u5047\u8bbe\u5177\u6709\u5408\u7406\u6027\uff09\uff0c\u7531\u4e8e\u76ee\u6807\u57df\u6570\u636e\u5728\u5206\u7c7b\u7684\u8fc7\u7a0b\u4e2d\u5177\u6709\u4e0d\u786e\u5b9a\u6027\uff0c\u56e0\u6b64\u76ee\u6807\u57df\u6570\u636e\u5f80\u5f80\u4e0e\u51b3\u7b56\u9762\u76f8\u4ea4\uff0c\u5177\u4f53\u5982\u4e0b\u56fe\u6a59\u8272\u7b26\u53f7\uff0c\u800c\u76f8\u4ea4\u7684\u6837\u672c\u5bb9\u6613\u4ea7\u751f\u9519\u8bef\u7684\u5206\u7c7b\uff0c\u5e76\u4e14\u5dee\u5f02\u533a\u57df\u4e4b\u95f4\u7684\u6570\u636e\u5177\u6709\u8f83\u5927\u7684\u5206\u7c7b\u4e0d\u786e\u5b9a\u6027\uff08\u4e0b\u56fe\u4e2dDiscrepancy for MCD\u4e4b\u95f4\u7684\u533a\u57df\uff09\uff0c\u56e0\u4e3a\u4e24\u4e2a\u5206\u7c7b\u5668\u505a\u51fa\u4e86\u4e0d\u540c\u7684\u51b3\u7b56\u3002\u968f\u7740\u8bad\u7ec3\u7684\u8fdb\u884c\uff0c\u5bf9\u4e8e\u5206\u7c7b\u5668\uff0c\u589e\u5927\u4e24\u4e2a\u9884\u6d4b\u5dee\u5f02\u53ef\u4ee5\u4f7f\u5f97\u51b3\u7b56\u9762\u5411\u6e90\u57df\u9760\u62e2\uff0c\u5373\u589e\u5927\u5dee\u5f02\u533a\u95f4\u7684\u533a\u57df\uff0c\u800c\u5bf9\u4e8e\u7279\u5f81\u63d0\u53d6\u5668\uff0c\u51cf\u5c0f\u5dee\u5f02\u53ef\u4ee5\u4f7f\u5f97\u63d0\u53d6\u5230\u7684\u7279\u5f81\u5411\u6e90\u57df\u9760\u62e2\uff0c\u8fd9\u79cd\u5bf9\u6297\u635f\u5931\u53ef\u4ee5\u8fbe\u5230\u201d\u4e00\u9000\u4e00\u8fdb\u201d\u7684\u8bad\u7ec3\u6548\u679c\u3002\u6700\u7ec8\uff0c\u7279\u5f81\u63d0\u53d6\u5668\u5bf9\u76ee\u6807\u57df\u63d0\u53d6\u5230\u7684\u7279\u5f81\u4f1a\u9010\u6e10\u504f\u5411\u6e90\u57df\u533a\u57df\uff0c\u56e0\u6b64RPN\u4ee5\u53caRPC\u7684\u8f93\u51fa\u53ef\u4ee5\u88ab\u8ba4\u4e3a\u662f\u53ef\u9760\u7684\u4f2a\u6807\u7b7e\u3002MCD\u5177\u4f53\u539f\u7406\u53ef\u4ee5\u89c1\u8bba\u6587\u7b14\u8bb0\u94fe\u63a5\uff0c\u8fd9\u91cc\u5176\u5b9e\u662f\u57df\u9002\u5e94\u5206\u7c7b\u7b97\u6cd5\u5728\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u4e2d\u4e00\u4e2a\u5f88\u597d\u7684\u5e94\u7528\u3002\u6ce8\uff1aMCD\u4e0e\u5229\u7528\u57df\u5224\u522b\u5668\u5bf9\u9f50\u7279\u5f81\u76f8\u6bd4\uff0c\u5f15\u5165\u4e86\u7c7b\u522b\u4fe1\u606f\uff0c\u53ef\u4ee5\u66f4\u597d\u5730\u6267\u884c\u5bf9\u9f50\u3002</p> <p> <p></p> <p></p>"},{"location":"domain_adaptive/paper/CST-MCD1/#rpn","title":"RPN\u6743\u91cd\u5bf9\u9f50","text":"<p>\u2003\u2003\u9886\u57df\u4e4b\u95f4\u7684\u7279\u5f81\u5bf9\u9f50\u65f6\u9886\u57df\u81ea\u9002\u5e94\u7b97\u6cd5\u7ecf\u5e38\u4f7f\u7528\u7684\u57fa\u672c\u7b56\u7565\uff0c\u5728\u672c\u7b97\u6cd5\u4e2d\uff0c\u4f5c\u8005\u540c\u6837\u5f15\u5165\u4e86\u57df\u5224\u522b\u5668\u6765\u5b9e\u73b0\u8de8\u57df\u7279\u5f81\u5bf9\u9f50(\u5982\u7ed3\u6784\u56fe\u4e2d\u7684\u9ec4\u8272\u90e8\u5206)\uff0c\u4ece\u800c\u8fdb\u4e00\u6b65\u7a33\u5b9a\u5e76\u4e14\u8865\u5145\u4e86\u4e4b\u524d\u63d0\u5230\u7684\u534f\u540c\u81ea\u8bad\u7ec3\u7b56\u7565\u3002\u7136\u800c\uff0c\u7531\u4e8e\u76ee\u6807\u68c0\u6d4b\u4e2d\u5bf9\u8c61\u7c7b\u522b\u7ec4\u5408\u7684\u591a\u6837\u6027\u4ee5\u53ca\u573a\u666f\u7684\u590d\u6742\u6027\uff0c\u7b80\u5355\u5730\u5bf9\u6574\u5f20\u56fe\u7247\u6267\u884c\u5bf9\u9f50\u4f1a\u5e26\u6765\u4e00\u5b9a\u7684\u8d1f\u9762\u5f71\u54cd\uff0c\u4e3a\u6b64\uff0c\u4f5c\u8005\u8bbe\u8ba1\u4e86\u4e00\u79cd\u66f4\u4e3a\u7075\u6d3b\u3001\u7cbe\u7ec6\u7684\u7279\u5f81\u5bf9\u9f50\u7b56\u7565\uff0c\u901a\u8fc7\u5229\u7528RPN\u5f97\u5230\u7684\u5206\u6570\u6765\u8ba9\u57df\u5224\u522b\u5668\u4e3b\u8981\u5173\u6ce8\u4e8e\u524d\u666f\u6982\u7387\u8f83\u9ad8\u7684\u533a\u57df\u3002</p> <p>\u2003\u2003\u5177\u4f53\u5730\u6765\u8bf4\uff0c\u4f5c\u8005\u8bbe\u8ba1\u4e86\u4e00\u79cd\u5229\u7528RPN\u52a0\u6743\u7684\u5c40\u90e8\u9886\u57df\u5224\u522b\u5668\uff0c\u5224\u522b\u5668D\u4ee5\u4ece\u4e3b\u5e72\u7f51\u7edc\u5f97\u5230\u7684\u7279\u5f81\u56fe\u4f5c\u4e3a\u8f93\u5165\uff0c\u5047\u8bbe\u7279\u5f81\u56fe\u5c3a\u5bf8\u4e3aH\\times W\\times C\uff0c\u8f93\u51fa\u4e00\u5f20\u5c3a\u5bf8\u4e3aH\\times W\u7684\u9886\u57df\u9884\u6d4b\u56fe\uff0c\u5e76\u4e14\u4ee41\u8868\u793a\u6e90\u57df\uff0c0\u8868\u793a\u76ee\u6807\u57df\uff0c\u56fe\u4e0a\u7684\u6570\u503c\u8868\u793a\u539f\u7279\u5f81\u56fe\u4e0a\u5bf9\u5e94\u50cf\u7d20\u70b9\u7684\u9886\u57df\u9884\u6d4b\u6982\u7387\u3002\u5047\u8bbeRPN\u524d\u666f\u9884\u6d4b\u56fef\u5c3a\u5bf8\u4e3aH\\times W\\times 9\uff0c\u5219\u52a0\u6743\u540e\u7684\u635f\u5931\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ L_{adv_s}=\\frac1{HW}\\sum^W_{w=1}\\sum^H_{h=1}(D(F(x_s))^2_{wh}\\sum^9_{i=1}(f_i)_{wh})\\\\ L_{adv_t}=\\frac1{HW}\\sum^W_{w=1}\\sum^H_{h=1}((1-D(F(x_t))_{wh})^2\\sum^9_{i=1}(f_i)_{wh}) $$  \u5176\u4e2df_i\u8868\u793aRPN\u524d\u666f\u9884\u6d4b\u56fef\u7684\u7b2ci\u4e2a\u901a\u9053\uff0c\u5c3a\u5bf8\u4e3aH\\times W\uff0c\u56fe\u4e0a\u7684\u6570\u503c\u8868\u793a\u6bcf\u4e2a\u4f4d\u7f6e\u5b9a\u4e49\u7684\u7b2ci\u4e2a\u951a\u70b9\u6846\u5c5e\u4e8e\u524d\u666f\u7684\u6982\u7387\uff0c(f_i)_{wh}\u548cD(F(x))_{wh}\u4f9d\u6b21\u8868\u793af_i\u548cD(F(x))\u5728\u4f4d\u7f6e(w,h)\u4e0a\u7684\u5143\u7d20\u3002\u524d\u666f\u9884\u6d4b\u56fef\u5728\u8bad\u7ec3\u521a\u5f00\u59cb\u65f6\u53ef\u80fd\u4f1a\u5f88\u7c97\u7cd9(rough)\uff0c\u5373\u6570\u503c\u53ef\u80fd\u4e0d\u51c6\u786e\uff0c\u4f46\u662f\u4ed6\u4f1a\u968f\u7740\u534f\u540c\u81ea\u8bad\u7ec3\u7684\u8fed\u4ee3\u800c\u4e0d\u65ad\u4f18\u5316\uff0c\u5e76\u4e14\u8be5\u5c40\u90e8\u5bf9\u9f50\u6a21\u5757\u4f1a\u8fdb\u4e00\u6b65\u6210\u4e3a\u534f\u540c\u81ea\u8bad\u7ec3\u5728\u4e3b\u5e72\u7f51\u7edc\u4e2d\u6709\u6548\u7684\u4e92\u8865\u7ec4\u4ef6\u3002</p>"},{"location":"domain_adaptive/paper/CST-MCD1/#_7","title":"\u635f\u5931\u4f18\u5316","text":"<p>\u2003\u2003Faster RCNN\u7684\u521d\u59cb\u68c0\u6d4b\u635f\u5931\u7531RPN\u8ba1\u7b97\u7684\u5b9a\u4f4d\u635f\u5931L_{rpn}\u548cRPC\u8ba1\u7b97\u7684\u5206\u7c7b\u635f\u5931L_{cls}\u6784\u6210\uff0c\u5bf9\u4e8e\u6e90\u57df\u56fe\u50cf\uff0c\u603b\u635f\u5931\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ L_s=L_{rpn}+L_{cls}-L_{adv_s} $$  \u2003\u2003\u5bf9\u4e8e\u76ee\u6807\u57df\u7684\u56fe\u50cf\u7684\u635f\u5931\u7565\u6709\u4e0d\u540c\uff0c\u591a\u4e86\u4e00\u4e2aL_{MCD}\uff0c\u5bf9\u4e8e\u4e3b\u5e72\u7f51\u7edc\u635f\u5931\u548cRPN\u635f\u5931\u5206\u522b\u5b9a\u4e49\u4e3a\uff1a $$ L_{t_{backbone}}=-L_{adv_t}+\\alpha L_{rpn_t}+\\beta L_{cls_t}+\\gamma L_{MCD}\\\\ L_{t_{RPN,RPC}}=\\alpha L_{rpn_t}+\\beta L_{cls_t}-\\gamma L_{MCD} $$  \u56e0\u4e3a\u4e3b\u5e72\u7f51\u7edc\u503e\u5411\u4e8e\u589e\u5927\u57df\u5206\u7c7b\u635f\u5931\uff08\u5229\u7528\u68af\u5ea6\u53cd\u8f6c\u5c42\u5b9e\u73b0\uff09\uff0c\u56e0\u6b64L_{adv}\u7684\u7cfb\u6570\u6211\u5bf9\u539f\u6587\u4fee\u6539\u4e86\u4e00\u4e0b\uff0c\u52a0\u4e86\u4e00\u4e2a\u8d1f\u53f7\u3002</p> <p>\u2003\u2003\u57df\u5224\u522b\u5668\u7684\u635f\u5931\u53ef\u4ee5\u5b9a\u4e49\u4e3a\uff1a $$ L_D=L_{adv_s}+L_{adv_t} $$  \u5176\u4e2d\uff0c\\alpha,\\beta,\\gamma\u8868\u793a\u63a7\u5236\u5404\u4e2a\u7ec4\u4ef6\u7684\u635f\u5931\u6743\u91cd\u3002</p>"},{"location":"domain_adaptive/paper/CST-MCD1/#map","title":"mAP\u5bf9\u6bd4","text":"<p>Cityscape \\rightarrow FoggyCityscape</p> <p> <p></p> <p></p>"},{"location":"domain_adaptive/paper/CST-MCD1/#_8","title":"\u603b\u7ed3","text":"<p>\u2003\u2003\u672c\u6587\u9996\u6b21\u63ed\u793a\u4e86\u4e8c\u9636\u6bb5\u68c0\u6d4b\u5668(\u5982Faster RCNN)\u4e2d\u7684RPN\u3001RPC\u6a21\u5757\u5728\u9762\u4e34\u5927\u7684\u9886\u57df\u95f4\u9699\u65f6\u4f1a\u8868\u73b0\u51fa\u663e\u8457\u4e0d\u540c\u7684\u53ef\u8f6c\u79fb\u6027\uff0c\u57fa\u4e8e\u4e0a\u8ff0\u89c2\u5bdf\uff0c\u4f5c\u8005\u4e3aRPN\u4e0eRPC\u8bbe\u8ba1\u4e86\u534f\u540c\u81ea\u8bad\u7ec3\u7b56\u7565\uff0c\u8ba9\u4ed6\u4eec\u91cd\u70b9\u5173\u6ce8\u5177\u6709\u9ad8\u7f6e\u4fe1\u5ea6\u7684ROI\u3002\u53e6\u5916\uff0c\u8fd8\u8bbe\u8ba1\u4e86\u4e00\u79cd\u6700\u5927\u5dee\u5f02\u5206\u7c7b\u5668\uff0c\u901a\u8fc7\u6709\u6548\u5730\u5229\u7528\u4f4e\u7f6e\u4fe1\u5ea6\u7684ROI\u6765\u8fdb\u4e00\u6b65\u63d0\u9ad8\u68c0\u6d4b\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002</p> <p>\u6ce8\uff1a\u4ee5\u4e0a\u5185\u5bb9\u4ec5\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u6279\u8bc4\u6307\u6b63</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e742\u670826\u65e5</p>"},{"location":"domain_adaptive/paper/Coarse-to-Fine1/","title":"\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\uff1aCoarse-to-Fine","text":""},{"location":"domain_adaptive/paper/Coarse-to-Fine1/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u4e0e\u65f6\u95f4\uff1aIEEE Conference on Computer Vision and Pattern Recognition 2020 (CVPR, 2020)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content_CVPR_2020/papers/Zheng_Cross-domain_Object_Detection_through_Coarse-to-Fine_Feature_Adaptation_CVPR_2020_paper.pdf</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b</p> <p>\u5728\u7f51\u4e0a\u6ca1\u6709\u627e\u5230\u516c\u5f00\u7684\u6e90\u7801\uff0c\u4f46\u662f\u627e\u5230\u4e86\u522b\u4eba\u5199\u7684\u6e90\u7801\u7b14\u8bb0(\u4ee3\u7801\u662f\u5411\u8bba\u6587\u4f5c\u8005\u8981\u7684)\uff0c\u53ef\u4ee5\u53c2\u8003\u4e0b\uff1a\u535a\u5ba2\u94fe\u63a5</p>"},{"location":"domain_adaptive/paper/Coarse-to-Fine1/#_2","title":"\u4e3b\u8981\u601d\u60f3","text":"<p>\u2003\u2003\u73b0\u6709\u7684\u65e0\u76d1\u7763\u9886\u57df\u9002\u5e94\u65b9\u6cd5(Unsupervised Domain Adaptation, UDA)\u5bf9\u89e3\u51b3\u57df\u9002\u5e94\u95ee\u9898\u5177\u6709\u8f83\u597d\u7684\u6548\u679c\uff0c\u901a\u8fc7\u5c06\u57fa\u672c\u77e5\u8bc6\u4ece\u73b0\u6210\u7684\u6807\u8bb0\u9886\u57df(\u6e90\u57df)\u8f6c\u79fb\u5230\u76f8\u5173\u4f46\u662f\u6a21\u578b\u6ca1\u89c1\u8fc7\u7684\u672a\u6807\u8bb0\u9886\u57df(\u76ee\u6807\u57df)\uff0c\u901a\u8fc7\u51cf\u5c11\u8de8\u57df\u5dee\u5f02\u6765\u4f7f\u6a21\u578b\u751f\u6210\u5177\u6709\u9886\u57df\u4e0d\u53d8\u6027\u7684\u7279\u5f81\u8868\u793a\uff0c\u662f\u89e3\u51b3\u6570\u636e\u9886\u57df\u504f\u79fb\u7684\u6709\u6548\u63aa\u65bd\u3002</p> <p>\u2003\u2003\u76f8\u6bd4\u4e8e\u56fe\u50cf\u5206\u7c7b\uff0c\u76ee\u6807\u68c0\u6d4b\u4e2d\u7684\u57df\u9002\u5e94\u95ee\u9898\u66f4\u52a0\u590d\u6742\uff0c\u9700\u8981\u5bf9\u56fe\u50cf\u4e2d\u4e0d\u540c\u76ee\u6807\u7684\u6240\u6709\u5b9e\u4f8b\u8fdb\u884c\u5b9a\u4f4d\u548c\u5206\u6790\u3002\u5728\u4e00\u5f20\u56fe\u7247\u4e2d\uff0c\u901a\u5e38\u6709\u591a\u79cd\u7c7b\u578b\u7684\u68c0\u6d4b\u5bf9\u8c61\uff0c\u5e76\u4e14\u6bcf\u4e2a\u5bf9\u8c61\u90fd\u6709\u81ea\u5df1\u7684\u5206\u5e03\uff0c\u4f46\u662f\u73b0\u6709\u7684\u65b9\u6cd5\u90fd\u5ffd\u7565\u4e86\u8fd9\u4e2a\u5173\u952e\u4fe1\u606f\uff0c\u5982\uff1adomain adaptive Faster R-CNN(\u8bba\u6587\u7b14\u8bb0\u94fe\u63a5)\u3001Strong-Weak feature adaptation(\u8bba\u6587\u7b14\u8bb0\u94fe\u63a5)\u7b49\u7b49\uff0c\u4ed6\u4eec\u90fd\u5c06\u4e0d\u540c\u5bf9\u8c61\u7684\u5206\u5e03\u4f5c\u4e3a\u4e00\u4e2a\u6574\u4f53\u6765\u8fdb\u884c\u6a21\u578b\u81ea\u9002\u5e94\uff0c\u6ca1\u6709\u8003\u8651\u5bf9\u8c61\u4e4b\u95f4\u7684\u5206\u5e03\u5dee\u5f02\u3002</p> <p>\u2003\u2003\u672c\u6587\u4e2d\uff0c\u4f5c\u8005\u9488\u5bf9\u4e0a\u8ff0\u95ee\u9898\u63d0\u51fa\u4e86\u4e00\u4e2a\u7531\u7c97\u5230\u7ec6\u7684\u7279\u5f81\u81ea\u9002\u5e94\u6846\u67b6\u3002\u4e3b\u8981\u601d\u60f3\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u9996\u5148\u8003\u8651\u5230\u4e0d\u540c\u9886\u57df\u4e4b\u95f4\u7684\u524d\u666f\u8981\u6bd4\u80cc\u666f\u5171\u4eab\u66f4\u591a\u7684\u5171\u540c\u7279\u5f81\uff0c\u56e0\u6b64\u63d0\u51fa\u4e86\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u533a\u57df\u8f6c\u6362\u6a21\u5757(Attention-based Region Transfer, ART)\uff0c\u4ee5\u4e00\u79cd\u4e0e\u7c7b\u522b\u65e0\u5173\u7684\u7c97\u7cd9\u65b9\u5f0f\u5de5\u4f5c\uff0c\u6765\u51f8\u663e\u524d\u666f\u4fe1\u606f\u7684\u91cd\u8981\u6027\uff0c\u901a\u8fc7\u5229\u7528\u9ad8\u7ea7\u7279\u5f81\u4e2d\u7684\u6ce8\u610f\u529b\u673a\u5236\u6765\u63d0\u53d6\u611f\u5174\u8da3\u7684\u524d\u666f\u5bf9\u8c61\uff0c\u4e4b\u540e\u5728\u542b\u6709\u524d\u666f\u5bf9\u8c61\u7684\u7279\u5f81\u6570\u636e\u4e2d\u5b9e\u73b0\u5bf9\u9f50\uff0c\u5e76\u4e14\u5728\u591a\u4e2a\u5377\u79ef\u5c42\u4e4b\u95f4\u5e94\u7528\u5bf9\u6297\u6027\u5b66\u4e60\uff0c\u4ece\u800c\u6709\u6548\u5730\u63d0\u9ad8\u6a21\u578b\u7684\u9886\u57df\u9002\u5e94\u80fd\u529b\u3002\u5176\u6b21\uff0c\u5bf9\u8c61\u7684\u7c7b\u522b\u4fe1\u606f\u53ef\u4ee5\u8fdb\u4e00\u6b65\u7ec6\u5316\u5148\u524d\u7684\u7279\u5f81\u9002\u5e94\uff0c\u56e0\u6b64\u6709\u5fc5\u8981\u8ba9\u6a21\u578b\u80fd\u591f\u533a\u5206\u4e0d\u540c\u79cd\u7c7b\u7684\u524d\u666f\u5bf9\u8c61\uff0c\u5bf9\u6bcf\u4e2a\u7c7b\u522b\u6267\u884c\u4e0d\u540c\u7684\u7279\u5f81\u9002\u5e94\u3002\u4f46\u662f\u5982\u679c\u76f4\u63a5\u4e3a\u6240\u6709\u7c7b\u522b\u90fd\u8bad\u7ec3\u4e00\u4e2a\u57df\u5206\u7c7b\u5668\u7684\u8bdd\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5bb9\u6613\u5bfc\u81f4\u5bf9\u8c61\u5339\u914d\u9519\u8bef(\u5177\u4f53\u539f\u56e0\u53ef\u89c1\u4e0b\u6587\u7684\u5206\u6790)\uff0c\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u539f\u578b\u7684\u8bed\u4e49\u5bf9\u9f50\u6a21\u5757\u6765\u4e3a\u8de8\u57df\u7684\u6bcf\u4e2a\u7c7b\u522b\u6784\u5efa\u5168\u5c40\u539f\u578b\uff0c\u5168\u5c40\u539f\u578b\u5728\u6bcf\u6b21\u8fed\u4ee3\u4e2d\u81ea\u9002\u5e94\u5730\u66f4\u65b0\uff0c\u56e0\u6b64\u53ef\u4ee5\u6291\u5236\u9519\u8bef\u6807\u7b7e\u9884\u6d4b\u4ee5\u53ca\u9519\u8bef\u7c7b\u522b\u5339\u914d\u6240\u5e26\u6765\u7684\u8d1f\u9762\u5f71\u54cd\u3002</p> <p> <p></p> <p></p>"},{"location":"domain_adaptive/paper/Coarse-to-Fine1/#_3","title":"\u65b9\u6cd5","text":""},{"location":"domain_adaptive/paper/Coarse-to-Fine1/#_4","title":"\u53c2\u6570\u5b9a\u4e49","text":"<p>\u2003\u2003\u5728\u8de8\u57df\u76ee\u6807\u68c0\u6d4b\u4e2d\uff0c\u5c06\u7ed9\u5b9a\u6807\u7b7e\u7684\u6e90\u57df\u6570\u636e\u5b9a\u4e49\u4e3a\\mathcal D_S=\\{(x_i^s,y_i^s)\\}^{N_s}_{i=1}\uff0c\u5176\u4e2dx_i^s\u548cy_i^s=(b_i^s,c_i^s)\u4f9d\u6b21\u8868\u793a\u4e3a\u7b2ci\u5f20\u56fe\u7247\u548c\u5bf9\u5e94\u7684\u6807\u7b7e\uff0c\u6807\u7b7e\u5305\u542b\u8fb9\u754c\u6846\u4fe1\u606fb\u548c\u7c7b\u522b\u6807\u7b7ec\uff0c\u5c06\u4e0d\u542b\u6807\u7b7e\u7684\u76ee\u6807\u57df\u6570\u636e\u5b9a\u4e49\u4e3a\\mathcal D_T=\\{x_i^t\\}^{N_t}_{i=1}\uff0c\u5047\u8bbe\u6e90\u57df\u548c\u76ee\u6807\u57df\u6837\u672c\u5177\u6709\u4e0d\u540c\u7684\u6570\u636e\u5206\u5e03(\u5982\uff1a\\mathcal D_S\\neq\\mathcal D_T)\u4f46\u662f\u5177\u6709\u76f8\u540c\u7684\u7269\u4f53\u68c0\u6d4b\u7c7b\u522b\uff0c\u7b97\u6cd5\u76ee\u6807\u5c31\u662f\u4e3a\u4e86\u4f7f\u7528\\mathcal D_S\u53bb\u63d0\u9ad8\u5728\\mathcal D_T\u4e2d\u7684\u68c0\u6d4b\u6027\u80fd\u3002</p>"},{"location":"domain_adaptive/paper/Coarse-to-Fine1/#_5","title":"\u7f51\u7edc\u6846\u67b6","text":"<p>\u2003\u2003\u7f51\u7edc\u6846\u67b6\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u8be5\u6846\u67b6\u7531\u4e00\u4e2a\u76ee\u6807\u68c0\u6d4b\u7f51\u7edc\u548c\u4e24\u4e2a\u57df\u9002\u5e94\u6a21\u5757\u6784\u6210\uff1a</p> <p> <p></p> <p></p> <p> \u76ee\u6807\u68c0\u6d4b\u7f51\u7edc\uff1a\u4f5c\u8005\u9009\u53d6\u4e86Faster R-CNN\u6a21\u578b\u6765\u5f53\u505a\u57fa\u7840\u7684\u68c0\u6d4b\u6a21\u578b\uff0cFaster R-CNN\u662f\u4e00\u4e2a\u4e8c\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\u5668\uff0c\u4e3b\u8981\u7531\u4e09\u4e2a\u7ec4\u4ef6\u6784\u6210\uff1a\u2460\u57fa\u7840\u7684\u7279\u5f81\u63d0\u53d6\u7f51\u7edcG\uff1b\u2461\u533a\u57df\u63d0\u8bae\u7f51\u7edc(Region Proposal Network, RPN)\uff0c\u7528\u4e8e\u9884\u6d4b\u5bf9\u8c61\u7684\u8fb9\u754c\u6846\u548c\u6846\u5185\u5b58\u5728\u7269\u4f53\u7684\u6982\u7387\uff1b\u2462\u611f\u5174\u8da3\u533a\u57df\u68c0\u6d4b\u6a21\u5757(Region-of-Interest, ROI)\uff0c\u7528\u4e8e\u8fdb\u4e00\u6b65\u7ec6\u5316\u8fb9\u754c\u6846\u7684\u56de\u5f52\u5668B\u548c\u7269\u4f53\u5206\u7c7b\u5668C\uff0cFaster R-CNN\u603b\u635f\u5931\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ \\mathcal L_{det}(x)=\\mathcal L_{rpn}+\\mathcal L_{reg}+\\mathcal L_{cls} $$  \u5176\u4e2d\uff0c\\mathcal L_{rpn},\\mathcal L_{reg}\u548c\\mathcal L_{cls}\u4f9d\u6b21\u8868\u793aRPN\u3001ROI\u8fb9\u754c\u6846\u56de\u5f52\u5668\u3001ROI\u7269\u4f53\u5206\u7c7b\u5668\u7684\u635f\u5931\u3002</p> <p> \u81ea\u9002\u5e94\u6a21\u5757\uff1a\u4e0d\u540c\u4e8e\u73b0\u6709\u5728\u6574\u4e2a\u7279\u5f81\u7a7a\u95f4\u964d\u4f4e\u57df\u504f\u79fb\u7684\u7814\u7a76\uff0c\u8003\u8651\u5230\u524d\u666f\u53ef\u4ee5\u5171\u4eab\u66f4\u591a\u7684\u8de8\u57df\u4fe1\u606f\uff0c\u4f5c\u8005\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u533a\u57df\u8f6c\u6362\u6a21\u5757(ART)\uff1b\u5e76\u4e14\u8fd8\u8003\u8651\u5230\u7c7b\u522b\u4fe1\u606f\u6709\u52a9\u4e8e\u57df\u9002\u5e94\u4efb\u52a1\uff0c\u901a\u8fc7\u7a81\u51fa\u6bcf\u4e2a\u7c7b\u522b\u7684\u5206\u5e03\u53ef\u4ee5\u8fdb\u4e00\u6b65\u7ec6\u5316\u7279\u5f81\u7684\u5bf9\u9f50\uff0c\u56e0\u6b64\u4f5c\u8005\u53c8\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u539f\u578b\u7684\u8bed\u4e49\u5bf9\u9f50\u6a21\u5757(PSA)\uff0c\u4e24\u4e2a\u6a21\u5757\u76f8\u7ed3\u5408\u53ef\u4ee5\u5b9e\u73b0\u524d\u666f\u4fe1\u606f\u7531\u7c97\u5230\u7ec6\u7684\u77e5\u8bc6\u8fc1\u79fb\u3002</p>"},{"location":"domain_adaptive/paper/Coarse-to-Fine1/#_6","title":"\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u533a\u57df\u8f6c\u6362","text":"<p>\u2003\u2003ART\u6a21\u5757\u7528\u4e8e\u63d0\u9ad8\u7f51\u7edc\u5bf9\u524d\u666f\u533a\u57df\u5185\u8de8\u57df\u5206\u5e03\u7684\u5173\u6ce8\u529b\u5ea6\uff0c\u4e3b\u8981\u7531\u4e24\u90e8\u5206\u7ec4\u6210\uff1a\u9886\u57df\u5206\u7c7b\u5668\u548c\u6ce8\u610f\u529b\u673a\u5236\u3002    </p> <p>\u2003\u2003\u4e3a\u4e86\u5bf9\u9f50\u8de8\u57df\u7684\u7279\u5f81\u5206\u5e03\uff0c\u4f5c\u8005\u5c06\u4e09\u4e2a\u57df\u5206\u7c7b\u5668D\u5206\u522b\u5d4c\u5165\u5230\u7279\u5f81\u63d0\u53d6\u7f51\u7edcG\u4e2d\u540e\u4e09\u4e2a\u9636\u6bb5\u7684\u5377\u79ef\u6a21\u5757\uff0c\u4e0e\u4e4b\u524d\u7684\u7814\u7a76\u5de5\u4f5c\u4e00\u6837\uff0c\u57df\u5206\u7c7b\u5668D\u5c1d\u8bd5\u533a\u5206\u9886\u57df\u7279\u5f81\uff0c\u540c\u65f6\u7279\u5f81\u63d0\u53d6\u7f51\u7edcG\u5c1d\u8bd5\u6df7\u6dc6\u57df\u5206\u7c7b\u5668\u7684\u5224\u65ad\u3002\u5b9e\u65bd\u8fc7\u7a0b\u4e2d\uff0cG\u548cD\u901a\u8fc7\u68af\u5ea6\u53cd\u8f6c\u5c42( Gradient Reverse Layer, GRL)\u8fde\u63a5\uff0c\u4f7f\u6d41\u7ecfG\u7684\u68af\u5ea6\u53cd\u8f6c\uff0c\u5f53\u8bad\u7ec3\u8fc7\u7a0b\u6536\u655b\u65f6\uff0cG\u8d8b\u5411\u4e8e\u63d0\u53d6\u57df\u4e0d\u53d8\u7684\u7279\u5f81\u8868\u793a\u3002\u5f62\u5f0f\u4e0a\uff0c\u7b2cl\u4e2a\u5377\u79ef\u6a21\u5757\u4e2d\u7684\u5bf9\u6297\u6027\u5b66\u4e60\u76ee\u6807\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ \\mathcal L_{ADV}^l=\\min_{\\theta_{G_l}}\\max_{\\theta_{D_l}}\\mathbb E_{x_s\\sim\\mathcal D_S}\\log D_l(G_l(x_s))+E_{x_t\\sim\\mathcal D_T}\\log D_l(G_l(x_t)) $$  \u5176\u4e2d\uff0c\\theta_{G_l}\u548c\\theta_{D_l}\u4f9d\u6b21\u8868\u793aG_l\u548cD_l\u7684\u53c2\u6570\uff0cD_L(\u00b7)^{(h,w)}\u8868\u793a\u5728\u4f4d\u7f6e\u4e3a(h,w)\u5904\u7684\u7279\u5f81\u9884\u6d4b\u4e3a\u6e90\u57df\u6570\u636e\u7684\u6982\u7387\u3002</p> <p>\u2003\u2003\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u901a\u5e38\u9700\u8981\u5b9a\u4f4d\u548c\u5206\u7c7b\u5bf9\u8c61\uff0c\u56e0\u6b64\u611f\u5174\u8da3\u7684\u524d\u666f\u533a\u57df\u4fe1\u606f\u901a\u5e38\u8981\u6bd4\u80cc\u666f\u4fe1\u606f\u91cd\u8981\uff0c\u4f46\u662f\u5982\u679c\u57df\u5206\u7c7b\u5668\u5728\u6ca1\u6709\u805a\u7126\u7684\u60c5\u51b5\u4e0b\u5bf9\u9f50\u6574\u4e2a\u56fe\u7247\u6240\u6709\u7a7a\u95f4\u4f4d\u7f6e\u7684\u7279\u5f81\uff0c\u53ef\u80fd\u4f1a\u964d\u4f4e\u6a21\u578b\u81ea\u9002\u5e94\u7684\u6027\u80fd\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u53ef\u4ee5\u5229\u7528\u6ce8\u610f\u529b\u673a\u5236\u6765\u5b9e\u73b0\u524d\u666f\u611f\u77e5\u7684\u5206\u5e03\u5bf9\u9f50\uff0c\u5728Faster R-CNN\u4e2d\uff0cRPN\u6a21\u5757\u5c31\u5145\u5f53\u6ce8\u610f\u529b\u7684\u4f5c\u7528\uff0c\u4ed6\u544a\u8bc9\u68c0\u6d4b\u6a21\u5e94\u8be5\u5f80\u54ea\u91cc\u770b\uff0c\u56e0\u6b64\u81ea\u7136\u5c31\u60f3\u5230\u5229\u7528RPN\u6a21\u5757\u4e2d\u7684\u9ad8\u6c34\u5e73\u7279\u5f81\u751f\u6210\u6ce8\u610f\u529b\u56fe\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u7ed9\u5b9a\u4e00\u5f20\u6765\u81ea\u4efb\u610f\u57df\u7684\u56fe\u7247x\uff0c\u5c06RPN\u6a21\u5757\u5377\u79ef\u5c42\u8f93\u51fa\u7684\u7279\u5f81\u8868\u793a\u4e3aF_{rpn}(x)\\in\\mathbb R^{H\\times W\\times C}\uff0c\u5176\u4e2dH\\times W\u548cC\u5206\u522b\u8868\u793a\u7279\u5f81\u56fe\u7684\u7a7a\u95f4\u7ef4\u5ea6\u548c\u901a\u9053\u6570\u3002\u4e4b\u540e\u518d\u901a\u8fc7\u5728\u901a\u9053\u7ef4\u5ea6\u4e0a\u5bf9\u6fc0\u6d3b\u503c\u505a\u4e00\u4e2a\u5e73\u5747\u64cd\u4f5c\uff0c\u6765\u6784\u5efa\u7a7a\u95f4\u6ce8\u610f\u529b\u56fe\u3002\u6700\u540e\u5728\u8ba1\u7b97\u4e00\u4e2a\u9608\u503c\uff0c\u5c06\u7a7a\u95f4\u6ce8\u610f\u529b\u56fe\u4e0a\u5c0f\u4e8e\u9608\u503c\u7684\u6570\u636e\u8fc7\u6ee4\u6389(\u8bbe\u7f6e\u4e3a\u96f6)\uff0c\u56e0\u4e3a\u4ed6\u4eec\u66f4\u53ef\u80fd\u5c5e\u4e8e\u80cc\u666f\u533a\u57df\u3002</p> <p> <p></p> <p></p> <p>\u6700\u7ec8\u6ce8\u610f\u529b\u56feA(x)\\in\\mathbb R^{H\\times W}\u7684\u8ba1\u7b97\u516c\u5f0f\u5982\u4e0b\uff1a $$ M(x)=S(\\frac1C\\sum_c|F^c_{rpn}(x)|)\\\\ T(x)=\\frac1{HW}\\sum_{h,w}M(x)^(h,w)\\\\ A(x)=I(M(x)&gt;T(x))\\otimes M(x) $$  \u5176\u4e2d\uff0cM(x)\u8868\u793a\u8fc7\u6ee4\u4e4b\u524d\u7684\u6ce8\u610f\u529b\u56fe\uff0cS(\u00b7)\u8868\u793aSigmoid\u6fc0\u6d3b\u51fd\u6570\uff0cF^c_{rpn}(x)\u8868\u793a\u7b2cc\u4e2a\u901a\u9053\u7684\u7279\u5f81\u56fe\uff0c\\otimes\u8868\u793a\u5143\u7d20\u70b9\u4e58\u64cd\u4f5c\uff0c\u9608\u503cT(x)\u4e3a\u521d\u59cb\u6ce8\u610f\u529b\u56feM(x)\u7684\u5747\u503c\u3002</p> <p>\u2003\u2003\u7531\u4e8e\u5f97\u5230\u7684\u6ce8\u610f\u529b\u56fe\u4e0e\u4e0d\u540c\u7684\u5377\u79ef\u5757\u4e2d\u7684\u7279\u5f81\u6570\u636e\u5c3a\u5bf8\u4e0d\u517c\u5bb9\uff0c\u5373\u7279\u5f81\u56fe\u5c3a\u5bf8\u6709\u53ef\u80fd\u6bd4\u6ce8\u610f\u529b\u56fe\u5c3a\u5bf8\u5927\uff0c\u56e0\u6b64\u4f5c\u8005\u91c7\u7528\u53cc\u7ebf\u6027\u63d2\u503c\u5bf9\u6ce8\u610f\u529b\u56fe\u8fdb\u884c\u4e0a\u91c7\u6837\u64cd\u4f5c\uff0c\u4e3a\u6bcf\u4e2a\u5377\u79ef\u5757\u4ea7\u751f\u4e00\u4e2a\u5bf9\u5e94\u7684\u6ce8\u610f\u529b\u56fe\u3002\u7531\u4e8e\u6ce8\u610f\u529b\u56fe\u53ef\u80fd\u4e0d\u662f\u90a3\u4e48\u51c6\u786e\uff0c\u5982\u679c\u524d\u666f\u533a\u57df\u88ab\u8bef\u8ba4\u4e3a\u662f\u80cc\u666f\uff0c\u5176\u6ce8\u610f\u529b\u6743\u91cd\u88ab\u8bbe\u7f6e\u4e3a\u96f6\uff0c\u5e76\u4e0d\u80fd\u6709\u52a9\u4e8e\u6a21\u578b\u7684\u81ea\u9002\u5e94\u3002\u4f5c\u8005\u53d7\u6b8b\u5dee\u6ce8\u610f\u529b\u7f51\u7edc\u7684\u542f\u53d1(\u8bba\u6587\u94fe\u63a5)\uff0c\u5728\u6ce8\u610f\u529b\u56fe\u4e2d\u5f15\u5165\u4e86\u8df3\u8dc3\u8fde\u63a5\u4ee5\u589e\u5f3a\u5176\u6027\u80fd\u3002</p> <p>\u2003\u2003ART\u6a21\u5757\u7684\u5b66\u4e60\u76ee\u6807\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ \\mathcal L_{ART}=\\sum_{l,h.w}(1+U_l(A(x)^{(h,w)}))\u00b7\\mathcal L_{ADV}^{l,h,w} $$  \u5176\u4e2d\uff0cU_l(\u00b7)\u4e3a\u4e0a\u91c7\u6837\u64cd\u4f5c\uff0c\\mathcal L_{ADV}^{l,h,w}\u8868\u793a\u4f4d\u4e8e\u7b2cl\u4e2a\u5377\u79ef\u5757\u5e76\u4e14\u4f4d\u7f6e\u4e3a(h,w)\u7684\u5bf9\u6297\u635f\u5931\u3002\u901a\u8fc7\u5c06\u6ce8\u610f\u529b\u673a\u5236\u548c\u5bf9\u6297\u6027\u5b66\u4e60\u76f8\u7ed3\u5408\uff0cART\u6a21\u5757\u53ef\u4ee5\u5bf9\u9f50\u5bf9\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u66f4\u6709\u7528\u7684\u524d\u666f\u7279\u5f81\u3002</p>"},{"location":"domain_adaptive/paper/Coarse-to-Fine1/#_7","title":"\u57fa\u4e8e\u539f\u578b\u7684\u8bed\u4e49\u5bf9\u9f50","text":"<p>\u2003\u2003\u56e0\u4e3a\u6765\u81eaRPN\u6a21\u5757\u7684\u6ce8\u610f\u529b\u56fe\u4e0d\u643a\u5e26\u5173\u4e8e\u7c7b\u522b\u7684\u4fe1\u606f\uff0c\u56e0\u6b64ART\u6a21\u5757\u4ee5\u7c7b\u522b\u672a\u77e5\u7684\u65b9\u5f0f\u5bf9\u9f50\u524d\u666f\u7684\u7279\u5f81\u5206\u5e03\u3002\u4e3a\u4e86\u5b9e\u73b0\u7c7b\u611f\u77e5\u8bed\u4e49\u5bf9\u9f50\uff0c\u4e00\u4e2a\u7b80\u5355\u7684\u65b9\u6cd5\u5c31\u662f\u4e3a\u6bcf\u4e2a\u7c7b\u522b\u8bad\u7ec3\u9886\u57df\u5206\u7c7b\u5668\u3002\u7136\u540e\uff0c\u76f4\u63a5\u8fd9\u6837\u505a\u7684\u8bdd\u4f1a\u6709\u4e24\u4e2a\u7f3a\u70b9\uff1a\u2460\u8bad\u7ec3\u591a\u4e2a\u7c7b\u522b\u7279\u5b9a\u7684\u5206\u7c7b\u5668\u662f\u4f4e\u6548\u7684\uff1b\u2461\u5982\u679c\u76ee\u6807\u57df\u4e2d\u51fa\u73b0\u9519\u8bef\u7684\u9884\u6d4b\u4fe1\u606f(\u5982\u80cc\u666f\u6216\u8005\u5206\u7c7b\u9519\u8bef\u7684\u524d\u666f)\uff0c\u53ef\u80fd\u4f1a\u5f71\u54cd\u5230\u540e\u7eed\u8bed\u4e49\u5bf9\u9f50\u7684\u6027\u80fd\u3002</p> <p>\u2003\u2003\u53d7\u5230\u5c11\u6837\u672c\u5b66\u4e60\u4e2d\u7684\u57fa\u4e8e\u539f\u578b\u7f51\u7edc\u7684\u65b9\u6cd5\u7684\u542f\u53d1(\u8bba\u6587\u94fe\u63a5)\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86PSA\u6a21\u5757\u6765\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898\u3002\u9884\u5236\u4ef6\u8bad\u7ec3\u57df\u5206\u7c7b\u5668\u4e0d\u540c\uff0cPSA\u5c1d\u8bd5\u8de8\u57df\u6700\u5c0f\u5316\u5177\u6709\u76f8\u540c\u7c7b\u522b\u7684\u4e00\u5bf9\u539f\u578b(P^S_k,P_k^T)\uff0c\u4ece\u800c\u4fdd\u5b58\u7279\u5f81\u7a7a\u95f4\u4e2d\u7684\u8bed\u4e49\u4e00\u81f4\u6027\uff0c\u5f62\u5f0f\u4e0a\uff0c\u539f\u578b\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ P^S_k=\\frac1{|GT_k|}\\sum_{r\\in GT_k}F(r)\\\\ P^T_k=\\frac1{|RoI_k|}\\sum_{r\\in RoI_k}F(r) $$  \u5176\u4e2d\uff0cP^S_k\u548cP_k^T\u4f9d\u6b21\u8868\u793a\u7b2ck\u7c7b\u7684\u6e90\u57df\u548c\u76ee\u6807\u57df\u539f\u578b\uff0cF(r)\u8868\u793a\u524d\u666f\u533a\u57dfr\u5728ROI\u4e2d\u7b2c\u4e8c\u4e2a\u5168\u8fde\u63a5\u5c42(FC)\u4e4b\u540e\u7684\u7279\u5f81\uff0c\u5177\u4f53\u53ef\u89c1\u7f51\u7edc\u7ed3\u6784\u56fe\uff0c|\u00b7|\u8868\u793a\u533a\u57df\u6570\u91cf\u3002\u4f7f\u7528\u771f\u5b9e\u6807\u7b7eGT_k\u53bb\u63d0\u53d6\u6e90\u57df\u4e2d\u7684\u524d\u666f\u533a\u57df\u6570\u636e\uff0c\u7531\u4e8e\u76ee\u6807\u57df\u6570\u636e\u7f3a\u5c11\u6807\u7b7e\uff0c\u56e0\u6b64\u4f7f\u7528ROI head\u6a21\u5757\u63d0\u4f9b\u7684ROI_k\u4f5c\u4e3a\u76ee\u6807\u57df\u4e2d\u7684\u4f2a\u6807\u7b7e\uff0c\u5229\u7528\u9884\u6d4b\u7684\u8fb9\u754c\u6846\u63d0\u53d6\u524d\u666f\u533a\u57df\u6570\u636e\u3002</p> <p>\u2003\u2003\u6ce8\uff1a\u8fd9\u91cc\u76f8\u5f53\u4e8e\u5229\u7528\u8fb9\u754c\u6846\uff0c\u5c06\u6bcf\u4e00\u7c7b\u7269\u4f53\u524d\u666f\u7684\u7279\u5f81\u6570\u636e\u63d0\u53d6\u51fa\u6765\uff0c\u4e4b\u540e\u6c42\u4e00\u4e2a\u5e73\u5747\u503c\u4f5c\u4e3a\u8be5\u7c7b\u7684\u539f\u578b\uff0c\u4f5c\u4e3a\u7c7b\u522b\u7279\u5f81\u7684\u5e73\u5747\u503c\uff0c\u539f\u578b\u53ef\u4ee5\u5f88\u597d\u7684\u53cd\u5e94\u6bcf\u4e00\u7c7b\u6574\u4f53\u7684\u7279\u5f81\u60c5\u51b5\u3002\u6e90\u57df\u6570\u636e\u7531\u4e8e\u6709\u6807\u51c6\u7684\u8fb9\u754c\u6846(\u5373\u6807\u7b7e)\uff0c\u56e0\u6b64\u53ef\u4ee5\u5229\u7528\u6807\u51c6\u8fb9\u754c\u6846\u5bf9\u76ee\u6807\u7279\u5f81\u505a\u88c1\u526a\uff0c\u6c42\u5e73\u5747\u4e4b\u540e\u5f97\u5230\u6807\u51c6\u7684\u7c7b\u522b\u7279\u5f81\uff0c\u76ee\u6807\u57df\u6570\u636e\u7f3a\u5c11\u8fb9\u754c\u6846\u6807\u7b7e\uff0c\u56e0\u6b64\u53ea\u80fd\u5229\u7528\u68c0\u6d4b\u6a21\u578b\u5f97\u5230\u7684\u76ee\u6807\u7279\u5f81\u6765\u6c42\u7c7b\u522b\u539f\u578b\uff0c\u7531\u4e8e\u662f\u6a21\u578b\u9884\u6d4b\u5f97\u5230\u7684\uff0c\u56e0\u6b64\u79f0\u4e3a\u4f2a\u6807\u7b7e\u3002</p> <p>\u2003\u2003\u4f7f\u7528\u539f\u578b\u5177\u6709\u4e24\u4e2a\u597d\u5904\uff1a\u2460\u539f\u578b\u4e0d\u9700\u8981\u989d\u5916\u7684\u8bad\u7ec3\u53c2\u6570\uff0c\u5e76\u4e14\u8ba1\u7b97\u91cf\u5c0f\uff1b\u2461\u5f53\u751f\u6210\u539f\u578b\u65f6\uff0c\u9519\u8bef\u7684\u4f2a\u6807\u7b7e\u4ea7\u751f\u7684\u8d1f\u5f71\u54cd\u53ef\u4ee5\u88ab\u6570\u91cf\u8f83\u5927\u7684\u6b63\u786e\u4f2a\u6807\u7b7e\u6240\u6291\u5236\u3002\u9700\u6ce8\u610f\u7684\u662f\uff0c\u4e0a\u9762\u7684\u539f\u578b\u662f\u5efa\u7acb\u5728\u6240\u6709\u6837\u672c\u4e4b\u4e0a\u7684\uff0c\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u7684batch\u7684\u5c3a\u5bf8\u901a\u5e38\u5f88\u5c0f\uff0c\u540c\u4e00\u6279\u6b21\u6e90\u57df\u56fe\u50cf\u548c\u76ee\u6807\u57df\u56fe\u50cf\u7684\u524d\u666f\u5bf9\u8c61\u53ef\u80fd\u5177\u6709\u4e0d\u4e00\u81f4\u7684\u7c7b\u522b\uff0c\u5728\u4e00\u4e2a\u6279\u6b21\u4e2d\u5bf9\u9f50\u5f53\u524d\u6279\u6b21\u7684\u6240\u6709\u7c7b\u522b\u53ef\u80fd\u4e0d\u592a\u5408\u9002\u3002\u4e3e\u4f8b\u6765\u8bf4\uff1a\u968f\u673a\u9009\u62e9\u4e24\u5e45\u56fe\u50cf(\u6bcf\u4e2a\u9886\u57df\u4e00\u5f20)\u8fdb\u884c\u8bad\u7ec3\uff0c\u4f46\u662f\u201d\u6c7d\u8f66\u201d\u8fd9\u4e00\u5bf9\u8c61\u4ec5\u51fa\u73b0\u5728\u6e90\u57df\u56fe\u50cf\u4e2d\uff0c\u76ee\u6807\u57df\u56fe\u50cf\u672a\u51fa\u73b0\u8f66\uff0c\u56e0\u6b64\u5728\u8fd9\u4e00\u6279\u6b21\u4e2d\u65e0\u6cd5\u8de8\u57df\u5bf9\u9f50\u6c7d\u8f66\u539f\u578b\u3002</p> <p>\u2003\u2003\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4f5c\u8005\u52a8\u6001\u5730\u7ef4\u62a4\u5168\u5c40\u539f\u578b\uff0c\u5728\u6bcf\u4e2a\u5c0f\u6279\u91cf\u4e2d\u7531\u672c\u5730\u539f\u578b\u81ea\u9002\u5e94\u5730\u8fdb\u884c\u66f4\u65b0\uff0c\u8fd9\u79cd\u66f4\u65b0\u4e0e\u4f18\u5316\u5668\u4e2d\u7684\u52a8\u91cf\u66f4\u65b0\u7c7b\u4f3c\uff1a $$ \\alpha=sim(P_k^{(i)},GP_k^{(i-1)})\\\\ GP_k^{(i)}=\\alpha P_k^{(i)}+(1-\\alpha)GP_k^{(i-1)} $$  \u5176\u4e2d\uff0csim(x_1,x_2)=(\\frac{x_1^T\u00b7x_2}{||x_1||||x_2||}+1)/2\u8868\u793a\u4f59\u5f26\u76f8\u4f3c\u6027\uff0cP_k^{(i)}\u4ee3\u8868\u7b2ci\u6b21\u8fed\u4ee3\u7b2ck\u7c7b\u7684\u5c40\u90e8\u539f\u578b\u3002\u6ce8\u610f\uff0c\u7531\u4e8e\u76ee\u6807\u57df\u9700\u8981\u901a\u8fc7\u9884\u6d4b\u6765\u83b7\u5f97\u539f\u578b\uff0c\u4f46\u8bad\u7ec3\u521d\u59cb\u9636\u6bb5\u6a21\u578b\u7684\u9884\u6d4b\u662f\u4e0d\u51c6\u786e\u7684\uff0c\u56e0\u6b64\u5728\u8bad\u7ec3\u521d\u671f\u9700\u8981\u5148\u5ffd\u7565PSA\uff0c\u5230\u4e86\u8bad\u7ec3\u4e2d\u671f\u518d\u542f\u7528\u8be5\u6a21\u5757\uff0c\u4f5c\u8005\u5728\u5b9e\u9a8c\u4e2d\u7ecf\u8fc7\u4e865000\u6b21\u8fed\u4ee3\u540e\u624d\u8d77\u7528\u7684PSA\u6a21\u5757\u3002</p> <p>\u2003\u2003\u6700\u540e\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u6e90\u57df\u5168\u5c40\u539f\u578bGP_k^S\u548c\u76ee\u6807\u57df\u5168\u5c40\u539f\u578bGP^T_k\u4e4b\u95f4\u7684L_2\u8ddd\u79bb\u6765\u5b9e\u73b0\u8bed\u4e49\u7684\u5bf9\u9f50\u3002PSA\u6a21\u5757\u7b2ci\u6b21\u8fed\u4ee3\u7684\u4f18\u5316\u76ee\u6807\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ \\mathcal L_{PSA}=\\sum_k||GP_k^{S(i)}-GP_k^{T(i)}||^2 $$ </p>"},{"location":"domain_adaptive/paper/Coarse-to-Fine1/#_8","title":"\u7f51\u7edc\u7684\u4f18\u5316","text":"<p>\u2003\u2003\u8be5\u7b97\u6cd5\u6846\u67b6\u7684\u8bad\u7ec3\u8fc7\u7a0b\u4e3b\u8981\u96c6\u6210\u4e86\u4e09\u4e2a\u7ec4\u4ef6\uff0c\u5177\u4f53\u53ef\u89c1\u5982\u4e0b\u6d41\u7a0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <ul> <li>\u76d1\u7763\u5b66\u4e60(Supervised Learning)\uff1a\u7528\u4e8e\u76d1\u7763\u76ee\u6807\u68c0\u6d4b\u635f\u5931\\mathcal L_{det}\uff0c\u4ec5\u7528\u4e8e\u5e26\u6709\u6807\u7b7e\u7684\u6e90\u57df\u6570\u636e\\mathcal D_S\u3002</li> <li>\u7531\u7c97\u5230\u7ec6\u7684\u81ea\u9002\u5e94(Coarse-grained Adaptation)\uff1a\u4f7f\u7528\u6ce8\u610f\u529b\u673a\u5236\u53bb\u63d0\u53d6\u56fe\u7247\u4e2d\u7684\u524d\u666f\u4fe1\u606f\uff0c\u4e4b\u540e\u901a\u8fc7\u4f18\u5316\\mathcal L_{ART}\u6765\u4f7f\u6a21\u578b\u805a\u7126\u4e8e\u5bf9\u9f50\u8fd9\u4e9b\u533a\u57df\u7684\u7279\u5f81\u3002</li> <li>\u7ec6\u7c92\u5ea6\u81ea\u9002\u5e94(Fine-grained Adaptation)\uff1a\u9996\u5148\uff0c\u5728\u76ee\u6807\u57df\u4e2d\u9884\u6d4b\u4f2a\u6807\u7b7e\uff0c\u4e4b\u540e\u8fdb\u4e00\u6b65\u81ea\u9002\u5e94\u5730\u66f4\u65b0\u6bcf\u4e2a\u7c7b\u522b\u7684\u5168\u5c40\u539f\u578b\uff0c\u6700\u540e\u901a\u8fc7\u4f18\u5316\\mathcal L_{PSA}\u6765\u5b9e\u73b0\u524d\u666f\u5bf9\u8c61\u7684\u8bed\u4e49\u5bf9\u9f50\u3002</li> </ul> <p>\u603b\u7684\u4f18\u5316\u76ee\u6807\u4e3a\uff1a $$ \\mathcal L_{total}=\\mathcal L_{det}+\\lambda_1\\mathcal L_{ART}+\\lambda_2\\mathcal L_{PSA} $$  \u5176\u4e2d\\lambda_1\u548c\\lambda_2\u5206\u522b\u8868\u793aART\u6a21\u5757\u548cPSA\u6a21\u5757\u7684\u635f\u5931\u6743\u91cd\u3002</p>"},{"location":"domain_adaptive/paper/Coarse-to-Fine1/#_9","title":"\u5b9e\u9a8c","text":""},{"location":"domain_adaptive/paper/Coarse-to-Fine1/#_10","title":"\u53ef\u89c6\u5316\u5206\u6790","text":"<p>\u2003\u2003\u4e3a\u4e86\u8fdb\u4e00\u6b65\u8bf4\u660e\u8be5\u65b9\u6cd5\u7684\u5148\u8fdb\u6027\uff0c\u4f5c\u8005\u5c06\u8be5\u7b97\u6cd5\u4e0e\u4e0d\u52a0\u81ea\u9002\u5e94\u7684\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u548cStrong-Weak feature adaptation(SWDA)\u7b97\u6cd5\u505a\u4e86\u5bf9\u6bd4\uff0c\u6240\u9762\u5411\u7684\u4efb\u52a1\u5747\u662f\u7531\u6e05\u6670\u57df\u5230\u6a21\u7cca\u57df\u7684\u9002\u5e94(\u5373\u6674\u5929\u5230\u96fe\u5929)\u3002</p> <p> \u524d\u666f\u7279\u5f81\u5206\u5e03\u5dee\u5f02\uff1a\u8bba\u6587\u300aAnalysis of Representations for Domain Adaptation\u300b\u4e2d\u8868\u660e\\mathcal A-distance\u53ef\u4ee5\u4f5c\u4e3a\u533a\u57df\u5dee\u5f02\u7684\u5ea6\u91cf(\u5177\u4f53\u8861\u91cf\u65b9\u6cd5\u53ef\u4ee5\u53bb\u53c2\u8003\u4e00\u4e0b\u539f\u6587\uff0c\u8bba\u6587\u94fe\u63a5)\uff0c\u56e0\u6b64\u4f5c\u8005\u8ba1\u7b97\u4e86\u4e09\u79cd\u7b97\u6cd5\u4e2d\u591a\u4e2a\u7c7b\u522b\u9886\u57df\u95f4\u7684\u5206\u5e03\u5dee\u5f02\uff0c\u7ed3\u679c\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u4ece\u56fe\u4e2d\u53ef\u4ee5\u53d1\u73b0\uff0c\u4e0e\u672a\u8fdb\u884c\u9886\u57df\u9002\u5e94\u7684\u6a21\u578b\u76f8\u6bd4\uff0c\u5f15\u5165\u4e86\u81ea\u9002\u5e94\u6a21\u5757\u7684\u4e24\u4e2a\u7b97\u6cd5\u5927\u5927\u7f29\u51cf\u4e86\u9886\u57df\u5dee\u5f02\uff0c\u8fd9\u8bc1\u660e\u4e86\u57df\u9002\u5e94\u7684\u5fc5\u8981\u6027\u3002\u6b64\u5916\uff0c\u7531\u4e8e\u4f5c\u8005\u5229\u7528PSA\u6a21\u5757\u663e\u5f0f\u4f18\u5316\u4e86\u6bcf\u4e2a\u7c7b\u522b\u7684\u539f\u578b\uff0c\u56e0\u6b64\u6700\u7ec8\u6a21\u578b\u5728\u6bcf\u4e2a\u7c7b\u522b\u4e0a\u83b7\u5f97\u4e86\u66f4\u5c0f\u7684\u524d\u666f\u5206\u5e03\u5dee\u5f02\u3002</p> <p> \u53ef\u89c6\u5316\u68c0\u6d4b\u7ed3\u679c\uff1a\u4f5c\u8005\u4e3a\u4e09\u4e2a\u6a21\u578b\u53ef\u89c6\u5316\u4e86\u68c0\u6d4b\u7ed3\u679c\uff0c\u5e76\u4e14\u8fd8\u53ef\u89c6\u5316\u4e86\u6ce8\u610f\u529b\u56fe\u7684\u5173\u6ce8\u533a\u57df\uff0c\u5177\u4f53\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u4e0a\u56fe\u4ece\u5de6\u5230\u53f3\u4f9d\u6b21\u4e3a\u672a\u5f15\u8fdb\u57df\u9002\u5e94\u6a21\u5757\u7684\u68c0\u6d4b\u7ed3\u679c\u3001SWDA\u68c0\u6d4b\u7ed3\u679c\u3001\u672c\u7b97\u6cd5\u68c0\u6d4b\u7ed3\u679c\u4ee5\u53ca\u6ce8\u610f\u529b\u56fe\u7684\u53ef\u89c6\u5316\u7ed3\u679c\u3002\u4ece\u56fe\u4e2d\u53ef\u4ee5\u53d1\u73b0\uff0c\u672a\u5f15\u8fdb\u57df\u9002\u5e94\u6a21\u5757\u7684\u7b97\u6cd5\u4ec5\u80fd\u68c0\u6d4b\u51fa\u4e00\u4e9b\u663e\u8457\u7684\u7269\u4f53\uff0c\u5bf9\u6bd4\u4f5c\u8005\u8bbe\u8ba1\u7684\u7b97\u6cd5\u4e0eSWDA\u53ef\u4ee5\u53d1\u73b0\uff0c\u8be5\u7b97\u6cd5\u53ef\u4ee5\u66f4\u51c6\u786e\u5730\u4ece\u6d53\u96fe\u4e2d\u68c0\u6d4b\u7269\u4f53\uff0c\u4f8b\u5982\u7b2c\u4e09\u5217\u76f8\u6bd4\u4e8e\u7b2c\u4e8c\u5217\u80fd\u591f\u68c0\u6d4b\u5f97\u5230\u66f4\u591a\u7684\u6c7d\u8f66\u3002</p>"},{"location":"domain_adaptive/paper/Coarse-to-Fine1/#map","title":"mAP\u5bf9\u6bd4","text":"<p>Cityscape \\rightarrow FoggyCityscape</p> <p> <p></p> <p></p>"},{"location":"domain_adaptive/paper/Coarse-to-Fine1/#_11","title":"\u603b\u7ed3","text":"<p>\u2003\u2003\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7531\u7c97\u5230\u7ec6\u7684\u7279\u5f81\u81ea\u9002\u5e94\u7b97\u6cd5\u6765\u89e3\u51b3\u8de8\u57df\u76ee\u6807\u68c0\u6d4b\u95ee\u9898\uff0c\u8be5\u7b97\u6cd5\u4e3b\u8981\u6709\u4e24\u4e2a\u6a21\u5757\u6784\u6210\u2014\u2014ART\u548cPSA\uff0c\u524d\u8005\u5229\u7528\u6ce8\u610f\u529b\u673a\u5236\u4ee5\u7c7b\u522b\u4e0d\u53ef\u77e5\u7684\u65b9\u5f0f\u6784\u9020\u524d\u666f\u533a\u57df\uff0c\u5e76\u4e14\u5728\u9886\u57df\u7279\u5f81\u5bf9\u9f50\u65f6\u7a81\u51fa\u524d\u666f\u533a\u57df\u7684\u91cd\u8981\u6027\uff0c\u540e\u8005\u5229\u7528\u539f\u578b\u5728\u8bed\u4e49\u5c42\u9762(\u5373\u7ed3\u5408\u4e86\u7c7b\u522b\u4fe1\u606f)\u5bf9\u524d\u666f\u8fdb\u884c\u7ec6\u7c92\u5ea6\u7684\u8c03\u6574\u3002</p> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u5185\u5bb9\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u5927\u5bb6\u6279\u8bc4\u6307\u6b63\u3002</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e741\u670830\u65e5</p>"},{"location":"domain_adaptive/paper/DAFaster1/","title":"\u57df\u9002\u5e94\uff1aDA Faster R-CNN","text":""},{"location":"domain_adaptive/paper/DAFaster1/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aIEEE Conference on Computer Vision and Pattern Recognition 2018 (CVPR, 2018)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_Domain_Adaptive_Faster_CVPR_2018_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/yuhuayc/da-faster-rcnn\uff08caffe\uff09\u3001https://github.com/krumo/Domain-Adaptive-Faster-RCNN-PyTorch\uff08PyTorch\uff09</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b</p>"},{"location":"domain_adaptive/paper/DAFaster1/#_2","title":"\u4e3b\u8981\u601d\u60f3","text":"<p>\u2003\u2003\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u76ee\u6807\u68c0\u6d4b\u5bb9\u6613\u9762\u4e34\u6765\u81ea\u89c6\u70b9\u3001\u76ee\u6807\u5916\u89c2\u3001\u80cc\u666f\u3001\u5149\u7167\u3001\u56fe\u50cf\u8d28\u91cf\u7b49\u65b9\u9762\u7684\u5de8\u5927\u5dee\u5f02\uff0c\u53ef\u80fd\u4f1a\u5bfc\u81f4\u8bad\u7ec3\u6570\u636e\u548c\u6d4b\u8bd5\u6570\u636e\u4e4b\u95f4\u76f8\u5f53\u5927\u7684\u9886\u57df\u504f\u79fb\uff0c\u4e0b\u56fe\u9009\u53d6\u4e86\u81ea\u52a8\u9a7e\u9a76\u4e2d\u51e0\u4e2a\u5e38\u7528\u7684\u6570\u636e\u96c6\u56fe\u7247\uff0c\u4ece\u4e2d\u53ef\u4ee5\u53d1\u73b0\uff0c\u4e0d\u540c\u7684\u6570\u636e\u96c6\u4e4b\u95f4\u56e0\u4e3a\u57ce\u5e02\u7684\u80cc\u666f\u3001\u5929\u6c14\u60c5\u51b5\u4ee5\u53ca\u8f66\u8f86\u5f62\u72b6\u7b49\u56e0\u7d20\u4f1a\u4ea7\u751f\u76f8\u5f53\u5927\u7684\u9886\u57df\u504f\u79fb\u95ee\u9898\uff0c\u9488\u5bf9\u8fd9\u4e00\u95ee\u9898\uff0c\u4f5c\u8005\u5f00\u53d1\u4e86\u4e00\u79cd\u8de8\u57df\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\uff0c\u53ef\u4ee5\u4f7f\u6a21\u578b\u9002\u5e94\u89c6\u89c9\u4e0a\u4e0d\u540c\u4e8e\u8bad\u7ec3\u96c6\u6570\u636e\u9886\u57df\u7684\u65b0\u9886\u57df\uff0c\u5982\u5229\u7528\u6674\u5929\u6570\u636e\u96c6\u8bad\u7ec3\u7684\u6a21\u578b\u4e5f\u53ef\u4ee5\u5f88\u597d\u5730\u5e94\u7528\u5230\u96fe\u5929\u7684\u76ee\u6807\u68c0\u6d4b\u3002</p> <p> <p></p> <p></p> <p>\u2003\u2003\u4f5c\u8005\u8bbe\u8ba1\u4e86\u4e00\u79cd\u57fa\u4e8eFaster R-CNN\u7684\u9886\u57df\u81ea\u9002\u5e94Faster R-CNN\u7b97\u6cd5(Domain Adaptive Faster R-CNN)\uff0c\u57fa\u4e8e\u534f\u53d8\u91cf\u504f\u79fb\u5047\u8bbe(covariate shift assumption)\uff0c\u57df\u504f\u79fb\u53ef\u80fd\u53d1\u751f\u5728\u56fe\u50cf\u7ea7\u522b\u6c34\u5e73(\u5982\u56fe\u50cf\u5c3a\u5ea6\u3001\u56fe\u50cf\u98ce\u683c\u7b49)\u4ee5\u53ca\u5b9e\u4f8b\u7ea7\u522b\u6c34\u5e73(\u5982\u7269\u4f53\u51fa\u73b0\u7684\u5c3a\u5bf8)\u3002\u4e3a\u4e86\u89e3\u51b3\u9886\u57df\u504f\u5dee\u95ee\u9898\uff0c\u4f5c\u8005\u8bbe\u8ba1\u4e86\u56fe\u50cf\u7ea7\u6c34\u5e73\u81ea\u9002\u5e94\u7ec4\u4ef6\u548c\u5b9e\u4f8b\u7ea7\u6c34\u5e73\u81ea\u9002\u5e94\u7ec4\u4ef6\uff0c\u5e76\u4e14\u5c06\u5176\u5d4c\u5165\u5230Faster R-CNN\u4e2d\uff0c\u4ece\u800c\u5b9e\u73b0\u6700\u5c0f\u5316\u4e24\u4e2a\u9886\u57df\u4e4b\u95f4\u7684\\mathcal H\u6563\u5ea6\u7684\u76ee\u7684\u3002\u5728\u6bcf\u4e2a\u7ec4\u4ef6\u4e2d\uff0c\u4f5c\u8005\u8bad\u7ec3\u4e86\u4e00\u4e2a\u9886\u57df\u5206\u7c7b\u5668\uff0c\u4f7f\u7528\u5bf9\u6297\u7b56\u7565\u6765\u5b66\u4e60\u9886\u57df\u4e0d\u53d8\u7684\u7279\u5f81\uff0c\u5e76\u4e14\u8fdb\u4e00\u6b65\u5728\u4e0d\u540c\u5c42\u6b21\u7684\u9886\u57df\u5206\u7c7b\u5668\u4e4b\u95f4\u5f15\u5165\u4e00\u81f4\u6027\u6b63\u5219\u5316\uff0c\u4ece\u800c\u8ba9Faster R-CNN\u5b66\u4e60\u5230\u4e00\u4e2a\u57df\u4e0d\u53d8\u7684\u533a\u57df\u63d0\u8bae\u6a21\u5757(RPN)\u3002</p> <p>\u2003\u2003\u672c\u6587\u7684\u8d21\u732e\u53ef\u4ee5\u603b\u7ed3\u4e3a\uff1a</p> <ul> <li>\u4ece\u6982\u7387\u7684\u89c6\u89c9\u5bf9\u9886\u57df\u504f\u79fb\u95ee\u9898\u505a\u4e86\u4e00\u4e2a\u5206\u6790\uff1b</li> <li>\u8bbe\u8ba1\u4e86\u4e24\u4e2a\u81ea\u9002\u5e94\u7ec4\u4ef6\u6765\u5206\u522b\u7f13\u89e3\u56fe\u50cf\u548c\u5b9e\u4f8b\u7ea7\u522b\u7684\u9886\u57df\u5dee\u5f02\u6240\u4ea7\u751f\u7684\u95ee\u9898\uff1b</li> <li>\u8bbe\u8ba1\u4e86\u4e00\u81f4\u6027\u6b63\u5219\u5316\u5668\u6765\u9f13\u52b1RPN\u7f51\u7edc\u5177\u6709\u9886\u57df\u4e0d\u53d8\u6027\uff1b</li> <li>\u5c06\u63d0\u51fa\u7684\u7ec4\u4ef6\u96c6\u6210\u5230Faster R-CNN\u4e2d\uff0c\u5e76\u4e14\u4ee5\u7aef\u5230\u7aef\u7684\u65b9\u5f0f\u8fdb\u884c\u8bad\u7ec3\u3002</li> </ul>"},{"location":"domain_adaptive/paper/DAFaster1/#_3","title":"\u65b9\u6cd5","text":""},{"location":"domain_adaptive/paper/DAFaster1/#_4","title":"\u9884\u5907\u5185\u5bb9","text":""},{"location":"domain_adaptive/paper/DAFaster1/#faster_r-cnn","title":"Faster R-CNN","text":"<p>\u2003\u2003\u672c\u6587\u4e2d\u4f7f\u7528\u7684\u57fa\u7ebf\u68c0\u6d4b\u6a21\u578b\u4e3aFaster R-CNN\uff0c\u8be5\u7f51\u7edc\u662f\u4e00\u4e2a\u4e8c\u9636\u6bb5\u68c0\u6d4b\u5668\uff0c\u4e3b\u8981\u7531\u4e09\u4e2a\u90e8\u4ef6\u7ec4\u6210\uff1a\u7279\u5f81\u63d0\u53d6\u7f51\u7edc(\u5e95\u5c42\u5377\u79ef\u5c42)\u3001\u533a\u57df\u63d0\u8bae\u7f51\u7edc(RPN)\u3001\u57fa\u4e8e\u611f\u5174\u8da3\u533a\u57df\u7684\u5206\u7c7b\u6a21\u5757(ROI)\uff0c\u7f51\u7edc\u7ed3\u6784\u5982\u4e0b\u56fe\u5de6\u4fa7\u6240\u793a\u3002</p> <p>\u2003\u2003\u9996\u5148\u8f93\u5165\u7684\u56fe\u7247\u5148\u7ecf\u8fc7\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u63d0\u53d6\u7279\u5f81\uff0c\u4e4b\u540e\u5c06\u5f97\u5230\u7684\u7279\u5f81\u56fe\u4f20\u5165RPN\u6a21\u5757\u751f\u6210\u5bf9\u5e94\u7684\u7269\u4f53\u63d0\u8bae\uff0c\u6700\u540eROI\u6a21\u5757\u5229\u7528\u611f\u5174\u8da3\u7684\u533a\u57df\u8fdb\u884c\u7269\u4f53\u7c7b\u522b\u9884\u6d4b\uff0c\u8bad\u7ec3\u635f\u5931\u7531RPN\u6a21\u5757\u7684\u635f\u5931\u548cROI\u6a21\u5757\u7684\u635f\u5931\u6784\u6210\uff1a $$ L_{det}=L_{rpn}+L_{roi} $$  \u5176\u4e2dRPN\u635f\u5931\u548cROI\u635f\u5931\u5747\u7531\u4e24\u90e8\u5206\u6784\u6210\uff1a\u5206\u7c7b\u5668\u9884\u6d4b\u7684\u51c6\u786e\u5ea6\u3001\u9884\u6d4b\u6846\u7684\u56de\u5f52\u53c2\u6570\u3002</p> <p> <p></p> <p></p>"},{"location":"domain_adaptive/paper/DAFaster1/#h","title":"\u5229\u7528H\u6563\u5ea6\u7684\u5206\u5e03\u5bf9\u9f50","text":"<p> \\mathcal H\u6563\u5ea6\u7528\u4e8e\u8861\u91cf\u4e24\u4e2a\u6837\u672c\u5206\u5e03\u4e4b\u95f4\u7684\u79bb\u6563\u7a0b\u5ea6\uff0c\u5047\u8bbe\u4e00\u4e2a\u7279\u5f81\u5411\u91cf\u8868\u793a\u4e3ax\uff0c\u6e90\u57df\u7684\u6837\u672c\u8868\u793a\u4e3ax_{\\mathcal S}\uff0c\u76ee\u6807\u57df\u7684\u6837\u672c\u8868\u793a\u4e3ax_{\\mathcal T}\uff0c\u5229\u7528h:x\\rightarrow{0,1}\u8868\u793a\u57df\u5206\u7c7b\u5668\uff0c\u5bf9\u4e8e\u6e90\u57df\u6570\u636ex_{\\mathcal S}\u671f\u671b\u9884\u6d4b\u4e3a0\uff0c\u5bf9\u4e8e\u76ee\u6807\u57df\u6570\u636ex_{\\mathcal T}\u671f\u671b\u9884\u6d4b\u4e3a1\u3002\u5047\u8bbe\\mathcal H\u4e3a\u6240\u6709\u53ef\u80fd\u7684\u57df\u5206\u7c7b\u5668\u96c6\u5408(\u5373\u5206\u7c7b\u5668h\u7684\u8303\u56f4)\uff0c\u5219\\mathcal H\u6563\u5ea6\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ d_{\\mathcal H}(\\mathcal S,\\mathcal T)=2(1-\\min_{h\\in\\mathcal H}(err_{\\mathcal S}(h(x))+err_{\\mathcal T}(h(x)))) $$  \u5176\u4e2derr_{\\mathcal S}\u548cerr_{\\mathcal T}\u5206\u522b\u8868\u793ah(x)\u5728\u6e90\u57df\u548c\u76ee\u6807\u57df\u6837\u672c\u4e0a\u7684\u9884\u6d4b\u8bef\u5dee\u3002\u4ece\u4e0a\u5f0f\u53ef\u4ee5\u770b\u51fa\u9886\u57df\u8ddd\u79bbd_{\\mathcal H}(\\mathcal S,\\mathcal T)\u4e0e\u57df\u5206\u7c7b\u5668h\u9519\u8bef\u7387\u6210\u53cd\u6bd4\uff0c\u6362\u53e5\u8bdd\u8bf4\uff0c\u5bf9\u4e8e\u6700\u597d\u7684\u57df\u5206\u7c7b\u5668\uff0c\u5982\u679c\u4ed6\u4eec\u9886\u57df\u5206\u7c7b\u7684\u9519\u8bef\u7387\u5f88\u9ad8\uff0c\u5219\u6b64\u65f6\u6563\u5ea6\u5c31\u5f88\u5c0f\uff0c\u8bf4\u660e\u7279\u5f81\u5f7c\u6b64\u5206\u5e03\u5f88\u8fd1\uff0c\u5373\u8fd9\u4e24\u4e2a\u9886\u57df\u7684\u6570\u636e\u5f88\u96be\u533a\u5206\u3002</p> <p>\u6ce8\uff1a\u8fd9\u4e5f\u6b63\u662f\u6211\u4eec\u5728\u57df\u9002\u5e94\u4efb\u52a1\u4e2d\u6240\u671f\u671b\u7684\uff0c\u5bf9\u9f50\u4e24\u4e2a\u9886\u57df\u4e4b\u95f4\u7684\u7279\u5f81\u6570\u636e\uff0c\u4f7f\u5176\u96be\u4ee5\u533a\u5206\uff0c\u56e0\u6b64\u6709\u4e24\u4e2a\u4efb\u52a1\uff1a\u5f97\u5230\u597d\u7684\u57df\u5206\u7c7b\u5668\u3001\u5e76\u4e14\u8ba9CNN\u4ea7\u751f\u4e0a\u8ff0\u57df\u5206\u7c7b\u5668\u96be\u4ee5\u9274\u522b\u9886\u57df\u5f52\u5c5e\u7684\u7279\u5f81\uff0c\u9700\u8981\u4ee5\u76f8\u53cd\u7684\u65b9\u5f0f\u4f18\u5316\u57df\u5206\u7c7b\u5668\u548cCNN\uff0c\u56e0\u6b64\u9700\u8981\u5229\u7528\u5bf9\u6297\u8bad\u7ec3\u7b56\u7565\u3002\uff08\u6ce8\u610f\u7406\u6e05\u903b\u8f91\u5173\u7cfb\uff09</p> <p>\u2003\u2003\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4e2d\uff0c\u7279\u5f81\u5411\u91cfx\u901a\u5e38\u8868\u793a\u4e3a\u4e00\u5c42\u7f51\u7edc\u540e\u7684\u6fc0\u6d3b\uff0c\u5047\u8bbe\u4ea7\u751f\u5411\u91cfx\u7684\u7f51\u7edc\u4e3af\uff0c\u4e3a\u4e86\u5bf9\u9f50\u4e24\u4e2a\u9886\u57df\u7684\u7279\u5f81\uff0c\u9700\u8981\u5f3a\u5236\u7f51\u7edcf\u8f93\u51fa\u6700\u5c0f\u5316\u9886\u57df\u8ddd\u79bbd_{\\mathcal H}(\\mathcal S,\\mathcal T)\u7684\u7279\u5f81\u5411\u91cf\uff0c\u5373\uff1a $$ \\min_fd_{\\mathcal H}(\\mathcal S,\\mathcal T)\\Leftrightarrow\\max_f\\min_{h\\in\\mathcal H}\\{err_{\\mathcal S}(h(x))+err_{\\mathcal T}h(x))\\} $$  \u8fd9\u53ef\u4ee5\u901a\u8fc7\u5bf9\u6297\u7684\u8bad\u7ec3\u65b9\u5f0f\u8fdb\u884c\u4f18\u5316\uff0c\u6700\u5e38\u7528\u7684\u65b9\u6cd5\u5c31\u662f\u5c06\u68af\u5ea6\u53cd\u8f6c\u5c42(gradient reverse layer, GRL)\u5d4c\u5165\u5230CNN\u4e2d\uff0c\u5177\u4f53\u5b9e\u73b0\u65b9\u6cd5\u53ef\u89c1\u6e90\u7801\u7b14\u8bb0\u3002</p> <p>\u2003\u2003\u4e3e\u4e2a\u4f8b\u5b50\u6765\u8bf4\uff0c\u5f53\u5229\u7528\u6674\u5929\u6570\u636e\u8bad\u7ec3\u6a21\u578b\u65f6\uff0c\u8f93\u5165\u4e00\u5f20\u96fe\u5929\u6570\u636e\uff0c\u7531\u4e8e\u7f51\u7edc\u6ca1\u6709\u89c1\u8fc7\u96fe\u5929\u7684\u6570\u636e\u96c6\uff0c\u56e0\u6b64\u5b58\u5728\u8bad\u7ec3\u6570\u636e\u4e0e\u6d4b\u8bd5\u6570\u636e\u4e4b\u95f4\u7684\u9886\u57df\u504f\u79fb\uff0c\u4ed6\u4f1a\u8ba4\u4e3a\u96fe\u5929\u7684\u6570\u636e\u4e0e\u6674\u5929\u7684\u6570\u636e\u5185\u5bb9\u5b8c\u5168\u4e0d\u540c(\u6781\u7aef\u60c5\u51b5\u4e0b)\uff0c\u56e0\u6b64\u4f1a\u4ea7\u751f\u4e00\u4e2a\u4e0e\u6674\u5929\u6570\u636e\u5b8c\u5168\u4e0d\u540c\u7684\u7279\u5f81\u5411\u91cf\uff0c\u9650\u5236\u4e86RPN\u548cROI\u7684\u9884\u6d4b\u3002\u4f46\u5b9e\u9645\u4e0a\u96fe\u5929\u6570\u636e\u4e0e\u6674\u5929\u6570\u636e\u6240\u8574\u542b\u7684\u4fe1\u606f\u4e00\u6837\uff0c\u5f85\u68c0\u6d4b\u76ee\u6807\u4e5f\u4e00\u6837\uff0c\u53ea\u662f\u6570\u636e\u5206\u5e03\u6709\u6240\u5dee\u5f02\uff0c\u56e0\u6b64\u6211\u4eec\u671f\u671b\u7f51\u7edc\u80fd\u591f\u5e73\u7b49\u5bf9\u5f85\u4e24\u79cd\u6570\u636e\uff0c\u5bf9\u4e8e\u96fe\u5929\u6570\u636e\u80fd\u4ea7\u751f\u4e0e\u6674\u5929\u6570\u636e\u76f8\u540c\u7684\u7279\u5f81\u5206\u5e03\uff0c\u8fd9\u6837\u624d\u4fbf\u4e8e\u540e\u7eed\u5bf9\u76ee\u6807\u4f4d\u7f6e\u548c\u7c7b\u522b\u7684\u9884\u6d4b\u3002</p>"},{"location":"domain_adaptive/paper/DAFaster1/#_5","title":"\u7528\u4e8e\u76ee\u6807\u68c0\u6d4b\u7684\u57df\u9002\u5e94","text":"<p>\u2003\u2003\u9075\u5faa\u4e00\u822c\u7684\u57df\u9002\u5e94\u672f\u8bed\uff0c\u5c06\u8bad\u7ec3\u6570\u636e\u79f0\u4e3a\u6e90\u57df\u6570\u636e\\mathcal S\uff0c\u6d4b\u8bd5\u6570\u636e\u79f0\u4e3a\u76ee\u6807\u57df\u6570\u636e\\mathcal T\u3002\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u5bf9\u4e8e\u6e90\u57df\u6570\u636e\u6709\u76ee\u6807\u6846\u5750\u6807\u3001\u7269\u4f53\u7c7b\u522b\u3001\u9886\u57df\u6807\u7b7e\u7b49\u4fe1\u606f\uff0c\u800c\u5bf9\u4e8e\u76ee\u6807\u57df\u6570\u636e\u4ec5\u6709\u9886\u57df\u6807\u7b7e\u3002</p>"},{"location":"domain_adaptive/paper/DAFaster1/#_6","title":"\u6982\u7387\u89c6\u89d2","text":"<p>\u2003\u2003\u7269\u4f53\u68c0\u6d4b\u95ee\u9898\u53ef\u4ee5\u89c6\u4e3a\u5b66\u4e60\u4e00\u4e2a\u540e\u9a8c\u6982\u7387P(C,B|I)\uff0c\u5176\u4e2dI\u8868\u793a\u56fe\u7247\u8868\u5f81(\u7279\u5f81\u56fe)\uff0cB\u8868\u793a\u7269\u4f53\u5750\u6807\u6846\uff0cC\\in\\{1,\\dots,K\\}\u8868\u793a\u7269\u4f53\u7c7b\u522b\uff0c\u5176\u4e2dK\u4e3a\u7c7b\u522b\u603b\u6570\u3002</p> <p>\u2003\u2003\u5047\u8bbe\u76ee\u6807\u68c0\u6d4b\u4e2d\u8bad\u7ec3\u6837\u672c\u7684\u8054\u5408\u5206\u5e03\u4e3aP(C,B,I)\uff0c\u4f7f\u7528P_{\\mathcal S}(C,B,I)\u4ee5\u53caP_{\\mathcal T}(C,B,I)\u5206\u522b\u8868\u793a\u6e90\u57df\u8054\u5408\u5206\u5e03\u548c\u76ee\u6807\u57df\u8054\u5408\u5206\u5e03(\u76ee\u6807\u57df\u4e2dC,B\u672a\u77e5)\u3002\u5f53\u5b58\u5728\u9886\u57df\u504f\u79fb\u65f6P_{\\mathcal S}(C,B,I)\\neq P_{\\mathcal T}(C,B,I)\u3002</p> <p> \u56fe\u50cf\u7ea7\u522b\u7684\u9886\u57df\u9002\u5e94\uff1a\u4f7f\u7528\u8d1d\u53f6\u65af\u516c\u5f0f\uff0c\u8054\u5408\u5206\u5e03\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ P(C,B,I)=P(C,B|I)P(I) $$  \u7c7b\u4f3c\u4e8e\u5206\u7c7b\u95ee\u9898\uff0c\u5bf9\u76ee\u6807\u68c0\u6d4b\u505a\u534f\u53d8\u91cf\u504f\u79fb\u5047\u8bbe(covariate shift assumption)\uff0c\u4f8b\u5982\uff1a\u4e24\u4e2a\u57df\u7684\u6761\u4ef6\u6982\u7387P(C,B|I)\u76f8\u540c\uff0c\u9886\u57df\u5206\u5e03\u504f\u79fb\u7531\u4e0d\u540c\u7684\u8fb9\u7f18\u5206\u5e03P(I)\u5f15\u8d77\u3002\u6362\u53e5\u8bdd\u8bf4\uff0c\u68c0\u6d4b\u5668\u5728\u4e24\u4e2a\u9886\u57df\u4e4b\u95f4\u662f\u4e00\u81f4\u7684\uff0c\u7ed9\u5b9a\u4e00\u5f20\u56fe\u7247\uff0c\u65e0\u8bba\u5b83\u5c5e\u4e8e\u54ea\u4e2a\u9886\u57df\uff0c\u68c0\u6d4b\u5668\u90fd\u5e94\u8be5\u8fd4\u56de\u76f8\u540c\u7684\u68c0\u6d4b\u7ed3\u679c(\u4f4d\u7f6e\u4e0e\u7c7b\u522b\u76f8\u540c)\u3002\u5728Faster R-CNN\u4e2d\uff0c\u56fe\u7247\u8868\u5f81I\u53ef\u4ee5\u8868\u793a\u57fa\u7840\u5377\u79ef\u5c42\u8f93\u51fa\u7684\u7279\u5f81\u56fe\uff0c\u56e0\u6b64\u4e3a\u4e86\u89e3\u51b3\u9886\u57df\u504f\u79fb\u95ee\u9898\uff0c\u5e94\u8be5\u5f3a\u5236\u4e24\u4e2a\u9886\u57df\u7684\u56fe\u7247\u8868\u5f81\u5206\u5e03\u76f8\u540c\uff0c\u5373P_{\\mathcal S}(I)=P_{\\mathcal T}(I)\uff0c\u8fd9\u91cc\u79f0\u4e3a\u56fe\u50cf\u7ea7\u522b\u7684\u81ea\u9002\u5e94\u3002</p> <p> \u5b9e\u4f8b\u7ea7\u522b\u7684\u81ea\u9002\u5e94\uff1a\u53e6\u4e00\u65b9\u9762\uff0c\u8054\u5408\u5206\u5e03\u4e5f\u53ef\u4ee5\u5206\u89e3\u4e3a\uff1a $$ P(C,B,I)=P(C|B,I)P(B,I) $$  \u5229\u7528\u534f\u53d8\u91cf\u504f\u79fb\u5047\u8bbe\uff0c\u4e24\u4e2a\u9886\u57df\u6761\u4ef6\u6982\u7387P(C|B,I)\u662f\u76f8\u540c\u7684\uff0c\u5047\u8bbe\u9886\u57df\u7684\u504f\u79fb\u7531\u8fb9\u7f18\u5206\u5e03P(B,I)\u7684\u4e0d\u540c\u5f15\u8d77\u3002\u76f4\u89c2\u5730\u8bf4\uff0c\u4e24\u4e2a\u9886\u57df\u4e4b\u95f4\u7684\u8bed\u4e49\u4fe1\u606f\u5e94\u4fdd\u6301\u4e00\u81f4\u6027\uff0c\u5373\u7ed9\u5b9a\u5305\u542b\u5bf9\u8c61\u7684\u76f8\u540c\u56fe\u50cf\u533a\u57df\uff0c\u65e0\u8bba\u4ed6\u5c5e\u4e8e\u54ea\u4e2a\u54ea\u4e2a\u57df\uff0c\u4ed6\u4eec\u7684\u7c7b\u522b\u6807\u7b7e\u5e94\u8be5\u76f8\u540c\u3002\u56e0\u6b64\u6211\u4eec\u53ef\u4ee5\u5f3a\u5236\u6765\u81ea\u4e24\u4e2a\u57df\u7684\u5b9e\u4f8b\u8868\u5f81\u5206\u5e03\u76f8\u540c\uff0c\u5373P_{\\mathcal S}(B,I)=P_{\\mathcal T}(B,I)\uff0c\u8fd9\u91cc\u79f0\u4e3a\u5b9e\u4f8b\u7ea7\u522b\u7684\u81ea\u9002\u5e94\u3002</p> <p>\u2003\u2003\u8fd9\u91cc\uff0c\u5b9e\u4f8b\u8868\u5f81(B,I)\u662f\u6307\u4ece\u6bcf\u4e2a\u5b9e\u4f8b\u7684\u5730\u9762\u771f\u5b9e\u8fb9\u754c\u6846\u4e2d\u56fe\u50cf\u533a\u57df\u63d0\u53d6\u7684\u7279\u5f81\u3002\u867d\u7136\u76ee\u6807\u57df\u4e2d\u6ca1\u6709\u771f\u5b9e\u8fb9\u754c\u6846\u6807\u7b7e\uff0c\u4f46\u662f\u53ef\u4ee5\u901a\u8fc7\u5982\u4e0b\u516c\u5f0f\u6765\u83b7\u5f97\uff1a $$ P(B,I)=P(B|I)P(I) $$  \u5176\u4e2dP(B|I)\u8868\u793a\u9884\u6d4b\u7684\u8fb9\u754c\u6846(\u4f8b\u5982Faster R-CNN\u4e2dRPN\u6a21\u5757\u7684\u8f93\u51fa)\uff0c\u8fd9\u4ec5\u5728P(B|I)\u9886\u57df\u4e0d\u53d8\u7684\u60c5\u51b5\u4e0b\u6210\u7acb\u3002</p> <p> \u8054\u5408\u81ea\u9002\u5e94\uff1a\u7406\u60f3\u60c5\u51b5\u4e0b\uff0c\u53ef\u4ee5\u5b9e\u73b0\u56fe\u50cf\u7ea7\u522b\u548c\u5b9e\u4f8b\u7ea7\u522b\u7684\u9886\u57df\u5bf9\u9f50\uff0c\u8003\u8651\u5230P(B,I)=P(B|I)P(I)\uff0c\u5e76\u4e14\u4e24\u4e2a\u57df\u7684\u6761\u4ef6\u5206\u5e03P(B|I)\u5047\u8bbe\u76f8\u540c\u4e14\u975e\u96f6\uff0c\u6709\u5982\u4e0b\u516c\u5f0f\u6210\u7acb\uff1a $$ P_{\\mathcal S}(I)=P_{\\mathcal T}(I)\\Leftrightarrow P_{\\mathcal S}(B,I)=P_{\\mathcal T}(B,I) $$ </p>  P_{\\mathcal S}(I)=P_{\\mathcal S}(I)\\Leftrightarrow P_{\\mathcal S}(B,I)=P_{\\mathcal T}(B,I)  <p>\u6362\u53e5\u8bdd\u8bf4\uff0c\u5982\u679c\u56fe\u50cf\u7ea7\u8868\u5f81\u7684\u5206\u5e03\u5728\u4e24\u4e2a\u57df\u4e4b\u95f4\u76f8\u540c\uff0c\u5219\u5b9e\u4f8b\u7ea7\u8868\u5f81\u4e5f\u5728\u4e24\u4e2a\u57df\u4e4b\u95f4\u76f8\u540c\u3002\u7136\u800c\uff0c\u5b8c\u7f8e\u5730\u4f30\u8ba1\u6761\u4ef6\u5206\u5e03P(B|I)\u662f\u4e0d\u592a\u73b0\u5b9e\u7684\uff0c\u5373RPN\u6a21\u5757\u4e0d\u80fd\u5b8c\u7f8e\u5730\u9884\u6d4b\u8fb9\u754c\u6846\uff0c\u539f\u56e0\u5982\u4e0b\uff1a\u2460\u5b9e\u8df5\u4e2d\uff0c\u53ef\u80fd\u5f88\u96be\u5b8c\u7f8e\u5730\u5bf9\u9f50\u8fb9\u754c\u5206\u5e03P(I)\uff0c\u56e0\u6b64\u7528\u4e8e\u4f30\u8ba1\u7684P(B|I)\u5728\u67d0\u79cd\u7a0b\u5ea6\u4e0a\u662f\u5b58\u5728\u504f\u5dee\u7684\uff1b\u2461\u7269\u4f53\u8fb9\u754c\u6846\u4fe1\u606f\u4ec5\u5728\u6e90\u57df\u6570\u636e\u53ef\u7528\uff0c\u56e0\u6b64P(B|I)\u4ec5\u80fd\u4f7f\u7528\u6e90\u57df\u6570\u636e\u6765\u5b66\u4e60\uff0c\u5f88\u5bb9\u6613\u8ba9\u5176\u504f\u5411\u6e90\u57df\u6570\u636e\u3002</p> <p>\u2003\u2003\u56e0\u6b64\uff0c\u4f5c\u8005\u5efa\u8bae\u540c\u65f6\u5728\u56fe\u50cf\u7ea7\u548c\u5b9e\u4f8b\u7ea7\u6c34\u5e73\u4e0a\u5b9e\u884c\u9886\u57df\u5206\u5e03\u5bf9\u9f50\uff0c\u5e76\u4e14\u5e94\u7528\u4e00\u81f4\u6027\u6b63\u5219\u5316\u5668\u6765\u51cf\u8f7b\u4f30\u8ba1P(B|I)\u7684\u504f\u5dee\u3002\u4e3a\u4e86\u5bf9\u9f50\u4e24\u4e2a\u57df\u7684\u5206\u5e03\uff0c\u9700\u8981\u8bad\u7ec3\u4e00\u4e2a\u57df\u5206\u7c7b\u5668h(x)\u3002\u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\uff0cx\u53ef\u4ee5\u662f\u56fe\u50cf\u7ea7\u522b\u7684\u8868\u5f81I\uff0c\u4e5f\u53ef\u4ee5\u662f\u5b9e\u4f8b\u7ea7\u522b\u7684\u8868\u5f81(B,I)\u3002\u4ece\u6982\u7387\u7684\u89d2\u5ea6\u6765\u770b\uff0ch(x)\u53ef\u4ee5\u770b\u4f5c\u662f\u4f30\u8ba1\u6837\u672cx\u5c5e\u4e8e\u76ee\u6807\u57df\u7684\u6982\u7387\u3002</p> <p>\u2003\u2003\u56e0\u6b64\uff0c\u901a\u8fc7\u5c06\u57df\u6807\u7b7e\u8868\u793a\u4e3aD\uff0c\u56fe\u50cf\u7ea7\u57df\u5206\u7c7b\u5668\u53ef\u4ee5\u88ab\u89c6\u4e3a\u4f30\u8ba1P(D|I)\uff0c\u5b9e\u4f8b\u7ea7\u57df\u5206\u7c7b\u5668\u53ef\u4ee5\u88ab\u89c6\u4e3a\u4f30\u8ba1P(D|B,I)\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u5b9a\u7406\uff0c\u53ef\u4ee5\u5f97\u5230\uff1a $$ P(D|B,I)P(B|I)=P(B|D,I)P(D|I) $$  \u5176\u4e2d\uff0cP(B|I)\u662f\u4e00\u4e2a\u4e0d\u4f9d\u8d56\u4e8e\u9886\u57df\u7684\u76ee\u6807\u6846\u9884\u6d4b\u5668\uff0cP(B|D,I)\u4e3a\u4f9d\u8d56\u4e8e\u9886\u57df\u7684\u76ee\u6807\u6846\u9884\u6d4b\u5668\u3002\u7531\u4e8e\u5728\u5b9e\u8df5\u4e2d\u56e0\u4e3a\u6ca1\u6709\u76ee\u6807\u57df\u7684\u8fb9\u754c\u6846\u6ce8\u91ca\uff0c\u56e0\u6b64\u53ea\u80fd\u5b66\u5230\u4f9d\u8d56\u4e8e\u9886\u57df\u7684\u76ee\u6807\u6846\u9884\u6d4b\u671fP(B|D,I)\u3002\u4ece\u4e0a\u8ff0\u516c\u5f0f\u53ef\u4ee5\u53d1\u73b0\uff0c\u901a\u8fc7\u52a0\u5f3a\u4e24\u4e2a\u9886\u57df\u5206\u7c7b\u5668\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\uff0c\u5373\u4f7fP(D|B,I)=P(D|I)\uff0c\u53ef\u4ee5\u4f7fP(B|D,I)\u6765\u63a5\u8fd1P(B|I)\u3002</p>"},{"location":"domain_adaptive/paper/DAFaster1/#_7","title":"\u57df\u9002\u5e94\u7ec4\u4ef6","text":"<p>\u4e24\u4e2a\u57df\u9002\u5e94\u7ec4\u4ef6\u5982\u4e0b\u56fe\u53f3\u4fa7\u6240\u793a</p> <p> <p></p> <p></p> <p> \u56fe\u50cf\u7ea7\u522b\u7684\u81ea\u9002\u5e94\uff1a\u5728Faster R-CNN\u6a21\u578b\u4e2d\uff0c\u56fe\u50cf\u7ea7\u522b\u7684\u8868\u793a\u662f\u6307\u57fa\u672c\u5377\u79ef\u5c42\u7684\u7279\u5f81\u8f93\u51fa(\u5982\u4e0a\u56fe\u4e2d\u7684\u7eff\u8272\u56db\u8fb9\u5f62)\u3002\u4e3a\u4e86\u6d88\u9664\u56fe\u50cf\u7ea7\u522b\u7684\u57df\u5206\u5e03\u4e0d\u5339\u914d\uff0c\u6211\u4eec\u4f7f\u7528\u4e00\u4e2a\u57fa\u4e8e\u8865\u4e01(patch)\u7684\u57df\u5206\u7c7b\u5668\uff0c\u5982\u4e0a\u56fe\u53f3\u4e0b\u65b9\u6240\u793a\u3002</p> <p>\u2003\u2003\u7279\u522b\u7684\uff0c\u6211\u4eec\u4ece\u7279\u5f81\u56fe\u7684\u6bcf\u4e2a\u6fc0\u6d3b\u503c\u8bad\u7ec3\u57df\u5206\u7c7b\u5668\uff0c\u56e0\u4e3a\u6bcf\u4e2a\u6fc0\u6d3b\u503c\u7684\u611f\u53d7\u91ce\u5bf9\u5e94\u4e8e\u8f93\u5165\u56fe\u50cf\u7684\u4e00\u4e2a\u56fe\u7247\u8865\u4e01I_i\uff0c\u56e0\u6b64\u57df\u5206\u7c7b\u5668\u5b9e\u9645\u4e0a\u9884\u6d4b\u6bcf\u4e2a\u56fe\u50cf\u8865\u4e01\u7684\u57df\u6807\u7b7e\uff0c\u5177\u4f53\u5b9e\u73b0\u65b9\u6cd5\u53ef\u89c1\u6e90\u7801\u7b14\u8bb0\u3002</p> <p>\u2003\u2003\u56fe\u50cf\u7ea7\u81ea\u9002\u5e94\u7684\u6784\u5efa\u6709\u5982\u4e0b\u4e24\u4e2a\u597d\u5904\uff1a\u2460\u5bf9\u9f50\u56fe\u50cf\u7ea7\u8868\u5f81\u6709\u5229\u4e8e\u51cf\u5c11\u7531\u5168\u5c40\u56fe\u50cf\u5dee\u5f02\u5f15\u8d77\u7684\u9886\u57df\u504f\u79fb(\u5982\u56fe\u50cf\u98ce\u683c\u3001\u56fe\u50cf\u6bd4\u4f8b\u3001\u7167\u660e\u7b49\u7b49)\uff1b\u2461\u7531\u4e8e\u4f7f\u7528\u9ad8\u5206\u8fa8\u7387\u8f93\u5165\uff0c\u56e0\u6b64\u76ee\u6807\u68c0\u6d4b\u7f51\u7edc\u7684\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0cbatch size\u8bbe\u7f6e\u7684\u901a\u5e38\u5f88\u5c0f\uff0c\u8fd9\u79cd\u57fa\u4e8e\u8865\u4e01\u7684\u8bbe\u8ba1\u6709\u52a9\u4e8e\u589e\u52a0\u8bad\u7ec3\u9886\u57df\u5206\u7c7b\u5668\u7684\u8bad\u7ec3\u6837\u672c\u6570\u91cf\u3002</p> <p>\u2003\u2003\u5047\u8bbe\u7b2ci\u4e2a\u8bad\u7ec3\u56fe\u7247\u7684\u57df\u6807\u7b7e\u8868\u793a\u4e3aD_i\uff0c\u5bf9\u4e8e\u6e90\u57df\u56fe\u7247D_i=0\uff0c\u5bf9\u4e8e\u76ee\u6807\u57df\u56fe\u7247D_i=1\u3002\u7b2ci\u5f20\u56fe\u5f97\u5230\u7684\u7279\u5f81\u56fe\u7684\u6fc0\u6d3b\u8868\u793a\u4e3a\\phi(I_i)\uff0c\u5e76\u4e14\u7279\u5f81\u56fe\u4e0a\u4f4d\u4e8e(u,v)\u4e0a\u7684\u6fc0\u6d3b\u8868\u793a\u4e3a\\phi_{u,v}(I_i)\uff0c\u5c06\u57df\u5206\u7c7b\u5668\u7684\u8f93\u51fa\u8868\u793a\u4e3ap_i^{(u,v)}\uff0c\u5e76\u4e14\u5206\u7c7b\u635f\u5931\u5229\u7528\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u5373\u56fe\u50cf\u7ea7\u81ea\u9002\u5e94\u635f\u5931\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ \\mathcal L_{img}=-\\sum_{i,u,v}[D_ilogp_i^{(u,v)}+(1-D_i)log(1-p_i^{(u,v)})] $$  \u2003\u2003\u4f18\u5316\u57df\u5206\u7c7b\u5668\u7684\u53c2\u6570\u6765\u6700\u5c0f\u5316\u4e0a\u8ff0\u635f\u5931\uff0c\u540c\u65f6\u4f18\u5316\u57fa\u5c42\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u7684\u53c2\u6570\u6765\u6700\u5927\u5316\u4e0a\u8ff0\u635f\u5931\uff0c\u5b9e\u65bd\u9636\u6bb5\u4f7f\u7528\u68af\u5ea6\u53cd\u8f6c\u5c42\u6765\u5b9e\u73b0\uff0c\u5373\u666e\u901a\u7684\u68af\u5ea6\u4e0b\u964d\u7528\u4e8e\u8bad\u7ec3\u57df\u5206\u7c7b\u5668\uff0c\u5f53\u68af\u5ea6\u901a\u8fc7\u68af\u5ea6\u53cd\u8f6c\u5c42\u65f6\u68af\u5ea6\u7b26\u53f7\u53cd\u8f6c\uff0c\u4ee5\u4f18\u5316\u57fa\u7840\u7f51\u7edc\u53c2\u6570\u3002</p> <p> \u5b9e\u4f8b\u7ea7\u522b\u7684\u81ea\u9002\u5e94\uff1a\u5b9e\u4f8b\u7ea7\u6c34\u5e73\u8868\u5f81\u662f\u6307\u5728\u8f93\u5165\u6700\u7ec8\u7c7b\u522b\u5206\u7c7b\u5668\u4e4b\u524d\u7684\u57fa\u4e8e\u611f\u5174\u8da3\u533a\u57df\u7684\u7279\u5f81\u5411\u91cf\uff0c\u4ee5Faster R-CNN\u4e3a\u4f8b\uff0c\u5373ROI Pooling\u4e4b\u540e\u7684\u7279\u5f81\uff0c\u5982\u4e0a\u56fe\u4e2d\uff0cFC\u5c42\u540e\u9762\u7684\u77e9\u5f62\u3002\u5bf9\u9f50\u5b9e\u4f8b\u7ea7\u7279\u5f81\u8868\u793a\u6709\u5229\u4e8e\u964d\u4f4e\u5c40\u90e8\u5b9e\u4f8b\u7684\u5dee\u5f02\uff0c\u5982\u5bf9\u8c61\u5916\u89c2\u3001\u5927\u5c0f\u3001\u89c6\u70b9\u7b49\u7b49\u3002\u5047\u8bbe\u7b2ci\u5f20\u56fe\u50cf\u4e2d\u7b2cj\u4e2a\u533a\u57df\u7684\u5b9e\u4f8b\u7ea7\u57df\u5206\u7c7b\u5668\u8f93\u51fa\u4e3ap_{i,j}\uff0c\u5b9e\u4f8b\u7ea7\u81ea\u9002\u5e94\u635f\u5931\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ \\mathcal L_{ins}=-\\sum_{i,j}[D_ilogp_{i,j}+(1-D_i)log(1-p_{i,j})] $$  \u4e0e\u56fe\u50cf\u7ea7\u57df\u5206\u7c7b\u5668\u7684\u8bad\u7ec3\u4e00\u6837\uff0c\u540c\u6837\u5728\u5b9e\u4f8b\u7ea7\u57df\u5206\u7c7b\u5668\u8bad\u7ec3\u7684\u8fc7\u7a0b\u4e2d\u6dfb\u52a0\u68af\u5ea6\u53cd\u8f6c\u6a21\u5c42\u3002</p> <p> \u4e00\u81f4\u6027\u6b63\u5219\u5316\u5668\uff1a\u5982\u4e0a\u6587\u5206\u6790\u7684\uff0c\u5f3a\u5236\u4e24\u4e2a\u5728\u4e0d\u540c\u6c34\u5e73\u4e0a\u7684\u57df\u5206\u7c7b\u5668\u5177\u6709\u4e00\u81f4\u6027\u53ef\u4ee5\u5e2e\u52a9\u8fb9\u754c\u6846\u9884\u6d4b\u5668\u5b66\u4e60\u8de8\u57df\u9c81\u68d2\u6027(\u5982Faster R-CNN\u4e2d\u7684RPN\u6a21\u5757)\uff0c\u56e0\u6b64\u4f5c\u8005\u8fdb\u4e00\u6b65\u6784\u5efa\u4e86\u4e00\u81f4\u6027\u6b63\u5219\u5316\u5668\u6765\u7ea6\u675f\u7f51\u7edc\u3002\u56e0\u4e3a\u56fe\u50cf\u7ea7\u6c34\u5e73\u57df\u5206\u7c7b\u5668\u4e3a\u56fe\u50cf\u7ea7\u6c34\u5e73\u8868\u5f81I\u7684\u6bcf\u4e2a\u6fc0\u6d3b\u70b9\u90fd\u63d0\u4f9b\u4e00\u4e2a\u8f93\u51fa\uff0c\u5373\u8f93\u51fa\u4e00\u5f20\u9886\u57df\u5bf9\u9f50\u56fe\uff0c\u56e0\u6b64\u4f5c\u8005\u5c06\u56fe\u50cf\u4e2d\u6240\u6709\u4f4d\u7f6e\u7684\u9884\u6d4b\u6982\u7387\u6c42\u4e00\u4e2a\u5e73\u5747\u503c\u4f5c\u4e3a\u56fe\u50cf\u7ea7\u9884\u6d4b\u6982\u7387\uff0c\u4e00\u81f4\u6027\u6b63\u5219\u5316\u5668\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ L_{cst}=\\sum_{i,j}\\left \\| \\frac1{|I|}\\sum_{u,v}p_i^{(u,v)}-p_{i,j} \\right \\|_2 $$  \u5176\u4e2d\uff0c|I|\u8868\u793a\u4e3a\u7279\u5f81\u56fe\u4e2d\u6fc0\u6d3b\u503c\u7684\u603b\u6570\uff0c||\u00b7||\u8868\u793a\u4e3al_2\u8ddd\u79bb\u3002</p>"},{"location":"domain_adaptive/paper/DAFaster1/#_8","title":"\u7f51\u7edc\u635f\u5931","text":"<p>\u2003\u2003\u7f51\u7edc\u7ed3\u6784\u5982\u4e0a\u56fe\u6240\u793a\uff0c\u4f5c\u8005\u4f7f\u7528\u4e86\u9886\u57df\u81ea\u9002\u5e94\u6a21\u5757\u6765\u6269\u5145Faster R-CNN\uff0c\u5728\u539f\u6709\u7684\u7f51\u7edc\u7ed3\u6784\u4e0a\u65b0\u5f15\u8fdb\u4e86\u4e09\u4e2a\u7f51\u7edc\u7ec4\u4ef6\u3002\u56fe\u50cf\u7ea7\u6c34\u5e73\u9886\u57df\u5206\u7c7b\u5668\u88ab\u6dfb\u52a0\u5230\u6700\u540e\u4e00\u5c42\u5377\u79ef\u4e4b\u540e\uff0c\u5b9e\u4f8b\u7ea7\u6c34\u5e73\u9886\u57df\u5206\u7c7b\u5668\u88ab\u6dfb\u52a0\u5230\u611f\u5174\u8da3\u7684\u533a\u57df\u7279\u5f81\u4e4b\u540e(ROI Pooling\u4e4b\u540e)\uff0c\u4e24\u4e2a\u5206\u7c7b\u5668\u901a\u8fc7\u4e00\u81f4\u6027\u635f\u5931\u8054\u7cfb\u5728\u4e00\u8d77\uff0c\u4ece\u800c\u9f13\u52b1RPN\u5177\u6709\u9886\u57df\u4e0d\u53d8\u6027\uff0c\u7f51\u7edc\u6700\u7ec8\u7684\u635f\u5931\u5982\u4e0b\uff1a $$ L=L_{det}+\\lambda(L_{img}+L_{ins}+L_{cst}) $$  \u5176\u4e2d\uff0c\\lambda\u662f\u4e00\u4e2a\u6743\u8861\u53c2\u6570\uff0c\u7528\u4e8e\u5e73\u8861\u539f\u59cb\u7684\u635f\u5931\u548c\u65b0\u52a0\u7ec4\u4ef6\u7684\u635f\u5931\u3002\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\u53ef\u4ee5\u5220\u53bb\u57df\u9002\u5e94\u7ec4\u4ef6\uff0c\u53ea\u9700\u4f7f\u7528\u539f\u59cb\u7684Faster R-CNN\u67b6\u6784\u9884\u6d4b\u56fe\u7247\u3002</p>"},{"location":"domain_adaptive/paper/DAFaster1/#map","title":"mAP\u5bf9\u6bd4","text":"<p>Cityscape \\rightarrow FoggyCityscape</p> <p> <p></p> <p></p>"},{"location":"domain_adaptive/paper/DAFaster1/#_9","title":"\u603b\u7ed3","text":"<p>\u2003\u2003\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u89e3\u51b3\u8de8\u57df\u76ee\u6807\u68c0\u6d4b\u95ee\u9898\u7684\u57df\u9002\u5e94Faster R-CNN\u7b97\u6cd5\uff0c\u53ef\u4ee5\u5b9e\u73b0\u5728\u4e0d\u4f7f\u7528\u4efb\u4f55\u9644\u52a0\u6807\u8bb0\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u83b7\u5f97\u65b0\u9886\u57df\u9c81\u68d2\u6027\u7684\u68c0\u6d4b\u5668\u3002\u4f5c\u8005\u5728\u5bf9\u8de8\u57df\u76ee\u6807\u68c0\u6d4b\u7406\u8bba\u5206\u6790\u7684\u57fa\u7840\u4e0a\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u56fe\u50cf\u7ea7\u81ea\u9002\u5e94\u7ec4\u4ef6\u548c\u5b9e\u4f8b\u7ea7\u81ea\u9002\u5e94\u7ec4\u4ef6\u6765\u7f13\u89e3\u7531\u57df\u504f\u79fb\u5f15\u8d77\u7684\u6a21\u578b\u6027\u80fd\u4e0b\u964d\u7684\u95ee\u9898\uff0c\u4e24\u4e2a\u7ec4\u4ef6\u7684\u8bad\u7ec3\u90fd\u662f\u57fa\u4e8e\\mathcal H\u6563\u5ea6\u7684\u5bf9\u6297\u6027\u8bad\u7ec3\u7684\uff0c\u5e76\u4e14\u4f5c\u8005\u8fd8\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u4e00\u81f4\u6027\u6b63\u5219\u5316\u5668\uff0c\u7528\u4e8e\u8fdb\u4e00\u6b65\u5b66\u4e60\u4e00\u4e2a\u57df\u4e0d\u53d8\u7684RPN\u7ec4\u4ef6\u3002</p> <p>\u6ce8\uff1a\u4ee5\u4e0a\u5185\u5bb9\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u5927\u5bb6\u6279\u8bc4\u6307\u6b63</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e741\u670828\u65e5</p>"},{"location":"domain_adaptive/paper/HTCN1/","title":"\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u2014\u2014HTCN","text":""},{"location":"domain_adaptive/paper/HTCN1/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aIEEE Conference on Computer Vision and Pattern Recognition 2020 (CVPR 2020)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content_CVPR_2020/papers/Chen_Harmonizing_Transferability_and_Discriminability_for_Adapting_Object_Detectors_CVPR_2020_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/chaoqichen/HTCN</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b</p>"},{"location":"domain_adaptive/paper/HTCN1/#_2","title":"\u4e3b\u8981\u601d\u60f3","text":"<p>\u2003\u2003\u76ee\u524d\u5927\u591a\u6570\u7684\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u90fd\u5229\u7528\u5bf9\u6297\u6027\u7684\u9002\u5e94\u635f\u5931\u6765\u4f7f\u7f51\u7edc\u5177\u6709\u53ef\u8f6c\u79fb\u6027(transferability)\uff0c\u7136\u800c\u7f51\u7edc\u53ef\u8f6c\u79fb\u6027\u7684\u4ea7\u751f\u662f\u5177\u6709\u4ee3\u4ef7\u7684\uff0c\u7531\u4e8e\u5e76\u4e0d\u662f\u6240\u6709\u7684\u7279\u5f81\u90fd\u5177\u6709\u76f8\u540c\u7684\u53ef\u8f6c\u79fb\u6027\uff0c\u56e0\u6b64\u5bf9\u6297\u6027\u7684\u9002\u5e94\u4f1a\u6f5c\u5728\u5730\u635f\u5bb3\u76ee\u6807\u57df\u56fe\u50cf\u7279\u5f81\u7684\u53ef\u8fa8\u522b\u6027\u3002\u7531\u4e8e\u56fe\u50cf\u4e2d\u5404\u79cd\u5bf9\u8c61\u5177\u6709\u6bd4\u8f83\u590d\u6742\u7684\u7ec4\u5408\u4ee5\u53ca\u4e0d\u540c\u9886\u57df\u4e4b\u95f4\u5177\u6709\u4e0d\u540c\u7684\u573a\u666f\u5e03\u5c40\uff0c\u56e0\u6b64\u8fd9\u79cd\u73b0\u8c61\u5728\u8de8\u57df\u76ee\u6807\u68c0\u6d4b\u4e2d\u66f4\u4e3a\u4e25\u91cd\u3002\u6362\u53e5\u8bdd\u8bf4\uff0c\u901a\u8fc7\u5bf9\u6297\u5b66\u4e60\u4e25\u683c\u6267\u884c\u5bf9\u9f50\u4e24\u4e2a\u9886\u57df\u4e4b\u95f4\u6574\u4e2a\u7279\u5f81\u5206\u5e03\u5bb9\u6613\u5bfc\u81f4\u8d1f\u8f6c\u79fb(negative domain)\uff0c\u56e0\u4e3a\u4e0d\u540c\u5c42\u6b21\uff08\u5982\u5c40\u90e8\u3001\u5168\u5c40\u4ee5\u53ca\u5b9e\u4f8b\uff09\u7684\u53ef\u8f6c\u79fb\u6027\u5728\u76ee\u6807\u68c0\u6d4b\u5668\u4e2d\u6ca1\u6709\u5f97\u5230\u660e\u786e\u7684\u9610\u8ff0\uff08\u5373\u7f51\u7edc\u5e76\u4e0d\u77e5\u9053\u56fe\u50cf\u54ea\u91cc\u8f6c\u79fb\u6027\u9ad8\u3001\u54ea\u91cc\u8f6c\u79fb\u6027\u4f4e\uff0c\u56e0\u6b64\u672c\u6587\u4e3b\u8981\u7684\u601d\u60f3\u5c31\u662f\u5bf9\u7279\u5f81\u56fe\u8fdb\u884c\u52a0\u6743\uff09\u3002</p> <p>\u2003\u2003\u6ce8\uff1a\u672c\u6587\u4e2d\u7684\u8f6c\u79fb\u6027\u8868\u793a\u7f51\u7edc\u5b66\u5230\u8de8\u9886\u57df\u7684\u4e0d\u53d8\u6027\uff0c\u5373\u540c\u4e00\u7269\u4f53\u5728\u4e0d\u540c\u9886\u57df\u73af\u5883\u4e0b\u4ea7\u751f\u76f8\u540c\u7684\u7279\u5f81\uff0c\u8f6c\u79fb\u6027\u8d8a\u5f3a\uff0c\u8868\u793a\u8d8a\u5bb9\u6613\u8de8\u57df\u4ea7\u751f\u76f8\u540c\u7684\u7279\u5f81\uff1b\u53ef\u8fa8\u522b\u6027\u8868\u793a\u68c0\u6d4b\u5668\u5b9a\u4f4d\u548c\u533a\u5206\u4e0d\u540c\u5bf9\u8c61\u5b9e\u4f8b\u7684\u80fd\u529b\uff0c\u5373\u6a21\u578b\u5bf9\u56fe\u50cf\u7269\u4f53\u7684\u68c0\u6d4b\u80fd\u529b\u3002</p> <p>\u2003\u2003\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5206\u5c42\u53ef\u8f6c\u79fb\u6027\u6821\u51c6\u7f51\u7edc(Hierarchical Transferability Calibration Network, HTCN)\u6765\u4e3a\u8de8\u57df\u76ee\u6807\u68c0\u6d4b\u5668\u534f\u8c03\u53ef\u8f6c\u79fb\u6027\u548c\u53ef\u8fa8\u522b\u6027\uff0c\u901a\u8fc7\u5206\u5c42\u6821\u51c6\u5177\u6709\u53ef\u8fa8\u522b\u6027\u8868\u5f81(\u7279\u5f81\u8868\u793a)\u7684\u53ef\u8f6c\u79fb\u6027\uff0c\u6765\u89c4\u8303\u5bf9\u6297\u6027\u9002\u5e94\u3002\u5177\u4f53\u5730\u6765\u8bf4\uff0c\u9996\u5148\u63d0\u51fa\u4e86\u4e00\u4e2a\u5177\u6709\u8f93\u5165\u63d2\u503c\u7684\u91cd\u8981\u6027\u52a0\u6743\u5bf9\u6297\u8bad\u7ec3\u7b56\u7565(Importance Weighted Adversarial Training with input Interpolation, IWAT-I)\uff0c\u8be5\u6a21\u5757\u56f4\u7ed5\u4e00\u4e2a\u601d\u60f3\uff0c\u5373\u5e76\u975e\u6240\u6709\u6837\u672c\u90fd\u540c\u7b49\u5730\u5177\u6709\u53ef\u8f6c\u79fb\u6027\uff0c\u63d0\u51fa\u4e86\u5bf9\u7279\u5f81\u7a7a\u95f4\u8fdb\u884c\u91cd\u65b0\u52a0\u6743\u7684\u7b56\u7565\uff0c\u4ece\u800c\u589e\u5f3a\u5168\u5c40\u7684\u53ef\u8fa8\u522b\u6027\uff1b\u5176\u6b21\uff0c\u8003\u8651\u5230\u7ed3\u6784\u5316\u7684\u573a\u666f\u5e03\u5c40\u548c\u68c0\u6d4b\u4efb\u52a1\u7684\u5c40\u90e8\u6027\u8d28\uff0c\u4f5c\u8005\u8fd8\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5177\u6709\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5b9e\u4f8b\u7ea7\u5bf9\u9f50\u6a21\u5757(Context-aware Instance-Level Alignment, CILA)\uff0c\u901a\u8fc7\u6355\u6349\u5b9e\u4f8b\u7ea7\u7279\u5f81\u548c\u5168\u5c40\u4e0a\u4e0b\u6587\u4fe1\u606f\u4e4b\u95f4\u7684\u4e92\u8865\u6548\u5e94\u6765\u589e\u5f3a\u5c40\u90e8\u7684\u53ef\u8fa8\u522b\u6027\uff0c\u4e0d\u540c\u4e8e\u4ee5\u524d\u7684\u5de5\u4f5c\uff08\u5982SW Distribution Alignment\uff0c\u76f4\u63a5\u5bf9\u4e0a\u4e0b\u6587\u5411\u91cf\u8fdb\u884c\u94fe\u63a5\uff09\uff0c\u4f5c\u8005\u5229\u7528\u5f20\u91cf\u79ef\u8fd0\u7b97\u6765\u8fdb\u884c\u66f4\u591a\u7684\u4fe1\u606f\u878d\u5408\uff1b\u6700\u540e\uff0c\u7531\u4e8e\u6574\u4e2a\u56fe\u50cf\u7684\u4e00\u4e9b\u5c40\u90e8\u5730\u533a\u66f4\u5177\u6709\u63cf\u8ff0\u6027\u4ee5\u53ca\u5360\u6709\u4e3b\u5bfc\u5730\u4f4d\uff0c\u56e0\u6b64\u4f5c\u8005\u8fdb\u4e00\u6b65\u63d0\u51fa\u4e86\u4e00\u79cd\u63d0\u9ad8\u5c40\u90e8\u53ef\u8fa8\u522b\u6027\u7684\u5c40\u90e8\u7279\u5f81\u63a9\u6a21\u65b9\u6cd5(local feature mask)\uff0c\u901a\u8fc7\u8ba1\u7b97\u4e24\u4e2a\u9886\u57df\u4e4b\u95f4\u57fa\u4e8e\u6d45\u5c42\u7279\u5f81\u7684\u5c40\u90e8\u63a9\u6a21\u56fe\u6765\u5927\u81f4\u6307\u5bfc\u7f51\u7edc\u7684\u8bed\u4e49\u4e00\u81f4\u6027\u5bf9\u9f50\uff0c\u8fd9\u53ef\u4ee5\u88ab\u89c6\u4e3a\u4e00\u4e2a\u7c7b\u4f3c\u5229\u7528\u6ce8\u610f\u529b\u6a21\u5757\u6765\u6355\u6349\u5c40\u90e8\u53ef\u8f6c\u79fb\u533a\u57df\u7684\u65e0\u76d1\u7763\u65b9\u6cd5\u3002\u901a\u8fc7HTCN\u7b97\u6cd5\uff0c\u7f51\u7edc\u53ef\u4ee5\u6709\u6548\u5730\u534f\u8c03\u53ef\u8f6c\u79fb\u6027\u548c\u53ef\u5224\u522b\u6027\u4e4b\u95f4\u7684\u6f5c\u5728\u77db\u76fe\uff0c\u663e\u8457\u5730\u6269\u5c55\u4e86\u4ee5\u5f80\u57fa\u4e8e\u5bf9\u6297\u6027\u7684\u81ea\u9002\u5e94\u68c0\u6d4b\u65b9\u6cd5\u3002</p>"},{"location":"domain_adaptive/paper/HTCN1/#_3","title":"\u65b9\u6cd5","text":"<p>\u2003\u2003HTCN\u7b97\u6cd5\u6846\u67b6\u662f\u57fa\u4e8eFaster-RCNN\u76ee\u6807\u68c0\u6d4b\u6846\u67b6\u800c\u8bbe\u8ba1\u7684\uff0c\u5728\u539f\u6709\u7684\u6846\u67b6\u4e0a\u4e3b\u8981\u589e\u52a0\u4e86\u4e09\u4e2a\u6a21\u5757\uff0c\u5373IWAT-I\u3001CILA\u4ee5\u53ca\u9488\u5bf9\u8bed\u4e49\u4e00\u81f4\u6027\u7684\u5c40\u90e8\u7279\u5f81\u63a9\u7801\u3002IWAT-I\u901a\u8fc7\u5bf9\u7279\u5f81\u7a7a\u95f4\u8fdb\u884c\u91cd\u65b0\u52a0\u6743\u6765\u89c4\u8303\u56fe\u50cf\u7ea7\u5bf9\u6297\u81ea\u9002\u5e94\uff0c\u4ee5\u6821\u51c6\u5168\u5c40\u7279\u5f81\u7684\u53ef\u8f6c\u79fb\u6027\uff1bCILA\u5229\u7528\u5f20\u91cf\u79ef\u8fd0\u7b97\u89c4\u8303\u5b9e\u4f8b\u7ea7\u5bf9\u6297\u81ea\u9002\u5e94\uff0c\u4ee5\u6821\u51c6\u5c40\u90e8\u7279\u5f81\u7684\u53ef\u8f6c\u79fb\u6027\uff0c\u4ece\u800c\u589e\u5f3a\u5b9e\u4f8b\u7ea7\u7279\u5f81\u548c\u805a\u5408\u4e0a\u4e0b\u6587\u5411\u91cf\u4e4b\u95f4\u7684\u4fe1\u606f\u4ea4\u4e92\uff0c\u7f51\u7edc\u5177\u4f53\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u95ee\u9898\u91cd\u8ff0</p> <p>\u2003\u2003\u5bf9\u4e8e\u8de8\u57df\u76ee\u6807\u68c0\u6d4b\uff0c\u9700\u8981\u540c\u65f6\u9884\u6d4b\u5bf9\u8c61\u4f4d\u7f6e\u7684\u8fb9\u754c\u6846\u4fe1\u606f\u548c\u5bf9\u8c61\u7c7b\u522b\u3002\u4e00\u822c\u6765\u8bf4\uff0c\u5bf9\u4e8eN_s\u5f20\u6709\u6807\u7b7e\u7684\u6e90\u57df\u6570\u636e\u8868\u793a\u4e3a\\mathcal D_s=\\{(x^s_i,y^s_i,b^s_i)\\}^{N_s}_{i=1} (y^s_i\\in\\mathcal R^{k=1},b^s_i\\in\\mathcal R^{k\\times 4})\uff0c\u5bf9\u4e8eN_t\u5f20\u65e0\u6807\u7b7e\u7684\u76ee\u6807\u57df\u6570\u636e\u8868\u793a\u4e3a\\mathcal D_t=\\{x^t_j\\}^{N_t}_{j=1}\uff0c\u672c\u6587\u7684\u76ee\u6807\u5c31\u662f\u5229\u7528\u5e26\u6709\u6807\u7b7e\u7684\\mathcal D_s\u548c\u4e0d\u5e26\u6807\u7b7e\u7684\\mathcal D_t\u8bad\u7ec3\u4e00\u4e2a\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u5668\uff0c\u8be5\u68c0\u6d4b\u5668\u53ef\u4ee5\u5728\u76ee\u6807\u9886\u57df\u4e0a\u6267\u884c\u6548\u679c\u826f\u597d\u7684\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u3002</p> <p>\u2003\u2003\u5982\u4e0a\u6587\u63d0\u5230\u7684\uff0c\u5728\u4f7f\u7528\u5bf9\u6297\u635f\u5931\u6267\u884c\u9886\u57df\u9002\u5e94\u65f6\uff0c\u8de8\u57df\u68c0\u6d4b\u4efb\u52a1\u4e2d\u7684\u53ef\u8f6c\u79fb\u6027\u548c\u53ef\u8fa8\u522b\u6027\u53ef\u80fd\u4f1a\u5b58\u5728\u6f5c\u5728\u7684\u77db\u76fe\uff0c\u56e0\u6b64\u672c\u7b97\u6cd5\u4e3b\u8981\u4ece\u5982\u4e0b\u4e24\u4e2a\u65b9\u9762\u89e3\u51b3\u8be5\u95ee\u9898\uff1a\u2460\u901a\u8fc7\u5206\u5c42\u8bc6\u522b\u548c\u5339\u914d\u53ef\u8f6c\u79fb\u7684\u5c40\u90e8\u533a\u57df\u7279\u5f81(\u5c40\u90e8\u7279\u5f81\u63a9\u7801)\u3001\u56fe\u50cf\u7ea7\u7279\u5f81(IWAT-I)\u4ee5\u53ca\u57fa\u4e8eROI\u7684\u5b9e\u4f8b\u7ea7\u7279\u5f81(CIAL)\u6765\u6821\u51c6\u6a21\u578b\u53ef\u8f6c\u79fb\u6027\uff1b\u2461\u901a\u8fc7\u57fa\u4e8e\u5c42\u6b21\u53ef\u8f6c\u79fb\u6027\u7684\u8de8\u57df\u5bf9\u9f50\u6765\u4ece\u591a\u4e2a\u5c42\u6b21\u4e0a\u63d0\u9ad8\u6a21\u578b\u7279\u5f81\u7684\u53ef\u8fa8\u522b\u6027\u3002</p>"},{"location":"domain_adaptive/paper/HTCN1/#_4","title":"\u5bf9\u6297\u8bad\u7ec3\u7684\u91cd\u8981\u6027\u52a0\u6743","text":"<p>\u2003\u2003\u867d\u7136\u5bf9\u6297\u6027\u7684\u57df\u9002\u5e94\u65b9\u6cd5\u662f\u4e00\u79cd\u5178\u578b\u5e76\u4e14\u6709\u6548\u5730\u57df\u5bf9\u9f50\u65b9\u6cd5\uff0c\u4f46\u662f\u7531\u4e8e\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u4e2d\u5177\u6709\u4e0d\u540c\u7684\u573a\u666f\u5e03\u5c40\u3001\u4e0d\u540c\u7684\u5bf9\u8c61\u7ec4\u5408\u65b9\u5f0f(\u540c\u4e00\u4e2a\u573a\u666f\u53ef\u80fd\u51fa\u73b0\u4e0d\u540c\u7c7b\u522b\u7684\u5bf9\u8c61)\uff0c\u56e0\u6b64\u5f88\u96be\u751a\u81f3\u4e0d\u53ef\u80fd\u660e\u786e\u5730\u9f13\u52b1\u6a21\u578b\u5177\u6709\u8de8\u57df\u8bed\u4e49\u4e00\u81f4\u6027\uff0c\u8bed\u4e49\u5206\u5272\u6216\u8005\u56fe\u50cf\u5206\u7c7b\u4e2d\u4f7f\u7528\u7eaf\u57df\u5bf9\u9f50\u7684\u65b9\u6cd5\u4f1a\u6f5c\u5728\u5730\u6076\u5316\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u7684\u8bed\u4e49\u4e00\u81f4\u6027\u3002</p> <p>\u2003\u2003\u4e3a\u4e86\u514b\u670d\u8de8\u57df\u68c0\u6d4b\u4e2d\u7684\u8d1f\u8f6c\u79fb\uff0c\u4f5c\u8005\u63d0\u51fa\u7684IWAT-I\u901a\u8fc7\u5728\u4e24\u4e2a\u9886\u57df\u4e4b\u95f4\u751f\u6210\u63d2\u503c\u6837\u672c\u6765\u5c06\u6e90\u504f\u7f6e(source biased)\u51b3\u7b56\u8fb9\u754c\u9002\u7528\u4e8e\u76ee\u6807\u6570\u636e\uff0c\u9690\u5f0f\u5730\u8bf1\u5bfc\u5bf9\u6297\u6027\u8bad\u7ec3\u6536\u655b\u5230\u4e00\u4e2a\u66f4\u597d\u7684\u978d\u70b9\uff0c\u5e76\u4e14\u663e\u5f0f\u7684\u6821\u51c6\u5168\u5c40\u7684\u53ef\u8f6c\u79fb\u6027\u4ee5\u9f13\u52b1\u79ef\u6781\u7684\u8f6c\u79fb\u3002\u57fa\u4e8e\u63d2\u503c\u7684\u5bf9\u6297\u6027\u8bad\u7ec3\u6548\u679c\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u4e0a\u56fe\u4e2d\u5708\u548c\u53c9\u5206\u522b\u8868\u793a\u4e24\u7c7b\u7269\u4f53\uff0c\u7531\u4e0a\u56fe\u6240\u793a\uff0c\u5728\u6ca1\u6709\u63d2\u503c\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u5bf9\u6297\u6027\u8bad\u7ec3\u5b66\u5230\u7684\u8fb9\u754c\u5bb9\u6613\u51fa\u73b0\u6e90\u504f\u7f6e\uff0c\u5373\u51b3\u7b56\u9762\u5bb9\u6613\u504f\u5411\u6e90\u57df\u6570\u636e\uff0c\u4ece\u800c\u964d\u4f4e\u6a21\u578b\u8fa8\u522b\u76ee\u6807\u57df\u6570\u636e\u7684\u80fd\u529b\uff0c\u5982\u4e0a\u56fe\u53f3\u4fa7\u7b2c\u4e00\u4e2a\u4f8b\u5b50\uff0c\u51b3\u7b56\u8fb9\u754c\u5c06\u90e8\u5206\u76ee\u6807\u57df\u4e2d\u7684\u5708\u7c7b\u5212\u5206\u5230\u4e86\u53c9\u7c7b\u9886\u57df\u3002\u63d2\u503c\u64cd\u4f5c\u901a\u8fc7\u5408\u6210\u6837\u672c\u6765\u586b\u8865\u51b3\u7b56\u8fb9\u754c\u7684\u5206\u5e03\u5dee\u8ddd\uff0c\u4ece\u800c\u63d0\u9ad8\u6a21\u578b\u5bf9\u76ee\u6807\u57df\u6570\u636e\u7684\u8fa8\u8bc6\u80fd\u529b\uff0c\u5982\u7b2c\u4e8c\u4e2a\u4f8b\u5b50\uff0c\u901a\u8fc7\u586b\u5145\u5408\u6210\u7684\u6837\u672c\uff0c\u53ef\u4ee5\u8ba9\u6a21\u578b\u6210\u529f\u5c06\u53c9\u7c7b\u4e0e\u5708\u7c7b\u5206\u5f00\u3002</p> <p>\u2003\u2003\u63d2\u503c\u64cd\u4f5c\u662f\u5229\u7528CycleGAN\u7b97\u6cd5(\u8bba\u6587\u94fe\u63a5)\u5b9e\u73b0\u7684\uff0c\u5373\u4ece\u5bf9\u5e94\u7684\u9886\u57df\u751f\u6210\u5408\u6210\u6837\u672c\u6765\u586b\u5145\u57df\u4e4b\u95f4\u7684\u5206\u5e03\u95f4\u9699\u3002\uff08\u4f46\u8fd9\u91cc\u7684\u63d2\u503c\u662f\u4ec0\u4e48\uff1f\u4e3a\u4ec0\u4e48\u548cCycleGAN\u6709\u5173\uff1f\u95ee\u9898\u8bb0\u5f55\uff09\u540e\u9762\uff0c\u6839\u636e\u63d2\u503c\u6570\u636e\u7a7a\u95f4\u7684\u91cd\u8981\u6027\u6765\u5bf9\u7279\u5f81\u8fdb\u884c\u91cd\u65b0\u52a0\u6743\uff0c\u5373\u5728\u56fe\u50cf\u7ea7\u522b\u5bf9\u7279\u5f81\u8fdb\u884c\u52a0\u6743\uff0c\u800c\u91cd\u8981\u6027\u4e0e\u8de8\u57df\u76f8\u4f3c\u6027\u76f8\u5173\u8054\uff0c\u4f8b\u5982\u5982\u679c\u6837\u672c\u7279\u5f81\u5728\u4e24\u4e2a\u9886\u57df\u4e4b\u95f4\u76f8\u4f3c\u6027\u8d8a\u9ad8\uff0c\u5373\u5206\u7c7b\u5668\u8d8a\u4e0d\u5bb9\u6613\u5224\u65ad\u9886\u57df\u5f52\u5c5e\uff0c\u5219\u8be5\u6837\u672c\u7684\u91cd\u8981\u6027\u5c31\u8d8a\u5927\u3002\u7531\u4e8e\u5e76\u4e0d\u662f\u6240\u6709\u7684\u56fe\u50cf\u5728\u9886\u57df\u8f6c\u79fb\u65b9\u9762\u90fd\u662f\u4e00\u6837\u7684\uff0c\u56e0\u6b64\u4f5c\u8005\u5229\u7528\u91cd\u8981\u6027\u6765\u589e\u52a0\u7406\u60f3\u7684\u56fe\u50cf\u6837\u672c\u7684\u6743\u91cd\uff0c\u4ece\u800c\u6821\u51c6\u56fe\u50cf\u7ea7\u7684\u53ef\u8f6c\u79fb\u6027\u3002</p> <p>\u2003\u2003\u5177\u4f53\u7684\u6765\u8bf4\uff0c\u4f5c\u8005\u5229\u7528\u57df\u5224\u522b\u5668\u76f8\u5bf9\u4e8e\u8f93\u5165\u6837\u672c\u7684\u4e0d\u786e\u5b9a\u6027\u6765\u53d1\u73b0\u53ef\u8f6c\u79fb\u6837\u672c\uff0c\u5047\u8bbe\u8f93\u5165\u56fe\u50cf\u4e3ax_i\uff0c\u5224\u522b\u5668D_2\u7684\u8f93\u51fa\u4e3ad_i=D_2(G_1\\circ G_2(x_i))\uff0c\u4e4b\u540e\u6bcf\u4e2ax_i\u7684\u4e0d\u786e\u5b9a\u6027v_i\u53ef\u7531\u57df\u5224\u522b\u5668\u8f93\u51fa\u7684\u4fe1\u606f\u71b5\u8861\u91cf\uff1a $$ v_i=H(d_i)=-d_i\u00b7\\log(d_i)-(1-d_i)\u00b7\\log(1-d_i) $$  \u5176\u4e2dH(\u00b7)\u8868\u793a\u71b5\u51fd\u6570\uff0c\u71b5\u503cv_i\u8d8a\u5927\uff0c\u8868\u793a\u5206\u7c7b\u5668\u8d8a\u4e0d\u786e\u5b9a\u8be5\u56fe\u7247\u7684\u9886\u57df\u5f52\u5c5e\uff0c\u56e0\u6b64\u6bcf\u4e2a\u56fe\u50cfx_i\u7684\u6743\u91cd\u53ef\u4ee5\u8868\u793a\u4e3a1+v_i\uff0c\u5177\u6709\u8f83\u9ad8\u4e0d\u786e\u5b9a\u6027\u7684\u56fe\u50cf\u5e94\u8be5\u88ab\u8d4b\u4e88\u8f83\u9ad8\u7684\u6743\u91cd\uff08\u5bf9\u6574\u5f20\u56fe\u50cf\u52a0\u6743\uff09\uff0c\u53cd\u4e4b\u4ea6\u7136\uff08\u8fd9\u91cc\u7684\u601d\u60f3\u6709\u70b9\u7c7b\u4f3cStrong-Weak\u7b97\u6cd5\u4e2d\u7684\u5f31\u5168\u5c40\u5bf9\u9f50\u6a21\u5757\u7684\u601d\u60f3\uff09\u3002\u4e4b\u540e\uff0c\u53ef\u4ee5\u7531\u5982\u4e0b\u516c\u5f0f\u5bf9\u539f\u7279\u5f81\u8fdb\u884c\u91cd\u65b0\u52a0\u6743\uff1a $$ g_i=f_i\\times (1+v_i) $$  \u5176\u4e2df_i\u8868\u793a\u4f20\u5165D_2\u4e4b\u524d\u7684\u7279\u5f81\uff0cD_3\u7684\u8f93\u5165\u4e3aG_3(g_i)\uff0c\u5bf9\u6297\u635f\u5931\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ \\mathcal L_{ga}=\\mathbb E[log(D_3(G_3(g_i^s)))]+\\mathbb E[1-log(D_3(G_3(g_i^t)))] $$  \u4e00\u822c\\mathbb E\u5e94\u8be5\u662f\u8868\u793a\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u4f46\u6e90\u7801\u91cc\u7528\u7684\u662fFocal Loss\uff0c\u4e0e\u5f31\u5168\u5c40\u5bf9\u9f50\u6a21\u5757\u7684\u635f\u5931\u7c7b\u4f3c\u3002</p>"},{"location":"domain_adaptive/paper/HTCN1/#_5","title":"\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5b9e\u4f8b\u7ea7\u5bf9\u9f50","text":"<p>\u2003\u2003\u57fa\u4e8eROI-Pooling\u7684\u5b9e\u4f8b\u7ea7\u5bf9\u9f50\u53ef\u4ee5\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u51cf\u8f7b\u8de8\u57df\u7684\u5c40\u90e8\u5b9e\u4f8b\u504f\u5dee\uff0c\u6bd4\u5982\u5bf9\u8c61\u5c3a\u5ea6\u3001\u89c6\u89d2\u3001\u5916\u89c2\u7b49\u7b49\uff0c\u4f46\u5982\u679c\u4ec5\u5bf9\u9f50\u5c40\u90e8\u533a\u57df\u7684\u8bdd\uff0c\u4f1a\u5e26\u6765\u4e00\u4e2a\u95ee\u9898\uff0c\u5373ROI\u533a\u57df\u7279\u5f81\u5411\u91cf\u90fd\u72ec\u7acb\u5730\u8868\u793a\u5c40\u90e8\u5bf9\u8c61\uff0c\u800c\u4e0d\u8003\u8651\u6574\u4f53\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u800c\u4e0a\u4e0b\u6587\u7279\u5f81\u662f\u540e\u7eed\u68c0\u6d4b\u7684\u4fe1\u606f\u6027\u548c\u51b3\u5b9a\u6027\u56e0\u7d20\uff0c\u5e76\u4e14\u662f\u5f15\u5bfc\u57df\u4e4b\u95f4\u7cbe\u786e\u5c40\u90e8\u5b9e\u4f8b\u5bf9\u9f50\u7684\u5148\u51b3\u6761\u4ef6\u3002\u53e6\u4e00\u65b9\u9762\uff0c\u7531\u4e8e\u6df1\u5c42\u7279\u5f81\u6700\u7ec8\u6cbf\u7740\u7f51\u7edc\u4ece\u9886\u57df\u4e0d\u53ef\u77e5(domain-agnostic)\u8fc7\u6e21\u5230\u9886\u57df\u7279\u5b9a(domain-specific)\uff0c\u56e0\u6b64\u4ece\u6df1\u5c42\u7f51\u7edc\u83b7\u5f97\u7684\u5b9e\u4f8b\u7ea7\u7279\u5f81\u5728\u57df\u4e4b\u95f4\u53ef\u80fd\u662f\u4e0d\u540c\u7684(\u5177\u6709\u8fa8\u8bc6\u529b)\uff0c\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u4e0a\u4e0b\u6587\u5411\u91cf\u662f\u4ece\u8f83\u4f4e\u5c42\u7684\u7279\u5f81\u805a\u5408\u800c\u6765\u7684\uff0c\u5728\u57df\u4e4b\u95f4\u5177\u6709\u76f8\u5bf9\u4e0d\u53d8\u6027(\u5177\u6709\u8f6c\u79fb\u6027)\uff0c\u56e0\u6b64\uff0c\u5408\u7406\u5730\u878d\u5408\u8fd9\u4e24\u7ec4\u7279\u5f81\u53ef\u4ee5\u8fdb\u4e00\u6b65\u8ba9\u7f51\u7edc\u63a2\u7d22\u4ed6\u4eec\u4e4b\u95f4\u7684\u4e92\u8865\u6027\u3002</p> <p>\u2003\u2003\u53d7\u6b64\u542f\u53d1\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e0a\u4e0b\u6587\u611f\u77e5\u5b9e\u4f8b\u7ea7\u57df\u5bf9\u9f50\u6a21\u5757(CILA)\uff0c\u901a\u8fc7\u5c06\u4e0a\u4e0b\u6587\u5411\u91cf\u548c\u5b9e\u4f8b\u7ea7\u7279\u5f81\u52a0\u4ee5\u878d\u5408\uff0c\u6765\u663e\u5f0f\u5bf9\u9f50\u6a21\u578b\u5728\u4e24\u4e2a\u9886\u57df\u4e4b\u95f4\u7684\u5b9e\u4f8b\u7ea7\u7279\u5f81\u8868\u793a\u3002\u4e00\u822c\u5730\u6765\u8bf4\uff0c\u5c06\u4e0d\u540c\u6c34\u5e73\u7684\u4e0a\u4e0b\u6587\u5411\u91cf\u4f9d\u6b21\u8868\u793a\u4e3af^1_c,f^2_c\u4ee5\u53caf^3_c\uff0c\u7b2ci\u5f20\u56fe\u7247\u7684\u7b2cj\u4e2a\u5b9e\u4f8b\u533a\u57df\u7279\u5f81\u8868\u793a\u4e3af^{(i,j)}_{ins}\uff0c\u4e3a\u4e86\u7b80\u5355\u8d77\u89c1\uff0c\u5c06\u5b9e\u4f8b\u7ea7\u7279\u5f81\u8868\u793a\u4e3af_{ins}\u3002\u878d\u5408\u8fd9\u4e9b\u7279\u5f81\u7684\u6700\u597d\u65b9\u6cd5\u5c31\u662f\u5c06\u4ed6\u4eec\u5408\u5e76\u8d77\u6765(\u4f8b\u5982\uff1aSW-Distribution Alignment)\uff0c\u5373\u5408\u5e76f_c^1,f_c^2,f_c^3\u4e0ef_{ins}\u4e3a[f_c^1,f_c^2,f_c^3,f_{ins}]\u3002\u8fd9\u79cd\u65b9\u6cd5\u867d\u7136\u7b80\u5355\uff0c\u4f46\u662f\u5177\u6709\u8f83\u5f3a\u7684\u5c40\u9650\u6027\uff0c\u5373\u4e0a\u4e0b\u6587\u7279\u5f81\u548c\u5b9e\u4f8b\u7ea7\u7279\u5f81\u76f8\u4e92\u95f4\u662f\u72ec\u7acb\u7684\uff0c\u5ffd\u7565\u4e86\u6f5c\u5728\u7684\u4e92\u8865\u6548\u5e94\u3002\u6b64\u5916\uff0c\u7531\u4e8e\u4e0a\u4e0b\u6587\u5411\u91cf\u548c\u5b9e\u4f8b\u7ea7\u7279\u5f81\u901a\u5e38\u662f\u4e0d\u5bf9\u79f0\u7684\uff0c\u5373\u957f\u5ea6\u901a\u5e38\u4e0d\u76f8\u7b49\uff0c\u56e0\u6b64\u4e00\u4e9b\u5e38\u7528\u7684\u65b9\u6cd5(\u5982\u5143\u7d20\u79ef\u3001\u6c42\u5747\u503c\u7b49\u7b49)\u5c06\u4e0d\u80fd\u7528\u4e8e\u8fd9\u91cc\u7684\u878d\u5408\u4efb\u52a1\u3002</p> <p>\u2003\u2003\u4e3a\u4e86\u514b\u670d\u8fd9\u4e00\u4e2a\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u975e\u7ebf\u6027\u7684\u878d\u5408\u7b56\u7565\uff1a $$ f_{fus}=[f^1_c,f^2_c,f^3_c]\\otimes f_{ins} $$  \u5176\u4e2d\\otimes\u8868\u793a\u5f20\u91cf\u4e58\u79ef\u64cd\u4f5c(\u975e\u5143\u7d20\u79ef)\uff0cf_{fus}\u4e3a\u878d\u5408\u540e\u7684\u7279\u5f81\u5411\u91cf\uff0c\u901a\u8fc7\u8be5\u4e58\u79ef\u8fd0\u7b97\uff0c\u53ef\u4ee5\u5f88\u597d\u5730\u8ba9\u7f51\u7edc\u6355\u6349\u4e0a\u4e0b\u6587\u7279\u5f81\u548c\u5b9e\u4f8b\u7ea7\u7279\u5f81\u4e4b\u95f4\u7684\u4fe1\u606f\u4ea4\u4e92\u3002\u4f46\u662f\uff0c\u8be5\u7b56\u7565\u8fd8\u9762\u4e34\u4e00\u4e2a\u7ef4\u6570\u7206\u70b8\u7684\u95ee\u9898\uff0c\u5177\u4f53\u5730\u6765\u8bf4\uff0c\u5047\u8bbe\u5c06[f^1_c,f^2_c,f^3_c]\u7b80\u6d01\u8868\u793a\u4e3af_c\uff0c\u7ef4\u6570\u5047\u5b9a\u4e3ad_c\uff0cf_{ins}\u7684\u7ef4\u6570\u5047\u8bbe\u4e3ad_{ins}\uff0c\u7ecf\u8fc7\u5f20\u91cf\u4e58\u79ef\u540e\uff0c\u878d\u5408\u540e\u7684\u7279\u5f81f_{fus}\u7ef4\u6570\u4e3ad_c\\times d_{ins}\uff0c\u9762\u5bf9\u9ad8\u7ef4\u6570\u636e\u5c06\u96be\u4ee5\u8fdb\u884c\u540e\u7eed\u7684\u4f18\u5316\u3002\u4e3a\u4e86\u89e3\u51b3\u7ef4\u6570\u7206\u70b8\u95ee\u9898\uff0c\u4f5c\u8005\u53c2\u8003\u8bba\u6587\u300aRandom feature maps for dot product kernels\u300b\u5229\u7528\u968f\u673a\u5316\u65b9\u6cd5\u4f5c\u4e3a\u5f20\u91cf\u79ef\u7684\u65e0\u504f\u4f30\u8ba1\u91cf\uff0c\u6700\u7ec8\u878d\u5408\u7279\u5f81\u7684\u8ba1\u7b97\u65b9\u7a0b\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ f_{fus}=\\frac1{\\sqrt{d}}(R_1f_c)\\odot(R_2f_{ins}) $$  \u5176\u4e2d\\odot\u8868\u793a\u54c8\u8fbe\u739b\u79ef\uff0c\u5373\u5143\u7d20\u79ef\uff0cR_1\u548cR_2\u4e3a\u968f\u673a\u77e9\u9635\uff0c\u77e9\u9635\u5c3a\u5bf8\u5206\u522b\u4e3a[d_c,d]\u548c[d_{ins},d]\uff0cd\u8868\u793a\u671f\u671b\u7684\u8f93\u51fa\u7ef4\u6570\uff0c\u77e9\u9635\u4e2d\u7684\u6bcf\u4e2a\u5143\u7d20\u670d\u4ece\u5bf9\u79f0\u5206\u5e03\uff0c\u4f8b\u5982\u9ad8\u65af\u5206\u5e03\u3001\u5747\u5300\u5206\u5e03\u7b49\u7b49\uff0c\u5e76\u4e14\u5177\u6709\u4e0d\u53d8\u6027\uff0c\u5373\u6a21\u578b\u4e00\u65e6\u521d\u59cb\u5316\uff0c\u5c31\u5bf9\u5e94\u751f\u6210\u968f\u673a\u77e9\u9635\uff0c\u968f\u673a\u77e9\u9635\u4e2d\u7684\u5143\u7d20\u5728\u6574\u4e2a\u8bad\u7ec3\u4ee5\u53ca\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\u4e0d\u6539\u53d8\u3002</p> <p>\u2003\u2003\u6700\u7ec8\u7684\u635f\u5931\u53ef\u4ee5\u8868\u793a\u4e3a\uff08\u6e90\u57df\u4e0e\u76ee\u6807\u57df\u635f\u5931\u8ba1\u7b97\u65b9\u6cd5\u76f8\u540c\uff09\uff1a $$ \\begin{aligned} \\mathcal L_{ins} &amp;=-\\frac1{N_s}\\sum^{N_s}_{i=1}\\sum_{i,j}log (D_{ins}(f^{i,j}_{fus})_s)\\\\ &amp;=-\\frac1{N_t}\\sum^{N_t}_{i=1}\\sum_{i,j}log (D_{ins}(f^{i,j}_{fus})_t) \\end{aligned} $$ </p>"},{"location":"domain_adaptive/paper/HTCN1/#_6","title":"\u9488\u5bf9\u8bed\u4e49\u4e00\u81f4\u6027\u7684\u5c40\u90e8\u7279\u5f81\u63a9\u7801","text":"<p>\u2003\u2003\u867d\u7136\u573a\u666f\u5e03\u5c40\u3001\u5bf9\u8c61\u7ec4\u5408(\u5171\u73b0\uff0cco-occurrence)\u4ee5\u53ca\u80cc\u666f\u5728\u9886\u57df\u4e4b\u95f4\u53ef\u80fd\u662f\u4e0d\u540c\u7684\uff0c\u4f46\u662f\u5bf9\u4e8e\u4e0d\u540c\u9886\u57df\u4e2d\u76f8\u540c\u5bf9\u8c61\u7684\u63cf\u8ff0\u5e94\u8be5\u662f\u8bed\u4e49\u4e0d\u53d8\u7684\uff0c\u5e76\u4e14\u540c\u7c7b\u5bf9\u8c61\u4e4b\u95f4\u53ef\u4ee5\u8fdb\u884c\u5339\u914d\uff0c\u4f8b\u5982\u5728\u4e0d\u540c\u57ce\u5e02\u573a\u666f\u4e2d\u7684\u6c7d\u8f66\u5e94\u8be5\u6709\u76f8\u4f3c\u7684\u8349\u56fe(sketch)\u3002\u56e0\u6b64\uff0c\u53ef\u4ee5\u5047\u8bbe\u6574\u5f20\u56fe\u50cf\u4e2d\u7684\u4e00\u4e9b\u5c40\u90e8\u5730\u533a\u6bd4\u5176\u4ed6\u5730\u65b9\u66f4\u5177\u6709\u63cf\u8ff0\u6027\u548c\u4e3b\u5bfc\u6027\uff0c\u53d7\u6b64\u542f\u53d1\uff0c\u4f5c\u8005\u63d0\u51fa\u5728\u4e24\u4e2a\u9886\u57df\u4e4b\u95f4\u8ba1\u7b97\u57fa\u4e8e\u6d45\u5c42\u7279\u5f81\u7684\u5c40\u90e8\u7279\u5f81\u63a9\u7801\uff0c\u7528\u4e8e\u6307\u5bfc\u9002\u5e94\u8fc7\u7a0b\u4e2d\u7684\u8bed\u4e49\u4e00\u81f4\u6027\uff0c\u8fd9\u91cc\u7c7b\u4f3c\u4e00\u4e2a\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5229\u7528\u65e0\u76d1\u7763\u65b9\u6cd5\u53bb\u6355\u6349\u53ef\u8f6c\u79fb\u7684\u533a\u57df\u3002</p> <p>\u2003\u2003\u4e0eIWAT-I\u6a21\u5757\u7c7b\u4f3c\uff0c\u8fd9\u91cc\u5229\u7528\u5c40\u90e8\u57df\u5206\u7c7b\u5668D_1\u5f97\u5230\u7684\u4e0d\u786e\u5b9a\u6027\u8ba1\u7b97\u7279\u5f81\u63a9\u7801m^s_f\u4e0em_f^t\uff0c\u5176\u4e2dD_1\u4e3a\u50cf\u7d20\u70b9\u7ea7\u522b\u7684\u57df\u5224\u65ad\u5668\uff0c\u5047\u8bbe\u4eceG_1\u5f97\u5230\u7684\u7279\u5f81\u56fe\u5bbd\u4e0e\u9ad8\u5206\u522b\u4e3aW,H\uff0c\u5219\u50cf\u7d20\u70b9\u7ea7\u522b\u7684\u5bf9\u6297\u6027\u635f\u5931\\mathcal L_{la}\u8868\u793a\u4e3a\uff1a $$ \\begin{aligned} \\mathcal L_{la}&amp;=\\frac1{N_s\u00b7HW}\\sum^{N_s}_{i=1}\\sum^{HW}_{k=1}log(D_1(G_1(x_i^s)_k))^2\\\\ &amp;+\\frac1{N_t\u00b7HW}\\sum^{N_t}_{i=1}\\sum^{HW}_{k=1}log(1-D_1(G_1(x_i^t)_k))^2 \\end{aligned} $$  \u5176\u4e2d\uff0c(G_1(x_i))_k\u8868\u793a\u4eceG_1(x_i)\u5f97\u5230\u7684\u7279\u5f81\u56fe\u4e2d\u7b2ck\u4e2a\u4f4d\u7f6e\u7684\u7279\u5f81\u5411\u91cf\uff0c\u5c06x^s_i,x_i^t\u5747\u7b80\u5199\u4e3ax_i\uff0c(G_1(x_i))_k\u7b80\u5199\u4e3ar_i^k\u3002\u6ce8\u610f\uff0c\u7279\u5f81\u56fe\u4e2d\u4e00\u4e2a\u50cf\u7d20\u70b9\u4ee3\u8868\u539f\u56fe\u50cf\u7684\u4e00\u4e2a\u5c0f\u533a\u57df\uff0c\u533a\u57df\u5927\u5c0f\u7531\u7279\u5f81\u56fe\u7684\u611f\u53d7\u91ce\u51b3\u5b9a\u3002\u5bf9\u4e8e\u6bcf\u4e2a\u533a\u57df\uff0c\u5224\u522b\u5668D_1\u7684\u8f93\u51fa\u88ab\u8868\u793a\u4e3ad^k_i=D_1(r^k_i)\uff0c\u7c7b\u4f3cIWAT-I\u6a21\u5757\u4e2d\u4e0d\u786e\u5b9a\u6027\u7684\u8ba1\u7b97\u65b9\u6cd5\uff0c\u6bcf\u4e2a\u533a\u57df\u7684\u4e0d\u786e\u5b9a\u6027\u8ba1\u7b97\u516c\u5f0f\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ v(r^k_i)=H(d^k_i) $$  \u57fa\u4e8e\u4e0a\u8ff0\u8ba1\u7b97\u5f97\u5230\u7684\u4e0d\u786e\u5b9a\u6027\u56fe\uff0c\u6bcf\u4e2a\u533a\u57df\u7684\u7279\u5f81\u63a9\u7801m^k_f\u53ef\u7531\u5982\u4e0b\u516c\u5f0f\u8ba1\u7b97\u5f97\u5230\uff1a $$ m^k_f=2-v(r^k_i) $$  \u2003\u2003\u4e0d\u786e\u5b9a\u6027\u8d8a\u5c0f\u7684\u533a\u57df\u8d8a\u5177\u6709\u8f6c\u79fb\u80fd\u529b\uff08\u539f\u6587\u4e2d\u63d0\u5230more transferable\uff0c\u8fd9\u91cc\u8be5\u5982\u4f55\u7406\u89e3\uff1f\u5177\u4f53\u89c1\u95ee\u9898\u8bb0\u5f55\uff09\uff0c\u5f97\u5230\u5c40\u90e8\u7279\u5f81\u63a9\u7801\u4e4b\u540e\uff0c\u518d\u5229\u7528\u8be5\u63a9\u7801\u5bf9\u7f51\u7edc\u4e2d\u7684\u5c40\u90e8\u7279\u5f81\u8fdb\u884c\u91cd\u65b0\u52a0\u6743\u7684\u64cd\u4f5c\uff1a $$ \\tilde{r}^k_i\\leftarrow r^k_i\u00b7m^k_i $$  \u2003\u2003\u7ecf\u8fc7\u4e0a\u8ff0\u64cd\u4f5c\uff0c\u4fe1\u606f\u91cf\u4e30\u5bcc\u7684\u533a\u57df\u5c06\u4f1a\u88ab\u5206\u914d\u8f83\u9ad8\u7684\u6743\u91cd\uff0c\u4ece\u800c\u8fbe\u5230\u66f4\u9ad8\u7684\u6fc0\u6d3b\u6548\u679c\uff0c\u800c\u5176\u4ed6\u4fe1\u606f\u91cf\u8f83\u5c11\u7684\u533a\u57df\u5c06\u4f1a\u88ab\u5206\u914d\u8f83\u4f4e\u7684\u6743\u91cd\uff0c\u4ece\u800c\u6291\u5236\u5176\u4fe1\u606f\u7684\u8868\u8fbe\u3002\u5206\u522b\u8ba1\u7b97\u6e90\u57df\u548c\u76ee\u6807\u57df\u7684\u7279\u5f81\u63a9\u7801\uff0c\u4ee5\u4ece\u8bed\u4e49\u4e0a\u6307\u5bfc\u540e\u7eed\u9ad8\u7ea7\u7279\u5f81\u7684\u81ea\u9002\u5e94\u3002\u6700\u540e\uff0cD_2\u6a21\u5757\u7684\u5bf9\u6297\u635f\u5931\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ \\mathcal L_{ma}=\\mathbb E[log(D_2(G_2(\\hat{f}^s_i)))]+\\mathbb E[1-log(D_2(G_2(\\hat{f}^t_i)))] $$  \u5176\u4e2d\uff0c\\hat{f}^s_i\u548c\\hat{f}^t_i\u4f9d\u6b21\u8868\u793a\u6240\u6709\u50cf\u7d20\u7ecf\u8fc7\u91cd\u52a0\u6743\u540e\u7684\u6574\u5f20\u7279\u5f81\u56fe\uff0c\u8fd9\u91cc\u7684\\mathbb E\u6309\u6e90\u7801\u6765\u770b\uff0c\u5e94\u8be5\u662f\u4ea4\u53c9\u71b5\u635f\u5931\u3002</p>"},{"location":"domain_adaptive/paper/HTCN1/#_7","title":"\u8bad\u7ec3\u635f\u5931","text":"<p>\u2003\u2003Faster R-CNN\u6846\u67b6\u539f\u672c\u7684\u68c0\u6d4b\u635f\u5931\u8868\u793a\u4e3a\\mathcal L_{cls}\u548c\\mathcal L_{reg}\uff0c\u7528\u4e8e\u8861\u91cf\u5bf9\u8c61\u5206\u7c7b\u635f\u5931\u548c\u8fb9\u754c\u6846\u56de\u5f52\u635f\u5931\uff0c\u7efc\u5408\u4e0a\u9762\u6240\u6709\u7684\u6a21\u5757\uff0c\u6a21\u578b\u6700\u7ec8\u7684\u4f18\u5316\u76ee\u6807\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ \\max_{D_1,D_2,D_3}\\min_{G_1,G_2,G_3}\\mathcal L_{cls}+\\mathcal L_{reg}-\\lambda(\\mathcal L_{la}+\\mathcal L_{ma}+\\mathcal L_{ga}+\\mathcal L_{ins}) $$  \u5176\u4e2d\uff0c\\lambda\u8868\u793a\u5e73\u8861\u635f\u5931\u7ec4\u4ef6\u7684\u6743\u91cd\u3002</p>"},{"location":"domain_adaptive/paper/HTCN1/#_8","title":"\u7406\u8bba\u652f\u6491","text":"<p>\u2003\u2003\u4e3a\u4e86\u8fdb\u4e00\u6b65\u8bc1\u660e\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u4f5c\u8005\u505a\u4e86\u9886\u57df\u9002\u5e94\u7684\u7406\u8bba\u89e3\u8bfb\u3002\u5047\u8bbe\u7531\u4e8e\u53ef\u8f6c\u79fb\u6027\u548c\u53ef\u8fa8\u522b\u6027\u4e4b\u95f4\u7684\u6f5c\u5728\u77db\u76fe\uff0c\u901a\u8fc7\u65e0\u7ea6\u675f\u5bf9\u6297\u8bad\u7ec3\u7684\u8de8\u57df\u68c0\u6d4b\u53ef\u4ee5\u88ab\u89c6\u4e3a\u4e00\u4e2a\u975e\u4fdd\u5b88(non-conservative)\u57df\u9002\u5e94\u95ee\u9898\uff0c\u4fdd\u5b88\u57df\u9002\u5e94\u662f\u6307\u5b66\u4e60\u8005\u53ea\u9700\u8981\u627e\u5230\u5173\u4e8e\u6807\u8bb0\u6e90\u6837\u672c\u7684\u6700\u4f18\u5047\u8bbe\uff0c\u5e76\u4e14\u901a\u8fc7\u4f7f\u7528\u672a\u6807\u8bb0\u76ee\u6807\u57df\u6837\u672c\u6765\u8bc4\u4f30\u8be5\u5047\u8bbe\u5728\u76ee\u6807\u57df\u4e0a\u7684\u6027\u80fd\u3002</p> <p>\u5b9a\u4e491\uff1a\u5047\u8bbe\u5b58\u5728\u4e00\u4e2a\\mathcal H\u7c7b\u7684\u7269\u4f53\uff0c\u7ed9\u5b9a\u4e24\u4e2a\u4e0d\u540c\u7684\u57df\\mathcal S,\\mathcal T\uff0c\u5728\u975e\u4fdd\u5b88\u57df\u81ea\u9002\u5e94\u4e2d\uff0c\u6709\u5982\u4e0b\u4e0d\u7b49\u5f0f\uff1a $$ \\begin{aligned} R_{\\mathcal T}&amp;(h^t)&lt;R_{\\mathcal T}(h^*),\u5176\u4e2d\\\\ &amp;h^*=\\arg\\min_{h\\in\\mathcal H}R_{\\mathcal S}(h)+R_{\\mathcal T}(h)\\\\ &amp;h^t=\\arg\\min_{h\\in\\mathcal H}R_{\\mathcal T}(h) \\end{aligned} $$  \u5176\u4e2d\uff0cR_{\\mathcal S}(\u00b7)\u548cR_{\\mathcal T}(\u00b7)\u5206\u522b\u8868\u793a\u6e90\u57df\u548c\u76ee\u6807\u57df\u7684\u9884\u671f\u98ce\u9669</p> <p>\u2003\u2003\u4e0a\u8ff0\u5b9a\u4e49\u8868\u660e\uff0c\u5728\u975e\u4fdd\u5b88\u57df\u81ea\u9002\u5e94\u4e2d\uff0c\u7531\u4e8e\u53ef\u8f6c\u79fb\u6027\u548c\u53ef\u8fa8\u522b\u6027\u4e4b\u95f4\u5b58\u5728\u5b58\u5728\u6f5c\u5728\u7684\u77db\u76fe\uff0c\u6700\u4f18\u6e90\u68c0\u6d4b\u5668\u548c\u6700\u4f18\u76ee\u6807\u68c0\u6d4b\u5668\u4e4b\u95f4\u5b58\u5728\u4e00\u4e2a\u6700\u4f18\u95f4\u9699\uff0c\u5373\u65e0\u6cd5\u540c\u65f6\u6700\u5c0f\u5316\u4e24\u4e2a\u9886\u57df\u4e0a\u7684\u9884\u671f\u98ce\u9669\u3002\u4e25\u683c\u5339\u914d\u4e24\u4e2a\u9886\u57df\u4e4b\u95f4\u6574\u4e2a\u7279\u5f81\u5206\u5e03\u4f1a\u4e0d\u53ef\u907f\u514d\u5730\u5f97\u5230\u6b21\u4f18\u89e3\uff08\u5373\u627e\u5230\u4e00\u4e2a\u5047\u8bbe\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u6e90\u57df\u548c\u76ee\u6807\u57df\u7684\u671f\u671b\u8bef\u5dee\uff09\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u9700\u8981\u8bbe\u8ba1\u4e00\u4e2a\u6a21\u578b\uff0c\u4fc3\u8fdb\u5177\u6709\u53ef\u8f6c\u79fb\u6027\u7684\u7279\u5f81\uff0c\u63d0\u5347\u8fd9\u4e9b\u79ef\u6781\u7279\u5f81\u7684\u91cd\u8981\u6027\uff0c\u540c\u65f6\u6291\u5236\u4e0d\u5177\u6709\u53ef\u8f6c\u79fb\u6027\u7684\u7279\u5f81\uff0c\u964d\u4f4e\u8fd9\u4e9b\u65e0\u5173\u7279\u5f81\u7684\u91cd\u8981\u6027\u3002\u4ece\u7406\u8bba\u4e0a\u8bb2\uff0c\u6211\u4eec\u7684\u5de5\u4f5c\u4e0d\u662f\u5728\u76ee\u6807\u57df\u4e2d\u663e\u5f0f\u7684\u5bfb\u627eh^t\uff08\u56e0\u4e3a\u76ee\u6807\u57df\u6570\u636e\u7f3a\u5c11\u6807\u7b7e\uff09\uff0c\u800c\u662f\u89e3\u51b3\u975e\u4fdd\u5b88\u57df\u81ea\u9002\u5e94\u95ee\u9898\uff0c\u5e76\u4e14\u6700\u5c0f\u5316\u76ee\u6807\u57df\u7684\u671f\u671b\u8bef\u5dee\u4e0a\u9650\uff0c\u5373R_{\\mathcal T}(h)\u3002</p> <p>\u2003\u2003\u57df\u9002\u5e94\u7406\u8bba\u7814\u7a76(\u8bba\u6587\u94fe\u63a5)\u5c06\u76ee\u6807\u57df\u4e0a\u7684\u671f\u671b\u8bef\u5dee\u505a\u4e86\u5982\u4e0b\u9650\u5236\uff1a $$ \\forall h\\in\\mathcal H,R_{\\mathcal T}(h)\u2264R_{\\mathcal S}(h)+\\frac12d_{\\mathcal H\\Delta\\mathcal H}(\\mathcal S,\\mathcal T)+C $$  \u5176\u4e2d\uff0cR_{\\mathcal S}\u8868\u793a\u76ee\u6807\u57df\u4e0a\u7684\u671f\u671b\u8bef\u5dee\uff0cd_{\\mathcal H\\Delta\\mathcal H}(\\mathcal S,\\mathcal T)\u4ee3\u8868\u57df\u6563\u5ea6\u548c\u76f8\u5173\u7684\u7279\u5f81\u8f6c\u79fb\u6027\uff0cC\u8868\u793a\u7406\u60f3\u7684\u8054\u5408\u5047\u8bbe\u7684\u8bef\u5dee\uff0c\u5373\u4e0a\u9762\u65b9\u7a0b\u4e2d\u7684h^*\uff0c\u8be5\u8bef\u5dee\u4e0e\u7279\u5f81\u53ef\u8fa8\u522b\u6027\u76f8\u5173\u8054\u3002\u5728\u4e0a\u8ff0\u4e0d\u7b49\u5f0f\u4e2d\uff0c\u7531\u4e8e\u5728\u6e90\u57df\u6570\u636e\u4e2d\u6709\u6807\u7b7e\uff0c\u56e0\u6b64R_{\\mathcal S}\u53ef\u4ee5\u5f88\u5bb9\u6613\u88ab\u6df1\u5c42\u7f51\u7edc\u6240\u4f18\u5316\uff0c\u66f4\u91cd\u8981\u7684\u662f\uff0c\u4f5c\u8005\u8bbe\u8ba1\u7684\u65b9\u6cd5\u5206\u5c42\u8bc6\u522b\u4e86\u7279\u5f81\u7684\u53ef\u8f6c\u79fb\u6027(\u533a\u57df\u3001\u56fe\u50cf\u3001\u5b9e\u4f8b)\uff0c\u5e76\u4e14\u901a\u8fc7\u5c40\u90e8\u7279\u5f81\u63a9\u7801\u3001IWAT-I\u4ee5\u53caCILA\u6765\u589e\u5f3a\u7279\u5f81\u7684\u53ef\u8f6c\u79fb\u6027\u3002\u6700\u540e\u8fd8\u901a\u8fc7\u57fa\u4e8e\u5206\u5c42\u53ef\u4f20\u9012\u6027\u7684\u8de8\u57df\u7279\u5f81\u5bf9\u9f50\u6765\u63d0\u9ad8\u6700\u5c0fC\u7684\u53ef\u8fa8\u522b\u6027\uff0c\u901a\u8fc7\u8fd9\u4e9b\u65b9\u6cd5\uff0c\u53ef\u4ee5\u7f13\u89e3\u53ef\u8f6c\u79fb\u6027\u4e0e\u53ef\u8fa8\u522b\u6027\u4e4b\u95f4\u7684\u77db\u76fe\u3002</p>"},{"location":"domain_adaptive/paper/HTCN1/#map","title":"mAP\u5bf9\u6bd4","text":"<p>Cityscape \\rightarrow FoggyCityscape</p> <p> <p></p> <p></p>"},{"location":"domain_adaptive/paper/HTCN1/#_9","title":"\u603b\u7ed3","text":"<p>\u2003\u2003\u672c\u6587\u4e3a\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u9886\u57df\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u7ea7\u53ef\u8f6c\u79fb\u6821\u51c6\u7f51\u7edc(HTCN)\uff0c\u901a\u8fc7\u63a2\u7d22\u4e0d\u540c\u5c40\u90e8\u533a\u57df\u3001\u56fe\u50cf\u548c\u5b9e\u4f8b\u7684\u53ef\u8f6c\u79fb\u6027\u6765\u534f\u8c03\u5bf9\u6297\u6027\u9002\u5e94\u4e2d\u53ef\u8f6c\u79fb\u6027\u548c\u53ef\u8fa8\u522b\u6027\u4e4b\u95f4\u7684\u6f5c\u5728\u77db\u76fe\u3002</p> <p>\u6ce8\uff1a\u4ee5\u4e0a\u5185\u5bb9\u4ec5\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u5927\u5bb6\u6279\u8bc4\u6307\u6b63</p> <p>\u672a\u5b8c\u5f85\u7eed\uff0c\u8fd8\u6709\u4e24\u4e2a\u5c0f\u7ec6\u8282\u9700\u8981\u8be2\u95ee\u4f5c\u8005\uff0c\u5177\u4f53\u89c1\u95ee\u9898\u8bb0\u5f55\u2014\u20142022\u5e742\u670812\u65e56</p>"},{"location":"domain_adaptive/paper/ICR-CCR1/","title":"\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\uff1aICR-CCR","text":""},{"location":"domain_adaptive/paper/ICR-CCR1/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u4e0e\u65f6\u95f4\uff1aIEEE Conference on Computer Vision and Pattern Recognition 2020 (CVPR, 2020)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttp://openaccess.thecvf.com/content_CVPR_2020/papers/Xu_Exploring_Categorical_Regularization_for_Domain_Adaptive_Object_Detection_CVPR_2020_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/Megvii-Nanjing/CR-DA-DET</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b</p>"},{"location":"domain_adaptive/paper/ICR-CCR1/#_2","title":"\u4e3b\u8981\u601d\u60f3","text":"<p>\u2003\u2003\u76ee\u524d\u89e3\u51b3\u9886\u57df\u504f\u79fb\u95ee\u9898\u6700\u6709\u6548\u7684\u65b9\u6cd5\u662f\u5229\u7528\u9886\u57df\u5206\u7c7b\u5668\u6765\u6d4b\u91cf\u4e24\u4e2a\u9886\u57df\u7684\u5dee\u5f02\uff0c\u5e76\u4e14\u4ee5\u5bf9\u6297\u7684\u65b9\u5f0f\u8bad\u7ec3\u9886\u57df\u5206\u7c7b\u5668\u548c\u7279\u5f81\u63d0\u53d6\u5668\uff0c\u901a\u8fc7\u5fae\u8c03\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u7684\u7279\u5f81\u8868\u793a\u6765\u8ba9\u6a21\u578b\u5177\u6709\u9886\u57df\u9002\u5e94\u80fd\u529b\u3002\u5728\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u4e2d\uff0cDomain Adaptive (DA) Faster R-CNN\u7cfb\u5217\u7684\u7b97\u6cd5\u662f\u6700\u5177\u6709\u4ee3\u8868\u6027\u7684\u7b97\u6cd5\uff0c\u5982DA Faster R-CNN\u3001SW Faster R-CNN\u7b49\u7b49\uff0c\u901a\u8fc7\u540c\u65f6\u5229\u7528\u5bf9\u6297\u635f\u5931\u6765\u5bf9\u9f50\u56fe\u50cf\u7ea7\u548c\u5b9e\u4f8b\u7ea7\u7684\u8de8\u57df\u7279\u5f81\u5206\u5e03\uff0c\u6765\u89e3\u51b3\u76ee\u6807\u68c0\u6d4b\u4e2d\u7684\u9886\u57df\u504f\u79fb\u95ee\u9898\u3002\u867d\u7136\u6700\u8fd1\u7684\u65b9\u6cd5\u6548\u679c\u90fd\u6bd4\u8f83\u663e\u8457\uff0c\u4f46\u662f\u4ed6\u4eec\u90fd\u5ffd\u7565\u4e86\u8de8\u57df\u5339\u914d\u56fe\u50cf\u7684\u5173\u952e\u533a\u57df\u548c\u91cd\u8981\u5b9e\u4f8b\uff0c\u5f71\u54cd\u4e86\u6a21\u578b\u7684\u9886\u57df\u9002\u5e94\u80fd\u529b\u3002</p> <p>\u2003\u2003\u9488\u5bf9\u6b64\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u7c7b\u6b63\u5219\u5316\u6846\u67b6(categorical regularization framework)\uff0c\u4ed6\u53ef\u4ee5\u4ee5\u4e00\u79cd\u5373\u63d2\u5373\u7528\u7684\u65b9\u5f0f\u5d4c\u5165\u5230\u76ee\u524d\u5927\u591a\u6570\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u4e2d\uff0c\u901a\u8fc7\u7cbe\u51c6\u5730\u5b9a\u4f4d\u56fe\u50cf\u7684\u5173\u952e\u533a\u57df\u548c\u91cd\u8981\u5b9e\u4f8b\uff0c\u6765\u51c6\u786e\u5730\u63d0\u5347\u4e3b\u5e72\u7f51\u7edc\u5bf9\u611f\u5174\u8da3\u5bf9\u8c61\u7684\u6fc0\u6d3b\u80fd\u529b\uff0c\u4ece\u800c\u8ba9\u7f51\u7edc\u5f97\u5230\u66f4\u597d\u7684\u81ea\u9002\u5e94\u68c0\u6d4b\u7ed3\u679c\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u5176\u4e2d\uff0c\u7b2c\u4e00\u884c\u8868\u793a\u8f93\u5165\u56fe\u50cf\uff0c\u7b2c\u4e8c\u884c\u8868\u793aDA Faster R-CNN\u7b97\u6cd5\u5f97\u5230\u7684\u4e3b\u5e72\u7f51\u7edc\u7684\u70ed\u56fe\uff0c\u7b2c\u4e09\u884c\u8868\u793a\u5728DA Faster R-CNN\u7b97\u6cd5\u7684\u57fa\u7840\u4e0a\uff0c\u5f15\u5165\u4f5c\u8005\u8bbe\u8ba1\u7684\u6b63\u5219\u5316\u5668\u6240\u5f97\u5230\u7684\u4e3b\u5e72\u7f51\u7edc\u70ed\u56fe\u3002\u4ece\u53ef\u89c6\u5316\u70ed\u56fe\u4e2d\u53ef\u4ee5\u53d1\u73b0\uff0c\u4f5c\u8005\u8bbe\u8ba1\u7684\u6846\u67b6\u53ef\u4ee5\u4f7f\u6a21\u578b\u4ee5\u66f4\u51c6\u786e\u5730\u65b9\u5f0f\u6765\u53d1\u73b0\u56fe\u50cf\u4e2d\u7684\u5173\u952e\u533a\u57df\u548c\u91cd\u8981\u5b9e\u4f8b\uff0c\u4ece\u800c\u63d0\u5347\u6a21\u578b\u5728\u8fd9\u4e9b\u533a\u57df\u7684\u9002\u5e94\u80fd\u529b\u3002</p> <p>\u2003\u2003\u4f5c\u8005\u8bbe\u8ba1\u7684\u6846\u67b6\u4e3b\u8981\u7531\u4e24\u4e2a\u6b63\u5219\u5316\u6a21\u5757\u6784\u6210\uff1a\u2460\u56fe\u50cf\u7ea7\u5206\u7c7b\u6b63\u5219\u5316(image-level categorical regularization, ICR)\uff1b\u2461\u5206\u7c7b\u4e00\u81f4\u6027\u6b63\u5219\u5316(categorical consistency regularization, CCR)\u3002\u5bf9\u4e8e\u56fe\u50cf\u7ea7\u5206\u7c7b\u6b63\u5219\u5316\uff0c\u9996\u5148\u5728\u4e3b\u5e72\u7f51\u7edc\u4e2d\u52a0\u5165\u56fe\u50cf\u6c34\u5e73\u7684\u591a\u6807\u7b7e\u5206\u7c7b\u5668\uff0c\u5e76\u4e14\u5229\u7528\u6765\u81ea\u6e90\u57df\u7684\u5bf9\u8c61\u6807\u7b7e\u7c7b\u522b\u8bad\u7ec3\u4ed6\uff0c\u7531\u4e8e\u5206\u7c7b\u7f51\u7edc\u5177\u6709\u4e00\u5b9a\u7684\u5f31\u5b9a\u4f4d\u80fd\u529b(\u5982\u4e0b\u56fe\u6240\u793a)\uff0c\u56e0\u6b64\u901a\u8fc7\u8bad\u7ec3\u8be5\u5206\u7c7b\u5668\u53ef\u4ee5\u4f7f\u7f51\u7edc\u4ece\u6574\u4f53\u56fe\u50cf\u4e2d\u5b66\u4e60\u5bf9\u8c61\u7ea7\u6982\u5ff5\uff0c\u540c\u65f6\u4e0d\u53d7\u6e90\u57df\u80cc\u666f\u5206\u5e03\u7684\u5f71\u54cd\uff0c\u4ece\u800c\u53ef\u4ee5\u8ba9\u7f51\u7edc\u5728\u56fe\u50cf\u7ea7\u522b\u9690\u5f0f\u5730\u5bf9\u9f50\u4e24\u4e2a\u9886\u57df\u4e4b\u95f4\u7684\u5173\u952e\u533a\u57df\u3002\u5bf9\u4e8e\u5206\u7c7b\u4e00\u81f4\u6027\u6b63\u5219\u5316\u5668\uff0c\u4f5c\u8005\u8003\u8651\u9644\u52a0\u5206\u7c7b\u5668\u56fe\u50cf\u7ea7\u9884\u6d4b\u548c\u68c0\u6d4b\u5668\u5b9e\u4f8b\u7ea7\u9884\u6d4b\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\uff0c\u91c7\u7528\u8fd9\u79cd\u5206\u7c7b\u4e00\u81f4\u6027\u4f5c\u4e3a\u4e00\u79cd\u65b0\u7684\u6b63\u5219\u5316\u56e0\u5b50\uff0c\u5e76\u4e14\u5728\u5b9e\u4f8b\u7ea7\u5bf9\u9f50\u7684\u8fc7\u7a0b\u4e2d\u4f7f\u7528\u5b83\u6765\u5bf9\u76ee\u6807\u57df\u7684\u5b9e\u4f8b\u5bf9\u6297\u635f\u5931\u8fdb\u884c\u52a0\u6743\uff0c\u4ece\u800c\u4f7f\u7f51\u7edc\u66f4\u52a0\u4fa7\u91cd\u5bf9\u9f50\u91cd\u8981\u5bf9\u8c61\u7684\u7279\u5f81\u3002</p> <p> <p></p> <p></p>"},{"location":"domain_adaptive/paper/ICR-CCR1/#_3","title":"\u65b9\u6cd5","text":""},{"location":"domain_adaptive/paper/ICR-CCR1/#_4","title":"\u7f51\u7edc\u6846\u67b6","text":"<p>\u2003\u2003\u4f5c\u8005\u63d0\u51fa\u7684\u6846\u67b6\u901a\u8fc7\u5c06\u4e24\u4e2a\u6b63\u5219\u5316\u6a21\u5757\u5d4c\u5165\u5230DA Faster R-CNN\u4e2d\uff0c\u6765\u8fdb\u4e00\u6b65\u63d0\u5347\u8be5\u7cfb\u5217\u7b97\u6cd5\u7684\u9886\u57df\u81ea\u9002\u5e94\u80fd\u529b\uff0c\u5177\u4f53\u7684\u7f51\u7edc\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u8be5\u6846\u67b6\u53ef\u4ee5\u5f88\u597d\u5730\u8de8\u9886\u57df\u534f\u8c03\u5173\u952e\u533a\u57df\u548c\u91cd\u8981\u5b9e\u4f8b\uff0c\u4ece\u800c\u5728\u4e3b\u5e72\u7f51\u7edc\u4e2d\u5bf9\u611f\u5174\u8da3\u7684\u5bf9\u8c61\u4e0a\u4ea7\u751f\u66f4\u9ad8\u7684\u6fc0\u6d3b\u3002\u6ce8\u610f\uff1aICR\u6a21\u5757\u4e0d\u4f9d\u8d56\u4e8eCCR\u6a21\u5757\uff0c\u56e0\u6b64\u4ed6\u53ef\u4ee5\u5d4c\u5165\u5230\u5355\u72ec\u5bf9\u56fe\u50cf\u7ea7\u9886\u57df\u5bf9\u9f50\u7684\u57df\u9002\u5e94\u7b97\u6cd5\u4e2d\uff1b\u4f46\u662fCCR\u6a21\u5757\u4f9d\u8d56\u4e8eICR\u6a21\u5757\uff0c\u56e0\u4e3aCCR\u6a21\u5757\u9700\u8981\u6765\u81eaICR\u6a21\u5757\u7684\u591a\u6807\u7b7e\u5206\u7c7b\u5668\u6765\u5bf9\u76ee\u6807\u57df\u7684\u56fe\u50cf\u505a\u9884\u6d4b\uff0c\u5177\u4f53\u53ef\u89c1\u4e0b\u9762\u5bf9\u8be5\u6a21\u5757\u7684\u63cf\u8ff0\u3002</p>"},{"location":"domain_adaptive/paper/ICR-CCR1/#_5","title":"\u56fe\u50cf\u7ea7\u5206\u7c7b\u6b63\u5219\u5316","text":"<p>\u2003\u2003\u5229\u7528\u56fe\u50cf\u7ea7\u5206\u7c7b\u6b63\u5219\u5316\u5668(ICR)\u53ef\u4ee5\u5f97\u5230\u5bf9\u5e94\u4e8e\u5206\u7c7b\u4fe1\u606f\u7a00\u758f\u4f46\u662f\u91cd\u8981\u7684\u56fe\u50cf\u533a\u57df\uff0c\u4f5c\u8005\u4f7f\u7528\u5f31\u76d1\u7763\u5b66\u4e60\u6765\u5b9e\u73b0\u8fd9\u4e00\u70b9\uff0c\u901a\u8fc7\u5b66\u4e60\u611f\u5174\u8da3\u5bf9\u8c61\u7684\u533a\u522b\u7279\u5f81(discriminative feature)\u6765\u8ba9\u7f51\u7edc\u5ffd\u7565\u6389\u80cc\u666f\u5206\u5e03\u7684\u5f71\u54cd\u3002\u867d\u7136\u6807\u51c6\u7684Faster R-CNN\u7b97\u6cd5\u540c\u6837\u53ef\u4ee5\u5b66\u5230\u611f\u5174\u8da3\u5bf9\u8c61\u7684\u533a\u522b\u7279\u5f81\uff0c\u4f46\u662f\u5728\u8be5\u7b97\u6cd5\u7684\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u4f1a\u5728\u91c7\u6837\u5927\u91cf\u7684\u80cc\u666f\u533a\u57df\uff0c\u5bf9\u6bd4\u4f5c\u8005\u63d0\u51fa\u7684ICR\u6a21\u5757\uff0c\u6807\u51c6\u7684\u68c0\u6d4b\u7b97\u6cd5\u66f4\u503e\u5411\u4e8e\u8bad\u7ec3\u80cc\u666f\u533a\u57df\uff0c\u4f46\u662f\u7531\u4e8e\u80cc\u666f\u5177\u6709\u4e0d\u53ef\u8f6c\u79fb\u7684\u6a21\u5f0f\uff0c\u5bf9\u80cc\u666f\u6267\u884c\u9886\u57df\u5bf9\u9f50\u7684\u8bdd\u53ef\u80fd\u4f1a\u4ea7\u751f\u4e00\u4e9b\u8d1f\u9762\u6548\u679c\uff0c\u56e0\u6b64\u7b80\u5355\u5730\u56fe\u50cf\u7ea7\u5bf9\u9f50\u53ef\u80fd\u4f1a\u5bfc\u81f4\u6fc0\u6d3b\u76ee\u6807\u57df\u4e2d\u7684\u566a\u58f0\u3002</p> <p>\u2003\u2003\u5728\u4f5c\u8005\u63d0\u51fa\u7684ICR\u6a21\u5757\u4e2d\uff0c\u9996\u5148\u5c06\u56fe\u50cf\u7ea7\u591a\u6807\u7b7e\u5206\u7c7b\u5668\u5d4c\u5165\u5230\u68c0\u6d4b\u5668\u7684\u4e3b\u5e72\u7f51\u7edc\u4e2d(\u5177\u4f53\u53ef\u89c1\u7f51\u7edc\u7ed3\u6784\u56fe)\uff0c\u4e4b\u540e\u5229\u7528\u6e90\u57df\u56fe\u50cf\u7684\u5bf9\u8c61\u7c7b\u522b\u6807\u7b7e\u6765\u8bad\u7ec3\u8be5\u5206\u7c7b\u5668\u3002</p> <p>\u2003\u2003\u7ed9\u5b9a\u68c0\u6d4b\u5668\u7684\u4e3b\u5e72\u7f51\u7edc\uff0c\u9996\u5148\u5728\u8f93\u51fa\u7684\u7279\u5f81\u4e0a\u6267\u884c\u5168\u5c40\u5e73\u5747\u6c60\u5316\uff0c\u4e4b\u540e\u5c06\u5f97\u5230\u7684\u7279\u5f81\u5411\u91cf\u4f20\u5165\u591a\u6807\u7b7e\u5206\u7c7b\u5668\u4e2d\uff0c\u8be5\u5206\u7c7b\u5668\u7531\u5377\u79ef\u6838\u5c3a\u5bf8\u4e3a1\\times1\u7684\u5377\u79ef\u5c42\u6784\u6210\uff0c\u6700\u540e\u5229\u7528\u6807\u51c6\u7684\u4ea4\u53c9\u71b5\u591a\u6807\u7b7e\u635f\u5931\u6765\u8bad\u7ec3\u8be5\u6a21\u5757\uff1a $$ \\mathcal L_{ICR}=\\sum^C_{c=1}y^c\\log(\\hat{y}^c)+(1-y^c)\\log(1-\\hat{y}^c) $$  \u5176\u4e2d\uff0cC\u8868\u793a\u6570\u636e\u96c6\u4e2d\u7269\u4f53\u7c7b\u522b\u603b\u6570\uff0cy^c\u8868\u793a\u5730\u9762\u771f\u5b9e\u6807\u7b7e\uff0c\u5373\u56fe\u50cf\u662f\u5426\u5b58\u5728\u8be5\u7c7b\uff0cy^c=1\u65f6\u8868\u793a\u8be5\u56fe\u4e2d\u81f3\u5c11\u6709\u4e00\u4e2a\u7c7b\u522b\u4e3ac\u7684\u7269\u4f53\uff0cy^c=0\u65f6\u8868\u793a\u8be5\u56fe\u4e2d\u6ca1\u6709\u7c7b\u522b\u4e3ac\u7684\u7269\u4f53\uff0c\\hat{y}^c\u8868\u793a\u8be5\u7c7b\u7684\u9884\u6d4b\u503c\u3002</p> <p>\u2003\u2003\u56fe\u50cf\u7ea7\u5206\u7c7b\u5668\u7684\u8bad\u7ec3\u9f13\u52b1\u68c0\u6d4b\u5668\u7684\u4e3b\u5e72\u7f51\u7edc\u5b66\u4e60\u80fd\u591f\u6fc0\u6d3b\u5bf9\u8c61\u76f8\u5173\u533a\u57df\u7684\u7279\u5b9a\u7c7b\u522b\u7279\u5f81\uff0c\u56e0\u6b64\u53ef\u4ee5\u4f7f\u7f51\u7edc\u4ee5\u66f4\u51c6\u786e\u7684\u65b9\u5f0f\u6765\u5bf9\u9f50\u56fe\u50cf\u7ea7\u7279\u5f81\uff0c\u4ece\u800c\u6821\u51c6\u4e24\u4e2a\u9886\u57df\u5173\u952e\u533a\u57df\u7684\u7279\u5f81\u63cf\u8ff0\u3002\u540c\u65f6\uff0c\u7531\u4e8e\u5728\u56fe\u50cf\u7ea7\u591a\u6807\u7b7e\u5206\u7c7b\u5668\u7684\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4e0d\u6d89\u53ca\u8bad\u7ec3\u80cc\u666f(\u4e0e\u4f20\u7edfFaster R-CNN\u7684\u533a\u522b\u4e4b\u5904)\uff0c\u56e0\u6b64\u964d\u4f4e\u4e86\u5339\u914d(\u751a\u81f3\u8fc7\u6e21\u5339\u914d)\u6e90\u57df\u80cc\u666f\u7684\u98ce\u9669\u3002</p>"},{"location":"domain_adaptive/paper/ICR-CCR1/#_6","title":"\u5206\u7c7b\u4e00\u81f4\u6027\u6b63\u5219\u5316","text":"<p>\u2003\u2003\u4f5c\u8005\u8fd8\u8bbe\u8ba1\u4e86\u5206\u7c7b\u4e00\u81f4\u6027\u6b63\u5219\u5316\u5668\u6765\u81ea\u52a8\u5bfb\u627e\u76ee\u6807\u57df\u6570\u636e\u4e2d\u96be\u4ee5\u5bf9\u9f50\u7684\u5b9e\u4f8b\uff0c\u52a8\u673a\u4e3b\u8981\u6709\u4e24\u4e2a\u65b9\u9762\uff1a\u2460\u7531\u4e8e\u7f51\u7edc\u4e0d\u80fd\u81ea\u52a8\u8bc6\u522b\u76ee\u6807\u57df\u4e2d\u90e8\u5206\u96be\u4ee5\u68c0\u6d4b\u7684\u524d\u666f\u5b9e\u4f8b\uff0c\u56e0\u6b64\u5f53\u524d\u7684\u5b9e\u4f8b\u7ea7\u5bf9\u9f50\u6a21\u5757\u53ef\u80fd\u4f1a\u88ab\u8fc7\u591a\u7684\u80cc\u666f\u533a\u57df\u6240\u652f\u914d\uff0c\u5bf9\u6a21\u578b\u7684\u81ea\u9002\u5e94\u8fc7\u7a0b\u5177\u6709\u8d1f\u9762\u5f71\u54cd\uff1b\u2461\u9644\u52a0\u7684\u56fe\u50cf\u7ea7\u5206\u7c7b\u5668\u548c\u5b9e\u4f8b\u7ea7\u68c0\u6d4b\u5934\u662f\u4e92\u8865\u7684\uff0c\u56e0\u4e3a\u524d\u8005\u5229\u7528\u6574\u4e2a\u56fe\u50cf\u7ea7\u4e0a\u4e0b\u6587\u9884\u6d4b\u56fe\u50cf\u4e2d\u7684\u7269\u4f53\u7c7b\u522b\uff0c\u540e\u8005\u5229\u7528\u51c6\u786e\u7684ROI\u7279\u5f81\u6765\u9884\u6d4b\u7269\u4f53\u7c7b\u522b\u3002</p> <p>\u2003\u2003\u57fa\u4e8e\u4e0a\u9762\u4e24\u4e2a\u8003\u8651\uff0c\u4f5c\u8005\u5229\u7528\u56fe\u50cf\u7ea7\u9884\u6d4b\u548c\u5b9e\u4f8b\u7ea7\u9884\u6d4b\u4e4b\u95f4\u7684\u5206\u7c7b\u4e00\u81f4\u6027\u6765\u8861\u91cf\u67d0\u4e2a\u76ee\u6807\u5b9e\u4f8b\u8fdb\u884c\u5206\u7c7b\u7684\u96be\u5ea6\uff0c\u76f4\u89c2\u5730\u6765\u8bf4\uff0c\u5982\u679c\u56fe\u50cf\u7ea7\u5206\u7c7b\u5668\u5728\u76ee\u6807\u56fe\u50cf\u4e2d\u6ca1\u6709\u9884\u6d4b\u5230\u201d\u4eba\u201d\uff0c\u800c\u5b9e\u4f8b\u7ea7\u5206\u7c7b\u5668\u9884\u6d4b\u5230\u4e86\u201d\u4eba\u201d\uff0c\u5219\u8be5\u5b9e\u4f8b\u5bf9\u4e8e\u5f53\u524d\u6a21\u578b\u6765\u8bf4\u662f\u6bd4\u8f83\u96be\u4ee5\u68c0\u6d4b\u7684\u5b9e\u4f8b\uff0c\u540c\u65f6\u542b\u6709\u8f83\u4e3a\u4e30\u5bcc\u7684\u6837\u672c\u4fe1\u606f\u3002\u56e0\u6b64\u5728\u5b9e\u4f8b\u7ea7\u7279\u5f81\u5bf9\u9f50\u7684\u8fc7\u7a0b\u4e2d\uff0c\u5e94\u8be5\u4f7f\u7528\u8fd9\u79cd\u4e00\u81f4\u6027\u4f5c\u4e3a\u6b63\u5219\u5316\u56e0\u5b50\u6765\u63d0\u5347\u8be5\u6837\u672c\u7684\u6743\u91cd\u3002</p> <p>\u2003\u2003\u5047\u8bbe\u68c0\u6d4b\u5934\u7684\u5206\u7c7b\u5668\u5bf9\u76ee\u6807\u57df\u56fe\u50cf\u4e2d\u7b2cj\u4e2a\u5b9e\u4f8b\u5206\u4e3ac\uff0c\u8ba9\\hat{p}^c_j\u8868\u793a\u5206\u7c7b\u5668\u4f30\u8ba1\u7684\u6982\u7387\uff0c\u540c\u65f6\u5047\u8bbe\\hat{y}^c\u8868\u793a\u56fe\u50cf\u7ea7\u5206\u7c7b\u5668\u5bf9\u8be5\u56fe\u50cf\u5305\u542bc\u7c7b\u7269\u4f53\u7684\u9884\u6d4b\u6982\u7387\u3002\u5229\u7528\u5982\u4e0b\u8ddd\u79bb\u516c\u5f0f\u6765\u8ba1\u7b97\u5b9e\u4f8b\u7ea7\u548c\u56fe\u50cf\u7ea7\u5206\u7c7b\u9884\u6d4b\u7684\u4e00\u81f4\u6027\uff1a $$ d_j=e^{|\\hat{p}^c_j-\\hat{y}^c|} $$  \u4e24\u4e2a\u6982\u7387\u76f8\u5dee\u8d8a\u5927\uff0c\u8868\u793a\u8fd9\u4e2a\u5b9e\u4f8b\u8d8a\u96be\u8fdb\u884c\u5206\u7c7b\uff0c\u56e0\u6b64\u8be5\u5b9e\u4f8b\u7684\u9886\u57df\u5bf9\u9f50\u5c31\u8d8a\u91cd\u8981\u3002</p> <p>\u2003\u2003\u4e0a\u8ff0\u5f97\u5230\u7684\u8ddd\u79bb\u7528\u4e8e\u5bf9\u5b9e\u4f8b\u7ea7\u5bf9\u9f50\u635f\u5931\u52a0\u6743\uff0c\u6700\u7ec8\u5e26\u6709CCR\u6b63\u5728\u5316\u7684\u5b9e\u4f8b\u7ea7\u635f\u5931\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ \\mathcal L^{CCR}_{ins}=-\\sum_j d_j[D\\log\\hat{D}_j+(1-D)\\log(1-\\hat{D}_j)] $$  \u2003\u2003\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u53ea\u5728\u76ee\u6807\u57df\u524d\u666f\u5b9e\u4f8b\u7684\u5bf9\u9f50\u4e2d\u52a0\u6743(\u6839\u636e\u68c0\u6d4b\u5934\u6765\u5224\u65ad\u76ee\u6807\u57df\u56fe\u50cf\u7684\u524d\u666f\u4e0e\u80cc\u666f)\uff0c\u5bf9\u4e8e\u6e90\u57df\u6570\u636e\u548c\u76ee\u6807\u57df\u7684\u80cc\u666f\u6570\u636e\u4e0d\u53d8\uff0c\u5373\u6743\u91cd\u5747\u8bbe\u7f6e\u4e3a1\uff0c\u56e0\u4e3a\u6e90\u57df\u6570\u636e\u53ef\u4ee5\u7531\u6807\u7b7e\u8fdb\u884c\u76d1\u7763\uff0c\u800c\u76ee\u6807\u57df\u7684\u80cc\u666f\u4fe1\u606f\u5bf9\u4e8e\u5b9e\u4f8b\u7ea7\u7279\u5f81\u7684\u5bf9\u9f50\u4f5c\u7528\u4e0d\u5927\u3002</p>"},{"location":"domain_adaptive/paper/ICR-CCR1/#_7","title":"\u4e0e\u7b97\u6cd5\u7684\u7ed3\u5408","text":"<p>\u2003\u2003\u672c\u6587\u4e2d\uff0c\u4f5c\u8005\u5c06Domain Adaptive Faster R-CNN(DA-Faster)\u7b97\u6cd5\u4e0eStrong-Weak aligned Faster R-CNN(SW-Faster)\u7b97\u6cd5\u4f5c\u4e3a\u57fa\u7ebf\u6a21\u578b\u505a\u7814\u7a76</p> <p>\u4e0eDA-Faster\u7684\u7ed3\u5408</p> <p>\u2003\u2003\u5c06\u8be5\u6b63\u5219\u5316\u5668\u4e0eDA-Faster\u7ed3\u5408\u975e\u5e38\u7b80\u5355\uff0c\u53ea\u9700\u8981\u5728\u7f51\u7edc\u4e2d\u989d\u5916\u9644\u52a0\u4e00\u4e2a\u591a\u6807\u7b7e\u5206\u7c7b\u5668\uff0c\u5373\u6dfb\u52a0\u4e00\u4e2a\u5168\u5c40\u5e73\u5747\u6c60\u5316\u5c42\u548c\u4e00\u4e2a1\\times1\u7684\u5377\u79ef\u5c42\uff0c\u5e76\u4e14\u4f7f\u7528CCR\u6a21\u5757\u6765\u5bf9\u5b9e\u4f8b\u7ea7\u5bf9\u9f50\u7684\u635f\u5931\u505a\u52a0\u6743\uff0c\u6700\u7ec8\u635f\u5931\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ \\begin{aligned} \\mathcal L^*_{DAF}=\\mathcal L_{det}+\\mathcal L_{ICR}+\\lambda\u00b7(\\mathcal L_{img}+\\mathcal L_{ins}^{CCR}+\\mathcal L_{cst}) \\end{aligned} $$  \u5176\u4e2d\\lambda\u8bbe\u7f6e\u4e3a0.1</p> <p>\u4e0eSW-Faster\u7684\u7ed3\u5408</p> <p>\u2003\u2003SW-Faster\u4e3b\u8981\u5728DA-Faster\u7684\u57fa\u7840\u4e0a\u4f7f\u7528\u5f31\u5168\u5c40\u5bf9\u9f50\u6765\u63d0\u5347\u6a21\u578b\u5728\u56fe\u50cf\u7ea7\u81ea\u9002\u5e94\u7684\u80fd\u529b\uff0c\u5e76\u4e14\u4f7f\u7528\u5f3a\u5c40\u90e8\u5bf9\u9f50\u6765\u4ee3\u66ff\u539f\u6765\u7684\u5b9e\u4f8b\u5bf9\u9f50\u6a21\u5757\u3002\u56e0\u4e3a\u4f5c\u8005\u8bbe\u8ba1\u7684\u5206\u7c7b\u6b63\u5219\u5316\u6846\u67b6\u7528\u4e8e\u63d0\u5347\u7279\u5b9a\u5bf9\u9f50\u7b97\u6cd5\u7684\u6027\u80fd\uff0cICR\u6a21\u5757\u53ef\u4ee5\u76f4\u63a5\u5730\u7ed3\u5408\u5230SW-Faster\u4e2d\uff0c\u4f46\u662f\u7531\u4e8e\u7b97\u6cd5\u7f3a\u5c11\u5b9e\u4f8b\u7ea7\u5bf9\u9f50\u6a21\u5757\uff0cCCR\u6a21\u5757\u4e0d\u80fd\u76f4\u63a5\u4e0e\u8be5\u7b97\u6cd5\u7ed3\u5408\uff0c\u56e0\u6b64\u4f5c\u8005\u5728\u6b64\u57fa\u7840\u4e0a\u6dfb\u52a0\u4e86\u5b9e\u4f8b\u7ea7\u5bf9\u9f50\u6a21\u5757\u3002\u6700\u540e\u7684\u603b\u635f\u5931\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ \\mathcal L^*_{SWF}=\\mathcal L_{det}+\\mathcal L_{ICR}+\\lambda'\u00b7(\\mathcal L_{ins}^{CCR}+\\mathcal L_{global}+\\mathcal L_{local}) $$  \u5176\u4e2d\\lambda'\u88ab\u8bbe\u7f6e\u4e3a1.0\u3002</p>"},{"location":"domain_adaptive/paper/ICR-CCR1/#map","title":"mAP\u5bf9\u6bd4","text":"<p>Cityscape \\rightarrow FoggyCityscape</p> <p> <p></p> <p></p>"},{"location":"domain_adaptive/paper/ICR-CCR1/#_8","title":"\u603b\u7ed3","text":"<p>\u2003\u2003\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8eDA Faster\u7684\u5206\u7c7b\u6b63\u5219\u5316\u6846\u67b6\uff0c\u4ee5\u63d0\u9ad8\u68c0\u6d4b\u6a21\u578b\u7684\u81ea\u9002\u5e94\u80fd\u529b\u3002\u5177\u4f53\u7684\u6765\u8bf4\uff0c\u4f5c\u8005\u5229\u7528\u4e86\u591a\u6807\u7b7e\u5206\u7c7b\u7f51\u7edc\u7684\u5f31\u5b9a\u4f4d\u80fd\u529b\u548c\u56fe\u50cf\u7ea7\u9884\u6d4b\u4e0e\u5b9e\u4f8b\u7ea7\u9884\u6d4b\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\uff0c\u901a\u8fc7\u8ba9\u7f51\u7edc\u805a\u7126\u4e8e\u5bf9\u9f50\u7269\u4f53\u76f8\u5173\u7684\u5c40\u90e8\u533a\u57df\u7279\u5f81\u548c\u96be\u5bf9\u9f50\u7684\u5b9e\u4f8b\u7279\u5f81\u6765\u8fdb\u4e00\u6b65\u63d0\u5347\u6a21\u578b\u7684\u9886\u57df\u81ea\u9002\u5e94\u80fd\u529b\u3002</p> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u5927\u5bb6\u6279\u8bc4\u6307\u6b63</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e742\u67089\u65e5</p>"},{"location":"domain_adaptive/paper/MeGA-CDA1/","title":"\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\uff1aMeGA-CDA","text":""},{"location":"domain_adaptive/paper/MeGA-CDA1/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u4e0e\u65f6\u95f4\uff1aIEEE Conference on Computer Vision and Pattern Recognition 2021 (CVPR, 2021)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttp://openaccess.thecvf.com/content/CVPR2021/papers/VS_MeGA-CDA_Memory_Guided_Attention_for_Category-Aware_Unsupervised_Domain_Adaptive_Object_CVPR_2021_paper.pdf</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b</p>"},{"location":"domain_adaptive/paper/MeGA-CDA1/#_2","title":"\u4e3b\u8981\u601d\u60f3","text":"<p>\u2003\u2003\u9762\u5bf9\u8bad\u7ec3\u6570\u636e\u4e0e\u6d4b\u8bd5\u6570\u636e\u7684\u9886\u57df\u504f\u79fb\u95ee\u9898\uff0c\u4e00\u79cd\u5e38\u7528\u7684\u65b9\u6cd5\u5c31\u662f\u901a\u8fc7\u65e0\u76d1\u7763\u7684\u9886\u57df\u81ea\u9002\u5e94\u6765\u5bf9\u9f50\u6e90\u57df\u4e0e\u76ee\u6807\u57df\u7684\u7279\u5f81\u5206\u5e03\uff0c\u901a\u8fc7\u5229\u7528\u5bf9\u6297\u635f\u5931\u6765\u8bad\u7ec3\u57df\u5206\u7c7b\u5668\u4ece\u800c\u63d0\u5347\u6a21\u578b\u7684\u9886\u57df\u9002\u5e94\u80fd\u529b\u3002\u867d\u7136\u73b0\u6709\u7684\u65b9\u6cd5\u5e26\u6765\u4e86\u76f8\u5f53\u5927\u7684\u6539\u8fdb\uff0c\u4f46\u662f\u5b83\u4eec\u90fd\u662f\u6267\u884c\u4e0e\u7c7b\u522b\u65e0\u5173\u7684\u9886\u57df\u9002\u5e94\u65b9\u6cd5\uff0c\u5728\u5bf9\u9f50\u9886\u57df\u6570\u636e\u5206\u5e03\u65f6\u6ca1\u6709\u8003\u8651\u7c7b\u522b\u4fe1\u606f\uff0c\u8fd9\u6709\u53ef\u80fd\u4f1a\u5bfc\u81f4\u6570\u636e\u9519\u8bef\u5bf9\u9f50\u7684\u60c5\u51b5\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u4e0a\u56fe\u7b2c\u4e00\u884c\u4ec5\u7528\u5168\u5c40\u81ea\u9002\u5e94\uff0c\u7b2c\u4e8c\u884c\u540c\u65f6\u4f7f\u7528\u5168\u5c40\u81ea\u9002\u5e94\u4e0e\u7c7b\u522b\u76f8\u5173\u7684\u81ea\u9002\u5e94\u3002</p> <p>\u2003\u2003\u8003\u8651\u5230\u8fd9\u4e2a\u95ee\u9898\uff0c\u4f5c\u8005\u9664\u4e86\u5728\u5168\u5c40\u9886\u57df\u6267\u884c\u5bf9\u9f50\u4e4b\u5916\uff0c\u8fd8\u5173\u6ce8\u5bf9\u7c7b\u522b\u7279\u5f81\u6267\u884c\u5bf9\u9f50\uff0c\u4ece\u800c\u5c06\u7c7b\u522b\u4fe1\u606f\u7eb3\u5165\u9886\u57df\u9002\u5e94\u7684\u8fc7\u7a0b\u4e2d\u3002\u5177\u4f53\u7684\u6765\u8bf4\uff0c\u4f5c\u8005\u8bbe\u8ba1\u4e86\u4e00\u79cd\u50cf\u7d20\u7ea7\u522b\u7684\u7c7b\u522b\u76f8\u5173\u5224\u522b\u5668(Category-wise discriminators)(\u4e0b\u9762\u7b80\u79f0\u7c7b\u5224\u522b\u5668)\uff0c\u5bf9\u6bcf\u4e2a\u7c7b\u522b\u4f7f\u7528\u4e0d\u540c\u7684\u7c7b\u5224\u522b\u5668\u6267\u884c\u9886\u57df\u81ea\u9002\u5e94\u3002\u4f46\u662f\uff0c\u5728\u65e0\u76d1\u7763\u7684\u9886\u57df\u81ea\u9002\u5e94\u4e2d\uff0c\u5bf9\u4e8e\u76ee\u6807\u57df\u6570\u636e\u96c6\u6ca1\u6709\u8fb9\u754c\u6846\u6ce8\u91ca\uff0c\u56e0\u6b64\u96be\u4ee5\u5f97\u5230\u76ee\u6807\u57df\u7684\u7c7b\u522b\u7279\u5f81\uff0c\u4ece\u800c\u96be\u4ee5\u8bad\u7ec3\u7279\u5b9a\u7684\u7c7b\u5224\u522b\u5668\u3002</p> <p>\u2003\u2003\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u7528\u4e8e\u7c7b\u522b\u7279\u5f81\u5bf9\u9f50\uff0c\u5e76\u4e14\u7531\u8bb0\u5fc6\u5f15\u5bfc\u7684\u6ce8\u610f\u529b\u673a\u5236\uff0c\u8be5\u673a\u5236\u4e3b\u8981\u7684\u4f5c\u7528\u5c31\u662f\u751f\u6210\u5173\u6ce8\u539f\u56fe\u4e2d\u7279\u5b9a\u7c7b\u522b\u7269\u4f53\u4f4d\u7f6e\u7684\u6ce8\u610f\u529b\u56fe\uff0c\u56e0\u6b64\uff0c\u53ef\u4ee5\u7528\u4e8e\u5c06\u4e3b\u5e72\u7279\u5f81\u5206\u914d\u5230\u9002\u5f53\u7684\u7c7b\u5224\u522b\u5668\u4e2d\uff0c\u5373\u5c06\u5c5e\u4e8e\u7279\u5b9a\u7c7b\u522b\u7684\u7279\u5f81\u5206\u914d\u5230\u7279\u5b9a\u7684\u7c7b\u5224\u522b\u5668\uff0c\u4f5c\u8005\u53c2\u8003\u8bba\u6587\u300aLearning Memory-guided Normality for Anomaly Detection\u300b\uff0c\u63d0\u51fa\u4e86\u5229\u7528\u8bb0\u5fc6\u7f51\u7edc\u6765\u751f\u6210\u6ce8\u610f\u529b\u56fe\u3002\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u7531\u4e8e\u8bb0\u5fc6\u7f51\u7edc\u53ef\u4ee5\u957f\u671f\u5b58\u50a8\u6570\u636e\u7684\u7279\u6027\uff0c\u56e0\u6b64\u8fd9\u4e9b\u8bb0\u5fc6\u6a21\u5757\u7528\u4e8e\u5b58\u50a8\u4e0d\u540c\u7c7b\u522b\u5bf9\u8c61\u7684\u539f\u578b\u7279\u5f81(prototypes)\u3002\u4e3a\u4e86\u786e\u5b9a\u7279\u5b9a\u4f4d\u7f6e\u7684\u6ce8\u610f\u529b\uff0c\u4f5c\u8005\u4f7f\u7528\u8be5\u4f4d\u7f6e\u63d0\u53d6\u5230\u7684\u7279\u5f81\u6765\u8fdb\u884c\u67e5\u8be2\uff0c\u4ece\u4e0d\u540c\u7c7b\u522b\u7279\u5b9a\u7684\u8bb0\u5fc6\u6a21\u5757\u4e2d\u68c0\u7d22\u76f8\u5173\u8bb0\u5fc6\u5355\u5143\uff0c\u7136\u540e\u5c06\u68c0\u7d22\u5230\u7684\u8bb0\u5fc6\u5355\u5143\u7279\u5f81\u4e0e\u67e5\u8be2\u7684\u7279\u5f81\u8fdb\u884c\u6bd4\u8f83\uff0c\u5f97\u5230\u76f8\u4f3c\u6027\u77e9\u9635\uff0c\u6700\u540e\u6839\u636e\u76f8\u4f3c\u6027\u77e9\u9635\u751f\u6210\u7c7b\u522b\u7279\u5b9a\u7684\u6ce8\u610f\u529b\u56fe\u3002\u6b64\u5916\uff0c\u4e3a\u4e86\u63d0\u9ad8\u8bb0\u5fc6\u6a21\u5757\u548c\u6ce8\u610f\u529b\u56fe\u751f\u6210\u8fc7\u7a0b\u7684\u6709\u6548\u6027\uff0c\u4f5c\u8005\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5ea6\u91cf\u5b66\u4e60\u7684\u76f8\u4f3c\u6027\u8ba1\u7b97\u65b9\u6cd5\uff0c\u5229\u7528\u6e90\u57df\u6570\u636e\u96c6\u6765\u5b66\u4e60\u9002\u5f53\u7684\u76f8\u4f3c\u6027\u5ea6\u91cf\u3002</p>"},{"location":"domain_adaptive/paper/MeGA-CDA1/#_3","title":"\u65b9\u6cd5","text":"<p>\u2003\u2003\u4e0e\u5927\u591a\u6570\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u4e00\u6837\uff0c\u4f5c\u8005\u5047\u8bbe\u6240\u6709\u7684\u6e90\u57df\u56fe\u50cf\u90fd\u5177\u6709\u6807\u7b7e(\u5982\u8fb9\u754c\u6846\u3001\u7c7b\u522b)\uff0c\u800c\u76ee\u6807\u57df\u56fe\u50cf\u6ca1\u6709\u4efb\u4f55\u6807\u7b7e\u3002\u672c\u6587\u4e2d\uff0c\u4ee4D_s=\\{X_s^i,b_s^i,y_s^i\\}^{N_s}_{i=1}\u8868\u793a\u6e90\u57df\u6570\u636e\u96c6\uff0c\u5176\u4e2dX_s^i\u8868\u793a\u7b2ci\u5f20\u56fe\u7247\u3001b_s^i\u548cy_s^i\u8868\u793a\u7b2ci\u5f20\u6e90\u57df\u56fe\u7247\u7684\u8fb9\u754c\u6846\u6807\u6ce8\u548c\u5bf9\u5e94\u7684\u7269\u4f53\u7c7b\u522b\u6807\u7b7e\uff0c\u5e76\u4e14\u7c7b\u522b\u6807\u7b7e\u5305\u542bK\u4e2a\u7269\u4f53\u7c7b\u522b\u548c\u4e00\u4e2a\u989d\u5916\u7684\u80cc\u666f\u7c7b\u522b\uff0c\u5373y_s^i\\in\\{1,2,\\dots,K+1\\}\uff0c\u8fdb\u4e00\u6b65\uff0c\u5047\u8bbe\u76ee\u6807\u57df\u6570\u636e\u4e3aD_t=\\{X^i_t\\}^{N_t}_{i=1}\uff0c\u5176\u4e2dX^i_t\u8868\u793a\u7b2ci\u5f20\u76ee\u6807\u57df\u56fe\u7247\u3002\u6700\u540e\uff0c\u4f7f\u7528Faster R-CNN\u4f5c\u4e3a\u57fa\u7840\u6a21\u578b\u3002\u7b97\u6cd5\u7684\u76ee\u6807\u5c31\u662f\u5229\u7528\u6e90\u57df\u6807\u7b7e\u4fe1\u606f\u53bb\u5b66\u4e60\u4e00\u4e2a\u5728\u76ee\u6807\u57df\u56fe\u50cf\u4e0a\u8868\u73b0\u826f\u597d\u7684\u7f51\u7edc\uff0c\u4e0e\u4ee5\u524d\u7684\u7b97\u6cd5\u4e00\u6837\uff0c\u4f5c\u8005\u91c7\u7528\u7279\u5f81\u5bf9\u9f50\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u9886\u57df\u5bf9\u6297\u7684\u8bad\u7ec3\u6765\u5339\u914d\u7531\u7279\u5f81\u7f16\u7801\u7f51\u7edc\u63d0\u53d6\u7684\u6e90\u57df\u548c\u76ee\u6807\u57df\u6570\u636e\u56fe\u50cf\u7684\u7279\u5f81\u5206\u5e03\uff0c\u5fae\u8c03\u6a21\u578b\u7684\u7279\u5f81\u8868\u793a\u4ece\u800c\u4f7f\u7f51\u7edc\u5177\u6709\u4e00\u5b9a\u7684\u9886\u57df\u9002\u5e94\u80fd\u529b\u3002</p>"},{"location":"domain_adaptive/paper/MeGA-CDA1/#_4","title":"\u7f51\u7edc\u7ed3\u6784","text":"<p>\u2003\u2003\u4e0b\u56fe\u5c55\u793a\u4e86\u7b97\u6cd5\u7684\u4e3b\u8981\u6d41\u7a0b\uff0c\u4e3b\u8981\u7531\u4e09\u4e2a\u6a21\u5757\u7ec4\u6210\uff1a\u2460\u5168\u5c40\u9886\u57df\u5224\u522b\u5668(Global discriminator)\uff1a\u5bf9\u9f50\u7531\u7279\u5f81\u7f16\u7801\u7f51\u7edc\u63d0\u53d6\u7684\u6574\u4e2a\u7279\u5f81\u56fe\uff1b\u2461\u7c7b\u5224\u522b\u5668(Category-wise discriminators, CDA)\uff1a\u5173\u6ce8\u5404\u4e2a\u7279\u5b9a\u7c7b\u522b\u7684\u4fe1\u606f\uff0c\u5bf9\u9f50\u6e90\u57df\u548c\u76ee\u6807\u57df\u4e4b\u95f4\u5c5e\u4e8e\u76f8\u5e94\u7c7b\u522b\u7684\u7279\u5f81\uff1b\u2462\u8bb0\u5fc6\u6307\u5bfc\u7684\u6ce8\u610f\u529b\u673a\u5236(Memory-guided attention mechanism)\uff1a\u901a\u8fc7\u5728\u63d0\u53d6\u5230\u7684\u7279\u5f81\u56fe\u4e0a\u751f\u6210\u7279\u5b9a\u7c7b\u522b\u7684\u6ce8\u610f\u529b\u56fe\uff0c\u8fdb\u4e00\u6b65\u5229\u7528\u7c7b\u522b\u6ce8\u610f\u529b\u56fe\u6765\u5c06\u539f\u59cb\u7279\u5f81\u5206\u914d\u5230\u4e0d\u540c\u7684\u7c7b\u5224\u522b\u5668\u4e2d\u3002\u901a\u8fc7\u4f7f\u7528\u5b58\u50a8\u7279\u5b9a\u5bf9\u8c61\u7c7b\u522b\u76f8\u5173\u4fe1\u606f\u7684\u8bb0\u5fc6\u6a21\u5757\u6765\u4ea7\u751f\u6ce8\u610f\u529b\uff0c\u8be5\u6ce8\u610f\u529b\u53ef\u4ee5\u5e2e\u52a9\u7f51\u7edc\u5173\u6ce8\u7279\u5f81\u56fe\u4e2d\u7684\u7c7b\u522b\u4fe1\u606f\uff0c\u4ece\u800c\u8bad\u7ec3\u5404\u81ea\u7684\u7c7b\u522b\u5224\u522b\u5668\u3002</p> <p> <p></p> <p></p>"},{"location":"domain_adaptive/paper/MeGA-CDA1/#_5","title":"\u5168\u5c40\u5224\u522b\u5668","text":"<p>\u2003\u2003\u4f5c\u8005\u53c2\u8003Domain Adaptive Faster R-CNN\u7b97\u6cd5(\u8bba\u6587\u94fe\u63a5\u3001\u8bba\u6587\u7b14\u8bb0\u94fe\u63a5)\uff0c\u5728\u7f51\u7edc\u4e2d\u5e94\u7528\u4e86\u5168\u5c40\u5224\u522b\u5668\u6765\u5bf9\u9f50\u56fe\u50cf\u6c34\u5e73(image-level)\u7684\u7279\u5f81\u56fe\u3002\u5047\u8bbe\\mathcal D_{gda}\u8868\u793a\u5168\u5c40\u5224\u522b\u5668\uff0c\u8f93\u5165\u7531\u4e3b\u5e72\u7f51\u7edc\u63d0\u53d6\u7684\u7279\u5f81\u56fe\uff0c\u4e4b\u540e\u8bad\u7ec3\u5176\u9886\u57df\u5206\u7c7b\u7684\u80fd\u529b\uff0c\u5373\u8ba9\u5176\u5224\u65ad\u8be5\u7279\u5f81\u56fe\u662f\u4ece\u6e90\u57df\u56fe\u50cf\u63d0\u53d6\u7684\u7279\u5f81\u8fd8\u662f\u76ee\u6807\u57df\u56fe\u50cf\u63d0\u53d6\u7684\u7279\u5f81\u3002\u5047\u8bbe\u7279\u5f81\u56feF_s,F_t\\in\\mathbb R^{C\\times H\\times W}\u5206\u522b\u4e3a\u4ece\u6e90\u57df\u56fe\u50cfX_s\u548c\u76ee\u6807\u57df\u56fe\u50cfX_t\u63d0\u53d6\u7684\u7279\u5f81\uff0c\u5168\u5c40\u5224\u522b\u5668\\mathcal D_{gda}\u8f93\u51fa\u4e00\u5f20\u5c3a\u5bf8\u4e3aH\\times W\u7684\u9886\u57df\u9884\u6d4b\u56fe\uff08\u56e0\u6b64\u5168\u5c40\u5224\u522b\u5668\u6267\u884c\u7684\u662f\u50cf\u7d20\u7ea7\u522b\u7684\u5bf9\u9f50\uff09\uff0c\u6e90\u57df\u56fe\u50cf\u548c\u76ee\u6807\u57df\u56fe\u50cf\u7684\u6807\u7b7ey_d\u5206\u522b\u4e3a0\u548c1\uff0c\u5168\u5c40\u5224\u522b\u5668\u7684\u635f\u5931\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ \\mathcal L_{gda}(X_s,X_t)=-\\sum^H_{h=1}\\sum^W_{w=1}y_d(1-\\mathcal D_{gda}(F_s^{(h,w)}))^2+(1-y_d)(\\mathcal D_{gda}(F_t^{(h,w)}))^2 $$  \u2003\u2003\u4e3a\u4e86\u8ba9\u5339\u914d\u6e90\u57df\u548c\u76ee\u6807\u57df\u7684\u7279\u5f81\uff0c\u4f5c\u8005\u5229\u7528\u68af\u5ea6\u53cd\u8f6c\u5c42\u6765\u8bad\u7ec3\u5168\u5c40\u5224\u522b\u5668\u4ee5\u53ca\u5fae\u8c03\u4e3b\u5e72\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\uff0c\u901a\u8fc7\u5c06\u68af\u5ea6\u4f20\u56de\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u4e4b\u524d\u5bf9\u68af\u5ea6\u7684\u7b26\u53f7\u8fdb\u884c\u53cd\u8f6c\uff0c\u8ba9\u5224\u522b\u5668\u548c\u4e3b\u5e72\u7f51\u7edc\u4ee5\u5bf9\u6297\u7684\u5f62\u5f0f\u8bad\u7ec3\uff0c\u4ece\u800c\u6709\u52a9\u4e8e\u7f29\u5c0f\u6e90\u57df\u56fe\u50cf\u548c\u76ee\u6807\u57df\u56fe\u50cf\u7279\u5f81\u4e4b\u95f4\u7684\u9886\u57df\u5dee\u5f02\u3002\u56e0\u6b64\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u4e0a\u8ff0\u635f\u5931\u6765\u8bad\u7ec3\u5224\u522b\u5668\u7f51\u7edc\\mathcal D_{gda}\u53c2\u6570\uff0c\u6700\u5927\u5316\u4e0a\u8ff0\u635f\u5931\u6765\u8bad\u7ec3\u4e3b\u5e72\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u7684\u53c2\u6570\u3002\u8fdb\u4e00\u6b65\u5730\uff0c\u4e0e\u4f20\u7edf\u4f7f\u7528\u4ea4\u53c9\u71b5\u635f\u5931\u4e0d\u540c\uff0c\u8fd9\u91cc\u4f5c\u8005\u53c2\u8003\u8bba\u6587\u300aLeast squares generative adversarial networks\u300b(\u8bba\u6587\u94fe\u63a5)\uff0c\u5229\u7528\u6700\u5c0f\u4e8c\u4e58\u635f\u5931(least-squares loss)\u6765\u8ba1\u7b97\u5224\u522b\u5668\u9884\u6d4b\u7684\u8bef\u5dee\uff0c\u53ef\u4ee5\u66f4\u597d\u5730\u7a33\u5b9a\u8bad\u7ec3\u7684\u8fc7\u7a0b\u3002\u4f46\u662f\uff0c\u5168\u5c40\u81ea\u9002\u5e94\u662f\u4e00\u79cd\u4e0e\u7c7b\u522b\u65e0\u5173\u7684\u9002\u5e94\u65b9\u6cd5\uff0c\u5982\u679c\u5355\u72ec\u5bf9\u4e0e\u7c7b\u522b\u65e0\u5173\u7684\u7279\u5f81\u5bf9\u9f50\uff0c\u4f1a\u5bfc\u81f4\u6a21\u578b\u529f\u80fd\u7684\u8d1f\u8fc1\u79fb\uff0c\u635f\u5bb3\u7f51\u7edc\u7684\u6574\u4f53\u6027\u80fd\uff0c\u56e0\u6b64\u9700\u8981\u989d\u5916\u7684\u7b56\u7565\u6765\u8fdb\u4e00\u6b65\u63d0\u9ad8\u7f51\u7edc\u7684\u6027\u80fd\u3002</p>"},{"location":"domain_adaptive/paper/MeGA-CDA1/#_6","title":"\u7c7b\u522b\u76f8\u5173\u7684\u5224\u522b\u5668","text":"<p>\u2003\u2003\u4f5c\u8005\u8bbe\u8ba1\u4e86\u7c7b\u522b\u76f8\u5173\u7684\u5224\u522b\u5668\u6765\u4f7f\u7f51\u7edc\u5728\u5bf9\u9f50\u6e90\u57df\u548c\u76ee\u6807\u57df\u7279\u5f81\u7684\u540c\u65f6\u89e3\u51b3\u7c7b\u522b\u4e4b\u95f4\u7684\u7279\u5f81\u8d1f\u8fc1\u79fb\u95ee\u9898\uff0c\u8be5\u9274\u522b\u5668\u4e13\u6ce8\u5728\u6e90\u57df\u548c\u76ee\u6807\u57df\u4e4b\u95f4\u5bf9\u9f50\u5404\u81ea\u7279\u5b9a\u7684\u7c7b\u522b\u7279\u5f81\u3002\u5177\u4f53\u5730\u6765\u8bf4\uff0c\u4f5c\u8005\u4f7f\u7528K\u4e2a\u7c7b\u5224\u522b\u5668\uff0c\u6bcf\u4e2a\u90fd\u4fa7\u91cd\u4e8e\u5bf9\u9f50\u5404\u81ea\u7684\u7c7b\u522b\uff0c\u5047\u8bbe\u7b2ck\u4e2a\u7c7b\u522b\u7684\u5224\u522b\u5668\u8868\u793a\u4e3a\\mathcal D_{cda}^k\uff0c\u4e3a\u4e86\u5bf9\u9f50\u6e90\u57df\u548c\u76ee\u6807\u57df\u4e4b\u95f4\u7b2ck\u7c7b\u7684\u7279\u5f81F_s\u548cF_t\uff0c\u9996\u5148\u751f\u6210\u6ce8\u610f\u529b\u56fe\\sigma(F_s)_k,\\sigma(F_t)_k\\in\\{0,1\\}^{H\\times W}\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u56fe\u6765\u8ba9\u7f51\u7edc\u53ea\u5173\u6ce8\u7b2ck\u7c7b\u76f8\u5173\u7684\u7279\u5f81\u4fe1\u606f\uff0c\u7b2ck\u7c7b\u7684\u7c7b\u522b\u9002\u5e94\u635f\u5931\u51fd\u6570\u53ef\u4ee5\u5199\u6210\uff1a $$ \\begin{aligned} \\mathcal L_{cda}^k(X_s,X_t)=&amp;-\\sum^H_{h=1}\\sum^W_{w=1}y_d(1-\\mathcal D^k_{cda}(\\sigma(F_s)_k^{(h,w)}\u00b7F_s^{(h,w)}))^2+\\\\&amp;(1-y_d)(\\mathcal D^k_{cda}(\\sigma(F_t)_k^{(h,w)}\u00b7F_t^{(h,w)}))^2 \\end{aligned} $$  \u5176\u4e2d\uff0c\\sigma(\u00b7)_k^{(h,w)}=1\u4e0e\\sigma(\u00b7)_k^{(h,w)}=0\u5206\u522b\u8868\u793a\u7279\u5f81\u56fe(F_s,F_t)\u5728\u4f4d\u7f6e(h,w)\u5904\u662f\u5426\u5b58\u5b58\u5728\u7b2ck\u7c7b\u7684\u7279\u5f81\uff0c\u4e00\u5171\u6709K\u4e2a\u7c7b\u522b\uff0c\u56e0\u6b64\u9700\u8981\u8ba1\u7b97K\u4e2a\u6ce8\u610f\u529b\u56fe\uff0c\u5206\u522b\u4e0eK\u4e2a\u7c7b\u5224\u522b\u5668\u76f8\u5bf9\u5e94\u3002</p> <p>\u2003\u2003\u73b0\u5728\u4e3b\u8981\u7684\u95ee\u9898\u5c31\u662f\u5728\u7c7b\u5224\u522b\u5668\u8bad\u7ec3\u7684\u8fc7\u7a0b\u4e2d\u7f3a\u5c11\u7279\u5f81\u56fe\u4e2d\u7c7b\u522b\u4f4d\u7f6e\u7684\u4fe1\u606f(\u5373\u7f3a\u5c11\u6ce8\u610f\u529b\u56fe)\uff0c\u5c24\u5176\u662f\u76ee\u6807\u57df\u7684\u7279\u5f81\u6570\u636e\uff0c\u5bf9\u6b64\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bb0\u5fc6\u5f15\u5bfc\u7684\u6ce8\u610f\u529b\u673a\u5236\uff0c\u901a\u8fc7\u5229\u7528\u8bb0\u5fc6\u6a21\u5757\u6765\u9884\u6d4b\u6bcf\u4e2a\u7c7b\u522b\u4f4d\u7f6e\u7684\u6ce8\u610f\u529b\u56fe\uff0c\u8fdb\u4e00\u6b65\u89e3\u51b3\u4e0a\u8ff0\u4f4d\u7f6e\u4fe1\u606f\u7f3a\u5931\u7684\u95ee\u9898\u3002</p>"},{"location":"domain_adaptive/paper/MeGA-CDA1/#_7","title":"\u57fa\u4e8e\u8bb0\u5fc6\u5f15\u5bfc\u7684\u6ce8\u610f\u529b\u673a\u5236","text":"<p>\u2003\u2003\u4f5c\u8005\u5206\u522b\u4e3aK\u7c7b\u6784\u5efa\u4e86K\u4e2a\u8bb0\u5fc6\u6a21\u5757\uff0c\u8fd9\u4e9b\u8bb0\u5fc6\u6a21\u5757\u7528\u4e8e\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5b58\u50a8\u4e0d\u540c\u5bf9\u8c61\u7684\u7c7b\u539f\u578b\uff0c\u4ee5\u4fbf\u53ef\u4ee5\u68c0\u7d22\u4ed6\u4eec\u6765\u8ba1\u7b97\u7279\u5b9a\u7c7b\u522b\u7684\u6ce8\u610f\u529b\u56fe\u3002</p>"},{"location":"domain_adaptive/paper/MeGA-CDA1/#_8","title":"\u8bb0\u5fc6\u6a21\u5757","text":"<p>\u4f5c\u8005\u53c2\u8003\u8bba\u6587\u300aLearning Memory-guided Normality for Anomaly Detection\u300b\u91cc\u9762\u7528\u4e8e\u5f02\u5e38\u68c0\u6d4b\u7684\u8bb0\u5fc6\u6a21\u5757\uff0c\u8bbe\u8ba1\u4e86\u7528\u4e8e\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u7684\u8bb0\u5fc6\u6a21\u5757</p> <p>\u2003\u2003\u4e00\u4e2a\u8bb0\u5fc6\u6a21\u5757\u4e3b\u8981\u6709\u4e24\u4e2a\u64cd\u4f5c\uff0c\u5206\u522b\u4e3a\u5199(write)\u548c\u8bfb(read)\u3002\u5199\u64cd\u4f5c\u5c31\u662f\u5229\u7528\u63d0\u53d6\u5230\u7684\u7279\u5f81\u6765\u9002\u5f53\u5730\u66f4\u65b0\u8bb0\u5fc6\u6a21\u5757\u7684\u5185\u5bb9\uff0c\u8bfb\u64cd\u4f5c\u5c31\u662f\u5229\u7528\u63d0\u53d6\u5f97\u5230\u7684\u7279\u5f81\u6765\u67e5\u8be2\u8bb0\u5fc6\u6a21\u5757\uff0c\u5e76\u4e14\u68c0\u7d22\u51fa\u6700\u76f8\u4f3c\u7684\u8bb0\u5fc6\u5143\u4ef6(\u6216\u539f\u578b\u7279\u5f81)\uff0c\u5373\u627e\u51fa\u8be5\u7279\u5f81\u4e0e\u54ea\u4e2a\u7c7b\u522b\u7684\u8bb0\u5fc6\u7279\u5f81\u6700\u76f8\u4f3c\u3002\u8fd9\u4e24\u4e2a\u64cd\u4f5c\u7684\u6d41\u7a0b\u56fe\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u672c\u7b97\u6cd5\u4e2d\uff0c\u4e00\u5171\u6784\u5efa\u4e86K\u4e2a\u8bb0\u5fc6\u6a21\u5757(\u4ec5\u5bf9\u5e94\u4e0d\u540c\u7684\u7c7b\u522b\uff0c\u4e0e\u9886\u57df\u65e0\u5173)\uff0c\u6e90\u57df\u548c\u76ee\u6807\u57df\u4e2d\u7b2cK\u4e2a\u7c7b\u522b\u7684\u8bb0\u5fc6\u6a21\u5757\u8868\u793a\u4e3aM_k\\in\\mathbb R^{N_m\\times C}\uff0c\u5176\u4e2dN_m\u8868\u793a\u6bcf\u4e2a\u7c7b\u522b\u7684\u8bb0\u5fc6\u5355\u5143\u6570\u91cf\uff08\u4e00\u4e2a\u8bb0\u5fc6\u6a21\u5757\u7531\u591a\u4e2a\u8bb0\u5fc6\u5355\u5143\u7ec4\u6210\uff09\uff0cC\u8868\u793a\u7279\u5f81\u56fe\u4e2d\u901a\u9053\u6570\u3002</p> <p>\u8bb0\u5fc6\u5199\u5165</p> <p>\u2003\u2003\u7531\u4e8e\u6e90\u57df\u56fe\u50cf\u53ef\u4ee5\u5229\u7528\u6807\u7b7e\u7684\u8fb9\u754c\u6846\u4e0e\u7c7b\u522b\u4fe1\u606f\u6765\u5b9a\u4f4d\u7279\u5f81\u56feF_s\u4e2d\u7c7b\u522b\u7279\u5b9a\u7684\u7279\u5f81\uff0c\u56e0\u6b64\u53ea\u8003\u8651\u5229\u7528\u6e90\u57df\u56fe\u50cf\u6570\u636e\u6765\u66f4\u65b0\u8bb0\u5fc6\u6a21\u5757\u3002\u4e3a\u4e86\u7b80\u6d01\u8d77\u89c1\uff0c\u5047\u8bbeG_k=\\{g_{s_k}^i\\in\\mathbb R^{1\\times C}\\}^{N_{s_k}}_{i=1}\u8868\u793a\u5728\u7279\u5f81\u56feF_s\u4e2d\u5c5e\u4e8e\u7c7b\u522bk\u7684\u6240\u6709\u7279\u5f81(\u5373\u4e00\u5f20\u56fe\u4e2d\u6240\u6709\u7c7b\u522b\u4e3ak\u7684\u50cf\u7d20\u70b9\u7279\u5f81\u96c6\u5408)\u3002\u540c\u65f6\uff0c\u5c06\u6bcf\u4e2a\u8bb0\u5fc6\u6a21\u5757\u4e2d\u7684\u8bb0\u5fc6\u5355\u5143\u8868\u793a\u4e3am_j\\in\\mathbb R^{1\\times C}\uff0c\u5176\u4e2dj\\in\\{1,\\dots,N_m\\}\u3002\u9996\u5148\u8ba1\u7b97M_k\u4e2d\u8bb0\u5fc6\u5355\u5143\u4e0e\u7b2ck\u7c7b\u7279\u5f81\u96c6\u5408G_k\u4e4b\u95f4\u7684\u6807\u51c6\u5316\u76f8\u4f3c\u5ea6\u91cf\uff1a $$ p^{(i,j)}=\\frac{\\exp(m_j\u00b7g^i_{s_k})}{\\sum_{l\\in G_k}\\exp(m_j\u00b7g_{s_k}^l)} $$  \u5176\u4e2d\uff0cp\u8868\u793a\u5c3a\u5bf8\u4e3aN_k\\times N_m\u7684\u76f8\u4f3c\u56fe(i\u5bf9\u5e94N_k\uff0cN_k\u8868\u793a\u8be5\u7279\u5f81\u56fe\u4e2d\u7b2ck\u7c7b\u7684\u7279\u5f81\u4e2a\u6570(\u50cf\u7d20\u70b9\u4e2a\u6570)\uff0cj\u5bf9\u5e94N_m\uff0cN_m\u8868\u793a\u8bb0\u5fc6\u5355\u5143\uff0c\u4ece\u4e8c\u7ef4\u77e9\u9635\u7684\u89c6\u89d2\u6765\u770b\uff0c\u884c\u8868\u793aG_k\u4e2d\u7684\u7279\u5f81\u5411\u91cf\uff0c\u5217\u8868\u793aM_k\u4e2d\u7684\u7279\u5f81\u5355\u5143)\uff0c\u4e4b\u540e\u5229\u7528\u8bb0\u5fc6\u5355\u5143\u548c\u7c7b\u522b\u7279\u5f81\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\u53bb\u66f4\u65b0\u5c5e\u4e8e\u8be5\u7c7b\u7684\u8bb0\u5fc6\u6a21\u5757\u4e2d\u6bcf\u4e2a\u8bb0\u5fc6\u5355\u5143\uff1a $$ m^j\\leftarrow m^j+\\sum_{i\\in G_k}p^{(i,j)}g^i_{s_k} $$  \u2003\u2003\u5982\u679c\u6e90\u57df\u56fe\u50cf\u4e2d\u4e0d\u5b58\u5728\u7b2ck\u7c7b\u7684\u7269\u4f53\uff0c\u5219\u4e0d\u4f1a\u66f4\u65b0\u54cd\u5e94\u5b58\u50a8\u6a21\u5757M_k\u4e2d\u7684\u5143\u7d20\u3002</p> <p>\u8bb0\u5fc6\u8bfb\u53d6</p> <p>\u2003\u2003\u4e3a\u4e86\u5229\u7528\u5f97\u5230\u7684\u7279\u5f81\u5bf9\u8bb0\u5fc6\u5355\u5143\u505a\u68c0\u7d22\uff0c\u9996\u5148\u8ba1\u7b97\u8bb0\u5fc6\u6a21\u5757M_k\u4e2d\u6bcf\u4e2a\u5355\u5143\u4e0e\u7ed9\u5b9a\u7684\u67e5\u8be2\u7279\u5f81\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6\uff0c\u6ce8\u610f\uff0c\u67e5\u8be2\u7279\u5f81\u53ef\u4ee5\u4ece\u6e90\u57df\u56fe\u50cf\u6216\u8005\u76ee\u6807\u57df\u56fe\u50cf\u83b7\u5f97(\u5747\u662f\u50cf\u7d20\u7ea7\u522b\u7684\u7279\u5f81)\uff0c\u4f8b\u5982\uff1ag^i_{s_k}\u6216\u8005g_{t_k}^i\u3002\u5bf9\u4e8eg_{s_k}^i\uff0c\u4f7f\u7528\u4e0b\u5f0f\u8ba1\u7b97\u5f52\u4e00\u5316\u76f8\u4f3c\u5ea6\uff1a $$ q^{(i,j)}=\\frac{\\exp(m_j\u00b7g_{s_k}^i)}{\\sum_{l\\in N_m}\\exp(m_l\u00b7g^i_{s_k})} $$  \u5f97\u5230\u76f8\u4f3c\u5ea6q\u4e4b\u540e\uff0c\u68c0\u7d22\u5230\u7684\u7279\u5f81\\hat{g}^i_{s_k}\\in\\mathbb R^{1\\times C}\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ \\hat{g}^i_{s_k}=\\sum_{j\\in N_m}q^{(i,j)}m_j $$  \u2003\u2003\u6e90\u57df\u56fe\u50cf\u548c\u76ee\u6807\u57df\u56fe\u50cf\u7684\u68c0\u7d22\u7279\u5f81(retrieved feature)\u8ba1\u7b97\u516c\u5f0f\u76f8\u540c\uff0c\u5747\u4ee5\u76f8\u540c\u7684\u65b9\u5f0f\u4ece\u8bb0\u5fc6\u6a21\u5757\u4e2d\u8bfb\u53d6\u6570\u636e\u3002</p> <p>\u2003\u2003\u6ce8\u610f\uff1a\u8bb0\u5fc6\u6a21\u5757\u7684\u5199\u64cd\u4f5c\u53ea\u9762\u5411\u6e90\u57df\u6570\u636e\uff0c\u5e76\u4e14\u53ea\u5229\u7528\u8fb9\u754c\u6846\u6807\u7b7e\u5bf9\u8868\u793a\u7279\u5b9a\u7c7b\u522b\u7684\u7279\u5f81\u505a\u88c1\u526a\uff0c\u4e4b\u540e\u5c06\u5f97\u5230\u7684\u7279\u5f81\u5199\u5165\u8bb0\u5fc6\u6a21\u5757\uff0c\u56e0\u6b64\u5199\u64cd\u4f5c\u4e2d\u7684g^i_{s_k}\u53ea\u8868\u793a\u8fb9\u754c\u6846\u5185\u90e8\u3001\u7279\u5b9a\u7c7b\u522b\u7684\u7279\u5f81\u5411\u91cf\uff1b\u800c\u8bfb\u64cd\u4f5c\u540c\u65f6\u9762\u5411\u6e90\u57df\u6570\u636e\u548c\u76ee\u6807\u57df\u6570\u636e\uff0c\u5e76\u4e14\u6ca1\u6709\u7528\u5230\u6e90\u57df\u6570\u636e\u4e2d\u7684\u8fb9\u754c\u6846\u4fe1\u606f\uff0c\u56e0\u6b64\u8bfb\u64cd\u4f5c\u4e2d\u7684g^i_{s_k}\u8868\u793a\u7279\u5f81\u56fe\u4e0a\u6240\u6709\u50cf\u7d20\u70b9\u7684\u7279\u5f81\u5411\u91cf(\u8fd9\u91cc\u76f4\u63a5\u8868\u793a\u6210g^i_s\u66f4\u5408\u9002)\u3002</p> <p>\u8bb0\u5fc6\u8bad\u7ec3\uff08\u8fd9\u91cc\u505a\u4e86\u4e00\u70b9\u66f4\u65b0\uff0c\u548c\u539f\u8bba\u6587\u5f62\u5f0f\u4e0d\u592a\u4e00\u6837\uff0c\u5177\u4f53\u53ef\u89c1\u95ee\u9898\u8bb0\u5f55\uff09</p> <p>\u2003\u2003\u9075\u5faa\u539f\u8bba\u6587\uff0c\u4f5c\u8005\u989d\u5916\u65b0\u52a0\u4e86\u4e24\u4e2a\u6b63\u5219\u5316\u5668\u6765\u7ea6\u675f\u7f51\u7edc\u6a21\u578b\u3002\u9996\u5148\uff0c\u4e3a\u4e86\u786e\u4fdd\u63d0\u53d6\u5230\u7684\u7279\u5f81\u4e0d\u79bb\u8bb0\u5fc6\u6a21\u5757\u592a\u8fdc\uff0c\u8bbe\u7acb\u4e86\u7d27\u5bc6\u5ea6\u635f\u5931(compactness loss)\u6765\u8fdb\u4e00\u6b65\u89c4\u8303\u7279\u5f81\uff0c\u901a\u8fc7\u4fc3\u8fdb\u67e5\u8be2\u7279\u5f81\u4e4b\u95f4\u7684\u7d27\u51d1\u6027\u6765\u51cf\u5c11\u7c7b\u5185\u53d8\u5316\uff0c\u8be5\u635f\u5931\u7531L2\u8ddd\u79bb\u60e9\u7f5a\u7ec4\u6210\uff1a $$ \\mathcal L_{cmp}=\\sum_{i=1}^{N_k}||m_p-g^i_{s_k}||_2 $$  \u8fd9\u91cc\u4ee5\u6e90\u57df\u56fe\u50cf\u7684\u7279\u5f81\u4e3a\u4f8b\uff0cN_k\u8868\u793a\u8be5\u7279\u5f81\u56fe\u4e2d\u5c5e\u4e8e\u7b2ck\u7c7b\u5bf9\u8c61\u7279\u5f81\u5411\u91cf\u7684\u4e2a\u6570\uff0c\u4e0e\u524d\u9762\u5b9a\u4e49\u7684N_k\u610f\u4e49\u76f8\u540c\uff0c\u7d22\u5f15p\u662fg^i\u7684\u4e00\u4e2a\u51fd\u6570\uff0c\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ p=\\mathop{\\arg\\max}_{j\\in N_m}\\quad q^{(i,j)} $$  \u8fd9\u91cc\u540c\u6837\u53ea\u5229\u7528\u6e90\u57df\u56fe\u50cf\u7684\u7b2ck\u7c7b\u88c1\u526a\u7279\u5f81\u6765\u8ba1\u7b97\u635f\u5931\uff0c\u8bb0\u5fc6\u8bfb\u53d6\u65f6\u6c42\u7684q\u662f\u9762\u5411\u6240\u6709\u50cf\u7d20\u70b9\u7684\uff0c\u56e0\u6b64\u8fd9\u91cc\u9700\u8981\u91cd\u65b0\u9488\u5bf9\u7b2ck\u7c7b\u88c1\u526a\u7279\u5f81\u6c42\u4e00\u6b21q\u3002</p> <p>\u2003\u2003\u5176\u6b21\uff0c\u9664\u4e86\u5c06\u8bb0\u5fc6\u6a21\u5757\u8c03\u6574\u5f97\u66f4\u7d27\u51d1\u4e4b\u5916\uff0c\u8fd8\u8bbe\u8ba1\u4e86\u552f\u4e00\u6027\u635f\u5931(uniqueness loss)\u6765\u7ea6\u675f\u6a21\u578b\u7279\u5f81\u7684\u8868\u793a\uff0c\u8be5\u635f\u5931\u7531\u4e09\u5143\u7ec4\u635f\u5931(triplet loss)\u51fd\u6570\u6784\u6210\uff0c\u901a\u8fc7\u4fc3\u8fdb\u8bb0\u5fc6\u6a21\u5757M_k\u4e2d\u6bcf\u4e2a\u8bb0\u5fc6\u5355\u5143\u8868\u793a\u7c7b\u522b\u552f\u4e00\u7684\u539f\u578b\u6765\u51cf\u5c11\u8bb0\u5fc6\u6a21\u5757\u4e2d\u7684\u6570\u636e\u5197\u4f59\uff1a $$ \\mathcal L_{unq}=\\sum_{i=1}^{N_k}[||m_p-g^i_{s_k}||_2-||m_n-g^i_{s_k}||_2+\\alpha]_+ $$  \u5176\u4e2d\uff0c\\alpha\u8868\u793a\u635f\u5931\u8fb9\u754c\uff0c\u7d22\u5f15n\u4e5f\u662fg^i\u7684\u4e00\u4e2a\u51fd\u6570\uff0c\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ n=\\mathop{\\arg\\max}_{j\\in N_m,j\\neq p}\\quad q^{(i,j)} $$  \u548c\u4e0a\u9762\u7d27\u5bc6\u5ea6\u635f\u5931\u4e00\u6837\uff0c\u53ea\u5229\u7528\u6e90\u57df\u56fe\u50cf\u7b2ck\u7c7b\u88c1\u526a\u7279\u5f81\u8ba1\u7b97\u635f\u5931\u3002</p> <p>\u2003\u2003\u5982\u679c\u8bb0\u5fc6\u6a21\u5757\u4e2d\u8bb0\u5fc6\u5355\u5143\u6240\u5b58\u50a8\u7684\u7279\u5f81\u6570\u636e\u76f8\u4f3c\u5ea6\u8fc7\u9ad8\u3001\u6570\u636e\u5197\u4f59\u6027\u8fc7\u5f3a(\u6709\u70b9\u7c7b\u4f3c\u8fc7\u62df\u5408)\uff0c\u4f1a\u964d\u4f4e\u8bb0\u5fc6\u7f51\u7edc\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u8fdb\u4e00\u6b65\u964d\u4f4e\u6a21\u578b\u7684\u6027\u80fd\u3002\u8be5\u635f\u5931\u4fc3\u8fdb\u4e86\u4e24\u4e2a\u8ddd\u79bb\u503c\u7684\u5206\u79bb\uff0c\u5373\u4fc3\u8fdb\u4e86\u67e5\u8be2\u7279\u5f81\u5411\u91cf\u548c\u7b2c\u4e8c\u4e2a\u6700\u8fd1\u7684\u8bb0\u5fc6\u5355\u5143\u76f8\u8fdc\u79bb\uff0c\u548c\u7b2c\u4e00\u4e2a\u6700\u8fd1\u7684\u8bb0\u5fc6\u5355\u5143\u76f8\u9760\u8fd1\uff0c\u8fdb\u4e00\u6b65\u5206\u79bb\u8bb0\u5fc6\u6a21\u5757\u4e2d\u7684\u6240\u6709\u5355\u5143\uff0c\u589e\u5f3a\u8fa8\u8bc6\u80fd\u529b\u3002</p> <p>\u2003\u2003\u7efc\u4e0a\u6240\u8ff0\uff0c\u8bb0\u5fc6\u6a21\u5757\u7684\u603b\u635f\u5931\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ \\mathcal L_{mem}=\\mathcal L_{cmp}+\\mathcal L_{unq} $$ </p>"},{"location":"domain_adaptive/paper/MeGA-CDA1/#_9","title":"\u6ce8\u610f\u529b\u673a\u5236","text":"<p>\u2003\u2003\u4f5c\u8005\u4f7f\u7528\u6240\u6709\u7684\u8bb0\u5fc6\u6a21\u5757\u53bb\u4e3a\u6bcf\u4e2a\u7c7b\u5224\u522b\u5668\u751f\u6210\u6ce8\u610f\u529b\u56fe\u3002\u5177\u4f53\u7684\u6765\u8bf4\uff0c\u4e3a\u76ee\u6807\u57df\u6570\u636e\u7684\u7279\u5f81\u56feF_t\u8ba1\u7b97\u6ce8\u610f\u529b\u56fe\uff0c\u9996\u5148\u5728\u7b2ck\u4e2a\u8bb0\u5fc6\u6a21\u5757\u4e2d\u67e5\u8be2\u7279\u5f81\u56fe\u4e2d\u6bcf\u4e2a\u4f4d\u7f6e\u7684\u7279\u5f81\u5143\u7d20f_t\\in\\mathbb R^{1\\times C}(C\u8868\u793a\u901a\u9053\u6570)\uff0c\u5f97\u5230\u68c0\u7d22\u7279\u5f81\u5411\u91cf\\hat{f}_t\\in\\mathbb R^{1\\times C}\uff0c\u4f9d\u6b21\u904d\u5386\u6240\u6709\u4f4d\u7f6e\uff0c\u6700\u540e\u5f97\u5230\u68c0\u7d22\u7279\u5f81\u56fe(retrieved feature map)\\hat{F}^k_t\\in\\mathbb R^{C\\times H\\times W}\u3002\u4e4b\u540e\u518d\u8ba1\u7b97\u63d0\u53d6\u5230\u7684\u7279\u5f81\u56feF_t\u548c\u68c0\u7d22\u7279\u5f81\u56fe\\hat{F}^k_t\u4e4b\u95f4\u7684\u5143\u7d20\u76f8\u4f3c\u6027\u6765\u5f97\u5230\u6ce8\u610f\u529b\u56fe\\sigma(F_t)_k\uff0c\u5bf9\u5e94\u4e8e\u7b2ck\u7c7b\u7684\u7c7b\u5224\u522b\u5668\uff0c\u8fd9\u91cc\u4f5c\u8005\u63a2\u7d22\u4e86\u4e24\u79cd\u76f8\u4f3c\u5ea6\u65b9\u7a0b\u6765\u8ba1\u7b97\u6ce8\u610f\u529b\u56fe\u3002</p> <p>\u4f59\u5f26\u76f8\u4f3c\u5ea6</p> <p>\u2003\u2003\u6700\u5e38\u7528\u7684\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u65b9\u7a0b\u5c31\u662f\u4f59\u5f26\u76f8\u4f3c\u5ea6\uff0c\u5229\u7528\u4f59\u5f26\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u5143\u7d20\u76f8\u4f3c\u6027\u7684\u516c\u5f0f\u4e3a\uff1a $$ \\sigma(F_t)^{(h,w)}_k=\\frac{F_t^{(h,w)}(\\hat{F}^{k(h,w)}_t)^T}{||F^{(h,w)}_t||_2||\\hat{F}_t^{k(h,w)}||_2} $$  \u5176\u4e2d\uff0c\\sigma(F_t)^{(h,w)}_k\u8868\u793a\\sigma(F_t)_k\u4e2d\u4f4d\u7f6e\u4e3a(h,w)\u7684\u5143\u7d20\uff0cF_t^{(h,w)}\u4e0e\\hat{F}^{k(h,w)}_t\u5c3a\u5bf8\u5747\u4e3a1\\times C\uff0c\u5982\u679c\u4e24\u4e2a\u7279\u5f81\u5411\u91cf\u8d8a\u76f8\u4f3c\uff0c\u5219\u8be5\u4f4d\u7f6e\u4e0a\u7684\u5143\u7d20\u8d8a\u63a5\u8fd1\u4e8e1\uff0c\u5219\u8868\u793a\u539f\u7279\u5f81\u56fe\u4e2d\uff0c\u8be5\u4f4d\u7f6e\u4e0a\u7684\u7269\u4f53\u8d8a\u63a5\u8fd1k\u7c7b\u3002</p> <p>\u53ef\u5b66\u4e60\u7684\u76f8\u4f3c\u6027</p> <p>\u2003\u2003\u5f53\u4f7f\u7528\u4f59\u5f26\u76f8\u4f3c\u6027\u53bb\u8ba1\u7b97\u6ce8\u610f\u529b\u56fe\u65f6\uff0c\u6a21\u578b\u6027\u80fd\u6709\u4e86\u5408\u7406\u5730\u63d0\u9ad8\uff0c\u4f46\u751f\u6210\u7684\u6ce8\u610f\u529b\u56fe\u5e76\u4e0d\u51c6\u786e(\u5177\u4f53\u53ef\u89c1\u53ef\u89c6\u5316\u5206\u6790)\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4f5c\u8005\u8bbe\u8ba1\u4e86\u4e00\u79cd\u57fa\u4e8e\u5ea6\u91cf\u5b66\u4e60\u7684\u76f8\u4f3c\u6027\u8ba1\u7b97\u65b9\u6cd5\uff0c\u5728\u8ba1\u7b97\u76f8\u4f3c\u6027\u4e4b\u524d\uff0c\u5f15\u5165\u4e86\u4e00\u7ec4\u53ef\u5b66\u4e60\u7684\u53c2\u6570\uff0c\u5373\u6dfb\u52a0\u4e86\u4e00\u7ec4\u5377\u79ef\u5c42\u3002F_t\u548c\\hat{F}^k_t\u9996\u5148\u4f9d\u6b21\u7ecf\u8fc7\u7f51\u7edc\\Theta_t\u548c\\Theta^k_t\uff0c\u5229\u7528\u6e90\u6570\u636e\u96c6\u4e2d\u7684\u8fb9\u754c\u6846\u6765\u76d1\u63a7\u7f51\u7edc\uff0c\u5177\u4f53\u6765\u8bf4\uff0c\u5bf9\u4e8e\u7c7b\u522bk\u6240\u5728\u7684\u4f4d\u7f6e\uff0c\u6700\u5927\u5316\\Theta_t(F_t)^{(h,w)}\u548c\\Theta^k_t(\\hat{F}^k_t)^{(h,w)}\u4e4b\u95f4\u7684\u4f59\u5f26\u76f8\u4f3c\u6027\uff0c\u4ee5\u53ca\u6700\u5c0f\u5316\u4e0d\u76f8\u5173\u7c7b\u522b\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\uff0c\u8fd9\u91cc\u4f5c\u8005\u5728\u8bba\u6587\u4e2d\u5c11\u52a0\u4e86\u4e00\u4e2a\u635f\u5931(\u5177\u4f53\u89c1\u95ee\u9898\u8bb0\u5f55)\uff0c\u5e94\u8be5\u518d\u52a0\u4e00\u4e2a\uff1a $$ \\begin{aligned} \\mathcal L_{sim}^k=&amp;\\mu\u00b7\\sum_{k'\\neq k,k'\\in K} Sim(\\Theta_t(F_{s_k}),\\Theta^{k'}_t(\\hat{F}^{k'}_{s_k}))- \\\\&amp;Sim(\\Theta_t(F_{s_k}),\\Theta^k_t(\\hat{F}^k_{s_k})) \\end{aligned} $$  \u5176\u4e2d\uff0c\\mu\u8868\u793a\u63a7\u5236\u4e0d\u76f8\u5173\u7c7b\u522b\u635f\u5931\u548c\u76f8\u5173\u7c7b\u522b\u635f\u5931\u4e4b\u95f4\u76f8\u5bf9\u91cd\u8981\u6027\u7684\u6743\u91cd\uff0c\\mathcal L_{sim}^k\u8868\u793a\u7b2ck\u7c7b\u6a21\u5757\u7684\u76f8\u4f3c\u6027\u635f\u5931\uff0cF_{s_k}\u8868\u793a\u6e90\u57df\u6570\u636e\u4e2d\uff0c\u7b2ck\u7c7b\u7269\u4f53\u7684\u7279\u5f81\uff0c\u53ef\u4ee5\u5229\u7528\u6807\u7b7e\u8fb9\u754c\u6846\u5bf9\u539f\u7279\u5f81\u8fdb\u884c\u88c1\u526a\u5f97\u5230\uff0c\\hat{F}^{k'}_{s_k}\u8868\u793a\u7279\u5f81F_{s_k}\u67e5\u8be2\u7b2ck'\u7c7b\u7684\u8bb0\u5fc6\u6a21\u5757\u5f97\u5230\u7684\u68c0\u7d22\u7279\u5f81\uff0c\\Theta^{k'}_t(\u00b7)\u8868\u793a\u7b2ck'\u7c7b\u8bb0\u5fc6\u6a21\u5757\u540e\u7684\u5377\u79ef\u5c42\u3002\u540c\u4e00\u4e2a\u7279\u5f81\u8fdb\u5165\u4e0d\u540c\u8bb0\u5fc6\u6a21\u5757\u5f97\u5230\u4e0d\u540c\u7684\u68c0\u7d22\u7279\u5f81\uff0c\u5728\u5df2\u77e5\u8be5\u7279\u5f81\u5c5e\u4e8e\u7c7b\u522bk\u7684\u60c5\u51b5\u4e0b\uff0c\u8fdb\u5165k\u7c7b\u8bb0\u5fc6\u6a21\u5757\u5f97\u5230\u7684\u68c0\u7d22\u7279\u5f81\u5e94\u8be5\u4e0e\u539f\u7279\u5f81\u76f8\u4f3c\u5ea6\u9ad8\uff0c\u8fdb\u5165k'\u7c7b\u8bb0\u5fc6\u6a21\u5757\u5f97\u5230\u7684\u68c0\u7d22\u7279\u5f81\u5e94\u8be5\u4e0e\u539f\u7279\u5f81\u76f8\u4f3c\u5ea6\u4f4e</p> <p>\u4f5c\u8005\u5e76\u6ca1\u6709\u76f4\u63a5\u56de\u590d\u8be5\u635f\u5931\u662f\u600e\u4e48\u6784\u5efa\u7684\uff0c\u56e0\u6b64\u4e0a\u9762\u7684\u516c\u5f0f\u662f\u6211\u81ea\u5df1\u6839\u636e\u8bba\u6587\u7406\u89e3\u6784\u9020\u7684\uff0c\u6027\u80fd\u8fd8\u6ca1\u7ecf\u8fc7\u9a8c\u8bc1\uff0c\u5982\u679c\u6709\u4e0d\u5bf9\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u6307\u6b63</p> <p>\u2003\u2003\u8be5\u6a21\u5757\u6574\u4f53\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u6ce8\u610f\u529b\u56fe\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ \\sigma(F_t)_k=Sim(\\Theta_t(F_t),\\Theta_t^k(\\hat{F}_t^k)) $$  \u5176\u4e2d\uff0cSim(x,y)\u8868\u793ax\u548cy\u4e4b\u95f4\u7684\u4f59\u5f26\u76f8\u4f3c\u6027\uff0c\u5f97\u5230\u7684\u6ce8\u610f\u529b\u56fe\\sigma(\u00b7)_k\u5c3a\u5bf8\u4e3aH\\times W\u3002\u5bf9\u4e8e\u6240\u6709\u7684\u7c7b\u522bK\uff0c\u5747\u8ba1\u7b97\u6e90\u57df\u56fe\u50cf\u548c\u76ee\u6807\u57df\u56fe\u50cf\u7684\u6ce8\u610f\u529b\uff0c\u518d\u5c06\u6ce8\u610f\u529b\u4f20\u5230\u540e\u9762\u7684\u7c7b\u5224\u522b\u5668\u4e4b\u524d\uff0c\u5229\u7528\u9608\u503c\u5c06\u5176\u4e8c\u503c\u5316(\u9608\u503c\u53ef\u8bbe\u4e3a0.5)\uff0c\u5f52\u4e00\u5316\u76f8\u4f3c\u5ea6\u5927\u4e8e0.5\u7684\u4f4d\u7f6e\u5206\u914d1\uff0c\u5176\u4f59\u5206\u914d0\u3002</p> <p>\u601d\u8def\u603b\u7ed3\uff1a</p> <ul> <li>\u4f5c\u8005\u8bbe\u8ba1\u4e86K\u4e2a\u7c7b\u5224\u522b\u5668\uff0c\u7528\u4e8e\u5bf9\u9f50K\u4e2a\u7c7b\u522b\u7684\u7279\u5f81\uff0c\u4e3b\u8981\u7684\u95ee\u9898\u5c31\u5728\u4e8e\u539f\u56fe\u4e0a\u6709\u53ef\u80fd\u6709\u591a\u4e2a\u7269\u4f53\uff0c\u56e0\u6b64\u6709\u53ef\u80fd\u6709\u591a\u79cd\u7c7b\u522b\u7684\u7279\u5f81\uff0c\u800c\u4e14\u76ee\u6807\u57df\u56fe\u50cf\u7f3a\u5c11\u8fb9\u754c\u6846\u6807\u7b7e\uff0c\u56e0\u6b64\u65e0\u6cd5\u76f4\u63a5\u5f97\u5230\u5355\u4e2a\u7c7b\u522b\u7684\u7279\u5f81\uff0c\u5f97\u4e0d\u5230\u7c7b\u522b\u7279\u5f81\u5c31\u6ca1\u6cd5\u8fdb\u884c\u5bf9\u9f50\u3002</li> <li>\u56e0\u6b64\u4f5c\u8005\u5f15\u5165\u4e86\u6ce8\u610f\u529b\u673a\u5236\u7684\u6982\u5ff5\uff0c\u901a\u8fc7\u7c7b\u522b\u7279\u5b9a\u7684\u6ce8\u610f\u529b\u56fe\u6765\u51f8\u663e\u539f\u56fe\u4e0a\u8be5\u7c7b\u7684\u7279\u5f81\uff0c\u5373\u7b2c\u4e8c\u4e2a\u516c\u5f0f\u4e2d\u6ce8\u610f\u529b\u56fe\u4e0e\u539f\u7279\u5f81\u505a\u70b9\u4e58\u7684\u64cd\u4f5c\uff0c\u73b0\u5728\u7684\u76ee\u6807\u5c31\u8f6c\u5411\u4e86\u751f\u6210K\u5f20\u6ce8\u610f\u529b\u56fe\u3002</li> <li>\u5bf9\u6b64\uff0c\u4f5c\u8005\u5f15\u5165\u4e86\u8bb0\u5fc6\u6a21\u5757\u7684\u6982\u5ff5\uff0c\u5229\u7528\u8bb0\u5fc6\u6a21\u5757\u5b58\u50a8\u6bcf\u4e00\u7c7b\u72ec\u7279\u7684\u7279\u5f81\uff0c\u5c06\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\u5f97\u5230\u7684\u7279\u5f81\u4e0e\u8bb0\u5fc6\u6a21\u5757\u5b58\u50a8\u7684\u7279\u5f81\u505a\u5339\u914d(\u68c0\u7d22)\uff0c\u6765\u751f\u6210\u7279\u5b9a\u7c7b\u522b\u7684\u6ce8\u610f\u529b\u56fe\u3002\u56e0\u6b64\u4e00\u5171\u6784\u5efa\u4e86K\u4e2a\u8bb0\u5fc6\u6a21\u5757\uff0c\u5206\u522b\u5bf9\u5e94K\u4e2a\u7c7b\u522b\uff0c\u6bcf\u4e2a\u8bb0\u5fc6\u6a21\u5757\u4e2d\u6709N_m\u4e2a\u8bb0\u5fc6\u5355\u5143\uff0c\u800c\u6bcf\u4e2a\u8bb0\u5fc6\u5355\u5143\u7684\u5c3a\u5bf8\u5747\u4e3a1\\times C\uff0c\u4e0e\u7279\u5f81g_{s_k}^i\u76f8\u5bf9\u5e94\u3002</li> <li>\u5c06\u63d0\u53d6\u5230\u7684\u7279\u5f81F_t\u4f20\u5165\u8bb0\u5fc6\u6a21\u5757\uff0c\u6309\u4f4d\u7f6e\u5207\u5206\uff0c\u5373\u5f97\u5230\u50cf\u7d20\u7ea7\u522b\u7684\u7279\u5f81\uff0c\u4e00\u5171\u5f97\u5230W\\times H\u4e2a\u5c3a\u5bf8\u4e3a1\\times C\u7684\u7279\u5f81\u5411\u91cf\uff0c\u4e4b\u540e\u518d\u5c06\u5b83\u4eec\u6309\u6240\u5c5e\u7684\u7c7b\u522b\u8fdb\u884c\u5206\u7c7b\uff0c\u5212\u5206\u6210K\u4efd(\u7531\u4e8e\u4e00\u5f20\u56fe\u4e2d\u53ef\u80fd\u7269\u4f53\u79cd\u7c7b\u4e0d\u5168\uff0c\u56e0\u6b64\u6709\u7684\u53ef\u80fd\u662f\u7a7a\u96c6)\uff0c\u8fd9\u91cc\u5c31\u5bf9\u5e94G_k\uff0c\u800cg_{s_k}^i\u5c31\u5bf9\u5e94\u521a\u624d\u63d0\u5230\u5c3a\u5bf8\u4e3a1\\times C\u7684\u7279\u5f81\u5411\u91cf\u3002</li> <li> <p>\u5206\u597d\u7279\u5f81\u96c6\u5408\u4e4b\u540e\uff0c\u518d\u4f9d\u6b21\u8fdb\u884c\u5199\u5165\u3001\u8bfb\u53d6\u64cd\u4f5c(\u6ce8\u610f\uff0c\u8fd9\u91cc\u4e5f\u662f\u6309\u5355\u4e2a\u7279\u5f81\u5411\u91cf\u8fdb\u884c\u5199\u5165\u3001\u8bfb\u53d6\u64cd\u4f5c)\uff0c\u5199\u64cd\u4f5c\u53ea\u9762\u5411\u6e90\u57df\u6570\u636e\uff0c\u8bfb\u64cd\u4f5c\u540c\u65f6\u9762\u5411\u4e24\u4e2a\u9886\u57df\u7684\u6570\u636e\u3002\u4e24\u4e2a\u64cd\u4f5c\u7684\u6838\u5fc3\u5c31\u662f\u6c42\u76f8\u4f3c\u5ea6\u77e9\u9635\uff0c\u5199\u64cd\u4f5c\u6c42\u7684\u662f\u7279\u5f81\u6761g^i_{s_k}\u7684\u6743\u91cd\uff0c\u7528\u4e8e\u66f4\u65b0\u8bb0\u5fc6\u5355\u5143m^j\uff0c\u56e0\u6b64\u4ee5\u96c6\u5408G_k\u4e3a\u6574\u4f53\uff0c\u76f8\u4f3c\u5ea6\u77e9\u9635p\u662f\u6309G_k\u5f52\u4e00\u5316\uff0c\u5bf9\u5e94\u5206\u6bcdl\\in G_k\uff1b\u800c\u8bfb\u64cd\u4f5c\u6c42\u7684\u662f\u8bb0\u5fc6\u5355\u5143m^j\u7684\u6743\u91cd\uff0c\u7528\u4e8e\u6c42\u68c0\u7d22\u7279\u5f81\u5411\u91cf\\hat{g}^t_{s_k}\uff0c\u56e0\u6b64\u4ee5\u8bb0\u5fc6\u5355\u5143m^j\u7684\u96c6\u5408M_k\u4e3a\u6574\u4f53\uff0c\u76f8\u4f3c\u5ea6\u77e9\u9635q\u6309M_k\u8fdb\u884c\u5f52\u4e00\u5316\uff0c\u5bf9\u5e94\u5206\u6bcdl\\in N_m\u3002</p> </li> <li> <p>\u8bfb\u5199\u64cd\u4f5c\u5f88\u597d\u5730\u5b8c\u6210\u4e86\u8bb0\u5fc6\u6a21\u5757\u7684\u66f4\u65b0\u548c\u5e94\u7528\u4e24\u4e2a\u529f\u80fd\uff0c\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\uff0c\u5c06\u5f97\u5230\u7684\u7279\u5f81\u8fdb\u884c\u68c0\u7d22\uff08\u4e5f\u5c31\u662f\u201d\u8bfb\u201d\u64cd\u4f5c\uff09\uff0c\u6700\u540e\u6839\u636e\u68c0\u7d22\u7ed3\u679c\u751f\u6210\u6ce8\u610f\u529b\u56fe\uff0c\u6b64\u65f6\u4e00\u5171\u751f\u6210K\u5f20\uff0c\u6700\u540e\u8be5\u6ce8\u610f\u529b\u56fe\u518d\u4e0e\u539f\u7279\u5f81\u505a\u70b9\u4e58\uff0c\u51f8\u663e\u51fa\u539f\u7279\u5f81\u5c5e\u4e8e\u8be5\u7c7b\u522b\u7684\u533a\u57df\u7279\u5f81\uff0c\u6700\u540e\u518d\u4f9d\u6b21\u5bf9\u9f50\u7ecf\u8fc7\u6ce8\u610f\u529b\u56fe\u5904\u7406\u540e\u7684\u7279\u5f81(\u4e00\u5171\u5bf9\u9f50K\u6b21\uff0c\u5bf9\u5e94K\u7c7b)\uff0c\u5b8c\u6210\u7c7b\u522b\u76f8\u5173\u7684\u5bf9\u9f50\u529f\u80fd\u3002</p> </li> </ul> <p>\u6ce8\u610f\uff1a\u56e0\u4e3a\u6700\u540e\u7684\u7279\u5f81\u5bf9\u9f50\u662f\u6309\u50cf\u7d20\u70b9\u6765\u5bf9\u9f50\u7684\uff08\u7279\u5f81\u56fe\u4e0a\u6bcf\u4e2a\u4f4d\u7f6e\u5747\u4ea7\u751f\u4e00\u4e2a\u9886\u57df\u7f6e\u4fe1\u5ea6\uff0c\u6240\u6709\u4f4d\u7f6e\u90fd\u4f1a\u4f9d\u6b21\u4ea7\u751f\u4e00\u4e2a\u635f\u5931\uff0c\u6700\u540e\u635f\u5931\u518d\u6c42\u5747\u503c\uff0c\u8fd9\u91cc\u53c8\u79f0\u4e3a\u50cf\u7d20\u7ea7\u522b\u7684\u5bf9\u9f50\uff09\uff0c\u6240\u4ee5\u8fd9\u91cc\u6c42\u6ce8\u610f\u529b\u56fe\u65f6\u4e5f\u662f\u6309\u50cf\u7d20\u70b9\u6765\u6c42\u7684\uff0c\u56e0\u6b64\u4e00\u5f00\u59cb\u8981\u5c06\u539f\u59cb\u7279\u5f81\u5207\u6210W\\times H\u4e2a\u5c0f\u77e9\u5f62\u5757\uff0c\u4e00\u5757\u4e00\u5757\u5730\u6c42\uff0c\u6700\u540e\u518d\u62fc\u63a5\u8d77\u6765\u3002</p> <p>\u4e2a\u4eba\u89c2\u70b9\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u6307\u6b63</p>"},{"location":"domain_adaptive/paper/MeGA-CDA1/#mega-cda_1","title":"MeGA-CDA\u603b\u635f\u5931","text":"<p>\u2003\u2003\u5728\u6a21\u578b\u7684\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u8fd8\u5728\u6e90\u57df\u6570\u636e\u4e0a\u6dfb\u52a0\u4e86\u68c0\u6d4b\u635f\u5931\\mathcal L_{det}\uff0c\u5305\u62ec\u8fb9\u754c\u6846\u56de\u5f52\u635f\u5931\u548c\u7269\u4f53\u7c7b\u522b\u635f\u5931\uff0c\u7efc\u4e0a\u6240\u8ff0\uff0c\u6a21\u578b\u7684\u603b\u635f\u5931\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ \\begin{aligned} \\mathcal L_{cda}^{mega}=&amp;\\mathcal L_{det}(X_s,b_s,y_s)+\\beta\\mathcal L_{gda}(X_s,X_t)+\\\\&amp;\\gamma\\sum^K_{k=1}\\mathcal L_{cda}^k(X_s,X_t)+\\lambda\\mathcal L_{mem}+\\eta\\sum_{k=1}^K\\mathcal L_{sim}^k \\end{aligned} $$  \u5176\u4e2d\uff0c\\beta,\\gamma\u3001\\lambda\u4ee5\u53ca\\mu\u5206\u522b\u8868\u793a\u56db\u4e2a\u7ec4\u4ef6\u7684\u635f\u5931\u6743\u91cd\uff0c\u5373\u5168\u5c40\u5224\u522b\u5668\u3001\u7c7b\u5224\u522b\u5668\u3001\u8bb0\u5fc6\u6a21\u5757\u4ee5\u53ca\u76f8\u4f3c\u6027\u8ba1\u7b97\u6a21\u5757\u3002</p>"},{"location":"domain_adaptive/paper/MeGA-CDA1/#_10","title":"\u5b9e\u9a8c","text":""},{"location":"domain_adaptive/paper/MeGA-CDA1/#_11","title":"\u53ef\u89c6\u5316\u5206\u6790","text":"<p>\u2003\u2003\u4e3a\u4e86\u5bf9\u6bd4\u4f7f\u7528\u4f59\u5f26\u76f8\u4f3c\u6027\u548c\u57fa\u4e8e\u5ea6\u91cf\u5b66\u4e60\u7684\u76f8\u4f3c\u6027\u6240\u4ea7\u751f\u7684\u6548\u679c\uff0c\u4f5c\u8005\u5c06\u4e8c\u8005\u5f97\u5230\u7684\u6ce8\u610f\u529b\u56fe\u505a\u4e86\u53ef\u89c6\u5316\uff0c\u5177\u4f53\u5bf9\u6bd4\u6548\u679c\u53ef\u89c1\u4e0b\u56fe\uff1a</p> <p> <p></p> <p></p> <p>\u4e0a\u56fe\u7b2c\u4e00\u884c\u4e3a\u5229\u7528\u4f59\u5f26\u76f8\u4f3c\u6027\u8ba1\u7b97\u5f97\u5230\u7684\u6ce8\u610f\u529b\u56fe\uff0c\u7b2c\u4e8c\u884c\u4e3a\u5229\u7528\u57fa\u4e8e\u5ea6\u91cf\u5b66\u4e60\u7684\u76f8\u4f3c\u6027\u8ba1\u7b97\u5f97\u5230\u7684\u6ce8\u610f\u529b\u56fe\u3002\u4ece\u56fe\u4e2d\u53ef\u4ee5\u53d1\u73b0\uff0c\u57fa\u4e8e\u4f59\u5f26\u76f8\u4f3c\u6027\u7684\u6ce8\u610f\u529b\u5bf9\u6c7d\u8f66\u6240\u5728\u7684\u4f4d\u7f6e\u63d0\u4f9b\u4e86\u5408\u7406\u7684\u5173\u6ce8\uff0c\u4f46\u662f\u5173\u6ce8\u529b\u5ea6\u4e0d\u591f\u5f3a\u3001\u5e76\u4e14\u5173\u6ce8\u70b9\u4e5f\u6bd4\u8f83\u5206\u6563\uff0c\u800c\u57fa\u4e8e\u5ea6\u91cf\u5b66\u4e60\u7684\u65b9\u6cd5\u5173\u6ce8\u6548\u679c\u66f4\u4e3a\u7406\u60f3\uff0c\u5e76\u4e14\u5173\u6ce8\u70b9\u4e5f\u8f83\u4e3a\u96c6\u4e2d\u3002</p>"},{"location":"domain_adaptive/paper/MeGA-CDA1/#map","title":"mAP\u5bf9\u6bd4","text":"<p>Cityscape \\rightarrow FoggyCityscape</p> <p> <p></p> <p></p>"},{"location":"domain_adaptive/paper/MeGA-CDA1/#_12","title":"\u603b\u7ed3","text":"<p>\u2003\u2003\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u7684\u7c7b\u522b\u7279\u5f81\u5bf9\u9f50\u65b9\u6cd5\uff0c\u5177\u4f53\u5730\u6765\u8bf4\uff0c\u901a\u8fc7\u6784\u5efa\u7c7b\u5224\u522b\u5668\u6765\u5c06\u7c7b\u522b\u4fe1\u606f\u7eb3\u5165\u9886\u57df\u5bf9\u9f50\u7684\u8fc7\u7a0b\u4e2d\u3002\u4e3a\u4e86\u514b\u670d\u7f3a\u4e4f\u76ee\u6807\u57df\u7c7b\u522b\u7279\u5f81\u6240\u4ea7\u751f\u7684\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u7531\u8bb0\u5fc6\u5f15\u5bfc\u7684\u6ce8\u610f\u529b\u673a\u5236\uff0c\u8be5\u673a\u5236\u53ef\u4ee5\u751f\u6210\u7c7b\u522b\u7279\u5b9a\u7684\u6ce8\u610f\u529b\u56fe\u6765\u5c06\u4e3b\u5e72\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u5f97\u5230\u7684\u7279\u5f81\u5206\u914d\u5230\u4e0d\u540c\u7684\u7c7b\u5224\u522b\u5668\u4e2d\u3002\u901a\u8fc7\u5bf9\u9f50\u7c7b\u522b\u7279\u5f81\uff0c\u53ef\u4ee5\u51cf\u8f7b\u7531\u5168\u5c40\u7279\u5f81\u5bf9\u9f50\u5f15\u8d77\u7684\u9886\u57df\u8d1f\u8fc1\u79fb\u95ee\u9898\uff0c\u8fdb\u4e00\u6b65\u63d0\u5347\u6a21\u578b\u7684\u9886\u57df\u9002\u5e94\u80fd\u529b\u3002</p> <p>\u6ce8\uff1a\u4ee5\u4e0a\u7406\u89e3\u4ee5\u53ca\u5bf9\u539f\u6587\u7684\u4fee\u6539\u4ec5\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u5927\u5bb6\u6279\u8bc4\u6307\u6b63</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e742\u670810\u65e5</p>"},{"location":"domain_adaptive/paper/Strong-Weak1/","title":"\u57df\u9002\u5e94\uff1aStrong-Weak","text":""},{"location":"domain_adaptive/paper/Strong-Weak1/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aIEEE Conference on Computer Vision and Pattern Recognition 2019 (CVPR, 2019)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttp://openaccess.thecvf.com/content_CVPR_2019/papers/Saito_Strong-Weak_Distribution_Alignment_for_Adaptive_Object_Detection_CVPR_2019_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/VisionLearningGroup/DA_Detection</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b</p>"},{"location":"domain_adaptive/paper/Strong-Weak1/#_2","title":"\u4e3b\u8981\u601d\u60f3","text":"<p>\u2003\u2003\u5229\u7528\u5bf9\u6297\u6027\u5b66\u4e60\u6765\u8c03\u6574\u6e90\u57df\u6570\u636e\u5206\u5e03\u548c\u76ee\u6807\u57df\u6570\u636e\u5206\u5e03\u662f\u5e38\u7528\u7684\u57df\u9002\u5e94\u7b97\u6cd5\uff0c\u901a\u8fc7\u5c06\u6cdb\u5316\u8bef\u5dee\u9650\u5236\u5728\u57df\u95f4\u7684\u5dee\u5f02\u5185\uff0c\u53ef\u4ee5\u5f88\u597d\u5730\u8ba9\u6a21\u578b\u9002\u5e94\u8f93\u5165\u56fe\u50cf\u9886\u57df\u7684\u53d8\u5316\u3002\u4f20\u7edf\u7684\u89c2\u70b9\u8ba4\u4e3a\u5fc5\u987b\u5c3d\u53ef\u80fd\u5730\u51cf\u5c11\u57df\u95f4\u5dee\u5f02\uff0c\u4f46\u6267\u884c\u65e0\u5dee\u522b\u7684\u5bf9\u9f50\u6709\u53ef\u80fd\u4f1a\u635f\u5bb3\u6a21\u578b\u7684\u68c0\u6d4b\u6027\u80fd\u3002\u5728\u76ee\u6807\u68c0\u6d4b\u4e2d\uff0c\u5bf9\u9f50\u5168\u5c40\u7279\u5f81\u610f\u5473\u7740\u4e0d\u4ec5\u5bf9\u8c61\u7c7b\u522b\u9700\u8981\u76f8\u4f3c\uff0c\u800c\u4e14\u80cc\u666f\u4fe1\u606f\u3001\u573a\u666f\u5206\u5e03\u4e5f\u5fc5\u987b\u8de8\u57df\u76f8\u4f3c\u3002\u8fd9\u79cd\u65b9\u6cd5\u5bf9\u4e8e\u4ec5\u5f71\u54cd\u5bf9\u8c61\u5916\u89c2\u7684\u5c0f\u533a\u57df\u504f\u79fb\u4e5f\u8bb8\u9002\u7528\uff0c\u5982\u5929\u6c14\u76f8\u5173\u7684\u9886\u57df\u504f\u79fb\uff0c\u4f46\u9762\u5bf9\u6bd4\u8f83\u5927\u7684\u9886\u57df\u504f\u79fb\uff0c\u5982\u573a\u666f\u5206\u5e03\u7684\u4e0d\u540c\u3001\u7269\u4f53\u6570\u91cf\u7684\u4e0d\u540c\u7b49\uff0c\u5982\u679c\u5f3a\u5236\u5bf9\u9f50\u8fd9\u4e9b\u7279\u5f81\u6570\u636e\uff0c\u4f1a\u635f\u5bb3\u6a21\u578b\u7684\u68c0\u6d4b\u6027\u80fd\u3002\u53e6\u4e00\u65b9\u9762\uff0c\u4f5c\u8005\u8fd8\u53d1\u73b0\u7531\u4e8e\u56fe\u50cf\u7684\u5c40\u90e8\u7279\u5f81(\u4ece\u6d45\u5c42\u7f51\u7edc\u4e2d\u63d0\u53d6\u7684\u7279\u5f81)\u4e2d\u4ec5\u5305\u542b\u8f83\u5c0f\u611f\u53d7\u91ce\u7684\u56fe\u50cf\u4fe1\u606f(\u5982\u5c40\u90e8\u7684\u989c\u8272\u3001\u7eb9\u7406\u7279\u5f81)\uff0c\u56e0\u6b64\u5bf9\u5c40\u90e8\u7279\u5f81\u6267\u884c\u5f3a\u5bf9\u9f50\u6709\u5229\u4e8e\u7f29\u5c0f\u57df\u95f4\u7684\u5dee\u5f02\uff0c\u5e76\u4e14\u4e0d\u4f1a\u635f\u5bb3\u6a21\u578b\u7684\u6027\u80fd\u3002</p> <p>\u2003\u2003\u672c\u6587\u4e2d\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u7684\u65e0\u76d1\u7763\u9002\u5e94\u65b9\u6cd5\uff0c\u5c06\u5f31\u5168\u5c40\u5bf9\u9f50\u548c\u5f3a\u5c40\u90e8\u5bf9\u9f50\u7ed3\u5408\u7684\u5f3a\u5f31\u57df\u5bf9\u9f50\u6a21\u5757(Strong-Weak Domain Alignment)\u3002\u4f5c\u8005\u5728\u5168\u5c40\u7279\u5f81\u4e0a\u5e94\u7528\u5f31\u5bf9\u9f50\uff0c\u6267\u884c\u90e8\u5206\u5bf9\u9f50\u4ee5\u51cf\u5c11\u9886\u57df\u5dee\u5f02\uff0c\u540c\u65f6\u4e0d\u635f\u5bb3\u6a21\u578b\u6027\u80fd\u3002\u5982\u4e0b\u56fe\u4e2d\u6240\u793a\u3002\u4f5c\u8005\u7684\u4e3b\u8981\u8d21\u732e\u5c31\u662f\u8bbe\u8ba1\u4e86\u5f31\u5168\u5c40\u5bf9\u9f50\u6a21\u5757\uff0c\u5c06\u5bf9\u6297\u635f\u5931\u96c6\u4e2d\u4e8e\u5168\u5c40\u76f8\u4f3c\u7684\u56fe\u50cf\u4e0a\uff0c\u540c\u65f6\u8fdc\u79bb\u5168\u5c40\u4e0d\u76f8\u4f3c\u7684\u56fe\u50cf\u3002\u6b64\u5916\uff0c\u4f5c\u8005\u8fd8\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u57df\u5206\u7c7b\u5668\u6765\u6267\u884c\u5f3a\u5c40\u90e8\u5bf9\u9f50\uff0c\u4f7f\u5f97\u4e24\u4e2a\u57df\u4e4b\u95f4\u7684\u5c40\u90e8\u7279\u5f81\u5b9e\u73b0\u4e25\u683c\u7684\u5f3a\u5bf9\u9f50\u3002</p> <p> <p></p> <p></p>"},{"location":"domain_adaptive/paper/Strong-Weak1/#_3","title":"\u65b9\u6cd5","text":""},{"location":"domain_adaptive/paper/Strong-Weak1/#_4","title":"\u7f51\u7edc\u7ed3\u6784","text":"<p>\u2003\u2003\u7b97\u6cd5\u7684\u7f51\u7edc\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u9996\u5148\u5728\u6d45\u5c42\u5377\u79ef\u5c42\u63d0\u53d6\u5c40\u90e8\u7279\u5f81\u4ee5\u53caRPN\u4e4b\u524d\u63d0\u53d6\u5168\u5c40\u7279\u5f81\uff0c\u5e76\u4e14\u5728\u4f4e\u6c34\u5e73\u7279\u5f81\u7a7a\u95f4\u4e0a\u6267\u884c\u5f3a\u5c40\u90e8\u5bf9\u9f50\uff0c\u5728\u9ad8\u6c34\u5e73\u7279\u5f81\u7a7a\u95f4\u4e0a\u6267\u884c\u5f31\u5168\u5c40\u5bf9\u9f50\uff0c\u6700\u540e\u8fdb\u4e00\u6b65\u5c06\u4e0a\u4e0b\u6587\u5411\u91cf\u4e0e\u7279\u5f81\u533a\u57df\u62fc\u63a5\uff0c\u6765\u63d0\u9ad8\u6a21\u578b\u7684\u68c0\u6d4b\u6027\u80fd\u3002</p> <p> <p></p> <p></p>"},{"location":"domain_adaptive/paper/Strong-Weak1/#_5","title":"\u5f31\u5168\u5c40\u7279\u5f81\u5bf9\u9f50","text":"<p>\u2003\u2003\u4f5c\u8005\u5229\u7528\u9886\u57df\u5206\u7c7b\u5668\u5c06\u76ee\u6807\u57df\u7279\u5f81\u4e0e\u6e90\u57df\u7279\u5f81\u5b9e\u73b0\u5bf9\u9f50\uff0c\u4ee5\u5b9e\u73b0\u5168\u5c40\u6c34\u5e73\u7684\u7279\u5f81\u5bf9\u9f50\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u5bb9\u6613\u5206\u7c7b\u7684\u76ee\u6807\u57df\u6837\u672c\u7279\u5f81\u5c06\u8fdc\u79bb\u7279\u5f81\u7a7a\u95f4\u4e2d\u7684\u6e90\u57df\u6837\u672c\u7279\u5f81\uff0c\u4e0d\u5bb9\u6613\u5206\u7c7b\u7684\u76ee\u6807\u57df\u6837\u672c\u7279\u5f81\u5c06\u9760\u8fd1\u6e90\u57df\u6837\u672c\u7279\u5f81\u3002\u56e0\u6b64\uff0c\u5728\u57df\u5206\u7c7b\u5668\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u5e94\u8be5\u5ffd\u7565\u5bb9\u6613\u5206\u7c7b\u7684\u6837\u672c\uff0c\u5373\u5ffd\u7565\u90a3\u4e9b\u5bb9\u6613\u5224\u65ad\u9886\u57df\u6807\u7b7e\u7684\u6837\u672c\uff0c\u5c06\u5173\u6ce8\u91cd\u70b9\u653e\u5728\u57df\u5206\u7c7b\u5668\u96be\u4ee5\u5206\u7c7b\u7684\u6837\u672c\u4e0a\uff0c\u5373\u63d0\u9ad8\u96be\u5206\u7c7b\u6837\u672c\u7684\u5168\u5c40\u5bf9\u6297\u635f\u5931\u7684\u6743\u91cd\u3002</p> <p> <p></p> <p></p> <p>\u2003\u2003\u5047\u8bbe\u6e90\u57df\u56fe\u7247\u4e3ax^{s}\uff0c\u5bf9\u5e94\u7684\u6807\u7b7e\u4e3ay_i^s\uff0c\u76ee\u6807\u57df\u56fe\u7247\u4e3ax^t\uff0c\u76ee\u6807\u57df\u56fe\u7247\u6ca1\u6709\u989d\u5916\u7684\u6807\u7b7e\u3002\u5168\u5c40\u7279\u5f81\u5411\u91cf\u7531F\u63d0\u53d6\uff0c\u57df\u5206\u7c7b\u5668D_g\u7528\u4e8e\u9884\u6d4b\u5168\u5c40\u7279\u5f81\u7684\u9886\u57df\u6807\u7b7e(\u5373\u9884\u6d4b\u8be5\u7279\u5f81\u5c5e\u4e8e\u54ea\u4e2a\u9886\u57df)\u3002\u4f5c\u8005\u901a\u8fc7\u4f18\u5316F\u6765\u4f7f\u7279\u5f81\u5bf9\u4e8e\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u662f\u6709\u533a\u5206\u5ea6\u7684\uff0c\u800c\u5bf9\u4e8e\u57df\u5206\u7c7b\u5668\u4efb\u52a1\u662f\u65e0\u4fe1\u606f\u7684(uninformative)\uff0c\u5373\u901a\u8fc7\u4f18\u5316F\u6765\u963b\u788d\u57df\u5206\u7c7b\u5668\u7684\u6267\u884c\u3002\u5bf9\u4e8e\u6e90\u57df\u6570\u636e\uff0c\u9886\u57df\u6807\u7b7ed\u4e3a1\uff0c\u5bf9\u4e8e\u76ee\u6807\u57df\u6570\u636e\uff0c\u9886\u57df\u6807\u7b7ed\u4e3a0\u3002\u7f51\u7edcR\u8f93\u5165\u4eceF\u63d0\u53d6\u7684\u7279\u5f81\uff0c\u8f93\u51fa\u8fb9\u754c\u6846\u4fe1\u606f\u4ee5\u53ca\u7c7b\u522b\u4fe1\u606f\uff0cR\u5305\u62ec\u533a\u57df\u63d0\u8bae\u7f51\u7edc(RPN)\u4ee5\u53caFaster RCNN\u7684\u5176\u4ed6\u6a21\u5757\uff0c\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u7684\u635f\u5931\u5982\u4e0b\uff1a $$ \\mathcal L_{cls}(F,R)=-\\frac1{n_s}\\sum^{n_s}_{i=1}\\mathcal L_{det}(R(F(x^s_i)),y^s_i) $$  \u5176\u4e2d\uff0c\\mathcal L_{cls}\u5305\u542bFaster RCNN\u7684\u6240\u6709\u635f\u5931\uff0c\u5982\u5206\u7c7b\u635f\u5931\u3001\u8fb9\u754c\u6846\u56de\u5f52\u635f\u5931\uff0cn_s\u8868\u793a\u6e90\u57df\u6837\u672c\u7684\u6570\u91cf\u3002</p> <p>\u2003\u2003\u73b0\u6709\u7684\u65b9\u6cd5\u4e2d\uff0c\u9886\u57df\u5206\u7c7b\u5668\u7684\u635f\u5931\u4f7f\u7528\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u5982\u4e0a\u56fe\u6240\u793a\uff0c\u5728\u4ea4\u53c9\u71b5\u635f\u5931\u4e2d\uff0c\u5bf9\u4e8e\u5177\u6709\u8f83\u9ad8\u7c7b\u522b\u6982\u7387\u7684\u6613\u5206\u7c7b\u6837\u672c\u5177\u6709\u540c\u6837\u7684\u60e9\u7f5a\u89c4\u5219\uff0c\u8fd9\u8868\u660eD_g\u4e0eF\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5e73\u7b49\u5bf9\u5f85\u6240\u6709\u7684\u6837\u672c\uff0c\u56e0\u6b64F\u4f1a\u5c1d\u8bd5\u5339\u914d\u6574\u4e2a\u6570\u636e\u7684\u7279\u5f81\u5206\u5e03\uff0c\u4f46\u8fd9\u5e76\u4e0d\u662f\u6211\u4eec\u6240\u5e0c\u671b\u7684\uff0c\u5982\u4e0a\u6587\u7684\u5206\u6790\uff0c\u6211\u4eec\u5e0c\u671b\u5728\u5168\u5c40\u5bf9\u9f50\u4e2d\uff0c\u8ba9D_g\u91cd\u70b9\u5173\u6ce8\u90a3\u4e9b\u96be\u4ee5\u5206\u7c7b\u7684\u6837\u672c\uff0c\u5373\u91cd\u70b9\u5173\u6ce8\u56fe\u50cf\u5177\u6709\u5c0f\u9886\u57df\u504f\u79fb\u7684\u6570\u636e(\u5c0f\u9886\u57df\u504f\u79fb\u7684\u56fe\u7247\u548c\u539f\u56fe\u5177\u6709\u8f83\u4e3a\u76f8\u4f3c\u7684\u5206\u5e03\uff0c\u56e0\u6b64\u96be\u4ee5\u5224\u522b\u9886\u57df\u7684\u6807\u7b7e\uff0c\u800c\u5f3a\u5236\u5bf9\u9f50\u8fd9\u4e9b\u5206\u5e03\u6709\u5229\u4e8e\u6a21\u578b\u7684\u9886\u57df\u9002\u5e94\u80fd\u529b)\uff0c\u5e76\u4e14\u5ffd\u7565\u5bb9\u6613\u5206\u7c7b\u7684\u6837\u672c\uff0c\u5373\u5ffd\u7565\u56fe\u50cf\u5177\u6709\u8f83\u5927\u9886\u57df\u504f\u79fb\u7684\u6570\u636e(\u5927\u504f\u79fb\u4f1a\u5e26\u6765\u89c6\u89c9\u4e0a\u8f83\u5927\u7684\u5dee\u5f02\uff0c\u5bb9\u6613\u5224\u65ad\u9886\u57df\u7684\u6807\u7b7e\uff0c\u5f3a\u5236\u5bf9\u9f50\u4e24\u4e2a\u5dee\u5f02\u6bd4\u8f83\u5927\u7684\u6570\u636e\u5206\u5e03\u4f1a\u635f\u5bb3\u6a21\u578b\u7684\u6027\u80fd)\u3002</p> <p>\u2003\u2003\u4ea4\u53c9\u71b5\u635f\u5931\u7684\u95ee\u9898\u5728\u4e8e\u4ed6\u7ed9\u5b9a\u4e86\u6613\u5206\u7c7b\u6837\u672c\u4e0d\u53ef\u5ffd\u7565\u7684\u503c\uff0c\u5047\u8bbep\u4e3a\u6b63\u786e\u5224\u65ad\u7684\u6982\u7387\uff0c\u7531\u516c\u5f0f-\\log(p)\u53ef\u4ee5\u53d1\u73b0\uff0c\u5f53\u6837\u672c\u9886\u57df\u6807\u7b7e\u6bd4\u8f83\u5bb9\u6613\u9884\u6d4b\u65f6\uff0c\u7ed3\u679c\u5f80\u5f80\u662f\u8d8b\u4e8e0\u7684\uff0c\u4f46\u9664\u975e\u80fd\u505a\u5230\u5b8c\u7f8e\u9884\u6d4b\u7c7b\u522b\uff08\u5373p=1\uff09\uff0c-\\log(p)\u59cb\u7ec8\u4f1a\u4ea7\u751f\u4e00\u4e2a\u4e0d\u53ef\u5ffd\u7565\u7684\u503c\uff0c\u4ea4\u53c9\u71b5\u635f\u5931\u59cb\u7ec8\u90fd\u4f1a\u5bf9\u57df\u5206\u7c7b\u5668\u7684\u9884\u6d4b\u505a\u60e9\u7f5a\uff0c\u56e0\u6b64\u4e3a\u4e86\u6291\u5236\u8fd9\u79cd\u5f71\u54cd\uff0c\u63d0\u9ad8\u635f\u5931\u8d8b\u4e8e\u96f6\u7684\u901f\u5ea6\uff0c\u6211\u4eec\u53ef\u4ee5\u5728\u539f\u6709\u5f0f\u5b50\u57fa\u7840\u4e0a\u505a\u5fae\u8c03\uff0c\u52a0\u4e00\u4e2a\u6743\u91cd\u7cfb\u6570\u3002\u5047\u8bbep\\in[0,1]\u8868\u793a\u6a21\u578b\u4f30\u8ba1\u6807\u7b7ed=1\u7684\u6982\u7387\uff0c\u4f5c\u8005\u5728\u4ea4\u53c9\u71b5\u635f\u5931\u4e2d\u589e\u52a0\u4e86\u4e00\u4e2a\u8c03\u5236\u56e0\u5b50(modulating factor)f(p_t)\uff1a $$ -f(p_t)log(p_t) $$  \u5176\u4e2d\uff0cp_t\u53ef\u4ee5\u7406\u89e3\u4e3a\u65e0\u8bba\u5bf9\u4e8e\u6e90\u57df\u6570\u636e\u8fd8\u662f\u76ee\u6807\u57df\u6570\u636e\uff0c\u57df\u5206\u7c7b\u5668\u6b63\u786e\u5224\u65ad\u9886\u57df\u6807\u7b7e\u7684\u6982\u7387(\u503c\u8d8a\u5927\uff0c\u8bf4\u660e\u8d8a\u597d\u5224\u65ad\u8be5\u56fe\u5c5e\u4e8e\u54ea\u4e2a\u9886\u57df)\uff0c\u7531\u5982\u4e0b\u516c\u5f0f\u6c42\u5f97\uff1a $$ p_t=\\left\\{  \\begin{matrix} p,&amp;if\\quad d=1 \\\\ 1-p,&amp;otherwise\\end{matrix}  \\right.  $$  \u4e0a\u8ff0\u635f\u5931\u51fd\u6570\u79f0\u4e3a\u7126\u70b9\u635f\u5931(Focal Loss, FL)\uff0cf(p_t)\u53ef\u4ee5\u8868\u793a\u4e3a\u4efb\u610f\u4e00\u4e2a\u968f\u7740p_t\u589e\u52a0\u800c\u51cf\u5c11\u7684\u51fd\u6570\uff0c\u8fd9\u91cc\u4f5c\u8005\u7ed9\u51fa\u4e86\u4e00\u4e2a\u4f8b\u5b50\uff1a $$ FL(p_t)=-f(p_t)log(p_t),f(p_t)=(1-p_t)^{\\gamma} $$  \u5176\u4e2d\\gamma\u63a7\u5236\u96be\u4ee5\u5206\u7c7b\u6837\u672c\u7684\u635f\u5931\u6743\u91cd\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff0c\\gamma\u8d8a\u5927\u8868\u793aFL\u635f\u5931\u7684\u4f5c\u7528\u8d8a\u660e\u663e\uff0c\u5373\u968f\u7740p_t\u7684\u589e\u52a0\uff0c\u635f\u5931\u8d8b\u4e8e\u96f6\u7684\u901f\u5ea6\u8d8a\u5feb(\u4f46\u5e76\u4e0d\u662f\\gamma\u8d8a\u5927\u8d8a\u597d)\u3002FL\u7684\u8bbe\u8ba1\u662f\u4e3a\u4e86\u5c06\u66f4\u591a\u7684\u57df\u5206\u7c7b\u635f\u5931\u6743\u91cd\u8d4b\u503c\u4e8e\u96be\u4ee5\u5206\u7c7b\u7684\u6837\u672c\uff0c\u5e76\u4e14\u5728\u6613\u5206\u7c7b\u7684\u6837\u672c\u4e0a\u5ffd\u7565\u57df\u5206\u7c7b\u635f\u5931\u3002\u5728\u57df\u5206\u7c7b\u5668\u53c2\u6570\u7684\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u7279\u5f81\u63d0\u53d6\u5668\u4e0d\u4f1a\u5c06\u9886\u57df\u5206\u7c7b\u826f\u597d\u7684\u76ee\u6807\u57df\u56fe\u7247\u4e0e\u6e90\u57df\u56fe\u7247\u5bf9\u9f50\uff0c\u56e0\u4e3a\u4ed6\u4eec\u7684\u635f\u5931\u5c3a\u5ea6\u975e\u5e38\u5c0f\uff0c\u51e0\u4e4e\u4e0d\u4f1a\u5f71\u54cd\u5230\u7f51\u7edc\u53c2\u6570\u7684\u53d8\u5316\u3002</p> <p> <p></p> <p></p> <p>\u5f31\u5168\u5c40\u57df\u5206\u7c7b\u5668\u7684\u635f\u5931\u53ef\u4ee5\u8868\u793a\u4e3a\\mathcal L_{global}\uff1a $$ \\mathcal L_{global_s}=-\\frac1{n_s}\\sum^{n_s}_{i=1}(1-D_g(F(x^s_i))^{\\gamma}\\log(D_g(F(x^s_i))))\\\\ \\mathcal L_{global_t}=-\\frac1{n_t}\\sum^{n_t}_{i=1}(1-D_g(F(x^t_i))^{\\gamma}\\log(D_g(F(x^t_i))))\\\\ \\mathcal L_{global}(F,D_g)=\\frac12(\\mathcal L_{global_s}+\\mathcal L_{global_t}) $$  \u5176\u4e2d\uff0cn_s\u548cn_t\u4f9d\u6b21\u8868\u793a\u6e90\u57df\u56fe\u7247\u6570\u91cf\u548c\u76ee\u6807\u57df\u56fe\u7247\u6570\u91cf\u3002</p> <p>\u2003\u2003\u8fd9\u79cd\u635f\u5931\u4e5f\u4f1a\u5bf9\u9f50\u7f51\u7edc\u4f4e\u5c42\u53c2\u6570\uff0c\u5373\u5bf9\u9f50\u4f4e\u5c42\u7279\u5f81\u6570\u636e\uff0c\u4f46\u6548\u679c\u4e0d\u591f\u5f3a\uff0c\u56e0\u6b64\u4f5c\u8005\u53c8\u8bbe\u8ba1\u4e86\u5f3a\u5c40\u90e8\u7279\u5f81\u5bf9\u9f50\u6a21\u5757\u3002</p>"},{"location":"domain_adaptive/paper/Strong-Weak1/#_6","title":"\u5f3a\u5c40\u90e8\u7279\u5f81\u5bf9\u9f50","text":"<p>\u2003\u2003\u4f5c\u8005\u8fd8\u8bbe\u8ba1\u4e86\u5c40\u90e8\u7279\u5f81\u57df\u5206\u7c7b\u5668D_l\u6765\u8ba9\u7f51\u7edc\u5173\u6ce8\u5c40\u90e8\u7279\u5f81\u7684\u5bf9\u9f50\uff0c\u5c40\u90e8\u7279\u5f81\u5bf9\u9f50\u7f51\u7edc\u7531\u5377\u79ef\u6838\u5c3a\u5bf8\u4e3a1\u7684\u5168\u5377\u79ef\u7f51\u7edc\u6784\u6210\uff0c\u5982\u7f51\u7edc\u7ed3\u6784\u56fe\u6240\u793a\uff0c\u7279\u5f81\u63d0\u53d6\u5668F\u88ab\u5206\u89e3\u4e3aF_2\\circ F_1\uff0c\u5c06F_1\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u4f20\u5165D_l\u6765\u9884\u6d4b\u9886\u57df\u6807\u7b7e\u3002\u5047\u8bbeF_1\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u5bbd\u548c\u9ad8\u4f9d\u6b21\u4e3aW\u548cH\uff0c\u5219D_l\u8f93\u51fa\u7684\u9884\u6d4b\u56fe\u5177\u6709\u76f8\u540c\u7684\u5bbd\u9ad8\u5c3a\u5bf8\u3002\u5f3a\u5c40\u90e8\u7279\u5f81\u5bf9\u9f50\u635f\u5931\u51fd\u6570\u5982\u4e0b\uff1a $$ \\mathcal L_{loc_s}=\\frac1{n_sHW}\\sum^{n_s}_{i=1}\\sum^W_{w=1}\\sum^H_{h=1}D_l(F_l(x_i^s))^2_{wh}\\\\ \\mathcal L_{loc_t}=\\frac1{n_tHW}\\sum^{n_t}_{i=1}\\sum^W_{w=1}\\sum^H_{h=1}D_l(F_l(x_i^t))^2_{wh}\\\\ \\mathcal L_{loc}(F,D_l)=\\frac12(\\mathcal L_{loc_s}+\\mathcal L_{loc_t}) $$  \u5176\u4e2d\uff0cD_l(F_l(x_i^s))_{wh}\u8868\u793a\u57df\u5206\u7c7b\u5668\u5728\u539f\u7279\u5f81\u56fe\u6bcf\u4e2a\u4f4d\u7f6e\u7684\u8f93\u51fa\uff0c\u8be5\u635f\u5931\u7684\u8bbe\u8ba1\u7528\u4e8e\u4f7f\u7279\u5f81\u7684\u6bcf\u4e2a\u611f\u53d7\u91ce\u533a\u57df\u4e0e\u53e6\u4e00\u4e2a\u9886\u57df\u7684\u6570\u636e\u5bf9\u9f50\u3002</p>"},{"location":"domain_adaptive/paper/Strong-Weak1/#_7","title":"\u57fa\u4e8e\u4e0a\u4e0b\u6587\u5411\u91cf\u7684\u6b63\u5219\u5316\u5668","text":"<p>\u2003\u2003\u4e3a\u4e86\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6a21\u578b\u7684\u6027\u80fd\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u7f51\u7edc\u6b63\u5219\u5316\u5668\u3002\u4e4b\u524d\u7684\u7814\u7a76\u4e2d\u63d0\u5230\uff0c\u5229\u7528\u5206\u5272\u635f\u5931\u6765\u8c03\u6574\u57df\u5206\u7c7b\u5668\u6709\u5229\u4e8e\u63d0\u9ad8\u57df\u9002\u5e94\u8bed\u4e49\u5206\u5272\u4efb\u52a1\u4e2d\u5bf9\u6297\u8bad\u7ec3\u7684\u7a33\u5b9a\u6027(\u8bba\u6587\u94fe\u63a5)\uff0c\u5e76\u4e14\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7528\u4e8e\u8f93\u51fa\u9886\u57df\u6807\u7b7e\u548c\u8bed\u4e49\u5206\u5272\u56fe\u7684\u9886\u57df\u5206\u7c7b\u5668\u3002\u53d7\u6b64\u542f\u53d1\uff0c\u4f5c\u8005\u8bbe\u8ba1\u4e86\u4e00\u79cd\u7a33\u5b9a\u57df\u5206\u7c7b\u5668\u8bad\u7ec3\u8fc7\u7a0b\u7684\u65b9\u6cd5\uff0c\u9996\u5148\u5206\u522b\u63d0\u53d6\u4e24\u4e2a\u57df\u5206\u7c7b\u5668\u4e2d\u95f4\u5c42\u4ea7\u751f\u7684\u7279\u5f81\u5411\u91cfv_1\u548cv_2\uff0c\u8fd9\u4e9b\u7279\u5f81\u5305\u542b\u6574\u4e2a\u8f93\u5165\u56fe\u50cf\u7684\u4fe1\u606f\uff0c\u56e0\u6b64\u4f5c\u8005\u5c06\u4ed6\u4eec\u79f0\u4e3a\u201d\u4e0a\u4e0b\u6587\u201d(context)\u3002\u4e4b\u540e\u518d\u5c06\u8fd9\u4e9b\u5411\u91cf\u5408\u5e76\u5230\u6240\u6709\u611f\u5174\u8da3\u533a\u57df\u7684\u7279\u5f81(region-wise features)\u540e\u9762(\u5177\u4f53\u53ef\u89c1\u4e0a\u9762\u7684\u7f51\u7edc\u7ed3\u6784\u56fe)\uff0c\u6700\u540e\u901a\u8fc7\u6700\u5c0f\u5316\u6e90\u57df\u6837\u672c\u5728\u76ee\u6807\u68c0\u6d4b\u5668\u4e0a\u7684\u635f\u5931\u548c\u57df\u5206\u7c7b\u5668\u4e0a\u7684\u635f\u5931\u6765\u8bad\u7ec3\u57df\u5206\u7c7b\u5668\u53c2\u6570\u3002\u6d4b\u8bd5\u9636\u6bb5\uff0c\u201d\u4e0a\u4e0b\u6587\u201d\u5411\u91cf\u540c\u6837\u88ab\u4f20\u5230ROI\u4e2d\uff0c\u53c2\u4e0e\u76ee\u6807\u7c7b\u522b\u548c\u76ee\u6807\u4f4d\u7f6e\u7684\u51b3\u7b56\u3002</p>"},{"location":"domain_adaptive/paper/Strong-Weak1/#_8","title":"\u635f\u5931\u51fd\u6570","text":"<p>\u2003\u2003\u7f51\u7edc\u5bf9\u6297\u635f\u5931\\mathcal L_{adv}\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ \\mathcal L_{adv}(F,D)=\\mathcal L_{loc}(F_1,D_l)+\\mathcal L_{global}(F,D_g) $$  \u7ed3\u5408\u5bf9\u6e90\u57df\u7684\u68c0\u6d4b\u635f\u5931\uff0c\u603b\u635f\u5931\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ \\max_D\\min_{F,R}\\mathcal L_{cls}(F,R)-\\lambda\\mathcal L_{adv}(F,D) $$  \u5176\u4e2d\uff0c\\lambda\u63a7\u5236\u68c0\u6d4b\u635f\u5931\u4e0e\u5bf9\u6297\u635f\u5931\u4e4b\u95f4\u7684\u6743\u91cd\uff0c\u57df\u5206\u7c7b\u5668\u7684\u5bf9\u6297\u635f\u5931\u53ef\u4ee5\u7531\u68af\u5ea6\u53cd\u8f6c\u5c42\u5b9e\u73b0\u3002</p>"},{"location":"domain_adaptive/paper/Strong-Weak1/#_9","title":"\u5b9e\u9a8c","text":""},{"location":"domain_adaptive/paper/Strong-Weak1/#_10","title":"\u53ef\u89c6\u5316\u5206\u6790","text":"<p>\u2003\u2003\u4f5c\u8005\u63d0\u51fa\u7684\u65b9\u6cd5\u4e3b\u8981\u7528\u4e8e\u63d0\u9ad8\u6a21\u578b\u5728\u9886\u57df\u504f\u79fb\u8f83\u5927\u7684\u6570\u636e\u4e0a\u7684\u68c0\u6d4b\u6027\u80fd\uff0c\u5982\u4e0b\u56fe(a)(b)\u6240\u793a\uff0c\u63d0\u51fa\u7684\u6a21\u578b\u7cbe\u5ea6\u8981\u8fdc\u9ad8\u4e8e\u5e26\u6709\u57fa\u7ebf\u57df\u5206\u7c7b\u5668\u7684Faster R-CNN\u6a21\u5757\u3002\u7531\u4e8e\u5bf9\u5168\u5c40\u7279\u5f81\u4e5f\u6267\u884c\u5f3a\u6570\u636e\u5bf9\u9f50\uff0c\u57fa\u7ebf\u6a21\u578b\u901a\u5e38\u4f1a\u4ea7\u751f\u7d27\u5bc6\u5339\u914d\u7684\u7279\u5f81\u5206\u5e03\uff0c\u8fd9\u79cd\u5206\u5e03\u5e76\u4e0d\u603b\u662f\u6709\u52a9\u4e8e\u57df\u9002\u5e94\u7684\u76ee\u6807\u68c0\u6d4b\uff0c\u4f5c\u8005\u63d0\u51fa\u7684\u7b97\u6cd5\u7531\u4e8e\u5bf9\u5168\u5c40\u7279\u5f81\u6267\u884c\u5f31\u5bf9\u9f50\uff0c\u56e0\u6b64\u5177\u6709\u8f83\u4e3a\u5206\u6563\u7684\u7279\u5f81\u5206\u5e03\uff0c\u800c\u8fd9\u6b63\u6709\u52a9\u4e8e\u57df\u9002\u5e94\u7684\u76ee\u6807\u68c0\u6d4b\u3002\u5bf9\u4e8e\u9886\u57df\u504f\u79fb\u8f83\u5c0f\u7684\u6570\u636e\uff0c\u5982\u4e0b\u56fe\u00a9(d)\u6240\u793a\uff0c\u867d\u7136\u7ed3\u679c\u90fd\u5dee\u4e0d\u591a\uff0c\u4f46\u662f\u7cbe\u5ea6\u8981\u6bd4\u57fa\u7ebf\u6a21\u578b\u9ad8\u4e00\u4e9b\u3002</p> <p> <p></p> <p></p> <p>\u4e0a\u56fe\u4e2d\uff0c\u84dd\u8272\u8868\u793a\u6e90\u57df\u6570\u636e\uff0c\u7ea2\u8272\u8868\u793a\u76ee\u6807\u57df\u6570\u636e\u3002</p>"},{"location":"domain_adaptive/paper/Strong-Weak1/#map","title":"mAP\u5bf9\u6bd4","text":"<p>Cityscape \\rightarrow FoggyCityscape</p> <p> <p></p> <p></p>"},{"location":"domain_adaptive/paper/Strong-Weak1/#_11","title":"\u603b\u7ed3","text":"<p>\u2003\u2003\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5c40\u90e8\u5bf9\u9f50\u548c\u5f31\u5168\u5c40\u5bf9\u9f50\u7684\u65e0\u76d1\u7763\u57df\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\uff0c\u4e3b\u8981\u7684\u8d21\u732e\u5c31\u662f\u8bbe\u8ba1\u4e86\u4e00\u79cd\u5f31\u5bf9\u9f50\u6a21\u5757\uff0c\u5c06\u5bf9\u6297\u635f\u5931\u96c6\u4e2d\u5728\u5168\u5c40\u76f8\u4f3c\u7684\u56fe\u50cf\u4e0a\uff0c\u8fdc\u79bb\u5168\u5c40\u4e0d\u76f8\u4f3c\u7684\u56fe\u50cf\uff0c\u5e76\u4e14\u9488\u5bf9\u7279\u5f81\u56fe\u4e0a\u5c40\u90e8\u7684\u611f\u53d7\u91ce\u533a\u57df\u8bbe\u8ba1\u4e86\u5f3a\u5c40\u90e8\u5bf9\u9f50\u6a21\u5757\u3002\u901a\u8fc7\u5b9e\u9a8c\u5206\u6790\u5f97\u5230\uff0c\u8be5\u7b97\u6cd5\u7684\u6027\u80fd\u8981\u4f18\u4e8e\u73b0\u6709\u7684\u57df\u9002\u5e94\u68c0\u6d4b\u7b97\u6cd5\u3002</p> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u5927\u5bb6\u6279\u8bc4\u6307\u6b63</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e741\u670829\u65e5</p>"},{"location":"domain_adaptive/relation/MCD1/","title":"\u57df\u9002\u5e94\u5206\u7c7b\uff1aMCD","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aIEEE Conference on Computer Vision and Pattern Recognition 2018 (CVPR 2018)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content_cvpr_2018/papers/Saito_Maximum_Classifier_Discrepancy_CVPR_2018_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/mil-tokyo/MCD_DA</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u57df\u9002\u5e94\u5206\u7c7b</p>"},{"location":"domain_adaptive/relation/MCD1/#_1","title":"\u4e3b\u8981\u601d\u60f3","text":"<p>\u2003\u2003\u73b0\u6709\u7684\u57df\u9002\u5e94\u65b9\u6cd5\u5927\u591a\u6570\u90fd\u662f\u5728\u4e0d\u8003\u8651\u6837\u672c\u7c7b\u522b\u7684\u60c5\u51b5\u4e0b\u5bf9\u6e90\u57df\u7279\u5f81\u548c\u76ee\u6807\u57df\u7279\u5f81\u6267\u884c\u5bf9\u9f50\uff0c\u4ee5\u5bf9\u6297\u7684\u65b9\u5f0f\u8bad\u7ec3\u7279\u5f81\u63d0\u53d6\u5668\u548c\u5206\u7c7b\u5668\uff0c\u6700\u7ec8\u8ba9\u7279\u5f81\u63d0\u53d6\u5668\u5339\u914d\u6e90\u57df\u6837\u672c\u548c\u76ee\u6807\u57df\u6837\u672c\u4e4b\u95f4\u7684\u7279\u5f81\u3002\u7136\u800c\uff0c\u8fd9\u79cd\u65b9\u6cd5\u7531\u4e8e\u5728\u7279\u5f81\u5bf9\u9f50\u7684\u8fc7\u7a0b\u4e2d\u4e0d\u8003\u8651\u76ee\u6807\u6837\u672c\u548c\u6a21\u578b\u51b3\u7b56\u8fb9\u754c\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u56e0\u6b64\u4f1a\u635f\u5bb3\u6a21\u578b\u5bf9\u8fa8\u8bc6\u529b\u7279\u5f81(discriminative features)\u7684\u63d0\u53d6\uff0c\u5982\u4e0b\u56fe\u5de6\u4fa7\u6240\u793a\uff0c\u4e3a\u4e86\u8ba9\u4e24\u4e2a\u9886\u57df\u7684\u7279\u5f81\u5206\u5e03\u5c3d\u53ef\u80fd\u76f8\u4f3c\uff0c\u7279\u5f81\u63d0\u53d6\u5668\u4f1a\u5728\u51b3\u7b56\u8fb9\u754c\u9644\u8fd1\u751f\u6210\u6a21\u7cca\u7684\u7279\u5f81\uff08\u672c\u6587\u7b97\u6cd5\u6700\u7ec8\u8981\u89e3\u51b3\u7684\u95ee\u9898\uff09\uff0c\u5bf9\u6b64\uff0c\u4f5c\u8005\u4f7f\u7528\u76ee\u6807\u57df\u6837\u672c\u5206\u7c7b\u5668\u7684\u8f93\u51fa\u6765\u5bf9\u9f50\u6e90\u57df\u548c\u76ee\u6807\u57df\u7684\u7279\u5f81\u5206\u5e03\u3002</p> <p> <p></p> <p></p> <p>\u2003\u2003\u8be5\u65b9\u6cd5\u4e3b\u8981\u7531\u4e24\u4e2a\u6a21\u5757\u6784\u6210\uff1a\u4e24\u4e2a\u7279\u5b9a\u4e8e\u4efb\u52a1(task-specific)\u7684\u5206\u7c7b\u5668\u548c\u7279\u5f81\u63d0\u53d6\u5668\u3002\u7279\u5b9a\u4e8e\u4efb\u52a1\u7684\u5206\u7c7b\u5668\u8868\u793a\u4e3a\u7531\u4efb\u52a1\u9a71\u52a8\u7684\u5206\u7c7b\u5668\uff08\u5982\u56fe\u50cf\u5206\u7c7b\u4e2d\u7684\u5168\u8fde\u63a5\u5c42\uff0c\u8f93\u51fa\u6bcf\u4e2a\u7c7b\u522b\u7684\u9884\u6d4b\u5206\u6570\uff09\u3002\u8bad\u7ec3\u9636\u6bb5\uff0c\u4e24\u4e2a\u5206\u7c7b\u5668\u540c\u65f6\u4ee5\u7279\u5f81\u63d0\u53d6\u5668\u63d0\u53d6\u5230\u7684\u7279\u5f81\u4f5c\u4e3a\u8f93\u5165\uff0c\u5bf9\u4e8e\u6e90\u57df\u6837\u672c\uff0c\u671f\u671b\u8f93\u51fa\u6b63\u786e\u7684\u7c7b\u522b\u6982\u7387\u9884\u6d4b\uff08\u76f4\u63a5\u5229\u7528\u4ea4\u53c9\u71b5\u635f\u5931\u5b9e\u73b0\uff09\uff1b\u800c\u5bf9\u4e8e\u76ee\u6807\u57df\u6570\u636e\uff0c\u671f\u671b\u6a21\u578b\u53ef\u4ee5\u68c0\u6d4b\uff08\u8bc6\u522b\uff09\u8fdc\u79bb\u6e90\u57df\u652f\u6301(support)\u7684\u76ee\u6807\u6837\u672c\uff0c\u6240\u8c13\u7684\u8fdc\u79bb\u6e90\u57df\u652f\u6301\u5176\u5b9e\u5c31\u662f\u6570\u636e\u5206\u5e03\u79bb\u6e90\u57df\u6570\u636e\u5206\u5e03\u8fdc\u7684\u6837\u672c\uff08\u5982\u4e0a\u56fe\u4e2d\uff0c\u79bb\u84dd\u8272\u70b9\u8f83\u8fdc\u7684\u90e8\u5206\u6a59\u8272\u70b9\uff09\u3002\u7531\u4e8e\u5bf9\u4e8e\u8fdc\u79bb\u6e90\u57df\u7684\u6837\u672c\uff0c\u7279\u5f81\u63d0\u53d6\u5668\u5f80\u5f80\u4e0d\u80fd\u63d0\u53d6\u51fa\u5177\u6709\u8fa8\u8bc6\u529b\u7684\u7279\u5f81\uff0c\u56e0\u6b64\u6a21\u578b\u4e0d\u80fd\u6e05\u695a\u5730\u5c06\u8fd9\u4e9b\u6837\u672c\u5206\u7c7b\u5230\u67d0\u4e9b\u7279\u5b9a\u7684\u7c7b\u522b\uff0c\u4ece\u800c\u5bfc\u81f4\u8bef\u5206\u7c7b\u3002\u5bf9\u6b64\uff0c\u4f5c\u8005\u4f7f\u7528\u7279\u5b9a\u4e8e\u4efb\u52a1\u7684\u5206\u7c7b\u5668\u4f5c\u4e3a\u5224\u522b\u5668\uff0c\u7531\u4e8e\u8be5\u5206\u7c7b\u5668\u76f4\u63a5\u4e0e\u6700\u7ec8\u7684\u56fe\u50cf\u5206\u7c7b\u6302\u94a9\uff0c\u800c\u6b63\u786e\u6267\u884c\u56fe\u50cf\u5206\u7c7b\u5c31\u5fc5\u987b\u6316\u6398\u56fe\u50cf\u4e2d\u4e0e\u7c7b\u522b\u76f8\u5173\u7684\u8fa8\u8bc6\u529b\u7279\u5f81\uff0c\u56e0\u6b64\u76f8\u6bd4\u4e8e\u4f20\u7edf\u4f7f\u7528\u57df\u5206\u7c7b\u5668\u6765\u5bf9\u9f50\u9886\u57df\u7279\u5f81\u5206\u5e03\u7684\u65b9\u6cd5\uff0c\u4f5c\u8005\u4f7f\u7528\u7684\u6837\u672c\u5206\u7c7b\u5668\u66f4\u80fd\u517c\u987e\u7c7b\u522b\u4fe1\u606f\uff1b\u800c\u7279\u5f81\u63d0\u53d6\u5668\u7684\u8bad\u7ec3\u5219\u4e0e\u5206\u7c7b\u5668\u76f8\u53cd\uff0c\u7528\u4e8e\u6df7\u6dc6\u5224\u522b\u5668\u7684\u5224\u65ad\uff08\u8fd9\u91cc\u7c7b\u4f3c\u4e8e\u5229\u7528\u57df\u5224\u522b\u5668\u5bf9\u9f50\u7279\u5f81\u4e2d\u7684\u5bf9\u6297\u635f\u5931\uff09\u3002\u6362\u53e5\u8bdd\u8bf4\uff0c\u5728\u8003\u8651\u5206\u7c7b\u5668\u5bf9\u76ee\u6807\u6837\u672c\u7c7b\u522b\u6982\u7387\u7684\u8f93\u51fa\u65f6\uff0c\u8ba9\u7279\u5f81\u63d0\u53d6\u5668\u5728\u6e90\u57df\u652f\u6301\u9644\u8fd1\u751f\u6210\u76ee\u6807\u57df\u6570\u636e\u7684\u7279\u5f81\uff08\u5373\u4f7f\u76ee\u6807\u57df\u6570\u636e\u9760\u8fd1\u6e90\u57df\u6570\u636e\uff09\u3002\u7531\u4e8e\u8be5\u65b9\u6cd5\u8003\u8651\u4e86\u76ee\u6807\u57df\u6837\u672c\u548c\u51b3\u7b56\u8fb9\u754c\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u56e0\u6b64\u5b83\u5141\u8bb8\u7279\u5f81\u63d0\u53d6\u5668\u4e3a\u76ee\u6807\u57df\u6837\u672c\u751f\u6210\u8fa8\u8bc6\u529b\u7279\u5f81\u3002\u6ce8\u610f\uff1a\u8be5\u65b9\u6cd5\u4ee5\u5bf9\u6297\u7684\u65b9\u5f0f\u6267\u884c\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u5e76\u4e14\u4e0e\u5229\u7528\u57df\u5206\u7c7b\u5668\u6765\u5bf9\u9f50\u7279\u5f81\u5206\u5e03\u7684\u65b9\u6cd5\u7c7b\u4f3c\uff0c\u53ea\u662f\u8fd9\u91cc\u4f7f\u7528\u4efb\u52a1\u76f8\u5173\u7684\u5206\u7c7b\u5668\u6765\u5bf9\u7279\u5f81\u6267\u884c\u5bf9\u9f50\uff08\u5f15\u5165\u4e86\u7c7b\u522b\u4fe1\u606f\uff09\u3002</p>"},{"location":"domain_adaptive/relation/MCD1/#_2","title":"\u65b9\u6cd5","text":""},{"location":"domain_adaptive/relation/MCD1/#_3","title":"\u603b\u4f53\u601d\u8def","text":"<p>\u2003\u2003\u5047\u8bbe\u6e90\u57df\u6570\u636e\u96c6\u4e3a\\{X_s,Y_s\\}\uff0c\u5176\u4e2d\u6e90\u57df\u56fe\u50cf\u8868\u793ax_s\\in X_s\uff0c\u5bf9\u5e94\u7684\u6807\u7b7e\u8868\u793ay_s\\in Y_s\uff0c\u5e76\u4e14\u76ee\u6807\u57df\u6570\u636e\u4e3aX_t\uff0c\u5176\u4e2d\u76ee\u6807\u57df\u56fe\u50cf\u8868\u793a\u4e3ax_t\\in X_t\u3002\u4ee5\u56fe\u50cfx_s\u4ee5\u53cax_t\u4f5c\u4e3a\u8f93\u5165\u7684\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u8868\u793a\u4e3aG\uff0c\u4ee5\u7279\u5f81\u56fe\u4f5c\u4e3a\u8f93\u5165\u7684\u5206\u7c7b\u7f51\u7edc\u8868\u793a\u4e3aF_1\u548cF_2\uff0c\u5206\u7c7b\u5668F_1\u548cF_2\u8f93\u51fa\u4e00\u4e2aK\u7ef4\u7684\u5411\u91cf\uff0c\u5206\u522b\u4ee3\u8868K\u4e2a\u7c7b\u522b\u7684\u9884\u6d4b\u5206\u6570\uff0c\u518d\u5c06\u9884\u6d4b\u5411\u91cf\u4f20\u5165softmax\u51fd\u6570\u5f97\u5230\u6bcf\u4e2a\u7c7b\u522b\u7684\u9884\u6d4b\u6982\u7387\uff0c\u5047\u8bbep_1(y|x)\u548cp_2(y|x)\u4f9d\u6b21\u8868\u793a\u7531F_1\u548cF_2\u83b7\u5f97\u7684K\u7ef4\u9884\u6d4b\u6982\u7387\uff08\u4ee5x\u4f5c\u4e3a\u8f93\u5165\uff09\u3002</p> <p>\u2003\u2003\u6a21\u578b\u603b\u76ee\u6807\u4e3a\u901a\u8fc7\u5229\u7528\u7279\u5b9a\u4e8e\u4efb\u52a1(task-specific)\u7684\u5206\u7c7b\u5668\u4f5c\u4e3a\u5224\u522b\u5668\u6765\u5bf9\u9f50\u6e90\u57df\u548c\u76ee\u6807\u57df\u7684\u7279\u5f81\uff0c\u4ee5\u4fbf\u4e8e\u8003\u8651\u7c7b\u522b\u8fb9\u754c\u548c\u76ee\u6807\u57df\u6837\u672c\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5bf9\u6b64\uff0c\u6211\u4eec\u5fc5\u987b\u68c0\u6d4b\u8fdc\u79bb\u6e90\u57df\u652f\u6301\u7684\u76ee\u6807\u57df\u6837\u672c\uff0c\u5373\u8ba9\u6a21\u578b\u53ef\u4ee5\u8bc6\u522b\u5230\u4e0e\u6e90\u57df\u6570\u636e\u5206\u5e03\u5dee\u522b\u5927\u7684\u76ee\u6807\u6837\u672c\uff0c\u8fd9\u4e9b\u76ee\u6807\u6837\u672c\u5f88\u5bb9\u6613\u88ab\u7531\u6e90\u57df\u6837\u672c\u8bad\u7ec3\u7684\u5206\u7c7b\u5668\u9519\u8bef\u5206\u7c7b\u3002\u56e0\u6b64\uff0c\u4e3a\u4e86\u68c0\u6d4b\u8fd9\u4e9b\u76ee\u6807\u57df\u6837\u672c\uff0c\u4f5c\u8005\u63d0\u51fa\u5229\u7528\u4e24\u4e2a\u5206\u7c7b\u5668\u5bf9\u76ee\u6807\u6837\u672c\u9884\u6d4b\u7684\u4e0d\u4e00\u81f4\u6027\u6765\u68c0\u6d4b\u4e0e\u6e90\u57df\u6570\u636e\u7684\u5dee\u5f02\u3002\u4f8b\u5982\uff1a\u5982\u679c\u5bf9\u4e8e\u4e00\u4e2a\u76ee\u6807\u57df\u6837\u672c\uff0c\u6a21\u578b\u63d0\u53d6\u5230\u7684\u7279\u5f81\u4e0e\u6e90\u57df\u7684\u7279\u5f81\u5206\u5e03\u8ddd\u79bb\u8d8a\u8fdc\uff0c\u5219\u6b64\u65f6\u4e24\u4e2a\u5206\u7c7b\u5668\u5bf9\u8be5\u7279\u5f81\u7684\u5206\u7c7b\u9884\u6d4b\u8d8a\u5177\u6709\u4e0d\u786e\u5b9a\u6027\uff0c\u5206\u7c7b\u7ed3\u679c\u5dee\u5f02\u5c31\u8d8a\u5927\uff1b\u53cd\u4e4b\uff0c\u5982\u679c\u63d0\u53d6\u5f97\u5230\u7684\u7279\u5f81\u4e0e\u6e90\u57df\u7279\u5f81\u5206\u5e03\u8d8a\u8fd1\uff0c\u5219\u6b64\u65f6\u5206\u7c7b\u5668\u5bf9\u8be5\u7279\u5f81\u7684\u5206\u7c7b\u51b3\u7b56\u5c31\u8d8a\u6709\u628a\u63e1\uff08\u56e0\u4e3a\u9760\u8fd1\u6e90\u57df\uff0c\u800c\u5bf9\u4e8e\u6e90\u57df\u7279\u5f81\uff0c\u5206\u7c7b\u5668\u662f\u975e\u5e38\u6709\u628a\u63e1\u505a\u51fa\u5224\u65ad\u7684\uff09\uff0c\u4e24\u4e2a\u5206\u7c7b\u5668\u5bf9\u8be5\u7279\u5f81\u7684\u5206\u7c7b\u9884\u6d4b\u7ed3\u679c\u5dee\u5f02\u5c31\u8d8a\u5c0f\u3002</p> <p>\u2003\u2003\u8003\u8651\u5230\u4e24\u4e2a\u5206\u7c7b\u5668(F_1,F_2)\u9700\u8981\u5177\u6709\u4e0d\u540c\u7684\u7279\u6027\uff08\u5982\u4e0b\u56fe\u6700\u5de6\u4fa7\u6240\u793a\uff0c\u51b3\u7b56\u8fb9\u754c\u4e0d\u80fd\u91cd\u5408\uff0c\u9700\u8981\u6709\u8f83\u5927\u7684\u76f8\u4ea4\u89d2\u5ea6\uff0c\u5982\u679c\u4e24\u4e2a\u51b3\u7b56\u8fb9\u754c\u91cd\u5408\u7684\u8bdd\uff0c\u5c31\u5931\u53bb\u4e86\u8bbe\u7f6e\u4e24\u4e2a\u5206\u7c7b\u5668\u7684\u610f\u4e49\u4e86\uff09\uff0c\u56e0\u6b64F_1\u4e0eF_2\u9700\u8981\u6709\u4e0d\u540c\u7684\u521d\u59cb\u5316\u53c2\u6570\uff08\u4ece\u4e00\u5f00\u59cb\u5c31\u5177\u6709\u5dee\u5f02\uff09\uff0c\u5e76\u4e14\u7531\u4e8e\u5177\u6709\u6e90\u57df\u6837\u672c\u7684\u6807\u7b7e\uff0c\u56e0\u6b64\u53ef\u4ee5\u5047\u8bbe\u4e24\u4e2a\u5206\u7c7b\u5668\u80fd\u591f\u6b63\u786e\u5730\u5bf9\u6e90\u57df\u6837\u672c\u8fdb\u884c\u5206\u7c7b\u3002\u8fd9\u91cc\uff0c\u6709\u4e00\u4e2a\u5173\u952e\u7684\u76f4\u89c9(intuition)\uff0c\u6e90\u57df\u652f\u6301\u5916\u7684\u76ee\u6807\u6837\u672c\u5f88\u53ef\u80fd\u88ab\u4e24\u4e2a\u4e0d\u540c\u7684\u5206\u7c7b\u5668\u4ee5\u4e0d\u540c\u7684\u65b9\u5f0f\u5206\u5f00\uff08\u5373\u5bf9\u4e8e\u540c\u4e00\u7279\u5f81\uff0c\u4e0d\u540c\u7684\u5206\u7c7b\u5668\u505a\u51fa\u4e0d\u540c\u7684\u51b3\u7b56\uff09\uff0c\u5982\u4e0b\u56fe\u4e2d\u6700\u5de6\u4fa7\u9ed1\u7ebf\u8868\u793a\u7684\u533a\u57df(\u5dee\u5f02\u533a\u57df, Discrepancy Region)\u3002\u76f8\u53cd\uff0c\u5982\u679c\u6211\u4eec\u53ef\u4ee5\u8861\u91cf\u4e24\u4e2a\u5206\u7c7b\u5668\u4e4b\u95f4\u7684\u5dee\u5f02\u6027\uff0c\u5e76\u4e14\u8bad\u7ec3\u7279\u5f81\u63d0\u53d6\u5668\u4ece\u800c\u6700\u5c0f\u5316\u4e0d\u4e00\u81f4\u6027\uff0c\u5219\u7f51\u7edc\u4f1a\u907f\u514d\u5728\u6e90\u6837\u672c\u652f\u6301\u5916\u7684\u533a\u57df\u751f\u6210\u76ee\u6807\u57df\u7279\u5f81\u3002\u8fd9\u91cc\u8003\u8651\u4f7f\u7528\u516c\u5f0fd(p_1(y|x_t),p_2(y|x_t))\u6765\u8861\u91cf\u76ee\u6807\u6837\u672c\u7684\u5dee\u5f02\uff0c\u5176\u4e2dd\u8868\u793a\u8861\u91cf\u4e24\u4e2a\u6982\u7387\u4e4b\u95f4\u6563\u5ea6\u7684\u51fd\u6570\uff0c\u540e\u9762\u7684\u76ee\u7684\u5c31\u662f\u83b7\u5f97\u4e00\u4e2a\u80fd\u591f\u6700\u5c0f\u5316\u76ee\u6807\u6837\u672c\u5dee\u5f02\u7684\u7279\u5f81\u751f\u6210\u5668\uff08\u8fd9\u91cc\u4e0e\u5229\u7528\u57df\u5206\u7c7b\u5668\u5bf9\u9f50\u7279\u5f81\u7684\u76ee\u7684\u7c7b\u4f3c\uff09\u3002</p> <p> <p></p> <p></p> <p>\u2003\u2003\u4e3a\u4e86\u6709\u6548\u5730\u68c0\u6d4b\u8fdc\u79bb\u6e90\u57df\u652f\u6301\u7684\u76ee\u6807\u6837\u672c\uff0c\u4f5c\u8005\u63d0\u51fa\u901a\u8fc7\u6700\u5927\u5316\u7ed9\u5b9a\u7684\u76ee\u6807\u57df\u7279\u5f81\u5dee\u5f02(Maximize Discrepancy)\u6765\u8bad\u7ec3\u5206\u7c7b\u5668(F_1\u4e0eF_2)\uff0c\u5177\u4f53\u8fc7\u7a0b\u5982\u4e0a\u56fe\u6240\u793a\uff0c\u51b3\u7b56\u8fb9\u754c\u4ece\u865a\u7ebf\u5230\u5b9e\u7ebf\u7684\u4e00\u4e2a\u6f14\u53d8\uff08\u7b2c\u4e00\u5f20\u56fe\uff09\uff0c\u8fd9\u91cc\u76f8\u5f53\u4e8e\u8ba9\u51b3\u7b56\u8fb9\u754c\u540e\u9000\u4e00\u6b65\uff0c\u5411\u6e90\u57df\u9760\u8fd1\uff0c\u8be5\u64cd\u4f5c\u53ef\u4ee5\u907f\u514d\u4e24\u4e2a\u5206\u7c7b\u5668\u975e\u5e38\u76f8\u4f3c\uff0c\u5e76\u4e14\u53ef\u4ee5\u68c0\u6d4b\u6e90\u57df\u652f\u6301\u5916\u7684\u76ee\u6807\u57df\u6837\u672c\u3002\u4e4b\u540e\uff0c\u518d\u901a\u8fc7\u6700\u5c0f\u5316\u5dee\u5f02(Minimize Discrepancy)\u6765\u8bad\u7ec3\u7279\u5f81\u63d0\u53d6\u5668\uff0c\u5177\u4f53\u8fc7\u7a0b\u5982\u4e0a\u56fe\uff0c\u865a\u7ebf\u533a\u57df\u5230\u5b9e\u7ebf\u533a\u57df\u7684\u8f6c\u6362\uff08\u7b2c\u4e8c\u5f20\u56fe\uff09\uff0c\u8fd9\u91cc\u76f8\u5f53\u4e8e\u8ba9\u7279\u5f81\u63d0\u53d6\u5668\u4ea7\u751f\u7684\u76ee\u6807\u57df\u7279\u5f81\u524d\u8fdb\u4e00\u6b65\uff0c\u8ba9\u7279\u5f81\u5206\u5e03\u4e5f\u5411\u6e90\u57df\u9760\u8fd1\uff0c\u8be5\u64cd\u4f5c\u53ef\u4ee5\u9f13\u52b1\u7279\u5f81\u63d0\u53d6\u5668\u5c06\u76ee\u6807\u6837\u672c\u63d0\u53d6\u5230\u7684\u7279\u5f81\u5305\u542b\u5728\u6e90\u57df\u7279\u5f81\u652f\u6301\u5185\uff08\u5373\u9760\u8fd1\u6e90\u57df\u7279\u5f81\uff09\uff0c\u4e24\u8005\u4e00\u7ed3\u5408\uff0c\u6709\u70b9\u7c7b\u4f3c\u4e8e\u5bf9\u6297\u5b66\u4e60\uff0c\u53ef\u4ee5\u8fbe\u5230\u201d\u4e00\u9000\u4e00\u8fdb\u201d\u7684\u8bad\u7ec3\u6548\u679c\uff0c\u6700\u7ec8\u53ef\u4ee5\u8ba9\u76ee\u6807\u57df\u7684\u652f\u6301\u7279\u5f81\u88ab\u6e90\u57df\u6837\u672c\u7684\u652f\u6301\u7279\u5f81\u6240\u5305\u542b\uff08\u5982\u4e0a\u56fe\u4e2d\u6700\u7ec8\u83b7\u5f97\u7684\u6570\u636e\u5206\u5e03\u4e0e\u51b3\u7b56\u8fb9\u754c\uff09\u3002</p> <p>\u6ce8\uff1a</p> <ul> <li>\u56e0\u4e3a\u7c7b\u522b\u5177\u6709\u552f\u4e00\u6027\uff0c\u9762\u5bf9\u4e00\u5f20\u76ee\u6807\u57df\u56fe\u50cf\u65f6\uff0c\u7406\u60f3\u5206\u7c7b\u5668\u7684\u5206\u7c7b\u7ed3\u679c\u5fc5\u7136\u5177\u6709\u786e\u5b9a\u6027\uff08\u8f93\u51fa\u7ed3\u679c\u662f\u552f\u4e00\u7684\uff09\uff0c\u5bf9\u5e94\u8fd9\u91cc\u4e24\u4e2a\u5206\u7c7b\u5668\u5206\u7c7b\u7ed3\u679c\u4e00\u6837\uff0c\u5982\u679c\u5c06\u4e00\u5f20\u76ee\u6807\u57df\u56fe\u50cf\u4f20\u5165\u4e00\u4e2a\u8de8\u57df\u8bc6\u522b\u80fd\u529b\u6bd4\u8f83\u5dee\u7684\u6a21\u578b\u4e2d\uff0c\u5219\u5206\u7c7b\u7ed3\u679c\u4f1a\u6709\u5f88\u5927\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5bf9\u5e94\u8fd9\u91cc\u4e24\u4e2a\u5206\u7c7b\u5668\u5206\u7c7b\u7ed3\u679c\u4e0d\u4e00\u3002\u5bf9\u6b64\uff0c\u5982\u679c\u60f3\u8981\u4f7f\u6a21\u578b\u53ef\u4ee5\u5f88\u597d\u5730\u8bc6\u522b\u76ee\u6807\u57df\u56fe\u7247\uff0c\u5219\u53ef\u4ee5\u8ba9\u6a21\u578b\u7684\u8f93\u51fa\u4ece\u4e0d\u786e\u5b9a\u7684\u8f6c\u4e3a\u786e\u5b9a\u7684\uff0c\u56e0\u6b64\u6211\u4eec\u6700\u7ec8\u6240\u671f\u671b\u9884\u8bbe\u7684\u4e24\u4e2a\u5206\u7c7b\u5668\u5bf9\u4e8e\u540c\u4e00\u5f20\u76ee\u6807\u57df\u56fe\u7247\u53ef\u4ee5\u5f97\u5230\u4e24\u4e2a\u4e00\u81f4\u7684\u5206\u7c7b\u7ed3\u679c\uff0c\u5e76\u4e14\u8be5\u7ed3\u679c\u5747\u662f\u6b63\u786e\u7684\u7c7b\u522b\uff1b</li> <li>\u4e3a\u4e86\u4fdd\u8bc1\u4e0a\u8ff0\u601d\u8def\u7684\u53ef\u884c\u6027\uff0c\u5fc5\u987b\u8981\u5b9e\u73b0\u4e00\u4e2a\u524d\u63d0\u2014\u2014\u51b3\u7b56\u8fb9\u754c\u4e0d\u80fd\u91cd\u5408\uff0c\u5982\u679c\u51b3\u7b56\u8fb9\u754c\u91cd\u5408\uff0c\u5219\u4e24\u4e2a\u5206\u7c7b\u7ed3\u679c\u5fc5\u7136\u4e00\u81f4\uff0c\u8fd9\u4e00\u601d\u8def\u5c31\u65e0\u6cd5\u5f97\u5230\u5b9e\u73b0\uff08\u5f88\u50cf\u5bf9\u6297\uff09\uff0c\u56e0\u6b64\uff0c\u5206\u7c7b\u5668\u548c\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u8981\u4ee5\u76f8\u53cd\u7684\u65b9\u5f0f\u53bb\u4f18\u5316\uff1b</li> <li>\u5229\u7528\u6e90\u57df\u56fe\u50cf\u7684\u5206\u7c7b\u635f\u5931\u4f18\u5316\u6a21\u578b\u7684\u5206\u7c7b\u6027\u80fd\uff0c\u540c\u65f6\u5229\u7528\u6e90\u57df\u548c\u76ee\u6807\u57df\u7684\u5dee\u5f02\u635f\u5931\u4f18\u5316\u6a21\u578b\u7684\u8de8\u57df\u8bc6\u522b\u6027\u80fd\u3002\u7406\u60f3\u7684\u4f18\u5316\u7ed3\u679c\uff1a\u4e24\u4e2a\u5206\u7c7b\u6a21\u578b\u4f1a\u4ee5\u4e0d\u540c\u89d2\u5ea6\u5f97\u5230\u76f8\u540c\u7684\u5206\u7c7b\u7ed3\u679c\uff08\u4e5f\u5c31\u662f\u7528\u4e0d\u540c\u7684\u51b3\u7b56\u9762\u51b3\u7b56\uff09\uff0c\u540c\u65f6\u7531\u4e8e\u76ee\u6807\u57df\u7684\u56fe\u50cf\u4e5f\u53c2\u4e0e\u4e86\u6a21\u578b\u5206\u7c7b\u6027\u80fd\u7684\u8bad\u7ec3\uff0c\u56e0\u6b64\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u53ef\u4ee5\u63d0\u53d6\u7c7b\u522b\u8fa8\u8bc6\u5ea6\u9ad8\u7684\u7279\u5f81\uff0c\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u6a21\u578b\u7684\u5206\u7c7b\u6027\u80fd\u3002</li> </ul>"},{"location":"domain_adaptive/relation/MCD1/#_4","title":"\u5dee\u5f02\u635f\u5931","text":"<p>\u2003\u2003\u672c\u6587\u4e2d\uff0c\u4f5c\u8005\u5728\u4e24\u4e2a\u5206\u7c7b\u5668\u7684\u9884\u6d4b\u6982\u7387\u4e4b\u95f4\u4f7f\u7528\u7684\u5dee\u5f02\u635f\u5931\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ d(p_1,p_2)=\\frac{1}{K}\\sum^K_{k=1}|p_{1k}-p_{2k}| $$  \u5176\u4e2d\uff0cp_{1k}\u548cp_{2k}\u4f9d\u6b21\u8868\u793a\u7c7b\u522bk\u4e2dp_1\u548cp_2\u7684\u8f93\u51fa\u6982\u7387\uff08\u5373softmax\u4e4b\u540e\u7684\u7ed3\u679c\uff09\u3002</p>"},{"location":"domain_adaptive/relation/MCD1/#_5","title":"\u8bad\u7ec3\u9636\u6bb5","text":"<p>\u2003\u2003\u4f5c\u8005\u5c06\u8bad\u7ec3\u8fc7\u7a0b\u5212\u5206\u6210\u4e86\u4e09\u4e2a\u9636\u6bb5</p> <p>\u7b2c\u4e00\u9636\u6bb5</p> <p>\u2003\u2003\u9996\u5148\uff0c\u5229\u7528\u6e90\u57df\u6837\u672c\u6765\u540c\u65f6\u8bad\u7ec3\u5206\u7c7b\u5668\u548c\u7279\u5f81\u63d0\u53d6\u5668\uff0c\u4fdd\u8bc1\u5b83\u4eec\u53ef\u4ee5\u5bf9\u6e90\u57df\u6837\u672c\u5f97\u5230\u6b63\u786e\u7684\u5206\u7c7b\uff0c\u5373\u53ef\u4ee5\u63d0\u53d6\u5224\u522b\u7279\u5f81\uff0c\u8be5\u9636\u6bb5\u4f7f\u7528\u4ea4\u53c9\u71b5\u635f\u5931\u6765\u4f18\u5316\uff0c\u4f18\u5316\u76ee\u6807\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ \\min_{G,F_1,F_2}\\mathcal L(X_s,Y_s) $$  \u5176\u4e2d\uff1a $$ \\mathcal L(X_s,Y_s)=-\\mathbb E_{(x_s,y_s)\\sim(X_s,Y_s)}\\sum^K_{k=1}\\mathbb 1_{[k=y_s]}\\log p(y|x_s) $$ \u7b2c\u4e8c\u9636\u6bb5</p> <p>\u2003\u2003\u56fa\u5b9a\u7279\u5f81\u63d0\u53d6\u5668G\uff0c\u901a\u8fc7\u6700\u5927\u5316\u5dee\u5f02\u6765\u8bad\u7ec3\u5206\u7c7b\u5668(F_1,F_2)\uff0c\u5373\u5c06\u5206\u7c7b\u5668\u89c6\u4e3a\u7279\u5f81\u63d0\u53d6\u5668\u7684\u5224\u522b\u5668\u3002\u901a\u8fc7\u589e\u52a0\u5206\u7c7b\u5668\u7684\u5dee\u5f02\u53ef\u4ee5\u4f7f\u7f51\u7edc\u68c0\u6d4b\u51fa\u88ab\u6e90\u57df\u652f\u6301\u6240\u6392\u9664\u7684\u76ee\u6807\u57df\u6837\u672c\uff0c\u5177\u4f53\u8fc7\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u5728\u6700\u7ec8\u7684\u4f18\u5316\u76ee\u6807\u4e2d\uff0c\u589e\u52a0\u4e86\u6e90\u57df\u6837\u672c\u7684\u5206\u7c7b\u635f\u5931\uff08\u4e0d\u6dfb\u52a0\u8be5\u635f\u5931\u7684\u8bdd\uff0c\u6a21\u578b\u7684\u6027\u80fd\u4f1a\u663e\u8457\u4e0b\u964d\uff09\uff0c\u56e0\u6b64\u4f7f\u7528\u76f8\u540c\u6570\u91cf\u7684\u6e90\u57df\u6837\u672c\u548c\u76ee\u6807\u57df\u6837\u672c\u6765\u66f4\u65b0\u6a21\u578b\uff1a $$ \\min_{F_1,F_2}\\mathcal L(X_s,Y_s)-\\mathcal L_{adv}(X_t) $$  \u5176\u4e2d\uff1a $$ \\mathcal L_{adv}(X_t)=\\mathbb E_{x_t\\sim X_t}[d(p_1(y|x_t),p_2(y|x_t))] $$ \u7b2c\u4e09\u9636\u6bb5</p> <p>\u2003\u2003\u56fa\u5b9a\u5206\u7c7b\u5668\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u5dee\u5f02\u6765\u8bad\u7ec3\u7279\u5f81\u63d0\u53d6\u5668\uff0c\u5177\u4f53\u8fc7\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u8fd9\u4e2a\u64cd\u4f5c\u4f1a\u91cd\u590dn\u904d\uff08\u5bf9\u5e94\u6e90\u7801\u4e2d\u505a\u4e86\u4e00\u4e2afor\u5faa\u73af\uff0c\u91cd\u590dn\u6b21\u524d\u5411\u4f20\u64ad\u548c\u68af\u5ea6\u66f4\u65b0\uff09\uff0c\u5373\u8d85\u53c2\u6570n\u7528\u4e8e\u6743\u8861\u7279\u5f81\u63d0\u53d6\u5668\u548c\u5206\u7c7b\u5668\u7684\u4f18\u5316\uff1a $$ \\min_{G}\\mathcal L_{adv}(X_t) $$  \u2003\u2003\u4e0a\u8ff0\u4e09\u4e2a\u9636\u6bb5\u540c\u65f6\u7528\u4e8e\u8bad\u7ec3\uff0c\u4f46\u4e09\u4e2a\u6b65\u9aa4\u7684\u8bad\u7ec3\u987a\u5e8f\u4e0d\u91cd\u8981\uff0c\u4e3b\u8981\u5173\u6ce8\u5206\u7c7b\u5668\u548c\u7279\u5f81\u63d0\u53d6\u5668\u80fd\u591f\u6b63\u786e\u5206\u7c7b\u6e90\u57df\u6837\u672c\u7684\u6761\u4ef6\u4e0b\uff0c\u4ee5\u5bf9\u6297\u7684\u65b9\u5f0f\u5229\u7528\u76ee\u6807\u57df\u6570\u636e\u8bad\u7ec3\u4ed6\u4eec\uff0c\u5176\u5b9e\u8fd9\u91cc\u7684\u5bf9\u6297\u4e5f\u53ef\u4ee5\u901a\u8fc7\u68af\u5ea6\u53cd\u8f6c\u5c42\u5b9e\u73b0\uff0c\u4f5c\u8005\u5728\u7ed3\u5c3e\u7684\u65f6\u5019\u4e5f\u63d0\u5230\u8fc7\u3002</p>"},{"location":"domain_adaptive/relation/MCD1/#_6","title":"\u603b\u7ed3","text":"<p>\u2003\u2003\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u7279\u5b9a\u4e8e\u4efb\u52a1\u7684\u5206\u7c7b\u5668\u6765\u5bf9\u9f50\u7279\u5f81\u5206\u5e03\u7684\u65e0\u76d1\u7763\u9886\u57df\u81ea\u9002\u5e94\u65b9\u6cd5\u3002\u5c06\u7279\u5b9a\u4e8e\u4efb\u52a1\u7684\u5206\u7c7b\u5668\u89c6\u4e3a\u5224\u522b\u5668\uff0c\u5c1d\u8bd5\u68c0\u6d4b\u8ddd\u79bb\u6e90\u57df\u652f\u6301\u6bd4\u8f83\u8fdc\u7684\u76ee\u6807\u57df\u6837\u672c\uff0c\u5e76\u4e14\u901a\u8fc7\u5bf9\u6297\u635f\u5931\u8ba9\u7279\u5f81\u63d0\u53d6\u5668\u5728\u6e90\u57df\u652f\u6301\u9644\u8fd1\u751f\u6210\u76ee\u6807\u57df\u7279\u5f81\uff0c\u7531\u4e8e\u751f\u6210\u5668\u4f7f\u7528\u6765\u81ea\u5206\u7c7b\u5668\u7684\u53cd\u9988\uff0c\u56e0\u6b64\u5b83\u5c06\u907f\u514d\u5728\u7c7b\u8fb9\u754c\u9644\u8fd1\u751f\u6210\u76ee\u6807\u57df\u7279\u5f81\u3002</p> <p>\u6ce8\uff1a\u4ee5\u4e0a\u5185\u5bb9\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u6279\u8bc4\u6307\u6b63</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e742\u670826\u65e5</p>"},{"location":"fine-grained/fine_dataset/","title":"\u6570\u636e\u96c6","text":""},{"location":"fine-grained/fine_dataset/#cub-200-2011","title":"CUB-200-2011\u2014\u2014\u9e1f\u7c7b","text":"<p>\u2003\u2003\u8be5\u6570\u636e\u96c6\u7531\u52a0\u5dde\u7406\u5de5\u5b66\u9662\u7684\u7814\u7a76\u56e2\u961f\u57282010\u5e74\u63d0\u51fa\uff0c\u662f\u7ec6\u7c92\u5ea6\u5206\u7c7b\u9886\u57df\u7684\u57fa\u51c6\u6570\u636e\u96c6\u4e4b\u4e00\uff0c\u5171\u6709200\u4e2a\u7c7b\u522b\uff0c11788\u5f20\u56fe\u7247\uff0c\u5176\u4e2d\u8bad\u7ec3\u96c6\u67095994\u5f20\u56fe\u7247\u3001\u6d4b\u8bd5\u96c6\u67095794\u5f20\u56fe\u50cf\u3002</p> <p> <p></p> <p></p> <p>\u6570\u636e\u96c6\u4e0b\u8f7d\u5730\u5740\uff1ahttp://www.vision.caltech.edu/datasets/cub_200_2011</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttp://www.vision.caltech.edu/visipedia/papers/CUB_200_2011.pdf</p> <p>\u5f15\u7528\uff1a</p> <pre><code>@article{wah2011caltech,\n  title={The caltech-ucsd birds-200-2011 dataset},\n  author={Wah, Catherine and Branson, Steve and Welinder, Peter and Perona, Pietro and Belongie, Serge},\n  year={2011},\n  publisher={California Institute of Technology}\n}\n</code></pre>"},{"location":"fine-grained/fine_dataset/#stanford_cars","title":"Stanford Cars\u2014\u2014\u6c7d\u8f66\u7c7b","text":"<p>\u2003\u2003\u8be5\u6570\u636e\u96c6\u7531\u65af\u5766\u798f\u5927\u5b66\u7684\u7814\u7a76\u56e2\u961f\u57282013\u5e74\u63d0\u51fa\uff0c\u662f\u7ec6\u7c92\u5ea6\u5206\u7c7b\u9886\u57df\u7684\u57fa\u51c6\u6570\u636e\u96c6\u4e4b\u4e00\uff0c\u5171\u6709196\u4e2a\u7c7b\u522b\uff0c16185\u5f20\u56fe\u7247\uff0c\u5176\u4e2d\u8bad\u7ec3\u96c6\u67098144\u5f20\u56fe\u7247\u3001\u6d4b\u8bd5\u96c6\u67098041\u5f20\u56fe\u7247\u3002</p> <p> <p></p> <p></p> <p>\u6570\u636e\u96c6\u4e0b\u8f7d\u5730\u5740\uff1ahttps://ai.stanford.edu/~jkrause/cars/car_dataset.html</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://ai.stanford.edu/~jkrause/papers/3drr13.pdf</p> <p>\u5f15\u7528\uff1a</p> <pre><code>@inproceedings{KrauseStarkDengFei-Fei_3DRR2013,\n  title = {3D Object Representations for Fine-Grained Categorization},\n  booktitle = {4th International IEEE Workshop on  3D Representation and Recognition (3dRR-13)},\n  year = {2013},\n  address = {Sydney, Australia},\n  author = {Jonathan Krause and Michael Stark and Jia Deng and Li Fei-Fei}\n}s\n</code></pre>"},{"location":"fine-grained/fine_dataset/#fgvc-aircraft","title":"FGVC-Aircraft\u2014\u2014\u98de\u673a\u7c7b","text":"<p>\u2003\u2003\u8be5\u6570\u636e\u96c6\u57282013\u5e74\u88ab\u63d0\u51fa\uff0c\u662f\u7ec6\u7c92\u5ea6\u5206\u7c7b\u9886\u57df\u7684\u57fa\u51c6\u6570\u636e\u96c6\u4e4b\u4e00\uff0c\u5171\u6709102\u4e2a\u7c7b\u522b\uff0c10200\u5f20\u56fe\u7247\uff0c\u6bcf\u4e2a\u7c7b\u522b\u5747\u6709100\u5f20\u56fe\u50cf\uff0c\u6570\u636e\u96c6\u4ee5\u5747\u7b49\u7684\u65b9\u5f0f\u5212\u5206\u4e3a\u8bad\u7ec3\u96c6\u3001\u9a8c\u8bc1\u96c6\u3001\u6d4b\u8bd5\u96c6\uff0c\u524d\u4e24\u4e2a\u5b50\u96c6\u53ef\u7528\u4e8e\u8bad\u7ec3\uff0c\u6d4b\u8bd5\u96c6\u7528\u4e8e\u8bc4\u4f30\u6a21\u578b\u3002</p> <p> <p></p> <p></p> <p>\u6570\u636e\u96c6\u4e0b\u8f7d\u5730\u5740\uff1ahttps://www.robots.ox.ac.uk/~vgg/data/fgvc-aircraft/</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://arxiv.org/pdf/1306.5151.pdf</p> <p>\u5f15\u7528\uff1a</p> <pre><code>@article{maji2013fine,\n  title={Fine-grained visual classification of aircraft},\n  author={Maji, Subhransu and Rahtu, Esa and Kannala, Juho and Blaschko, Matthew and Vedaldi, Andrea},\n  journal={arXiv preprint arXiv:1306.5151},\n  year={2013}\n}\n</code></pre>"},{"location":"fine-grained/fine_dataset/#stanford_dogs","title":"Stanford Dogs\u2014\u2014\u72d7\u7c7b","text":"<p>\u2003\u2003\u8be5\u6570\u636e\u96c6\u7531\u65af\u5766\u798f\u5927\u5b66\u7684\u7814\u7a76\u56e2\u961f\u57282011\u5e74\u63d0\u51fa\uff0c\u662f\u7ec6\u7c92\u5ea6\u5206\u7c7b\u9886\u57df\u7684\u57fa\u51c6\u6570\u636e\u96c6\u4e4b\u4e00\uff0c\u5171\u6709120\u4e2a\u7c7b\u522b\uff0c20580\u5f20\u56fe\u7247\uff0c\u5176\u4e2d\u8bad\u7ec3\u96c6\u6bcf\u7c7b\u6709100\u5f20\u56fe\u7247\uff0c\u5176\u4f59\u7684\u7528\u4e8e\u6d4b\u8bd5(\u6bcf\u7c7b\u81f3\u5c1150\u5f20)\u3002</p> <p> <p></p> <p></p> <p>\u6570\u636e\u96c6\u4e0b\u8f7d\u5730\u5740\uff1ahttp://vision.stanford.edu/aditya86/ImageNetDogs/</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttp://people.csail.mit.edu/khosla/papers/fgvc2011.pdf</p> <p>\u5f15\u7528\uff1a</p> <pre><code>@inproceedings{khosla2011novel,\n  title={Novel dataset for fine-grained image categorization: Stanford dogs},\n  author={Khosla, Aditya and Jayadevaprakash, Nityananda and Yao, Bangpeng and Li, Fei-Fei},\n  booktitle={Proc. CVPR workshop on fine-grained visual categorization (FGVC)},\n  volume={2},\n  number={1},\n  year={2011},\n  organization={Citeseer}\n}\n</code></pre> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e742\u67088\u65e5</p>"},{"location":"fine-grained/sum_fine/","title":"\u7ec6\u7c92\u5ea6\u5206\u7c7b\u603b\u7ed3","text":"<p>\u6ce8\uff1a\u5168\u6587\u539f\u521b\uff0c\u672a\u7ecf\u5141\u8bb8\uff0c\u7981\u6b62\u8f6c\u8f7d\uff01</p>"},{"location":"fine-grained/sum_fine/#_2","title":"\u6982\u8ff0","text":"<p>\u2003\u2003\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u662f\u5bf9\u4e00\u4e2a\u5927\u7c7b\u522b\u4e2d\u7684\u5b50\u7c7b\u522b\u8fdb\u884c\u8bc6\u522b\u3001\u5206\u7c7b\u3002\u4e0e\u4f20\u7edf\u7684\u56fe\u50cf\u5206\u7c7b\u4e0d\u540c\uff0c\u7ec6\u7c92\u5ea6\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u56fe\u50cf\u5f80\u5f80\u5177\u6709\u8f83\u5927\u7684\u7c7b\u95f4\u76f8\u4f3c\u6027\u4e0e\u8f83\u5927\u7684\u7c7b\u5185\u5dee\u5f02\uff0c\u5373\u5c5e\u4e8e\u4e0d\u540c\u7c7b\u522b\u7684\u7269\u4f53\u5f80\u5f80\u5177\u6709\u76f8\u4f3c\u7684\u5f62\u6001\u4e0e\u7279\u5f81\uff0c\u800c\u5c5e\u4e8e\u540c\u4e00\u7c7b\u522b\u7684\u7269\u4f53\u56fe\u50cf\u7531\u4e8e\u5149\u7167\u3001\u80cc\u666f\u3001\u906e\u6321\u4ee5\u53ca\u62cd\u6444\u89d2\u5ea6\u7684\u4e0d\u540c\uff0c\u5f80\u5f80\u4f1a\u5177\u6709\u8f83\u5927\u7684\u89c6\u89c9\u5dee\u5f02\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u533a\u5206\u56fe\u7247\u4e2d\u7684\u7269\u4f53\u5c5e\u4e8e\u201c\u8f66\u7c7b\u201d\u8fd8\u662f\u5c5e\u4e8e\u201c\u9e1f\u7c7b\u201d\u975e\u5e38\u5bb9\u6613\uff0c\u4f46\u662f\u5982\u679c\u9700\u8981\u8bc6\u522b\u56fe\u7247\u4e2d\u7684\u9e1f\u662f\u5c5e\u4e8e\u201cYellow Bellied Flycatcher\u201d\u8fd8\u662f\u5c5e\u4e8e\u201cYellow breasted Chat\u201d\uff0c\u5219\u5f80\u5f80\u9700\u8981\u6a21\u578b\u5177\u6709\u76f8\u5bf9\u8f83\u5f3a\u7684\u8bc6\u522b\u80fd\u529b\u3002</p> <p> <p></p> <p></p> <p>\u2003\u2003\u60f3\u8981\u6b63\u786e\u9274\u522b\u4e0d\u540c\u7684\u7c7b\u522b\uff0c\u5c31\u8981\u6c42\u7f51\u7edc\u5177\u6709\u6355\u6349\u7ec6\u5fae\u5dee\u5f02\u7684\u80fd\u529b\uff0c\u56e0\u6b64\u4f20\u7edf\u7684\u7ec6\u7c92\u5ea6\u8bc6\u522b\u7b97\u6cd5\u5f80\u5f80\u9700\u8981\u989d\u5916\u7684\u533a\u57df\u6807\u7b7e\uff0c\u901a\u8fc7\u5bf9\u4e00\u4e9b\u8fa8\u8bc6\u6027\u9ad8\u7684\u533a\u57df\u8fdb\u884c\u4eba\u5de5\u6807\u6ce8\uff0c\u4ece\u800c\u8f85\u52a9\u8bad\u7ec3\u7f51\u7edc\u6355\u6349\u7ec6\u8282\u7684\u80fd\u529b\uff0c\u4f46\u8fd9\u4e0d\u4ec5\u9700\u8981\u8f83\u9ad8\u7684\u6210\u672c\uff0c\u8fd8\u5177\u6709\u4e00\u5b9a\u4e3b\u89c2\u56e0\u7d20\u7684\u5e72\u6270\uff08\u5982\u533a\u57df\u4f4d\u7f6e\u3001\u6570\u91cf\u7b49\u7b49\uff09\uff0c\u9650\u5236\u4e86\u6a21\u578b\u7684\u8fdb\u4e00\u6b65\u5b66\u4e60\uff0c\u901a\u4fd7\u6765\u8bb2\u5c31\u662f\u5982\u679c\u4e00\u4e2a\u7269\u4f53\u5177\u6709\u56db\u5904\u53ef\u8fa8\u8bc6\u6027\u7684\u533a\u57df\uff0c\u4f46\u662f\u4eba\u5de5\u6807\u6ce8\u65f6\u53ea\u6807\u6ce8\u4e86\u4e09\u5904\uff0c\u5219\u5728\u6a21\u578b\u7684\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5c31\u4f1a\u5c11\u5b66\u4e60\u4e00\u4e2a\u533a\u57df\uff0c\u6216\u8005\u4eba\u5de5\u6807\u6ce8\u65f6\u533a\u57df\u4f4d\u7f6e\u6807\u6ce8\u7684\u4e0d\u51c6\uff0c\u4e5f\u4f1a\u9650\u5236\u6a21\u578b\u7684\u8bad\u7ec3\uff0c\u5229\u7528\u989d\u5916\u4eba\u5de5\u6807\u6ce8\u7684\u5b66\u4e60\u7b56\u7565\u7edf\u79f0\u4e3a\u5f3a\u76d1\u7763\u5b66\u4e60\u3002\u76f8\u6bd4\u4e8e\u57fa\u4e8e\u5f3a\u76d1\u7763\u5b66\u4e60\u7684\u7b97\u6cd5\uff0c\u57fa\u4e8e\u5f31\u76d1\u7763\u5b66\u4e60\u7684\u65b9\u6cd5\uff08\u53ea\u4f7f\u7528\u56fe\u50cf\u7c7b\u522b\u6807\u7b7e\uff09\u66f4\u9002\u5408\u5b9e\u9645\u7684\u63a8\u5e7f\u5e94\u7528\uff0c\u4e0b\u6587\u6240\u603b\u7ed3\u7684\u5185\u5bb9\u5168\u662f\u57fa\u4e8e\u5f31\u76d1\u7763\u5b66\u4e60\u7684\u7b97\u6cd5\u3002</p>"},{"location":"fine-grained/sum_fine/#_3","title":"\u65b9\u6cd5\u603b\u7ed3","text":""},{"location":"fine-grained/sum_fine/#_4","title":"\u57fa\u4e8e\u6ce8\u610f\u529b","text":"<p>\u2003\u2003\u6ce8\u610f\u529b\u53c8\u5206\u201c\u786c\u201d\u6ce8\u610f\u529b\uff08hard attention\uff09\u548c\u201c\u8f6f\u201d\u6ce8\u610f\u529b\uff08soft attention\uff09\uff0c\u5176\u4e2d\u786c\u6ce8\u610f\u529b\u4fa7\u91cd\u4e8e\u5f97\u5230\u5177\u4f53\u7684\u5173\u952e\u533a\u57df\u4f4d\u7f6e\uff0c\u4f8b\u5982\u8fb9\u754c\u6846\u3001\u5206\u5272\u63a9\u7801\u7b49\u7b49\uff0c\u8f6f\u6ce8\u610f\u529b\u4fa7\u91cd\u4e8e\u5173\u6ce8\u5bf9\u8c61\u7684\u7a7a\u95f4\u5206\u5e03\uff0c\u5f97\u5230\u4e00\u5f20\u6ce8\u610f\u529b\u56fe\uff0c\u6ce8\u610f\u529b\u56fe\u4e0a\u54cd\u5e94\u503c\u7684\u5927\u5c0f\u53cd\u5e94\u4e86\u533a\u57df\u7684\u91cd\u8981\u7a0b\u5ea6\uff0c\u5177\u4f53\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u8be5\u65b9\u6cd5\u7684\u4e3b\u8981\u601d\u8def\u5c31\u662f\u5148\u5f97\u5230\u6ce8\u610f\u529b\u56fe\uff0c\u5b9a\u4f4d\u51fa\u6709\u533a\u5206\u5ea6\u7684\u533a\u57df\uff08discriminative region\uff09\uff0c\u4ee5\u4e0b\u7b80\u79f0\u5173\u952e\u533a\u57df\uff0c\u4e4b\u540e\u57fa\u4e8e\u5b9a\u4f4d\u5230\u7684\u5173\u952e\u533a\u57df\u518d\u6267\u884c\u5176\u4ed6\u7684\u64cd\u4f5c\uff0c\u6700\u5e38\u89c1\u7684\u64cd\u4f5c\u5c31\u662f\u518d\u5206\u7c7b\uff0c\u5229\u7528\u5b50\u533a\u57df\u7684\u5206\u7c7b\u635f\u5931\u63d0\u5347\u6a21\u578b\u7684\u7279\u5f81\u8868\u793a\u80fd\u529b\uff08feature representation\uff09\u3002\u57fa\u4e8e\u6ce8\u610f\u529b\u601d\u60f3\u7684\u7b97\u6cd5\u7814\u7a76\u6700\u5173\u952e\u7684\u5c31\u662f\u89e3\u51b3\uff1a\u5982\u4f55\u83b7\u5f97\u6ce8\u610f\u529b\u8fd9\u4e00\u95ee\u9898\uff0c\u800c\u83b7\u5f97\u6ce8\u610f\u529b\u7684\u9014\u5f84\u4e3b\u8981\u6709\u4e24\u79cd\u65b9\u5f0f\uff1a\u5206\u6790\u7279\u5f81\u6570\u636e\u3001\u5229\u7528\u7279\u5f81\u505a\u9884\u6d4b\u3002\u4e3a\u4e86\u65b9\u4fbf\u8d77\u89c1\uff0c\u5c06\u4e0b\u6587\u4e2d\u4ea7\u751f\u6ce8\u610f\u529b\u7684\u6a21\u5757\u7edf\u79f0\u4e3a\u5b9a\u4f4d\u6a21\u5757\uff0c\u7528\u4e8e\u5b9a\u4f4d\u5173\u952e\u533a\u57df\u3002</p>"},{"location":"fine-grained/sum_fine/#_5","title":"\u5206\u6790\u7279\u5f81\u56fe\u6570\u636e","text":"<p>\u2003\u2003\u8be5\u7c7b\u65b9\u6cd5\u76f8\u5bf9\u6765\u8bf4\u8f83\u4e3a\u7b80\u5355\uff0c\u4e0d\u989d\u5916\u8bbe\u5355\u72ec\u7684\u53c2\u6570\u53bb\u9884\u6d4b\u533a\u57df\uff0c\u53ea\u5206\u6790\u7279\u5f81\u56fe\u6570\u636e\uff0c\u5229\u7528\u67d0\u79cd\u56fa\u5b9a\u7684\u8fd0\u7b97\u89c4\u5219\u8ba1\u7b97\u51fa\u7279\u5f81\u56fe\u7684\u5173\u6ce8\u533a\u57df\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5927\u90e8\u5206\u4f1a\u76f4\u63a5\u5f97\u5230\u8f6f\u6ce8\u610f\u529b\u56fe\u3002</p> <p>\u2003\u2003\u7531\u4e8e\u5377\u79ef\u8fd0\u7b97\u5177\u6709\u5c40\u90e8\u6027\uff0c\u53ea\u5728\u5c40\u90e8\u533a\u57df\u63d0\u53d6\u7279\u5f81\uff0c\u5e76\u4e14\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u5728\u8bad\u7ec3\u7684\u8fc7\u7a0b\u4e2d\u53d7\u5206\u7c7b\u4efb\u52a1\u6240\u9a71\u52a8\uff0c\u6240\u63d0\u53d6\u7684\u7279\u5f81\u548c\u7269\u4f53\u7c7b\u522b\u606f\u606f\u76f8\u5173\uff0c\u56e0\u6b64\u7f51\u7edc\u81ea\u7136\u5730\u4f1a\u5173\u6ce8\u5bf9\u5206\u7c7b\u4efb\u52a1\u6709\u5229\u7684\u533a\u57df\uff0c\u8fd9\u4e5f\u662f\u6211\u4eec\u6240\u719f\u77e5\u7684\u201c\u5206\u7c7b\u7f51\u7edc\u5177\u6709\u4e00\u5b9a\u7684\u5f31\u5b9a\u4f4d\u80fd\u529b\u201d\uff0c\u6211\u4eec\u53ef\u4ee5\u5229\u7528\u8fd9\u4e00\u7279\u70b9\u6765\u83b7\u5f97\u8f6f\u6ce8\u610f\u529b\u56fe\uff0c\u6700\u7b80\u5355\u7684\u65b9\u6cd5\u5c31\u662f\u6cbf\u901a\u9053\u7ef4\u5ea6\u5c06\u7279\u5f81\u56fe\u76f8\u52a0\uff08\u5982\uff1aMMAL\uff09\uff0c\u6216\u8005\u5229\u7528\u89c4\u5b9a\u7684\u516c\u5f0f\u8ba1\u7b97\u7279\u5f81\u56fe\u7684\u76f8\u5173\u6027\uff08\u5982\uff1aTASN\uff09\uff0c\u8fdb\u4e00\u6b65\u5f97\u5230\u8f6f\u6ce8\u610f\u529b\u56fe\uff0c\u6ce8\u610f\u529b\u56fe\u4e0a\u7279\u5f81\u6570\u636e\u7684\u5206\u5e03\u53ef\u4ee5\u770b\u6210\u533a\u57df\u91cd\u8981\u7a0b\u5ea6\uff0c\u6240\u5f97\u7684\u6ce8\u610f\u529b\u56fe\u53ef\u4ee5\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u53cd\u5e94\u7269\u4f53\u7684\u533a\u57df\u5206\u5e03\uff0c\u4f46\u662f\u8fd9\u79cd\u65b9\u6cd5\u53ea\u8003\u8651\u4e86\u7279\u5f81\u6570\u636e\u8fd9\u4e00\u5355\u4e00\u56e0\u7d20\uff0c\u6700\u7ec8\u6548\u679c\u53ef\u80fd\u5e76\u4e0d\u7406\u60f3\u3002</p> <p>\u2003\u2003\u7f51\u7edc\u6240\u63d0\u53d6\u7684\u7279\u5f81\uff0c\u662f\u9762\u5411\u6240\u6709\u7c7b\u522b\u7684\u7279\u5f81\uff0c\u5982\u679c\u53ef\u4ee5\u5c06\u8be5\u7279\u5f81\u8f6c\u5316\u4e3a\u67d0\u4e2a\u5177\u4f53\u7c7b\u522b\u7684\uff0c\u90a3\u4e48\u53ef\u4ee5\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u63d0\u9ad8\u6ce8\u610f\u529b\u56fe\u7684\u5173\u6ce8\u80fd\u529b\uff0c\u6bd4\u5982\u5982\u679c\u4e00\u5f20\u56fe\u4e2d\u662f\u9e1fA\uff0c\u90a3\u4e48\u53ef\u4ee5\u5c06\u6240\u63d0\u53d6\u7684\u7279\u5f81\u8f6c\u5316\u4e3aA\u7c7b\u7279\u5b9a\u7684\u7279\u5f81\uff0c\u5728S3N\u4e2d\uff0c\u4f5c\u8005\u5229\u7528\u5168\u8fde\u63a5\u5c42\u4e2d\u7684\u6743\u91cd\u5bf9\u7279\u5f81\u56fe\u6cbf\u901a\u9053\u65b9\u5411\u505a\u52a0\u6743\u6c42\u548c\uff0c\u751f\u6210\u6240\u6709\u7c7b\u522b\u5bf9\u5e94\u7684\u6ce8\u610f\u529b\u56fe\uff08\u6587\u4e2d\u6307\u54cd\u5e94\u56fe\uff09\uff0c\u6700\u540e\u6839\u636e\u6a21\u578b\u5bf9\u6574\u5f20\u56fe\u7684\u9884\u6d4b\u60c5\u51b5\u6765\u9009\u62e9\u4f7f\u7528\u54ea\u4e2a\u7c7b\u522b\u7684\u6ce8\u610f\u529b\u56fe\u3002</p> <p>\u2003\u2003\u9664\u4e86\u5229\u7528\u6240\u5b66\u7684\u53c2\u6570\uff0c\u8fd8\u53ef\u4ee5\u5229\u7528\u68af\u5ea6\uff0c\u6bd4\u5982\u5728MGE-CNN\u4e2d\uff0c\u4f5c\u8005\u5229\u7528Grad-CAM\u7b97\u6cd5\u6765\u5b9e\u73b0\u5b9a\u4f4d\u529f\u80fd\uff0c\u5c06\u5bf9\u6700\u7ec8\u7684\u7269\u4f53\u5206\u7c7b\u8d21\u732e\u5927\u7684\u7279\u5f81\u533a\u57df\u89c6\u4e3a\u5206\u7c7b\u7684\u5173\u952e\u533a\u57df\uff0c\u5229\u7528\u5377\u79ef\u5c42\u7684\u68af\u5ea6\u4fe1\u606f\u53bb\u7406\u89e3\u6bcf\u4e2a\u795e\u7ecf\u5143\u5bf9\u4e8e\u51b3\u7b56\u7684\u91cd\u8981\u6027\uff0c\u4ece\u800c\u83b7\u5f97\u7279\u5f81\u56fe\u4e2d\u6bcf\u4e2a\u4f4d\u7f6e\u4e0a\u7684\u7279\u5f81\u5bf9\u7269\u4f53\u5206\u7c7b\u7684\u8d21\u732e\uff0c\u8d21\u732e\u5206\u6570\u8d8a\u5927\uff0c\u5219\u8868\u660e\u8be5\u7279\u5f81\u6240\u5bf9\u5e94\u539f\u56fe\u4e0a\u7684\u533a\u57df\u8d8a\u91cd\u8981\uff0c\u6700\u7ec8\u7f51\u7edc\u6839\u636e\u7279\u5f81\u7684\u91cd\u8981\u7a0b\u5ea6\u5212\u5206\u51fa\u7406\u60f3\u7684\u6ce8\u610f\u529b\u5173\u6ce8\u533a\u57df\uff0c\u4e4b\u540e\u518d\u505a\u540e\u7eed\u5904\u7406\u3002</p> <p>\u2003\u2003\u4e0a\u8ff0\u65b9\u6cd5\u7531\u4e8e\u4e0d\u9700\u8981\u8bbe\u7f6e\u989d\u5916\u7684\u635f\u5931\u6765\u76d1\u7763\uff0c\u56e0\u6b64\u5b9e\u73b0\u8d77\u6765\u8f83\u4e3a\u7b80\u5355\u3002\u4f46\u8fd9\u4e00\u7c7b\u65b9\u6cd5\u6709\u4e00\u4e2a\u5f88\u5927\u7684\u7f3a\u70b9\u2014\u2014\u6ce8\u610f\u529b\u56fe\u7684\u751f\u6210\u5177\u6709\u5355\u5411\u4f9d\u8d56\u6027\uff0c\u6240\u5f97\u6ce8\u610f\u529b\u56fe\u7684\u597d\u574f\u5f88\u5927\u7a0b\u5ea6\u4e0a\u4f9d\u8d56\u4e8e\u7f51\u7edc\u7684\u7279\u5f81\u63d0\u53d6\u80fd\u529b\uff0c\u5982\u679c\u7f51\u7edc\u7279\u5f81\u63d0\u53d6\u80fd\u529b\u597d\uff0c\u90a3\u4e48\u81ea\u7136\u5c31\u4f1a\u5f97\u5230\u5f88\u597d\u7684\u5b9a\u4f4d\u7ed3\u679c\uff0c\u4f46\u7ec6\u7c92\u5ea6\u5206\u7c7b\u4e2d\uff0c\u7531\u4e8e\u7c7b\u4e4b\u95f4\u7269\u4f53\u5dee\u5f02\u5f88\u5c0f\uff0c\u7f51\u7edc\u5f88\u96be\u76f4\u63a5\u63d0\u53d6\u5230\u6709\u7528\u7684\u7279\u5f81\uff0c\u56e0\u6b64\u53ea\u901a\u8fc7\u5206\u6790\u7279\u5f81\u56fe\u6570\u636e\u505a\u5b9a\u4f4d\u7684\u8bdd\uff0c\u5b9a\u4f4d\u6548\u679c\u5e76\u4e0d\u660e\u663e\u3002</p>"},{"location":"fine-grained/sum_fine/#_6","title":"\u5229\u7528\u7279\u5f81\u505a\u9884\u6d4b","text":"<p>\u2003\u2003\u8be5\u65b9\u6cd5\u76f8\u5bf9\u6765\u8bf4\u8f83\u4e3a\u9ad8\u6548\uff0c\u901a\u8fc7\u8bbe\u5b9a\u989d\u5916\u7684\u5b9a\u4f4d\u6a21\u5757\u6765\u4e13\u95e8\u505a\u5173\u952e\u533a\u57df\u7684\u5b9a\u4f4d\uff0c\u5229\u7528\u7279\u5f81\u56fe\u6570\u636e\u6765\u505a\u9884\u6d4b\uff0c\u5b9a\u4f4d\u51fa\u533a\u5206\u5ea6\u9ad8\u7684\u533a\u57df\uff0c\u540c\u65f6\u5982\u679c\u5b9a\u4f4d\u6a21\u5757\u53ef\u4ee5\u548c\u540e\u7eed\u5b50\u5206\u7c7b\u6a21\u5757\u76f8\u8054\u7cfb\u8d77\u6765\uff0c\u5219\u53ef\u4ee5\u8d77\u5230\u53cc\u5411\u4f18\u5316\u7684\u4f5c\u7528\uff0c\u7f51\u7edc\u533a\u57df\u5b9a\u4f4d\u80fd\u529b\u7684\u5b66\u4e60\u548c\u7279\u5f81\u63d0\u53d6\u80fd\u529b\u7684\u5b66\u4e60\u53ef\u4ee5\u4e92\u76f8\u4fc3\u8fdb\u3001\u4e92\u76f8\u63d0\u5347\u3002\uff08\u76f8\u5f53\u4e8e\u5f15\u5165\u6ce8\u610f\u529b\u673a\u5236\uff09</p>"},{"location":"fine-grained/sum_fine/#_7","title":"\u786c\u6ce8\u610f\u529b","text":"<p>\u2003\u2003\u56e0\u4e3a\u786c\u6ce8\u610f\u529b\u6240\u4f53\u73b0\u7684\u5f62\u5f0f\u5927\u591a\u4e3a\u79bb\u6563\u5206\u5e03\u7684\u5750\u6807\u70b9\u6216\u8005\u63a9\u6a21\u56fe\uff0c\u6570\u636e\u5206\u5e03\u4e0d\u8fde\u7eed\uff0c\u56e0\u6b64\u5982\u679c\u9700\u8981\u7f51\u7edc\u6765\u9884\u6d4b\u786c\u6ce8\u610f\u529b\uff0c\u5219\u9762\u4e34\u4e00\u4e2a\u95ee\u9898\u2014\u2014\u9700\u8981\u5bf9\u5b9a\u4f4d\u6a21\u5757\u505a\u76d1\u7763\uff0c\u5355\u7eaf\u53ea\u7528\u5206\u7c7b\u635f\u5931\u7684\u8bdd\u65e0\u6cd5\u4f18\u5316\u5b9a\u4f4d\u6a21\u5757\uff0c\u6240\u5b9a\u4f4d\u7684\u533a\u57df\u5f88\u96be\u8fbe\u5230\u7406\u60f3\u7684\u6548\u679c\uff0c\u4f46\u7531\u4e8e\u5f31\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u6ca1\u6709\u989d\u5916\u7684\u6807\u6ce8\uff0c\u56e0\u6b64\u4e0d\u80fd\u76f4\u63a5\u4f5c\u76d1\u7763\uff0c\u56e0\u6b64\u5728\u8bbe\u5b9a\u5b9a\u4f4d\u6a21\u5757\u7684\u540c\u65f6\uff0c\u9700\u8981\u6316\u6398\u9690\u542b\u7684\u5173\u7cfb\u6761\u4ef6\uff0c\u8fdb\u4e00\u6b65\u8bbe\u5b9a\u989d\u5916\u7684\u635f\u5931\u53bb\u4f18\u5316\u5b9a\u4f4d\u6a21\u5757\u7684\u53c2\u6570\u3002</p> <p>\u2003\u2003\u5728RA-CNN\u4e2d\uff0c\u4f5c\u8005\u76f4\u63a5\u5728\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u4e2d\u5d4c\u5165\u591a\u5c42\u611f\u77e5\u673a\uff08\u5373\u7ebf\u6027\u56de\u5f52\u5c42\uff09\uff0c\u56de\u5f52\u51fa\u53ef\u4ee5\u5b9a\u4f4d\u5bf9\u8c61\u533a\u57df\u7684\u5750\u6807\u70b9\uff08\u5373\u533a\u5206\u5bf9\u8c61\u7684\u5173\u952e\u533a\u57df\uff09\uff0c\u4e3a\u4e86\u4f7f\u8be5\u6a21\u5757\u53ef\u4ee5\u5f97\u5230\u6709\u6548\u5730\u76d1\u7763\uff0c\u8fd9\u91cc\u5f97\u5230\u5750\u6807\u70b9\u540e\u4e0d\u76f4\u63a5\u5bf9\u539f\u56fe\u505a\u88c1\u526a\uff0c\u5148\u5229\u7528\u4e8c\u7ef4\u8109\u51b2\u51fd\u6570\u8fd1\u4f3c\u51fa\u56db\u4e2a\u5750\u6807\u70b9\u6240\u4ee3\u8868\u7684\u533a\u57df\uff0c\u76f8\u5f53\u4e8e\u5c06\u56de\u5f52\u5f97\u5230\u7684\u5750\u6807\u70b9\u8f6c\u5316\u6210\u4e00\u5f20\u6ce8\u610f\u529b\u56fe\uff08\u56db\u4e2a\u5750\u6807\u70b9\u6570\u636e\u5316\u4e3a\u4e00\u5f20\u6570\u636e\u8fde\u7eed\u5206\u5e03\u7684\u56fe\uff09\uff0c\u4e4b\u540e\u518d\u5c06\u8fd9\u5f20\u56fe\u4e0e\u539f\u56fe\u76f8\u4e58\uff0c\u5b9a\u4f4d\u51fa\u5173\u6ce8\u7684\u533a\u57df\uff0c\u5c06\u56de\u5f52\u51fa\u6765\u7684\u5750\u6807\u4e0e\u539f\u59cb\u7279\u5f81\u56fe\u5f3a\u52a0\u5173\u8054\uff0c\u5982\u679c\u76f4\u63a5\u88c1\u526a\u7684\u8bdd\u524d\u5411\u4f20\u64ad\u662f\u95f4\u65ad\u7684\uff0c\u68af\u5ea6\u65e0\u6cd5\u4f20\u56de\u6765\uff0c\u4e5f\u5c31\u662f\u540e\u7eed\u7684\u64cd\u4f5c\u65e0\u6cd5\u5f71\u54cd\u56de\u5f52\u5c42\u5bf9\u5173\u952e\u533a\u57df\u7684\u5b9a\u4f4d\u3002\u5173\u8054\u540e\u7684\u56fe\u7247\u5728\u53cd\u5411\u4f20\u64ad\u7684\u8fc7\u7a0b\u4e2d\u5b58\u5728\u4e00\u4e2a\u68af\u5ea6\u4f20\u9012\u7684\u8fc7\u7a0b\uff0c\u5373\u7ecf\u8fc7\u6ce8\u610f\u529b\u8fd1\u4f3c\u64cd\u4f5c\u53ef\u4ee5\u8ba9\u540e\u7eed\u7684\u7f51\u7edc\u77e5\u9053\u8fd9\u4e2a\u533a\u57df\u662f\u5982\u4f55\u88ab\u5b9a\u4f4d\u7684\uff0c\u6700\u7ec8\u7684\u56fe\u7247\u5206\u7c7b\u635f\u5931\u4ee5\u53ca\u5c3a\u5ea6\u95f4\u7684\u6392\u5e8f\u635f\u5931\u53ef\u4ee5\u7ecf\u8fc7\u53cd\u5411\u4f20\u64ad\u6765\u4f18\u5316\u5b9a\u4f4d\u6a21\u5757\uff0c\u4e5f\u5c31\u662f\u4f18\u5316\u90a3\u51e0\u5c42\u7ebf\u6027\u56de\u5f52\u4e2d\u7684\u53c2\u6570\u3002\u8fd9\u91cc\u5f88\u50cf\u81ea\u6ce8\u610f\u529b\u64cd\u4f5c\uff08self-attention\uff09\uff0c\u5229\u7528\u7279\u5f81\u56fe\u751f\u6210\u6ce8\u610f\u529b\u56fe\uff08\u4ee5\u5750\u6807\u4e3a\u4e2d\u4ecb\uff09\uff0c\u6ce8\u610f\u529b\u56fe\u518d\u53cd\u4f5c\u7528\u4e8e\u7279\u5f81\u56fe\u3002</p> <p> <p></p> <p></p> <p>\u2003\u2003\u60f3\u8981\u83b7\u5f97\u5173\u952e\u533a\u57df\u7684\u8fb9\u754c\u6846\u5750\u6807\uff0c\u4e5f\u53ef\u4ee5\u53c2\u8003\u76ee\u6807\u68c0\u6d4b\u4e2d\u6ed1\u52a8\u7a97\u53e3\u7684\u601d\u60f3\uff0c\u5728NTS-Net\u4e2d\uff0c\u4f5c\u8005\u5229\u7528\u6ed1\u52a8\u7a97\u53e3\u53bb\u68c0\u6d4b\u533a\u57df\uff0c\u7c7b\u4f3cFaster R-CNN\u4e2d\u7684RPN\u6a21\u5757\uff0c\u5148\u9884\u8bbe\u4e00\u7ec4\u951a\u70b9\u6846\uff0c\u4e4b\u540e\u9884\u6d4b\u51fa\u6bcf\u4e2a\u951a\u70b9\u6846\u7684\u5206\u6570\uff08\u8fd9\u91cc\u5c31\u662f\u5b9a\u4f4d\u6a21\u5757\uff09\uff0c\u6ce8\u610f\uff0c\u7531\u4e8e\u6ca1\u6709\u771f\u5b9e\u533a\u57df\u6807\u7b7e\uff0c\u56e0\u6b64\u8fd9\u91cc\u53ea\u9884\u6d4b\u5206\u6570\uff0c\u4e0d\u9884\u6d4b\u8fb9\u754c\u6846\u56de\u5f52\u53c2\u6570\uff0c\u53ea\u80fd\u5229\u7528\u951a\u70b9\u9884\u8bbe\u7684\u60c5\u51b5\uff0c\u9884\u6d4b\u51fa\u5927\u6982\u7684\u4f4d\u7f6e\uff0c\u5e76\u4e14\u5206\u6570\u8d8a\u9ad8\u8868\u660e\u5b50\u533a\u57df\u5bf9\u6700\u7ec8\u7684\u5206\u7c7b\u60c5\u51b5\u8d8a\u6709\u5229\uff08\u8d8a\u5173\u952e\uff09\uff0c\u4e4b\u540e\u6309\u5206\u6570\u5927\u5c0f\u9009\u62e9\u540e\u7eed\u5b50\u533a\u57df\u3002\u95ee\u9898\u7684\u6838\u5fc3\u5c31\u5728\u4e8e\u5982\u4f55\u4f18\u5316\u5b9a\u4f4d\u6a21\u5757\uff0c\u4e5f\u5c31\u662f\u4f18\u5316\u951a\u70b9\u6253\u5206\u6a21\u5757\uff0c\u8ba9\u6253\u5206\u6a21\u5757\u5206\u6570\u6253\u7684\u66f4\u51c6\uff0c\u5206\u6570\u8d8a\u51c6\uff0c\u8bf4\u660e\u540e\u7eed\u9884\u6d4b\u60c5\u51b5\u4e0e\u6240\u6253\u7684\u5206\u6570\u8d8a\u5177\u6709\u6b63\u76f8\u5173\u6027\uff0c\u5373\u5982\u679c\u5206\u6570\u8d8a\u5927\uff0c\u5219\u6b63\u786e\u7c7b\u522b\u7684\u9884\u6d4b\u6982\u7387\u5e94\u5f53\u8d8a\u5927\uff0c\u56e0\u6b64\u53ef\u4ee5\u6839\u636e\u8fd9\u4e00\u6761\u4ef6\uff0c\u7b5b\u9009\u51fa\u6307\u5b9a\u7684\u533a\u57df\u5206\u6570\uff0c\u5229\u7528\u5206\u6570\u4e4b\u95f4\u7684\u6392\u5e8f\u635f\u5931\u5bf9\u539f\u6a21\u5757\u505a\u4f18\u5316\uff0c\u68af\u5ea6\u4f1a\u6cbf\u5206\u6570\u4ea7\u751f\u7684\u8def\u5f84\u4f20\u56de\u5b9a\u4f4d\u6a21\u5757\uff0c\u4ece\u800c\u4f18\u5316\u5b9a\u4f4d\u6a21\u5757\uff0c\u4f7f\u5176\u6253\u7684\u5206\u6570\u548c\u5b50\u7f51\u7edc\u9884\u6d4b\u6982\u7387\u987a\u5e8f\u4e00\u81f4\u3002</p> <p> <p></p> <p></p> <p>\u6ce8\uff1a\u5728\u7279\u5f81\u56fe\u4e0a\u9884\u8bbe\u68c0\u6d4b\u7a97\u53e3\u7684\u601d\u60f3\u5728MMAL\u7b97\u6cd5\u4e2d\u4e5f\u6709\u6240\u5e94\u7528\uff0c\u4e0d\u8fc7\u4e3a\u4e86\u907f\u514d\u4f18\u5316\u9ebb\u70e6\uff0c\u8be5\u7b97\u6cd5\u5229\u7528\u5168\u5377\u79ef\u5c42\uff08full convolutional\uff09\u6765\u5b9e\u73b0\u6ed1\u52a8\u7a97\u53e3\uff0c\u53ea\u6839\u636e\u5377\u79ef\u63d0\u53d6\u5230\u7684\u7279\u5f81\u6570\u636e\u6765\u51b3\u5b9a\u54ea\u4e2a\u7a97\u53e3\u4ee3\u8868\u7684\u533a\u57df\u4e3a\u5173\u952e\u533a\u57df\u3002\uff08\u8be5\u65b9\u6cd5\u53ea\u9700\u8981\u5206\u6790\u7279\u5f81\u56fe\u6570\u636e\uff0c\u53ef\u5229\u7528\u6c60\u5316\u64cd\u4f5c\u5b9e\u73b0\u7279\u5f81\u7684\u5c40\u90e8\u6c42\u5747\u503c\u76ee\u7684\uff09</p> <p>\u2003\u2003\u5bf9\u4e8e\u786c\u6ce8\u610f\u529b\uff0c\u6700\u4e3b\u8981\u7684\u5c31\u662f\u8868\u793a\u51fa\u5173\u952e\u533a\u57df\uff0c\u4e4b\u540e\u518d\u5355\u72ec\u5bf9\u5173\u952e\u533a\u57df\u505a\u7279\u5f81\u63d0\u53d6\u3001\u5206\u7c7b\u64cd\u4f5c\uff0c\u63d0\u5347\u7f51\u7edc\u7684\u7279\u5f81\u63d0\u53d6\u80fd\u529b\u3002\u4f46\u662f\u8981\u6ce8\u610f\u4e00\u4e2a\u6838\u5fc3\u70b9\uff1a\u4e00\u5b9a\u8981\u6709\u635f\u5931\u80fd\u591f\u4f18\u5316\u5230\u5b9a\u4f4d\u6a21\u5757\u3002\u5e38\u89c1\u7684\u88c1\u526a\u64cd\u4f5c\u5c5e\u4e8e\u95f4\u65ad\u64cd\u4f5c\uff0c\u5b50\u533a\u57df\u5206\u652f\u53ea\u4f1a\u770b\u5230\u88c1\u526a\u540e\u7684\u7279\u5f81\uff0c\u4e0d\u4f1a\u770b\u5230\u88c1\u526a\u5750\u6807\uff0c\u56e0\u6b64\u5b50\u533a\u57df\u5206\u7c7b\u635f\u5931\u6240\u4ea7\u751f\u7684\u7684\u68af\u5ea6\u4e0d\u4f1a\u6cbf\u7740\u5750\u6807\u56de\u4f20\uff08\u8fd9\u6761\u8def\u4e2d\u5206\u7c7b\u635f\u5931\u4ea7\u751f\u7684\u5f71\u54cd\u5c31\u56de\u4e0d\u5230\u5b9a\u4f4d\u6a21\u5757\u4e86\uff09\uff0c\u53ea\u80fd\u6cbf\u7740\u7279\u5f81\u56de\u4f20\uff0c\u4e00\u5b9a\u8981\u634b\u6e05\u6982\u5ff5\u3002\u5f53\u5b50\u533a\u57df\u5206\u7c7b\u7ed3\u679c\u53ef\u4ee5\u548c\u5b9a\u4f4d\u6a21\u5757\u5efa\u7acb\u201c\u8fde\u7eed\u201d\u7684\u8054\u7cfb\uff0c\u5373\u5b50\u5206\u652f\u53ef\u4ee5\u201c\u770b\u201d\u5230\u5b50\u533a\u57df\u7684\u5b9a\u4f4d\u8fc7\u7a0b\u65f6\uff0c\u7f51\u7edc\u7684\u8bad\u7ec3\u5c31\u53ef\u4ee5\u8d77\u5230\u53cc\u5411\u4f18\u5316\u7684\u4f5c\u7528\uff0c\u5373\u5b9a\u4f4d\u7684\u5b66\u4e60\u4f18\u5316\u5206\u7c7b\u7684\u5b66\u4e60\uff08\u6216\u7ec6\u7c92\u5ea6\u7279\u5f81\u8868\u793a\u7684\u5b66\u4e60\uff09\uff0c\u5e76\u4e14\u5206\u7c7b\u7684\u5b66\u4e60\u53cd\u8fc7\u6765\u4fc3\u8fdb\u5b9a\u4f4d\u7684\u5b66\u4e60\uff0c\u5173\u952e\u5c31\u662f\u627e\u6865\u6881\uff0c\u601d\u8003\u5982\u4f55\u8fde\u63a5\u4e24\u4e2a\u90e8\u5206\u3002</p>"},{"location":"fine-grained/sum_fine/#_8","title":"\u8f6f\u6ce8\u610f\u529b","text":"<p>\u2003\u2003\u8f6f\u6ce8\u610f\u529b\u76f8\u6bd4\u786c\u6ce8\u610f\u529b\u6765\u8bf4\uff0c\u66f4\u5bb9\u6613\u4f18\u5316\uff0c\u56e0\u4e3a\u8f6f\u6ce8\u610f\u529b\u4fa7\u91cd\u4e8e\u751f\u6210\u6ce8\u610f\u529b\u56fe\uff0c\u6ce8\u610f\u529b\u56fe\u4e0a\u7684\u54cd\u5e94\u6570\u503c\u90fd\u662f\u8fde\u7eed\u5206\u5e03\u7684\uff0c\u53ea\u4f7f\u7528\u5206\u7c7b\u635f\u5931\u4e5f\u53ef\u4ee5\u5bf9\u5b9a\u4f4d\u6a21\u5757\u8d77\u5230\u4e00\u5b9a\u7684\u76d1\u7763\u4f5c\u7528\uff0c\u4f7f\u5f97\u5b9a\u4f4d\u6a21\u5757\u6240\u5173\u6ce8\u7684\u90e8\u5206\u662f\u5bf9\u6700\u540e\u5206\u7c7b\u6709\u7528\u7684\u533a\u57df\uff0cCNN\u4e2d\u6700\u5e38\u7528\u81ea\u6ce8\u610f\u529b\u673a\u5236\u6765\u751f\u6210\u8f6f\u6ce8\u610f\u529b\u56fe\uff0c\u5982CBAM\u7b97\u6cd5\u4e2d\u7684\u901a\u9053\u6ce8\u610f\u529b\u548c\u7a7a\u95f4\u6ce8\u610f\u529b\u3002\u5728\u7ec6\u7c92\u5ea6\u5206\u7c7b\u4e2d\uff0c\u81ea\u6ce8\u610f\u529b\u673a\u5236\u5f80\u5f80\u4e0d\u4f1a\u76f4\u63a5\u62ff\u6765\u7528\uff0c\u8fd8\u9700\u8981\u7ed3\u5408\u5176\u4ed6\u7684\u635f\u5931\u505a\u8f85\u52a9\u4f18\u5316\uff0c\u4ece\u800c\u8fbe\u5230\u66f4\u597d\u7684\u5173\u6ce8\u6548\u679c\u3002</p> <p>\u2003\u2003\u60f3\u8981\u9274\u5b9a\u4e00\u4e2a\u7c7b\u522b\u5f80\u5f80\u9700\u8981\u4f9d\u9760\u591a\u4e2a\u5173\u952e\u533a\u57df\uff0c\u56e0\u6b64\u9700\u8981\u7f51\u7edc\u53ef\u4ee5\u5b9a\u4f4d\u591a\u4e2a\u533a\u57df\uff0c\u5bf9\u5e94\u751f\u6210\u591a\u4e2a\u6ce8\u610f\u529b\u56fe\uff0c\u5728MA-CNN\u4e2d\uff0c\u4f5c\u8005\u8bbe\u7f6e\u4e86\u591a\u4e2a\u6ce8\u610f\u529b\u5206\u652f\uff0c\u540c\u65f6\u751f\u6210\u591a\u5f20\u6ce8\u610f\u529b\u56fe\u53bb\u5173\u6ce8\u5173\u952e\u533a\u57df\u3002\u6bcf\u4e2a\u5206\u652f\u8bbe\u7f6e\u5168\u8fde\u63a5\u5c42\uff0c\u5c06\u7279\u5f81\u5411\u91cf\uff08\u5168\u5c40\u5e73\u5747\u6c60\u5316\u540e\uff09\u4f20\u5165\u5168\u8fde\u63a5\u5c42\u9884\u6d4b\u51fa\u4e00\u7ec4\u6743\u91cd\uff0c\u7279\u5f81\u56fe\u518d\u6cbf\u901a\u9053\u65b9\u5411\u52a0\u6743\u6c42\u548c\uff0c\u5f97\u5230\u6ce8\u610f\u529b\u56fe\uff0c\u5b9a\u4f4d\u7684\u6838\u5fc3\u5c31\u5728\u4e8e\u9884\u6d4b\u6743\u91cd\u7684\u5168\u8fde\u63a5\u5c42\uff0c\u901a\u8fc7\u9002\u5f53\u5730\u52a0\u6743\u6c42\u548c\u53ef\u4ee5\u4f7f\u7279\u5f81\u56fe\u5173\u6ce8\u6b63\u786e\u7684\u533a\u57df\u3002\u5982\u679c\u53ea\u4f7f\u7528\u5206\u7c7b\u635f\u5931\u7684\u8bdd\uff0c\u591a\u4e2a\u6ce8\u610f\u529b\u56fe\u5fc5\u7136\u6709\u91cd\u53e0\u7684\u5173\u6ce8\u533a\u57df\uff0c\u56e0\u4e3a\u6240\u6709\u5206\u652f\u90fd\u671d\u7740\u6709\u5229\u4e8e\u5206\u7c7b\u7684\u5730\u65b9\u5173\u6ce8\uff0c\u4e0d\u77e5\u9053\u5176\u4ed6\u5206\u652f\u7684\u5173\u6ce8\u60c5\u51b5\uff0c\u5373\u5206\u652f\u4e4b\u95f4\u662f\u72ec\u7acb\u65e0\u8054\u7cfb\u7684\uff0c\u56e0\u6b64\u4f5c\u8005\u8bbe\u8ba1\u4e86\u5206\u7ec4\u635f\u5931\u4f7f\u5206\u652f\u4e4b\u95f4\u5efa\u7acb\u8d77\u8054\u7cfb\uff0c\u8f85\u52a9\u76d1\u7763\u5b9a\u4f4d\u6a21\u5757\uff0c\u9f13\u52b1\u5176\u4ea7\u751f\u7684\u6743\u91cd\u53ef\u4ee5\u4f7f\u5c40\u90e8\u6ce8\u610f\u529b\u56fe\u5177\u6709\u591a\u6837\u6027\u3001\u7d27\u51d1\u6027\u7684\u7279\u70b9\u3002</p> <p> <p></p> <p></p> <p>\u2003\u2003\u9664\u4e86\u4f7f\u591a\u5f20\u6ce8\u610f\u529b\u56fe\u66f4\u52a0\u7d27\u51d1\u591a\u6837\uff0c\u8fd8\u6709\u4e00\u79cd\u76d1\u7763\u65b9\u6cd5\u5c31\u662f\u5bf9\u4e8e\u4e0d\u540c\u7684\u56fe\u7247\uff0c\u4f7f\u76f8\u540c\u7684\u6ce8\u610f\u529b\u56fe\u53bb\u5173\u6ce8\u76f8\u540c\u7684\u90e8\u4f4d\u3002Cross-X\u4e2d\u5f15\u5165\u4e86OSME\u6a21\u5757\uff08\u51fa\u81ea\u8bba\u6587MAMC\uff09\uff0c\u548cMA-CNN\u7c7b\u4f3c\uff0c\u8bbe\u8ba1\u591a\u4e2a\u5168\u8fde\u63a5\u5c42\uff0c\u901a\u8fc7\u751f\u6210\u6743\u91cd\u5bf9\u539f\u59cb\u7279\u5f81\u56fe\u6cbf\u901a\u9053\u65b9\u5411\u505a\u52a0\u6743\u64cd\u4f5c\uff0c\u5f97\u5230\u591a\u7ec4\u65b0\u7279\u5f81\uff0c\u6587\u4e2d\u6307\u6fc0\u52b1\u5757\u3002\u4e3a\u4e86\u9f13\u52b1\u76f8\u540c\u7684\u6fc0\u52b1\u5757\u53bb\u5173\u6ce8\u76f8\u540c\u7684\u90e8\u4f4d\uff0c\u5373\u5177\u6709\u76f8\u540c\u7684\u8bed\u4e49\u4fe1\u606f\uff0c\u4f5c\u8005\u5229\u7528\u76f8\u5173\u6027\u77e9\u9635\u6765\u8861\u91cf\u4e0d\u540c\u6fc0\u52b1\u6a21\u5757\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6\uff0c\u76f8\u4f3c\u5ea6\u9ad8\u7684\u6fc0\u52b1\u5757\u8868\u793a\u5173\u6ce8\u533a\u57df\u7c7b\u4f3c\uff0c\u5728\u540c\u4e00batch\u5185\uff0c\u901a\u8fc7\u63d0\u9ad8\u76f8\u540c\u6fc0\u52b1\u5757\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6\u4ee5\u53ca\u964d\u4f4e\u4e0d\u540c\u6fc0\u52b1\u5757\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6\u6765\u9f13\u52b1\u76f8\u540c\u7684\u6fc0\u52b1\u6a21\u5757\u53bb\u5173\u6ce8\u76f8\u540c\u7684\u90e8\u4f4d\uff0cWS-DAN\u4e2d\u7684\u6ce8\u610f\u529b\u6b63\u5219\u5316\u635f\u5931\u4e5f\u6709\u7c7b\u4f3c\u7684\u76ee\u7684\u3002</p> <p>\u2003\u2003\u603b\u800c\u8a00\u4e4b\uff0c\u5b9a\u4f4d\u6a21\u5757\u5343\u7bc7\u4e00\u5f8b\uff0c\u751f\u6210\u6ce8\u610f\u529b\u56fe\u7684\u65b9\u6cd5\u6709\u5f88\u591a\uff0c\u7b80\u5355\u5230\u4e00\u5c42\u5377\u79ef\u5c31\u53ef\u4ee5\u5b9e\u73b0\uff08\u5982WS-DAN\uff09\uff0c\u5b9a\u4f4d\u6a21\u5757\u7684\u4f18\u5316\u624d\u662f\u6838\u5fc3\uff0c\u9700\u8981\u59cb\u7ec8\u56f4\u7ed5\u4e00\u4e2a\u601d\u60f3\uff1a\u60f3\u8981\u4f7f\u6ce8\u610f\u529b\u56fe\u8fbe\u5230\u4ec0\u4e48\u6837\u7684\u5173\u6ce8\u6548\u679c\uff0c\u5c31\u9700\u8981\u5bf9\u5e94\u8bbe\u8ba1\u4ec0\u4e48\u6837\u7684\u635f\u5931\u505a\u8f85\u52a9\u4f18\u5316\uff0c\u5355\u51ed\u5206\u7c7b\u635f\u5931\u4e0d\u6613\u4f7f\u6ce8\u610f\u529b\u8fbe\u5230\u7406\u60f3\u7684\u6548\u679c\u3002</p> <p>\u2003\u2003\u5f97\u5230\u8f6f\u6ce8\u610f\u529b\u56fe\u4e4b\u540e\uff0c\u53ef\u4ee5\u6267\u884c\u591a\u79cd\u64cd\u4f5c\uff1a</p> <ul> <li>\u53ef\u4ee5\u5c06\u6ce8\u610f\u529b\u56fe\u4e0e\u7279\u5f81\u56fe\u505a\u70b9\u4e58\u64cd\u4f5c\uff0c\u5f3a\u5316\u6240\u5173\u6ce8\u533a\u57df\u7684\u7279\u5f81\uff0c\u6291\u5236\u65e0\u5173\u533a\u57df\u7684\u7279\u5f81\uff0c\u5e76\u4e14\u524d\u5411\u4f20\u64ad\u662f\u8fde\u7eed\u7684\uff0c\u56e0\u6b64\u533a\u57df\u5b9a\u4f4d\u7684\u5b66\u4e60\u548c\u7279\u5f81\u8868\u793a\u7684\u5b66\u4e60\u53ef\u4ee5\u76f8\u4e92\u4fc3\u8fdb\uff1b</li> <li>\u53ef\u4ee5\u8f6c\u5316\u4e3a\u786c\u6ce8\u610f\u529b\uff0c\u5982MGE-CNN\u3001WS-DAN\u4e2d\u8bbe\u5b9a\u4e00\u4e2a\u9608\u503c\uff0c\u5c06\u54cd\u5e94\u503c\u5927\u4e8e\u9608\u503c\u7684\u533a\u57df\u5212\u5206\u51fa\u6765\uff0cMA-CNN\u4e2d\u9009\u53d6\u5cf0\u503c\u54cd\u5e94\u5750\u6807\u4f5c\u4e3a\u4e2d\u5fc3\uff0c\u88c1\u526a\u51fa\u4e00\u4e2a\u77e9\u5f62\u6846\u4f5c\u4e3a\u5b50\u533a\u57df\u3002\u4f46\u662f\u8f6c\u4e3a\u786c\u6ce8\u610f\u529b\u7684\u8fc7\u7a0b\u662f\u4e0d\u662f\u201c\u8fde\u7eed\u201d\u7684\uff0c\u662f\u95f4\u65ad\u7684\uff0c\u56e0\u6b64\u540e\u7eed\u5b50\u533a\u57df\u7684\u5206\u7c7b\u635f\u5931\u4e0d\u4f1a\u5f71\u54cd\u5b9a\u4f4d\u8fc7\u7a0b\u3002\uff08\u5212\u5206\u533a\u57df\u65f6\u7528\u5230\u5927\u4e8e\u8fd0\u7b97\uff0c\u5e76\u4e14\u5cf0\u503c\u54cd\u5e94\u70b9\u662f\u76f4\u63a5\u9009\u53d6\uff0c\u4e8c\u8005\u51fd\u6570\u90fd\u4e0d\u8fde\u7eed\uff0c\u65e0\u6cd5\u6c42\u5bfc\uff09\uff1b</li> <li>\u53ef\u4ee5\u53c2\u8003B-CNN\u4e2d\u7684\u53cc\u7ebf\u6027\u6c60\u5316\u64cd\u4f5c\uff0c\u5145\u5206\u5c06\u6bcf\u5f20\u6ce8\u610f\u529b\u56fe\u548c\u7279\u5f81\u56fe\u878d\u5408\uff08\u4e5f\u5c31\u662f\u6240\u6709\u6ce8\u610f\u529b\u56fe\u9010\u4e00\u548c\u6240\u6709\u7279\u5f81\u76f8\u4e58\uff0c\u518d\u5168\u5c40\u6c60\u5316\uff09\uff0c\u4e4b\u540e\u4f20\u5165\u5168\u8fde\u63a5\u505a\u8fd0\u7b97\uff0c\u4f8b\u5982WS-DAN\u7b97\u6cd5\uff0c\u4f46\u662f\u53cc\u7ebf\u6027\u6c60\u5316\u6709\u4e2a\u7f3a\u70b9\uff0c\u751f\u6210\u7684\u6570\u636e\u7ef4\u5ea6\u8fc7\u5927\uff0c\u5168\u8fde\u63a5\u5c42\u53c2\u6570\u8fc7\u5927\uff0c\u4e0d\u6613\u4f18\u5316\uff0c\u5bb9\u6613\u8fc7\u62df\u5408\uff0c\u5bf9\u6b64\u53ef\u53c2\u8003Graph-based\u7b97\u6cd5\uff0c\u5229\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u505a\u5316\u7b80\u64cd\u4f5c\uff1b</li> <li>\u53ef\u4ee5\u505a\u975e\u5747\u5300\u91c7\u6837\uff0c\u653e\u5927\u5c40\u90e8\u7684\u5173\u952e\u533a\u57df\uff0c\u5982S3N\u548cTASN\uff0c\u4f46\u8fd9\u4e24\u4e2a\u7b97\u6cd5\u7684\u91c7\u6837\u8fc7\u7a0b\u90fd\u662f\u95f4\u65ad\u7684\uff0c\u56e0\u6b64\u6ce8\u610f\u529b\u56fe\u7684\u751f\u6210\u53ea\u80fd\u901a\u8fc7\u5206\u6790\u7279\u5f81\u6570\u636e\u5f97\u5230\u3002</li> </ul> <p>\u8865\u5145\uff1a</p> <ul> <li>\u4e3a\u4e86\u8fdb\u4e00\u6b65\u63d0\u5347\u6ce8\u610f\u529b\u7684\u5173\u6ce8\u80fd\u529b\uff0c\u4f7f\u7f51\u7edc\u63d0\u4f9b\u66f4\u6709\u6548\u7684\u6ce8\u610f\u529b\u56fe\uff0c\u5728CAL\u4e2d\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56e0\u679c\u63a8\u7406\u7684\u53cd\u4e8b\u5b9e\u6ce8\u610f\u529b\u5b66\u4e60\u65b9\u6cd5\uff08\u53cd\u4e8b\u5b9e\u6ce8\u610f\u529b\u4e5f\u5c31\u662f\u968f\u673a\u751f\u6210\u7684\u6ce8\u610f\u529b\u56fe\uff09\uff0c\u53ef\u4ee5\u8ba9\u7f51\u7edc\u5b66\u5230\u66f4\u6709\u6548\u7684\u6ce8\u610f\u529b\uff0c\u901a\u8fc7\u6bd4\u8f83\u4e8b\u5b9e\u6ce8\u610f\u529b\u548c\u53cd\u4e8b\u5b9e\u6ce8\u610f\u529b\u5bf9\u6700\u7ec8\u7684\u5f71\u54cd\u6765\u8bc4\u4f30\u6ce8\u610f\u529b\u7684\u8d28\u91cf\uff0c\u540c\u65f6\u6700\u5927\u5316\u4e8c\u8005\u7684\u5dee\u5f02\u6765\u9f13\u52b1\u7f51\u7edc\u5b66\u4e60\u66f4\u6709\u6548\u7684\u89c6\u89c9\u6ce8\u610f\u529b\uff08\u6700\u5927\u5316\u6b63\u5e38\u6ce8\u610f\u529b\u56fe\u548c\u968f\u673a\u751f\u6210\u6ce8\u610f\u529b\u56fe\u4e4b\u95f4\u7684\u9884\u6d4b\u5dee\u5f02\uff09\u3002</li> </ul>"},{"location":"fine-grained/sum_fine/#_9","title":"\u57fa\u4e8e\u591a\u5c3a\u5ea6\u7279\u5f81","text":"<p>\u2003\u2003\u5728\u5e38\u89c1\u7684\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u4e2d\uff0c\u6df1\u5c42\u7279\u5f81\u5177\u6709\u8f83\u5927\u7684\u611f\u53d7\u91ce\uff0c\u5e76\u4e14\u7279\u5f81\u6570\u636e\u7684\u8bed\u4e49\u4fe1\u606f\u4e30\u5bcc\uff1b\u800c\u6d45\u5c42\u7279\u5f81\u5177\u6709\u8f83\u5c0f\u7684\u611f\u53d7\u91ce\uff0c\u5e76\u4e14\u7279\u5f81\u6570\u636e\u7684\u8bed\u4e49\u4fe1\u606f\u8f83\u4e3a\u532e\u4e4f\uff0c\u56e0\u6b64\u5728\u4f20\u7edf\u7684\u5206\u7c7b\u4efb\u52a1\u4e2d\u6211\u4eec\u5e38\u5e38\u4f7f\u7528\u6700\u6df1\u5c42\u7684\u7279\u5f81\u6765\u505a\u7c7b\u522b\u9884\u6d4b\uff0c\u5e76\u4e14\u4e22\u5f03\u6d45\u5c42\u7279\u5f81\u3002\u5728\u7ec6\u7c92\u5ea6\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u4e00\u4e2a\u6838\u5fc3\u7684\u95ee\u9898\u5c31\u662f\u5982\u4f55\u8ba9\u7f51\u7edc\u6355\u83b7\u56fe\u50cf\u4e2d\u7684\u7ec6\u5fae\u5dee\u5f02\uff0c\u8fd9\u4e9b\u7ec6\u5fae\u5dee\u5f02\u5f80\u5f80\u4ec5\u5b58\u5728\u4e8e\u539f\u56fe\u5f88\u5c0f\u7684\u533a\u57df\uff0c\u800c\u6d45\u5c42\u7279\u5f81\u611f\u53d7\u91ce\u5c0f\uff0c\u53ef\u4ee5\u4ee3\u8868\u539f\u56fe\u6bd4\u8f83\u5c0f\u7684\u533a\u57df\uff0c\u56e0\u6b64\u6211\u4eec\u53ef\u4ee5\u5229\u7528\u8fd9\u4e00\u7279\u70b9\uff0c\u4e5f\u8ba9\u6d45\u5c42\u7279\u5f81\u53c2\u4e0e\u6a21\u578b\u7684\u51b3\u7b56\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u6a21\u578b\u6355\u83b7\u7ec6\u5fae\u5dee\u5f02\u7684\u80fd\u529b\uff0c\u8fdb\u4e00\u6b65\u63d0\u5347\u51c6\u786e\u6027\u80fd\u3002\u7ec6\u7c92\u5ea6\u5206\u7c7b\u7b97\u6cd5\u5e38\u4f7f\u7528\u4e2d\u95f4\u9636\u6bb5\u7684\u7279\u5f81\u56fe\u53c2\u4e0e\u9884\u6d4b\uff0c\u4ee5\u4e0b\u7b80\u79f0\u4e2d\u7ea7\u7279\u5f81\uff08mid-level feature\uff09\uff0c\u6df1\u5c42\u7279\u5f81\u7b80\u79f0\u9ad8\u7ea7\u7279\u5f81\uff08high-level feature\uff09\u3002</p> <p>\u2003\u2003\u5bf9\u4e8e\u5229\u7528\u4e2d\u7ea7\u7279\u5f81\uff0c\u6700\u7b80\u5355\u7684\u65b9\u5f0f\u5c31\u662f\u5f15\u5165\u5b50\u5206\u7c7b\u5668\u6765\u9488\u5bf9\u4e2d\u7ea7\u7279\u5f81\u505a\u5206\u7c7b\uff0c\u4e4b\u540e\u5229\u7528\u5206\u7c7b\u635f\u5931\u6765\u4f18\u5316\u7f51\u7edc\u53c2\u6570\uff0c\u4f8b\u5982\u5728\u7b97\u6cd5SPS\u4e2d\u5c31\u5e94\u7528\u4e86\u8fd9\u4e00\u7b56\u7565\uff0c\u4f46\u662f\u76f4\u63a5\u5e94\u7528\u5206\u7c7b\u635f\u5931\u53bb\u4f18\u5316\u7f51\u7edc\u5f80\u5f80\u5f97\u4e0d\u5230\u8f83\u4e3a\u7406\u60f3\u7684\u6548\u679c\uff0c\u4f5c\u8005\u8fdb\u4e00\u6b65\u7cfb\u7edf\u5206\u6790\u4e86\u8fd9\u4e00\u65b9\u6cd5\u7684\u7f3a\u9677\uff0c\u4e3b\u8981\u5c31\u662f\u5b58\u5728\u5c40\u90e8\u8fc7\u62df\u5408\u7684\u95ee\u9898\uff0c\u7f51\u7edc\u4ec5\u4ec5\u4f9d\u8d56\u4e8e\u56fe\u7247\u4e2d\u5c11\u91cf\u7684\u533a\u57df\u6765\u51b3\u5b9a\u7269\u4f53\u7684\u7c7b\u522b\uff0c\u6a21\u578b\u5bb9\u6613\u88ab\u5c11\u6570\u5177\u6709\u9ad8\u8fa8\u8bc6\u529b\u7684\u7279\u5f81\u6240\u652f\u914d\uff0c\u964d\u4f4e\u4e86\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002\u4e3a\u4e86\u6539\u5584\u4e2d\u7ea7\u7279\u5f81\u8868\u793a\uff0c\u63d0\u9ad8\u4e2d\u5c42\u7f51\u7edc\u7684\u7279\u5f81\u63d0\u53d6\u80fd\u529b\u4ee5\u53ca\u4e2d\u5c42\u6a21\u578b\u7684\u9c81\u68d2\u6027\uff0c\u4f5c\u8005\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5f15\u5165\u4e86\u968f\u673a\u4ea4\u6362\u65b9\u6cd5\uff0c\u968f\u673a\u4ea4\u6362\u4e0d\u540c\u6837\u672c\u4e4b\u95f4\u7684\u7279\u5f81\uff08\u6cbfbatch\u65b9\u5411\uff09\uff0c\u4e00\u65e6\u9ad8\u7f6e\u4fe1\u5ea6\u533a\u57df\u7279\u5f81\u548c\u5176\u4ed6\u6837\u672c\u7684\u4f4e\u7f6e\u4fe1\u5ea6\u533a\u57df\u7279\u5f81\u4ea4\u6362\uff0c\u5c31\u4f1a\u6291\u5236\u67d0\u4e9b\u8fc7\u5ea6\u81ea\u4fe1\u7684\u795e\u7ecf\u5143\uff0c\u4ece\u800c\u7f13\u89e3\u533a\u57df\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u8fdb\u4e00\u6b65\u6539\u8fdb\u4e2d\u7ea7\u7279\u5f81\u7684\u7279\u5f81\u8868\u793a\u3002</p> <p>\u2003\u2003\u4e3a\u4e86\u5145\u5206\u5229\u7528\u591a\u5c3a\u5ea6\u7279\u5f81\u7684\u4f18\u52bf\uff0c\u53ef\u4ee5\u901a\u8fc7\u63a2\u7d22\u4e0d\u540c\u5c3a\u5ea6\u7279\u5f81\u4e4b\u95f4\u7684\u8054\u7cfb\u3001\u4fc3\u8fdb\u591a\u5c3a\u5ea6\u7279\u5f81\u878d\u5408\u6765\u6700\u5927\u5316\u6539\u5584\u7f51\u7edc\u7684\u6027\u80fd\uff0c\u5982\u76ee\u6807\u68c0\u6d4b\u4e2d\u7684FPN\u6a21\u5757\uff0c\u8bbe\u8ba1\u81ea\u9876\u5411\u4e0b\u4ee5\u53ca\u6a2a\u5411\u8fde\u63a5\u7684\u7ed3\u6784\uff0c\u5c06\u4e0d\u540c\u5c3a\u5ea6\u7684\u7279\u5f81\u52a0\u4ee5\u878d\u5408\uff0c\u63d0\u5347\u6d45\u5c42\u7279\u5f81\u7684\u8bed\u4e49\u4fe1\u606f\uff0c\u4e4b\u540e\u5229\u7528\u878d\u5408\u540e\u7684\u7279\u5f81\u540c\u65f6\u68c0\u6d4b\u5927\u7269\u4f53\u548c\u5c0f\u7269\u4f53\u3002Cross-X\u4e2d\uff0c\u4f5c\u8005\u4e5f\u7528\u5230\u4e86\u8fd9\u4e00\u601d\u60f3\uff0c\u8bbe\u8ba1\u6a2a\u5411\u8fde\u63a5\uff0c\u7528\u4e8e\u878d\u5408\u4e2d\u7ea7\u548c\u9ad8\u7ea7\u7684\u7279\u5f81\u6570\u636e\uff0c\u4f7f\u5f97\u878d\u5408\u540e\u7684\u7279\u5f81\u5177\u6709\u7cbe\u7ec6\u7a7a\u95f4\u5206\u8fa8\u7387\u7279\u6027\u548c\u4e30\u5bcc\u7684\u7684\u9ad8\u7ea7\u8bed\u4e49\u7279\u6027\u3002\u540c\u65f6\uff0c\u8fd8\u5229\u7528KL\u635f\u5931\u53bb\u5339\u914d\u4e0d\u540c\u5c42\u7279\u5f81\u4e4b\u95f4\u7684\u9884\u6d4b\u5206\u5e03\uff0c\u7528\u4e8e\u63d0\u9ad8\u591a\u5c3a\u5ea6\u7279\u5f81\u7684\u9c81\u68d2\u6027\u3002</p> <p>\u2003\u2003\u6700\u540e\uff0c\u6211\u4eec\u5f15\u5165\u4e2d\u7ea7\u7279\u5f81\u5c31\u662f\u4e3a\u4e86\u4f7f\u7f51\u7edc\u53ef\u4ee5\u66f4\u597d\u5730\u5173\u6ce8\u7c97\u7c92\u5ea6\u7279\u5f81\u4e4b\u5916\u7684\u7ec6\u7c92\u5ea6\u7279\u5f81\uff0c\u5373\u5c40\u90e8\u7684\u5fae\u5c0f\u5dee\u5f02\uff0c\u4f46\u662f\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u7c97\u7c92\u5ea6\u7279\u5f81\u5f80\u5f80\u4f1a\u5305\u542b\u4e00\u90e8\u5206\u7ec6\u7c92\u5ea6\u7279\u5f81\uff0c\u5982\u679c\u76f4\u63a5\u5b66\u4e60\u6574\u5e45\u56fe\u50cf\u7684\u4e2d\u7ea7\u7279\u5f81\uff0c\u7f51\u7edc\u5bb9\u6613\u53d7\u5230\u7c97\u7c92\u5ea6\u4fe1\u606f\u7684\u5e72\u6270\uff0c\u6240\u5b66\u4e60\u5230\u7684\u7ec6\u7c92\u5ea6\u7279\u5f81\u5f88\u5bb9\u6613\u96c6\u4e2d\u5206\u5e03\u4e8e\u7c97\u7c92\u5ea6\u7279\u5f81\u9644\u8fd1\uff08\u5173\u6ce8\u533a\u57df\u91cd\u53e0\uff09\u3002\u56e0\u6b64\uff0c\u4e3a\u4e86\u4f7f\u7f51\u7edc\u72ec\u7acb\u5730\u5728\u6307\u5b9a\u7279\u5f81\u5c42\u7684\u57fa\u7840\u4e0a\u5b66\u4e60\u6307\u5b9a\u7c92\u5ea6\u7ea7\u522b\u7684\u7279\u5f81\uff0c\u4f5c\u8005\u5728PMG\u7b97\u6cd5\u4e2d\u5f15\u5165\u4e86\u968f\u673a\u6253\u4e71\u7684\u601d\u60f3\uff0c\u5c06\u56fe\u7247\u5747\u5300\u5212\u5206\u6210\u56fe\u7247\u788e\u7247\uff0c\u5e76\u4e14\u6253\u4e71\u91cd\u7ec4\uff0c\u5176\u4e2d\u788e\u7247\u5927\u5c0f\u4e0e\u7279\u5b9a\u7684\u7c92\u5ea6\u4e00\u4e00\u5bf9\u5e94\uff0c\u8feb\u4f7f\u7f51\u7edc\u5728\u4e0d\u540c\u9636\u6bb5\u5173\u6ce8\u4e0d\u540c\u5927\u5c0f\u7684\u533a\u57df\uff0c\u4ece\u800c\u5b66\u4e60\u6307\u5b9a\u7c92\u5ea6\u7ea7\u522b\u7684\u7279\u5f81\uff0c\u5e76\u4e14\u8fd8\u5e94\u7528\u6e10\u8fdb\u8bad\u7ec3\u7b56\u7565\u6765\u8ba9\u7f51\u7edc\u5145\u5206\u63a2\u7d22\u5c3a\u5ea6\u4e4b\u95f4\u7684\u4e92\u8865\u5173\u7cfb\u3002\u6700\u540e\uff0c\u5728\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\uff0c\u5c06\u5b8c\u6574\u56fe\u50cf\u591a\u4e2a\u5c3a\u5ea6\u7684\u7279\u5f81\u56fe\u6cbf\u901a\u9053\u65b9\u5411\u5408\u5e76\uff0c\u4e00\u6b21\u6027\u4f20\u5165\u5168\u8fde\u63a5\u5c42\uff0c\u4f7f\u7f51\u7edc\u5145\u5206\u53c2\u8003\u6240\u6709\u7c92\u5ea6\u7ea7\u522b\u7684\u7279\u5f81\u505a\u7c7b\u522b\u9884\u6d4b\u3002</p> <p> <p></p> <p></p>"},{"location":"fine-grained/sum_fine/#_10","title":"\u5176\u4ed6\u65b9\u6cd5","text":""},{"location":"fine-grained/sum_fine/#_11","title":"\u975e\u5747\u5300\u91c7\u6837","text":"<p>\u2003\u2003\u975e\u5747\u5300\u91c7\u6837\u5c31\u662f\u5728\u539f\u56fe\u4e0a\u505a\u4e0d\u5747\u8861\u7684\u91c7\u6837\u64cd\u4f5c\uff0c\u8fd9\u91cc\u53ef\u4ee5\u5bf9\u6bd4\u5747\u5300\u91c7\u6837\u7406\u89e3\uff0c\u76f4\u89c2\u6765\u770b\u5747\u5300\u91c7\u6837\u76f8\u5f53\u4e8e\u5bf9\u539f\u56fe\u7684\u7b49\u6bd4\u653e\u7f29\uff0c\u4e0d\u4f1a\u5728\u89c6\u89c9\u4e0a\u6539\u53d8\u56fe\u50cf\u5f62\u72b6\uff0c\u800c\u975e\u5747\u5300\u91c7\u6837\u7531\u4e8e\u662f\u4e0d\u5747\u8861\u91c7\u96c6\u50cf\u7d20\u70b9\uff0c\u56e0\u6b64\u4f1a\u6539\u53d8\u56fe\u50cf\u7684\u5f62\u72b6\uff0c\u91c7\u6837\u70b9\u5bc6\u7684\u5730\u65b9\u4f1a\u88ab\u653e\u5927\uff08\u7c7b\u4f3c\u5229\u7528\u653e\u5927\u955c\u89c2\u5bdf\u5bc6\u96c6\u91c7\u6837\u533a\u57df\uff09\uff0c\u4f8b\u5982\u4e0b\u56fe\u653e\u5927\u4e86\u5934\u90e8\u533a\u57df\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u5728\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u65b9\u6cd5\u4e2d\uff0c\u6ce8\u610f\u529b\u56fe\u7684\u5173\u6ce8\u533a\u57df\u5f80\u5f80\u53ea\u96c6\u4e2d\u5728\u4e00\u90e8\u5206\u533a\u57df\uff0c\u5927\u90e8\u5206\u7b97\u6cd5\u5f80\u5f80\u559c\u6b22\u5c06\u8be5\u533a\u57df\u88c1\u526a\u51fa\u6765\uff0c\u8fdb\u4e00\u6b65\u518d\u5bf9\u5b50\u533a\u57df\u505a\u5206\u7c7b\uff0c\u4f46\u662f\u76f4\u63a5\u88c1\u526a\u539f\u56fe\u7684\u8bdd\u4f1a\u4e22\u5931\u4e00\u90e8\u5206\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u5bb9\u6613\u5f71\u54cd\u6700\u7ec8\u7684\u7279\u5f81\u8868\u793a\u3002\u76f8\u6bd4\u800c\u8a00\uff0c\u5bf9\u539f\u56fe\u505a\u975e\u5747\u5300\u91c7\u6837\u6700\u5927\u7684\u597d\u5904\u5c31\u5728\u4e8e\u65e2\u7a81\u51fa\u4e86\u539f\u56fe\u7684\u5173\u952e\u533a\u57df\uff0c\u51f8\u663e\u4e86\u7ec6\u7c92\u5ea6\u7ec6\u8282\uff0c\u53c8\u4fdd\u7559\u4e86\u76f8\u5bf9\u4e0d\u76f8\u5173\u7684\u533a\u57df\u3002</p> <p>\u2003\u2003\u800c\u975e\u5747\u5300\u91c7\u6837\u524d\u63d0\u5c31\u662f\u5f97\u5230\u91c7\u6837\u56fe\uff0c\u4e5f\u53ef\u4ee5\u770b\u4f5c\u6ce8\u610f\u529b\u56fe\uff0c\u7528\u4e8e\u6307\u660e\u5728\u54ea\u91cc\u91c7\u6837\u529b\u5ea6\u5927\uff08\u5bf9\u5e94\u5173\u952e\u533a\u57df\uff09\uff0c\u8fdb\u4e00\u6b65\u5f97\u5230\u5177\u4f53\u7684\u91c7\u6837\u70b9\uff0c\u5bf9\u67d0\u4e00\u533a\u57df\u8fdb\u884c\u96c6\u4e2d\u91c7\u6837\uff0c\u4ee5\u9ad8\u5206\u8fa8\u7387\u7684\u65b9\u5f0f\u66f4\u597d\u5730\u63cf\u8ff0\u539f\u59cb\u56fe\u50cf\u4e2d\u7684\u5173\u952e\u533a\u57df\uff0c\u4ece\u800c\u66f4\u597d\u5730\u8f85\u52a9\u7f51\u7edc\u505a\u7c7b\u522b\u51b3\u7b56\u3002\u7b97\u6cd5TASN\u548c\u7b97\u6cd5S3N\u5747\u7528\u5230\u4e86\u8fd9\u4e00\u601d\u60f3\uff0c\u5176\u4e2d\u5728S3N\u4e2d\uff0c\u4f5c\u8005\u5e76\u6ca1\u6709\u76f4\u63a5\u9009\u53d6\u54cd\u5e94\u56fe\u505a\u4e3a\u91c7\u6837\u56fe\uff0c\u800c\u662f\u9009\u53d6\u4e86\u54cd\u5e94\u56fe\u4e0a\u7684\u5cf0\u503c\u54cd\u5e94\u70b9\u505a\u4e3a\u91c7\u6837\u4e2d\u5fc3\u70b9\uff0c\u4e4b\u540e\u5229\u7528\u54cd\u5e94\u503c\u8ba1\u7b97\u9ad8\u65af\u6838\uff0c\u5229\u7528\u6240\u5f97\u7684\u9ad8\u65af\u5206\u5e03\u56fe\u4f5c\u4e3a\u6700\u540e\u7684\u91c7\u6837\u56fe\u3002</p> <p>\u6ce8\uff1a</p> <ul> <li>\u6ce8\u610f\u6240\u7528\u7684\u975e\u5747\u5300\u91c7\u6837\u65b9\u6cd5\u662f\u5426\u662f\u8fde\u7eed\u7684\uff0c\u5982\u679c\u4e0d\u8fde\u7eed\uff0c\u5373\u65e0\u6cd5\u7528\u8fde\u7eed\u51fd\u6570\u5b9e\u73b0\uff0c\u5219\u540e\u7eed\u91c7\u6837\u56fe\u50cf\u7684\u5206\u7c7b\u635f\u5931\u65e0\u6cd5\u4f18\u5316\u5b9a\u4f4d\u6a21\u5757\uff08\u65e0\u6cd5\u4f18\u5316\u6ce8\u610f\u529b\u56fe\u7684\u751f\u6210\uff09\uff0c\u6b64\u65f6\u53ea\u80fd\u901a\u8fc7\u5206\u6790\u7279\u5f81\u6570\u636e\u6765\u5f97\u5230\u6ce8\u610f\u529b\u56fe\uff1b</li> <li>\u975e\u5747\u5300\u91c7\u6837\u7c7b\u4f3c\u4e8e\uff1a\u6ce8\u610f\u529b\u91c7\u6837\u3001\u663e\u8457\u6027\u91c7\u6837\u3001\u9009\u62e9\u6027\u91c7\u6837\u7b49\uff1b</li> <li>\u5982\u679c\u91c7\u6837\u70b9\u4ecb\u4e8e\u539f\u56fe\u4e24\u4e2a\u50cf\u7d20\u70b9\u4e4b\u95f4\uff0c\u5219\u4e00\u822c\u4f1a\u91c7\u7528\u63d2\u503c\u7b97\u6cd5\u9009\u53d6\u4e24\u70b9\u7684\u63d2\u503c\u7ed3\u679c\uff1b</li> <li>\u867d\u7136\u975e\u5747\u5300\u91c7\u6837\u4f1a\u6539\u53d8\u56fe\u50cf\u7269\u4f53\u7684\u5f62\u72b6\uff0c\u4f46\u5206\u7c7b\u4efb\u52a1\u53ea\u8981\u7c7b\u522b\u4fe1\u606f\uff0c\u548c\u76ee\u6807\u68c0\u6d4b\u4e0d\u4e00\u6837\uff0c\u5206\u7c7b\u53ef\u4ee5\u4efb\u610f\u5904\u7406\u539f\u59cb\u56fe\u50cf\uff0c\u53ea\u8981\u7ed3\u679c\u6709\u5229\u5f97\u5230\u5206\u7c7b\u7ed3\u679c\u5c31\u53ef\u4ee5\u3002</li> </ul>"},{"location":"fine-grained/sum_fine/#_12","title":"\u56fe\u50cf\u6253\u4e71","text":"<p>\u2003\u2003\u5728\u7ec6\u7c92\u5ea6\u5206\u7c7b\u4e2d\uff0c\u5c40\u90e8\u7ec6\u8282\u8981\u6bd4\u5168\u5c40\u7ed3\u6784\u8d77\u7740\u66f4\u91cd\u8981\u7684\u4f5c\u7528\uff0c\u5e76\u4e14\u7c7b\u4e4b\u95f4\u5168\u5c40\u7ed3\u6784\u7684\u76f8\u4f3c\u6027\u8f83\u9ad8\uff08\u5982CUB\u4e2d\u6240\u6709\u7684\u6570\u636e\u90fd\u662f\u9e1f\uff0c\u5927\u4f53\u5f62\u72b6\u4e00\u6837\uff09\uff0c\u4e3a\u4e86\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6291\u5236\u5168\u5c40\u4fe1\u606f\u7684\u5e72\u6270\uff0c\u4e00\u79cd\u6bd4\u8f83\u65b0\u9896\u7684\u65b9\u6cd5\u5c31\u662f\u6253\u4e71\u539f\u59cb\u56fe\u7247\uff0c\u7834\u574f\u5168\u5c40\u7ed3\u6784\u7684\u540c\u65f6\u4fdd\u7559\u5c40\u90e8\u7ec6\u8282\uff0c\u8fdb\u4e00\u6b65\u8feb\u4f7f\u7f51\u7edc\u4e3b\u8981\u5173\u6ce8\u5c40\u90e8\u7ec6\u8282\uff0c\u4ece\u800c\u8f85\u52a9\u8bad\u7ec3\u7f51\u7edc\u5bf9\u7ec6\u8282\u7684\u6355\u83b7\u80fd\u529b\uff0c\u5177\u4f53\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u4f46\u662f\u5355\u7eaf\u53ea\u5b66\u4e60\u6253\u4e71\u56fe\u50cf\u7684\u8bdd\uff0c\u4e5f\u4f1a\u6709\u4e00\u4e9b\u95ee\u9898\uff0c\u8bba\u6587DCL\u6307\u51fa\uff0c\u5728\u6253\u4e71\u539f\u59cb\u56fe\u50cf\u7684\u540c\u65f6\u4f1a\u5f15\u5165\u4e00\u90e8\u5206\u4e0d\u786e\u5b9a\u7684\u566a\u58f0\u6a21\u5f0f\uff08\u6253\u4e71\u56fe\u548c\u5b8c\u6574\u56fe\u5728\u89c6\u89c9\u89c2\u611f\u4e0a\u4e0d\u4e00\u6837\uff09\uff0c\u800c\u6211\u4eec\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u53ea\u5e0c\u671b\u7f51\u7edc\u5b66\u4e60\u6253\u4e71\u56fe\u4e2d\u7684\u5c40\u90e8\u7ec6\u8282\uff0c\u4e0d\u5e0c\u671b\u5f15\u5165\u8fd9\u79cd\u566a\u58f0\u5e72\u6270\uff0c\u5bf9\u6b64\uff0c\u53d7\u5bf9\u6297\u5b66\u4e60\u4e2d\u9274\u522b\u5668\uff08descriminator\uff09\u7684\u542f\u53d1\uff0c\u4f5c\u8005\u5728\u7f51\u7edc\u4e0a\u989d\u5916\u5f15\u51fa\u4e86\u4e00\u6761\u9274\u522b\u5206\u652f\uff0c\u7528\u4e8e\u9274\u522b\u8f93\u5165\u56fe\u50cf\u662f\u5426\u88ab\u6253\u4e71\uff0c\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u9694\u79bb\u4e24\u7c7b\u56fe\u50cf\uff0c\u8fdb\u4e00\u6b65\u6291\u5236\u4e0a\u8ff0\u566a\u58f0\u7684\u5e72\u6270\u3002\u6700\u540e\uff0c\u4e3a\u4e86\u4f7f\u7f51\u7edc\u8fdb\u4e00\u6b65\u7406\u89e3\u6bcf\u4e2a\u533a\u57df\u7684\u8bed\u4e49\u4fe1\u606f\uff0c\u4f5c\u8005\u8fd8\u8bbe\u8ba1\u4e86\u6062\u590d\u5206\u652f\uff0c\u5c06\u88ab\u6253\u4e71\u7684\u56fe\u50cf\u6062\u590d\u6210\u539f\u59cb\u56fe\u50cf\uff0c\u4ece\u800c\u66f4\u597d\u5730\u4f7f\u7f51\u7edc\u8fdb\u884c\u51b3\u7b56\u3002</p> <p>\u6ce8\uff1a</p> <ul> <li>PMG\u7b97\u6cd5\u4e2d\u5f15\u5165\u6253\u4e71\u64cd\u4f5c\u662f\u4e3a\u4e86\u548c\u5229\u7528\u4e2d\u7ea7\u7279\u5f81\u505a\u9884\u6d4b\u76f8\u7ed3\u5408\uff0c\u4e8c\u8005\u5207\u5165\u70b9\u4e0d\u540c\uff0c\u56e0\u6b64\u5bf9\u4e8e\u201c\u6253\u4e71\u201d\u8fd9\u4e00\u64cd\u4f5c\u6709\u4e0d\u540c\u7684\u7406\u89e3\u89d2\u5ea6\u3002</li> </ul>"},{"location":"fine-grained/sum_fine/#_13","title":"\u53cc\u56fe\u5bf9\u6bd4\u5b66\u4e60","text":"<p>\u2003\u2003\u4ee5\u5f80\u7684\u7ec6\u7c92\u5ea6\u5206\u7c7b\u7b97\u6cd5\u5927\u591a\u6570\u4e3a\u5355\u5f20\u56fe\u7247\u5b66\u4e60\u6cd5\uff0c\u5373\u4e00\u5f20\u56fe\u4e00\u5f20\u56fe\u5730\u5b66\uff0c\u4f46\u662f\u5355\u5f20\u56fe\u7247\u6240\u8574\u542b\u7684\u79cd\u7c7b\u4fe1\u606f\u6709\u9650\uff0c\u56e0\u6b64\u96be\u4ee5\u6316\u6398\u91cc\u9762\u7684\u7cbe\u7ec6\u7279\u5f81\u3002\u76f8\u53cd\uff0c\u4eba\u4eec\u5728\u5b66\u4e60\u76f8\u4f3c\u7269\u4f53\u7684\u5206\u7c7b\u65f6\uff0c\u5e38\u5e38\u901a\u8fc7\u6bd4\u8f83\u4e24\u5f20\u56fe\u50cf\u6765\u5b66\u4e60\uff0c\u901a\u8fc7\u5bf9\u6bd4\u89c2\u5bdf\u56fe\u50cf\u4e2d\u7684\u7ec6\u5fae\u5dee\u5f02\uff0c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u7406\u89e3\u6bcf\u4e00\u5f20\u56fe\u7247\u6240\u8574\u542b\u7684\u7279\u5f81\u4fe1\u606f\uff0c\u4ece\u800c\u5bf9\u7269\u4f53\u4e0d\u540c\u4f4d\u7f6e\u7ed9\u4e88\u4e86\u4e0d\u540c\u7a0b\u5ea6\u7684\u5173\u6ce8\u3002\u5bf9\u6b64API-Net\u7b97\u6cd5\u9996\u5148\u63d0\u51fa\u53cc\u56fe\u5bf9\u6bd4\u5b66\u4e60\u7684\u601d\u60f3\uff0c\u9996\u5148\u5229\u7528\u6b27\u6c0f\u8ddd\u79bb\u8861\u91cf\u4e24\u5e45\u56fe\u50cf\u7279\u5f81\u7684\u76f8\u4f3c\u5ea6\uff0c\u5bf9\u4e8e\u6bcf\u5e45\u56fe\u50cf\uff0c\u5206\u522b\u5339\u914d\u7c7b\u95f4\u76f8\u4f3c\u5ea6\u6700\u9ad8\u548c\u7c7b\u5185\u76f8\u4f3c\u5ea6\u6700\u9ad8\u7684\u56fe\u50cf\u7279\u5f81\uff0c\u4e4b\u540e\u5229\u7528\u6240\u5339\u914d\u7684\u6210\u5bf9\u7279\u5f81\u751f\u6210\u95e8\u5411\u91cf\uff0c\u53c8\u79f0\u56fe\u50cf\u4e4b\u95f4\u7684\u4ea4\u4e92\u5411\u91cf\uff0c\u4e4b\u540e\u518d\u53cd\u4f5c\u7528\u4e8e\u539f\u59cb\u56fe\u50cf\uff0c\u7c7b\u4f3c\u901a\u9053\u6ce8\u610f\u529b\u7684\u901a\u9053\u6743\u91cd\uff0c\u53ea\u4e0d\u8fc7\u8fd9\u91cc\u7684\u6ce8\u610f\u529b\u6743\u91cd\u662f\u901a\u8fc7\u4e24\u7ec4\u76f8\u4f3c\u56fe\u50cf\u7684\u7279\u5f81\u751f\u6210\u7684\u3002\u901a\u8fc7\u4e0a\u8ff0\u5b66\u4e60\uff0c\u7f51\u7edc\u53ef\u4ee5\u81ea\u9002\u5e94\u5730\u4ece\u4e00\u5bf9\u7ec6\u7c92\u5ea6\u56fe\u50cf\u4e2d\u53d1\u73b0\u5bf9\u6bd4\u7ebf\u7d22\uff0c\u5e76\u4e14\u901a\u8fc7\u6210\u5bf9\u4ea4\u4e92\u6a21\u578b\u533a\u5206\u5b83\u4eec\u3002</p> <p>\u6ce8\uff1a</p> <ul> <li>\u53cc\u56fe\u5bf9\u6bd4\u5b66\u4e60\u51fa\u53d1\u70b9\u5f88\u597d\uff0c\u4f46\u662f\u6709\u4e00\u4e2a\u7f3a\u70b9\uff1a\u8bad\u7ec3\u65f6\u663e\u5b58\u8981\u6c42\u5f88\u9ad8\u3002\u6bd4\u5982\u5728API-Net\u4e2d\uff0c\u7531\u4e8e\u6d89\u53ca\u7c7b\u5185\u7c7b\u95f4\u76f8\u4f3c\u5ea6\uff0c\u56e0\u6b64\u8bba\u6587\u9ed8\u8ba4\u6bcf\u6b21\u91c7\u6837\u91c7\u53d630\u79cd\u7c7b\u522b\uff0c\u6bcf\u4e2a\u7c7b\u522b\u91c74\u5f20\u56fe\uff0cbatch\u81f3\u5c11\u9700\u8981\u8bbe\u7f6e120\uff0c\u540e\u7eed\u6bcf\u5f20\u56fe\u518d\u5339\u914d\u7c7b\u5185\u3001\u7c7b\u95f4\u76f8\u4f3c\u7684\u7279\u5f81\uff0c\u53c2\u4e0e\u8fd0\u7b97\u7684\u7279\u5f81\u6570\u636e\u53c8\u4f1a\u53d8\u4e3a\u539f\u6765\u76842\u500d\u3002</li> </ul>"},{"location":"fine-grained/sum_fine/#_14","title":"\u5e94\u5bf9\u8fc7\u62df\u5408","text":"<p>\u2003\u2003\u7ec6\u7c92\u5ea6\u5206\u7c7b\u4efb\u52a1\u8fd8\u6709\u4e00\u4e2a\u660e\u663e\u7684\u95ee\u9898\u5c31\u662f\u5b50\u7269\u4f53\u56fe\u7247\u96be\u4ee5\u83b7\u5f97\uff0c\u7c7b\u522b\u8bad\u7ec3\u6570\u636e\u8f83\u5c11\uff0c\u518d\u52a0\u4e0a\u7c7b\u95f4\u76f8\u4f3c\u5ea6\u9ad8\uff0c\u5bb9\u6613\u4ea7\u751f\u8fc7\u62df\u5408\u7684\u95ee\u9898\u3002\u964d\u4f4e\u4e86\u7f51\u7edc\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4e0d\u5229\u4e8e\u6a21\u578b\u5b9e\u9645\u7684\u63a8\u5e7f\u3002</p> <p>\u2003\u2003\u5728\u673a\u5668\u5b66\u4e60\u4e2d\uff0c\u9762\u5bf9\u8fc7\u62df\u5408\u95ee\u9898\u6700\u5e38\u7528\u7684\u5c31\u662f\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6dfb\u52a0\u6b63\u5219\u5316\u5668\uff08\u5982l_1\u3001l_2\u6b63\u5219\u5316\u5668\uff09\uff0c\u7528\u4e8e\u5e73\u6ed1\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u4f46\u662f\u901a\u7528\u7684\u6b63\u5219\u5316\u5668\u5e76\u4e0d\u76f4\u63a5\u9002\u7528\u4e8e\u8fd9\u91cc\uff0c\u9700\u8981\u5177\u4f53\u95ee\u9898\u5177\u4f53\u5206\u6790\u3002\u5728PC\u7b97\u6cd5\u4e2d\uff0c\u4f5c\u8005\u5177\u4f53\u5206\u6790\u4e86\u7ec6\u7c92\u5ea6\u5206\u7c7b\u4efb\u52a1\u4e2d\u6240\u5b58\u5728\u7684\u95ee\u9898\uff0c\u9762\u5bf9\u4e24\u5f20\u7c7b\u522b\u4e0d\u4e00\u6837\uff0c\u4f46\u662f\u975e\u5e38\u76f8\u4f3c\u7684\u56fe\u7247\uff0c\u5982\u679c\u5355\u7eaf\u5229\u7528\u4f20\u7edf\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u53bb\u8bad\u7ec3\u7f51\u7edc\uff0c\u5f3a\u8feb\u7f51\u7edc\u4ee5\u9ad8\u7f6e\u4fe1\u5ea6\u7684\u65b9\u5f0f\u5b66\u4e60\u80fd\u591f\u533a\u5206\u8fd9\u4e24\u5f20\u56fe\u7247\u7684\u7279\u5f81\uff0c\u7f51\u7edc\u4e3a\u4e86\u6700\u5c0f\u5316\u8bad\u7ec3\u635f\u5931\uff0c\u53ef\u80fd\u4f1a\u5b66\u4e60\u5230\u7279\u5b9a\u4e8e\u6837\u672c\u7684\u7279\u5f81\uff08\u800c\u975e\u7c7b\u522b\u7279\u5f81\uff09\uff0c\u8fdb\u4e00\u6b65\u5e72\u6270\u7f51\u7edc\u5bf9\u56fe\u7247\u7c7b\u522b\u7684\u5224\u65ad\u3002\u4e3a\u4e86\u7f13\u89e3\u8fd9\u4e00\u77db\u76fe\uff0c\u4f5c\u8005\u5f15\u5165\u4e86\u6df7\u6dc6(confusion)\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u6210\u5bf9\u6837\u672c\u4e4b\u95f4\u9884\u6d4b\u6982\u7387\u7684\u5206\u5e03\uff0c\u8feb\u4f7f\u7f51\u7edc\u53bb\u5b66\u4e60\u8fa8\u522b\u6027\u7a0d\u5dee\u7684\u7279\u5f81\uff0c\u8fdb\u4e00\u6b65\u9632\u6b62\u7f51\u7edc\u8fc7\u5ea6\u62df\u5408\u57fa\u4e8e\u6837\u672c\u7684\u7279\u5f81\uff0c\u63d0\u9ad8\u6cdb\u5316\u6027\u80fd\u3002</p> <p>\u2003\u2003\u5bf9\u4e8e\u6837\u672c\u5c11\u8fd9\u4e00\u73b0\u8c61\uff0c\u8fd8\u4f1a\u4ea7\u751f\u4e00\u79cd\u95ee\u9898\u2014\u2014\u7f51\u7edc\u53ef\u80fd\u8fc7\u5ea6\u4f9d\u8d56\u4e8e\u67d0\u4e9b\u7279\u5f81\uff0c\u8fd9\u4e5f\u662f\u8fc7\u62df\u5408\u95ee\u9898\u7684\u4e00\u79cd\u8868\u8c61\u3002\u5bf9\u6b64\uff0c\u5e38\u7528\u7684\u65b9\u6cd5\u5c31\u662f\u4ece\u7279\u5f81\u5165\u624b\uff0c\u4f8b\u5982DropOut\u7b97\u6cd5\uff0c\u901a\u8fc7\u968f\u673a\u4e22\u5f03\u4e00\u90e8\u5206\u7279\u5f81\u6765\u63d0\u5347\u7f51\u7edc\u7684\u6cdb\u5316\u6027\u80fd\uff0c\u4f7f\u795e\u7ecf\u7f51\u7edc\u7684\u8282\u70b9\u4e0d\u80fd\u4f9d\u8d56\u4efb\u4f55\u8f93\u5165\u7684\u7279\u5f81\u3002\u5728SPS\u7b97\u6cd5\u4e2d\uff0c\u4f5c\u8005\u901a\u8fc7\u5206\u6790\u6570\u636e\u53d1\u73b0\uff0c\u7ec6\u7c92\u5ea6\u5206\u7c7b\u4efb\u52a1\u4e5f\u6709\u8fd9\u4e00\u95ee\u9898\uff0c\u5bf9\u6b64\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u968f\u673a\u4ea4\u6362\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u968f\u673a\u9009\u62e9\u4e00\u4e2a\u6837\u672c\u7279\u5f81\u4f5c\u4e3a\u566a\u58f0\u6e90\u5e76\u4e14\u5c06\u5b83\u7684\u4e00\u4e9b\u7279\u5f81\u5143\u7d20\u4e0e\u53e6\u4e00\u4e2a\u6837\u672c\u76f8\u5e94\u4f4d\u7f6e\u7684\u7279\u5f81\u5143\u7d20\u505a\u4ea4\u6362\uff08\u4e5f\u5c31\u662f\u968f\u673a\u4ea4\u6362\u4e24\u4e2a\u6837\u672c\u7684\u7279\u5f81\u6570\u636e\uff09\uff0c\u6765\u6291\u5236\u67d0\u4e9b\u4e3b\u5bfc\u9884\u6d4b\u7684\u795e\u7ecf\u5143\uff0c\u589e\u5f3a\u6a21\u578b\u5206\u7c7b\u5668\u7684\u9c81\u68d2\u6027\u3002</p> <p>\u2003\u2003\u5728\u5b9a\u4f4d\u6a21\u5757\u7684\u8bad\u7ec3\u4e2d\u4e5f\u6709\u4f53\u73b0\uff08\u5373\u6ce8\u610f\u529b\u56fe\u7684\u751f\u6210\uff09\uff0c\u5982\u679c\u7f51\u7edc\u8fc7\u5206\u5173\u6ce8\u67d0\u4e2a\u533a\u57df\u800c\u5ffd\u7565\u4e86\u5176\u4ed6\u533a\u57df\uff08\u5173\u6ce8\u70b9\u8fc7\u4e8e\u96c6\u4e2d\uff09\uff0c\u4e5f\u5bb9\u6613\u9020\u6210\u8fc7\u5ea6\u4f9d\u8d56\u7684\u95ee\u9898\uff0c\u4e00\u65e6\u8be5\u533a\u57df\u88ab\u906e\u6321\uff0c\u5219\u4f1a\u4e25\u91cd\u5f71\u54cd\u7f51\u7edc\u7684\u51b3\u7b56\u5224\u65ad\u3002\u5bf9\u6b64\uff0cWS-DAN\u7b97\u6cd5\u63d0\u51fa\u4e86\u6ce8\u610f\u529b\u4e0b\u964d\u7b56\u7565\uff0c\u5229\u7528\u751f\u6210\u7684\u6ce8\u610f\u529b\u56fe\uff0c\u5220\u53bb\u67d0\u4e9b\u5173\u6ce8\u7684\u533a\u57df\u6570\u636e\uff08\u548c\u4e00\u822c\u64cd\u4f5c\u76f8\u53cd\uff09\uff0c\u518d\u5c06\u5176\u4f20\u5165\u7f51\u7edc\uff0c\u5f3a\u8feb\u7f51\u7edc\u5728\u5176\u4ed6\u533a\u57df\u5b66\u4e60\u533a\u5206\u7c7b\u522b\u7684\u7279\u5f81\uff0c\u6291\u5236\u8fc7\u5ea6\u81ea\u4fe1\u7684\u533a\u57df\u3002\u540c\u65f6\uff0c\u5728S3N\u7b97\u6cd5\u4e2d\u4e5f\u6709\u7c7b\u4f3c\u7684\u64cd\u4f5c\uff0c\u7b97\u6cd5\u5728\u975e\u5c40\u90e8\u91c7\u6837\u8fc7\u7a0b\u4e2d\u4f1a\u751f\u6210\u4e24\u4e2a\u91c7\u6837\u56fe\uff0c\u4e00\u4e2a\u662f\u5728\u5cf0\u503c\u54cd\u5e94\u5927\u7684\u5730\u65b9\u505a\u91c7\u6837\uff0c\u63d0\u5347\u7f51\u7edc\u7ec6\u7c92\u5ea6\u7279\u5f81\u63d0\u53d6\u7684\u80fd\u529b\uff0c\u53e6\u4e00\u4e2a\u5c31\u662f\u5728\u5cf0\u503c\u54cd\u5e94\u5c0f\u7684\u5730\u65b9\u505a\u91c7\u6837\uff0c\u963b\u6b62\u4e86\u5f3a\u7279\u5f81\u5bf9\u68af\u5ea6\u7684\u63a7\u5236\uff0c\u4ece\u800c\u5b9e\u73b0\u4f7f\u7f51\u7edc\u805a\u7126\u4e8e\u591a\u4e2a\u5173\u6ce8\u70b9\u3001\u63d0\u5347\u56fe\u50cf\u7279\u5f81\u8868\u793a\u591a\u6837\u6027\u7684\u76ee\u7684\uff08\u5cf0\u503c\u54cd\u5e94\u8868\u793a\u54cd\u5e94\u56fe\u7684\u5c40\u90e8\u6781\u5927\u503c\uff0c\u7c7b\u4f3c\u5c71\u5cf0\uff09\u3002</p>"},{"location":"fine-grained/sum_fine/#_15","title":"\u53c2\u8003\u7b97\u6cd5","text":"<ul> <li>CAL: Counterfactual Attention Learning for Fine-Grained Visual Categorization and Re-identification, ICCV 2021.</li> <li>SPS: Stochastic Partial Swap: Enhanced Model Generalization and Interpretability for Fine-grained Recognition, ICCV 2021.</li> <li>Graph-based: Graph-based High-Order Relation Discovery for Fine-grained Recognition, CVPR 2021.</li> <li>MMAL: Multi-branch and multi-scale attention learning for fine-grained visual categorization, MMM 2021.</li> <li>PMG: Fine-Grained Visual Classification via Progressive Multi-Granularity Training of Jigsaw Patches, ECCV 2020.</li> <li>API-Net: Learning Attentive Pairwise Interaction for Fine-Grained Classification, AAAI 2020.</li> <li>Cross-X: Cross-X Learning for Fine-Grained Visual Categorization, ICCV 2019.</li> <li>S3N: Selective Sparse Sampling for Fine-grained Image Recognition, ICCV2019.</li> <li>MGE-CNN: Learning a Mixture of Granularity-Specific Experts for Fine-Grained Categorization, ICCV 2019.</li> <li>DCL: Destruction and Construction Learning for Fine-grained Image Recognition, CVPR 2019.</li> <li>TASN: Looking for the Devil in the Details: Learning Trilinear Attention Sampling Network for Fine-grained Image Recognition, CVPR 2019.</li> <li>WS-DAN: See Better Before Looking Closer: Weakly Supervised Data Augmentation Network for Fine-Grained Visual Classification, arXiv 2019.</li> <li>NTS-Net: Learning to Navigate for Fine-grained Classification, ECCV 2018.</li> <li>PC: Pairwise Confusion for Fine-Grained Visual Classification, ECCV 2018.</li> <li>CBAM: CBAM: Convolutional Block Attention Module, ECCV 2018.</li> <li>MAMC: Multi-attention multi-class constraint for fine-grained image recognition, ECCV 2018.</li> <li>MA-CNN: Learning Multi-Attention Convolutional Neural Network for Fine-Grained Image Recognition, ICCV 2017.</li> <li>Grad-CAM: Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization, ICCV 2017.</li> <li>RA-CNN: Look Closer to See Better: Recurrent Attention Convolutional Neural Network for Fine-grained Image Recognition, CVPR 2017.</li> <li>FPN: Feature Pyramid Networks for Object Detection, CVPR 2017.</li> <li>B-CNN: Bilinear CNN Models for Fine-grained Visual Recognition, ICCV 2015.</li> </ul> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u6307\u6b63\u3002</p> <p>\u521d\u6b65\u5b8c\u7a3f\u4e8e\uff1a2023\u5e742\u67082\u65e5</p>"},{"location":"fine-grained/sum_fine_year/","title":"\u7ec6\u7c92\u5ea6\u5206\u7c7b\u6c47\u603b","text":"<p>\u6ce8\uff1a\u5982\u975e\u7279\u6b8a\u8bf4\u660e\uff0c\u6e90\u7801\u5747\u4e3aPyTorch\u7248\u672c</p>"},{"location":"fine-grained/sum_fine_year/#2021","title":"2021","text":"<p>ICCV\uff1a</p> <p>CAL</p> <p> <p></p> <p></p> <p>\u7b80\u4ecb\uff1a\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56e0\u679c\u63a8\u7406\u7684\u53cd\u4e8b\u5b9e\u6ce8\u610f\u529b\u5b66\u4e60\u65b9\u6cd5\uff0c\u53ef\u4ee5\u8ba9\u7f51\u7edc\u5b66\u5230\u66f4\u6709\u6548\u7684\u6ce8\u610f\u529b\u3002\u901a\u8fc7\u6bd4\u8f83\u4e8b\u5b9e\u6ce8\u610f\u529b\u548c\u53cd\u4e8b\u5b9e\u6ce8\u610f\u529b\u5bf9\u6700\u7ec8\u7684\u5f71\u54cd\u6765\u8bc4\u4f30\u6ce8\u610f\u529b\u7684\u8d28\u91cf\uff0c\u540c\u65f6\u6700\u5927\u5316\u4e8c\u8005\u7684\u5dee\u5f02\u6765\u9f13\u52b1\u7f51\u7edc\u5b66\u4e60\u66f4\u6709\u6548\u7684\u89c6\u89c9\u6ce8\u610f\u529b\u3002CAL\u4ec5\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5f15\u5165\u4e86\u53ef\u5ffd\u7565\u7684\u989d\u5916\u8ba1\u7b97\u6210\u672c\uff0c\u5728\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\u4e0d\u4f1a\u5f15\u5165\u4efb\u4f55\u8ba1\u7b97\u6210\u672c\uff0c\u5e76\u4e14\u8be5\u65b9\u6cd5\u662f\u4e00\u4e2a\u4e0e\u6a21\u578b\u65e0\u5173\u7684\u6846\u67b6\uff0c\u53ef\u4ee5\u8f7b\u677e\u5730\u5d4c\u5165\u5230\u5927\u90e8\u5206\u7684\u6ce8\u610f\u529b\u673a\u5236\u4e2d\uff0c\u7528\u4e8e\u589e\u5f3a\u6ce8\u610f\u529b\u7684\u5b66\u4e60\u548c\u51cf\u8f7b\u6570\u636e\u96c6\u504f\u5dee\u7684\u5f71\u54cd\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u7ec6\u7c92\u5ea6\u7684\u89c6\u89c9\u8bc6\u522b\u4efb\u52a1\u3002</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content/ICCV2021/papers/Rao_Counterfactual_Attention_Learning_for_Fine-Grained_Visual_Categorization_and_Re-Identification_ICCV_2021_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/raoyongming/CAL</p> <p>\u8bba\u6587\u7b14\u8bb0\u94fe\u63a5\u3001\u6e90\u7801\u7b14\u8bb0\u94fe\u63a5</p> <p>SPS</p> <p> <p></p> <p></p> <p>\u7b80\u4ecb\uff1a\u672c\u6587\u4f5c\u8005\u901a\u8fc7\u7edf\u8ba1\uff0c\u53d1\u73b0\u4e86\u4e2d\u7ea7\u6a21\u578b\u5b58\u5728\u4e00\u4e2a\u95ee\u9898\uff0c\u5373\u53ea\u6709\u5c11\u91cf\u7684\u56fe\u50cf\u533a\u57df\u6709\u52a9\u4e8e\u6700\u7ec8\u7684\u9884\u6d4b\uff0c\u56e0\u6b64\u63d0\u51fa\u4e86\u968f\u673a\u90e8\u5206\u4ea4\u6362\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002\u4e3b\u8981\u601d\u60f3\u5c31\u662f\u5c06\u4e00\u5f20\u771f\u5b9e\u7684\u7279\u5f81\u4f5c\u4e3a\u566a\u58f0\u6e90\u53bb\u5e72\u6270\u53e6\u4e00\u4e2a\u7279\u5f81\uff0c\u5e76\u4e14\u8bc1\u660e\u4e86\u8fd9\u79cd\u7b56\u7565\u6709\u6548\u5730\u4fc3\u8fdb\u4e86\u795e\u7ecf\u7f51\u7edc\u5728\u9884\u6d4b\u8fc7\u7a0b\u4e2d\u4f9d\u9760\u66f4\u591a\u7684\u533a\u57df\u505a\u5224\u65ad\uff0c\u4f5c\u8005\u8fd8\u5c55\u793a\u4e86\u5b83\u5728\u63d0\u9ad8\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u7684\u4f18\u52bf\u3002</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content/ICCV2021/papers/Huang_Stochastic_Partial_Swap_Enhanced_Model_Generalization_and_Interpretability_for_Fine-Grained_ICCV_2021_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/Shaoli-Huang/SPS</p> <p>\u8bba\u6587\u7b14\u8bb0\u94fe\u63a5\u3001\u6e90\u7801\u7b14\u8bb0\u94fe\u63a5</p>"},{"location":"fine-grained/sum_fine_year/#2020","title":"2020","text":"<p>CVPR\uff1a</p> <p>ACNet</p> <p> <p></p> <p></p> <p>\u7b80\u4ecb\uff1a\u672c\u6587\u63d0\u51fa\u4e86\u7528\u4e8e\u7ec6\u7c92\u5ea6\u5206\u7c7b\u7684\u6ce8\u610f\u529b\u5377\u79ef\u4e8c\u5143\u795e\u7ecf\u6811(ACNet)\uff0c\u5177\u4f53\u7684\u6765\u8bf4\uff0c\u6811\u7f51\u7edc\u4e2d\u4ece\u6839\u7ed3\u70b9\u5230\u53f6\u7ed3\u70b9\u5177\u6709\u591a\u79cd\u8def\u5f84\uff0c\u6bcf\u6761\u8def\u5f84\u5747\u63d2\u5165\u4e86\u6ce8\u610f\u529b\u8f6c\u6362\u5668\uff0c\u7528\u4e8e\u8ba9\u7f51\u7edc\u5728\u4e0d\u540c\u7684\u6839\u8282\u70b9\u4e0a\u805a\u7126\u4e8e\u4e0d\u540c\u7684\u5224\u522b\u529b\u533a\u57df\uff0c\u6700\u7ec8\u7684\u9884\u6d4b\u6982\u7387\u7531\u6bcf\u4e2a\u53f6\u8282\u70b9\u4e0e\u5176\u76f8\u5e94\u7684\u79ef\u7d2f\u6982\u7387\u51b3\u5b9a\uff0c\u6982\u7387\u6700\u5927\u7684\u7c7b\u522b\u5c31\u662f\u6700\u7ec8\u7684\u56fe\u7247\u7c7b\u522b\u3002</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttp://openaccess.thecvf.com/content_CVPR_2020/papers/Ji_Attention_Convolutional_Binary_Neural_Tree_for_Fine-Grained_Visual_Categorization_CVPR_2020_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740(PyTorch\u7248\u672c)\uff1ahttps://github.com/FlyingMoon-GitHub/ACNet</p> <p>\u8bba\u6587\u7b14\u8bb0\u94fe\u63a5\u3001\u6e90\u7801\u7b14\u8bb0\u94fe\u63a5</p> <p>ECCV\uff1a</p> <p>PMG</p> <p> <p></p> <p></p> <p>\u7b80\u4ecb\uff1a\u672c\u6587\u5c06\u6e10\u8fdb\u8bad\u7ec3\u7b56\u7565\u5e94\u7528\u5230\u7ec6\u7c92\u5ea6\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u7c92\u5ea6(PMG)\u8bad\u7ec3\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u4e3b\u8981\u7531\u4e24\u90e8\u5206\u7ec4\u6210\uff1a\u2460\u4ee5\u6e10\u8fdb\u65b9\u5f0f\u878d\u5408\u591a\u7c92\u5ea6\u7279\u5f81\u7684\u65b0\u578b\u8bad\u7ec3\u7b56\u7565\uff1b\u2461\u7528\u4e8e\u5f62\u6210\u5305\u542b\u4e0d\u540c\u7c92\u5ea6\u7ea7\u522b\u4fe1\u606f\u56fe\u50cf\u7684\u62fc\u56fe\u751f\u6210\u5668\u3002\u901a\u8fc7\u5c06\u8be5\u4e24\u4e2a\u6a21\u578b\u52a0\u4ee5\u7ec4\u5408\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u4f7f\u7f51\u7edc\u5b66\u4e60\u4e0d\u540c\u7ea7\u522b\u7684\u7c92\u5ea6\u4fe1\u606f\uff0c\u5e76\u4e14\u53ef\u4ee5\u4f7f\u5404\u7c92\u5ea6\u95f4\u7684\u7279\u5f81\u76f8\u878d\u5408\uff0c\u5145\u5206\u5730\u8ba9\u7f51\u7edc\u63a2\u7d22\u4ed6\u4eec\u4e4b\u95f4\u7684\u4e92\u8865\u5173\u7cfb\u3002</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://arxiv.org/pdf/2003.03836.pdf</p> <p>\u6e90\u7801\u5730\u5740(PyTorch\u7248\u672c)\uff1ahttps://github.com/PRIS-CV/PMG-Progressive-Multi-Granularity-Training</p> <p>\u8bba\u6587\u7b14\u8bb0\u94fe\u63a5\u3001\u6e90\u7801\u7b14\u8bb0\u94fe\u63a5</p> <p>AAAI\uff1a</p> <p>API-Net</p> <p> <p></p> <p></p> <p>\u7b80\u4ecb\uff1a\u672c\u6587\u7b97\u6cd5\u7684\u63d0\u51fa\u59cb\u7ec8\u56f4\u7ed5\u7740\u4e00\u4e2a\u6838\u5fc3\u7684\u601d\u60f3\uff1a\u901a\u8fc7\u8054\u5408\u6bd4\u8f83\u4e00\u5bf9\u56fe\u50cf\u6765\u533a\u5206\u76f8\u4f3c\u7269\u4f53\u4e4b\u95f4\u7684\u7ec6\u5fae\u5dee\u5f02\uff0c\u53ef\u4ee5\u66f4\u597d\u5730\u63d0\u5347\u6a21\u578b\u5bf9\u7269\u4f53\u7cbe\u7ec6\u7279\u5f81\u7684\u8868\u793a\u80fd\u529b\u3002\u4f5c\u8005\u4f9d\u636e\u4e0a\u8ff0\u601d\u60f3\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u7ec6\u7c92\u5ea6\u5206\u7c7b\u7684\u6210\u5bf9\u4ea4\u4e92\u7f51\u7edc(API-Net)\uff0c\u4ed6\u53ef\u4ee5\u81ea\u9002\u5e94\u5730\u4ece\u4e00\u5bf9\u56fe\u50cf\u4e2d\u53d1\u73b0\u5bf9\u6bd4\u7ebf\u7d22\uff0c\u5e76\u4e14\u901a\u8fc7\u6210\u5bf9\u4ea4\u4e92\u6a21\u5757\u6765\u533a\u5206\u5b83\u4eec\u3002</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://arxiv.org/pdf/2002.10191v1.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/PeiqinZhuang/API-Net</p> <p>\u8bba\u6587\u7b14\u8bb0\u94fe\u63a5\u3001\u6e90\u7801\u7b14\u8bb0\u94fe\u63a5</p> <p>TIP\uff1a</p> <p>MC-Loss</p> <p> <p></p> <p></p> <p>\u7b80\u4ecb\uff1a\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5b66\u4e60\u5c40\u90e8\u5224\u522b\u7279\u5f81\u7684\u635f\u5931\u51fd\u6570\u2014\u2014\u901a\u9053\u4ea4\u4e92\u635f\u5931(MC-Loss)\uff0c\u8be5\u635f\u5931\u53ef\u4ee5\u6709\u6548\u5730\u9a71\u52a8\u7279\u5f81\u901a\u9053\u66f4\u5177\u6709\u533a\u5206\u6027\uff0c\u5e76\u4e14\u8ba9\u5176\u805a\u7126\u4e8e\u5404\u4e2a\u533a\u57df\u3002\u66f4\u91cd\u8981\u7684\u662f\u5728\u4e0d\u5f15\u5165\u989d\u5916\u53c2\u6570\u7684\u524d\u63d0\u4e0b\uff0c\u53ef\u4ee5\u5c06\u8be5\u635f\u5931\u5e94\u7528\u5230\u4e0d\u540c\u7684\u7f51\u7edc\u67b6\u6784\u4e2d\uff0c\u63d0\u5347\u7f51\u7edc\u7684\u7ec6\u7c92\u5ea6\u7279\u5f81\u63d0\u53d6\u80fd\u529b\u3002</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://arxiv.org/pdf/2002.04264</p> <p>\u6e90\u7801\u5730\u5740(PyTorch\u7248\u672c)\uff1ahttps://github.com/dongliangchang/Mutual-Channel-Loss</p> <p>\u8bba\u6587\u7b14\u8bb0\u94fe\u63a5\u3001\u6e90\u7801\u7b14\u8bb0\u94fe\u63a5</p>"},{"location":"fine-grained/sum_fine_year/#2019","title":"2019","text":"<p>ICCV\uff1a</p> <p>Cross-X</p> <p> <p></p> <p></p> <p>\u7b80\u4ecb\uff1a\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u7ec6\u7c92\u5ea6\u5206\u7c7b\u7684Cross-X\u7f51\u7edc\u7ed3\u6784\uff0c\u901a\u8fc7\u63a2\u7d22\u4e0d\u540c\u56fe\u50cf\u3001\u4e0d\u540c\u5c42\u7279\u5f81\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u6765\u5b66\u4e60\u7a33\u5b9a\u7684\u7ec6\u7c92\u5ea6\u7279\u5f81\u3002\u901a\u8fc7\u56f4\u7ed5\u201c\u76f8\u540c\u8bed\u4e49\u90e8\u5206\u7684\u7279\u5f81\u867d\u7136\u6765\u81ea\u4e0d\u540c\u7c7b\u522b\u7684\u4e0d\u540c\u56fe\u50cf\uff0c\u4f46\u5e94\u8be5\u6bd4\u4e0d\u540c\u8bed\u4e49\u90e8\u5206\u7684\u7279\u5f81\u66f4\u76f8\u5173\u201d\u8fd9\u4e00\u601d\u60f3\uff0c\u8bbe\u8ba1\u4e86C3S\u6b63\u5219\u5316\u5668\u6765\u4f18\u5316\u7f51\u7edc\u8bed\u4e49\u7279\u5f81\u7684\u63d0\u53d6\u80fd\u529b\uff0c\u5e76\u4e14\u8bbe\u8ba1\u4e86CL\u635f\u5931\u6765\u8ba9\u7f51\u7edc\u5b66\u4e60\u66f4\u7a33\u5b9a\u7684\u7279\u5f81\uff0c\u63d0\u9ad8\u4e86\u9c81\u68d2\u6027\u3002</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttp://openaccess.thecvf.com/content_ICCV_2019/papers/Luo_Cross-X_Learning_for_Fine-Grained_Visual_Categorization_ICCV_2019_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740(PyTorch\u7248\u672c)\uff1ahttps://github.com/cswluo/CrossX</p> <p>\u8bba\u6587\u7b14\u8bb0\u94fe\u63a5\u3001\u6e90\u7801\u7b14\u8bb0\u94fe\u63a5</p> <p>S3N</p> <p> <p></p> <p></p> <p>\u7b80\u4ecb\uff1a\u672c\u6587\u5229\u7528\u56fe\u50cf\u5206\u7c7b\u7f51\u7edc\u5b66\u4e60\u5230\u7684\u7c7b\u5cf0\u503c\u54cd\u5e94\u6765\u4f30\u8ba1\u7ec6\u7c92\u5ea6\u56fe\u50cf\u7684\u4fe1\u606f\u533a\u57df\uff0c\u518d\u5229\u7528\u8be5\u533a\u57df\u6307\u5bfc\u5bf9\u539f\u56fe\u7684\u9009\u62e9\u6027\u91c7\u6837\u8fc7\u7a0b\uff0c\u4ece\u800c\u7a81\u51fa\u56fe\u50cf\u4e2d\u7684\u7ec6\u8282\u5e76\u4e14\u4e0d\u4e22\u5931\u5468\u56f4\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002\u901a\u8fc7\u5c06\u91cd\u91c7\u6837\u540e\u7684\u56fe\u50cf\u518d\u6b21\u4f20\u5165\u76f8\u540c\u7684\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u4e2d\uff0c\u6765\u66f4\u65b0\u6240\u5b66\u4e60\u7684\u7c7b\u5cf0\u503c\u54cd\u5e94\u3002\u8be5\u7f51\u7edc\u63d0\u51fa\u4e86\u4e24\u79cd\u91c7\u6837\u5206\u652f\uff0c\u4e00\u79cd\u662f\u5bf9\u56fe\u50cf\u5cf0\u503c\u54cd\u5e94\u70b9\u4e2d\u54cd\u5e94\u503c\u8f83\u9ad8\u7684\u5c40\u90e8\u533a\u57df\u8fdb\u884c\u91c7\u6837(\u5224\u522b\u5206\u652f)\uff0c\u901a\u8fc7\u51f8\u663e\u56fe\u50cf\u5177\u6709\u533a\u5206\u6027\u7684\u89c6\u89c9\u4fe1\u606f\uff0c\u4ece\u800c\u63d0\u9ad8\u7f51\u7edc\u7279\u5f81\u63d0\u53d6\u7684\u80fd\u529b\uff1b\u53e6\u4e00\u79cd\u662f\u5bf9\u56fe\u50cf\u5cf0\u503c\u54cd\u5e94\u70b9\u4e2d\u54cd\u5e94\u503c\u8f83\u4f4e\u7684\u5168\u5c40\u533a\u57df\u8fdb\u884c\u91c7\u6837(\u4e92\u8865\u5206\u652f)\uff0c\u901a\u8fc7\u51f8\u663e\u56fe\u50cf\u4e2d\u5dee\u5f02\u5c0f\u7684\u533a\u57df\uff0c\u8ba9\u7f51\u7edc\u63a2\u7d22\u56fe\u50cf\u4e2d\u7684\u5fae\u5c0f\u5dee\u5f02\uff0c\u9f13\u52b1\u7f51\u7edc\u6316\u6398\u5176\u4ed6\u7684\u89c6\u89c9\u7ebf\u7d22\uff0c\u4ece\u800c\u63d0\u9ad8\u7f51\u7edc\u591a\u5143\u7279\u5f81\u8868\u793a\u7684\u80fd\u529b\u3002\u4e0a\u8ff0\u4e24\u4e2a\u5206\u652f\u662f\u76f8\u8f85\u76f8\u6210\u7684\uff0c\u5728\u63d0\u9ad8\u7f51\u7edc\u8bc6\u522b\u7cbe\u5ea6\u7684\u540c\u65f6\u8fd8\u63d0\u9ad8\u4e86\u7f51\u7edc\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u63d0\u9ad8\u4e86\u8bc6\u522b\u5206\u7c7b\u7684\u7a33\u5b9a\u6027\u3002</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttp://openaccess.thecvf.com/content_ICCV_2019/papers/Ding_Selective_Sparse_Sampling_for_Fine-Grained_Image_Recognition_ICCV_2019_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/Yao-DD/S3N</p> <p>\u8bba\u6587\u7b14\u8bb0\u94fe\u63a5\u3001\u6e90\u7801\u7b14\u8bb0\u94fe\u63a5</p> <p>MGE-CNN</p> <p> <p></p> <p></p> <p>\u7b80\u4ecb\uff1a\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u7ec6\u7c92\u5ea6\u5206\u7c7b\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u4e3b\u8981\u57fa\u4e8e\u4e13\u5bb6\u6df7\u5408\u6a21\u578b\uff0c\u4f46\u662f\u4e0e\u4f20\u7edf\u7684\u65b9\u6cd5\u4e0d\u540c\uff0c\u4f5c\u8005\u901a\u8fc7\u8ba9\u540e\u4e00\u4e2a\u4e13\u5bb6\u5b66\u4e60\u524d\u4e00\u4e2a\u4e13\u5bb6\u7684\u5148\u9a8c\u4fe1\u606f\u6765\u5c06\u7ec6\u7c92\u5ea6\u95ee\u9898\u5212\u5206\u4e3a\u4e0d\u540c\u7684\u5b50\u7a7a\u95f4\u95ee\u9898\u3002\u4f5c\u8005\u901a\u8fc7\u7ed3\u5408\u9010\u6b65\u589e\u5f3a\u7684\u7b56\u7565\u548c\u57fa\u4e8eKL\u6563\u5ea6\u7684\u7ea6\u675f\u6765\u5b66\u4e60\u5177\u6709\u591a\u6837\u6027\u7684\u4e13\u5bb6\u6a21\u578b\uff0c\u6700\u7ec8\u7684\u9884\u6d4b\u662f\u901a\u8fc7\u4f7f\u7528\u7531\u95e8\u63a7\u7f51\u7edc\u751f\u6210\u7684\u6743\u91cd\u5bf9\u6240\u6709\u4e13\u5bb6\u7684\u9884\u6d4b\u8fdb\u884c\u52a0\u6743\u6c42\u548c\u800c\u5f97\u5230\u7684\u3002</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content_ICCV_2019/papers/Zhang_Learning_a_Mixture_of_Granularity-Specific_Experts_for_Fine-Grained_Categorization_ICCV_2019_paper.pdf</p> <p>\u8bba\u6587\u7b14\u8bb0\u94fe\u63a5</p> <p>CVPR\uff1a</p> <p>DCL</p> <p> <p></p> <p></p> <p>\u7b80\u4ecb\uff1a\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u7ec6\u7c92\u5ea6\u5206\u7c7b\u7684DCL\u7f51\u7edc\u3002\u9996\u5148\u901a\u8fc7\u7834\u574f\u5b66\u4e60\uff0c\u63d0\u9ad8\u4e86\u8bc6\u522b\u7684\u96be\u5ea6\uff0c\u4ece\u800c\u5f15\u5bfc\u7f51\u7edc\u5b66\u4e60\u7ec6\u7c92\u5ea6\u8bc6\u522b\u4e2d\u7684\u4e13\u4e1a\u77e5\u8bc6(\u7ec6\u8282\u5dee\u5f02)\u3002\u800c\u6784\u5efa\u5b66\u4e60\u53ef\u4ee5\u6a21\u62df\u7269\u4f53\u5404\u90e8\u5206\u4e4b\u95f4\u7684\u8bed\u4e49\u5173\u8054\uff0c\u4ece\u800c\u5f15\u5bfc\u7f51\u7edc\u5b66\u4e60\u7269\u4f53\u5404\u90e8\u5206\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u3002\u540c\u65f6\uff0c\u8be5\u7f51\u7edc\u5728\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\u53ea\u9700\u8981\u5c06\u56fe\u7247\u4f20\u5165\u4e3b\u5e72\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u4e2d\u8fdb\u884c\u5206\u7c7b\u9884\u6d4b\uff0c\u8ba1\u7b97\u91cf\u5c0f\uff0c\u5177\u6709\u5f88\u597d\u7684\u5b9e\u7528\u4ef7\u503c\u3002</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content_CVPR_2019/papers/Chen_Destruction_and_Construction_Learning_for_Fine-Grained_Image_Recognition_CVPR_2019_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740(PyTorch\u7248\u672c)\uff1ahttps://github.com/JDAI-CV/DCL</p> <p>\u8bba\u6587\u7b14\u8bb0\u94fe\u63a5\u3001\u6e90\u7801\u7b14\u8bb0\u94fe\u63a5</p> <p>\u5176\u4ed6\uff1a</p> <p>WS-DAN</p> <p> <p></p> <p></p> <p>\u7b80\u4ecb\uff1a\u672c\u6587\u901a\u8fc7\u5c06\u5f31\u76d1\u7763\u5b66\u4e60\u548c\u6570\u636e\u589e\u5f3a\u76f8\u7ed3\u5408\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5f31\u76d1\u7763\u6570\u636e\u6ce8\u610f\u529b\u7f51\u7edc\uff0c\u5f31\u76d1\u7763\u5b66\u4e60\u4e3a\u6570\u636e\u589e\u5f3a\u63d0\u4f9b\u7a7a\u95f4\u5206\u5e03(\u5373\u6ce8\u610f\u529b)\uff0c\u6570\u636e\u589e\u5f3a\u9f13\u52b1\u5b66\u4e60\u591a\u6837\u6027\u7684\u6ce8\u610f\u529b\uff0c\u4ed6\u4eec\u76f8\u4e92\u4fc3\u8fdb\uff0c\u5171\u540c\u4f18\u5316\u7f51\u7edc\uff0c\u4f7f\u5f97\u7f51\u7edc\u80fd\u591f\u5b66\u5230\u6765\u81ea\u591a\u4e2a\u5c40\u90e8\u533a\u57df\u7684\u5224\u522b\u56fe\u50cf\u7279\u5f81\u3002</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://arxiv.org/pdf/1901.09891v2.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/GuYuc/WS-DAN.PyTorch</p> <p>\u8bba\u6587\u7b14\u8bb0\u94fe\u63a5\u3001\u6e90\u7801\u7b14\u8bb0\u94fe\u63a5</p>"},{"location":"fine-grained/sum_fine_year/#2018","title":"2018","text":"<p>ECCV\uff1a</p> <p>NTS-Net</p> <p> <p></p> <p></p> <p>\u7b80\u4ecb\uff1a\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65e0\u9700\u8fb9\u754c\u6846\u6807\u6ce8\u7684\u7ec6\u7c92\u5ea6\u5206\u7c7b\u7b97\u6cd5\u3002\u7531navigator\u6a21\u5757\u9884\u6d4b\u533a\u57df\u4fe1\u606f\u91cf\uff0cTeahcer\u6a21\u5757\u5bf9\u9884\u6d4b\u7684\u4fe1\u606f\u91cf\u6253\u5206\uff0c\u5229\u7528\u533a\u57df\u7684\u4fe1\u606f\u91cf\u548c\u7f6e\u4fe1\u5ea6(\u5206\u6570)\u4e4b\u95f4\u7684\u6392\u5e8f\u635f\u5931\uff0c\u5bf9navigator\u8fdb\u884c\u4f18\u5316\uff0c\u6700\u540eScrutinizer\u6a21\u5757\u5c06\u7efc\u5408\u8003\u8651\u539f\u56fe\u7279\u5f81\u4ee5\u53ca\u4e00\u4e9b\u4fe1\u606f\u91cf\u5927\u7684\u533a\u57df\u7279\u5f81\uff0c\u5bf9\u56fe\u7247\u7684\u7c7b\u522b\u505a\u51fa\u6700\u7ec8\u7684\u5224\u65ad\uff0c\u4e09\u4e2a\u6a21\u5757\u4e92\u76f8\u5408\u4f5c\uff0c\u4e92\u76f8\u52a0\u5f3a\uff0c\u6709\u6548\u5730\u63d0\u9ad8\u4e86\u7f51\u7edc\u7ec6\u7c92\u5ea6\u7684\u5206\u7c7b\u80fd\u529b\u3002</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content_ECCV_2018/papers/Ze_Yang_Learning_to_Navigate_ECCV_2018_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/yangze0930/NTS-Net</p> <p>\u8bba\u6587\u7b14\u8bb0\u94fe\u63a5\u3001\u6e90\u7801\u7b14\u8bb0\u94fe\u63a5</p> <p>PC</p> <p> <p></p> <p></p> <p>\u7b80\u4ecb\uff1a\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6210\u5bf9\u6df7\u6dc6(PC)\u4f18\u5316\u7b56\u7565\uff0c\u901a\u8fc7\u9f13\u52b1\u8f93\u51fa\u7684\u6df7\u6dc6\u6765\u63d0\u9ad8\u7ec6\u7c92\u5ea6\u89c6\u89c9\u5206\u7c7b\u4efb\u52a1\u7684\u6cdb\u5316\u80fd\u529b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u7ecf\u8fc7PC\u8bad\u7ec3\u51fa\u6765\u7684\u7f51\u7edc\u663e\u8457\u5730\u6539\u8fdb\u4e86\u6a21\u578b\u7684\u5b9a\u4f4d\u6027\u80fd\uff0c\u6709\u5229\u4e8e\u63d0\u9ad8\u5206\u7c7b\u7684\u7cbe\u5ea6\u3002\u4e0e\u4e00\u822c\u8bbe\u8ba1\u65b0\u7684\u3001\u590d\u6742\u7684\u7f51\u7edc\u7ed3\u6784\u76f8\u6bd4\uff0cPC\u6613\u4e8e\u5b9e\u73b0\uff0c\u4e0d\u4f1a\u5728\u8bad\u7ec3\u671f\u95f4\u589e\u52a0\u8fc7\u591a\u7684\u5f00\u652f\uff0c\u5e76\u4e14\u4fbf\u4e8e\u6dfb\u52a0\u5230\u5404\u79cd\u7f51\u7edc\u6a21\u578b\u4e2d\uff0c\u6765\u63d0\u9ad8\u6a21\u578b\u7684\u6027\u80fd\u3002 </p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content_ECCV_2018/papers/Abhimanyu_Dubey_Improving_Fine-Grained_Visual_ECCV_2018_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/abhimanyudubey/confusion</p> <p>\u8bba\u6587\u7b14\u8bb0\u94fe\u63a5\u3001\u6e90\u7801\u7b14\u8bb0\u94fe\u63a5</p>"},{"location":"fine-grained/sum_fine_year/#2017","title":"2017","text":"<p>ICCV\uff1a</p> <p>MA-CNN</p> <p> <p></p> <p></p> <p>\u7b80\u4ecb\uff1a\u672c\u6587\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u7ec6\u7c92\u5ea6\u8bc6\u522b\u7684\u591a\u91cd\u6ce8\u610f\u529b\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u540c\u65f6\u63d0\u51fa\u4e86\u8ddd\u79bb\u635f\u5931\u548c\u591a\u6837\u6027\u635f\u5931\u6765\u4f18\u5316\u4e0d\u540c\u5206\u652f\u7684\u6ce8\u610f\u529b\uff0c\u4f7f\u5f97\u751f\u6210\u7684\u5c40\u90e8\u6ce8\u610f\u529b\u56fe\u5177\u6709\u7d27\u5bc6\u5ea6\u9ad8\u3001\u591a\u6837\u6027\u5f3a\u7684\u7279\u70b9\uff0c\u5e76\u4e14\u5229\u7528\u4ea4\u66ff\u4f18\u5316\u7b56\u7565\u5b9e\u73b0\u5224\u522b\u533a\u57df\u7684\u5b9a\u4f4d\u548c\u7ec6\u7c92\u5ea6\u7279\u5f81\u7684\u8868\u793a\u76f8\u4e92\u4fc3\u8fdb\u5b66\u4e60\u3002</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttp://openaccess.thecvf.com/content_ICCV_2017/papers/Zheng_Learning_Multi-Attention_Convolutional_ICCV_2017_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1a</p> <ul> <li> <p>https://github.com/Jianlong-Fu/Multi-Attention-CNN\uff08\u5b98\u65b9\u4ee3\u7801\uff0ccaffe\u7248\u672c\uff09</p> </li> <li> <p>https://github.com/liangnjupt/Multi-Attention-CNN-pytorch\uff08PyTorch\u7248\u672c\uff09</p> </li> </ul> <p>\u8bba\u6587\u7b14\u8bb0\u94fe\u63a5\u3001\u6e90\u7801\u7b14\u8bb0\u94fe\u63a5</p> <p>CVPR\uff1a</p> <p>RA-CNN</p> <p> <p></p> <p></p> <p>\u7b80\u4ecb\uff1a\u672c\u6587\u56f4\u7ed5\u533a\u57df\u5b9a\u4f4d\u548c\u7279\u5f81\u5b66\u4e60\u53ef\u4ee5\u76f8\u4e92\u4fc3\u8fdb\u8fd9\u4e00\u601d\u60f3\uff0c\u63d0\u51fa\u4e86\u5faa\u73af\u6ce8\u610f\u529b\u7f51\u7edc\uff0c\u7f51\u7edc\u7684\u6838\u5fc3\u7ed3\u6784\u662f\u6ce8\u610f\u529b\u5efa\u8bae\u5b50\u7f51\u7edc(ANP\u6a21\u5757)\uff0c\u53ea\u9700\u8981\u63d0\u4f9b\u56fe\u7247\u7684\u6807\u7b7e\uff0c\u5c31\u53ef\u4ee5\u8ba9\u8be5\u5b50\u7f51\u7edc\u8fed\u4ee3\u4ea7\u751f\u7531\u7c97\u5230\u7ec6\u7684\u591a\u5c3a\u5ea6\u6ce8\u610f\u529b\u533a\u57df\uff0c\u8fdb\u4e00\u6b65\u5c06\u5176\u88c1\u526a\u653e\u5927\uff0c\u5b66\u4e60\u653e\u5927\u540e\u7684\u5fae\u5c0f\u5dee\u5f02\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u63d0\u9ad8\u7ec6\u7c92\u5ea6\u7279\u5f81\u63d0\u53d6\u7684\u80fd\u529b\uff1b\u5e76\u4e14\u63d0\u51fa\u4e86\u5229\u7528\u5c3a\u5ea6\u5185\u5206\u7c7b\u635f\u5931\u6765\u4f18\u5316\u7279\u5f81\u63d0\u53d6\u80fd\u529b\u3001\u5229\u7528\u5c3a\u5ea6\u95f4\u6392\u5e8f\u635f\u5931\u6765\u4f18\u5316\u533a\u57df\u5b9a\u4f4d\u80fd\u529b\uff0c\u5e76\u4e14\u8fd8\u63d0\u51fa\u4e86\u4ea4\u66ff\u5b66\u4e60\u7684\u8bad\u7ec3\u7b56\u7565\uff0c\u8ba9\u7279\u5f81\u63d0\u53d6\u5b66\u4e60\u548c\u533a\u57df\u5b9a\u4f4d\u5b66\u4e60\u4e92\u76f8\u4fc3\u8fdb\uff0c\u4ea4\u66ff\u4f18\u5316\u3002</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content_cvpr_2017/papers/Fu_Look_Closer_to_CVPR_2017_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740(PyTorch\u7248\u672c)\uff1ahttps://github.com/jeong-tae/RACNN-pytorch</p> <p>\u8bba\u6587\u7b14\u8bb0\u94fe\u63a5\u3001\u6e90\u7801\u7b14\u8bb0\u94fe\u63a5</p>"},{"location":"fine-grained/sum_fine_year/#2015","title":"2015","text":"<p>ICCV\uff1a</p> <p>B-CNN</p> <p> <p></p> <p></p> <p>\u7b80\u4ecb\uff1a\u672c\u6587\u4e3b\u8981\u63d0\u51fa\u4e86\u7528\u4e8e\u805a\u5408\u4e8c\u9636\u7edf\u8ba1\u6570\u636e\u7684B-CNN\u67b6\u6784\uff0c\u4ee5\u77e9\u9635\u5916\u79ef\u7684\u5f62\u5f0f\u7ec4\u5408\u4e00\u5e45\u56fe\u7247\u7684\u4e24\u79cd\u7279\u5f81\uff0c\u4f7f\u7f51\u7edc\u5145\u5206\u63a2\u7d22\u96f6\u4ef6\u7279\u5f81\u4e4b\u95f4\u7684\u4ea4\u4e92\u5173\u7cfb\uff0c\u4ece\u800c\u4f7f\u7f51\u7edc\u66f4\u597d\u5730\u7406\u89e3\u56fe\u50cf\uff0c\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u3002</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Lin_Bilinear_CNN_Models_ICCV_2015_paper.pdf</p> <p>\u8bba\u6587\u7b14\u8bb0\u94fe\u63a5\u3001\u6e90\u7801\u7b14\u8bb0\u94fe\u63a5</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2023\u5e741\u670829\u65e5</p>"},{"location":"fine-grained/code/ACNet2/","title":"\u7ec6\u7c92\u5ea6\uff1aACNet","text":""},{"location":"fine-grained/code/ACNet2/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aIEEE Conference on Computer Vision and Pattern Recognition 2020 (CVPR, 2020)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttp://openaccess.thecvf.com/content_CVPR_2020/papers/Ji_Attention_Convolutional_Binary_Neural_Tree_for_Fine-Grained_Visual_Categorization_CVPR_2020_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740(PyTorch\u7248\u672c)\uff1ahttps://github.com/FlyingMoon-GitHub/ACNet</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u7c7b(FGVC)</p>"},{"location":"fine-grained/code/ACNet2/#acnet_1","title":"ACNet\u7f51\u7edc\u7ed3\u6784","text":""},{"location":"fine-grained/code/ACNet2/#_2","title":"\u7f51\u7edc\u6574\u4f53\u7ed3\u6784","text":"<pre><code>class ACNet(nn.Module):\n\n    def __init__(self, config):\n        super(ACNet, self).__init__()\n        # \u52a0\u8f7dACNet\u7f51\u7edc\u7684\u5404\u79cd\u53c2\u6570\n        self.target_size = (3, config['target_size'], config['target_size'])\n        self.class_num = config['class_num']\n        self.aux_conv_in = config['aux_conv_in']\n        self.tree_in = config['tree_in']\n        self.use_cuda = config['use_cuda']\n        self.log_dir = config['log_dir']\n        self.tree_height = config['tree_height']\n\n        self.pretrained = config['pretrained']\n        # \u5f97\u5230\u4e3b\u5e72\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\n        self.backbone = getBackbone(config['backbone'], pretrained=self.pretrained)\n        self.aux_conv = self._aux_conv(self.aux_conv_in, self.tree_in)\n        # \u5b9a\u4e49\u6811\u7ed3\u6784\n        self.tree = BinaryNeuralTree(class_num=self.class_num, tree_height=self.tree_height, in_channels=self.tree_in)\n\n    def _aux_conv(self, aux_conv_in, aux_conv_out):\n        layers = []\n        if aux_conv_in &gt; 0:\n            extra_conv = nn.Conv2d(in_channels=aux_conv_in, out_channels=aux_conv_out, kernel_size=1)\n            extra_conv.apply(weightInit)\n            layers.append(extra_conv)\n            layers.append(nn.ReLU())\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        # \u5c06\u8f93\u5165\u4f20\u5165\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u63d0\u53d6\u7279\u5f81\n        init_feature = self.backbone(x)\n        init_feature = self.aux_conv(init_feature)\n        # \u5c06\u7279\u5f81\u56fe\u4f20\u5165\u4e8c\u53c9\u6811\u7ed3\u6784\uff0c\u5f97\u5230\u8f93\u51fa\n        leaves_out, final_out, final_features, penultimate_out = self.tree(init_feature)\n        # \u8fd4\u56de:\u6bcf\u4e2a\u53f6\u5b50\u7ed3\u70b9\u7684\u9884\u6d4b\u6982\u7387\u3001\u5012\u6570\u7b2c\u4e8c\u5c42\u7ed3\u70b9\u7684\u9884\u6d4b\u6982\u7387\u3001\u6700\u7ec8\u7684\u9884\u6d4b\u6982\u7387\u3001\u6700\u540e\u4e00\u5c42\u7684\u7279\u5f81\n        return leaves_out, final_out, final_features, penultimate_out\n</code></pre>"},{"location":"fine-grained/code/ACNet2/#_3","title":"\u4e8c\u53c9\u6811\u7ed3\u6784","text":""},{"location":"fine-grained/code/ACNet2/#_4","title":"\u4e8c\u53c9\u6811\u7684\u521d\u59cb\u5316","text":"<pre><code>class BinaryNeuralTree(nn.Module):\n    def __init__(self, class_num, tree_height=3, in_channels=512):\n        super(BinaryNeuralTree, self).__init__()\n\n        assert tree_height &gt; 1\n        # \u7c7b\u522b\u6570\n        self.class_num = class_num\n        # \u6811\u9ad8\n        self.tree_height = tree_height\n        # \u7279\u5f81\u56fe\u901a\u9053\u6570\n        self.in_channels = in_channels\n        # \u8ba1\u7b97\u7ed3\u70b9\u5904\u7684routing\n        self.branch_routings = self._branch_routings()\n        # \u8ba1\u7b97\u5206\u652f\u4e0a\u6ce8\u610f\u529b\n        self.attention_transformers = self._attention_transformers()\n        # \u8ba1\u7b97\u7ed3\u70b9\u7684\u9884\u6d4b\u6982\u7387\n        self.label_predictions = self._label_predictions()\n        # \u8ba1\u7b97\u5bf9\u6570\n        self.logs = self._log()\n\n    def _branch_routings(self):\n        # structure\u8868\u793aroutings\u6a21\u5757\u7684\u7ed3\u6784\uff0cstructure\u4e3a\u4e8c\u7ef4\u5217\u8868\uff0c\u5176\u4e2d\u6bcf\u4e2a\u5143\u7d20\u4ee3\u8868\u4e00\u4e2a\u7ed3\u70b9\u4e0a\u7684routing\uff0c\u53ef\u4ee5\u901a\u8fc7\u4e00\u4e2a\u4e8c\u7ef4\u5750\u6807\u6765\u5b9a\u4f4d\u8be5routing\u4f4d\u4e8e\u6811\u7684\u54ea\u4e2a\u7ed3\u70b9\u4f4d\u7f6e\n        # \u6811\u7684\u6700\u540e\u4e00\u5c42\u4e0d\u9700\u8981routing\uff0c\u56e0\u6b64\uff0c\u5982\u679c\u6811\u9ad8\u4e3a3\u7684\u8bdd\uff0cstructure\u7ed3\u6784\u4e3a[1,3](\u53ea\u6709\u524d\u4e24\u5c42\u5305\u542brouting)\n        structure = [[None for _ in range(int(pow(2, i)))] for i in range(self.tree_height - 1)]\n        cur = 0\n        for i in range(self.tree_height - 1):\n            for j in range(int(pow(2, i))):\n                # \u6bcf\u4e2a\u7ed3\u70b9\u4e0a\u7684routing\u5747\u7531BranchRoutingModule\u6a21\u5757\u6784\u6210\n                self.__setattr__('branch_routing_module' + str(cur), BranchRoutingModule(in_channels=self.in_channels))\n                structure[i][j] = self.__getattr__('branch_routing_module' + str(cur))\n                cur += 1\n\n        return structure\n\n    def _attention_transformers(self):\n        # \u4e0e_branch_routings\u51fd\u6570\u7c7b\u4f3c\uff0cstructure\u8868\u793aattention\u6a21\u5757\u7684\u7ed3\u6784\uff0c\u4e5f\u662f\u4e00\u4e2a\u4e8c\u7ef4\u5217\u8868\n        # \u6811\u7684\u6bcf\u4e2a\u5206\u652f\u90fd\u9700\u8981attention\u7ed3\u6784\uff0c\u56e0\u6b64\u5982\u679c\u6811\u9ad8\u4e3a3\uff0c\u5219structure\u7ed3\u6784\u53ef\u4ee5\u8868\u793a\u4e3a[2,4]\n        structure = [[None for _ in range(int(pow(2, i + 1)))] for i in range(self.tree_height - 1)]\n        cur = 0\n        for i in range(self.tree_height - 1):\n            for j in range(int(pow(2, i + 1))):\n                # \u9700\u8981\u5206\u5947\u5076\uff0c\u5076\u6570(\u53f3\u5206\u652f)\uff0c\u7531\u4e00\u4e2aattention_transformer\u7ec4\u6210\n                if j % 2:# j\u4ece0\u5f00\u59cb\uff0c\u56e0\u6b64\u5076\u6570\u4ee3\u8868\u5de6\u4fa7\uff0c\u5947\u6570\u4ee3\u8868\u53f3\u4fa7\n                    self.__setattr__('attention_transformer' + str(cur),\n                                     nn.Sequential(*[AttentionTransformer(in_channels=self.in_channels)]))\n                # \u5947\u6570(\u5de6\u5206\u652f)\uff0c\u7531\u4e24\u4e2aattention_transformer\u7ec4\u6210\n                else:\n                    self.__setattr__('attention_transformer' + str(cur),\n                                     nn.Sequential(*[AttentionTransformer(in_channels=self.in_channels),\n                                                     AttentionTransformer(in_channels=self.in_channels)]))\n                structure[i][j] = self.__getattr__('attention_transformer' + str(cur))\n                cur += 1\n\n        return structure\n\n    def _label_predictions(self):\n        # \u8868\u793a\u53f6\u5b50\u7ed3\u70b9(\u6807\u7b7e\u9884\u6d4b\u6a21\u5757)\u7684\u7ed3\u6784\uff0c\u5982\u679c\u9ad8\u4e3a3\uff0c\u5219\u67094\u4e2a\u53f6\u5b50\u7ed3\u70b9\n        structure = [None] * int(pow(2, self.tree_height - 1))\n        cur = 0\n        for i in range(int(pow(2, self.tree_height - 1))):\n            # \u6bcf\u4e2a\u53f6\u5b50\u7ed3\u70b9\u7684\u6807\u7b7e\u9884\u6d4b\u5747\u7531LabelPredictionModule\u51fd\u6570\u6784\u6210\n            self.__setattr__('label_prediction_module' + str(cur),\n                             LabelPredictionModule(class_num=self.class_num, in_channels=self.in_channels))\n            structure[i] = self.__getattr__('label_prediction_module' + str(cur))\n            cur += 1\n\n        return structure\n\n    # \u7528\u4e8e\u8ba1\u7b97\u9884\u6d4b\u7ed3\u679c\u7684\u5bf9\u6570\uff0c\u4e3a\u6700\u7ec8\u8ba1\u7b97\u5bf9\u6570\u4f3c\u7136\u635f\u5931\u505a\u51c6\u5907\n    def _log(self, epsilon=1e-12):\n        # epsilon\u4e3a\u8fb9\u754c\u503c\uff0c\u9632\u6b62\u51fa\u73b0\u9884\u6d4b\u7ed3\u679c\u662f0\u7684\u60c5\u51b5(log0\u65e0\u610f\u4e49)\n        structure = [None] * int(pow(2, self.tree_height - 1) + 1)\n        cur = 0\n        for i in range(int(pow(2, self.tree_height - 1)) + 1):\n            # \u5206\u522b\u8ba1\u7b97\u8f93\u5165\u7684\u5bf9\u6570\n            self.__setattr__('log' + str(cur), (lambda x: torch.log(x + epsilon)))\n            structure[i] = self.__getattribute__('log' + str(cur))\n            cur += 1\n\n        return structure\n</code></pre>"},{"location":"fine-grained/code/ACNet2/#_5","title":"\u4e8c\u53c9\u6811\u7684\u524d\u5411\u4f20\u64ad","text":"<pre><code>def forward(self, x):\n    # probs\u957f\u5ea6\u4e3a[2,4]\u7684\u7a7a\u5217\u8868(\u4e8c\u7ef4)\n    # \u8868\u793a\u6bcf\u884c\u4e2d\uff0c\u6bcf\u4e2a\u7ed3\u70b9\u7684\u8def\u7ebf\u6982\u7387\uff0c\u5373\u8bba\u6587\u4e2d\u7684\u03c6\uff0c\u7b2c\u4e00\u884c\u4e00\u4e2a\u7ed3\u70b9\uff0c\u6709\u4e24\u4e2a\u8def\u7ebf\u6982\u7387(\u5de6\u548c\u53f3)\uff0c\u7b2c\u4e8c\u884c\u4e24\u4e2a\uff0c\u4f9d\u6b21\u7c7b\u63a8\uff1b\n    probs = [[None for _ in range(int(pow(2, i + 1)))] for i in range(self.tree_height - 1)]\n    # features\u957f\u5ea6\u4e3a[1,2,4]\n    # \u8868\u793a\u6bcf\u5c42\u4e2d\uff0c\u6bcf\u4e2a\u7ed3\u70b9\u7684\u7279\u5f81\uff0c\u7b2c\u4e00\u5c42\u4e00\u4e2a\uff0c\u7b2c\u4e8c\u5c42\u4e24\u4e2a\uff0c\u7b2c\u4e09\u5c42\u56db\u4e2a\uff0c\u4f9d\u6b21\u7c7b\u63a8\uff1b\n    features = [[None for _ in range(int(pow(2, i)))] for i in range(self.tree_height)]\n    # \u9876\u5c42\u7684\u7279\u5f81\u4e3a\u7279\u5f81\u7f51\u7edc\u8f93\u51fa\u7684\u7279\u5f81\uff0c\u76f4\u63a5\u8d4b\u503c\u5373\u53ef\n    features[0][0] = x\n    # \u904d\u5386\u6240\u6709\u7684\u5c42\uff0c\u4ece\u7b2c\u4e00\u5c42(\u9876\u5c42\uff0c\u53ea\u6709\u4e00\u4e2a\u7ed3\u70b9)\u5f00\u59cb\n    for i in range(self.tree_height - 1):\n        # \u5728\u6bcf\u5c42\u4e2d\u518d\u904d\u5386\u7ed3\u70b9\n        for j in range(int(pow(2, i))):\n            # \u5f97\u5230\u5f53\u524d\u7ed3\u70b9\u5411\u53f3\u504f\u79fb\u7684\u6982\u7387\uff0c\u5177\u4f53\u8ba1\u7b97\u65b9\u6cd5\u89c1\u8def\u7ebf\u5206\u652f\u6a21\u5757\u5c0f\u8282\n            temp_prob = self.branch_routings[i][j](features[i][j])\n            # \u5411\u5de6\u4fbf\u5b9c\u6982\u7387\u4e3a1-\u5411\u53f3\u504f\u79fb\u7684\u6982\u7387\n            probs[i][j * 2] = 1 - temp_prob\n            # \u5411\u53f3\u504f\u79fb\u7684\u6982\u7387\u76f4\u63a5\u8d4b\u503c\u5373\u53ef\n            probs[i][j * 2 + 1] = temp_prob\n            # \u5982\u679c\u662f\u4e0d\u662f\u7b2c\u4e00\u5c42\uff0c\u5219\u672c\u5c42\u6700\u7ec8\u7684\u5de6\u53f3\u8def\u7ebf\u6982\u7387\u9700\u8981\u4e58\u4e0a\u4e0a\u4e00\u5c42\u7684\u6982\u7387\n            if i:\n                # \u672c\u5c42\u5de6\u4fa7\u6700\u7ec8\u7684\u8def\u7ebf\u6982\u7387\n                probs[i][j * 2] = probs[i][j * 2] * probs[i - 1][j]\n                # \u672c\u5c42\u53f3\u4fa7\u6700\u7ec8\u7684\u8def\u7ebf\u6982\u7387\n                probs[i][j * 2 + 1] = probs[i][j * 2 + 1] * probs[i - 1][j]\n            # \u4e0b\u4e00\u5c42\u7684\u7279\u5f81\uff0c\u9700\u8981\u5c06\u672c\u5c42\u7684\u7279\u5f81\u4e58\u4e0a\u672c\u5c42\u8def\u7ebf\u7684attention_transformers\u6a21\u5757\n            # \u4e0d\u540c\u8def\u7ebf(\u5206\u5de6\u53f3)\u5bf9\u5e94\u4e0d\u540c\u7684\u6ce8\u610f\u529b\u6a21\u5757\u8ba1\u7b97\u65b9\u6cd5\n            # \u5148\u8ba1\u7b97\u5f53\u524d\u7ed3\u70b9\u4e0b\u4e00\u5c42\u5de6\u4fa7\u7684\u7279\u5f81\uff0c\u518d\u8ba1\u7b97\u53f3\u4fa7\u7684\u7279\u5f81\n            features[i + 1][j * 2] = self.attention_transformers[i][j * 2](features[i][j])\n            features[i + 1][j * 2 + 1] = self.attention_transformers[i][j * 2 + 1](features[i][j])\n    # \u5f97\u5230\u6bcf\u4e2a\u53f6\u5b50\u7ed3\u70b9\u7684\u9884\u6d4b\u6982\u7387\n    leaves_out = [self.label_predictions[i](features[self.tree_height - 1][i]) for i in\n                  range(int(pow(2, self.tree_height - 1)))]\n    # \u5f97\u5230\u5012\u6570\u7b2c\u4e8c\u5c42\u7ed3\u70b9\u7279\u5f81\u7684\u9884\u6d4b\u6982\u7387(\u8bba\u6587\u4e2d\u672a\u63d0\uff0c\u6e90\u7801\u4f5c\u8005\u65b0\u52a0\u7684:\u5229\u7528\u5012\u6570\u7b2c\u4e8c\u5c42\u7ed3\u70b9\u7684\u9884\u6d4b\u6c42\u5bf9\u6570\u4f3c\u7136\u635f\u5931\u4ee5\u53ca\u4e24\u5c42\u4e4b\u95f4\u7684\u6392\u5e8f\u635f\u5931\u4f18\u5316\u7f51\u7edc)\n    # \u7531\u4e8e\u6700\u540e\u4e00\u5c42\u7ed3\u70b9\u6570\u662f\u5012\u6570\u7b2c\u4e8c\u5c42\u7ed3\u70b9\u6570\u7684\u4e24\u500d\uff0c\u56e0\u6b64\u6700\u540e\u4e00\u5c42\u4e24\u4e2a\u7ed3\u70b9(\u53f6\u5b50)\u5bf9\u5e94\u5012\u6570\u7b2c\u4e8c\u5c42\u4e00\u4e2a\u7ed3\u70b9\uff0c\u56e0\u6b64\u5217\u7d22\u5f15i\u8981\u9664\u4ee52\n    penultimate_out = [self.label_predictions[i](features[self.tree_height - 2][i//2]) for i in\n                  range(int(pow(2, self.tree_height - 1)))]\n    # \u6240\u6709\u53f6\u5b50\u7ed3\u70b9\u9884\u6d4b\u6982\u7387\u52a0\u6743\u6c42\u548c\uff0c\u4f5c\u4e3a\u6700\u7ec8\u7684\u7c7b\u522b\u9884\u6d4b\u6982\u7387\n    # \u6743\u91cd\u4e3a\u4e0a\u4e00\u5c42\u7ed3\u70b9\u7684\u8def\u7ebf\u9009\u62e9\u6982\u7387(\u5411\u5de6\u6216\u8005\u5411\u53f3)\n    final_out = probs[self.tree_height - 2][0] * leaves_out[0]\n    for i in range(1, int(pow(2, self.tree_height - 1))):\n        final_out = final_out + probs[self.tree_height - 2][i] * leaves_out[i]\n    # \u6bcf\u4e2a\u53f6\u5b50\u7ed3\u70b9\u7279\u5f81\u7684\u9884\u6d4b\u6982\u7387\uff0c\u5206\u522b\u6c42\u5bf9\u6570\uff0c\u4fbf\u4e8e\u540e\u9762\u8ba1\u7b97\u5bf9\u6570\u4f3c\u7136\u635f\u5931(\u4e0b\u9762\u7528\u9014\u76f8\u540c)\n    leaves_out = tuple((self.logs[i](leaves_out[i]) for i in range(int(pow(2, self.tree_height - 1)))))\n    # \u5012\u6570\u7b2c\u4e8c\u5c42\u7ed3\u70b9\u7279\u5f81\u7684\u9884\u6d4b\u6982\u7387\uff0c\u6c42\u5bf9\u6570\n    penultimate_out = tuple((self.logs[i](penultimate_out[i]) for i in range(int(pow(2, self.tree_height - 1)))))\n    # \u6700\u7ec8\u7684\u9884\u6d4b\u6982\u7387\uff0c\u6c42\u5bf9\u6570\n    final_out = self.logs[int(pow(2, self.tree_height - 1))](final_out)\n    # \u5f97\u5230\u6700\u540e\u4e00\u5c42\u7684\u7279\u5f81\uff0c\u5373\u53f6\u5b50\u7ed3\u70b9\u7684\u7279\u5f81\uff0c\u540e\u7eed\u8ba1\u7b97\u591a\u6837\u6027\u635f\u5931(\u8bba\u6587\u4e2d\u672a\u63d0\uff0c\u6e90\u7801\u4f5c\u8005\u65b0\u52a0\u7684)\n    final_features = tuple(features[self.tree_height - 1][i] for i in range(int(pow(2, self.tree_height - 1))))\n    # \u8fd4\u56de:\u6bcf\u4e2a\u53f6\u5b50\u7ed3\u70b9\u7684\u9884\u6d4b\u6982\u7387\u3001\u6700\u7ec8\u7684\u9884\u6d4b\u6982\u7387\u3001\u6700\u540e\u4e00\u5c42\u7684\u7279\u5f81\u3001\u5012\u6570\u7b2c\u4e8c\u5c42\u7ed3\u70b9\u7684\u9884\u6d4b\u6982\u7387\n    return leaves_out, final_out, final_features, penultimate_out\n</code></pre>"},{"location":"fine-grained/code/ACNet2/#branch_routing_module","title":"branch routing module","text":"<pre><code>class BranchRoutingModule(nn.Module):\n    def __init__(self, in_channels=512, epsilon=1e-12):\n        super(BranchRoutingModule, self).__init__()\n\n        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n        # \u5b9a\u4e49GlobaL Context Block\u6a21\u5757\n        self.gcblock = GCBlock(in_channels, in_channels)\n        # \u5b9a\u4e49\u6807\u51c6\u5316\u5904\u7406\n        self.l2norm = lambda x: F.normalize(x, dim=1)\n        # \u5c06\u6240\u6709\u901a\u9053\u7ecf\u8fc7\u7ebf\u6027\u6620\u5c04\uff0c\u53d8\u6210\u4e00\u4e2a\u6570\n        self.fc = nn.Linear(in_channels, 1)\n        # \u5168\u5c40\u5e73\u5747\u6c60\u5316\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        # \u5bf9\u5e94\u5143\u7d20\u5f00\u5e73\u65b9\u6839\n        self.signedsqrt = lambda x: torch.sign(x) * torch.sqrt(torch.sign(x) * x + epsilon)\n        # Sigmoid\u6fc0\u6d3b\u51fd\u6570\uff0c\u53d8\u6210[0,1]\u4e4b\u95f4\u7684\u6982\u7387\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        feature = self.conv1(x)\n        # \u7ecf\u8fc7GlobaL Context Block\u6a21\u5757\uff0c\u5f97\u5230\u641c\u96c6\u4e86\u4e0a\u4e0b\u6587\u4fe1\u606f\u7684\u7279\u5f81\u56fe\u6570\u636e\n        feature = self.gcblock(feature)\n        # \u7ecf\u8fc7\u5168\u5c40\u5e73\u5747\u6c60\u5316\uff0c\u5f97\u5230\u7279\u5f81\u5411\u91cf\n        feature = self.avgpool(feature)\n        # \u5c06\u7279\u5f81\u6570\u636e\u5f00\u6839\n        feature = self.signedsqrt(feature)\n        # \u5c06\u5f97\u5230\u7684\u7279\u5f81\u8fdb\u884c\u6807\u51c6\u5316\u64cd\u4f5c\n        feature = self.l2norm(feature)\n        # \u5c06\u7279\u5f81\u6570\u636e\u53d8\u4e3a\u4e24\u7ef4\n        feature = feature.view(feature.size(0), -1)\n        # \u8f93\u5165\u5168\u8fde\u63a5\uff0c\u8fdb\u884c\u9884\u6d4b\uff0c\u5f97\u5230\u8def\u7ebf\u5206\u6570(\u9009\u62e9\u5de6\u8fd8\u662f\u9009\u62e9\u53f3)\n        out = self.fc(feature)\n        # \u7ecf\u8fc7sigmoid\uff0c\u5c06\u6700\u540e\u7684\u8def\u7ebf\u5206\u6570\u505a\u5f52\u4e00\u5316\u5904\u7406\n        out = self.sigmoid(out)\n\n        return out\n</code></pre>"},{"location":"fine-grained/code/ACNet2/#attention_transformer","title":"Attention transformer","text":"<pre><code>class AttentionTransformer(nn.Module):\n    def __init__(self, in_channels=512):\n        super(AttentionTransformer, self).__init__()\n        # \u5b9a\u4e49ASPP\u6a21\u5757\n        self.aspp = ASPP(in_channel=in_channels, depth=in_channels)\n        # self.se = SEBlock(in_planes=in_channels // 2, planes=in_channels)\n\n        # self.aspp = nn.Sequential()\n        # \u5b9a\u4e49SE\u6a21\u5757\n        self.se = SEBlock(in_planes=in_channels, planes=in_channels)\n\n    def forward(self, x):\n        # \u4f9d\u6b21\u7ecf\u8fc7aspp\u3001se\u6a21\u5757\n        feature = self.aspp(x)\n        out = self.se(feature)\n\n        return out\n</code></pre> <p>ASPP</p> <pre><code>class ASPP(nn.Module):\n    def __init__(self, in_channel=512, depth=256):\n        super(ASPP, self).__init__()\n        # \u5168\u5c40\u5e73\u5747\u6c60\u5316\n        self.mean = nn.AdaptiveAvgPool2d((1, 1))\n        self.conv = nn.Conv2d(in_channel, depth, 1, 1)\n        # \u5b9a\u4e49\u56db\u79cd\u6269\u5f20\u901f\u7387(dilation)\u4e0d\u540c\u7684\u6269\u5f20\u5377\u79ef\u5c42\n        # \u6269\u5f20\u901f\u7387\u4e3a1\u65f6\uff0c\u5377\u79ef\u6838\u5c3a\u5bf8\u4e3a1\uff0c\u5176\u4f59\u5747\u4e3a3\n        self.atrous_block1 = nn.Conv2d(in_channel, depth, kernel_size=1, stride=1)\n        self.atrous_block6 = nn.Conv2d(in_channel, depth, kernel_size=3, stride=1, padding=6, dilation=6)\n        self.atrous_block12 = nn.Conv2d(in_channel, depth, kernel_size=3, stride=1, padding=12, dilation=12)\n        self.atrous_block18 = nn.Conv2d(in_channel, depth, kernel_size=3, stride=1, padding=18, dilation=18)\n        # \u70b9\u79ef\u5c42\uff0c\u7528\u4e8e\u6539\u53d8\u7279\u5f81\u56fe\u901a\u9053\u6570\uff0c\u5c06\u5806\u53e0\u540e\u7684\u7279\u5f81\u56fe\u901a\u9053\u6570\u538b\u7f29\u62101\u500d\u7684(\u4e0e\u5806\u53e0\u524d\u76f8\u540c)\n        self.conv_1x1_output = nn.Conv2d(depth * 5, depth, 1, 1)\n\n    def forward(self, x):\n        size = x.shape[2:]\n        # \u9996\u5148\u539f\u56fe\u7ecf\u8fc7\u5168\u5c40\u5e73\u5747\u6c60\u5316\u64cd\u4f5c(\u6c42\u5e73\u5747\u503c)\n        image_features = self.mean(x)\n        image_features = self.conv(image_features)\n        # \u7136\u540e\u653e\u5927\u5230\u4e0e\u539f\u7279\u5f81\u56fe\u5c3a\u5bf8\u4e00\u6837\u7684\u5927\u5c0f\n        image_features = F.upsample(image_features, size=size, mode='bilinear')\n        # \u4f9d\u6b21\u7ecf\u8fc7\u4e0d\u540c\u6269\u5c55\u901f\u7387\u7684\u6269\u5f20\u5377\u79ef\u6a21\u5757\uff0c\u63d0\u9ad8\u7279\u5f81\u56fe\u611f\u53d7\u91ce\n        atrous_block1 = self.atrous_block1(x)\n        atrous_block6 = self.atrous_block6(x)\n        atrous_block12 = self.atrous_block12(x)\n        atrous_block18 = self.atrous_block18(x)\n        # \u5c06\u5177\u6709\u4e0d\u540c\u611f\u53d7\u91ce\u7684\u7279\u5f81\u56fe\u5408\u5e76\uff0c\u6700\u540e\u7ecf\u8fc7\u4e00\u5c42\u5377\u79ef\u6838\u4e3a1*1\u7684\u5377\u79ef\u8fd0\u7b97\n        net = self.conv_1x1_output(torch.cat([image_features, atrous_block1, atrous_block6,\n                                              atrous_block12, atrous_block18], dim=1))\n        return net\n</code></pre> <p>SEBlock</p> <pre><code>class SEBlock(nn.Module):\n    def __init__(self, in_planes, planes, stride=1):\n        super(SEBlock, self).__init__()\n        # \u5b9a\u4e49\u4e00\u4e9b\u5217\u5377\u79ef\u64cd\u4f5c\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        # \u5b9a\u4e49\u5168\u5c40\u5e73\u5747\u6c60\u5316\u4e0eSigmoid\u51fd\u6570\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.sigmoid = nn.Sigmoid()\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes)\n            )\n\n        # SE layers\n        # fc1\u3001fc2\u8868\u793a\u591a\u5c42\u611f\u77e5\u673a(\u7c7b\u4f3c\u4e8e\u591a\u5c42\u7ebf\u6027\u6620\u5c04)\n        self.fc1 = nn.Conv2d(planes, planes // 16, kernel_size=1)  # Use nn.Conv2d instead of nn.Linear\n        self.fc2 = nn.Conv2d(planes // 16, planes, kernel_size=1)\n\n    def forward(self, x):\n        # \u4f9d\u6b21\u7ecf\u8fc7\u5377\u79ef\u3001\u6807\u51c6\u5316\u3001\u5377\u79ef\u3001\u6807\u51c6\u5316\n        out = torch.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        # Squeeze\uff0c\u6c42\u5168\u5c40\u5e73\u5747\u503c\uff0c\u5f97\u5230b*1024*1*1\u7684\u901a\u9053\u6743\u91cd\n        w = self.avgpool(out)\n        # \u7ecf\u8fc7\u4e00\u5c42\u591a\u5c42\u611f\u77e5\u673a\u6a21\u5757\n        w = torch.relu(self.fc1(w))\n        w = self.sigmoid(self.fc2(w))\n\n        # \u5c06\u5f97\u5230\u7684\u901a\u9053\u6743\u91cd\u4e0e\u539f\u59cb\u8f93\u51fa\u76f8\u4e58\n        out = out * w  # New broadcasting feature from v0.2!\n\n        out += self.shortcut(x)\n        out = torch.relu(out)\n        return out\n</code></pre>"},{"location":"fine-grained/code/ACNet2/#_6","title":"\u7ed3\u70b9\u9884\u6d4b","text":"<pre><code>class LabelPredictionModule(nn.Module):\n    def __init__(self, class_num, in_channels=512):\n        super(LabelPredictionModule, self).__init__()\n        # \u5b9a\u4e49\u597d\u5206\u7c7b\u6570\n        self.class_num = class_num\n        # \u5b9a\u4e49\u6807\u51c6\u5316\u4e0e\u5377\u79ef\u64cd\u4f5c\n        self.bn = nn.BatchNorm2d(in_channels)\n        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n        self.l2norm = lambda x: F.normalize(x, dim=1)\n        # \u5168\u8fde\u63a5\u5c42\uff0c\u7528\u4e8e\u9884\u6d4b\u7c7b\u522b\n        self.fc = nn.Linear(in_channels, self.class_num, bias=True)\n        # \u81ea\u9002\u5e94\u5168\u5c40\u5e73\u5747\u6c60\u5316\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.signedsqrt = lambda x: torch.sign(x) * torch.sqrt(torch.sign(x) * x + 1e-12)\n        self.softmax = nn.Softmax(dim=1)\n\n    def forward(self, x):\n        # \u4e0e\u4e00\u822c\u7684\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u7c7b\u4f3c\uff0c\u4f9d\u6b21\u7ecf\u8fc7\u6807\u51c6\u5316\u3001\u5377\u79ef\u3001\u5168\u5c40\u5e73\u5747\u6c60\u5316\uff0c\u5f97\u5230\u7528\u4e8e\u5206\u7c7b\u76841024\u4e2a\u5411\u91cf\n        feature = self.bn(x)\n        feature = self.conv1(feature)\n        feature = self.avgpool(feature)\n        # \u5411\u91cf\u4e2d\u7684\u7279\u5f81\u6570\u636e\u5f00\u6839\n        feature = self.signedsqrt(feature)\n        # \u518d\u7ecf\u8fc7\u4e00\u6b21\u6807\u51c6\u5316\n        feature = self.l2norm(feature)\n        # \u5c06\u7279\u5f81\u56fe\u6570\u636e\u53d8\u6210\u4e8c\u7ef4\u7684\uff0cb*1024\n        feature = feature.view(feature.size(0), -1)\n        # \u7ecf\u8fc7\u5168\u8fde\u63a5\u5c42\u5f97\u5230\u9884\u6d4b\u503c\n        out = self.fc(feature)\n        # \u518d\u7ecf\u8fc7softmax\uff0c\u5f97\u5230\u9884\u6d4b\u6982\u7387\n        out = self.softmax(out)\n\n        return out\n</code></pre>"},{"location":"fine-grained/code/ACNet2/#_7","title":"\u635f\u5931\u51fd\u6570","text":"<pre><code>class MyLossFunction(object):\n    def __init__(self, lambdas, margin):\n        self.lambdas = lambdas\n        self.margin = margin\n\n    def __call__(self, output, label, target):\n        # \u7f51\u7edc\u7684\u8fd4\u56de\u503c:\u6bcf\u4e2a\u53f6\u5b50\u7ed3\u70b9\u7684\u9884\u6d4b\u6982\u7387\u3001\u5012\u6570\u7b2c\u4e8c\u5c42\u7ed3\u70b9\u7684\u9884\u6d4b\u6982\u7387\u3001\u6700\u7ec8\u7684\u9884\u6d4b\u6982\u7387\u3001\u6700\u540e\u4e00\u5c42\u7684\u7279\u5f81\u56fe\n        leaves_out, final_out, final_features, penultimate_out = output\n        # \u5404\u635f\u5931\u7684\u6743\u91cd\u7cfb\u6570\n        lambda_0, lambda_1, lambda_2, lambda_3, lambda_4 = self.lambdas\n        # \u6392\u5e8f\u635f\u5931\u4e2d\u7684\u8fb9\u754c\u503c\n        margin = self.margin\n        # \u9996\u5148\u8ba1\u7b97\u6700\u7ec8\u7684\u9884\u6d4b\u503c\u4e0e\u6807\u7b7e\u4e4b\u95f4\u7684\u5bf9\u6570\u4f3c\u7136\u635f\u5931\n        loss = lambda_0 * nn.NLLLoss()(final_out, label)\n        # \u518d\u5206\u522b\u8ba1\u7b97\u5404\u4e2a\u53f6\u5b50\u7684\u9884\u6d4b\u503c\u4e0e\u6807\u7b7e\u4e4b\u95f4\u7684\u5bf9\u6570\u4f3c\u7136\u635f\u5931\n        for out in leaves_out:\n            loss = loss + lambda_1 * nn.NLLLoss()(out, label)\n        # \u5230\u8fd9\uff0c\u8bba\u6587\u4e2d\u635f\u5931\u51fd\u6570\u7684\u8ba1\u7b97\u516c\u5f0f(4)\u5c31\u5df2\u7ecf\u5b8c\u6210\u4e86\n</code></pre> <p>\u6e90\u7801\u4e2d\uff0c\u4f5c\u8005\u53c8\u65b0\u52a0\u4e86\u56db\u79cd\u635f\u5931\uff0c\u611f\u5174\u8da3\u7684\u540c\u5b66\u53ef\u4ee5\u53bb\u770b\u4e00\u4e0b\u590d\u73b0\u6e90\u7801</p>"},{"location":"fine-grained/code/ACNet2/#_8","title":"\u8bad\u7ec3\u8fc7\u7a0b","text":""},{"location":"fine-grained/code/ACNet2/#_9","title":"\u8bad\u7ec3\u521d\u59cb\u5316\u9636\u6bb5","text":"<pre><code># \u9996\u5148\u52a0\u8f7d\u5404\u79cd\u8bad\u7ec3\u53c2\u6570\n    args = getArgs()\n\n    assert args.type in ['train', 'val']\n\n    dataloaders = {}\n    # \u52a0\u8f7d\u6570\u636e\u96c6\u53c2\u6570(\u6570\u636e\u96c6\u6839\u76ee\u5f55\u3001\u6570\u636e\u96c6\u7c7b\u522b\u6570\u3001txt\u6587\u4ef6\u7b49\u7b49)\n    train_data_config = getDatasetConfig(args, 'train')\n    # \u52a0\u8f7d\u8bad\u7ec3\u96c6\n    train_dataset = MyDataset(train_data_config)\n    train_dataloader = DataLoader(dataset=train_dataset,\n                                  batch_size=args.train_batch,\n                                  shuffle=True,\n                                  num_workers=args.train_num_workers,\n                                  drop_last=False,\n                                  pin_memory=True)\n    dataloaders['train'] = train_dataloader\n    # \u5982\u679c\u6709\u9a8c\u8bc1\u7684\u8bdd\uff0c\u5c31\u52a0\u8f7d\u9a8c\u8bc1\u96c6\n    if args.type == 'val':\n        # \u52a0\u8f7d\u9a8c\u8bc1\u96c6\u53c2\u6570\uff0c\u540c\u4e0a\n        val_data_config = getDatasetConfig(args, 'val')\n        # \u52a0\u8f7d\u9a8c\u8bc1\u96c6\n        val_dataset = MyDataset(val_data_config)\n        val_dataloader = DataLoader(dataset=val_dataset,\n                                    batch_size=args.val_batch,\n                                    shuffle=True,\n                                    num_workers=args.val_num_workers,\n                                    drop_last=False,\n                                    pin_memory=True)\n        dataloaders['val'] = val_dataloader\n    # \u52a0\u8f7d\u6a21\u578b\u53c2\u6570(backbone\u3001\u6811\u9ad8\u3001\u5206\u7c7b\u6570\u3001\u662f\u5426\u7528cuda\u7b49\u7b49)\n    model_config = getModelConfig(args, args.type)\n    # \u52a0\u8f7d\u6a21\u578b\n    model = ACNet(model_config)\n    # \u5982\u679c\u4e4b\u524d\u8bad\u7ec3\u8fc7\u6a21\u578b\uff0c\u5219\u4e0a\u6b21\u8bad\u7ec3\u597d\u7684\u6a21\u578b\uff0c\u7ee7\u7eed\u8bad\u7ec3\n    if args.savepoint_file:\n        model_dict = model.state_dict()\n        model_dict.update({k.replace('module.', ''): v for k, v in torch.load(args.savepoint_file).items()})\n        model.load_state_dict(model_dict)\n    else:\n        # \u5426\u5219\u521d\u59cb\u5316\u6a21\u578b\u53c2\u6570\n        model.aux_conv.apply(weightInit)\n        model.tree.apply(weightInit)\n    # \u5982\u679c\u4f7f\u7528cuda\u8bad\u7ec3\uff0c\u5219\u5c06\u6a21\u578b\u653e\u5165cuda\u4e2d\n    if args.use_cuda:\n        model = model.cuda()\n\n    if args.summary:\n        # \u6253\u5370\u7f51\u7edc\u7ed3\u6784\u548c\u53c2\u6570\n        model.summary()\n    if args.save_graph:\n        # \u521b\u5efa\u6a21\u578b\u8bad\u7ec3\u65e5\u5fd7\n        model.saveGraph()\n    # DataParallel\u8868\u793a\u591a\u5361\u8bad\u7ec3\n    if args.use_cuda:\n        model = nn.DataParallel(model)\n        if torch.cuda.device_count() &gt; 1:\n            # \u5982\u679c\u663e\u5361\u6570\u5927\u4e8e1\uff0c\u5219\u53ef\u4ee5\u4ece\u8fd9\u91cc\u6307\u5b9a\u7528\u54ea\u4e2a\u5361\u8bad\u7ec3\n            model = model.to(torch.device('cuda:0'))\n    # \u5b9a\u4e49\u4f18\u5316\u5668\n    optimizer1 = None\n    # \u7b2c\u4e00\u4e2a\u4f18\u5316\u5668\uff0c\u4f18\u5316\u9664\u4e86\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u4ee5\u5916\u7684\u53c2\u6570\n    if args.use_cuda:\n        optimizer1 = optim.SGD([*model.module.aux_conv.parameters(), *model.module.tree.parameters()], lr=args.learning_rate1,\n                               momentum=args.momentum1, weight_decay=args.weight_decay1)\n    else:\n        optimizer1 = optim.SGD([*model.aux_conv.parameters(), *model.tree.parameters()], lr=args.learning_rate1,\n                               momentum=args.momentum1, weight_decay=args.weight_decay1)\n    # \u7b2c\u4e00\u4e2a\u4f18\u5316\u5668\u7684\u5b66\u4e60\u7387\u8c03\u6574\u7b56\u7565\n    learning_rate_scheduler1 = lr_scheduler.LambdaLR(optimizer1, lr_lambda=lambda x: lr_lambda1(x, args))\n\n    optimizer2 = None\n    # \u7b2c\u4e8c\u4e2a\u4f18\u5316\u5668\uff0c\u4f18\u5316\u6a21\u578b\u6240\u6709\u7684\u53c2\u6570\uff0c\u52a8\u91cf\u3001\u8870\u51cf\u901f\u7387\u7b49\u8d85\u53c2\u6570\u89c1arg_parse\u51fd\u6570\n    if args.use_cuda:\n        optimizer2 = optim.SGD(model.module.parameters(), lr=args.learning_rate2,\n                               momentum=args.momentum2, weight_decay=args.weight_decay2)\n    else:\n        optimizer2 = optim.SGD(model.parameters(), lr=args.learning_rate2,\n                               momentum=args.momentum2, weight_decay=args.weight_decay2)\n    # \u7b2c\u4e8c\u4e2a\u4f18\u5316\u5668\u7684\u5b66\u4e60\u7387\u8c03\u6574\u7b56\u7565\n    learning_rate_scheduler2 = lr_scheduler.LambdaLR(optimizer2, lr_lambda=lambda x: lr_lambda2(x, args))\n</code></pre>"},{"location":"fine-grained/code/ACNet2/#_10","title":"\u8bad\u7ec3\u6d41\u7a0b","text":"<pre><code>def train(args, model, optimizers, learning_rate_schedulers, dataloaders):\n    loss_records = []\n    # \u521b\u5efa\u6a21\u578b\u4fdd\u5b58\u7684\u5730\u5740\n    if not os.path.exists(args.save_dir):\n        os.makedirs(args.save_dir)\n    # \u521b\u5efa\u65e5\u5fd7\u4fdd\u5b58\u7684\u5730\u5740\n    if args.log_file:\n        if not os.path.exists(args.log_dir):\n            os.makedirs(args.log_dir)\n        with open(os.path.join(args.log_dir, args.log_file), 'a+') as log_file:\n            log_file.write(('-' * 5) + '\\n')\n\n    train_batch_size = dataloaders['train'].batch_size\n    # \u6bcf\u4e2aepoch\u9700\u8981\u8bad\u7ec3\u591a\u5c11\u6b21\n    train_epoch_step = len(dataloaders['train'])\n\n    savepoint = args.savepoint\n    checkpoint = args.checkpoint\n    if savepoint &gt; train_epoch_step:\n        savepoint = train_epoch_step\n        checkpoint = savepoint\n    # \u5404\u4e2a\u635f\u5931\u7684\u6743\u91cd\uff0c\u6700\u7ec8\u7684\u635f\u5931\u7531\u5404\u4e2a\u635f\u5931\u52a0\u6743\u6c42\u548c\u800c\u5b9a\n    lambdas = (args.lambda_0, args.lambda_1, args.lambda_2, args.lambda_3, args.lambda_4)\n    margin = args.margin\n    # \u5b9a\u4e49\u635f\u5931\u51fd\u6570\n    loss_func = MyLossFunction(lambdas, margin)\n    # \u521d\u59cb\u5316\u4e24\u4e2a\u65f6\u95f4\u53d8\u91cf(\u7528\u4e8e\u8ba1\u7b97\u6bcf\u6b21\u8fed\u4ee3\u6240\u6d88\u8017\u7684\u65f6\u95f4)\n    last_time, cur_time = None, datetime.datetime.now()\n    # \u7b2c\u4e00\u9636\u6bb5\u7684\u8bad\u7ec3start_epoch1\u5230epoch_num1\uff0c\u6b64\u65f6\u66f4\u65b0\u9664\u4e86backbone(\u7279\u5f81\u63d0\u53d6\u7f51\u7edc)\u4e4b\u5916\u7684\u7f51\u7edc\u53c2\u6570\n    for epoch in range(args.start_epoch1, args.epoch_num1):\n        # \u521d\u59cb\u5316\u66f4\u65b0\u6b21\u6570\n        cur_step = 0\n        # \u8fed\u4ee3\u904d\u5386\u8bad\u7ec3\u96c6\n        for batch_no, data in enumerate(dataloaders['train']):\n            # \u66f4\u65b0last_time(\u4e0a\u4e00\u6b21)\n            last_time = cur_time\n            # \u66f4\u65b0\u6b21\u6570\u52a01\n            cur_step += 1\n            # \u6a21\u578b\u6539\u4e3a\u8bad\u7ec3\u6a21\u5f0f(\u53c2\u6570\u53ef\u66f4\u65b0)\n            model.train(True)\n            # \u5c06\u7f51\u7edc\u4e2d\u7684backbone\u6a21\u5757(\u6d4b\u8bd5\u6a21\u5757)\u6539\u4e3a\u6d4b\u8bd5\u6a21\u5f0f(\u4e0d\u66f4\u65b0\u53c2\u6570)\n            if args.use_cuda:\n                model.module.backbone.train(False)\n            else:\n                model.backbone.train(False)\n            # \u5f97\u5230\u8f93\u5165\u4e0e\u6807\u7b7e\n            image, label = data\n            # \u5c06\u5f20\u91cf\u8f6c\u5316\u4e3a\u53d8\u91cf\uff0c\u4fbf\u4e8e\u53cd\u5411\u4f20\u64ad\n            if args.use_cuda:\n                image = Variable(image.cuda())\n                label = Variable(label.cuda()).long()\n            else:\n                image = Variable(image)\n                label = Variable(label).long()\n            # \u68af\u5ea6\u6e05\u96f6\n            optimizers[0].zero_grad()\n            # \u8f93\u5165\u4f20\u5165\u6a21\u578b\uff0c\u5f97\u5230\u8f93\u51fa\n            leaves_out, final_out, final_features, penultimate_out = model(image)\n            # target\u4e3a\u4e86\u540e\u671f\u8ba1\u7b97\u6392\u5e8f\u635f\u5931\uff0c\u51681\u8868\u793a\u6240\u6709\u7684\u5747\u662f\u6b63\u5e8f(\u987a\u5e8f\u76f8\u540c)\n            target = torch.ones([leaves_out[0].shape[0]])\n            # target\u4f20\u5165cuda\n            if args.use_cuda:\n                target = target.cuda()\n            # \u6c42\u603b\u635f\u5931\n            loss = loss_func((leaves_out, final_out, final_features, penultimate_out), label, target)\n\n            if args.use_cuda:\n                # loss\u4f20\u5165cuda\n                loss = loss.cuda()\n            # \u53cd\u5411\u4f20\u64ad\uff0c\u6c42\u68af\u5ea6\n            loss.backward()\n\n            if args.use_cuda:\n                # \u7b49\u5f85\u5f53\u524d\u8bbe\u5907\u6240\u6709\u7684cuda\u6c42\u5b8c\u68af\u5ea6(\u5e38\u7528\u4e8e\u591a\u5361\u8bad\u7ec3)\n                torch.cuda.synchronize()\n            # \u5229\u7528\u68af\u5ea6\u66f4\u65b0\u53c2\u6570\uff0c\u5229\u7528\u7b2c\u4e00\u4e2a\u4f18\u5316\u5668\u66f4\u65b0\n            optimizers[0].step()\n\n            if args.use_cuda:\n                # \u4e0e\u4e0a\u8ff0\u7c7b\u4f3c\uff0c\u7b49\u5f85\u6240\u6709\u7684cuda\u66f4\u65b0\u5b8c\u53c2\u6570\n                torch.cuda.synchronize()\n            # \u4e00\u6b21\u66f4\u65b0\u7ed3\u675f\uff0c\u4fdd\u5b58\u65f6\u95f4\n            cur_time = datetime.datetime.now()\n            # \u50a8\u5b58\u5f53\u6b21\u635f\u5931\n            loss_records.append(loss.detach().item())\n            # \u8f93\u51fa\u5f53\u524d\u9636\u6bb5\u8bad\u7ec3\u4fe1\u606f\n            print('train_step: {:-8d} / {:d}, loss: {:6.4f}'\n                  .format(cur_step, train_epoch_step, loss.detach().item()), flush=True)\n\n            print(cur_time - last_time)\n        # \u66f4\u65b0\u7b2c\u4e00\u4e2a\u4f18\u5316\u5668\u7684\u5b66\u4e60\u7387\n        if learning_rate_schedulers[0]:\n            learning_rate_schedulers[0].step()\n\n        print('stage 1')\n        print('epoch: {:-4d}, start_epoch: {:-4d}, epoch_num: {:-4d}.'\n              .format(epoch, args.start_epoch1, args.epoch_num1))\n        # \u6bcf\u6b21\u8bad\u7ec3\u5b8c\u662f\u5426\u9a8c\u8bc1\n        if args.type == 'val':\n            if (epoch + 1) % args.val_interval == 0:\n                # \u4f20\u5165test\u51fd\u6570\uff0c\u6d4b\u8bd5\u6a21\u578b\n                val_result = test(args, model=model, dataloader=dataloaders['val'], type='val')\n                # \u5f97\u5230\u9a8c\u8bc1\u7cbe\u5ea6\n                val_acc = val_result['val_acc']\n                # \u8f93\u51fa\u9a8c\u8bc1\u7cbe\u5ea6\n                val_acc_str = 'val_acc: {:6.4f}.'.format(val_acc)\n                print(val_acc_str)\n                # \u4fdd\u5b58\u65e5\u5fd7\n                if args.log_file:\n                    with open(os.path.join(args.log_dir, args.log_file), 'a+') as log_file:\n                        log_file.write('stage 1 ' + 'epoch ' + str(epoch) + ', ' + val_acc_str + '\\n')\n        # \u4e0e\u524d\u9762\u7c7b\u4f3c\uff0c\u7b49\u5f85\u6240\u6709cuda\u4e0a\u7684\u8fd0\u7b97\u7ed3\u675f\uff0c\u518d\u6267\u884c\u4e0b\u4e00\u6b65\n        if args.use_cuda:\n            torch.cuda.synchronize()\n        # \u4fdd\u5b58\u65e5\u5fd7\n        if (epoch + 1) % args.save_interval == 0:\n            save_path = os.path.join(args.save_dir, 'weight_stage' + str(1) + '_epoch' + str(epoch) + '.pth')\n            torch.save(model.state_dict(), save_path)\n        # \u81ea\u52a8\u6e05\u7406\u663e\u5b58\n        if args.use_cuda:\n            torch.cuda.empty_cache()\n# \u5230\u8fd9\uff0c\u7b2c\u4e00\u9636\u6bb5\u7684\u8bad\u7ec3\u6d41\u7a0b\u5df2\u7ecf\u5b8c\u4e86\uff0c\u63a5\u4e0b\u6765\u662f\u7b2c\u4e8c\u9636\u6bb5\u7684\u8bad\u7ec3\n</code></pre> <p>\u7b2c\u4e8c\u9636\u6bb5\u7684\u8bad\u7ec3\uff0c\u8bad\u7ec3\u8fc7\u7a0b\u4e0e\u7b2c\u4e00\u9636\u6bb5\u7c7b\u4f3c\uff0c\u552f\u4e00\u4e0d\u540c\u7684\u5c31\u662f\u6240\u4f7f\u7528\u7684\u4f18\u5316\u5668\u4e0d\u540c\uff0c\u8fd9\u91cc\u4e0d\u518d\u91cd\u590d\u63cf\u8ff0\u3002</p>"},{"location":"fine-grained/code/ACNet2/#_11","title":"\u6d4b\u8bd5\u6d41\u7a0b","text":"<pre><code>def test(args, model, dataloader, type):\n    assert type in ['val', 'test']\n    # \u521d\u59cb\u5316\u7ed3\u679c\u5b57\u5178\n    result = {}\n    # \u635f\u5931\u53d8\u5316\u8fc7\u7a0b\n    loss_records = []\n\n    batch_size = dataloader.batch_size\n    # \u4e00\u5171\u7684\u8fed\u4ee3\u6b21\u6570\n    epoch_step = len(dataloader)\n    # \u6d4b\u8bd5\u96c6\u603b\u6570\n    data_num = len(dataloader.dataset)\n    # \u8ba1\u7b97\u51c6\u786e\u9884\u6d4b\u7684\u56fe\u7247\u4e2a\u6570\n    correct = 0\n    # \u7c7b\u522b\u6570\u91cf\n    class_num = args.class_num\n    # \u6df7\u6dc6\u77e9\u9635\n    confusion_matrix = [[0] * class_num for _ in range(class_num)]\n    # \u635f\u5931\u6743\u91cd\u7cfb\u6570\n    lambdas = (args.lambda_0, args.lambda_1, args.lambda_2, args.lambda_3, args.lambda_4)\n    # \u6392\u5e8f\u635f\u5931\u7684\u8fb9\u754c\u503c\n    margin = args.margin\n    # \u7528\u4e8e\u8ba1\u7b97\u603b\u635f\u5931\n    loss_func = MyLossFunction(lambdas, margin)\n    # \u6a21\u578b\u8f6c\u5316\u4e3a\u6d4b\u8bd5\u72b6\u6001(\u4e0d\u66f4\u65b0\u6a21\u578b\u53c2\u6570)\n    model.train(False)\n\n    with torch.no_grad():\n        # \u4e0e\u8bad\u7ec3\u8fc7\u7a0b\u7c7b\u4f3c\uff0c\u521d\u59cb\u5316\u8fed\u4ee3\u6b21\u6570\n        cur_step = 0\n        # \u8fed\u4ee3\u8bfb\u53d6\u6570\u636e\u96c6\n        for batch_no, data in enumerate(dataloader):\n\n            cur_step += 1\n            # \u5f97\u5230\u6d4b\u8bd5\u6570\u636e\u4e0e\u6807\u7b7e\n            image, label = data\n            # \u663e\u5361\n            if args.use_cuda:\n                image = Variable(image.cuda())\n                label = Variable(label.cuda()).long()\n            else:\n                image = Variable(image)\n                label = Variable(label).long()\n            # \u8f93\u5165\u4f20\u5165\u6a21\u578b\u4e2d\uff0c\u5f97\u5230\u8f93\u51fa\n            leaves_out, final_out, final_features, penultimate_out = model(image)\n            # \u4e0e\u8bad\u7ec3\u8fc7\u7a0b\u7c7b\u4f3c\uff0ctarget\u7528\u4f5c\u6392\u5e8f\u635f\u5931\u4e2d\n            target = torch.ones([leaves_out[0].shape[0]])\n\n            if args.use_cuda:\n                target = target.cuda()\n            # \u5f97\u5230\u6d4b\u8bd5\u635f\u5931\n            loss = loss_func((leaves_out, final_out, final_features, penultimate_out), label, target)\n\n            if args.use_cuda:\n                loss = loss.cuda()\n            # \u6bcf\u6b21\u8fed\u4ee3\u5f97\u5230\u7684\u635f\u5931\u90fd\u4fdd\u5b58\u8d77\u6765\n            loss_records.append(loss.detach().item())\n            # \u8f93\u51fa\u5f53\u524d\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\uff0c\u8fed\u4ee3\u6570\u636e\n            print(type + '_step: {:-8d} / {:d}, loss: {:6.4f}.'\n                  .format(cur_step, epoch_step, loss.detach().item()), flush=True)\n            # \u5f97\u5230\u9884\u6d4b\u7ed3\u679c\uff0c\u8ba1\u7b97\u6b63\u786e\u9884\u6d4b\u7684\u4e2a\u6570\n            _, pred = torch.topk(final_out, 1)\n            correct += torch.sum((pred[:, 0] == label)).data.item()\n            # \u6df7\u6dc6\u77e9\u9635\n            for i in range(label.shape[0]):\n                confusion_matrix[label[i]][pred[i, 0]] += 1\n    # \u6b63\u786e\u6570\u9664\u4ee5\u6d4b\u8bd5\u96c6\u603b\u6570\u5f97\u5230\u51c6\u786e\u7387\n    acc = correct / data_num\n    # \u635f\u5931\u53d8\u5316\u8fc7\u7a0b\n    result['loss_records'] = loss_records\n    # \u6d4b\u8bd5\u7cbe\u5ea6\n    result[type + '_acc'] = acc\n    # \u6df7\u6dc6\u77e9\u9635\n    result[type + '_cfs_mat'] = confusion_matrix\n\n    return result\n</code></pre> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u5927\u5bb6\u6279\u8bc4\u6307\u6b63\u3002</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e7411\u670825\u65e5</p>"},{"location":"fine-grained/code/API-Net2/","title":"\u7ec6\u7c92\u5ea6\uff1aAPI-Net","text":""},{"location":"fine-grained/code/API-Net2/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aAmerican Association for Artificial Intelligence 2020 (AAAI, 2020)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://arxiv.org/pdf/2002.10191v1.pdf</p> <p>\u6e90\u7801\u5730\u5740(PyTorch\u7248\u672c)\uff1ahttps://github.com/PeiqinZhuang/API-Net</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u7c7b(FGVC)</p>"},{"location":"fine-grained/code/API-Net2/#api-net_1","title":"API-Net\u7f51\u7edc\u7ed3\u6784","text":""},{"location":"fine-grained/code/API-Net2/#_2","title":"\u7f51\u7edc\u521d\u59cb\u5316\u9636\u6bb5","text":"<pre><code>def __init__(self, num_classes):\n    super(API_Net, self).__init__()\n\n    resnet101 = models.resnet101(pretrained=True)\n    # .children()\u65b9\u6cd5\u4e3a\u63d0\u53d6\u6a21\u578b\u7684\u6240\u6709module\n    layers = list(resnet101.children())[:-2]\n    # \u5b9a\u4e49\u7279\u5f81\u63d0\u53d6\u5c42\u7684\u4e00\u7cfb\u5217\u5377\u79ef\u64cd\u4f5c\uff0cresnet101\u9664\u53bb\u540e\u4e24\u5c42(\u5168\u5c40\u5e73\u5747\u4e0e\u5168\u8fde\u63a5)\n    # \u5f97\u5230\u7528\u4e8e\u7279\u5f81\u63d0\u53d6\u7684\u90e8\u5206\n    self.conv = nn.Sequential(*layers)\n    # \u5b9a\u4e49\u5168\u5c40\u5e73\u5747\u6c60\u5316\n    self.avg = nn.AvgPool2d(kernel_size=14, stride=1)\n    # \u5b9a\u4e49MLP\u6a21\u5757\n    self.map1 = nn.Linear(2048 * 2, 512)\n    self.map2 = nn.Linear(512, 2048)\n    # \u5b9a\u4e49\u6700\u540e\u7528\u4e8e\u5206\u7c7b\u9884\u6d4b\u7684\u5168\u8fde\u63a5\u5c42\n    self.fc = nn.Linear(2048, num_classes)\n    self.drop = nn.Dropout(p=0.5)\n    # \u5b9a\u4f4d\u4eeaSigmoid\u51fd\u6570\n    self.sigmoid = nn.Sigmoid()\n</code></pre>"},{"location":"fine-grained/code/API-Net2/#_3","title":"\u524d\u5411\u4f20\u64ad","text":"<pre><code>def forward(self, images, targets=None, flag='train'):\n    # \u9996\u5148\u5c06\u539f\u56fe\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\n    conv_out = self.conv(images)\n    # \u5168\u5c40\u5e73\u5747\u6c60\u5316\uff0c\u5f97\u52302048\u4e2a\u7279\u5f81\n    pool_out = self.avg(conv_out).squeeze()\n\n    if flag == 'train':\n        intra_pairs, inter_pairs, \\\n                intra_labels, inter_labels = self.get_pairs(pool_out, targets)\n        # \u7c7b\u5185\u76f8\u4f3c\u548c\u7c7b\u95f4\u76f8\u4f3c\u5408\u5e76\n        # features1\u3001features2\u4e24\u4e2a\u7279\u5f81\u5c3a\u5bf8\u5206\u522b\u4e3a(2*batch)*2048\uff0c\u7531\u4e8e\u6709\u7c7b\u5185\u7c7b\u95f4\u4e4b\u5206\uff0c\u56e0\u6b64\u662f2\u500d\u5173\u7cfb\n        # features1\u8868\u793a\u5f53\u524d\u56fe\u7247\u7279\u5f81\uff0c\u5bf9\u5e94\u8bba\u6587\u91ccx1\n        features1 = torch.cat([pool_out[intra_pairs[:, 0]], pool_out[inter_pairs[:, 0]]], dim=0)\n        # features2\u8868\u793a\u4e0e\u5f53\u524d\u56fe\u7247\u7c7b\u4f3c\u7684\u56fe\u7247\u7279\u5f81\uff0c\u5bf9\u5e94\u8bba\u6587\u91ccx2\n        features2 = torch.cat([pool_out[intra_pairs[:, 1]], pool_out[inter_pairs[:, 1]]], dim=0)\n        # \u4f9d\u6b21\u5f97\u5230x1\u548cx2\u7684\u6807\u7b7e\n        labels1 = torch.cat([intra_labels[:, 0], inter_labels[:, 0]], dim=0)\n        labels2 = torch.cat([intra_labels[:, 1], inter_labels[:, 1]], dim=0)\n        # \u5c06x1\u7279\u5f81\u4e0ex2\u7279\u5f81\u5408\u5e76\n        mutual_features = torch.cat([features1, features2], dim=1)\n        # \u7136\u540e\u4f20\u5165\u5168\u8fde\u63a5\u6620\u5c04\uff0c\u5bf9\u5e94\u8bba\u6587\u4e2dMLP\u6a21\u5757\n        map1_out = self.map1(mutual_features)\n        map2_out = self.drop(map1_out)\n        map2_out = self.map2(map2_out)\n        # xm\u4e0ex1\u505a\u70b9\u4e58\uff0c\u7136\u540e\u4f20\u5165sigmoid\u51fd\u6570\uff0c\u5f97\u5230\u7b2c\u4e00\u95e8\u5411\u91cfg1\uff0c\u5bf9\u5e94\u8bba\u6587\u4e2d\u516c\u5f0f(2)\n        gate1 = torch.mul(map2_out, features1)\n        gate1 = self.sigmoid(gate1)\n        # \u4e0b\u9762\u64cd\u4f5c\u7c7b\u4f3c\uff0c\u5f97\u5230\u7b2c\u4e8c\u95e8\u5411\u91cfg2\n        gate2 = torch.mul(map2_out, features2)\n        gate2 = self.sigmoid(gate2)\n        # \u76f8\u4e92\u4f5c\u7528\u673a\u5236\uff0c\u5f15\u5165\u4e86\u6b8b\u5dee\u7ed3\u6784\uff0c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f(3)-(6)\n        # \u95e8\u5411\u91cf\u4e0e\u7279\u5f81\u4e4b\u95f4\u76f8\u4e92\u505a\u70b9\u4e58\u518d\u4e0e\u7279\u5f81\u76f8\u52a0\uff0c\u5f97\u5230\u4e0d\u540c\u7684\u8054\u5408\u7279\u5f81\n        features1_self = torch.mul(gate1, features1) + features1\n        features1_other = torch.mul(gate2, features1) + features1\n\n        features2_self = torch.mul(gate2, features2) + features2\n        features2_other = torch.mul(gate1, features2) + features2\n        # \u5c06\u5f97\u5230\u7684\u56db\u7ec4\u8054\u5408\u7279\u5f81\u4f9d\u6b21\u7ecf\u8fc7\u5168\u8fde\u63a5\u5c42\uff0c\u5f97\u5230\u56db\u7ec4\u9884\u6d4b\u6982\u7387\n        logit1_self = self.fc(self.drop(features1_self))\n        logit1_other = self.fc(self.drop(features1_other))\n        logit2_self = self.fc(self.drop(features2_self))\n        logit2_other = self.fc(self.drop(features2_other))\n        # \u8fd4\u56de\u9884\u6d4b\u6982\u7387\n        # \u6bcf\u4e2a\u9884\u6d4b\u6982\u7387\u7b2c\u4e00\u7ef4\u5ea6\u5747\u4e3a2*batch(\u7c7b\u5185\u3001\u7c7b\u95f4\u5408\u5e76\u5230\u4e00\u8d77)\n        return logit1_self, logit1_other, logit2_self, logit2_other, labels1, labels2\n    # \u5982\u679c\u662f\u6d4b\u8bd5\u8fc7\u7a0b\uff0c\u5219\u76f4\u63a5\u7ecf\u8fc7\u5168\u8fde\u63a5\u5c42\u5373\u53ef\n    elif flag == 'val':\n        return self.fc(pool_out)\n</code></pre>"},{"location":"fine-grained/code/API-Net2/#_4","title":"\u6210\u5bf9\u56fe\u50cf\u7684\u751f\u6210","text":"<pre><code>def get_pairs(self, embeddings, labels):\n    # \u9996\u5148\u6c42\u5f97\u8ddd\u79bb\u77e9\u9635\uff0c\u5373\u4e24\u4e24\u56fe\u7247\u4e4b\u95f4\u7684\u8ddd\u79bb\n    distance_matrix = pdist(embeddings).detach().cpu().numpy()\n    # \u56fe\u7247\u7684\u6807\u7b7e\n    labels = labels.detach().cpu().numpy().reshape(-1,1)\n    # num\u8868\u793a\u603b\u6570\uff0c\u7b49\u4e8ebatch_size\n    num = labels.shape[0]\n    # \u751f\u6210\u5c3a\u5bf8\u4e3anum*num\u7684\u6570\u7ec4\u4e0a\uff0c\u4e3b\u5bf9\u89d2\u7ebf\u5143\u7d20\u7684\u7d22\u5f15\n    dia_inds = np.diag_indices(num)\n    lb_eqs = (labels == labels.T)\n\n    # \u8fd9\u91cc\u6c42\u540c\u4e00\u7c7b\u4e2d\uff0c\u76f8\u4f3c\u5ea6\u6700\u9ad8\u7684\u4e24\u7ec4\u56fe\u7247\n    # \u5c06\u4e3b\u5bf9\u89d2\u7ebf\u4e0a\u5143\u7d20\u5168\u8bbe\u7f6e\u4e3aFalse\uff0c\u53bb\u9664\u81ea\u5df1\u4e0e\u81ea\u5df1\u6bd4\u8f83\u7684\u60c5\u51b5\n    lb_eqs[dia_inds] = False\n    # \u590d\u5236\u4e00\u4efd\u8ddd\u79bb\u77e9\u9635\n    dist_same = distance_matrix.copy()\n    # \u5c06\u4e0d\u5c5e\u4e8e\u540c\u4e00\u7c7b\u4ee5\u53ca\u4e3b\u5bf9\u89d2\u7ebf\u4e0a\u7684\u8ddd\u79bb\u8bbe\u7f6e\u4e3a\u65e0\u7a77\u5927\n    dist_same[lb_eqs == False] = np.inf\n    # \u5bf9\u6bcf\u5f20\u56fe\u7247\uff0c\u627e\u51fa\u540c\u7c7b\u522b\u4e2d\u76f8\u4f3c\u5ea6\u6700\u9ad8\u7684\u56fe\u7247\uff0c\u6784\u6210\u4e00\u5bf9\u56fe\n    intra_idxs = np.argmin(dist_same, axis=1)\n\n    # \u4e0b\u9762\u6c42\u4e0d\u540c\u7c7b\u4e2d\uff0c\u76f8\u4f3c\u5ea6\u6700\u9ad8\u7684\u4e24\u7ec4\u56fe\u7247\n    dist_diff = distance_matrix.copy()\n    # \u548c\u4e0a\u4e2a\u60c5\u51b5\u4e00\u6837\uff0c\u53bb\u9664\u81ea\u5df1\u4e0e\u81ea\u5df1\u6bd4\u8f83\u7684\u60c5\u51b5\n    lb_eqs[dia_inds] = True\n    dist_diff[lb_eqs == True] = np.inf\n    # \u5bf9\u6bcf\u5f20\u56fe\u7247\uff0c\u627e\u51fa\u4e0d\u540c\u7c7b\u522b\u4e2d\u76f8\u4f3c\u5ea6\u6700\u9ad8\u7684\u56fe\u7247\uff0c\u6784\u6210\u4e00\u5bf9\u56fe\n    inter_idxs = np.argmin(dist_diff, axis=1)\n\n    # \u5206\u522b\u7528\u4e8e\u50a8\u5b58\u7c7b\u5185\u56fe\u7247\u5bf9\u548c\u7c7b\u95f4\u56fe\u7247\u5bf9\u7684\u7279\u5f81\u5e8f\u53f7(\u7d22\u5f15)\uff0c\u5c3a\u5bf8\u4e3abatch*2\n    # \u7b2c\u4e8c\u7ef4\u5ea6\u4e2d\uff0c\u7b2c\u4e00\u4e2a\u6570\u4ee3\u8868\u5f53\u524d\u56fe\u7247\u7684\u7d22\u5f15\uff0c\u7b2c\u4e8c\u4e2a\u6570\u4ee3\u8868\u4e0e\u4e4b\u76f8\u4f3c\u56fe\u7247\u7684\u5e8f\u53f7\uff0c\u4e0b\u9762\u7684labels\u7c7b\u4f3c\n    intra_pairs = np.zeros([embeddings.shape[0], 2])\n    inter_pairs = np.zeros([embeddings.shape[0], 2])\n    # \u5206\u522b\u7528\u4e8e\u50a8\u5b58\u7c7b\u5185\u56fe\u7247\u5bf9\u548c\u7c7b\u95f4\u56fe\u7247\u5bf9\u7684\u6807\u7b7e\uff0c\u5c3a\u5bf8\u4e3abatch*2\n    intra_labels = np.zeros([embeddings.shape[0], 2])\n    inter_labels = np.zeros([embeddings.shape[0], 2])\n    # \u4f9d\u6b21\u8d4b\u503c\n    for i in range(embeddings.shape[0]):\n        # \u7c7b\u5185\u56fe\u7247\n        # \u5f53\u524d\u56fe\u7247\u7684\u6807\u7b7e\n        intra_labels[i, 0] = labels[i]\n        # \u4e0e\u5f53\u524d\u56fe\u7247\u7c7b\u4f3c\u7684\u56fe\u7247\u6807\u7b7e\n        intra_labels[i, 1] = labels[intra_idxs[i]]\n        # \u5f53\u524d\u56fe\u7247\u5e8f\u53f7\n        intra_pairs[i, 0] = i\n        # \u4e0e\u5f53\u524d\u56fe\u7247\u7c7b\u4f3c\u7684\u56fe\u7247\u5e8f\u53f7\n        intra_pairs[i, 1] = intra_idxs[i]\n        # \u4e0b\u9762\u7c7b\u95f4\u56fe\u7247\uff0c\u4e0e\u4e0a\u8ff0\u64cd\u4f5c\u7c7b\u4f3c\n        inter_labels[i, 0] = labels[i]\n        inter_labels[i, 1] = labels[inter_idxs[i]]\n        inter_pairs[i, 0] = i\n        inter_pairs[i, 1] = inter_idxs[i]\n    # \u7edf\u4e00\u8f6c\u5316\u6210tensor\u683c\u5f0f\n    intra_labels = torch.from_numpy(intra_labels).long().to(device)\n    intra_pairs = torch.from_numpy(intra_pairs).long().to(device)\n    inter_labels = torch.from_numpy(inter_labels).long().to(device)\n    inter_pairs = torch.from_numpy(inter_pairs).long().to(device)\n    # \u6700\u540e\u8fd4\u56de\u56fe\u7247\u7684\u914d\u5bf9\u5e8f\u53f7\n    return intra_pairs, inter_pairs, intra_labels, inter_labels\n</code></pre>"},{"location":"fine-grained/code/API-Net2/#_5","title":"\u635f\u5931\u51fd\u6570","text":"<p>\u672c\u6587\u7528\u5230\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\u4e0e\u6392\u5e8f\u635f\u5931\u51fd\u6570\u53ef\u76f4\u63a5\u4ecenn\u6a21\u5757\u8c03\u53d6</p> <p>\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570</p> <pre><code>nn.CrossEntropyLoss()\n</code></pre> <p>\u6392\u5e8f\u635f\u5931\u51fd\u6570</p> <pre><code>nn.MarginRankingLoss(margin=0.05)\n</code></pre>"},{"location":"fine-grained/code/API-Net2/#_6","title":"\u6570\u636e\u91c7\u6837\u7b56\u7565","text":"<pre><code>class BalancedBatchSampler(BatchSampler):\n    def __init__(self, dataset, n_classes, n_samples):\n        # \u63d0\u53d6\u6807\u7b7e\n        self.labels = dataset.labels\n        # \u6807\u7b7e\u53d8\u6210\u5e8f\u5217\n        self.labels_set = list(set(self.labels.numpy()))\n        # \u6807\u7b7e(\u952e)\u4e0e\u6807\u7b7e\u5bf9\u5e94\u7684\u56fe\u7247\u5e8f\u53f7(\u503c)\n        self.label_to_indices = {label: np.where(self.labels.numpy() == label)[0]\n                                 for label in self.labels_set}\n        for l in self.labels_set:\n            # \u968f\u673a\u6253\u4e71\u6bcf\u4e00\u7c7b\u5185\u90e8\u7684\u56fe\u7247\u987a\u5e8f\n            np.random.shuffle(self.label_to_indices[l])\n        # used_label_indices_count\u8868\u793a\u6bcf\u7c7b\u4e2d\u88ab\u9009\u53d6\u7684\u56fe\u7247\u6570\u91cf\uff0c\u5b57\u5178\u683c\u5f0f\n        self.used_label_indices_count = {label: 0 for label in self.labels_set}\n        # count\u8868\u793a\u5f53\u524d\u53d6\u4e86\u591a\u5c11\u5f20\u56fe\u7247\n        self.count = 0\n        # \u4e00\u6b21\u53d6\u51e0\u7c7b\n        self.n_classes = n_classes\n        # \u4e00\u7c7b\u53d6\u51e0\u5f20\n        self.n_samples = n_samples\n        # \u8868\u793a\u6570\u636e\u96c6\n        self.dataset = dataset\n        # batch_size\u5927\u5c0f\n        self.batch_size = self.n_samples * self.n_classes\n\n    def __iter__(self):\n        self.count = 0\n        # \u5f53\u5df2\u7ecf\u9009\u53d6\u7684\u548c\u5373\u5c06\u9009\u53d6\u7684\u56fe\u7247\u6570\u91cf\u5927\u4e8e\u6570\u636e\u96c6\u603b\u6570\u65f6\uff0c\u505c\u6b62\u5faa\u73af\n        # \u5373\u9632\u6b62\u9009\u53d6\u7684\u56fe\u7247\u8d85\u51fa\u6570\u636e\u96c6\u6570\u91cf\n        while self.count + self.batch_size &lt; len(self.dataset):\n            # \u968f\u673a\u5728\u6807\u7b7e\u4e2d\uff0c\u6311\u9009n_classes\u4e2a\u6570\n            classes = np.random.choice(self.labels_set, self.n_classes, replace=False)\n            indices = []\n            for class_ in classes:\n                # extend\u8868\u793a\u6269\u5c55\u5217\u8868\uff0c\u5c06label_to_indices\u4e2d\u7684\u56fe\u7247\u7f16\u53f7\u9009\u53d6n_samples\u4e2a\u5e76\u5165indices\u4e2d\n                # indices\u5373\u4e3a\u6700\u7ec8\u7684\u8fed\u4ee3\u5668\n                indices.extend(self.label_to_indices[class_][\n                               self.used_label_indices_count[class_]:self.used_label_indices_count[\n                                                                         class_] + self.n_samples])\n                # \u66f4\u65b0\u6bcf\u7c7b\u7684\u6570\u636e\u91cf\n                self.used_label_indices_count[class_] += self.n_samples\n                # \u5982\u679c\u8be5\u7c7b\u7684\u9009\u53d6\u7c7b\u522b\u6570\u91cf\u5373\u5c06\u5927\u4e8e\u6807\u7b7e\u6570\u91cf\u7684\u8bdd\uff0c\u5c31\u518d\u6b21\u6253\u4e71\u7c7b\u522b\u6807\u7b7e\u5e8f\u53f7\n                # \u4e4b\u540e\u7c7b\u522b\u6807\u7b7e\u6570\u91cf\u5f52\u96f6\uff0c\u5373\u4ece\u5934\u5f00\u59cb\u9009\u53d6\n                if self.used_label_indices_count[class_] + self.n_samples &gt; len(self.label_to_indices[class_]):\n                    np.random.shuffle(self.label_to_indices[class_])\n                    self.used_label_indices_count[class_] = 0\n            # \u8fd4\u56de\u4e00\u4e2a\u8fed\u4ee3(iterable)\u5bf9\u8c61\uff0c\u6bcf\u6b21\u8fed\u4ee3\u8fd4\u56de\u56fe\u7247\u7d22\u5f15\u7f16\u53f7indices\n            # \u5373\u8fd4\u56de\u88ab\u9009\u7684\u56fe\u7247\u7d22\u5f15\uff0c\u5b8c\u6210\u4e00\u6b21\u91c7\u6837Sampler\n            yield indices\n            # \u66f4\u65b0\u53d6\u51fa\u7684\u6570\u636e\u91cf\n            self.count += self.n_classes * self.n_samples\n\n    def __len__(self):\n        return len(self.dataset) // self.batch_size\n</code></pre>"},{"location":"fine-grained/code/API-Net2/#_7","title":"\u8bad\u7ec3\u6d41\u7a0b","text":""},{"location":"fine-grained/code/API-Net2/#_8","title":"\u8bad\u7ec3\u521d\u59cb\u5316","text":"<pre><code>def main():\n    global args, best_prec1\n    # \u5f97\u5230\u4e4b\u524d\u9884\u5b9a\u4e49\u7684\u53c2\u6570\n    args = parser.parse_args()\n    # \u5b9a\u4e49\u968f\u673a\u79cd\u5b50\n    torch.manual_seed(2)\n    torch.cuda.manual_seed_all(2)\n    np.random.seed(2)\n\n    # \u5b9a\u4e49\u6a21\u578b\uff0c\u5e76\u4e14\u4f20\u5165GPU\u4e2d\n    model = API_Net(200)\n    model = model.to(device)\n    # \u5e76\u884c\u8bad\u7ec3\n    model.conv = nn.DataParallel(model.conv)\n\n    # \u5b9a\u4e49\u635f\u5931\u51fd\u6570\u4ee5\u53ca\u4f18\u5316\u5668\n    # \u5b9a\u4e49\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\n    criterion = nn.CrossEntropyLoss().to(device)\n    # \u5b9a\u4e49SGD\u4f18\u5316\u5668\uff0c\u7528\u4e8e\u4e00\u7cfb\u5217\u5377\u79ef\u64cd\u4f5c(\u7279\u5f81\u63d0\u53d6\u6a21\u5757)\n    optimizer_conv = torch.optim.SGD(model.conv.parameters(), args.lr,\n                                momentum=args.momentum,\n                                weight_decay=args.weight_decay)\n    # \u63d0\u53d6\u9664\u4e86\u5377\u79ef\u64cd\u4f5c(\u7279\u5f81\u63d0\u53d6)\u7684\u53c2\u6570\uff0c\u4ee5\u4fbf\u6784\u9020\u7b2c\u4e8c\u4e2a\u4f18\u5316\u5668\n    fc_parameters = [value for name, value in model.named_parameters() if 'conv' not in name]\n    optimizer_fc = torch.optim.SGD(fc_parameters, args.lr,\n                                momentum=args.momentum,\n                                weight_decay=args.weight_decay)\n    # \u5982\u679c\u6709\u9884\u8bad\u7ec3\u6a21\u578b\n    if args.resume:\n        if os.path.isfile(args.resume):\n            print('loading checkpoint {}'.format(args.resume))\n            # \u52a0\u8f7d\u6a21\u578b\n            checkpoint = torch.load(args.resume)\n            # \u52a0\u8f7d\u6a21\u578b\u4e2d\u7684\u8bad\u7ec3\u6b21\u6570\uff0c\u521d\u59cb\u5316start_epoch\n            args.start_epoch = checkpoint['epoch']\n            # \u52a0\u8f7d\u6700\u597d\u7684\u9884\u6d4b\u7cbe\u5ea6\n            best_prec1 = checkpoint['best_prec1']\n            # \u52a0\u8f7d\u6a21\u578b\u53c2\u6570\n            model.load_state_dict(checkpoint['state_dict'])\n            # \u52a0\u8f7d\u4e24\u4e2a\u4f18\u5316\u5668\n            optimizer_conv.load_state_dict(checkpoint['optimizer_conv'])\n            optimizer_fc.load_state_dict(checkpoint['optimizer_fc'])\n            print('loaded checkpoint {}(epoch {})'.format(args.resume, checkpoint['epoch']))\n        else:\n            print('no checkpoint found at {}'.format(args.resume))\n\n    # \u63d0\u9ad8\u8fd0\u7b97\u6548\u7387\n    cudnn.benchmark = True\n    # \u52a0\u8f7d\u6570\u636e\u96c6\uff0c\u5b9a\u4e49\u597d\u6570\u636e\u9884\u5904\u7406\u64cd\u4f5c\n    train_dataset = BatchDataset(transform=transforms.Compose([\n                                            transforms.Resize([512,512]),\n                                            transforms.RandomCrop([448,448]),\n                                            transforms.RandomHorizontalFlip(),\n                                            transforms.ToTensor(),\n                                            transforms.Normalize(\n                                                mean=(0.485, 0.456, 0.406),\n                                                std=(0.229, 0.224, 0.225)\n                                            )]))\n    # \u5b9a\u4e49\u6570\u636e\u91c7\u6837\u7b56\u7565\n    train_sampler = BalancedBatchSampler(train_dataset, args.n_classes, args.n_samples)\n    # \u6309\u7167\u5b9a\u4e49\u597d\u7684\u91c7\u6837\u7b56\u7565\uff0c\u751f\u6210\u6570\u636e\u96c6\u8fed\u4ee3\u5668\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_sampler=train_sampler,\n        num_workers=args.workers, pin_memory=True)\n    # \u4e24\u79cd\u4f18\u5316\u5668\u7684\u5b66\u4e60\u7387\u66f4\u65b0\u7b56\u7565\n    scheduler_conv = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_conv, 100*len(train_loader))\n    scheduler_fc = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_fc, 100*len(train_loader))\n\n    step = 0\n    print('START TIME:', time.asctime(time.localtime(time.time())))\n    # \u5f00\u59cb\u8bad\u7ec3\n    for epoch in range(args.start_epoch, args.epochs):\n        step = train(train_loader, model, criterion, optimizer_conv, scheduler_conv, optimizer_fc, scheduler_fc, epoch, step)\n</code></pre>"},{"location":"fine-grained/code/API-Net2/#_9","title":"\u8bad\u7ec3\u9636\u6bb5","text":"<pre><code>def train(train_loader, model, criterion, optimizer_conv,scheduler_conv, optimizer_fc, scheduler_fc, epoch, step):\n    global best_prec1\n    # \u90fd\u8f6c\u5316\u6210AverageMeter\u7c7b\uff0c\u50a8\u5b58\u6700\u8fd1\u3001\u5e73\u5747\u3001\u603b\u548c\u3001\u603b\u6570\u7b49\u6570\u503c\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    softmax_losses = AverageMeter()\n    rank_losses = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to train mode\n    end = time.time()\n    # \u5b9a\u4e49\u6392\u5e8f\u635f\u5931\n    rank_criterion = nn.MarginRankingLoss(margin=0.05)\n    # \u5b9a\u4e49Softmax\u51fd\u6570\n    softmax_layer = nn.Softmax(dim=1).to(device)\n    # \u5f00\u59cb\u8fed\u4ee3\u6570\u636e\u96c6\uff0c\u8fdb\u884c\u8bad\u7ec3\n    for i, (input, target) in enumerate(train_loader):\n        model.train()\n        # measure data loading time\n        # \u66f4\u65b0\u65f6\u95f4\n        data_time.update(time.time() - end)\n        # \u8f93\u5165\u4e0e\u6807\u7b7e\u4f20\u5165\u663e\u5361\n        input_var = input.to(device)\n        target_var = target.to(device).squeeze()\n\n        # \u8ba1\u7b97\u6a21\u578b\u8f93\u51fa\n        logit1_self, logit1_other, logit2_self, logit2_other, labels1, labels2 = model(input_var, target_var, flag='train')\n        # 2*batch_size(\u7c7b\u5185\u3001\u7c7b\u95f4\u5408\u5e76\u5230\u4e00\u8d77)\n        batch_size = logit1_self.shape[0]\n        # \u6807\u7b7e\u6570\u636e\u4f20\u5165cuda\n        labels1 = labels1.to(device)\n        labels2 = labels2.to(device)\n\n        # \u5206\u522b\u5c06self\u7684\u9884\u6d4b\u6982\u7387\u4ee5\u53caother\u7684\u9884\u6d4b\u6982\u7387\u5408\u5e76\u5230\u4e24\u4e2a\u53d8\u91cf\u91cc\uff0c\u5408\u5e76\u540e\u7b2c\u4e00\u7ef4\u5ea6\u5927\u5c0f\u5747\u4e3a4*batch\n        # \u5f97\u5230self_logits\u548cother_logits\n        self_logits = torch.zeros(2*batch_size, 200).to(device)\n        other_logits= torch.zeros(2*batch_size, 200).to(device)\n        self_logits[:batch_size] = logit1_self\n        self_logits[batch_size:] = logit2_self\n        other_logits[:batch_size] = logit1_other\n        other_logits[batch_size:] = logit2_other\n\n        # \u9884\u6d4b\u6982\u7387\u91cd\u65b0\u6574\u5408(self\u4e0eother\u5408\u5e76\u5230\u4e00\u5757)\uff0c\u7136\u540e\u8ba1\u7b97\u5206\u7c7b\u635f\u5931\n        # \u6b64\u65f6\u6709\u4e24\u7ec4(self\u548cother)\u6982\u7387\uff0c\u6bcf\u7ec4\u5185\u90e8\u53c8\u6709\u4e24\u7ec4(\u5f53\u524d\u56fe\u3001\u4e0e\u5f53\u524d\u56fe\u505a\u6bd4\u8f83\u7684\u56fe)\u6982\u7387\n        # \u6bcf\u7ec4\u5185\u90e8\u53c8\u6709\u4e24\u7ec4(\u7c7b\u5185\u3001\u7c7b\u95f4)\u6982\u7387\n        # \u56e0\u6b64\uff0c\u6700\u7ec8\u5f97\u5230\u7684\u9884\u6d4b\u6982\u7387\u7b2c\u4e00\u7ef4\u5ea6\u5927\u5c0f\u4e3a8*batch\n        logits = torch.cat([self_logits, other_logits], dim=0)\n        # \u5f97\u5230\u603b\u6807\u7b7e\uff0c\u6ce8\u610f\u6807\u7b7e\u987a\u5e8f\u9700\u8981\u548c\u9884\u6d4b\u6982\u7387\u4e00\u4e00\u5bf9\u5e94\n        targets = torch.cat([labels1, labels2, labels1, labels2], dim=0)\n        # \u8ba1\u7b97\u5f97\u5230\u5206\u7c7b\u635f\u5931\n        softmax_loss = criterion(logits, targets)\n        # \u5f97\u5230self\u4e2d\u7684\u6807\u7b7e\u7c7b\u522b\u9884\u6d4b\u6982\u7387\uff0c\u7528\u4e8e\u8ba1\u7b97\u5f97\u5230\u6392\u5e8f\u635f\u5931\n        self_scores = softmax_layer(self_logits)[torch.arange(2*batch_size).to(device).long(),\n                                                         torch.cat([labels1, labels2], dim=0)]\n        # \u5f97\u5230other\u4e2d\u7684\u6807\u7b7e\u7c7b\u522b\u9884\u6d4b\u6982\u7387\n        other_scores = softmax_layer(other_logits)[torch.arange(2*batch_size).to(device).long(),\n                                                         torch.cat([labels1, labels2], dim=0)]\n        flag = torch.ones([2*batch_size, ]).to(device)\n        # flag\u4e3a\u51681\u5411\u91cf\uff0c\u8868\u793a\u6bcf\u4e2a\u4f4d\u7f6e\u4e0a\uff0cself_scores\u4e2d\u7684\u503c\u90fd\u5e94\u8be5\u5728other_scores\u524d\u9762\n        # \u6392\u5e8f\u635f\u5931\u8ba1\u7b97\u8fc7\u7a0b\u4e3a\uff1a-y*(self_scores-other_scores)\n        rank_loss = rank_criterion(self_scores, other_scores, flag)\n        # \u5f97\u5230\u6700\u7ec8\u7684\u635f\u5931\n        loss = softmax_loss + rank_loss\n\n        # \u8ba1\u7b97\u6a21\u578b\u7cbe\u5ea6:top-1\u548ctop-5\n        prec1 = accuracy(logits, targets, 1)\n        prec5 = accuracy(logits, targets, 5)\n        # \u4f9d\u6b21\u66f4\u65b0\u50a8\u5b58\u7684\u603b\u635f\u5931\u3001\u5206\u7c7b\u635f\u5931\u3001\u6392\u5e8f\u635f\u5931\u3001top1\u7cbe\u5ea6\u3001top5\u7cbe\u5ea6\n        losses.update(loss.item(), 2*batch_size)\n        softmax_losses.update(softmax_loss.item(), 4*batch_size)\n        rank_losses.update(rank_loss.item(), 2*batch_size)\n        top1.update(prec1, 4*batch_size)\n        top5.update(prec5, 4*batch_size)\n\n        # \u68af\u5ea6\u6e05\u96f6\n        optimizer_conv.zero_grad()\n        optimizer_fc.zero_grad()\n        # \u53cd\u5411\u4f20\u64ad\u8ba1\u7b97\u68af\u5ea6\uff0c\u5e76\u4e14\u66f4\u65b0\u53c2\u6570\n        loss.backward()\n        # \u524d8\u6b21\u8fed\u4ee3\uff0c\u4e0d\u66f4\u65b0\u7279\u5f81\u63d0\u53d6\u6a21\u5757\n        if epoch &gt;= 8:\n            optimizer_conv.step()\n        # \u66f4\u65b0\u53c2\u6570\u4e0e\u5b66\u4e60\u7387\n        optimizer_fc.step()\n        scheduler_conv.step()\n        scheduler_fc.step()\n\n        # \u8ba1\u7b97\u65f6\u95f4\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        # \u8f93\u51fa\u8bad\u7ec3\u4fe1\u606f\n        if i % args.print_freq == 0:\n            print('Time: {time}\\nStep: {step}\\t Epoch: [{0}][{1}/{2}]\\t'\n                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n                  'SoftmaxLoss {softmax_loss.val:.4f} ({softmax_loss.avg:.4f})\\t'\n                  'RankLoss {rank_loss.val:.4f} ({rank_loss.avg:.4f})\\t'\n                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n                  'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n                   epoch, i, len(train_loader), batch_time=batch_time,\n                   data_time=data_time, loss=losses, softmax_loss=softmax_losses, rank_loss=rank_losses,\n                   top1=top1, top5=top5, step=step, time= time.asctime(time.localtime(time.time()))))\n        # \u5982\u679c\u662f\u5f53\u524depoch\u4e2d\u6700\u540e\u4e00\u6b21\u8bad\u7ec3\uff0c\u5219\u5229\u7528\u9a8c\u8bc1\u96c6\u8fdb\u884c\u6d4b\u8bd5\n        if i == len(train_loader) - 1:\n            # \u52a0\u8f7d\u6570\u636e\u96c6\n            val_dataset = RandomDataset(transform=transforms.Compose([\n                transforms.Resize([512,512]),\n                transforms.CenterCrop([448,448]),\n                transforms.ToTensor(),\n                transforms.Normalize(\n                    mean=(0.485, 0.456, 0.406),\n                    std=(0.229, 0.224, 0.225)\n                )]))\n            # \u7531\u4e8e\u9a8c\u8bc1\u9636\u6bb5\u662f\u4e00\u5f20\u56fe\u4e00\u5f20\u56fe\u5730\u9a8c\u8bc1\uff0c\u56e0\u6b64\u5bf9\u6570\u636e\u96c6\u7684\u91c7\u6837\u6ca1\u6709\u8981\u6c42\uff0c\u4e0d\u9700\u8981\u66f4\u65b0\u91c7\u6837\u7b56\u7565\n            val_loader = torch.utils.data.DataLoader(\n                val_dataset, batch_size=args.batch_size, shuffle=False,\n                num_workers=args.workers, pin_memory=True)\n            # \u5f97\u5230\u9a8c\u8bc1\u7cbe\u5ea6\n            prec1 = validate(val_loader, model, criterion)\n\n            # \u5224\u65ad\u662f\u5426\u9a8c\u8bc1\u7cbe\u5ea6\u5927\u4e8e\u5f53\u524d\u6700\u597d\u7684\u7cbe\u5ea6\n            is_best = prec1 &gt; best_prec1\n            best_prec1 = max(prec1, best_prec1)\n            # \u6a21\u578b\u4fdd\u5b58\u7b56\u7565\uff0c\u662f\u5426\u4fdd\u5b58\u53d6\u51b3\u4e8eis_best\n            save_checkpoint({\n                'epoch': epoch + 1,\n                'state_dict': model.state_dict(),\n                'best_prec1': best_prec1,\n                'optimizer_conv': optimizer_conv.state_dict(),\n                'optimizer_fc': optimizer_fc.state_dict(),\n            }, is_best)\n\n        step = step +1\n    return step\n</code></pre> <p>\u6a21\u578b\u4fdd\u5b58\u51fd\u6570\uff1a</p> <pre><code>def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n    torch.save(state, filename)\n    if is_best:\n        # \u5c06\u53c2\u6570\u6587\u4ef6\u590d\u5236\u4e3amodel_best.pth.tar\n        shutil.copyfile(filename, 'model_best.pth.tar')\n</code></pre>"},{"location":"fine-grained/code/API-Net2/#_10","title":"\u9a8c\u8bc1\u9636\u6bb5","text":"<p><pre><code>def validate(val_loader, model, criterion):\n    # \u521d\u59cb\u5316\u5404\u79cd\u53d8\u91cf\n    batch_time = AverageMeter()\n    softmax_losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n    end = time.time()\n    # \u52a0\u8f7d\u6570\u636e\u96c6\n    with torch.no_grad():\n        for i, (input, target) in enumerate(val_loader):\n            # \u6570\u636e\u4f20\u5165cuda\n            input_var = input.to(device)\n            target_var = target.to(device).squeeze()\n\n            # \u8ba1\u7b97\u635f\u5931\u8f93\u51fa\n            logits = model(input_var, targets=None, flag='val')\n            # \u8ba1\u7b97\u5206\u7c7b\u635f\u5931\n            softmax_loss = criterion(logits, target_var)\n\n            # \u8ba1\u7b97top1\u7cbe\u5ea6\n            prec1= accuracy(logits, target_var, 1)\n            # \u8ba1\u7b97top5\u7cbe\u5ea6\n            prec5 = accuracy(logits, target_var, 5)\n            # \u66f4\u65b0\u5206\u7c7b\u635f\u5931\u3001top1\u3001top2\n            softmax_losses.update(softmax_loss.item(), logits.size(0))\n            top1.update(prec1, logits.size(0))\n            top5.update(prec5, logits.size(0))\n\n            # \u8ba1\u7b97\u65f6\u95f4\n            batch_time.update(time.time() - end)\n            end = time.time()\n            # \u8f93\u51fa\u8bad\u7ec3\u4fe1\u606f\n            if i % args.print_freq == 0:\n                print('Time: {time}\\nTest: [{0}/{1}]\\t'\n                        'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n                        'SoftmaxLoss {softmax_loss.val:.4f} ({softmax_loss.avg:.4f})\\t'\n                        'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n                        'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n                        i, len(val_loader), batch_time=batch_time, softmax_loss=softmax_losses,\n                        top1=top1, top5=top5, time=time.asctime(time.localtime(time.time()))))\n        print(' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n    # \u8fd4\u56de\u7cbe\u5ea6\n    return top1.avg\n</code></pre> \u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u5927\u5bb6\u6279\u8bc4\u6307\u6b63</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e7411\u670821\u65e5</p>"},{"location":"fine-grained/code/B-CNN2/","title":"\u7ec6\u7c92\u5ea6\uff1aB-CNN","text":""},{"location":"fine-grained/code/B-CNN2/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aIEEE International Conference on Computer Vision 2015 (ICCV 2015)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Lin_Bilinear_CNN_Models_ICCV_2015_paper.pdf</p> <p>\u4ee3\u7801\u94fe\u63a5\uff08PyTorch\u7248\u672c\uff0c\u975e\u5b98\u65b9\uff09\uff1ahttps://github.com/HaoMood/bilinear-cnn</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u7c7b(FGVC)</p>"},{"location":"fine-grained/code/B-CNN2/#_2","title":"\u4ee3\u7801\u5b9e\u73b0","text":"<p>\u2003\u2003\u7b80\u5355\u6765\u8bf4\uff0c\u53cc\u7ebf\u6027\u6c60\u5316\u5c31\u662f\u4e24\u7ec4\u7279\u5f81\u56fe\u4e92\u76f8\u505a\u4e58\u79ef\uff0cA\u4e2d\u6bcf\u5f20\u7279\u5f81\u56fe\u548cB\u4e2d\u6bcf\u5f20\u7279\u5f81\u56fe\u505a\u4e58\u79ef\uff0c\u4e00\u5171\u4f1a\u5f97\u5230C_A\u548cC_B\u5f20\u7279\u5f81\u56fe\uff08C\u8868\u793a\u901a\u9053\u6570\uff09\uff0c\u4e4b\u540e\u6bcf\u5f20\u7279\u5f81\u56fe\u518d\u505a\u5168\u5c40\u5e73\u5747\u6c60\u5316\uff0c\u5bf9\u5e94\u77e9\u9635\u4e58\u79ef\u4e2d\u7684\u6c42\u548c\uff0c\u4ee5\u53ca\u5f52\u4e00\u5316\u64cd\u4f5c\uff08\u9664\u4ee5\u957f\u5bbd\u4e4b\u79ef\uff09\uff0c\u6700\u7ec8\u5f97\u5230\u7684\u7279\u5f81\u6570\u636e\u5c3a\u5bf8\u4e3a(B,C_A,C_B)\u3002\uff08\u53ef\u4ee5\u7ed3\u5408WS-DAN\u4e2d\u7684\u5e94\u7528\u6765\u7406\uff0cWS-DAN\u5c31\u662f\u4e3a\u4e86\u5145\u5206\u5229\u7528\u6240\u6709\u7684\u6ce8\u610f\u529b\u56fe\u624d\u91c7\u7528\u53cc\u7ebf\u6027\u6c60\u5316\u64cd\u4f5c\u3002\uff09</p> <p>\u5047\u8bbeX\u548cY\u662f\u5f85\u878d\u5408\u7684\u4e24\u7ec4\u7279\u5f81</p> <p>\u65b9\u5f0f\u4e00\uff1a</p> <p>\u5229\u7528\u77e9\u9635\u4e58\u79ef</p> <pre><code>import torch\n\nx = torch.rand((2,4,5,6))\ny = torch.rand((2,3,5,6))\n# \u5408\u5e76\u5bbd\u9ad8\u7ef4\u5ea6\nx1 = torch.reshape(x, (2, 4, 5 * 6))\ny1 = torch.reshape(y, (2, 3, 5 * 6))\n# \u5148\u8f6c\u7f6e\uff0c\u518d\u4e58\u79ef\na2 = torch.bmm(x1, torch.transpose(y1, 1, 2))\nprint(a2.shape)\nprint(a2)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># \u8f93\u51fa\u5c3a\u5bf8\u4e3a\u4e24\u7ec4\u7279\u5f81\u56fe\u7684\u901a\u9053\u6570\ntorch.Size([2, 4, 3])\ntensor([[[8.5686, 9.2178, 8.1480],\n         [7.6605, 8.8889, 7.4322],\n         [7.1803, 8.5409, 6.8328],\n         [8.0793, 8.9139, 7.4227]],\n\n        [[7.0898, 9.3404, 9.6230],\n         [7.2315, 8.1439, 9.4451],\n         [7.5622, 7.6522, 9.4802],\n         [4.8507, 6.3615, 7.3697]]])\n</code></pre> <p>\u65b9\u5f0f\u4e8c\uff1a</p> <p>\u5229\u7528\u7231\u56e0\u65af\u5766\u6c42\u548c\u7ea6\u5b9a</p> <pre><code>import torch\n\nx = torch.rand((2,4,5,6))\ny = torch.rand((2,3,5,6))\na1 = torch.einsum('imjk,injk-&gt;imn',x,y)\nprint(a1.shape)\nprint(a1)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code>torch.Size([2, 4, 3])\ntensor([[[ 8.6233,  8.0064,  5.0810],\n         [10.4337,  9.4304,  7.1013],\n         [ 8.2184,  6.7143,  5.0488],\n         [ 7.2257,  7.1047,  4.8244]],\n\n        [[ 6.1212,  6.3353,  6.8132],\n         [ 7.5675,  7.4697,  7.9084],\n         [ 6.7426,  6.5126,  7.9303],\n         [ 8.3843,  7.5638,  8.5947]]])\n</code></pre> <p>\u521d\u6b65\u5b8c\u7a3f\u4e8e\uff1a2023\u5e741\u670829\u65e5</p>"},{"location":"fine-grained/code/CAL2/","title":"\u7ec6\u7c92\u5ea6\uff1aCAL","text":""},{"location":"fine-grained/code/CAL2/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aIEEE International Conference on Computer Vision 2021 (ICCV, 2021)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content/ICCV2021/papers/Rao_Counterfactual_Attention_Learning_for_Fine-Grained_Visual_Categorization_and_Re-Identification_ICCV_2021_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740(PyTorch\u7248\u672c)\uff1ahttps://github.com/raoyongming/CAL</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u7c7b(FGVC)\u3001\u884c\u4eba\u91cd\u8bc6\u522b</p> <p>\u5d4c\u5165CAL\u6b65\u9aa4\u5982\u4e0b\uff1a</p> <ul> <li>\u627e\u5230\u6ce8\u610f\u529b\u56fe\u7684\u751f\u6210\u90e8\u5206\uff0c\u968f\u673a\u521d\u59cb\u5316\u4e00\u5f20\u6ce8\u610f\u529b\u56fe\uff0c\u5c3a\u5bf8\u548c\u539f\u6ce8\u610f\u529b\u56fe\u5c3a\u5bf8\u76f8\u540c\uff1b</li> <li>\u8ba9\u968f\u673a\u7684\u6ce8\u610f\u529b\u56fe\u548c\u539f\u59cb\u6ce8\u610f\u529b\u56fe\u7ecf\u8fc7\u4e00\u6837\u7684\u64cd\u4f5c\uff0c\u5f97\u5230\u5206\u7c7b\u6982\u7387\uff1b</li> <li>\u5c06\u5206\u7c7b\u6982\u7387\u505a\u5dee\uff08\u539f\u59cb-\u968f\u673a\uff09\uff0c\u4e4b\u540e\u548c\u771f\u5b9e\u7c7b\u522b\u6807\u7b7e\u505a\u4ea4\u53c9\u71b5\u635f\u5931\u3002</li> </ul> <p>\u5176\u4e2d\uff0c\u8bba\u6587\u5171\u6709\u56db\u79cd\u968f\u673a\u65b9\u5f0f\uff0c\u5206\u522b\u4e3a\u968f\u673a\u6ce8\u610f\u529b\u3001\u5747\u5300\u6ce8\u610f\u529b\u3001\u53cd\u8f6c\u6ce8\u610f\u529b\u4ee5\u53ca\u6253\u4e71\u6ce8\u610f\u529b\uff1a</p> <ul> <li>\u968f\u673a\u6ce8\u610f\u529b\uff1a\u4f7f\u7528\u968f\u673a\u751f\u6210\u7684\u6ce8\u610f\u529b\u56fe\u5f53\u505a\u53cd\u4e8b\u5b9e\u6ce8\u610f\u529b\u56fe\uff0c\u6ce8\u610f\u529b\u56fe\u7684\u6570\u636e\u5206\u5e03\u670d\u4ece\u5747\u5300\u5206\u5e03\\mathcal U(0,2)\uff1b</li> <li>\u5747\u5300\u6ce8\u610f\u529b\uff1a\u9996\u5148\u8ba1\u7b97\u771f\u5b9e\u6ce8\u610f\u529b\u56fe\u6570\u636e\u7684\u5e73\u5747\u503c\uff0c\u4e4b\u540e\u5229\u7528\u8be5\u503c\u586b\u5145\u539f\u6ce8\u610f\u529b\u56fe\uff0c\u5373\u751f\u6210\u4e00\u5f20\u503c\u552f\u4e00\u7684\u56fe\uff1b</li> <li>\u53cd\u8f6c\u6ce8\u610f\u529b\uff1a\u901a\u8fc7\u5c06\u539f\u6ce8\u610f\u529b\u56fe\u51cf\u53bb\u8be5\u6ce8\u610f\u529b\u56fe\u4e0a\u7684\u6700\u5927\u503c\uff0c\u6765\u53cd\u8f6c\u6ce8\u610f\u529b\u7684\u5173\u6ce8\u533a\u57df\uff1b</li> <li>\u6253\u4e71\u6ce8\u610f\u529b\uff1a\u6cbf\u6279\u6b21(batch)\u7ef4\u5ea6\u968f\u673a\u6253\u4e71\u6ce8\u610f\u529b\u56fe\u3002</li> </ul> <p>\u5b9e\u9a8c\u8bc1\u660e\uff0c\u968f\u673a\u6ce8\u610f\u529b\u548c\u6253\u4e71\u6ce8\u610f\u529b\u6548\u679c\u8f83\u597d\uff0c\u4f46\u662f\u5747\u503c\u548c\u53cd\u8f6c\u6ca1\u8bf4\u662f\u5426\u8981\u5207\u65ad\u68af\u5ea6\uff0c\u5b9e\u9a8c\u8fc7\u7a0b\u53ef\u4ee5\u8bd5\u4e00\u4e0b\u3002</p>"},{"location":"fine-grained/code/CAL2/#_2","title":"\u4ee3\u7801\u5b9e\u73b0","text":"<p>\u4ee5wsdan\u4e3a\u4f8b</p>"},{"location":"fine-grained/code/CAL2/#_3","title":"\u7f51\u7edc\u7ed3\u6784","text":"<p>\u53ea\u6ce8\u91ca\u4e86CAL\u65b0\u52a0\u7684\u90e8\u5206</p> <pre><code>class WSDAN_CAL(nn.Module):\n    def __init__(self, num_classes, M=32, net='inception_mixed_6e', pretrained=False):\n        super(WSDAN_CAL, self).__init__()\n        self.num_classes = num_classes\n        self.M = M\n        self.net = net\n\n        # Network Initialization\n        if 'inception' in net:\n            if net == 'inception_mixed_6e':\n                self.features = inception_v3(pretrained=pretrained).get_features_mixed_6e()\n                self.num_features = 768\n            elif net == 'inception_mixed_7c':\n                self.features = inception_v3(pretrained=pretrained).get_features_mixed_7c()\n                self.num_features = 2048\n            else:\n                raise ValueError('Unsupported net: %s' % net)\n        elif 'vgg' in net:\n            self.features = getattr(vgg, net)(pretrained=pretrained).get_features()\n            self.num_features = 512\n        elif 'resnet' in net:\n            self.features = getattr(resnet, net)(pretrained=pretrained).get_features()\n            self.num_features = 512 * self.features[-1][-1].expansion\n        elif 'att' in net:\n            print('==&gt; Using MANet with resnet101 backbone')\n            self.features = MANet()\n            self.num_features = 2048\n        else:\n            raise ValueError('Unsupported net: %s' % net)\n\n        # Attention Maps\n        self.attentions = BasicConv2d(self.num_features, self.M, kernel_size=1)\n\n        # Bilinear Attention Pooling\n        self.bap = BAP(pool='GAP')\n\n        # Classification Layer\n        self.fc = nn.Linear(self.M * self.num_features, self.num_classes, bias=False)\n\n        logging.info(\n            'WSDAN: using {} as feature extractor, num_classes: {}, num_attentions: {}'.format(net, self.num_classes,\n\n\n    def forward(self, x):\n        batch_size = x.size(0)\n\n        # Feature Maps, Attention Maps and Feature Matrix\n        feature_maps = self.features(x)\n        if self.net != 'inception_mixed_7c':\n            attention_maps = self.attentions(feature_maps)\n        else:\n            attention_maps = feature_maps[:, :self.M, ...]\n        # \u591a\u63a5\u6536\u4e00\u4e2a\u5229\u7528\u968f\u673a\u6ce8\u610f\u529b\u6c42\u5f97\u7684\u7279\u5f81\u77e9\u9635\n        feature_matrix, feature_matrix_hat = self.bap(feature_maps, attention_maps)\n\n        # Classification\n        p = self.fc(feature_matrix * 100.)\n\n        # Generate Attention Map\n        if self.training:\n            # Randomly choose one of attention maps Ak\n            attention_map = []\n            for i in range(batch_size):\n                attention_weights = torch.sqrt(attention_maps[i].sum(dim=(1, 2)).detach() + EPSILON)\n                attention_weights = F.normalize(attention_weights, p=1, dim=0)\n                k_index = np.random.choice(self.M, 2, p=attention_weights.cpu().numpy())\n                attention_map.append(attention_maps[i, k_index, ...])\n            attention_map = torch.stack(attention_map)  # (B, 2, H, W) - one for cropping, the other for dropping\n        else:\n            attention_map = torch.mean(attention_maps, dim=1, keepdim=True)  # (B, 1, H, W)\n        # \u591a\u8fd4\u56de\u4e00\u4e2a\u6982\u7387\u505a\u5dee\u7684\u7ed3\u679c\uff08\u7b2c\u4e8c\u4e2a\u53c2\u6570\uff09\n        return p, p - self.fc(feature_matrix_hat * 100.), feature_matrix, attention_map\n</code></pre>"},{"location":"fine-grained/code/CAL2/#bap","title":"BAP\u6a21\u5757","text":"<pre><code>class BAP(nn.Module):\n    def __init__(self, pool='GAP'):\n        super(BAP, self).__init__()\n        assert pool in ['GAP', 'GMP']\n        if pool == 'GAP':\n            self.pool = None\n        else:\n            self.pool = nn.AdaptiveMaxPool2d(1)\n\n    def forward(self, features, attentions):\n        B, C, H, W = features.size()\n        _, M, AH, AW = attentions.size()\n\n        # match size\n        if AH != H or AW != W:\n            attentions = F.upsample_bilinear(attentions, size=(H, W))\n\n        # feature_matrix: (B, M, C) -&gt; (B, M * C)\n        if self.pool is None:\n            feature_matrix = (torch.einsum('imjk,injk-&gt;imn', (attentions, features)) / float(H * W)).view(B, -1)\n        else:\n            feature_matrix = []\n            for i in range(M):\n                AiF = self.pool(features * attentions[:, i:i + 1, ...]).view(B, -1)\n                feature_matrix.append(AiF)\n            feature_matrix = torch.cat(feature_matrix, dim=1)\n\n        # sign-sqrt\n        feature_matrix_raw = torch.sign(feature_matrix) * torch.sqrt(torch.abs(feature_matrix) + EPSILON)\n\n        # l2 normalization along dimension M and C\n        feature_matrix = F.normalize(feature_matrix_raw, dim=-1)\n\n        if self.training:\n            # \u968f\u673a\u751f\u6210\u4e00\u4e2a\u6ce8\u610f\u529b\u56fe\uff0c0-2\u4e4b\u95f4\u7684\u5747\u5300\u5206\u5e03\n            fake_att = torch.zeros_like(attentions).uniform_(0, 2)\n        else:\n            fake_att = torch.ones_like(attentions)\n        # \u7ecf\u8fc7\u76f8\u540c\u7684\u64cd\u4f5c\uff0c\u518d\u8fd4\u56de\n        counterfactual_feature = (torch.einsum('imjk,injk-&gt;imn', (fake_att, features)) / float(H * W)).view(B, -1)\n\n        counterfactual_feature = torch.sign(counterfactual_feature) * torch.sqrt(\n            torch.abs(counterfactual_feature) + EPSILON)\n\n        counterfactual_feature = F.normalize(counterfactual_feature, dim=-1)\n        return feature_matrix, counterfactual_feature\n</code></pre> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u6307\u6b63</p> <p>\u521d\u6b65\u5b8c\u7a3f\u4e8e2023\u5e741\u670829\u65e5</p>"},{"location":"fine-grained/code/Cross-X2/","title":"\u7ec6\u7c92\u5ea6\uff1aCross-X","text":""},{"location":"fine-grained/code/Cross-X2/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aIEEE International Conference on Computer Vision 2019 (ICCV, 2019)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttp://openaccess.thecvf.com/content_ICCV_2019/papers/Luo_Cross-X_Learning_for_Fine-Grained_Visual_Categorization_ICCV_2019_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740(PyTorch\u7248\u672c)\uff1ahttps://github.com/cswluo/CrossX</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u7c7b(FGVC)</p>"},{"location":"fine-grained/code/Cross-X2/#_2","title":"\u7f51\u7edc\u7ed3\u6784","text":"<p>\u4ee5Cross-X(ResNet)-GAP\u4e3a\u4f8b</p>"},{"location":"fine-grained/code/Cross-X2/#_3","title":"\u7f51\u7edc\u521d\u59cb\u5316\u9636\u6bb5","text":"<pre><code>class ResNet(nn.Module):\n\n    def __init__(self, block, layers, nparts=1, meflag=False, num_classes=1000):\n        self.nparts = nparts\n        self.nclass = num_classes\n        self.meflag = meflag\n        self.inplanes = 64\n        # \u4ece\u8fd9\u4e00\u76f4\u5230layer3\u4e4b\u524d\uff0c\u90fd\u4e0eresnet\u76f8\u540c\n        super(ResNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        # \u4ece\u65b0\u5b9a\u4e49layer3\u4e0elayer4\uff0c\u589e\u52a0\u4e86OSME\u6a21\u5757\n        self.layer3 = self._make_layer(block, 256, layers[2], meflag=meflag, stride=2, nparts=nparts, reduction=256)\n        self.layer4 = self._make_layer(block, 512, layers[3], meflag=meflag, stride=2, nparts=nparts, reduction=256)\n        self.adpavgpool = nn.AdaptiveAvgPool2d(1)\n        # \u5b9a\u4e49\u6700\u7ec8(L\u9636\u6bb5)\u7684\u5206\u7c7b\u5c42\n        self.fc_ulti = nn.Linear(512 * block.expansion * nparts, num_classes)\n\n        # \u5982\u679cnparts(\u6fc0\u52b1\u6a21\u5757\u6570\u91cf\uff0c\u8bba\u6587\u4e2d\u8bbe\u7f6e\u4e3a2\u62163)\u5927\u4e8e1\uff0c\u5373\u5b58\u5728OMSE\u6a21\u5757\uff0c\u5219\u9700\u8981\u76f8\u5e94\u5730\u589e\u52a0\u5377\u79ef\u5c42\u4e0e\u5206\u7c7b\u5668\n        if self.nparts &gt; 1:\n            # \u589e\u52a0\u4e00\u4e2a\u5168\u5c40\u6700\u5927\u6c60\u5316\u5c42(L-1\u9636\u6bb5\u7279\u5f81\u56fe\u53d8\u4e3a\u7279\u5f81\u5411\u91cf\u65f6\uff0c\u53ef\u80fd\u4f1a\u7528\u5230)\n            self.adpmaxpool = nn.AdaptiveMaxPool2d(1)\n            # \u5b9a\u4e49L-1\u9636\u6bb5\u7279\u5f81\u5411\u91cf\u7684\u5206\u7c7b\u5668\n            self.fc_plty = nn.Linear(256 * block.expansion * nparts, num_classes)\n            # \u5b9a\u4e49\u7efc\u5408\u7279\u5f81\u5411\u91cf(\u4e24\u9636\u6bb5\u7279\u5f81\u56fe\u7ecf\u8fc7\u516c\u5f0f(5)\u5408\u5e76\u540e)\u7684\u5206\u7c7b\u5668\n            self.fc_cmbn = nn.Linear(256 * block.expansion * nparts, num_classes)\n\n            # for the last convolutional layer\n            # \u4ee5\u4e0b\u4e09\u7ec4\u64cd\u4f5c\u5bf9\u5e94\u8bba\u6587\u4e2d\u516c\u5f0f(5)\n            # \u540e\u7f001\u548c2\u5206\u522b\u5bf9\u5e94\u7b2c\u4e00\u7ec4\u7279\u5f81\u56fe(p=1)\u548c\u7b2c\u4e8c\u7ec4\u7279\u5f81\u56fe(p=2)\n            # \u5b9a\u4e49\u5377\u79ef\u6838\u4e3a1*1\u7684\u5377\u79ef\u5c42\uff0c\u7528\u4e8eL\u9636\u6bb5\u7279\u5f81\u56fe\u901a\u9053\u7684\u538b\u7f29(2048-&gt;1024)\uff0c\u4fbf\u4e8e\u548cL-1\u9636\u6bb5\u76f8\u5408\u5e76\n            self.conv2_1 = nn.Conv2d(512 * block.expansion, 256 * block.expansion, kernel_size=1, bias=False)\n            self.conv2_2 = nn.Conv2d(512 * block.expansion, 256 * block.expansion, kernel_size=1, bias=False)\n\n            # for the penultimate layer\n            # \u7279\u5f81\u56fe\u5408\u5e76\u65f6\u7528\u5230\u76843*3\u7684\u5377\u79ef\u5c42\n            self.conv3_1 = nn.Conv2d(256 * block.expansion, 256 * block.expansion, kernel_size=3, padding=1, bias=False)\n            self.conv3_2 = nn.Conv2d(256 * block.expansion, 256 * block.expansion, kernel_size=3, padding=1, bias=False)\n            # \u7279\u5f81\u56fe\u5408\u5e76\u65f6\u7528\u5230\u7684\u6807\u51c6\u5316\u5c42\n            self.bn3_1 = nn.BatchNorm2d(256 * block.expansion)\n            self.bn3_2 = nn.BatchNorm2d(256 * block.expansion)\n\n            if nparts == 3:\n                # \u5982\u679cP=3\uff0c\u5373\u6709\u4e09\u4e2a\u6fc0\u52b1\u6a21\u5757\uff0c\u5219\u9700\u8981\u518d\u52a0\u4e00\u7ec4\u5377\u79ef\u64cd\u4f5c\n                self.conv2_3 = nn.Conv2d(512 * block.expansion, 256 * block.expansion, kernel_size=1, bias=False)\n                self.conv3_3 = nn.Conv2d(256 * block.expansion, 256 * block.expansion, kernel_size=3, padding=1, bias=False)\n                self.bn3_3 = nn.BatchNorm2d(256 * block.expansion)\n\n        # \u968f\u673a\u521d\u59cb\u5316\u7f51\u7edc\u53c2\u6570\uff0c\u4e0eresnet\u4e2d\u7684\u521d\u59cb\u5316\u65b9\u6cd5\u4e00\u6837\n        for m in self.modules():\n            # \u5377\u79ef\u5c42\u4e2d\u7684\u53c2\u6570\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            # \u6807\u51c6\u5316\u5c42\u4e2d\u7684\u53c2\u6570\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n</code></pre> <p>Bottleneck\u6a21\u5757\uff1a\u5728\u539fresnet\u7684\u57fa\u7840\u4e0a\uff0c\u6dfb\u52a0\u4e86OSME\u6a21\u5757</p> <pre><code>class Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None, meflag=False, nparts=1, reduction=1):\n        # \u4ece\u8fd9\uff0c\u4e00\u76f4\u5230self.meflag\u4e4b\u524d\uff0c\u90fd\u4e0eresnet\u4e2d\u4e00\u6837\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        # \u662f\u5426\u6dfb\u52a0OSME\u7684\u6807\u5fd7\n        self.meflag = meflag\n        if self.meflag:\n            # \u5982\u679c\u6dfb\u52a0OSME\uff0c\u5219\u521d\u59cb\u5316me\u6a21\u5757\n            self.me = MELayer(planes * 4, nparts=nparts, reduction=reduction)\n        # \u4e0b\u91c7\u6837\u64cd\u4f5c\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        # \u4ece\u8fd9\u91cc\uff0c\u4e00\u76f4\u5230if self.meflag\u90fd\u4e0eresnet\u4e00\u6837\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n        if self.downsample is not None:\n            residual = self.downsample(x)\n        # \u5982\u679c\u6709OSME\u6a21\u5757\n        if self.meflag:\n            # \u590d\u5236\u4e00\u904d\u8f93\u51fa\uff0c\u4e3a\u4e86\u540e\u9762\u6784\u6210\u6b8b\u5dee\u7ed3\u6784\n            # .clone()\u8868\u793a\u590d\u5236\u4e00\u904d\uff0cclone\u65b9\u6cd5\u662f\u53ef\u5fae\u7684\uff0c\u5373outreach\u7684\u68af\u5ea6\u53ef\u4ee5\u4f20\u56deout\n            outreach = out.clone()\n            # \u5c06\u7279\u5f81\u56fe\u4f20\u5165OSME\u6a21\u5757\uff0c\u5f97\u5230\u7279\u5f81\u6ce8\u610f\u529b\u56feU_p\uff0c\u5bf9\u5e94\u8bba\u6587\u4e2d\u516c\u5f0f(2)\n            parts = self.me(outreach)\n            # \u5f97\u5230\u539fresnet\u5f97\u5230\u7684\u7279\u5f81\u56fe\n            out += residual\n            out = self.relu(out)\n            # \u7279\u5f81\u6ce8\u610f\u529b\u56feU_p\u4e0e\u539f\u7279\u5f81\u56fe\u76f8\u52a0\uff0c\u6784\u6210\u6b8b\u5dee\u7ed3\u6784\n            for i in range(len(parts)):\n                parts[i] = self.relu(parts[i] + residual)\n            # \u8fd4\u56de\u539fresnet\u5f97\u5230\u7684\u7279\u5f81\u56fe\u4e0e\u7279\u5f81\u6ce8\u610f\u529b\u56fe\n            return out, parts\n        else:\n            # \u5982\u679c\u6ca1\u6709OSME\u6a21\u5757\uff0c\u5219\u76f4\u63a5\u8fd4\u56de\n            out += residual\n            out = self.relu(out)\n            return out\n</code></pre> <p>OSME\u6a21\u5757\uff1a\u5bf9\u5e94\u8bba\u6587\u4e2d\u7684\u516c\u5f0f(1)\u3001(2)</p> <pre><code>class MELayer(nn.Module):\n    def __init__(self, channel, reduction=16, nparts=1):\n        super(MELayer, self).__init__()\n        # \u5b9a\u4e49\u5168\u5c40\u5e73\u5747\u6c60\u5316\u5c42\uff0c\u7528\u4e8e\u8ba1\u7b97\u53c2\u6570z\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.nparts = nparts\n        parts = list()\n        for part in range(self.nparts):\n            # \u5bf9\u5e94\u8bba\u6587\u4e2d\u7684\u516c\u5f0f(1)\uff0c\u901a\u8fc7\u8ba1\u7b97\uff0c\u53ef\u4ee5\u5f97\u5230\u53c2\u6570m^p\n            # part\u4e2a\u6570\u7531\u8d85\u53c2nparts\u786e\u5b9a\uff0c\u5bf9\u5e94\u8bba\u6587\u4e2d\u53c2\u6570P(\u6fc0\u52b1\u6a21\u5757\u6570\u91cf)\n            parts.append(nn.Sequential(\n                nn.Linear(channel, channel // reduction),\n                nn.ReLU(inplace=True),\n                nn.Linear(channel // reduction, channel),\n                nn.Sigmoid()\n            ))\n        self.parts = nn.Sequential(*parts)\n\n    def forward(self, x):\n        b, c, _, _ = x.size()\n        # \u7279\u5f81\u56fe\u9996\u5148\u7ecf\u8fc7\u5168\u5c40\u5e73\u5747\u6c60\u5316\uff0c\u5f97\u5230\u53c2\u6570z\n        y = self.avg_pool(x).view(b, c)\n\n        meouts = list()\n        for i in range(self.nparts):\n            # m^p\u4e0eu(\u5373\u7279\u5f81\u56fe)\u505a\u70b9\u4e58\uff0c\u5f97\u5230\u770b\u7279\u5f81\u6ce8\u610f\u529b\u56feU_p\uff0c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f(2)\n            meouts.append(x * self.parts[i](y).view(b, c, 1, 1))\n\n        return meouts\n</code></pre>"},{"location":"fine-grained/code/Cross-X2/#_4","title":"\u524d\u5411\u4f20\u64ad","text":"<pre><code>    def forward(self, x):\n        # \u4e00\u76f4\u5230layer3\u4e4b\u524d\uff0c\u524d\u5411\u4f20\u64ad\u90fd\u4e0eresnet\u76f8\u540c\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        if self.meflag:\n            # plty_parts\u4ee3\u8868\u5012\u6570\u7b2c\u4e8c\u5c42(L-1\u9636\u6bb5)\u7684\u7279\u5f81\u6ce8\u610f\u529b\u56fe\uff0c\u5c3a\u5bf8\u5747\u4e3a1*1024*28*28\n            # ulti_parts\u4ee3\u8868\u5012\u6570\u7b2c\u4e00\u5c42(L\u9636\u6bb5)\u7684\u7279\u5f81\u6ce8\u610f\u529b\u56fe\uff0c\u5c3a\u5bf8\u5747\u4e3a1*2048*14*14\n            x, plty_parts = self.layer3(x)\n            _, ulti_parts = self.layer4(x)\n\n            cmbn_ftres = list()\n            # nparts\u76f8\u5f53\u4e8e\u8bba\u6587\u4e2d\u7684P(\u6fc0\u52b1\u6a21\u5757\u6570\u91cf)\uff0c\u8bba\u6587\u8bbe\u7f6e\u4e3a2\u62163\n            for i in range(self.nparts):\n                # pdb.set_trace()\n                # \u7b2c\u4e00\u7ec4\uff0c\u5bf9\u5e94\u7b2c\u4e00\u4e2a\u6fc0\u52b1\u6a21\u5757\n                if i == 0:\n                    # \u5bf9\u5e94\u8bba\u6587\u516c\u5f0f(5)\n                    # \u9996\u5148\u5c06\u5012\u6570\u7b2c\u4e00\u5c42\u7279\u5f81\u6ce8\u610f\u529b\u56fe\u7ecf\u8fc7\u4e00\u5c42\u5377\u79ef\uff0c\u901a\u9053\u538b\u7f29\u62101024\n                    # \u4e4b\u540e\u7ecf\u8fc7\u91c7\u6837\u653e\u5927\uff0c\u653e\u5927\u523028*28\n                    # \u4e0e\u5012\u6570\u7b2c\u4e8c\u5c42\u7279\u5f81\u6ce8\u610f\u529b\u56fe\u901a\u9053\u6570\u4e0e\u7279\u5f81\u56fe\u5c3a\u5bf8\u5bf9\u5e94\u8d77\u6765\n                    ulti_parts_iplt = F.interpolate(self.conv2_1(ulti_parts[i]), 28)\n                    # \u5012\u6570L-1\u5c42\u5148\u548c\u5012\u6570\u7b2c\u4e8c\u5c42\u7279\u5f81\u56fe\u76f8\u52a0\uff0c\u4e4b\u540e\u518d\u7ecf\u8fc7\u4e00\u5c423*3\u7684\u5377\u79ef\u5c42\u4ee5\u53ca\u6807\u51c6\u5316\u5c42\uff0c\u5f97\u5230\u7efc\u5408\u7279\u5f81\u56feU_p^G\n                    # \u6700\u540e\u7ecf\u8fc7\u5168\u5c40\u5e73\u5747\u6c60\u5316\uff0c\u5c06\u7efc\u5408\u7279\u5f81\u56fe\u53d8\u6210\u7efc\u5408\u7279\u5f81\u5411\u91cf\n                    cmbn_ftres.append(self.adpavgpool(self.bn3_1(self.conv3_1(torch.add(plty_parts[i], ulti_parts_iplt)))))\n                # \u7b2c\u4e8c\u7ec4\uff0c\u5bf9\u5e94\u7b2c\u4e8c\u4e2a\u6fc0\u52b1\u6a21\u5757\n                elif i == 1:\n                    # \u4e0ep=1\u7684\u60c5\u51b5\u64cd\u4f5c\u4e00\u6837\n                    ulti_parts_iplt = F.interpolate(self.conv2_2(ulti_parts[i]), 28)\n                    cmbn_ftres.append(self.adpavgpool(self.bn3_2(self.conv3_2(torch.add(plty_parts[i], ulti_parts_iplt)))))\n                # \u7b2c\u4e09\u7ec4\uff0c\u5bf9\u5e94\u7b2c\u4e09\u4e2a\u6fc0\u52b1\u6a21\u5757(\u5982\u679cP\u4e3a3\u7684\u8bdd\uff0c\u624d\u4f1a\u8fdb\u5165\u5230\u8fd9\u4e00\u5206\u652f)\uff0c\u4e0e\u4e0a\u8ff0\u7c7b\u4f3c\n                elif i == 2:\n                    ulti_parts_iplt = F.interpolate(self.conv2_3(ulti_parts[i]), 28)\n                    cmbn_ftres.append(self.adpavgpool(self.bn3_3(self.conv3_3(torch.add(plty_parts[i], ulti_parts_iplt)))))\n                # \u518d\u5206\u522b\u8ba9\u4e24\u4e2a\u9636\u6bb5\u7684\u7279\u5f81\u6ce8\u610f\u529b\u56fe\u7ecf\u8fc7\u5168\u5c40\u5e73\u5747\u6c60\u5316(\u6216\u5168\u5c40\u6700\u5927\u6c60\u5316\uff0c\u8fd9\u91cc\u4ee5\u5168\u5c40\u5e73\u5747\u6c60\u5316\u4e3a\u4f8b)\uff0c\u5f97\u5230\u7279\u5f81\u5411\u91cf\n                plty_parts[i] = self.adpavgpool(plty_parts[i])\n                ulti_parts[i] = self.adpavgpool(ulti_parts[i])\n\n            # \u5bf9\u4e8e\u5012\u6570\u7b2c\u4e8c\u5c42(L-1\u9636\u6bb5)\u7684\u7279\u5f81\u5411\u91cf\n            # \u5c06\u7279\u5f81\u5411\u91cf\u6cbf\u901a\u9053\u7ef4\u5ea6\u5806\u53e0,\u5c3a\u5bf8\u4e3abatch*2048*1*1(\u4ee5P=2\u4e3a\u4f8b\uff0c\u4e0b\u9762\u540c\u7406)\n            xp = torch.cat(plty_parts, 1)\n            # \u8f6c\u5316\u5f62\u72b6\uff0c\u5c3a\u5bf8\u53d8\u4e3abatch*2048\n            xp = xp.view(xp.size(0), -1)\n            # \u5c06\u7279\u5f81\u5411\u91cf\u4f20\u5165\u5206\u7c7b\u5c42\uff0c\u5f97\u5230L-1\u9636\u6bb5\u7684\u9884\u6d4b\u6982\u7387\n            xp = self.fc_plty(xp)\n\n            # \u5bf9\u4e8e\u5012\u6570\u7b2c\u4e00\u5c42(L\u9636\u6bb5)\u7684\u7279\u5f81\u5411\u91cf\n            # \u4e0b\u8ff0\u64cd\u4f5c\u4e0e\u5012\u6570\u7b2c\u4e8c\u5c42\u7c7b\u4f3c\n            xf = torch.cat(ulti_parts, 1)\n            # \u552f\u4e00\u4e0d\u540c\u7684\u662f\u6700\u7ec8\u5f97\u5230\u7684\u7279\u5f81\u5411\u91cf\u5c3a\u5bf8\u4e3abatch*4096\n            xf = xf.view(xf.size(0), -1)\n            # \u5f97\u5230L\u9636\u6bb5\u7684\u9884\u6d4b\u6982\u7387\n            xf = self.fc_ulti(xf)\n\n            # \u5bf9\u4e8e\u7efc\u5408\u7684\u7279\u5f81\u5411\u91cf\uff0c\u4e0e\u4e0a\u8ff0\u64cd\u4f5c\u7c7b\u4f3c\n            xc = torch.cat(cmbn_ftres, 1)\n            # \u6700\u7ec8\u7279\u5f81\u5411\u91cf\u5c3a\u5bf8\u4e3abatch*2048\n            xc = xc.view(xc.size(0), -1)\n            # \u5f97\u5230\u7efc\u5408\u7684\u9884\u6d4b\u6982\u7387\n            xc = self.fc_cmbn(xc)\n            # \u4f9d\u6b21\u8fd4\u56deL\u9636\u6bb5\u7279\u5f81\u56fe\u7684\u9884\u6d4b\u6982\u7387\u3001L-1\u9636\u6bb5\u7279\u5f81\u56fe\u7684\u9884\u6d4b\u6982\u7387\u3001\u7efc\u5408\u7279\u5f81\u56fe\u7684\u9884\u6d4b\u6982\u7387\n            # L\u9636\u6bb5\u7684\u7279\u5f81\u5411\u91cf\u3001L-1\u9636\u6bb5\u7684\u7279\u5f81\u5411\u91cf\u3001\u4e24\u9636\u6bb5\u7efc\u5408\u540e\u7684\u7279\u5f81\u5411\u91cf\n            return xf, xp, xc, ulti_parts, plty_parts, cmbn_ftres\n\n        else:\n            x = self.layer3(x)\n            x = self.layer4(x)\n\n            x = self.adpavgpool(x)\n            x = x.view(x.size(0), -1)\n            x = self.fc_ulti(x)\n\n            return x\n</code></pre>"},{"location":"fine-grained/code/Cross-X2/#_5","title":"\u635f\u5931\u51fd\u6570","text":"<p>C^3S\u635f\u5931\uff1a</p> <pre><code>class RegularLoss(nn.Module):\n\n    def __init__(self, gamma=0, part_features=None, nparts=1):\n        \"\"\"\n        :param bs: batch size\n        :param ncrops: number of crops used at constructing dataset\n        \"\"\"\n        super(RegularLoss, self).__init__()\n        self.register_buffer('part_features', part_features)\n        # nparts\u8868\u793aP\uff0c\u5373\u6fc0\u52b1\u6a21\u5757\u6570\u91cf\n        self.nparts = nparts\n        # \u8868\u793a\u635f\u5931\u7684\u6743\u91cd\uff0c\u5bf9\u5e94\u8bba\u6587\u4e2d\u516c\u5f0f(10)\u7684gamma\u53c2\u6570\n        self.gamma = gamma\n\n    def forward(self, x):\n        # \u8fd9\u91cc\u7684x\u662f\u5217\u8868\u683c\u5f0f\u7684\u6570\u636e\uff0c\u91cc\u9762\u50a8\u5b58\u7740\u4e0d\u540c\u6fc0\u52b1\u6a21\u5757\u7684\u7279\u5f81\u56fe\n        assert isinstance(\n            x, list), \"parts features should be presented in a list\"\n        # \u521d\u59cb\u5316\u76f8\u5173\u6027\u77e9\u9635\n        corr_matrix = torch.zeros(self.nparts, self.nparts)\n        # \u904d\u5386\u6240\u6709\u7684\u6fc0\u52b1\u6a21\u5757\n        for i in range(self.nparts):\n            # \u5148\u5c06\u7279\u5f81\u5411\u91cf\u538b\u7f29\uff0c\u538b\u7f29\u6210\u4e8c\u7ef4\u7684(batch*1024)\n            x[i] = x[i].squeeze()\n            # \u4e4b\u540e\u8ba1\u7b97x\u7684L2\u6b63\u5219\u5316\u5f97\u5230F_p\uff0c\u5373x\u6bcf\u4e2a\u5143\u7d20\u9664\u4ee5x\u5404\u5143\u7d20\u5e73\u65b9\u548c\u7684\u4e8c\u5206\u4e4b\u4e00\u6b21\u65b9(\u5f00\u6839)\uff0c\u4e5f\u5c31\u662fx\u9010\u5143\u7d20\u9664\u4ee5x\u7684Frobenius\u8303\u6570\n            # norm\u65b9\u6cd5\u5c31\u662f\u6c42\u5411\u91cf(\u6216\u77e9\u9635)\u7684\u8303\u6570\uff0c\u9ed8\u8ba4\u6c42Frobenius\u8303\u6570\n            x[i] = torch.div(x[i], x[i].norm(dim=0, keepdim=True))\n\n        # original design\n        for i in range(self.nparts):\n            for j in range(self.nparts):\n                # \u8fd9\u91cc\u5bf9\u5e94\u8bba\u6587\u4e2d\u516c\u5f0f(3)\uff0cF_p\u7684\u8f6c\u7f6e\u4e0eF_p\u2018\u76f8\u4e58\uff0c\u518d\u6c42\u5747\u503c\uff0c\u5f97\u5230\u76f8\u5173\u77e9\u9635\u4e2d\u7684p,p'\u4f4d\u7f6e\u7684\u5143\u7d20\n                # p\u4e0ep'\u5bf9\u5e94\u8fd9\u91cc\u7684i\u548cj\n                # \u8fd9\u91cc\u7684x\u662f\u5217\u8868\u683c\u5f0f\u7684\u6570\u636e\uff0c\u91cc\u9762\u50a8\u5b58\u7740\u4e0d\u540c\u6fc0\u52b1\u6a21\u5757\u7684\u7279\u5f81\u56fe\n                corr_matrix[i, j] = torch.mean(torch.mm(x[i], x[j].t()))\n                # \u82e5i\u7b49\u4e8ej\uff0c\u8bf4\u660e\u662f\u76f8\u5173\u77e9\u9635\u4e2d\u7684\u5bf9\u89d2\u5143\u7d20\n                if i == j:\n                    # \u5982\u679c\u662f\u5bf9\u89d2\u7ebf\u4e0a\u7684\u5143\u7d20\uff0c\u5219\u53d6\u76f8\u53cd\u6570\n                    corr_matrix[i, j] = 1.0 - corr_matrix[i, j]\n        # \u8fd9\u91cc\u5bf9\u5e94\u8bba\u6587\u4e2d\u516c\u5f0f(4)\n        # \u9996\u5148\u63d0\u53d6\u5bf9\u89d2\u7ebf\u4ee5\u53ca\u5bf9\u89d2\u7ebf\u4e0a\u9762(\u4e0a\u4e09\u89d2)\u7684\u5143\u7d20(\u76f8\u5173\u77e9\u9635\u4e0a\u4e09\u89d2\u4e0e\u4e0b\u4e09\u89d2\u5143\u7d20\u76f8\u540c)\uff0c\u8fc7\u6ee4\u6389\u4e00\u534a\uff0c\u6b63\u597d\u5bf9\u5e94\u516c\u5f0f\u524d\u9762\u76841/2\n        # \u4e4b\u540e\u518d\u5c06\u63d0\u53d6\u7684\u5143\u7d20\u6c42\u548c\uff0c\u6700\u540e\u518d\u5c06\u5f97\u5230\u7684\u635f\u5931\u4e58\u4ee5gamma\u53c2\u6570\n        # \u8fd9\u91cc\u7684gamma\u5bf9\u5e94\u8bba\u6587\u4e2d\u516c\u5f0f(10)\u7684gamma\u53c2\u6570\n        regloss = torch.mul(torch.sum(torch.triu(corr_matrix)), self.gamma).to(device)\n        # \u6700\u540e\u8fd4\u56de\u635f\u5931\n        return regloss\n</code></pre> <p>\u4ea4\u53c9\u71b5\u635f\u5931\u4e0eKL\u635f\u5931\u53ef\u4ee5\u76f4\u63a5\u4ecenn\u6a21\u5757\u8c03\u53d6\uff1a</p> <pre><code>cls_loss = nn.CrossEntropyLoss()\nkl_loss = nn.KLDivLoss(reduction='sum')\n</code></pre>"},{"location":"fine-grained/code/Cross-X2/#_6","title":"\u6a21\u578b\u53c2\u6570\u7684\u8bad\u7ec3","text":""},{"location":"fine-grained/code/Cross-X2/#_7","title":"\u8bad\u7ec3\u521d\u59cb\u5316\u9636\u6bb5","text":"<pre><code>\"\"\" user defined variables \"\"\"\n# \u8bbe\u7f6e\u4f7f\u7528\u7684\u4e3b\u5e72\u7f51\u7edc\nbackbone = \"resnet\" # or \"senet\"\n# \u8bbe\u7f6e\u6570\u636e\u96c6\u540d\u79f0\ndatasetname = \"vggaircraft\" # we experiment on 5 datasets: \"nabirds\", \"cubbirds\", \"stcars\", \"stdogs\", and \"vggaircraft\"\n# \u8bbe\u7f6ebatchsize\nbatchsize = 32\n\n#################### model zoo: it's a folder to place vanilla models, like ResNet-50\n# \u5b58\u653eResNet\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u5730\u5740\uff0c\u8bad\u7ec3\u65f6\u4fee\u6539\u6210\u81ea\u5df1\u7684\u5730\u5740\u5373\u53ef\nmodelzoopath = \"/home/luowei/Codes/pymodels\"   \nsys.path.append(os.path.dirname(modelzoopath))\n# import pymodels\n\n##################### Dataset path\n# \u6570\u636e\u96c6\u5730\u5740\uff0c\u8bad\u7ec3\u65f6\u4fee\u6539\u6210\u81ea\u5df1\u7684\u5730\u5740\u5373\u53ef\ndatasets_path = os.path.expanduser(\"/home/luowei/Datasets\")\ndatasetpath = os.path.join(datasets_path, datasetname)\n\n# \u4f7f\u7528\u7684\u8bad\u7ec3\u8bbe\u5907(GPU\u6216\u8005CPU)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() &gt; 0 else \"cpu\")\n\n# \u5224\u65ad\u662f\u5426\u53ef\u4ee5\u52a0\u8f7d\u6570\u636e\u96c6\nassert imdb.creatDataset(datasetpath, datasetname=datasetname) == True, \"Failing to creat train/val/test sets\"\n# \u6570\u636e\u96c6\u7684\u9884\u5904\u7406\u64cd\u4f5c\ndata_transform = data_transform(datasetname)\n\n# \u52a0\u8f7d\u6570\u636e\u96c6\ndatasplits = {x: datasets.ImageFolder(os.path.join(datasetpath, x), data_transform[x])\n              for x in ['trainval', 'test']}\n\ndataloader = {x: torch.utils.data.DataLoader(datasplits[x], batch_size=batchsize, shuffle=True, num_workers=8)\n              for x in ['trainval', 'test']}\ndatasplit_sizes = {x: len(datasplits[x]) for x in ['trainval', 'test']}\nclass_names = datasplits['trainval'].classes\nnum_classes = len(class_names)\n\n################################### constructing or loading model\n# \u52a0\u8f7d\u6a21\u578b\nif datasetname is 'stdogs' and backbone is 'senet':\n    nparts = 3\nelse:\n    nparts = 2   # number of parts you want to use for your dataset \n# \u6839\u636e\u4e0d\u540c\u6570\u636e\u96c6\u52a0\u8f7d\u4e0d\u540c\u7684\u6a21\u578b\nif backbone is 'senet':\n    if datasetname in ['cubbirds', 'nabirds']:\n        import crossxsenetmix as crossxmodel\n        model = crossxmodel.senet50(num_classes=num_classes, nparts=nparts)\n    else:\n        import crossxsenetavg as crossxmodel\n        model = crossxmodel.senet50(num_classes=num_classes, nparts=nparts)\nelif backbone is 'resnet':\n    if datasetname in ['cubbirds', 'nabirds']:\n        import crossxresnetmix as crossxmodel\n        model = crossxmodel.resnet50(pretrained=True, modelpath=modelzoopath, num_classes=num_classes,  nparts=nparts)\n    else:\n        import crossxresnetavg as crossxmodel\n        model = crossxmodel.resnet50(pretrained=True, modelpath=modelzoopath, num_classes=num_classes,  nparts=nparts)\n\n# \u5982\u679c\u6709\u591a\u4e2a\u663e\u5361\uff0c\u5c31\u53ea\u6267\u884c\u5e76\u884c\u8bad\u7ec3\u64cd\u4f5c\nif torch.cuda.device_count() &gt; 0:\n    model = nn.DataParallel(model)\nmodel.to(device)\n\n# \u5982\u679c\u6a21\u578b\u662fSE\uff0c\u5219\u9700\u8981\u53e6\u5916\u52a0\u8f7d\u6a21\u578b\u7684\u9884\u8bad\u7ec3\u53c2\u6570\nif backbone is 'senet':\n    # load pretrained senet weights\n    state_dict_path = \"pretrained-weights.pkl\"\n    state_params = torch.load(state_dict_path, map_location=device)\n    state_params['weight'].pop('module.fc.weight')\n    state_params['weight'].pop('module.fc.bias')\n    model.load_state_dict(state_params['weight'], strict=False)\n\n\n# creating loss functions\ngamma1, gamma2, gamma3, lr, epochs = init_crossx_params(backbone, datasetname)\n# \u4ea4\u53c9\u71b5\u635f\u5931\ncls_loss = nn.CrossEntropyLoss()\n# L_C3S\u635f\u5931\u7684\u7b2c\u4e00\u90e8\u5206\uff0c\u5bf9\u5e94\u4e8eL\u9636\u6bb5\u7684\u76f8\u5173\u6027\u77e9\u9635S^L\nreg_loss_ulti = crossxmodel.RegularLoss(gamma=gamma1, nparts=nparts)\n# L_C3S\u635f\u5931\u7684\u7b2c\u4e8c\u90e8\u5206\uff0c\u5bf9\u5e94\u4e8eL-1\u9636\u6bb5\u7684\u76f8\u5173\u6027\u77e9\u9635S^L-1\nreg_loss_plty = crossxmodel.RegularLoss(gamma=gamma2, nparts=nparts)\n# L_C3S\u635f\u5931\u7684\u7b2c\u4e09\u90e8\u5206\uff0c\u5bf9\u5e94\u4e8e\u7efc\u5408\u9636\u6bb5\u7684\u76f8\u5173\u6027\u77e9\u9635S^G\nreg_loss_cmbn = crossxmodel.RegularLoss(gamma=gamma3, nparts=nparts)\n# K-L\u635f\u5931,\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f(6)\u7684\u8ba1\u7b97\nkl_loss = nn.KLDivLoss(reduction='sum')\n# \u635f\u5931\u51fd\u6570\u5408\u5e76\u6210\u5217\u8868\uff0c\u4fbf\u4e8e\u540e\u9762\u8c03\u53d6\ncriterion = [cls_loss, reg_loss_ulti, reg_loss_plty, reg_loss_cmbn, kl_loss]\n\n# creating optimizer\n# \u5b9a\u4e49\u4f18\u5316\u5668\noptmeth = 'sgd'\noptimizer = opt.SGD(model.parameters(), lr=lr, momentum=0.9)\n\n# creating optimization scheduler\n#scheduler = lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)\n# \u5b9a\u4e49\u5b66\u4e60\u7387\u4e0b\u964d\u7b56\u7565\uff0cepoch\u523015\u300125\u65f6\uff0c\u5b66\u4e60\u7387\u5747\u53d8\u4e3a\u539f\u6765\u76840.1\nscheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[15, 25], gamma=0.1)\n\n# training the model\n# \u662f\u5426\u6709\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u5982\u679c\u6709\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u5c31\u8bbe\u7f6e\u4e3aTrue\nisckpt = False  # True for restoring model from checking point\n# print parameters\nprint(\"{}: {}, gamma: {}_{}_{}, nparts: {}, epochs: {}\".format(optmeth, lr, gamma1, gamma2, gamma3, nparts, epochs))\n# \u5f00\u59cb\u8bad\u7ec3\uff0c\u5177\u4f53\u8fc7\u7a0b\u89c1\u8bad\u7ec3\u6d41\u7a0b\nmodel, train_rsltparams = modellearning.train(model, dataloader, criterion, optimizer, scheduler, backbone=backbone, datasetname=datasetname, isckpt=isckpt, epochs=epochs)\n\n#### save model\n# \u4fdd\u5b58\u6700\u7ec8\u7684\u6a21\u578b\nmodelpath = './models'\nif backbone is 'senet':\n    modelname = r\"{}_parts{}-sc{}_{}_{}-{}{}-SeNet50-crossx.model\".format(datasetname, nparts, gamma1, gamma2, gamma3, optmeth, lr)\nelse:\n    modelname = r\"{}_parts{}-sc{}_{}_{}-{}{}-ResNet50-crossx.model\".format(datasetname, nparts, gamma1, gamma2, gamma3, optmeth, lr)\ntorch.save(model.state_dict(), os.path.join(modelpath, modelname))\n</code></pre>"},{"location":"fine-grained/code/Cross-X2/#_8","title":"\u8bad\u7ec3\u6d41\u7a0b","text":"<pre><code>def train(model, dataloader, criterion, optimizer, scheduler, backbone='resnet', datasetname=None, isckpt=False, epochs=30):\n\n    # get the size of train and evaluation data\n    if isinstance(dataloader, dict):\n        # \u5f97\u5230\u6570\u636e\u96c6\u89c4\u6a21(\u6570\u91cf)\n        dataset_sizes = {x: len(dataloader[x].dataset) for x in dataloader.keys()}\n        print(dataset_sizes)\n    else:\n        dataset_size = len(dataloader.dataset)\n    # \u5c06\u635f\u5931\u51fd\u6570\u53d8\u4e3a\u5217\u8868\u7c7b\u578b\n    if not isinstance(criterion, list):\n        criterion = [criterion]\n    # \u521d\u59cb\u5316\u5404\u79cd\u53d8\u91cf\n    best_model_params = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    global_step = 0\n    global_step_resume = 0\n    best_epoch = 0\n    best_step = 0\n    start_epoch = -1\n    # \u5982\u679c\u6709\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u5219\u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b\u53c2\u6570\n    if isckpt:\n        checkpoint = modelserial.loadCheckpoint(datasetname)\n        # \u52a0\u8f7d\u5f53\u524d\u6a21\u578b\u8fed\u4ee3\u6b21\u6570\n        start_epoch = checkpoint['epoch']\n        # \u52a0\u8f7d\u6700\u9ad8\u7684\u7cbe\u5ea6\n        best_acc = checkpoint['best_acc']\n        # \u52a0\u8f7d\u5f53\u524d\u7f51\u7edc\u6a21\u578b\u53c2\u6570\n        model.load_state_dict(checkpoint['state_dict'])\n        # \u52a0\u8f7d\u7cbe\u5ea6\u6700\u9ad8\u65f6\u7684\u7f51\u7edc\u6a21\u578b\u53c2\u6570\n        best_model_params = checkpoint['best_state_dict']\n        # \u5f97\u5230\u7cbe\u5ea6\u6700\u9ad8\u65f6\u7684\u904d\u5386\u6b21\u6570\n        best_epoch = checkpoint['best_epoch']\n    # \u521d\u59cb\u65f6\u95f4\n    since = time.time()\n    # \u5f00\u59cb\u8fed\u4ee3\n    for epoch in range(start_epoch+1, epochs):\n        print('Epoch {}/{}'.format(epoch, epochs))\n        print('-' * 10)\n        # \u7f51\u7edc\u4f9d\u6b21\u7ecf\u8fc7\u8bad\u7ec3\u4e0e\u6d4b\u8bd5\u9636\u6bb5\n        for phase in ['trainval', 'test']:\n            # \u8bad\u7ec3\u9636\u6bb5\u65f6\n            if phase == 'trainval':\n                scheduler.step()\n                # \u5c06\u6a21\u578b\u53d8\u4e3a\u8bad\u7ec3\u72b6\u6001\n                model.train()  # Set model to training mode\n                global_step = global_step_resume\n            else:\n                model.eval()   # Set model to evaluate mode\n                global_step_resume = global_step\n            # \u521d\u59cb\u5316\u4ea4\u53c9\u71b5\u635f\u5931\n            running_cls_loss = 0.0\n            # \u521d\u59cb\u5316C3S\u635f\u5931\n            running_reg_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            # \u8fed\u4ee3\u6570\u636e\u96c6\n            for inputs, labels in dataloader[phase]:\n                # \u6570\u636e\u653e\u5165\u663e\u5361\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                # \u68af\u5ea6\u6e05\u96f6\n                optimizer.zero_grad()\n\n                # forward\n                # \u5982\u679c\u662f\u8bad\u7ec3\u9636\u6bb5\uff0c\u5c31\u8bbe\u7f6e\u6240\u6709\u7684\u9636\u6bb5\u53ef\u5bfc\n                # \u5982\u679c\u662f\u6d4b\u8bd5\u9636\u6bb5(\u62ec\u53f7\u91cc\u662fFalse)\uff0c\u5219\u8bbe\u7f6e\u6240\u6709\u9636\u6bb5\u4e0d\u53ef\u5bfc\n                with torch.set_grad_enabled(phase == 'trainval'):\n                    # \u5982\u679cnparts\u662f1\uff0c\u5219\u4ee3\u8868\u53ea\u6709\u4e00\u4e2a\u9884\u6d4b\u6982\u7387(\u4e0d\u542b\u6709Cross-X\u6a21\u5757)\uff0c\u5373\u53ea\u8ba1\u7b97\u4ea4\u53c9\u71b5\u635f\u5931\n                    if model.module.nparts == 1:\n                        outputs = model(inputs)\n                        _, preds = torch.max(outputs, 1)\n                        all_loss = criterion[0](outputs, labels)\n                    else:\n                        if datasetname is 'stdogs' and backbone is 'resnet':\n                            # \u8be5\u9636\u6bb5(dog\u6570\u636e\u96c6+resnet\u7f51\u7edc)\u65e0\u9700\u8ba1\u7b97\u7efc\u5408\u7279\u5f81\u56fe\u7684C3S\u635f\u5931\n                            outputs_ulti, outputs_plty, _, ulti_ftrs, plty_ftrs, _ = model(inputs)\n                            _, preds = torch.max(outputs_ulti+outputs_plty, 1)\n                            cls_loss = criterion[0](outputs_ulti+outputs_plty, labels)\n                        else:\n                            outputs_ulti, outputs_plty, outputs_cmbn, ulti_ftrs, plty_ftrs, cmbn_ftrs = model(inputs)\n                            # \u4ee5\u4e09\u4e2a\u9884\u6d4b\u6982\u7387(L\u9636\u6bb5\u3001L-1\u9636\u6bb5\u3001\u7efc\u5408\u7279\u5f81\u56fe\u7684\u9884\u6d4b\u6982\u7387)\u4e4b\u548c\u4f5c\u4e3a\u6700\u7ec8\u7684\u7c7b\u522b\u9884\u6d4b\u6982\u7387\n                            # \u9009\u53d6\u9884\u6d4b\u503c\u6700\u5927\u7684\u7d22\u5f15\u4f5c\u4e3a\u6700\u7ec8\u7684\u9884\u6d4b\u7c7b\u522b\n                            _, preds = torch.max(outputs_ulti+outputs_plty+outputs_cmbn, 1)\n                            # \u6700\u7ec8\u7684\u9884\u6d4b\u6982\u7387\u4e0e\u6807\u7b7e\u505a\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u5f97\u5230L_data\u635f\u5931\uff0c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f(9)\n                            cls_loss = criterion[0](outputs_ulti+outputs_plty+outputs_cmbn, labels)\n                            # \u5c06\u7efc\u5408\u7279\u5f81\u56fe\u5f97\u5230\u7684\u7279\u5f81\u5411\u91cf\u4f20\u5165RegularLoss\u635f\u5931\u51fd\u6570\uff0c\u7528\u4e8e\u8ba1\u7b97L_C3S\u7b2c\u4e00\u90e8\u5206\n                            reg_loss_cmbn = criterion[3](cmbn_ftrs)\n                            # \u8ba9outputs_cmbn\u7ecf\u8fc7\u4e00\u6b21softmax\uff0c\u7528\u4e8e\u540e\u7eed\u8ba1\u7b97CL\u635f\u5931\n                            outputs_cmbn = F.log_softmax(outputs_cmbn, 1)\n                        # \u8ba1\u7b97C3S\u635f\u5931\u7684\u7b2c\u4e8c\u90e8\u5206\u548c\u7b2c\u4e09\u90e8\u5206\n                        reg_loss_ulti = criterion[1](ulti_ftrs)\n                        reg_loss_plty = criterion[2](plty_ftrs)                        \n                        # \u4e0e\u4e0a\u8ff0\u7c7b\u4f3c\uff0c\u5206\u522b\u7ecf\u8fc7\u4e00\u6b21softmax\uff0c\u7528\u4e8e\u8ba1\u7b97CL\u635f\u5931\n                        outputs_plty = F.log_softmax(outputs_plty, 1)\n                        outputs_ulti = F.softmax(outputs_ulti, 1)\n\n                        if datasetname is 'stdogs' and backbone is 'resnet':\n                            # dog\u6570\u636e\u96c6+resnet\u672a\u8ba1\u7b97\u7efc\u5408\u7279\u5f81\u56fe\uff0c\u56e0\u6b64\u5728\u8ba1\u7b97CL\u635f\u5931\u7684\u65f6\u5019\uff0c\u53ea\u9700\u8981\u8ba1\u7b97L-1\u9636\u6bb5\u548cL\u9636\u6bb5\u9884\u6d4b\u6982\u7387\u7684KL\u635f\u5931\n                            kl_loss = (criterion[4](outputs_plty, outputs_ulti)) / inputs.size(0)\n                            all_loss = reg_loss_ulti + reg_loss_plty + kl_loss + cls_loss\n                        else:\n                            # \u4e00\u822c\u60c5\u51b5\u4e0b\uff0cCL\u635f\u5931\u7531L-1\u9636\u6bb5\u4e0eL\u9636\u6bb5\u9884\u6d4b\u6982\u7387\u7684KL\u635f\u5931\u3001L\u9636\u6bb5\u4e0e\u7efc\u5408\u7279\u5f81\u56fe\u7684KL\u635f\u5931\u6784\u6210\n                            # \u5bf9\u5e94\u8bba\u6587\u4e2d\u516c\u5f0f(11)\n                            kl_loss = (criterion[4](outputs_plty, outputs_ulti) + criterion[4](outputs_cmbn, outputs_ulti)) / inputs.size(0)\n                            # \u603b\u635f\u5931\u4e3a\u6240\u6709\u635f\u5931\u7684\u6c42\u548c\u5f62\u5f0f\uff0c\u5bf9\u5e94\u8bba\u6587\u4e2d\u516c\u5f0f(8)\n                            all_loss = reg_loss_ulti + reg_loss_plty + reg_loss_cmbn + kl_loss + cls_loss\n\n                    # backward + optimize only if in training phase\n                    # \u5982\u679c\u662f\u8bad\u7ec3\u9636\u6bb5\uff0c\u5219\u9700\u8981\u8fdb\u884c\u53cd\u5411\u4f20\u64ad\u6c42\u5bfc\uff0c\u66f4\u65b0\u7f51\u7edc\u53c2\u6570\n                    if phase == 'trainval':\n                        all_loss.backward()\n                        optimizer.step()\n\n                # statistics\n                # \u603b\u635f\u5931\u7684\u8ba1\u7b97\uff0c\u548c\u524d\u9762\u7684\u635f\u5931\u8ba1\u7b97\u4e00\u6837\uff0c\u9700\u8981\u5206nparts\u3001\u662f\u5426\u662fdog\u6570\u636e\u96c6\u8ba8\u8bba\n                if model.module.nparts == 1:\n                    running_cls_loss += all_loss.item() * inputs.size(0)\n                else:\n                    running_cls_loss += cls_loss.item() * inputs.size(0)\n                    if datasetname is 'stdogs' and backbone is 'resnet':\n                        running_reg_loss += (reg_loss_ulti.item() + reg_loss_plty.item() + kl_loss.item()) * inputs.size(0)\n                    else:\n                        # \u4e00\u822c\u60c5\u51b5\u4e0b\u4f1a\u8d70\u8fd9\u4e2a\u5206\u652f\n                        running_reg_loss += (reg_loss_ulti.item() + reg_loss_plty.item() + reg_loss_cmbn.item() + kl_loss.item()) * inputs.size(0)\n                # \u9884\u6d4b\u7ed3\u679c\u6b63\u786e\u7684\u4e2a\u6570\n                running_corrects += torch.sum(preds == labels.data)\n            # \u8ba1\u7b97\u5f53\u524depoch\u4e0b\u5e73\u5747\u7684\u635f\u5931\uff0c\u5373\u603b\u635f\u5931\u9664\u4ee5\u6570\u636e\u91cf(\u56fe\u7247\u6570\u91cf)\n            if model.module.nparts == 1:\n                epoch_loss = running_cls_loss / dataset_sizes[phase]\n            else:\n                epoch_loss = (running_cls_loss + running_reg_loss) / dataset_sizes[phase]\n            # \u8ba1\u7b97\u8fed\u4ee3\u5f53\u524depoch\u5f97\u5230\u7684\u7cbe\u5ea6(\u8bad\u7ec3\u6216\u6d4b\u8bd5)\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n            # \u8f93\u51fa\u8bad\u7ec3(\u6216\u6d4b\u8bd5)\u635f\u5931\u4e0e\u7cbe\u5ea6\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            # \u5982\u679c\u662f\u6d4b\u8bd5\u9636\u6bb5\uff0c\u5e76\u4e14\u5f53\u524d\u8fed\u4ee3epoch\u5f97\u5230\u7684\u7cbe\u5ea6\u5927\u4e8e\u6700\u9ad8\u7cbe\u5ea6\uff0c\u5219\u4fdd\u5b58\u76f8\u5173\u53c2\u6570\n            if phase == 'test' and epoch_acc &gt; best_acc:\n                # \u4fdd\u5b58\u6700\u9ad8\u7cbe\u5ea6\n                best_acc = epoch_acc\n                # \u4fdd\u5b58\u6700\u9ad8\u7cbe\u5ea6\u5bf9\u5e94\u7684\u8fed\u4ee3epoch\n                best_epoch = epoch\n                # \u53d8\u91cfglobal_step_resume\u6216\u8bb8\u672a\u7528\u5230\uff1f\n                best_step = global_step_resume\n                # \u4fdd\u5b58\u6700\u9ad8\u6d4b\u8bd5\u7cbe\u5ea6\u65f6\uff0c\u6a21\u578b\u7684\u53c2\u6570\n                best_model_params = copy.deepcopy(model.state_dict())\n\n            if phase == 'test' and epoch % 2 == 1:\n                # \u4fdd\u5b58\u6a21\u578b\n                modelserial.saveCheckpoint({'epoch': epoch,\n                                            'best_epoch': best_epoch,\n                                            'state_dict': model.state_dict(),\n                                            'best_state_dict': best_model_params,\n                                            'best_acc': best_acc}, datasetname)\n        print()\n    # \u8bad\u7ec3\u7ed3\u675f\u65f6\u7684\u65f6\u95f4\n    time_elapsed = time.time() - since\n    # \u8f93\u51fa\u8bad\u7ec3\u65f6\u95f4\u4e0e\u6a21\u578b\u6700\u9ad8\u7684\u6d4b\u8bd5\u7cbe\u5ea6\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    print('Best test Acc: {:4f}'.format(best_acc))\n    # \u50a8\u5b58\u8bad\u7ec3\u7ed3\u675f\u540e\u7684\u5404\u79cd\u53c2\u6570\n    rsltparams = dict()\n    rsltparams['val_acc'] = best_acc.item()\n    rsltparams['gamma1'] = criterion[1].gamma\n    rsltparams['gamma2'] = criterion[2].gamma\n    rsltparams['gamma3'] = criterion[3].gamma\n    rsltparams['lr'] = optimizer.param_groups[0]['lr']\n    rsltparams['best_epoch'] = best_epoch\n    rsltparams['best_step'] = best_step\n\n    # load best model weights\n    # \u8bad\u7ec3\u7ed3\u675f\u540e\uff0c\u52a0\u8f7d\u6a21\u578b\u7cbe\u5ea6\u6700\u9ad8\u65f6\u7684\u53c2\u6570\u6743\u91cd\n    model.load_state_dict(best_model_params)\n    # \u8fd4\u56de\u6a21\u578b\u4e0e\u53c2\u6570\u5b57\u5178\n    return model, rsltparams\n</code></pre> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u5927\u5bb6\u6279\u8bc4\u6307\u6b63\u3002</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e7412\u670810\u65e5</p>"},{"location":"fine-grained/code/DCL2/","title":"\u7ec6\u7c92\u5ea6\uff1aDCL","text":""},{"location":"fine-grained/code/DCL2/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aIEEE Conference on Computer Vision and Pattern Recognition 2019 (CVPR, 2019)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content_CVPR_2019/papers/Chen_Destruction_and_Construction_Learning_for_Fine-Grained_Image_Recognition_CVPR_2019_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740(PyTorch\u7248\u672c)\uff1ahttps://github.com/JDAI-CV/DCL</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u7c7b(FGVC)</p>"},{"location":"fine-grained/code/DCL2/#dcl_1","title":"DCL\u7f51\u7edc\u7ed3\u6784","text":""},{"location":"fine-grained/code/DCL2/#_2","title":"\u7f51\u7edc\u521d\u59cb\u5316\u9636\u6bb5","text":"<pre><code>class MainModel(nn.Module):\n    def __init__(self, config):\n        super(MainModel, self).__init__()\n        # \u4f7f\u7528DCL\u7f51\u7edc\n        self.use_dcl = config.use_dcl\n        # \u5206\u7c7b\u6570\n        self.num_classes = config.numcls\n        # \u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u540d\u5b57\n        self.backbone_arch = config.backbone\n        # \u8bba\u6587\u4e2d\u672a\u63d0\u53caAsoftmax\n        self.use_Asoftmax = config.use_Asoftmax\n        print(self.backbone_arch)\n        # \u52a0\u8f7d\u4e3b\u5e72\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\n        if self.backbone_arch in dir(models):\n            self.model = getattr(models, self.backbone_arch)()\n            if self.backbone_arch in pretrained_model:\n                self.model.load_state_dict(torch.load(pretrained_model[self.backbone_arch]))\n        else:\n            if self.backbone_arch in pretrained_model:\n                self.model = pretrainedmodels.__dict__[self.backbone_arch](num_classes=1000, pretrained=None)\n            else:\n                self.model = pretrainedmodels.__dict__[self.backbone_arch](num_classes=1000)\n        # \u63d0\u53d6\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u4e2d\u7684\u5377\u79ef\u3001\u6c60\u5316\u5c42\uff0c\u4f5c\u4e3aDCL\u7684\u7279\u5f81\u63d0\u53d6\u6a21\u5757\n        if self.backbone_arch == 'resnet50' or self.backbone_arch == 'se_resnet50':\n            self.model = nn.Sequential(*list(self.model.children())[:-2])\n        if self.backbone_arch == 'senet154':\n            self.model = nn.Sequential(*list(self.model.children())[:-3])\n        if self.backbone_arch == 'se_resnext101_32x4d':\n            self.model = nn.Sequential(*list(self.model.children())[:-2])\n        if self.backbone_arch == 'se_resnet101':\n            self.model = nn.Sequential(*list(self.model.children())[:-2])\n        # \u5b9a\u4e49\u5168\u5c40\u5e73\u5747\u6c60\u5316\u5c42\n        self.avgpool = nn.AdaptiveAvgPool2d(output_size=1)\n        # \u5b9a\u4e49\u5206\u7c7b\u5c42\n        self.classifier = nn.Linear(2048, self.num_classes, bias=False)\n\n        if self.use_dcl:\n            if config.cls_2:\n                # self.classifier_swap\u76f8\u5f53\u4e8e\u8bba\u6587\u4e2d\u7684discriminator(\u9274\u522b\u5668)\uff0c\u7528\u4e8e\u9884\u6d4b\u8be5\u56fe\u662f\u539f\u56fe\u7684\u6982\u7387(\u672a\u88ab\u6253\u4e71)\n                self.classifier_swap = nn.Linear(2048, 2, bias=False)\n            if config.cls_2xmul:\n                # xmul\u8bba\u6587\u4e2d\u672a\u63d0\n                self.classifier_swap = nn.Linear(2048, 2*self.num_classes, bias=False)\n            # \u7528\u4e8e\u91cd\u6784\u56fe\u50cf\uff0c\u5bf9\u5e94\u8bba\u6587\u4e2d\u7684construction learning\u6a21\u5757\n            self.Convmask = nn.Conv2d(2048, 1, 1, stride=1, padding=0, bias=True)\n            self.avgpool2 = nn.AvgPool2d(2, stride=2)\n        # \u8bba\u6587\u4e2d\u672a\u63d0\u53caAsoftmax\u6a21\u5757\n        if self.use_Asoftmax:\n            self.Aclassifier = AngleLinear(2048, self.num_classes, bias=False)\n</code></pre>"},{"location":"fine-grained/code/DCL2/#_3","title":"\u524d\u5411\u4f20\u64ad\u9636\u6bb5","text":"<pre><code>    def forward(self, x, last_cont=None):\n        # \u5c06\u56fe\u7247\u7ecf\u8fc7\u9884\u5148\u8bbe\u7f6e\u597d\u7684\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u8fdb\u884c\u63d0\u53d6\u7279\u5f81\n        x = self.model(x)\n        if self.use_dcl:\n            # construction learning\u6a21\u5757\n            # \u4e0b\u9762\u5bf9\u5e94\u8bba\u6587\u4e2d\u7684\u516c\u5f0f(8)\n            mask = self.Convmask(x)\n            mask = self.avgpool2(mask)\n            mask = torch.tanh(mask)\n            # \u751f\u6210\u957f\u5ea6\u4e3a49\u7684\u5f20\u91cf\u6570\u636e\uff0c\u8868\u793a\u539f\u56fe\u6bcf\u4e2a\u533a\u57df\u7684\u4f4d\u7f6e\u5e8f\u53f7\n            # \u53ef\u4ee5\u5b9e\u73b0\u590d\u539f\u539f\u56fe(\u6216\u6253\u4e71\u7684\u56fe\u50cf)\u7684\u4f5c\u7528\n            mask = mask.view(mask.size(0), -1)\n        # \u5c06\u7279\u5f81\u56fe\u4f20\u5165\u5168\u8fde\u63a5\u5c42\uff0c\u9884\u6d4b\u6982\u7387\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        out = []\n        # \u5f97\u5230\u56fe\u7247\u7684\u9884\u6d4b\u6982\u7387\n        out.append(self.classifier(x))\n\n        if self.use_dcl:\n            # \u9884\u6d4b\u8be5\u56fe\u662f\u539f\u59cb\u56fe\u50cf\u7684\u6982\u7387\uff0c\u7528\u4e8e\u8ba1\u7b97\u5bf9\u6297\u635f\u5931(\u8bba\u6587\u4e2d\u7684\u516c\u5f0f(6))\n            out.append(self.classifier_swap(x))\n            # \u9884\u6d4b\u7684\u539f\u56fe\u533a\u57df\u987a\u5e8f\uff0c\u7528\u4e8e\u8ba1\u7b97\u8bba\u6587\u4e2d\u7684\u516c\u5f0f(9)\n            out.append(mask)\n        # use_Asoftmax\u6a21\u5757\u8bba\u6587\u4e2d\u672a\u63d0\u53ca\n        if self.use_Asoftmax:\n            if last_cont is None:\n                x_size = x.size(0)\n                out.append(self.Aclassifier(x[0:x_size:2]))\n            else:\n                last_x = self.model(last_cont)\n                last_x = self.avgpool(last_x)\n                last_x = last_x.view(last_x.size(0), -1)\n                out.append(self.Aclassifier(last_x))\n\n        return out\n</code></pre>"},{"location":"fine-grained/code/DCL2/#_4","title":"\u6570\u636e\u96c6\u7684\u52a0\u8f7d","text":"<pre><code>class dataset(data.Dataset):\n    def __init__(self, Config, anno, swap_size=[7,7], common_aug=None, swap=None, totensor=None, train=False, train_val=False, test=False):\n        # \u6570\u636e\u96c6\u56fe\u7247\u6839\u76ee\u5f55\n        self.root_path = Config.rawdata_root\n        # \u6570\u636e\u96c6\u7c7b\u522b\u6570\n        self.numcls = Config.numcls\n        # \u6570\u636e\u96c6\u540d\u79f0\n        self.dataset = Config.dataset\n        self.use_cls_2 = Config.cls_2\n        self.use_cls_mul = Config.cls_2xmul\n        if isinstance(anno, pandas.core.frame.DataFrame):\n            # \u56fe\u7247\u540d\u79f0,\u4fbf\u4e8e\u540e\u7eed\u8bfb\u53d6\n            self.paths = anno['ImageName'].tolist()\n            # \u56fe\u7247\u6807\u7b7e\n            self.labels = anno['label'].tolist()\n        elif isinstance(anno, dict):\n            self.paths = anno['img_name']\n            self.labels = anno['label']\n\n        if train_val:\n            # \u8bad\u7ec3\u65f6\u662f\u5426\u9a8c\u8bc1\uff0c\u5982\u679c\u9700\u8981\u9a8c\u8bc1\uff0c\u5219\u52a0\u8f7d\u9a8c\u8bc1\u96c6\n            self.paths, self.labels = random_sample(self.paths, self.labels)\n        # \u8bad\u7ec3\u56fe\u7247\u9884\u5904\u7406\u7b56\u7565:\u653e\u5927\u3001\u968f\u673a\u88c1\u526a\u7b49\u7b49\n        self.common_aug = common_aug\n        # \u968f\u673a\u6253\u4e71,\u5177\u4f53\u8fc7\u7a0b\u89c1swap\u51fd\u6570\n        self.swap = swap\n        # \u6d4b\u8bd5\u56fe\u7247\u9884\u5904\u7406-&gt;\u76f4\u63a5\u653e\u5927\u3001\u5e76\u8f6c\u5316\u4e3atensor\n        self.totensor = totensor\n        # \u52a0\u8f7dconfig\u53c2\u6570\n        self.cfg = Config\n        # \u5982\u679c\u662fTrue\uff0c\u8868\u793a\u8be5\u9636\u6bb5\u662f\u8bad\u7ec3\u8fc7\u7a0b\n        self.train = train\n        self.swap_size = swap_size\n        # \u4e0etrain\u7c7b\u4f3c\uff0c\u5982\u679c\u662fTrue\uff0c\u8868\u793a\u8be5\u9636\u6bb5\u662f\u6d4b\u8bd5\u9636\u6bb5\n        self.test = test\n\n    def __len__(self):\n        return len(self.paths)\n\n    def __getitem__(self, item):\n        # \u56fe\u7247\u8def\u5f84\n        img_path = os.path.join(self.root_path, self.paths[item])\n        # \u8bfb\u53d6\u56fe\u7247\n        img = self.pil_loader(img_path)\n        # \u5982\u679c\u662f\u6d4b\u8bd5\u8fc7\u7a0b\uff0c\u5219\u76f4\u63a5\u653e\u5927\uff0c\u7136\u540e\u8fd4\u56detensor\u683c\u5f0f\u7684\u539f\u56fe\u5373\u53ef\uff0c\u65e0\u9700\u6253\u4e71\n        if self.test:\n            img = self.totensor(img)\n            label = self.labels[item]\n            return img, label, self.paths[item]\n        # \u5c06\u672a\u6253\u4e71\u7684\u56fe\u7247\u8fdb\u884c\u9884\u5904\u7406\uff1a\u8c03\u6574\u5927\u5c0f\u3001\u968f\u673a\u65cb\u8f6c\u3001\u968f\u673a\u88c1\u526a\u6307\u5b9a\u5927\u5c0f\n        img_unswap = self.common_aug(img) if not self.common_aug is None else img\n        # \u5f97\u5230\u539f\u56fe\u7684\u5c0f\u533a\u57df\u5757\n        image_unswap_list = self.crop_image(img_unswap, self.swap_size)\n        # swap_range\u8868\u793a\u4e00\u5171\u591a\u5c11\u4e2a\u5c0f\u533a\u57df\n        swap_range = self.swap_size[0] * self.swap_size[1]\n        # \u5c06\u533a\u57df\u5757\u5e8f\u5217\u7f29\u653e\u5230-0.5\u52300.5\u5185\uff0c\u5f97\u5230\u7b2c\u4e00\u4e2a\u987a\u5e8f\u6807\u7b7e(\u672a\u6253\u4e71\u7684\u56fe)\uff0c\u7528\u4e8e\u8ba1\u7b97\u8bba\u6587\u4e2d\u7684\u516c\u5f0f(9)\n        swap_law1 = [(i-(swap_range//2))/swap_range for i in range(swap_range)]\n\n        if self.train:\n            # \u5c06\u539f\u56fe\u6253\u4e71\uff0c\u5f97\u5230\u6253\u4e71\u7684\u56fe\u7247\n            img_swap = self.swap(img_unswap)\n            # \u5f97\u5230\u6253\u4e71\u56fe\u7247\u7684\u533a\u57df\u5757(49\u5f20\u5b50\u56fe)\n            image_swap_list = self.crop_image(img_swap, self.swap_size)\n            # \u9488\u5bf9\u672a\u6253\u4e71\u7684\u6bcf\u5f20\u5b50\u56fe\uff0c\u9996\u5148\u83b7\u53d6\u5b50\u56fe\u4e2d\u6bcf\u4e2a\u901a\u9053\u7684\u50cf\u7d20\u503c\u7684\u5e73\u5747\u503c\uff0c\u4e4b\u540e\u518d\u6c42\u548c\uff0c\u5f97\u523049\u4e2a\u6570\uff0c\u4e0b\u9762\u540c\u7406\n            unswap_stats = [sum(ImageStat.Stat(im).mean) for im in image_unswap_list]\n            # \u9488\u5bf9\u6253\u4e71\u7684\u6bcf\u5f20\u5b50\u56fe\uff0c\u9996\u5148\u83b7\u53d6\u5b50\u56fe\u4e2d\u6bcf\u4e2a\u901a\u9053\u7684\u50cf\u7d20\u503c\u7684\u5e73\u5747\u503c\uff0c\u4e4b\u540e\u518d\u6c42\u548c\n            swap_stats = [sum(ImageStat.Stat(im).mean) for im in image_swap_list]\n\n            swap_law2 = []\n            for swap_im in swap_stats:\n                # \u6309\u987a\u5e8f\u8ba1\u7b97\u6253\u4e71\u56fe\u50cf\u533a\u57df\u548c\u672a\u6253\u4e71\u56fe\u50cf\u533a\u57df\u7684\u8ddd\u79bb\n                distance = [abs(swap_im - unswap_im) for unswap_im in unswap_stats]\n                # \u5f97\u5230\u6700\u8fd1\u5b50\u56fe\u50cf\u5e8f\u53f7\uff0c\u5373\u5f97\u5230\u6253\u4e71\u540e\u56fe\u50cf\u7684\u5b50\u533a\u57df\u4f4d\u4e8e\u539f\u56fe\u7684\u54ea\u4e2a\u4f4d\u7f6e\n                index = distance.index(min(distance))\n                # \u5229\u7528\u8be5\u4f4d\u7f6e\u5e8f\u53f7\uff0c\u5f97\u5230\u76f8\u5bf9\u5750\u6807\uff0c\u751f\u6210\u6253\u4e71\u540e\u533a\u57df\u987a\u5e8f\u6807\u7b7e\n                swap_law2.append((index-(swap_range//2))/swap_range)\n            # \u5c06\u6253\u4e71\u540e\u7684\u56fe\u50cf\u6570\u636e\u683c\u5f0f\u8f6c\u5316\u4e3atensor\u683c\u5f0f\n            img_swap = self.totensor(img_swap)\n            # \u5f97\u5230\u6807\u7b7e\n            label = self.labels[item]\n            if self.use_cls_mul:\n                # \u8be5\u5206\u652f\u8bba\u6587\u4e2d\u672a\u63d0\u53ca\n                label_swap = label + self.numcls\n            if self.use_cls_2:\n                # label_swap\u5177\u4f53\u4f5c\u7528\u89c1collate_fn4train\u65b9\u6cd5\n                label_swap = -1\n            # \u6570\u636e\u8f6c\u5316\u4e3atensor\u683c\u5f0f\n            img_unswap = self.totensor(img_unswap)\n            # \u4f9d\u6b21\u8fd4\u56de\u672a\u6253\u4e71\u7684\u56fe\u7247\u3001\u6253\u4e71\u7684\u56fe\u7247\u3001\u7c7b\u522b\u6807\u7b7e\u3001\u662f\u5426\u6253\u4e71\u7684\u6807\u7b7e\u3001\u672a\u6253\u4e71\u56fe\u50cf\u7684\u533a\u57df\u987a\u5e8f\u6807\u7b7e\u3001\u6253\u4e71\u56fe\u50cf\u7684\u533a\u57df\u987a\u5e8f\u6807\u7b7e\u3001\u56fe\u7247\u540d\n            return img_unswap, img_swap, label, label_swap, swap_law1, swap_law2, self.paths[item]\n        else:\n            # \u5982\u679c\u662f\u6d4b\u8bd5\u8fc7\u7a0b\uff0c\u5219\u76f4\u63a5\u8fd4\u56de\u539f\u56fe\u6807\u7b7e\n            label = self.labels[item]\n            # \u539f\u56fe\u7684\u533a\u57df\u987a\u5e8f\u6807\u7b7e\n            swap_law2 = [(i-(swap_range//2))/swap_range for i in range(swap_range)]\n            label_swap = label\n            # \u6570\u636e\u8f6c\u5316\u4e3atensor\u683c\u5f0f\n            img_unswap = self.totensor(img_unswap)\n            return img_unswap, label, label_swap, swap_law1, swap_law2, self.paths[item]\n</code></pre> <p>transforms\u65b9\u6cd5\uff1a\u6570\u636e\u9884\u5904\u7406</p> <pre><code>def load_data_transformers(resize_reso=512, crop_reso=448, swap_num=[7, 7]):\n    center_resize = 600\n    Normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    data_transforms = {\n        # \u5c06\u6570\u636e\u6253\u4e71\n        'swap': transforms.Compose([\n            transforms.Randomswap((swap_num[0], swap_num[1])),\n        ]),\n        # \u8bad\u7ec3\u56fe\u7247\u9884\u5904\u7406\u7b56\u7565\n        'common_aug': transforms.Compose([\n            # \u653e\u5927\n            transforms.Resize((resize_reso, resize_reso)),\n            # \u968f\u673a\u65cb\u8f6c\n            transforms.RandomRotation(degrees=15),\n            # \u968f\u673a\u88c1\u526a\n            transforms.RandomCrop((crop_reso,crop_reso)),\n            # \u968f\u673a\u6c34\u5e73\u7ffb\u8f6c\n            transforms.RandomHorizontalFlip(),\n        ]),\n        # \u8f6c\u5316\u4e3atensor\u683c\u5f0f\uff0c\u4e09\u79cd\u9636\u6bb5\u5904\u7406\u65b9\u6cd5\u76f8\u540c:\u653e\u5927-&gt;\u6570\u636e\u7c7b\u578b\u8f6c\u6362-&gt;\u6807\u51c6\u5316\n        'train_totensor': transforms.Compose([\n            transforms.Resize((crop_reso, crop_reso)),\n            # ImageNetPolicy(),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n        ]),\n        'val_totensor': transforms.Compose([\n            transforms.Resize((crop_reso, crop_reso)),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n        ]),\n        'test_totensor': transforms.Compose([\n            transforms.Resize((resize_reso, resize_reso)),\n            transforms.CenterCrop((crop_reso, crop_reso)),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n        ]),\n        'None': None,\n    }\n    return data_transforms\n</code></pre> <p>swap\u51fd\u6570\uff1a\u6253\u4e71\u539f\u56fe(\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f(1)-(3))</p> <pre><code>def swap(img, crop):\n    def crop_image(image, cropnum):\n        width, high = image.size\n        # x,y\u4ee3\u8868\u533a\u57df\u5de6\u4e0a\u89d2\uff0c\u901a\u8fc7\u8fdb\u4e00\u6b65\u5229\u7528x,y\u53ef\u4ee5\u88c1\u526a\u5c0f\u533a\u57df\n        crop_x = [int((width / cropnum[0]) * i) for i in range(cropnum[0] + 1)]\n        crop_y = [int((high / cropnum[1]) * i) for i in range(cropnum[1] + 1)]\n        im_list = []\n        for j in range(len(crop_y) - 1):\n            for i in range(len(crop_x) - 1):\n                # \u5c06\u88c1\u526a\u5f97\u5230\u7684\u533a\u57df\u4fdd\u5b58\u5230im_list\u4e2d\n                im_list.append(image.crop((crop_x[i], crop_y[j], min(crop_x[i + 1], width), min(crop_y[j + 1], high))))\n        return im_list\n    # \u539f\u56fe\u7684\u5bbd\u3001\u9ad8\n    widthcut, highcut = img.size\n    # \u5220\u53bb\u539f\u56fe\u5468\u56f410*10\u7684\u533a\u57df\n    img = img.crop((10, 10, widthcut-10, highcut-10))\n    # \u5c06\u539f\u56fe\u53d8\u6210\u533a\u57df\u5757\uff0c\u8fd4\u56de\u7684images\u957f\u5ea6\u4e3a49,\u4ee3\u886849\u4e2a\u5b50\u533a\u57df(\u5bbd\u9ad8\u54047)\n    images = crop_image(img, crop)\n    pro = 5\n    if pro &gt;= 5:          \n        tmpx = []\n        tmpy = []\n        count_x = 0\n        count_y = 0\n        k = 1\n        # RAN\u76f8\u5f53\u4e8e\u8bba\u6587\u4e2d\u7684\u8d85\u53c2\u6570k\n        RAN = 2\n        # \u6253\u4e71\u64cd\u4f5c\uff0c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f(1)-(3)\n        for i in range(crop[1] * crop[0]):\n            tmpx.append(images[i])\n            # count_x\u8868\u793a\u6bcf\u884c\u4e2d\uff0c\u53d6\u5f97\u7684\u56fe\u7247\u6570\u91cf\uff0c\u6bcf\u53d6\u4e00\u5f20\u56fe\u7247\uff0c\u5c31\u52a0\u4e00\n            count_x += 1\n            if len(tmpx) &gt;= k:\n                # \u9009\u53d6\u540e\u4e24\u4e2a\u6570\u636e\n                tmp = tmpx[count_x - RAN:count_x]\n                # \u8fdb\u884c\u6253\u4e71(\u76f8\u5f53\u4e8e\u5bf9\u5217\u6253\u4e71)\n                random.shuffle(tmp)\n                # \u91cd\u65b0\u8d4b\u503c\n                tmpx[count_x - RAN:count_x] = tmp\n            # \u5982\u679c\u7b2c\u4e00\u884c\u5b50\u533a\u57df\u6570\u91cf\u8fbe\u5230\u9884\u5148\u8bbe\u7f6e\u597d\u7684\u6570\u91cf(7\u4e2a)\uff0c\u5219count_x\u5f52\u96f6(\u6362\u884c\u64cd\u4f5c)\n            if count_x == crop[0]:\n                # tmpy\u50a8\u5b58\u603b\u7684\u56fe\u7247\u5e8f\u53f7\n                tmpy.append(tmpx)\n                # count_x\u5f52\u96f6\n                count_x = 0\n                # count_y\u8868\u793a\u884c\u6570\n                count_y += 1\n                # tmpx\u6e05\u96f6\n                tmpx = []\n            # \u5982\u679c\u884c\u6570\u975e\u96f6\uff0c\u5219\u4e5f\u5bf9\u884c\u8fdb\u884c\u6253\u4e71\uff0c\u5bf9\u884c\u6253\u4e71\u65f6\uff0c\u4e0d\u6539\u53d8\u884c\u5185\u90e8\u987a\u5e8f\uff0c\u53ea\u6539\u53d8\u884c\u95f4\u987a\u5e8f\n            if len(tmpy) &gt;= k:\n                # \u540c\u6837\uff0c\u5bf9\u540e\u4e24\u884c(\u8bbe\u7f6e\u597d\u7684\u8d85\u53c2\u6570)\u8fdb\u884c\u6253\u4e71\n                tmp2 = tmpy[count_y - RAN:count_y]\n                random.shuffle(tmp2)\n                # \u91cd\u65b0\u8d4b\u503c\n                tmpy[count_y - RAN:count_y] = tmp2\n        random_im = []\n        for line in tmpy:\n            # \u5f97\u5230\u6253\u4e71\u540e\u7684\u533a\u57df\u5757\u987a\u5e8f\n            random_im.extend(line)\n\n        # random.shuffle(images)\n        width, high = img.size\n        # \u5f97\u5230\u6bcf\u5757\u5c0f\u533a\u57df\u7684\u671f\u671b\u5927\u5c0f\n        # \u4e4b\u524d\u5728\u88c1\u526a\u5c0f\u533a\u57df\u4e4b\u524d\uff0c\u7531\u4e8e\u5220\u6389\u4e86\u5468\u56f410\u4e2a\u50cf\u7d20\uff0c\u6240\u4ee5\u5982\u679c\u4e0d\u52a0\u4ee5\u653e\u5927\uff0c\u62fc\u51fa\u6765\u7684\u56fe\u548c\u539f\u56fe\u5c3a\u5bf8\u4e0d\u4e00\u6837\n        iw = int(width / crop[0])\n        ih = int(high / crop[1])\n        # \u5f97\u5230\u65b0\u56fe\u7247toImage\n        toImage = Image.new('RGB', (iw * crop[0], ih * crop[1]))\n        x = 0\n        y = 0\n        # \u904d\u5386\u6bcf\u5757\u533a\u57df\n        for i in random_im:\n            # \u5c06\u533a\u57df\u5757\u653e\u5927\u5230\u671f\u671b\u7684\u5927\u5c0f\n            i = i.resize((iw, ih), Image.ANTIALIAS)\n            # \u5c06\u6253\u4e71\u540e\u7684\u533a\u57df\u5757\u4f9d\u6b21\u7c98\u8d34\u5230\u539f\u56fe\u6307\u5b9a\u7684\u4f4d\u7f6e\u4e0a\n            # \u6240\u6709\u56fe\u7247\u7c98\u8d34\u5b8c\uff0c\u5f97\u5230\u7684\u56fe\u50cf\u5c31\u662f\u6253\u4e71\u540e\u7684\u56fe\u7247\n            toImage.paste(i, (x * iw, y * ih))\n            x += 1\n            if x == crop[0]:\n                x = 0\n                y += 1\n    else:\n        toImage = img\n    toImage = toImage.resize((widthcut, highcut))\n    # \u6700\u540e\u8fd4\u56de\u6253\u4e71\u540e\u7684\u56fe\u7247\n    return toImage\n</code></pre> <p>collate\u65b9\u6cd5\uff1a\u4ee5\u8bad\u7ec3\u96c6\u56fe\u7247\u52a0\u8f7d\u4e3a\u4f8b</p> <pre><code>def collate_fn4train(batch):\n    imgs = []\n    label = []\n    label_swap = []\n    law_swap = []\n    img_name = []\n    # \u8fd9\u91cc\u7684sample\u8868\u793a\u91c7\u6837\u5f97\u5230\u7684\u6570\u636e\n    # sample\u4e0edataset\u51fd\u6570\u4e2d__getitem__\u65b9\u6cd5\u8fd4\u56de\u7684\u53d8\u91cf\u4e00\u6837\n    for sample in batch:\n        # \u524d\u4e24\u4e2a\u53d8\u91cf\u5747\u8868\u793a\u56fe\u7247\uff0c\u53ea\u662f\u542b\u4e49\u4e0d\u540c\n        # \u56e0\u6b64\u5c06\u524d\u4e24\u4e2a\u56fe\u7247\u5408\u5e76\u5230\u4e00\u4e2a\u53d8\u91cf\u4e2d\n        imgs.append(sample[0])\n        imgs.append(sample[1])\n        # \u5e76\u4e14\u5c06\u6807\u7b7e\u4e5f\u5408\u5e76\n        label.append(sample[2])\n        label.append(sample[2])\n        if sample[3] == -1:\n            # \u7b2c\u4e00\u4e2a\u6807\u7b7e\u8868\u793a\u672a\u88ab\u7834\u574f\uff0c\u7b2c\u4e8c\u4e2a\u8868\u793a\u56fe\u7247\u88ab\u7834\u574f\n            label_swap.append(1)\n            label_swap.append(0)\n        else:\n            label_swap.append(sample[2])\n            label_swap.append(sample[3])\n        # label_swap\u8868\u793a\u533a\u57df\u5757\u7684\u987a\u5e8f\n        # \u5206\u522b\u4e3a\u539f\u56fe\u7684\u533a\u57df\u5757\u987a\u5e8f\u548c\u88ab\u7834\u574f\u540e\u56fe\u50cf\u7684\u533a\u57df\u5757\u987a\u5e8f\n        law_swap.append(sample[4])\n        law_swap.append(sample[5])\n        # img_name\u8868\u793a\u56fe\u7247\u540d\u79f0\n        img_name.append(sample[-1])\n        # \u4f9d\u6b21\u8fd4\u56de\u56fe\u7247\u6570\u636e\u3001\u6807\u7b7e\u3001\u662f\u5426\u6253\u4e71\u7684\u6807\u7b7e\u3001\u533a\u57df\u5757\u987a\u5e8f\u3001\u56fe\u7247\u540d\u79f0\n    return torch.stack(imgs, 0), label, label_swap, law_swap, img_name\n</code></pre>"},{"location":"fine-grained/code/DCL2/#_5","title":"\u8bad\u7ec3\u8fc7\u7a0b","text":""},{"location":"fine-grained/code/DCL2/#_6","title":"\u8bad\u7ec3\u521d\u59cb\u5316\u9636\u6bb5","text":"<pre><code># \u52a0\u8f7d\u8d85\u53c2\u6570config\n    args = parse_args()\n    print(args, flush=True)\n    Config = LoadConfig(args, 'train')\n    Config.cls_2 = args.cls_2\n    Config.cls_2xmul = args.cls_mul\n    assert Config.cls_2 ^ Config.cls_2xmul\n    # \u52a0\u8f7d\u6570\u636e\u9884\u5904\u7406\u65b9\u6cd5\n    transformers = load_data_transformers(args.resize_resolution, args.crop_resolution, args.swap_num)\n    # inital dataloader\n    # \u52a0\u8f7d\u8bad\u7ec3\u96c6\n    train_set = dataset(Config = Config,\\\n                        anno = Config.train_anno,\\\n                        common_aug = transformers[\"common_aug\"],\\\n                        swap = transformers[\"swap\"],\\\n                        totensor = transformers[\"train_totensor\"],\\\n                        train = True)\n    # \u52a0\u8f7d\u9a8c\u8bc1\u96c6\n    trainval_set = dataset(Config = Config,\\\n                        anno = Config.train_anno,\\\n                        common_aug = transformers[\"None\"],\\\n                        swap = transformers[\"None\"],\\\n                        totensor = transformers[\"val_totensor\"],\\\n                        train = False,\n                        train_val = True)\n    # \u52a0\u8f7d\u6d4b\u8bd5\u96c6\n    val_set = dataset(Config = Config,\\\n                      anno = Config.val_anno,\\\n                      common_aug = transformers[\"None\"],\\\n                      swap = transformers[\"None\"],\\\n                      totensor = transformers[\"test_totensor\"],\\\n                      test=True)\n\n    dataloader = {}\n    # \u751f\u6210\u8bad\u7ec3\u6570\u636e\u8fed\u4ee3\u5668\n    dataloader['train'] = torch.utils.data.DataLoader(train_set,\\\n                                                batch_size=args.train_batch,\\\n                                                shuffle=True,\\\n                                                num_workers=args.train_num_workers,\\\n                                                collate_fn=collate_fn4train if not Config.use_backbone else collate_fn4backbone,\n                                                drop_last=True if Config.use_backbone else False,\n                                                pin_memory=True)\n    # \u8bbe\u7f6edataloader['train']\u4e2d\uff0ctotal_item_len\u7684\u5c5e\u6027\u503c\u4e3alen(train_set)\n    setattr(dataloader['train'], 'total_item_len', len(train_set))\n    # \u751f\u6210\u9a8c\u8bc1\u6570\u636e\u8fed\u4ee3\u5668\n    dataloader['trainval'] = torch.utils.data.DataLoader(trainval_set,\\\n                                                batch_size=args.val_batch,\\\n                                                shuffle=False,\\\n                                                num_workers=args.val_num_workers,\\\n                                                collate_fn=collate_fn4val if not Config.use_backbone else collate_fn4backbone,\n                                                drop_last=True if Config.use_backbone else False,\n                                                pin_memory=True)\n    # \u4e0etrian\u76f8\u540c\uff0c\u8bbe\u7f6edataloader['trainval']\u4e2dtotal_item_len\u5c5e\u6027\u4e3alen(trainval_set)\uff0cnum_cls\u5c5e\u6027\u4e3aConfig.numcls\n    setattr(dataloader['trainval'], 'total_item_len', len(trainval_set))\n    setattr(dataloader['trainval'], 'num_cls', Config.numcls)\n    # \u52a0\u8f7d\u6d4b\u8bd5\u6570\u636e\u96c6\n    dataloader['val'] = torch.utils.data.DataLoader(val_set,\\\n                                                batch_size=args.val_batch,\\\n                                                shuffle=False,\\\n                                                num_workers=args.val_num_workers,\\\n                                                collate_fn=collate_fn4test if not Config.use_backbone else collate_fn4backbone,\n                                                drop_last=True if Config.use_backbone else False,\n                                                pin_memory=True)\n\n    setattr(dataloader['val'], 'total_item_len', len(val_set))\n    setattr(dataloader['val'], 'num_cls', Config.numcls)\n    # \u4f18\u5316\u6a21\u578b\u8bad\u7ec3\u6548\u7387\n    cudnn.benchmark = True\n\n    print('Choose model and train set', flush=True)\n    # \u52a0\u8f7d\u6a21\u578b\n    model = MainModel(Config)\n\n    if (args.resume is None) and (not args.auto_resume):\n        # \u82e5\u65e0\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u5219\u53ea\u52a0\u8f7dImageNet\u9884\u8bad\u7ec3\u6a21\u578b\n        print('train from imagenet pretrained models ...', flush=True)\n    else:\n        # \u5982\u679c\u6709\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u5219\u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b\n        if not args.resume is None:\n            resume = args.resume\n            print('load from pretrained checkpoint %s ...'% resume, flush=True)\n        elif args.auto_resume:\n            resume = auto_load_resume(Config.save_dir)\n            print('load from %s ...'%resume, flush=True)\n        else:\n            raise Exception(\"no checkpoints to load\")\n        # \u63d0\u53d6\u7f51\u7edc\u6a21\u578b\u539f\u59cb\u53c2\u6570\n        model_dict = model.state_dict()\n        # \u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b\u53c2\u6570\n        pretrained_dict = torch.load(resume)\n        pretrained_dict = {k[7:]: v for k, v in pretrained_dict.items() if k[7:] in model_dict}\n        # \u66f4\u65b0\u7f51\u7edc\u539f\u59cb\u53c2\u6570\n        model_dict.update(pretrained_dict)\n        # \u52a0\u8f7d\u53c2\u6570\n        model.load_state_dict(model_dict)\n\n    print('Set cache dir', flush=True)\n    # \u5f97\u5230\u5f53\u524d\u65f6\u95f4\n    time = datetime.datetime.now()\n    # \u4ee5\u5f53\u524d\u65f6\u95f4\u5b9a\u4e49\u6a21\u578b\u4fdd\u5b58\u5730\u5740\n    filename = '%s_%d%d%d_%s'%(args.discribe, time.month, time.day, time.hour, Config.dataset)\n    save_dir = os.path.join(Config.save_dir, filename)\n    if not os.path.exists(save_dir):\n        # \u521b\u5efa\u5730\u5740\n        os.makedirs(save_dir)\n    # \u5c06\u6a21\u578b\u653e\u5165\u663e\u5361\u4e2d\n    model.cuda()\n    # \u591a\u5361\u5e76\u884c\u8bad\u7ec3\n    model = nn.DataParallel(model)\n\n    # optimizer prepare\n    # id\u8868\u793a\u8fd4\u56de\u5bf9\u8c61\u5185\u5b58\u5730\u5740\n    if Config.use_backbone:\n        ignored_params = list(map(id, model.module.classifier.parameters()))\n    else:\n        # \u5f97\u5230\u7f51\u7edc\u6a21\u578b\u4f18\u5316\u53c2\u6570\n        ignored_params1 = list(map(id, model.module.classifier.parameters()))\n        ignored_params2 = list(map(id, model.module.classifier_swap.parameters()))\n        ignored_params3 = list(map(id, model.module.Convmask.parameters()))\n        ignored_params = ignored_params1 + ignored_params2 + ignored_params3\n\n    print('the num of new layers:', len(ignored_params), flush=True)\n    # base_params\u8868\u793a\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u7684\u53c2\u6570\n    base_params = filter(lambda p: id(p) not in ignored_params, model.module.parameters())\n    # \u5b66\u4e60\u7387\u6bd4\u7387\n    lr_ratio = args.cls_lr_ratio\n    # \u57fa\u7840\u5b66\u4e60\u7387\n    base_lr = args.base_lr\n    if Config.use_backbone:\n        optimizer = optim.SGD([{'params': base_params},\n                               {'params': model.module.classifier.parameters(), 'lr': base_lr}], lr = base_lr, momentum=0.9)\n    else:\n        optimizer = optim.SGD([{'params': base_params},\n                               # \u8fd9\u91cc\u8868\u793aclassifier\u3001classifier_swap\u3001Convmask\u7684\u53c2\u6570\u66f4\u65b0\u901f\u7387\u662f\u5176\u4ed6\u53c2\u6570\u7684lr_ratio\u500d\n                               {'params': model.module.classifier.parameters(), 'lr': lr_ratio*base_lr},\n                               {'params': model.module.classifier_swap.parameters(), 'lr': lr_ratio*base_lr},\n                               {'params': model.module.Convmask.parameters(), 'lr': lr_ratio*base_lr},\n                              ], lr = base_lr, momentum=0.9)\n    # \u5b66\u4e60\u7387\u66f4\u65b0\u7b56\u7565\n    exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=args.decay_step, gamma=0.1)\n    # \u5f00\u59cb\u8bad\u7ec3\n    # train entry\n    train(Config,\n          model,\n          epoch_num=args.epoch,\n          start_epoch=args.start_epoch,\n          optimizer=optimizer,\n          exp_lr_scheduler=exp_lr_scheduler,\n          data_loader=dataloader,\n          save_dir=save_dir,\n          data_size=args.crop_resolution,\n          savepoint=args.save_point,\n          checkpoint=args.check_point)\n</code></pre>"},{"location":"fine-grained/code/DCL2/#_7","title":"\u8bad\u7ec3\u6d41\u7a0b","text":"<pre><code>def train(Config,\n          model,\n          epoch_num,\n          start_epoch,\n          optimizer,\n          exp_lr_scheduler,\n          data_loader,\n          save_dir,\n          data_size=448,\n          savepoint=500,\n          checkpoint=1000\n          ):\n    # savepoint: save without evalution\n    # checkpoint: save with evaluation\n\n    step = 0\n    eval_train_flag = False\n    rec_loss = []\n    checkpoint_list = []\n    # \u5f97\u5230batch_size\n    train_batch_size = data_loader['train'].batch_size\n    # \u5f97\u5230\u6bcf\u4e2aepoch\u8fed\u4ee3\u6b21\u6570\n    train_epoch_step = data_loader['train'].__len__()\n    # \u52a0\u8f7d\u8bb0\u5f55\u635f\u5931\u7684\u7c7b\n    train_loss_recorder = LossRecord(train_batch_size)\n    # \u6700\u5c11\u6bcf\u7ecf\u8fc7\u4e00\u4e2aepoch\u4fdd\u5b58\u4e00\u6b21\u6a21\u578b\n    # \u4e00\u4e2aepoch\u91cc\u53ef\u4ee5\u4fdd\u5b58\u591a\u6b21\u6a21\u578b\n    if savepoint &gt; train_epoch_step:\n        savepoint = 1*train_epoch_step\n        checkpoint = savepoint\n    # \u5f97\u5230\u5f53\u524d\u65f6\u95f4\n    date_suffix = dt()\n    # \u52a0\u8f7d\u65e5\u5fd7\u6587\u4ef6\n    log_file = open(os.path.join(Config.log_folder, 'formal_log_r50_dcl_%s_%s.log'%(str(data_size), date_suffix)), 'a')\n    # \u5b9a\u4e49\u635f\u5931\u51fd\u6570\n    add_loss = nn.L1Loss()\n    get_ce_loss = nn.CrossEntropyLoss()\n    get_focal_loss = FocalLoss()\n    get_angle_loss = AngleLoss()\n\n    for epoch in range(start_epoch,epoch_num-1):\n        exp_lr_scheduler.step(epoch)\n        model.train(True)\n\n        save_grad = []\n        for batch_cnt, data in enumerate(data_loader['train']):\n            step += 1\n            loss = 0\n            model.train(True)\n            # \u5982\u679c\u53ea\u4f7f\u7528\u4e3b\u5e72\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\uff0c\u5219\u53ea\u9700\u8981\u539f\u59cb\u56fe\u7247\u4e0e\u6807\u7b7e\n            if Config.use_backbone:\n                # \u5f97\u5230\u8f93\u5165\u6570\u636e\u3001\u6807\u7b7e\u4e0e\u56fe\u7247\u540d\u79f0\n                inputs, labels, img_names = data\n                # \u5c06\u8f93\u5165\u4e0e\u6807\u7b7e\u8f6c\u5316\u6210\u53d8\u91cf\uff0c\u4fbf\u4e8e\u53cd\u5411\u4f20\u64ad\n                inputs = Variable(inputs.cuda())\n                labels = Variable(torch.from_numpy(np.array(labels)).cuda())\n            if Config.use_dcl:\n                # \u82e5\u4f7f\u7528dcl\u7f51\u7edc\uff0c\u5219\u4f9d\u6b21\u5f97\u5230\u56fe\u7247\u6570\u636e\u3001\u6807\u7b7e\u3001\u662f\u5426\u6253\u4e71\u7684\u6807\u7b7e\u3001\u533a\u57df\u5757\u987a\u5e8f\u3001\u56fe\u7247\u540d\u79f0\n                inputs, labels, labels_swap, swap_law, img_names = data\n                # \u5c06\u6240\u6709\u7684\u6570\u636e\u53d8\u4e3a\u53d8\u91cf\uff0c\u4fbf\u4e8e\u53cd\u5411\u4f20\u64ad\n                inputs = Variable(inputs.cuda())\n                labels = Variable(torch.from_numpy(np.array(labels)).cuda())\n                labels_swap = Variable(torch.from_numpy(np.array(labels_swap)).cuda())\n                swap_law = Variable(torch.from_numpy(np.array(swap_law)).float().cuda())\n            # \u68af\u5ea6\u6e05\u96f6\n            optimizer.zero_grad()\n            if inputs.size(0) &lt; 2*train_batch_size:\n                # \u4e0eAsoftmax\u6a21\u5757\u6709\u5173\uff0c\u8bba\u6587\u672a\u63d0\n                outputs = model(inputs, inputs[0:-1:2])\n            else:\n                # \u5c06\u8f93\u5165\u4f20\u5165\u6a21\u578b\u4e2d\uff0c\u5f97\u5230\u8f93\u51fa\n                outputs = model(inputs, None)\n            if Config.use_focal_loss:\n                # focal_loss\u8bba\u6587\u4e2d\u672a\u63d0\n                ce_loss = get_focal_loss(outputs[0], labels)\n            else:\n                # \u56fe\u50cf(\u539f\u56fe\u4e0e\u6253\u4e71\u540e\u7684\u56fe)\u9884\u6d4b\u503c\u4e0e\u6807\u7b7e\u505a\u4ea4\u53c9\u71b5\u635f\u5931\n                ce_loss = get_ce_loss(outputs[0], labels)\n            # \u8bba\u6587\u4e2d\u672a\u63d0\u53caAsoftmax\u6a21\u5757\n            if Config.use_Asoftmax:\n                fetch_batch = labels.size(0)\n                if batch_cnt % (train_epoch_step // 5) == 0:\n                    angle_loss = get_angle_loss(outputs[3], labels[0:fetch_batch:2], decay=0.9)\n                else:\n                    angle_loss = get_angle_loss(outputs[3], labels[0:fetch_batch:2])\n                loss += angle_loss\n\n            loss += ce_loss\n            # alpha_\u3001beta_\u3001gamma_\u8868\u793a\u5404\u635f\u5931\u7684\u6743\u91cd\uff0c\u7528\u4e8e\u8ba1\u7b97\u6700\u540e\u7684\u603b\u635f\u5931\n            alpha_ = 1\n            beta_ = 1\n            gamma_ = 0.01 if Config.dataset == 'STCAR' or Config.dataset == 'AIR' else 1\n            if Config.use_dcl:\n                # \u5bf9\u6297\u635f\u5931\uff0c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f(6)\n                # \u9884\u6d4b\u8be5\u56fe\u662f\u539f\u56fe\u7684\u6982\u7387\uff0c\u4e0e\u5b9e\u9645\u7684\u662f\u5426\u662f\u539f\u56fe\u8fd9\u4e00\u6807\u7b7e(\u8bba\u6587\u4e2d\u7684d\u53c2\u6570)\u505a\u4ea4\u53c9\u71b5\u635f\u5931\n                swap_loss = get_ce_loss(outputs[1], labels_swap) * beta_\n                loss += swap_loss\n                # \u5229\u7528\u9884\u6d4b\u7684\u533a\u57df\u987a\u5e8f\u4e0e\u6807\u7b7e\u987a\u5e8f\u6c42L1\u635f\u5931\uff0c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f(9)\n                law_loss = add_loss(outputs[2], swap_law) * gamma_\n                loss += law_loss\n            # \u53cd\u5411\u4f20\u64ad\uff0c\u6c42\u68af\u5ea6\n            loss.backward()\n            # \u7b49\u5f85\u5f53\u524d\u8bbe\u5907\u4e0a\u6240\u6709\u6d41\u4e2d\u7684\u6240\u6709\u6838\u5fc3\u5b8c\u6210(\u591a\u5361\u8bad\u7ec3\u65f6\u7528\u5230)\n            torch.cuda.synchronize()\n            # \u66f4\u65b0\u53c2\u6570\n            optimizer.step()\n            torch.cuda.synchronize()\n            # \u8f93\u51fa\u8bad\u7ec3\u9636\u6bb5\u53c2\u6570\n            if Config.use_dcl:\n                print('step: {:-8d} / {:d} loss=ce_loss+swap_loss+law_loss: {:6.4f} = {:6.4f} + {:6.4f} + {:6.4f} '.format(step, train_epoch_step, loss.detach().item(), ce_loss.detach().item(), swap_loss.detach().item(), law_loss.detach().item()), flush=True)\n            if Config.use_backbone:\n                print('step: {:-8d} / {:d} loss=ce_loss+swap_loss+law_loss: {:6.4f} = {:6.4f} '.format(step, train_epoch_step, loss.detach().item(), ce_loss.detach().item()), flush=True)\n            # \u8bb0\u5f55\u635f\u5931\u53d8\u5316\n            rec_loss.append(loss.detach().item())\n            train_loss_recorder.update(loss.detach().item())\n\n            # evaluation &amp; save\uff0c\u6d4b\u8bd5\u4e0e\u6a21\u578b\u4fdd\u5b58\n            if step % checkpoint == 0:\n                rec_loss = []\n                print(32*'-', flush=True)\n                print('step: {:d} / {:d} global_step: {:8.2f} train_epoch: {:04d} rec_train_loss: {:6.4f}'.format(step, train_epoch_step, 1.0*step/train_epoch_step, epoch, train_loss_recorder.get_val()), flush=True)\n                print('current lr:%s' % exp_lr_scheduler.get_lr(), flush=True)\n                # \u662f\u5426\u8fdb\u884c\u6d4b\u8bd5(\u8fd9\u91cc\u53ef\u80fd\u662f\u591a\u4f59\u7684)\n                if eval_train_flag:\n                    # \u6d4b\u8bd5\u8fc7\u7a0b\uff0c\u89c1eval_turn\u51fd\u6570\n                    trainval_acc1, trainval_acc2, trainval_acc3 = eval_turn(Config, model, data_loader['trainval'], 'trainval', epoch, log_file)\n                    if abs(trainval_acc1 - trainval_acc3) &lt; 0.01:\n                        # \u5982\u679c\u6d4b\u8bd5\u7ed3\u679ctop-1\u4e0etop-3\u7cbe\u5ea6\u76f8\u5dee\u4e0d\u5927\uff0c\u5219\u4e0b\u4e00\u6b21\u4e0d\u518d\u6d4b\u8bd5\n                        eval_train_flag = False\n                # \u6d4b\u8bd5\u8fc7\u7a0b\uff0c\u5f97\u5230top-1\u3001top-2\u3001top-3\u7cbe\u5ea6\n                val_acc1, val_acc2, val_acc3 = eval_turn(Config, model, data_loader['val'], 'val', epoch, log_file)\n                # \u5f97\u5230\u6a21\u578b\u4fdd\u5b58\u8def\u5f84\n                save_path = os.path.join(save_dir, 'weights_%d_%d_%.4f_%.4f.pth'%(epoch, batch_cnt, val_acc1, val_acc3))\n                torch.cuda.synchronize()\n                # \u4fdd\u5b58\u6a21\u578b\u53c2\u6570\n                torch.save(model.state_dict(), save_path)\n                print('saved model to %s' % (save_path), flush=True)\n                # \u91ca\u653e\u663e\u5b58\n                torch.cuda.empty_cache()\n\n            # \u53ea\u4fdd\u5b58\u6a21\u578b\n            elif step % savepoint == 0:\n                train_loss_recorder.update(rec_loss)\n                rec_loss = []\n                # \u6a21\u578b\u4fdd\u5b58\u8def\u5f84\n                save_path = os.path.join(save_dir, 'savepoint_weights-%d-%s.pth'%(step, dt()))\n                # \u4fdd\u5b58\u6a21\u578b\u8def\u5f84\n                checkpoint_list.append(save_path)\n                # \u6700\u591a\u540c\u65f6\u4fdd\u5b586\u4e2a\u6a21\u578b\n                if len(checkpoint_list) == 6:\n                    os.remove(checkpoint_list[0])\n                    del checkpoint_list[0]\n                # \u4fdd\u5b58\u7f51\u7edc\u53c2\u6570\n                torch.save(model.state_dict(), save_path)\n                # \u91ca\u653e\u663e\u5b58\n                torch.cuda.empty_cache()\n    # \u5173\u95ed\u65e5\u5fd7\u6587\u4ef6\n    log_file.close()\n</code></pre>"},{"location":"fine-grained/code/DCL2/#_8","title":"\u9a8c\u8bc1\u6d41\u7a0b","text":"<pre><code>def eval_turn(Config, model, data_loader, val_version, epoch_num, log_file):\n    # \u5c06\u6a21\u578b\u8f6c\u4e3a\u6d4b\u8bd5\u9636\u6bb5(\u4e0d\u66f4\u65b0\u53c2\u6570)\n    model.train(False)\n    # \u521d\u59cb\u5316\u7528\u4e8e\u50a8\u5b58\u7cbe\u5ea6\u7684\u53d8\u91cf\n    val_corrects1 = 0\n    val_corrects2 = 0\n    val_corrects3 = 0\n    # \u6d4b\u8bd5\u96c6\u5927\u5c0f\n    val_size = data_loader.__len__()\n    # \u6d4b\u8bd5\u96c6\u56fe\u7247\u6570\u91cf\n    item_count = data_loader.total_item_len\n    # \u521d\u59cb\u5316\u65f6\u95f4\n    t0 = time.time()\n    # \u5b9a\u4e49\u635f\u5931\u51fd\u6570\n    get_l1_loss = nn.L1Loss()\n    get_ce_loss = nn.CrossEntropyLoss()\n    # \u5f97\u5230batch_size\u5927\u5c0f\u4e0e\u6d4b\u8bd5\u603b\u6b21\u6570(\u6bcf\u4e2aepoch\u9700\u8981\u9884\u6d4b\u591a\u5c11\u6b21)\n    val_batch_size = data_loader.batch_size\n    val_epoch_step = data_loader.__len__()\n    # \u5f97\u5230\u7c7b\u522b\u6570\u91cf\n    num_cls = data_loader.num_cls\n    # \u8bb0\u5f55\u635f\u5931\u53d8\u5316\u8fc7\u7a0b\n    val_loss_recorder = LossRecord(val_batch_size)\n    val_celoss_recorder = LossRecord(val_batch_size)\n    print('evaluating %s ...'%val_version, flush=True)\n    with torch.no_grad():\n        # \u904d\u5386\u6d4b\u8bd5\u96c6\n        for batch_cnt_val, data_val in enumerate(data_loader):\n            # \u5c06\u6570\u636e\u8f6c\u53d8\u4e3a\u53d8\u91cf\n            inputs = Variable(data_val[0].cuda())\n            labels = Variable(torch.from_numpy(np.array(data_val[1])).long().cuda())\n            # \u5f97\u5230\u8f93\u51fa\n            outputs = model(inputs)\n            loss = 0\n            # \u5f97\u5230\u56fe\u7247\u9884\u6d4b\u6982\u7387\u4e0e\u56fe\u7247\u6807\u7b7e\u4e4b\u95f4\u7684\u635f\u5931\n            ce_loss = get_ce_loss(outputs[0], labels).item()\n            loss += ce_loss\n            # \u8bb0\u5f55\u5f97\u5230\u7684\u635f\u5931\n            val_loss_recorder.update(loss)\n            val_celoss_recorder.update(ce_loss)\n            # \u8bba\u6587\u4e2d\u672a\u63d0\u53cacls_2xmul\n            if Config.use_dcl and Config.cls_2xmul:\n                outputs_pred = outputs[0] + outputs[1][:,0:num_cls] + outputs[1][:,num_cls:2*num_cls]\n            else:\n                # \u5f97\u5230\u7c7b\u522b\u9884\u6d4b\u6982\u7387\n                outputs_pred = outputs[0]\n            # torch.topk\u8868\u793a\u5148\u6392\u5e8f(\u9ed8\u8ba4\u6309\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\u4ee5\u964d\u5e8f\u7684\u987a\u5e8f\u6392\u5e8f)\uff0c\u4e4b\u540e\u53d6\u524dk\u4e2a\u6570\u636e\n            # \u8fd9\u91cc\u8868\u793a\u53d6\u524d3\u4e2a\u6700\u5927\u7684\u9884\u6d4b\u6982\u7387\n            top3_val, top3_pos = torch.topk(outputs_pred, 3)\n            # \u8f93\u51fa\u6d4b\u8bd5\u4fe1\u606f\n            print('{:s} eval_batch: {:-6d} / {:d} loss: {:8.4f}'.format(val_version, batch_cnt_val, val_epoch_step, loss), flush=True)\n            # \u4e0b\u9762\u4f9d\u6b21\u8ba1\u7b97top-1\u3001top-2\u3001top-3\u7cbe\u5ea6\n            batch_corrects1 = torch.sum((top3_pos[:, 0] == labels)).data.item()\n            # val_corrects1\u8868\u793atop-1\u6b63\u786e\u4e2a\u6570\n            val_corrects1 += batch_corrects1\n            batch_corrects2 = torch.sum((top3_pos[:, 1] == labels)).data.item()\n            # val_corrects2\u8868\u793atop-2(\u9884\u6d4b\u6982\u7387\u524d2)\u6b63\u786e\u4e2a\u6570\n            val_corrects2 += (batch_corrects2 + batch_corrects1)\n            batch_corrects3 = torch.sum((top3_pos[:, 2] == labels)).data.item()\n            # val_corrects3\u8868\u793atop-3(\u9884\u6d4b\u6982\u7387\u524d3)\u6b63\u786e\u4e2a\u6570\n            val_corrects3 += (batch_corrects3 + batch_corrects2 + batch_corrects1)\n        # \u4f9d\u6b21\u5f97\u5230top-1\u3001top-2\u3001top-3\u7cbe\u5ea6\n        val_acc1 = val_corrects1 / item_count\n        val_acc2 = val_corrects2 / item_count\n        val_acc3 = val_corrects3 / item_count\n        # \u5199\u5165\u65e5\u5fd7\n        log_file.write(val_version  + '\\t' +str(val_loss_recorder.get_val())+'\\t' + str(val_celoss_recorder.get_val()) + '\\t' + str(val_acc1) + '\\t' + str(val_acc3) + '\\n')\n        # \u5f97\u5230\u6d4b\u8bd5\u7ec8\u6b62\u65f6\u95f4\n        t1 = time.time()\n        # \u505a\u5dee\uff0c\u5f97\u5230\u6d4b\u8bd5\u65f6\u95f4\n        since = t1-t0\n        print('--'*30, flush=True)\n        print('% 3d %s %s %s-loss: %.4f ||%s-acc@1: %.4f %s-acc@2: %.4f %s-acc@3: %.4f ||time: %d' % (epoch_num, val_version, dt(), val_version, val_loss_recorder.get_val(init=True), val_version, val_acc1,val_version, val_acc2, val_version, val_acc3, since), flush=True)\n        print('--' * 30, flush=True)\n    # \u8fd4\u56de\u7cbe\u5ea6\n    return val_acc1, val_acc2, val_acc3\n</code></pre> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u5927\u5bb6\u6279\u8bc4\u6307\u6b63\u3002</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e7412\u67087\u65e5</p>"},{"location":"fine-grained/code/MA-CNN2/","title":"\u7ec6\u7c92\u5ea6\uff1aMA-CNN","text":""},{"location":"fine-grained/code/MA-CNN2/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aIEEE International Conference on Computer Vision 2017 (ICCV 2017)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttp://openaccess.thecvf.com/content_ICCV_2017/papers/Zheng_Learning_Multi-Attention_Convolutional_ICCV_2017_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/Jianlong-Fu/Multi-Attention-CNN\uff08\u5b98\u65b9\u4ee3\u7801\uff0ccaffe\u7248\u672c\uff09\u3001https://github.com/liangnjupt/Multi-Attention-CNN-pytorch\uff08PyTorch\u7248\u672c\uff09</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u7c7b(FGVC)</p> <p>\u4ee5\u4e0b\u4ee3\u7801\u53c2\u8003\uff1ahttps://github.com/liangnjupt/Multi-Attention-CNN-pytorch</p>"},{"location":"fine-grained/code/MA-CNN2/#_2","title":"\u7f51\u7edc\u7ed3\u6784","text":""},{"location":"fine-grained/code/MA-CNN2/#_3","title":"\u6574\u4f53\u7ed3\u6784","text":"<pre><code>class MACNN(nn.Module):\n    # \u53c2\u6570\u521d\u59cb\u5316\n    def __init__(self, class_num):\n        super(MACNN, self).__init__()\n        self.vgg = vgg.vgg19(True)\n        self.feat_dims = 512\n        self.class_num = class_num\n        # \u5b9a\u4e49\u56db\u4e2a\u901a\u9053\u5206\u7ec4\u5c42\uff0c\u5373\u8bba\u6587\u4e2d\u7684channel grouping layers\n        self.se1 = SELayer(self.feat_dims)\n        self.se2 = SELayer(self.feat_dims)\n        self.se3 = SELayer(self.feat_dims)\n        self.se4 = SELayer(self.feat_dims)\n        # \u5b9a\u4e49\u5168\u5c40\u5e73\u5747\u6c60\u5316\u5c42\n        self.pool = nn.AdaptiveAvgPool2d(1)\n        # \u5b9a\u4e49\u5168\u8fde\u63a5\u5c42\uff0c\u7528\u4e8e\u5bf9\u56fe\u50cf\u505a\u5206\u7c7b\n        self.fc1 = nn.Linear(self.feat_dims, self.class_num)\n        self.fc2 = nn.Linear(self.feat_dims, self.class_num)\n        self.fc3 = nn.Linear(self.feat_dims, self.class_num)\n        self.fc4 = nn.Linear(self.feat_dims, self.class_num)\n        self.fcall = nn.Linear(5 * self.feat_dims, self.class_num)\n\n    # \u524d\u5411\u4f20\u64ad\n    def forward(self, x):\n        # \u5148\u5c06\u56fe\u7247\u4f20\u5165\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u63d0\u53d6\u7279\u5f81\n        feat_maps = self.vgg(x)\n        # \u4f9d\u6b21\u5c06\u5f97\u5230\u7684\u7279\u5f81\u4f20\u5165\u901a\u9053\u5206\u7ec4\u5c42\uff0c\u5f97\u5230\u5c40\u90e8\u7279\u5f81(Pi)\u548c\u5c40\u90e8\u6ce8\u610f\u529b\u56fe(Mi)\n        # \u5176\u4e2d\u5c40\u90e8\u7279\u5f81Pi\u662f\u7531\u7279\u5f81x\u548c\u5c40\u90e8\u6ce8\u610f\u529b\u56feMi\u76f8\u4e58\uff0c\u518d\u5168\u5c40\u6c60\u5316\u5f97\u5230\n        P1, M1 = self.se1(feat_maps)\n        P2, M2 = self.se2(feat_maps)\n        P3, M3 = self.se3(feat_maps)\n        P4, M4 = self.se4(feat_maps)\n        # \u4f9d\u6b21\u5c06\u5c40\u90e8\u7279\u5f81\u4f20\u5165\u5b9a\u4e49\u597d\u7684\u5168\u8fde\u63a5\u5c42\uff0c\u5f97\u5230\u6bcf\u4e2a\u90e8\u4f4d\u7684\u5206\u7c7b\u7ed3\u679c\n        pred1 = self.fc1(P1.flatten(1))\n        pred2 = self.fc2(P2.flatten(1))\n        pred3 = self.fc3(P3.flatten(1))\n        pred4 = self.fc4(P4.flatten(1))\n        # \u5c06\u5c40\u90e8\u7279\u5f81\u4e0e\u5168\u5c40\u7279\u5f81\u5408\u5e76\uff0c\u518d\u4f20\u5165\u5168\u8fde\u63a5\u5c42\u5f97\u5230\u6700\u7ec8\u7684\u5206\u7c7b\u7ed3\u679c\n        P = torch.cat([P1, P2, P3, P4, self.pool(feat_maps)], dim=1)\n        pred = self.fcall(P.flatten(1))\n\n        return [P1, P2, P3, P4], \\\n            [M1, M2, M3, M4], \\\n            [pred1, pred2, pred3, pred4, pred]\n</code></pre>"},{"location":"fine-grained/code/MA-CNN2/#_4","title":"\u901a\u9053\u5206\u7ec4\u5c42","text":"<pre><code>class SELayer(nn.Module):\n    def __init__(self, channel, reduction=1):\n        super(SELayer, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        # \u5b9a\u4e49\u5168\u8fde\u63a5\u5c42\uff0c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f3\u4e2d\u7684fi(\u00b7)\n        self.fc = nn.Sequential(\n            nn.Linear(channel, channel // reduction, bias=False),\n            nn.Tanh(),\n            nn.Linear(channel // reduction, channel, bias=False)\n        )\n\n    def forward(self, x):\n        b, c, h, w = x.size()\n        # \u5148\u5c06\u7279\u5f81\u4f9d\u6b21\u4f20\u5165\u5168\u5c40\u6c60\u5316\u3001\u5168\u8fde\u63a5\u5c42\uff0c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f3\n        y = self.avg_pool(x).view(b, c)\n        y = self.fc(y)\n        y_ = y.view(b, c, 1, 1)\n\n        # paper revised version\n        # \u6cbf\u901a\u9053\u6c42\u548c,\u4e4b\u540e\u518d\u5c06\u6ce8\u610f\u529b\u56fe\u505asigmoid\u5f52\u4e00\u5316\u5904\u7406\uff0c\u5f97\u5230\u5c40\u90e8\u6ce8\u610f\u529b\u56fe\uff0c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f4\n        M = torch.sum(x * y_.expand_as(x), dim=1, keepdim=True)  # b,1,h,w\n        M = torch.sigmoid(M).view(b, 1, h, w)\n        # \u5c06\u6ce8\u610f\u529b\u56fe\u548c\u56fe\u7247\u7279\u5f81\u505a\u70b9\u4e58\uff0c\u5f97\u5230\u5c40\u90e8\u7279\u5f81\n        P = x * M.expand_as(x)  # b,1,h,w\n        P = F.avg_pool2d(P, (h, w))  # b,c,1,1\n\n        return P, M.squeeze(dim=1)\n</code></pre>"},{"location":"fine-grained/code/MA-CNN2/#_5","title":"\u635f\u5931\u51fd\u6570","text":""},{"location":"fine-grained/code/MA-CNN2/#_6","title":"\u8ddd\u79bb\u635f\u5931","text":"<p>\u7528\u4e8e\u9f13\u52b1\u540c\u4e00\u5206\u652f\u7684\u6ce8\u610f\u529b\u53bb\u5173\u6ce8\u7269\u4f53\u76f8\u540c\u7684\u90e8\u4f4d</p> <pre><code># \u8ddd\u79bb\u635f\u5931\nclass DisLoss(nn.Module):\n    def __init__(self):\n        super(DisLoss, self).__init__()\n        return\n\n    def forward(self, x):\n        '''\n        :param x:  b,h,w\n        :return:\n        '''\n        b, h, w = x.shape\n        x = x.view(b, -1)\n        # \u5b9a\u4f4d\u6ce8\u610f\u529b\u56fe\u6700\u5927\u503c\u6240\u5728\u7684\u4f4d\u7f6e\n        num = torch.argmax(x, dim=1)\n        # \u5f97\u5230\u6700\u503c\u5904\u7684\u6a2a\u7eb5\u5750\u6807\n        cx = num % h\n        cy = num // h\n        # \u8ddd\u79bb\u56fe\uff0c\u4e5f\u5c31\u662f\u4e00\u5f20h\u00d7w\u7684\u56fe\uff0c\u56fe\u4e0a\u7684\u70b9\u8ddd\u79bb\u6700\u503c\u70b9\u8d8a\u8fdc\uff0c\u503c\u8d8a\u5927\n        # \u5bf9\u5e94\u8bba\u6587\u516c\u5f0f8\u4e2d\u540e\u534a\u90e8\u5206(\u7b97\u8ddd\u79bb)\n        maps = self.get_maps(h, cx, cy)\n        maps = torch.from_numpy(maps).to(x.device)\n        # \u8ddd\u79bb\u548c\u6ce8\u610f\u529b\u6570\u636e\u70b9\u4e58\u6c42\u548c\uff0c\u5f97\u5230\u635f\u5931\n        # \u8be5\u635f\u5931\u7528\u4e8e\u9f13\u52b1\u6bcf\u4e2a\u5206\u652f\u7684\u6ce8\u610f\u529b\u6570\u636e\u90fd\u96c6\u4e2d\u4e8e\u4e00\u4e2a\u4f4d\u7f6e\uff0c\u5373\u96c6\u4e2d\u5728\u6700\u5927\u503c\u5904\n        part = x * maps\n        loss = torch.sum(part) / b\n        return loss\n\n    # \u8ba1\u7b97\u6700\u503c\u8ddd\u79bb\n    def get_maps(self, a, cx, cy):\n        batch_size = len(cx)\n        cx = cx.data.cpu().numpy()\n        cy = cy.data.cpu().numpy()\n        maps = np.zeros((batch_size, a * a), dtype=np.float32)\n        # \u5148\u5f97\u5230\u4e24\u7ec4\u8fde\u7eed\u6570\u636e\uff0c\u5206\u522b\u8868\u793a\u6ce8\u610f\u529b\u56fe\u7684\u957f\u5bbd\n        rows = np.arange(a)\n        cols = np.arange(a)\n        coords = np.empty((len(rows), len(cols), 2), dtype=np.intp)\n        # \u4e24\u7ec4\u6570\u636e\u7ec4\u6210\u5750\u6807\u77e9\u9635\uff0c\u8fd9\u91cccoords\u5c3a\u5bf8\u4e3a(h*w, 2)\uff0c\u7b2c\u4e8c\u7ef4\u5ea6\u50a8\u5b58x\uff0cy\u5750\u6807\u6570\u636e\n        coords[..., 0] = rows[:, None]\n        coords[..., 1] = cols\n        coords = coords.reshape(-1, 2)\n        # \u9010batch\u904d\u5386\n        for b in range(batch_size):\n            vec = np.array([cy[b], cx[b]])\n            # \u8ba1\u7b97\u5f53\u524d\u5750\u6807\u70b9\u4e0e\u6700\u503c\u5904\u5750\u6807\u70b9\u7684\u6b27\u6c0f\u8ddd\u79bb\uff0c\u5f97\u5230\u8ddd\u79bb\u6570\u636e\uff0c\u5b58\u5165maps\u4e2d\n            maps[b, :] = np.linalg.norm(coords - vec, axis=1)\n        return maps\n</code></pre>"},{"location":"fine-grained/code/MA-CNN2/#_7","title":"\u591a\u6837\u6027\u635f\u5931","text":"<p>\u7528\u4e8e\u9f13\u52b1\u7f51\u7edc\u4e0d\u540c\u6ce8\u610f\u529b\u5206\u652f\u53bb\u5173\u6ce8\u7269\u4f53\u4e0d\u540c\u90e8\u4f4d</p> <pre><code># \u591a\u6837\u6027\u635f\u5931\nclass DivLoss(nn.Module):\n    def __init__(self):\n        super(DivLoss, self).__init__()\n        return\n\n    def forward(self, x):\n        '''\n        :param x: [b,h,w]\n        :return:\n        '''\n        # \u4f9d\u6b21\u63d0\u53d6\u56db\u4e2a\u5206\u652f\u7684\u5c40\u90e8\u6ce8\u610f\u529b\u56fe\uff0c\u5bf9\u5e94\u8bba\u6587Mi\n        x1 = x[0]\n        x2 = x[1]\n        x3 = x[2]\n        x4 = x[3]\n        # \u5bf9\u5e94\u8bba\u6587\u516c\u5f0f9\u4e2d\u7684\u8fb9\u7f18\u53c2\u6570mrg\n        mrg = 0.02\n        # \u5c06\u4e8c\u7ef4\u6570\u636e\u538b\u7f29\u4e3a\u4e00\u7ef4\u6570\u636e\uff0c\u4fbf\u4e8e\u9010\u5143\u7d20\u8fd0\u7b97\n        # \u8fd9\u91ccxi\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f9\u4e2d\u7684mi(x, y)\n        x1 = x1.view(x1.size(0), -1)\n        x2 = x2.view(x2.size(0), -1)\n        x3 = x3.view(x3.size(0), -1)\n        x4 = x4.view(x4.size(0), -1)\n        # \u5408\u5e76mk(x, y)\u6570\u636e\uff0c\u4fbf\u4e8e\u4e4b\u540e\u518d\u6bd4\u51fa\u6700\u5927\u503c\n        tmp1 = torch.stack((x2, x3, x4))\n        tmp2 = torch.stack((x1, x3, x4))\n        tmp3 = torch.stack((x1, x2, x4))\n        tmp4 = torch.stack((x1, x2, x3))\n        # \u6cbf\u5206\u652f\u65b9\u5411\u6bd4\u51fa\u6700\u5927\u503c\uff0c\u4e5f\u5c31\u662f\u9010\u70b9\u6bd4\u51fa\u4e09\u4e2a\u5206\u652f\u7684\u6700\u5927\u54cd\u5e94\n        t1, _ = torch.max(tmp1, dim=0)\n        t2, _ = torch.max(tmp2, dim=0)\n        t3, _ = torch.max(tmp3, dim=0)\n        t4, _ = torch.max(tmp4, dim=0)\n        # \u6700\u5927\u54cd\u5e94\u51cf\u53bb\u8fb9\u7f18\u53c2\u6570\uff0c\u63d0\u5347\u6a21\u578b\u9c81\u68d2\u6027\n        t1 = t1 - mrg\n        t2 = t2 - mrg\n        t3 = t3 - mrg\n        t4 = t4 - mrg\n        # \u9010\u5143\u7d20\u70b9\u4e58\u6c42\u548c\uff0c\u5f97\u5230\u8ddd\u79bb\u635f\u5931\uff0c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f9\n        loss = (torch.sum(x1 * t1) + torch.sum(x2 * t2) + torch.sum(x3 * t3) + torch.sum(x4 * t4)) / x1.size(0)\n        return loss\n</code></pre> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u7406\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u6307\u6b63\u3002</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u4e8e\uff1a2023\u5e741\u67087\u65e5</p>"},{"location":"fine-grained/code/MC-Loss2/","title":"\u7ec6\u7c92\u5ea6\uff1aMC-Loss","text":""},{"location":"fine-grained/code/MC-Loss2/#_1","title":"\u7efc\u8ff0","text":"<p>\u671f\u520a\u4e0e\u65f6\u95f4\uff1aIEEE Transactions on Image Processing 2020 (TIP 2020)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://arxiv.org/pdf/2002.04264</p> <p>\u6e90\u7801\u5730\u5740(PyTorch\u7248\u672c)\uff1ahttps://github.com/dongliangchang/Mutual-Channel-Loss</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u7c7b(FGVC)</p>"},{"location":"fine-grained/code/MC-Loss2/#_2","title":"\u7f51\u7edc\u7ed3\u6784","text":"<p>\u4ee5resnet\u4e3a\u4f8b</p> <pre><code>class model_bn(nn.Module):\n    def __init__(self, feature_size=512,classes_num=200):\n        super(model_bn, self).__init__() \n        # \u5b9a\u4e49\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\uff0c\u5220\u6389\u539fresnet\u4e2d\u7684\u5168\u5c40\u5e73\u5747\u6c60\u5316\u548c\u5168\u8fde\u63a5\u5c42\n        # \u6ce8\u610f\uff0c\u4f5c\u8005\u5c06\u6700\u540e\u4e00\u5c42\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u901a\u9053\u6570\u6539\u4e86\uff0c\u6539\u6210\u4e86\u5206\u7c7b\u6570*\u03be\uff0c\u4f5c\u8005\u6e90\u7801\u4e2d\u4ee5600\u4e3a\u4f8b(200*3)\n        # \u53ea\u6539\u53d8\u4e86layer4\u8f93\u51fa\u7279\u5f81\u56fe\u7684\u901a\u9053\u6570\uff0c\u5176\u4ed6\u90e8\u5206\u4e0e\u539f\u59cb\u7684resnet\u76f8\u540c\n        self.features = nn.Sequential(*list(net.children())[:-2]) \n        # \u5168\u5c40\u6700\u5927\u6c60\u5316\n        self.max = nn.MaxPool2d(kernel_size=14, stride=14)\n        # \u7279\u5f81\u56fe\u901a\u9053\u6570\u3002\u8fd9\u91cc\u505a\u4e86\u4fee\u6539\uff0c\u4e0e\u539f\u901a\u9053\u6570\u4e0d\u4e00\u6837\n        self.num_ftrs = 600*1*1\n        # \u5206\u7c7b\u5668\uff0c\u4f9d\u6b21\u4e3a\u6279\u91cf\u6807\u51c6\u5316\u3001\u7ebf\u6027\u56de\u5f52\u3001\u6279\u91cf\u6807\u51c6\u5316ELU\u6fc0\u6d3b\u51fd\u6570\u3001\u7ebf\u6027\u56de\u5f52\n        self.classifier = nn.Sequential(\n            nn.BatchNorm1d(self.num_ftrs),\n            #nn.Dropout(0.5),\n            nn.Linear(self.num_ftrs, feature_size),\n            nn.BatchNorm1d(feature_size),\n            nn.ELU(inplace=True),\n            #nn.Dropout(0.5),\n            nn.Linear(feature_size, classes_num),\n        )\n\n    def forward(self, x, targets):\n        # \u9996\u5148\u56fe\u7247\u7ecf\u8fc7\u7279\u5f81\u63d0\u53d6\uff0c\u5f97\u5230\u7279\u5f81\u56fe\n        x = self.features(x)\n        # \u4e4b\u540e\u7ecf\u8fc7MC_Loss\u6a21\u5757,\u5f97\u5230MC\u635f\u5931\n        if self.training:\n            MC_loss = supervisor(x, targets, height=14, cnum=3)\n        # \u7279\u5f81\u56fe\u4f9d\u6b21\u7ecf\u8fc7\u5168\u5c40\u6700\u5927\u6c60\u5316\uff0c\u5f97\u5230\u7279\u5f81\u5411\u91cf\n        x = self.max(x)\n        x = x.view(x.size(0), -1)\n        # \u518d\u7ecf\u8fc7\u5206\u7c7b\u5668\uff0c\u5f97\u5230\u7f51\u7edc\u7684\u9884\u6d4b\u503c\n        x = self.classifier(x)\n        # \u6c42\u4ea4\u53c9\u71b5\u635f\u5931\n        loss = criterion(x, targets)\n        # \u5982\u679c\u662f\u8bad\u7ec3\u9636\u6bb5\uff0c\u5219\u8fd4\u56de\u9884\u6d4b\u503c\u548c\u9884\u6d4b\u635f\u5931\u7684\u540c\u65f6\uff0c\u8fd8\u9700\u8981\u8fd4\u56deMC\u635f\u5931\n        if self.training:\n            return x, loss, MC_loss\n        # \u5982\u679c\u662f\u6d4b\u8bd5\u9636\u6bb5\uff0c\u5219\u53ea\u9700\u8981\u8fd4\u56de\u9884\u6d4b\u503c\u4e0e\u635f\u5931\n        else:\n            return x, loss\n</code></pre>"},{"location":"fine-grained/code/MC-Loss2/#mc-loss_1","title":"MC-Loss","text":"<pre><code>def supervisor(x, targets, height, cnum):\n    # \u9996\u5148\u5f97\u5230\u63a9\u6a21\u56fe\n    mask = Mask(x.size(0), cnum).cpu()\n    branch = x\n    # \u5c06\u7279\u5f81\u56fe\u6539\u53d8\u5f62\u72b6\uff0c\u53d8\u6210(batch,200*\u03be,h*w)\uff0c\u03be\u8868\u793a\u591a\u5c11\u7279\u5f81\u56fe\u4ee3\u8868\u4e00\u7c7b\uff0c\u4f5c\u8005\u4ee5\u03be=3\u4e3a\u4f8b\n    # \u7b2c\u4e8c\u7ef4\u5ea6(dim=2)\u8868\u793a\u7279\u5f81\u56fe\u4e2d\u7684\u7279\u5f81\u6570\u636e\n    branch = branch.reshape(branch.size(0),branch.size(1), branch.size(2) * branch.size(3))\n    # \u5c06\u7279\u5f81\u6570\u636e\u653e\u5165softmax\uff0c\u6cbf\u7b2c\u4e8c\u7ef4\u5ea6\u8fdb\u884c\u5f52\u4e00\u5316\u64cd\u4f5c(\u76f8\u5f53\u6cbf\u539f\u6765\u7279\u5f81\u56fe\u4e0a\u7684\u6570\u636e\u8fdb\u884c\u626b\u63cf)\uff0c\u5bf9\u5e94\u8bba\u6587\u4e2d\u516c\u5f0f(7)\u540e\u534a\u6bb5\n    branch = F.softmax(branch, 2)\n    # \u518d\u5c06\u7279\u5f81\u56fe\u53d8\u56de\u539f\u6765\u7684\u5f62\u72b6\n    branch = branch.reshape(branch.size(0), branch.size(1), x.size(2), x.size(2))\n    # \u5c06\u5f52\u4e00\u5316\u540e\u7684\u6570\u636e\u4f20\u5165CCMP\u6a21\u5757\uff0c\u5bf9\u5e94\u8bba\u6587\u4e2d\u516c\u5f0f(7)\u524d\u534a\u6bb5\n    branch = my_MaxPool2d(kernel_size=(1, cnum), stride=(1, cnum))(branch)\n    # \u7279\u5f81\u56fe\u7ecf\u8fc7CCMP\u4e4b\u540e\uff0c\u901a\u9053\u6570\u53d8\u4e3a\u5206\u7c7b\u6570\uff0c\u4e4b\u540e\u518d\u8f6c\u5316\u4e00\u4e0b\u5f62\u72b6\n    # \u8f6c\u5316\u4e3a(batch,200,w*h)\n    branch = branch.reshape(branch.size(0),branch.size(1), branch.size(2) * branch.size(3))\n    # \u4e4b\u540e\u9996\u5148\u5bf9branch\u4e2d\u7684\u5143\u7d20\u6309\u7b2c\u4e8c\u7ef4\u5ea6\u6c42\u548c\uff0c\u5373\u5bf9\u7279\u5f81\u6570\u636e\u6c42\u548c\n    # \u4e4b\u540e\u518d\u5bf9\u6240\u6709\u901a\u9053\u53d6\u5e73\u5747\u503c\uff0c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f(6)\n    loss_2 = 1.0 - 1.0 * torch.mean(torch.sum(branch, 2)) / cnum# set margin = 3.0\n    # CWA\u6a21\u5757:\u63a9\u6a21\u56feM\u4e0e\u7279\u5f81\u56fe\u76f8\u4e58\n    branch_1 = x * mask\n    # CCMP\u6a21\u5757\uff0c\u5c06\u6240\u6709\u7279\u5f81\u56fe\u53d6\u76f8\u5e94\u7c7b\u522b\u7684\u6700\u5927\u503c\uff0c(\u5bf9\u4e8e\u6bcf\u4e00\u7c7b\uff0c3\u5f20\u538b\u7f29\u62101\u5f20)\uff0c\u5f97\u5230\u7684\u7279\u5f81\u56fe\u5c3a\u5bf8\u4e3a(batch,200,h,w)\n    branch_1 = my_MaxPool2d(kernel_size=(1,cnum), stride=(1,cnum))(branch_1)\n    # \u5168\u5c40\u5e73\u5747\u5316\uff0c\u5f97\u5230\u6bcf\u4e00\u7c7b\u7684\u9884\u6d4b\u5206\u6570(h*w\u4e2a\u503c\u538b\u7f29\u62101\u4e2a\u6570)\uff0c\u6700\u7ec8\u5f97\u5230\u8bba\u6587\u4e2d\u516c\u5f0f(5)\u7684\u7ed3\u679c\n    branch_1 = nn.AvgPool2d(kernel_size=(height,height))(branch_1)\n    # \u538b\u6241\uff0c\u4fbf\u4e8e\u540e\u7eed\u53d6\u4ea4\u53c9\u71b5\u635f\u5931\n    branch_1 = branch_1.view(branch_1.size(0), -1)\n    # \u53d6\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u5bf9\u4e8e\u8bba\u6587\u4e2d\u516c\u5f0f(4)\n    loss_1 = criterion(branch_1, targets)\n    # \u8fd4\u56de\u635f\u5931\n    return [loss_1, loss_2]\n</code></pre> <p>\u8ba1\u7b97CWA\u6a21\u5757\u4e2d\u7684\u63a9\u6a21\u56feM\uff1a</p> <pre><code># \u5f97\u5230CWA\u6a21\u5757\u4e2d\u7684\u63a9\u6a21\u56feM\ndef Mask(nb_batch, channels):\n    # \u5047\u8bbe\u4e09\u5f20\u7279\u5f81\u56fe\u8868\u793a\u4e00\u4e2a\u7c7b\u522b\uff0c\u5373\u8bba\u6587\u4e2d\u7684\u53c2\u6570\u03be\u4e3a3\n    # \u6b64\u65f6\u4e00\u7ec4\u63a9\u6a21M_i\u4e2d\u7531\u4e24\u4e2a1,\u4e00\u4e2a0\u7ec4\u6210\n    foo = [1] * 2 + [0] *  1\n    # \u521d\u59cb\u5316\u603b\u7684M\u5217\u8868\n    bar = []\n    # \u8fd9\u91cc\u7684200\u8868\u793a\u5206\u7c7b\u6570\n    for i in range(200):\n        # \u6253\u4e71\u521d\u59cb\u5316\u540eM_i\u4e2d\u7684\u5143\u7d20\uff0c\u8868\u793a\u968f\u673a\u751f\u6210M_i\n        random.shuffle(foo)\n        # \u4e0e\u603b\u5217\u8868\u5408\u5e76\n        bar += foo\n    # \u6309\u6279\u6b21(batch)\u590d\u5236\n    bar = [bar for i in range(nb_batch)]\n    # \u8f6c\u6362\u6210array\u683c\u5f0f\n    bar = np.array(bar).astype(\"float32\")\n    # \u8f6c\u6362\u5f62\u72b6\uff0c\u8f6c\u6362\u6210(batch,200*\u03be,1,1)\uff0c\u524d\u4e24\u4e2a\u7ef4\u5ea6\u4e2d\uff0c\u63a9\u6a21\u548c\u7279\u5f81\u56fe\u5927\u5c0f\u76f8\u540c\uff0c\u4fbf\u4e8e\u540e\u7eed\u7684\u70b9\u4e58\u64cd\u4f5c\n    bar = bar.reshape(nb_batch, 200 * channels, 1, 1)\n    # \u8f6c\u6362\u6210tensor\u683c\u5f0f\uff0c\u4e4b\u540e\u653e\u5165\u663e\u5361\uff0c\u518d\u4ee4\u5176\u53ef\u6c42\u5bfc\n    bar = torch.from_numpy(bar)\n    bar = bar.cuda()\n    bar = Variable(bar)\n    # \u6700\u540e\u8fd4\u56de\u63a9\u6a21M\n    return bar\n</code></pre> <p>CCMP\u6a21\u5757\uff1a</p> <pre><code>class my_MaxPool2d(Module):\n\n    def __init__(self, kernel_size, stride=None, padding=0, dilation=1,\n                 return_indices=False, ceil_mode=False):\n        super(my_MaxPool2d, self).__init__()\n        # \u6700\u5927\u6c60\u5316\u7684\u4e00\u7cfb\u5217\u53c2\u6570\uff0c\u53ef\u4ee5\u5728\u5b9a\u4e49my_MaxPool2d\u7684\u540c\u65f6\u5f15\u5165\n        self.kernel_size = kernel_size\n        self.stride = stride or kernel_size\n        self.padding = padding\n        self.dilation = dilation\n        self.return_indices = return_indices\n        self.ceil_mode = ceil_mode\n\n    def forward(self, input):\n        # \u5c06\u8f93\u5165\u76841,3\u7ef4\u5ea6\u8fdb\u884c\u4ea4\u6362\uff0c\u5373\u5c06\u901a\u9053\u7ef4\u5ea6\u4e0e\u56fe\u7247\u7684\u5bbdw\u4ea4\u6362\uff0c\u5f97\u5230(batch,w,h,600)\u7684\u6570\u636e(\u4ee5CUB\u6570\u636e\u96c6\u4e3a\u4f8b)\n        input = input.transpose(3,1)\n        # \u6700\u5927\u6c60\u5316\uff0c\u6ce8\u610f\uff0c\u6b64\u65f6\u6c60\u5316\u6838\u4e3a(1, cnum)\n        # \u76f8\u5f53\u4e8e\u5728\u539f\u59cb\u7684\u4e09\u5f20\u7279\u5f81\u56fe\u4e2d\u6cbf\u901a\u9053\u9009\u62e9\u6700\u5927\u503c,\u5bf9\u5e94\u8bba\u6587\u4e2d\u516c\u5f0f(5)\u7684\u4e2d\u95f4\u90e8\u5206(CCMP)\n        input = F.max_pool2d(input, self.kernel_size, self.stride,\n                            self.padding, self.dilation, self.ceil_mode,\n                            self.return_indices)\n        # \u518d\u5c06\u7279\u5f81\u56fe\u7ef4\u5ea6\u53d8\u56de\u53bb\uff0c\u53d8\u6210\u6b63\u5e38\u7684\u5c3a\u5bf8\uff0c\u5373(1,200,h,w)\n        input = input.transpose(3,1).contiguous()\n        # \u6700\u540e\u8fd4\u56de\u7279\u5f81\u56fe\n        return input\n</code></pre> <p>\u6ce8\uff1a\u4ee5\u4e0a\u5185\u5bb9\u4ec5\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u89c2\u70b9\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u5927\u5bb6\u6279\u8bc4\u6307\u6b63\u3002</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e7412\u670830\u65e5</p>"},{"location":"fine-grained/code/NTS-Net2/","title":"\u7ec6\u7c92\u5ea6\uff1aNTS-Net","text":""},{"location":"fine-grained/code/NTS-Net2/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aEuropean Conference on Computer Vision 2018 (ECCV, 2018)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content_ECCV_2018/papers/Ze_Yang_Learning_to_Navigate_ECCV_2018_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740(PyTorch\u7248\u672c)\uff1ahttps://github.com/yangze0930/NTS-Net</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u7c7b(FGVC) </p>"},{"location":"fine-grained/code/NTS-Net2/#nts-net_1","title":"NTS-Net\u7f51\u7edc\u6574\u4f53\u7ed3\u6784","text":""},{"location":"fine-grained/code/NTS-Net2/#_2","title":"\u7f51\u7edc\u521d\u59cb\u5316\u9636\u6bb5","text":"<pre><code>def __init__(self,num_classes, topN=4):\n    super(attention_net, self).__init__()\n    # \u5b9a\u4e49\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\uff0c\u6240\u6709\u7684\u7279\u5f81\u63d0\u53d6\u64cd\u4f5c\u5747\u7531\u540c\u4e00\u7f51\u7edc\u5b8c\u6210\n    self.pretrained_model = resnet.resnet50(pretrained=True)\n    self.pretrained_model.avgpool = nn.AdaptiveAvgPool2d(1)\n    # pretrained_model\u4e2d\u7684\u5168\u8fde\u63a5\u5c42\uff0c\u7528\u4e8e\u9884\u6d4b\u539f\u59cb\u56fe\u50cf\u7684\u6982\u7387\n    self.pretrained_model.fc = nn.Linear(512 * 4, num_classes)\n    # Navigator\u4e2d\u7684\u533a\u57df\u5efa\u8bae\u6a21\u5757\uff0c\u5f97\u5230\u7a97\u53e3\u4fe1\u606f\u91cf\n    self.proposal_net = ProposalNet()\n    # topN\u5bf9\u5e94\u4e8e\u8bba\u6587\u4e2d\u7684\u53c2\u6570M\uff0c\u5373\u6700\u7ec8\u9009\u53d6\u524dtopN\u4e2a\u7a97\u53e3\u90e8\u4ef6\u7528\u4e8e\u8bc4\u4ef7\u53cd\u9988\n    self.topN = topN\n    # Scrutinizer\u6a21\u5757\u7684\u5168\u8fde\u63a5\u5c42\uff0c\u7528\u4e8e\u6700\u7ec8\u7684\u7c7b\u522b\u9884\u6d4b\n    # CAT_NUM\u4ee3\u8868\u7528\u4e8e\u9884\u6d4b\u6700\u7ec8\u7c7b\u522b\u7684\u533a\u57df\u6570\u91cf\uff0c\u5bf9\u5e94\u8bba\u6587\u4e2d\u7684\u53c2\u6570K\n    self.concat_net = nn.Linear(2048 * (CAT_NUM + 1), num_classes)\n    # Teacher\u6a21\u5757\u7684\u5168\u8fde\u63a5\u5c42\uff0c\u7528\u4e8e\u8bc4\u4ef7\u7f6e\u4fe1\u5ea6\n    self.partcls_net = nn.Linear(512 * 4, num_classes)\n    # \u751f\u6210\u951a\u70b9\u56fe\n    _, edge_anchors, _ = generate_default_anchor_maps()\n    self.pad_side = 224\n    self.edge_anchors = (edge_anchors + 224).astype(np.int)\n</code></pre>"},{"location":"fine-grained/code/NTS-Net2/#_3","title":"\u524d\u5411\u4f20\u64ad","text":"<pre><code>def forward(self, x):\n    resnet_out, rpn_feature, feature = self.pretrained_model(x)\n    # \u7531\u4e8e\u951a\u70b9\u7684\u5c3a\u5bf8\u4e0d\u540c\uff0c\u6240\u4ee5\u53ef\u80fd\u4f1a\u8d85\u51fa\u8fb9\u754c\u533a\u57df\uff0c\u56e0\u6b64\u9700\u8981\u586b\u5145\n    x_pad = F.pad(x, (self.pad_side, self.pad_side, self.pad_side, self.pad_side), mode='constant', value=0)\n    batch = x.size(0)\n    # we will reshape rpn to shape: batch * nb_anchor\n    # \u8fd4\u56deb*1614,\u5373\u7a97\u53e3\u4fe1\u606f\u91cf\n    rpn_score = self.proposal_net(rpn_feature.detach())\n    # \u5c06\u7a97\u53e3\u4fe1\u606f\u91cf\u4e0e\u7a97\u53e3\u5750\u6807\u76f8\u7ec4\u5408\u5f97\u5230\u957f\u5ea6\u4e3abatch\u7684\u5217\u8868\uff0c\u5217\u8868\u4e2d\u5747\u4e3a1614*6\u7684\u6570\u7ec4\n    # \u7b2c1\u4e2a\u6570\u4ee3\u8868\u4fe1\u606f\u91cf\uff0c\u7b2c2-5\u4e2a\u6570\u4ee3\u8868\u7a97\u53e3\u5750\u6807\uff0c\u7b2c6\u4e2a\u6570\u4ee3\u8868\u7a97\u53e3\u7f16\u53f7\n    all_cdds = [\n        np.concatenate((x.reshape(-1, 1), self.edge_anchors.copy(), np.arange(0, len(x)).reshape(-1, 1)), axis=1)\n        for x in rpn_score.data.cpu().numpy()]\n    # \u7ecf\u8fc7nms\uff0c\u4fe1\u606f\u91cf\u5927\uff0c\u5e76\u4e14\u7a97\u53e3\u533a\u57df\u5197\u4f59\u5ea6\u5c0f\u7684\u51e0\u4e2a\u7a97\u53e3\n    # top_n_cdds\u50a8\u5b58\u4e86\u6bcf\u4e2a\u7a97\u53e3\u7684\u54cd\u5e94\u503c\u548c\u4e24\u70b9\u5750\u6807\uff0c\u4ee5\u53ca\u7f16\u53f7\n    top_n_cdds = [hard_nms(x, topn=self.topN, iou_thresh=0.25) for x in all_cdds]\n    top_n_cdds = np.array(top_n_cdds)\n    # \u83b7\u53d6\u7a97\u53e3\u7f16\u53f7\n    top_n_index = top_n_cdds[:, :, -1].astype(np.int64)\n    top_n_index = torch.from_numpy(top_n_index).cuda()\n    # \u83b7\u53d6\u54cd\u5e94\u503c\n    top_n_prob = torch.gather(rpn_score, dim=1, index=top_n_index)\n    part_imgs = torch.zeros([batch, self.topN, 3, 224, 224]).cuda()\n    # \u5f97\u5230\u7a97\u53e3\u56fe\uff0c\u5148\u88c1\u526a\u51fa\u6765\uff0c\u7136\u540e\u8fdb\u884c\u4e0a\u91c7\u6837\u653e\u5927\uff0c\u5c3a\u5bf8\u653e\u5927\u5230224*224\n    for i in range(batch):\n        for j in range(self.topN):\n            [y0, x0, y1, x1] = top_n_cdds[i][j, 1:5].astype(np.int)\n            part_imgs[i:i + 1, j] = F.interpolate(x_pad[i:i + 1, :, y0:y1, x0:x1], size=(224, 224), mode='bilinear',\n                                                  align_corners=True)\n    # \u90e8\u4ef6\u56fe\u6570\u4e0ebatch\u878d\u5408\uff0c\u4fbf\u4e8e\u63a5\u4e0b\u6765\u653e\u5165\u7f51\u7edc\u4e2d\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\n    part_imgs = part_imgs.view(batch * self.topN, 3, 224, 224)\n    # \u5bf9\u7a97\u53e3\u56fe\u63d0\u53d6\u7279\u5f81\n    _, _, part_features = self.pretrained_model(part_imgs.detach())\n    # \u63d0\u53d6\u5b8c\u7279\u5f81\u518d\u62c6\u5f00\n    part_feature = part_features.view(batch, self.topN, -1)\n    # \u83b7\u53d6\u524d\u51e0\u5f20\u90e8\u4ef6\u56fe\uff0c\u5e76\u4e14\u5c06\u5176\u8f6c\u5316\u6210\u8fde\u7eed\u7684\n    part_feature = part_feature[:, :CAT_NUM, ...].contiguous()\n    part_feature = part_feature.view(batch, -1)\n    # concat_logits have the shape: B*200\n    # \u5c06\u6240\u6709\u7684\u7279\u5f81\u56fe\u878d\u5408\uff0c\u8fdb\u4e00\u6b65\u7528\u4e8e\u6700\u7ec8\u7684\u5206\u7c7b\u9884\u6d4b\uff0c\u5bf9\u5e94\u4e8e\u8bba\u6587\u4e2d\u7684Scrutinizer\u6a21\u5757\n    concat_out = torch.cat([part_feature, feature], dim=1)\n    # Scrutinizer\u6a21\u5757\u7684\u5206\u7c7b\u9884\u6d4b\n    concat_logits = self.concat_net(concat_out)\n    # \u539f\u59cb\u56fe\u50cf\u7684\u9884\u6d4b\u503c\uff0c\u7528\u4e8e\u4f18\u5316Teacher\u6a21\u5757\uff0c\u4ee5\u53ca\u5bf9Navigation\u505a\u53cd\u9988\n    raw_logits = resnet_out\n    # part_logits have the shape: B*N*200\n    # \u90e8\u4ef6\u56fe\u5206\u522b\u505a\u9884\u6d4b\uff0c\u7528\u4e8eTeacher\u6a21\u5757\u7684\u6253\u5206\n    part_logits = self.partcls_net(part_features).view(batch, self.topN, -1)\n    # \u5206\u522b\u8fd4\u56de\uff0c\u539f\u59cb\u56fe\u50cf\u9884\u6d4b\u6982\u7387\u3001\u7279\u5f81\u56fe\u878d\u5408\u540e\u7684\u9884\u6d4b\u6982\u7387(Scrutinizer)\u3001\u6bcf\u5f20\u90e8\u4ef6\u56fe\u7684\u9884\u6d4b\u6982\u7387(Teacher)\u3001\u7a97\u53e3\u7f16\u53f7\u3001\u7a97\u53e3\u4fe1\u606f\u91cf(Navigate)\n    return [raw_logits, concat_logits, part_logits, top_n_index, top_n_prob]\n</code></pre>"},{"location":"fine-grained/code/NTS-Net2/#_4","title":"\u533a\u57df\u5efa\u8bae\u6a21\u5757","text":"<pre><code>class ProposalNet(nn.Module):\n    # Navigator\u4e2d\u7684\u533a\u57df\u5efa\u8bae\u6a21\u5757,\u5229\u7528\u4e86\u76ee\u6807\u68c0\u6d4b\u6a21\u5757\u4e2d\u7684\u951a\u70b9\u601d\u60f3\n    def __init__(self):\n        super(ProposalNet, self).__init__()\n        # \u5b9a\u4e49\u4e09\u79cd\u6ed1\u52a8\u7a97\u53e3\uff0c\u5bf9\u5e94\u8bba\u6587\u4e2d\u768414*14,7*7,4*4\u4e09\u4e2a\u5c3a\u5ea6\n        self.down1 = nn.Conv2d(2048, 128, 3, 1, 1)\n        self.down2 = nn.Conv2d(128, 128, 3, 2, 1)\n        self.down3 = nn.Conv2d(128, 128, 3, 2, 1)\n        self.ReLU = nn.ReLU()\n        # \u4e09\u4e2a\u5c3a\u5ea6\u5206\u522b\u4ea7\u751f6\u30016\u30019\u5f20\u56fe\uff0c\u7528\u4e8e\u68c0\u6d4b\u7a97\u53e3\u533a\u57df\n        self.tidy1 = nn.Conv2d(128, 6, 1, 1, 0)\n        self.tidy2 = nn.Conv2d(128, 6, 1, 1, 0)\n        self.tidy3 = nn.Conv2d(128, 9, 1, 1, 0)\n\n    def forward(self, x):\n        # \u4ee5\u6700\u521d\u8f93\u5165448*448\u4e3a\u4f8b\n        batch_size = x.size(0)\n        # d1:b*128*14*14\n        d1 = self.ReLU(self.down1(x))\n        # d2:b*128*7*7\n        d2 = self.ReLU(self.down2(d1))\n        # d3:b*128*4*4\n        d3 = self.ReLU(self.down3(d2))\n        # t1:b*1176\n        t1 = self.tidy1(d1).view(batch_size, -1)\n        # t2:b*294\n        t2 = self.tidy2(d2).view(batch_size, -1)\n        # t1:b*144\n        t3 = self.tidy3(d3).view(batch_size, -1)\n        # \u8fd4\u56deb*1614\n        return torch.cat((t1, t2, t3), dim=1)\n</code></pre>"},{"location":"fine-grained/code/NTS-Net2/#_5","title":"\u751f\u6210\u951a\u70b9\u56fe","text":"<pre><code>_default_anchors_setting = (\n    dict(layer='p3', stride=32, size=48, scale=[2 ** (1. / 3.), 2 ** (2. / 3.)], aspect_ratio=[0.667, 1, 1.5]),\n    dict(layer='p4', stride=64, size=96, scale=[2 ** (1. / 3.), 2 ** (2. / 3.)], aspect_ratio=[0.667, 1, 1.5]),\n    dict(layer='p5', stride=128, size=192, scale=[1, 2 ** (1. / 3.), 2 ** (2. / 3.)], aspect_ratio=[0.667, 1, 1.5]),\n)\n\n\ndef generate_default_anchor_maps(anchors_setting=None, input_shape=INPUT_SIZE):\n    \"\"\"\n    generate default anchor\n\n    :param anchors_setting: all informations of anchors\n    :param input_shape: shape of input images, e.g. (h, w)\n    :return: center_anchors: # anchors * 4 (oy, ox, h, w)\n             edge_anchors: # anchors * 4 (y0, x0, y1, x1)\n             anchor_area: # anchors * 1 (area)\n    \"\"\"\n    # anchors_setting\u5b58\u6709\u951a\u70b9\u7684\u5c5e\u6027\n    if anchors_setting is None:\n        anchors_setting = _default_anchors_setting\n    # \u951a\u70b9\u5750\u6807\u4e0e\u68c0\u6d4b\u6846\u5c3a\u5bf8\n    center_anchors = np.zeros((0, 4), dtype=np.float32)\n    # \u68c0\u6d4b\u6846\u5de6\u4e0a\u89d2\u548c\u53f3\u4e0b\u89d2\uff0c\u5373\u8fb9\u7f18\u4fe1\u606f\n    edge_anchors = np.zeros((0, 4), dtype=np.float32)\n    # \u68c0\u6d4b\u6846\u9762\u79ef\n    anchor_areas = np.zeros((0,), dtype=np.float32)\n    # \u5f97\u5230\u8f93\u5165\u5c3a\u5bf8\n    input_shape = np.array(input_shape, dtype=int)\n\n    for anchor_info in anchors_setting:\n        # stride\u4ee3\u8868\u6bcf\u4e2a\u951a\u70b9\u4e2d\u5fc3\u7684\u8ddd\u79bb\uff0c\u5373\u6b65\u957f\n        stride = anchor_info['stride']\n        # size\u4ee3\u8868\u653e\u5927\u5c3a\u5ea6\n        size = anchor_info['size']\n        scales = anchor_info['scale']\n        # aspect_ratios\u50a8\u5b58\u7684\u662f\u5f62\u72b6\u6bd4\u4f8b\uff0c\u5373\u9ad8\u4e0e\u5bbd\u4e4b\u6bd4\n        aspect_ratios = anchor_info['aspect_ratio']\n        # \u8f93\u51fa\u7279\u5f81\u56fe\u7684\u5c3a\u5bf8\n        output_map_shape = np.ceil(input_shape.astype(np.float32) / stride)\n        # \u8f6c\u6362\u4e3a\u6574\u578b\n        output_map_shape = output_map_shape.astype(np.int)\n        # \u52a0\u4e00\u4e2a\u7ef4\u5ea6\uff0c\u4ee3\u8868\u7a97\u53e3\u5750\u6807\n        output_shape = tuple(output_map_shape) + (4,)\n        # \u5c3a\u5ea6\u5355\u4f4d\u957f\u5ea6\u7684\u4e00\u534a\n        ostart = stride / 2.\n        # ox\u3001oy\u4ee3\u8868\u4e2d\u5fc3\u951a\u70b9\u7684\u6a2a\u7eb5\u5750\u6807\u70b9\n        oy = np.arange(ostart, ostart + stride * output_shape[0], stride)\n        oy = oy.reshape(output_shape[0], 1)\n        ox = np.arange(ostart, ostart + stride * output_shape[1], stride)\n        ox = ox.reshape(1, output_shape[1])\n        # center_anchor_map_template\u524d\u4e24\u4e2a\u6570\u951a\u4e2d\u5fc3\u70b9\u5750\u6807\uff0c\u540e\u4e24\u4e2a\u6570\u8868\u793a\u68c0\u6d4b\u6846\u7684\u957f\u5bbd\n        center_anchor_map_template = np.zeros(output_shape, dtype=np.float32)\n        center_anchor_map_template[:, :, 0] = oy\n        center_anchor_map_template[:, :, 1] = ox\n        for scale in scales:\n            for aspect_ratio in aspect_ratios:\n                # \u5206\u522b\u4ee3\u8868\u68c0\u6d4b\u7a97\u957f\u4e0e\u9ad8\n                center_anchor_map = center_anchor_map_template.copy()\n                center_anchor_map[:, :, 2] = size * scale / float(aspect_ratio) ** 0.5\n                center_anchor_map[:, :, 3] = size * scale * float(aspect_ratio) ** 0.5\n                # \u5f97\u5230\u68c0\u6d4b\u6846\u7684\u56db\u4e2a\u89d2\u4e0a\u7684\u5750\u6807\n                edge_anchor_map = np.concatenate((center_anchor_map[..., :2] - center_anchor_map[..., 2:4] / 2.,\n                                                  center_anchor_map[..., :2] + center_anchor_map[..., 2:4] / 2.),\n                                                 axis=-1)\n                # \u68c0\u6d4b\u6846\u9762\u79ef\n                anchor_area_map = center_anchor_map[..., 2] * center_anchor_map[..., 3]\n                # \u951a\u70b9\u4e2d\u5fc3\u5750\u6807\u4ee5\u53ca\u68c0\u6d4b\u6846\u957f\u5bbd\n                center_anchors = np.concatenate((center_anchors, center_anchor_map.reshape(-1, 4)))\n                # \u68c0\u6d4b\u6846\u4e24\u4e2a\u89d2\u5750\u6807\n                edge_anchors = np.concatenate((edge_anchors, edge_anchor_map.reshape(-1, 4)))\n                # \u68c0\u6d4b\u6846\u9762\u79ef\n                anchor_areas = np.concatenate((anchor_areas, anchor_area_map.reshape(-1)))\n\n    return center_anchors, edge_anchors, anchor_areas\n</code></pre>"},{"location":"fine-grained/code/NTS-Net2/#nms","title":"NMS","text":"<pre><code>def hard_nms(cdds, topn=10, iou_thresh=0.25):\n    # NMS\u8fd0\u7b97\uff0c\u9009\u53d6\u524d\u51e0\u4e2a\u91cd\u53e0\u533a\u57df\u5c0f\uff0c\u5e76\u4e14\u4fe1\u606f\u91cf\u591a\u7684\u7a97\u53e3\n    if not (type(cdds).__module__ == 'numpy' and len(cdds.shape) == 2 and cdds.shape[1] &gt;= 5):\n        raise TypeError('edge_box_map should be N * 5+ ndarray')\n\n    cdds = cdds.copy()\n    # \u4ee5\u4fe1\u606f\u91cf\u4e3a\u6807\u51c6\uff0c\u8fdb\u884c\u6392\u5e8f\uff0c\u5f97\u5230\u6392\u5e8f\u540e\u7684\u7d22\u5f15\uff0c\u5229\u7528\u8be5\u7d22\u5f15\u8fdb\u884c\u6392\u5e8f\n    indices = np.argsort(cdds[:, 0])\n    # \u6309\u5347\u5e8f\u7684\u6807\u51c6\u5bf9\u539f\u6570\u7ec4\u8fdb\u884c\u6392\u5e8f\n    cdds = cdds[indices]\n    cdd_results = []\n\n    res = cdds\n    # .any()\u5224\u65ad\u662f\u5426\u975e\u7a7a\n    while res.any():\n        # \u5f97\u5230\u5f53\u524d\u4fe1\u606f\u91cf\u6700\u5927\u7684\u7a97\u53e3\uff0c\u4f5c\u4e3a\u8f93\u51fa\u7a97\u53e3\uff0c\u6bcf\u8fed\u4ee3\u4e00\u6b21\uff0c\u9009\u53d6\u4e00\u4e2a\n        cdd = res[-1]\n        cdd_results.append(cdd)\n        if len(cdd_results) == topn:\n            return np.array(cdd_results)\n        # \u9664\u53bb\u88ab\u9009\u62e9\u7684\n        res = res[:-1]\n        # np.maximum\uff0c\u9010\u5143\u7d20\u6bd4\u8f83\u4e24\u4e2aarray\u7684\u5927\u5c0f\uff0c\u8fd4\u56de\u6700\u5927\u7684\u30021:3\u662f\u7a97\u53e3\u5de6\u4e0a\u89d2x,y\u5750\u6807\n        # \u6b64\u65f6\u6bd4\u8f83\u4e24\u4e2a\u7a97\u53e3\u5de6\u4e0a\u89d2\u7684x,y\u5750\u6807\u70b9\uff0c\u901a\u8fc7\u53d6\u6700\u5927\u503c\uff0c\u53ef\u5f97\u5230\u91cd\u53e0\u533a\u57df\u5de6\u4e0a\u89d2\u7684\u5750\u6807\u70b9\n        start_max = np.maximum(res[:, 1:3], cdd[1:3])\n        # np.minimum\u4e0emaximum\u7528\u6cd5\u7c7b\u4f3c\uff0c\u8fd4\u56de\u6700\u5c0f\u7684\u30023:5\u662f\u7a97\u53e3\u53f3\u4e0b\u89d2x,y\u5750\u6807\n        # \u8fd9\u91cc\u8868\u793a\u8fd4\u56de\u91cd\u53e0\u533a\u57df\u53f3\u4e0b\u89d2\u7684\u5750\u6807\u70b9\n        end_min = np.minimum(res[:, 3:5], cdd[3:5])\n        # \u8fd9\u4e24\u4e2a\u5730\u65b9\u4e0d\u7406\u89e3\u7684\u53ef\u4ee5\u81ea\u5df1\u753b\u4e00\u4e0b\u56fe\uff0c\u76f4\u89c2\u7684\u7406\u89e3\u4e00\u4e0b\n        # \u5f97\u5230\u91cd\u53e0\u533a\u57df\u7684\u957f\u5bbd\uff0c\u5982\u679c\u6ca1\u6709\u91cd\u53e0\uff0c\u5219\u503c\u4e3a\u8d1f\u6570\uff0c\u4e0b\u9762\u4f1a\u8fc7\u6ee4\u6389\n        lengths = end_min - start_max\n        # \u8ba1\u7b97\u91cd\u53e0\u533a\u57df\u7684\u9762\u79ef\n        intersec_map = lengths[:, 0] * lengths[:, 1]\n        # np.logical_or\u6216\u8fd0\u7b97\uff0c\u5982\u679c\u957f\u5bbd\u4efb\u610f\u957f\u5ea6\u5c0f\u4e8e\u96f6\uff0c\u4ee3\u8868\u65e0\u91cd\u53e0\uff0c\u91cd\u53e0\u9762\u79ef\u8bbe\u7f6e\u4e3a0\u5373\u53ef\n        intersec_map[np.logical_or(lengths[:, 0] &lt; 0, lengths[:, 1] &lt; 0)] = 0\n        # \u8ba1\u7b97\u91cd\u53e0\u533a\u57df\u9762\u79ef\u4e0e\u672a\u91cd\u53e0\u533a\u57df\u9762\u79ef\u7684\u6bd4\u503c\n        iou_map_cur = intersec_map / ((res[:, 3] - res[:, 1]) * (res[:, 4] - res[:, 2]) + (cdd[3] - cdd[1]) * (\n            cdd[4] - cdd[2]) - intersec_map)\n        # \u5728\u5269\u4e0b\u7684\u7a97\u53e3\u4e2d\u7b5b\u9009\uff0c\u5982\u679c\u91cd\u53e0\u533a\u57df\u9762\u79ef\u6bd4\u503c\u5c0f\u4e8e\u8bbe\u5b9a\u7684\u9608\u503c\uff0c\u5c31\u9009\u53d6\uff0c\u5426\u5219\u820d\u5f03\n        res = res[iou_map_cur &lt; iou_thresh]\n\n    return np.array(cdd_results)\n</code></pre>"},{"location":"fine-grained/code/NTS-Net2/#_6","title":"\u635f\u5931\u51fd\u6570","text":""},{"location":"fine-grained/code/NTS-Net2/#_7","title":"\u4fe1\u606f\u91cf\u4e0e\u7f6e\u4fe1\u5ea6\u6392\u5e8f\u635f\u5931","text":"<p>\u9996\u5148\u5f97\u5230\u6807\u7b7e\u7c7b\u522b\u7684\u9884\u6d4b\u6982\u7387</p> <pre><code>def list_loss(logits, targets):\n    # \u9996\u5148\u5c06\u9884\u6d4b\u7ed3\u679c\u7ecf\u8fc7\u4e00\u4e2alog_softmax\n    temp = F.log_softmax(logits, -1)\n    # \u5f97\u5230\u6807\u7b7e\u7c7b\u522b\u7684\u9884\u6d4b\u6982\u7387\n    loss = [-temp[i][targets[i].item()] for i in range(logits.size(0))]\n    return torch.stack(loss)\n</code></pre> <p>\u7136\u540e\u8ba1\u7b97\u6392\u5e8f\u635f\u5931\uff0c\u5373\uff1a $$ L_I(I,C)=\\sum_{(i,s):C_i&lt;C_s}f(I_s-I_i)\\\\ \u5176\u4e2d\uff0cC\u662f\u7a97\u53e3\u7f6e\u4fe1\u5ea6\uff0cI\u662f\u7a97\u53e3\u4fe1\u606f\u91cf $$ </p> <pre><code>def ranking_loss(score, targets, proposal_num=PROPOSAL_NUM):\n    # score\u662f\u4fe1\u606f\u91cf\uff0ctargets\u662f\u6807\u7b7e\u7c7b\u522b\u7684\u9884\u6d4b\u6982\u7387\uff0cPROPOSAL_NUM\u662f\u7a97\u53e3\u5b66\u4e60\u91cf(\u5373\u5b66\u4e60\u591a\u5c11\u4e2a\u7a97\u53e3)\n    # \u5148\u5b9a\u4e49\u4e00\u4e2a\u635f\u5931\u53d8\u91cf\uff0c\u5229\u7528Variable\u8ba9\u5176\u53ef\u53c2\u4e0e\u53cd\u5411\u4f20\u64ad\n    loss = Variable(torch.zeros(1).cuda())\n    batch_size = score.size(0)\n    for i in range(proposal_num):\n        # \u8ba9\u5f53\u524d\u7a97\u53e3\u7684\u7f6e\u4fe1\u5ea6\u4e0e\u5176\u4ed6\u7a97\u53e3\u7f6e\u4fe1\u5ea6\u505a\u6bd4\u8f83\n        # \u4e0b\u9762\u88ab\u6ce8\u91ca\u7684\u90a3\u884c\u4f5c\u8005\u53ef\u80fd\u5199\u9519\u4e86\uff0c\u548c\u8bba\u6587\u91cc\u4e0d\u5bf9\u5e94\uff0c\u5e94\u8be5\u662ftargets &lt; targets[:, i]\n        # targets_p = (targets &gt; targets[:, i].unsqueeze(1)).type(torch.cuda.FloatTensor)\n        # \u5c06\u6bd4\u5f53\u524d\u7a97\u53e3\u7f6e\u4fe1\u5ea6\u5c0f\u7684\u7a97\u53e3\u9009\u51fa\u6765\n        targets_p = (targets &lt; targets[:, i].unsqueeze(1)).type(torch.cuda.FloatTensor)\n        # \u5f97\u5230\u5f53\u524d\u7a97\u53e3\u7684\u4fe1\u606f\u91cf\n        pivot = score[:, i].unsqueeze(1)\n        # \u4e0b\u4e24\u53e5\u5bf9\u5e94\u516c\u5f0f\u4e2d\u7684max{1-x,0}\uff0c\u8fd9\u91cc\u7684x\u662fIs-Ii\uff0c\u5373pivot - score\uff0c\u5f53\u524d\u7a97\u53e3\u4fe1\u606f\u4f9d\u6b21\u51cf\u53bb\u6240\u6709\u7a97\u53e3\u7684\u4fe1\u606f\uff0c\u5f97\u5230\u5dee\u503c\u3002\n        # \u7136\u540e\u518d\u6839\u636e\u524d\u9762\u5f97\u5230\u7684\u7a97\u53e3\u6807\u7b7e\uff0c\u5bf9\u7ed3\u679c\u505a\u4e00\u4e2a\u7b5b\u9009\n        loss_p = (1 - pivot + score) * targets_p\n        # \u6c42\u548c\u5f97\u5230\u6700\u7ec8\u7684\u635f\u5931\n        loss_p = torch.sum(F.relu(loss_p))\n        loss += loss_p\n    return loss / batch_size\n</code></pre>"},{"location":"fine-grained/code/NTS-Net2/#_8","title":"\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570","text":"<p>\u53ef\u76f4\u63a5\u4ecetorch\u8c03\u53d6</p> <pre><code>torch.nn.CrossEntropyLoss()\n</code></pre>"},{"location":"fine-grained/code/NTS-Net2/#_9","title":"\u6570\u636e\u96c6\u7684\u52a0\u8f7d","text":""},{"location":"fine-grained/code/NTS-Net2/#_10","title":"\u521d\u59cb\u5316\u9636\u6bb5","text":"<pre><code>class CUB():\n    def __init__(self, root, is_train=True, data_len=None):\n        self.root = root\n        self.is_train = is_train\n        # \u9996\u5148\u52a0\u8f7d\u5b58\u6709\u6570\u636e\u4fe1\u606f\u7684txt\u6587\u4ef6\n        img_txt_file = open(os.path.join(self.root, 'images.txt'))\n        label_txt_file = open(os.path.join(self.root, 'image_class_labels.txt'))\n        train_val_file = open(os.path.join(self.root, 'train_test_split.txt'))\n        # \u52a0\u8f7dtxt\u4e2d\u7684\u4fe1\u606f\uff0c\u50a8\u5b58\u6210\u5217\u8868\uff0c\u4fbf\u4e8e\u540e\u7eed\u7684\u8c03\u7528\n        # \u52a0\u8f7d\u56fe\u7247\u540d\u79f0\n        img_name_list = []\n        for line in img_txt_file:\n            img_name_list.append(line[:-1].split(' ')[-1])\n        # \u52a0\u8f7d\u6807\u7b7e\u5217\u8868\n        label_list = []\n        for line in label_txt_file:\n            label_list.append(int(line[:-1].split(' ')[-1]) - 1)\n        # \u52a0\u8f7d\u8bad\u7ec3\u96c6\u4e0e\u6d4b\u8bd5\u96c6\u7684\u5212\u5206\n        train_test_list = []\n        for line in train_val_file:\n            train_test_list.append(int(line[:-1].split(' ')[-1]))\n        # \u5212\u5206\u8bad\u7ec3\u96c6\u4e0e\u9a8c\u8bc1\u96c6\n        train_file_list = [x for i, x in zip(train_test_list, img_name_list) if i]\n        test_file_list = [x for i, x in zip(train_test_list, img_name_list) if not i]\n        if self.is_train:\n            self.train_img = [scipy.misc.imread(os.path.join(self.root, 'images', train_file)) for train_file in\n                              train_file_list[:data_len]]\n            self.train_label = [x for i, x in zip(train_test_list, label_list) if i][:data_len]\n        if not self.is_train:\n            self.test_img = [scipy.misc.imread(os.path.join(self.root, 'images', test_file)) for test_file in\n                             test_file_list[:data_len]]\n            self.test_label = [x for i, x in zip(train_test_list, label_list) if not i][:data_len]\n</code></pre>"},{"location":"fine-grained/code/NTS-Net2/#_11","title":"\u8fed\u4ee3\u8bfb\u53d6\u8fc7\u7a0b","text":"<pre><code>def __getitem__(self, index):\n    # \u6839\u636e\u8bad\u7ec3\u3001\u6d4b\u8bd5\u8fc7\u7a0b\u5b9a\u4e49\u6570\u636e\u7684\u9884\u8bad\u7ec3\u8fc7\u7a0b\n    # \u8bad\u7ec3\u8fc7\u7a0b\n    if self.is_train:\n        # \u9996\u5148\u8bfb\u53d6\u56fe\u7247\n        img, target = self.train_img[index], self.train_label[index]\n        if len(img.shape) == 2:\n            img = np.stack([img] * 3, 2)\n        # \u5229\u7528tranforms\u5bf9\u56fe\u7247\u505a\u9884\u5904\u7406\n        img = Image.fromarray(img, mode='RGB')\n        img = transforms.Resize((600, 600), Image.BILINEAR)(img)\n        img = transforms.RandomCrop(INPUT_SIZE)(img)\n        img = transforms.RandomHorizontalFlip()(img)\n        img = transforms.ToTensor()(img)\n        img = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])(img)\n    # \u6d4b\u8bd5\u8fc7\u7a0b\n    else:\n        # \u4e0e\u8bad\u7ec3\u8fc7\u7a0b\u7c7b\u4f3c\uff0c\u5148\u8bfb\u56fe\u7247\uff0c\u518d\u9884\u5904\u7406\n        img, target = self.test_img[index], self.test_label[index]\n        if len(img.shape) == 2:\n            img = np.stack([img] * 3, 2)\n        img = Image.fromarray(img, mode='RGB')\n        img = transforms.Resize((600, 600), Image.BILINEAR)(img)\n        img = transforms.CenterCrop(INPUT_SIZE)(img)\n        img = transforms.ToTensor()(img)\n        img = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])(img)\n    # \u8fd4\u56de\u9884\u5904\u7406\u540e\u7684\u56fe\u7247\u548c\u6807\u7b7e\n    return img, target\n\n\ndef __len__(self):\n    if self.is_train:\n        return len(self.train_label)\n    else:\n        return len(self.test_label)\n</code></pre>"},{"location":"fine-grained/code/NTS-Net2/#_12","title":"\u8bad\u7ec3\u6d41\u7a0b","text":""},{"location":"fine-grained/code/NTS-Net2/#_13","title":"\u8bad\u7ec3\u521d\u59cb\u5316\u9636\u6bb5","text":"<pre><code># \u4f7f\u7528\u591a\u5757\u663e\u5361\u8fdb\u884c\u8bad\u7ec3\n# \u5982\u679c\u53ef\u7528\u7684\u663e\u5361\u6570\u5c11\u4e8e\u56db\u5757\u7684\u8bdd\uff0c\u9700\u8981\u4fee\u6539\u8fd9\u91cc\u7684\u53c2\u6570\nos.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3'\nstart_epoch = 1\n# \u6a21\u578b\u4fdd\u5b58\u7684\u5730\u5740\nsave_dir = os.path.join(save_dir, datetime.now().strftime('%Y%m%d_%H%M%S'))\nif os.path.exists(save_dir):\n    raise NameError('model dir exists!')\nos.makedirs(save_dir)\n# \u5b9a\u4e49\u65e5\u5fd7\u7684\u52a0\u8f7d\nlogging = init_log(save_dir)\n_print = logging.info\n\n# \u52a0\u8f7d\u6570\u636e\u96c6\ntrainset = dataset.CUB(root='./CUB_200_2011', is_train=True, data_len=None)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n                                          shuffle=True, num_workers=8, drop_last=False)\ntestset = dataset.CUB(root='./CUB_200_2011', is_train=False, data_len=None)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n                                         shuffle=False, num_workers=8, drop_last=False)\n# \u5b9a\u4e49\u6a21\u578b\nnet = model.attention_net(topN=PROPOSAL_NUM,num_classes=200)\n# \u662f\u5426\u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b\nif resume:\n    ckpt = torch.load(resume)\n    net.load_state_dict(ckpt['net_state_dict'])\n    start_epoch = ckpt['epoch'] + 1\n# \u5b9a\u4e49\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\ncreterion = torch.nn.CrossEntropyLoss()\n\n# define optimizers\n# \u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u7684\u53c2\u6570\nraw_parameters = list(net.pretrained_model.parameters())\n# Navigation\u6a21\u5757\u4e2d\u9884\u6d4b\u7a97\u53e3\u4fe1\u606f\u91cf\u7684\u53c2\u6570\uff0c\u5373\u6ed1\u52a8\u7a97\u53e3\u53c2\u6570\npart_parameters = list(net.proposal_net.parameters())\n# Scrutinizer\u6a21\u5757\u4e2d\u6700\u7ec8\u5206\u7c7b\u9884\u6d4b\u7684\u53c2\u6570\nconcat_parameters = list(net.concat_net.parameters())\n# Teacher\u4e2d\u7684\u7a97\u53e3\u8bc4\u4ef7\u53c2\u6570\npartcls_parameters = list(net.partcls_net.parameters())\n# \u4e0a\u8ff0\u53c2\u6570\u5177\u6709\u4e0d\u540c\u7684\u529f\u80fd\uff0c\u7531\u4e0d\u540c\u7684\u635f\u5931\u51fd\u6570\u8fdb\u884c\u4f18\u5316\n# \u6307\u5b9a\u4e0d\u56db\u79cd\u4f18\u5316\u5668\u7528\u4e8e\u4f18\u5316\u4e0a\u8ff0\u53c2\u6570\nraw_optimizer = torch.optim.SGD(raw_parameters, lr=LR, momentum=0.9, weight_decay=WD)\nconcat_optimizer = torch.optim.SGD(concat_parameters, lr=LR, momentum=0.9, weight_decay=WD)\npart_optimizer = torch.optim.SGD(part_parameters, lr=LR, momentum=0.9, weight_decay=WD)\npartcls_optimizer = torch.optim.SGD(partcls_parameters, lr=LR, momentum=0.9, weight_decay=WD)\n# \u5b66\u4e60\u7387\u7684\u4e0b\u964d\u7b56\u7565\u8fed\u4ee3\u523060\u548c100\u6b21\u7684\u65f6\u5019\uff0c\u5b66\u4e60\u7387\u53d8\u4e3a\u539f\u6765\u76840.1\u500d\nschedulers = [MultiStepLR(raw_optimizer, milestones=[60, 100], gamma=0.1),\n              MultiStepLR(concat_optimizer, milestones=[60, 100], gamma=0.1),\n              MultiStepLR(part_optimizer, milestones=[60, 100], gamma=0.1),\n              MultiStepLR(partcls_optimizer, milestones=[60, 100], gamma=0.1)]\n# \u7f51\u7edc\u653e\u5165cuda\u4e2d\uff0c\u5e76\u6307\u5b9a\u5e76\u884c\u8bad\u7ec3\nnet = net.cuda()\n# \u5e76\u884c\u8bad\u7ec3\uff0c\u5982\u679c\u53ea\u6709\u4e00\u5757\u663e\u5361\uff0c\u9700\u8981\u6ce8\u91ca\u6389\u8fd9\u4e00\u884c\nnet = DataParallel(net)\n</code></pre>"},{"location":"fine-grained/code/NTS-Net2/#_14","title":"\u8bad\u7ec3\u8fc7\u7a0b","text":"<pre><code>for epoch in range(start_epoch, 500):\n    for scheduler in schedulers:\n        scheduler.step()\n\n    # begin training\n    _print('--' * 50)\n    net.train()\n    for i, data in enumerate(trainloader):\n        # \u8bfb\u53d6\u6570\u636e\u96c6\n        img, label = data[0].cuda(), data[1].cuda()\n        batch_size = img.size(0)\n        # \u68af\u5ea6\u5f52\u96f6\n        raw_optimizer.zero_grad()\n        part_optimizer.zero_grad()\n        concat_optimizer.zero_grad()\n        partcls_optimizer.zero_grad()\n\n        # \u5206\u522b\u8fd4\u56de\uff0c\u539f\u59cb\u56fe\u50cf\u9884\u6d4b\u6982\u7387\u3001\u7279\u5f81\u56fe\u878d\u5408\u540e\u7684\u9884\u6d4b\u6982\u7387(Scrutinizer)\u3001\u6bcf\u5f20\u90e8\u4ef6\u56fe\u7684\u9884\u6d4b\u6982\u7387(Teacher)\u3001\u7a97\u53e3\u7f16\u53f7\u3001\u7a97\u53e3\u4fe1\u606f\u91cf(Navigate)\n        raw_logits, concat_logits, part_logits, _, top_n_prob = net(img)\n        # \u5f97\u5230\u533a\u57df\u7f6e\u4fe1\u5ea6\uff0c\u5373\u6807\u7b7e\u7c7b\u522b\u7684\u9884\u6d4b\u6982\u7387\n        part_loss = model.list_loss(part_logits.view(batch_size * PROPOSAL_NUM, -1),\n                                    label.unsqueeze(1).repeat(1, PROPOSAL_NUM).view(-1)).view(batch_size, PROPOSAL_NUM)\n        # \u539f\u59cb\u56fe\u50cf\u5206\u7c7b\u635f\u5931\uff0c\u7528\u4e8e\u4f18\u5316Teacher\uff0c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f(7)\n        raw_loss = creterion(raw_logits, label)\n        # \u533a\u57df\u7279\u5f81\u56fe\u878d\u5408\u540e\u7684\u635f\u5931\uff0c\u7528\u4e8e\u4f18\u5316Scrutinizer\uff0c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f(8)\n        concat_loss = creterion(concat_logits, label)\n        # \u533a\u57df\u4fe1\u606f\u91cf\u4e0e\u533a\u57df\u7f6e\u4fe1\u5ea6\u7684\u6392\u5e8f\u635f\u5931\uff0c\u7528\u4e8e\u4f18\u5316Navigate\uff0c\u5bf9\u5e94\u8bba\u6587\u4e2d\u516c\u5f0f(5)\n        rank_loss = model.ranking_loss(top_n_prob, part_loss)\n        # \u6240\u6709\u533a\u57df\u7684\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u7528\u4e8e\u4f18\u5316Teacher\uff0c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f(7)\n        partcls_loss = creterion(part_logits.view(batch_size * PROPOSAL_NUM, -1),\n                                 label.unsqueeze(1).repeat(1, PROPOSAL_NUM).view(-1))\n        # \u603b\u635f\u5931\uff0c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f(9)\n        total_loss = raw_loss + rank_loss + concat_loss + partcls_loss\n        # \u53cd\u5411\u4f20\u64ad\uff0c\u6c42\u68af\u5ea6\n        total_loss.backward()\n        # \u4f9d\u6b21\u66f4\u65b0\u53c2\u6570\n        raw_optimizer.step()\n        part_optimizer.step()\n        concat_optimizer.step()\n        partcls_optimizer.step()\n        progress_bar(i, len(trainloader), 'train')\n\n    if epoch % SAVE_FREQ == 0:\n        # \u6bcf\u8bad\u7ec3SAVE_FREQ\u6b21\uff0c\u8fdb\u884c\u4e00\u6b21\u6d4b\u8bd5\uff0c\u4f9d\u6b21\u6d4b\u8bd5\u8bad\u7ec3\u96c6\u6570\u636e\u3001\u6d4b\u8bd5\u96c6\u6570\u636e\u5e76\u4fdd\u5b58\u6a21\u578b\n        train_loss = 0\n        train_correct = 0\n        total = 0\n        net.eval()\n        # \u4e0b\u9762\u6d4b\u8bd5\u8bad\u7ec3\u96c6\u7cbe\u5ea6\u4e0e\u635f\u5931\n        for i, data in enumerate(trainloader):\n            with torch.no_grad():\n                img, label = data[0].cuda(), data[1].cuda()\n                batch_size = img.size(0)\n                # \u6d4b\u8bd5\u65f6\uff0c\u53ea\u9700\u8981\u5f97\u5230Scrutinizer\u6a21\u5757\u4e2d\u7684\u9884\u6d4b\u6982\u7387\u5373\u53ef\n                _, concat_logits, _, _, _ = net(img)\n                # \u8ba1\u7b97\u6700\u7ec8\u7684\u9884\u6d4b\u6982\u7387\u4e0e\u6807\u7b7e\u4e4b\u95f4\u7684\u635f\u5931\n                concat_loss = creterion(concat_logits, label)\n                # \u8ba1\u7b97\u9884\u6d4b\u51c6\u786e\u7387\n                _, concat_predict = torch.max(concat_logits, 1)\n                total += batch_size\n                train_correct += torch.sum(concat_predict.data.eq(label.data))\n                train_loss += concat_loss.item() * batch_size\n                progress_bar(i, len(trainloader), 'eval train set')\n        # \u5f97\u5230\u8bad\u7ec3\u96c6\u7cbe\u5ea6\u4e0e\u8bad\u7ec3\u96c6\u635f\u5931\n        train_acc = float(train_correct) / total\n        train_loss = train_loss / total\n        # \u8f93\u51fa\n        _print(\n            'epoch:{} - train loss: {:.3f} and train acc: {:.3f} total sample: {}'.format(\n                epoch,\n                train_loss,\n                train_acc,\n                total))\n\n        # \u5728\u6d4b\u8bd5\u96c6\u6570\u636e\u4e0a\u8fdb\u884c\u6d4b\u8bd5\uff0c\u6c42\u89e3\u7cbe\u5ea6\u4e0e\u635f\u5931\n        # \u4e0b\u9762\u7684\u8fc7\u7a0b\u4e0e\u8bad\u7ec3\u96c6\u6570\u636e\u4e0a\u7684\u8fc7\u7a0b\u7c7b\u4f3c\uff0c\u8fd9\u91cc\u4e0d\u518d\u8bf4\u660e\n        test_loss = 0\n        test_correct = 0\n        total = 0\n        for i, data in enumerate(testloader):\n            with torch.no_grad():\n                img, label = data[0].cuda(), data[1].cuda()\n                batch_size = img.size(0)\n                _, concat_logits, _, _, _ = net(img)\n                # calculate loss\n                concat_loss = creterion(concat_logits, label)\n                # calculate accuracy\n                _, concat_predict = torch.max(concat_logits, 1)\n                total += batch_size\n                test_correct += torch.sum(concat_predict.data.eq(label.data))\n                test_loss += concat_loss.item() * batch_size\n                progress_bar(i, len(testloader), 'eval test set')\n\n        test_acc = float(test_correct) / total\n        test_loss = test_loss / total\n        _print(\n            'epoch:{} - test loss: {:.3f} and test acc: {:.3f} total sample: {}'.format(\n                epoch,\n                test_loss,\n                test_acc,\n                total))\n\n        # \u4fdd\u5b58\u6a21\u578b\n        net_state_dict = net.module.state_dict()\n        if not os.path.exists(save_dir):\n            os.mkdir(save_dir)\n        # \u4f9d\u6b21\u4fdd\u5b58\u8bad\u7ec3\u6b21\u6570\uff0c\u8bad\u7ec3\u635f\u5931\u3001\u8bad\u7ec3\u7cbe\u5ea6\u3001\u6d4b\u8bd5\u635f\u5931\u3001\u6d4b\u8bd5\u7cbe\u5ea6\u4ee5\u53ca\u6a21\u578b\u53c2\u6570\n        torch.save({\n            'epoch': epoch,\n            'train_loss': train_loss,\n            'train_acc': train_acc,\n            'test_loss': test_loss,\n            'test_acc': test_acc,\n            'net_state_dict': net_state_dict},\n            os.path.join(save_dir, '%03d.ckpt' % epoch))\n</code></pre> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u5927\u5bb6\u6279\u8bc4\u6307\u6b63</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e7411\u670811\u65e5</p>"},{"location":"fine-grained/code/PC2/","title":"\u7ec6\u7c92\u5ea6\uff1aPC","text":""},{"location":"fine-grained/code/PC2/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aEuropean Conference on Computer Vision 2018 (ECCV, 18)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content_ECCV_2018/html/Abhimanyu_Dubey_Improving_Fine-Grained_Visual_ECCV_2018_paper.html</p> <p>\u6e90\u7801\u5730\u5740(PyTorch\u7248\u672c)\uff1ahttps://github.com/abhimanyudubey/confusion</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u7c7b(FGVC)</p>"},{"location":"fine-grained/code/PC2/#_2","title":"\u4ee3\u7801\u5b9e\u73b0","text":"<p><code>features</code>\u4f20\u5165softmax\u8fd0\u7b97\u4e4b\u540e\u7684\u9884\u6d4b\u6982\u7387</p> <pre><code>def PairwiseConfusion(features):\n    # \u5f97\u5230batch\u6570\u91cf\n    batch_size = features.size(0)\n    if float(batch_size) % 2 != 0:\n        raise Exception('Incorrect batch size provided')\n    # \u5c06 \u9884\u6d4b\u6982\u7387 \u6cbfbatch\u65b9\u5411\u62c6\u6210\u4e24\u4efd\n    batch_left = features[:int(0.5 * batch_size)]\n    batch_right = features[int(0.5 * batch_size):]\n    # \u9010\u9879\u505a\u5dee\uff0c\u6c42\u5f97\u6b27\u6c0f\u8ddd\u79bb\uff0c\u4f5c\u4e3a\u6b63\u5219\u5316\u9879\n    loss = torch.norm((batch_left - batch_right).abs(), 2, 1).sum() / float(batch_size)\n\n    return loss\n</code></pre> <p>\u521d\u6b65\u5b8c\u7a3f\u4e8e2023\u5e742\u67081\u65e5</p>"},{"location":"fine-grained/code/PMG2/","title":"\u7ec6\u7c92\u5ea6\uff1aPMG","text":""},{"location":"fine-grained/code/PMG2/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aEuropean Conference on Computer Vision 2020 (ECCV, 2020)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://arxiv.org/pdf/2003.03836.pdf</p> <p>\u6e90\u7801\u5730\u5740(PyTorch\u7248\u672c)\uff1ahttps://github.com/PRIS-CV/PMG-Progressive-Multi-Granularity-Training</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u7c7b(FGVC)</p> <p>\u5173\u952e\u8bcd\uff1a\u7ec6\u7c92\u5ea6\u5206\u7c7b\u3001\u6e10\u8fdb\u8bad\u7ec3\u3001\u62fc\u56fe\u8865\u4e01</p>"},{"location":"fine-grained/code/PMG2/#pmg_1","title":"PMG\u7f51\u7edc\u7ed3\u6784","text":""},{"location":"fine-grained/code/PMG2/#_2","title":"\u7f51\u7edc\u521d\u59cb\u5316\u9636\u6bb5","text":"<pre><code>def __init__(self, model, feature_size, classes_num):\n    super(PMG, self).__init__()\n    # \u5b9a\u4e49\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\n    self.features = model\n    # \u5206\u522b\u7ed9\u4e09\u4e2a\u9636\u6bb5\u5b9a\u4e49\u4e09\u79cd\u6700\u5927\u6c60\u5316\u8fd0\u7b97\n    self.max1 = nn.MaxPool2d(kernel_size=56, stride=56)\n    self.max2 = nn.MaxPool2d(kernel_size=28, stride=28)\n    self.max3 = nn.MaxPool2d(kernel_size=14, stride=14)\n    # \u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u6700\u540e\u8f93\u51fa\u7684\u7279\u5f81\u6570\u91cf\uff0c\u5373\u5168\u8fde\u63a5\u5c42\u7684\u8f93\u5165\u5c3a\u5bf8\n    self.num_ftrs = 2048 * 1 * 1\n    # ELU\u6fc0\u6d3b\u51fd\u6570\n    self.elu = nn.ELU(inplace=True)\n    # \u4e09\u4e2a\u7279\u5f81\u56fe\u878d\u5408\u9636\u6bb5\u7684\u5168\u8fde\u63a5\u5c42\n    # \u4f9d\u6b21\u7ecf\u8fc7\u6279\u91cf\u5f52\u4e00\u5316\u3001\u7b2c\u4e00\u4e2a\u7ebf\u6027\u56de\u5f52\u3001\u6279\u91cf\u5f52\u4e00\u5316\u3001ELU\u6fc0\u6d3b\u51fd\u6570\u3001\u7b2c\u4e8c\u4e2a\u7ebf\u6027\u56de\u5f52\n    # \u878d\u5408\u540e\u7684\u7279\u5f81\u56fe\u901a\u9053\u6570\u662f\u524d\u4e09\u4e2a\u9636\u6bb5\u7279\u5f81\u56fe\u901a\u9053\u6570\u7684\u4e09\u500d\uff0c\u56e0\u6b64\u8981\u4e58\u4ee53\n    self.classifier_concat = nn.Sequential(\n        nn.BatchNorm1d(1024 * 3),\n        nn.Linear(1024 * 3, feature_size),\n        nn.BatchNorm1d(feature_size),\n        nn.ELU(inplace=True),\n        nn.Linear(feature_size, classes_num),\n    )\n    # \u7b2c\u4e00\u9636\u6bb5\u7684Conv Block\u6a21\u5757\uff0c\u7531\u4e24\u4e2aBasicConv\u6784\u6210\uff0c\u7279\u5f81\u56fe\u6570\u4ece512(\u7b2c\u4e00\u9636\u6bb5\u7684\u7279\u5f81\u56fe\u901a\u9053\u6570)\u5230512\u518d\u52301024\n    self.conv_block1 = nn.Sequential(\n        BasicConv(self.num_ftrs//4, feature_size, kernel_size=1, stride=1, padding=0, relu=True),\n        BasicConv(feature_size, self.num_ftrs//2, kernel_size=3, stride=1, padding=1, relu=True)\n    )\n    # \u7b2c\u4e00\u9636\u6bb5\u7684\u5206\u7c7b\u5668\uff0c\u4e0e\u4e0a\u8ff0\u878d\u5408\u540e\u7684\u7279\u5f81\u56fe\u7ecf\u8fc7\u7684\u5206\u7c7b\u5668\u7c7b\u4f3c\n    # \u7531\u6279\u91cf\u5f52\u4e00\u5316\u3001\u7b2c\u4e00\u4e2a\u7ebf\u6027\u56de\u5f52\u3001\u6279\u91cf\u5f52\u4e00\u5316\u3001ELU\u6fc0\u6d3b\u51fd\u6570\u3001\u7b2c\u4e8c\u4e2a\u7ebf\u6027\u56de\u5f52\u4e94\u4e2a\u6a21\u5757\u7ec4\u6210\n    self.classifier1 = nn.Sequential(\n        nn.BatchNorm1d(self.num_ftrs//2),\n        nn.Linear(self.num_ftrs//2, feature_size),\n        nn.BatchNorm1d(feature_size),\n        nn.ELU(inplace=True),\n        nn.Linear(feature_size, classes_num),\n    )\n    # \u7b2c\u4e8c\u9636\u6bb5\u7684Conv Block\u6a21\u5757\uff0c\u7531\u4e24\u4e2aBasicConv\u6784\u6210\uff0c\u7279\u5f81\u56fe\u6570\u4ece1024(\u7b2c\u4e8c\u9636\u6bb5\u7684\u7279\u5f81\u56fe\u901a\u9053\u6570)\u5230512\u518d\u52301024\n    self.conv_block2 = nn.Sequential(\n        BasicConv(self.num_ftrs//2, feature_size, kernel_size=1, stride=1, padding=0, relu=True),\n        BasicConv(feature_size, self.num_ftrs//2, kernel_size=3, stride=1, padding=1, relu=True)\n    )\n    # \u7b2c\u4e8c\u9636\u6bb5\u7684\u5206\u7c7b\u5668\uff0c\u4e0e\u4e0a\u8ff0\u5206\u7c7b\u5668\u6784\u6210\u7c7b\u4f3c\n    self.classifier2 = nn.Sequential(\n        nn.BatchNorm1d(self.num_ftrs//2),\n        nn.Linear(self.num_ftrs//2, feature_size),\n        nn.BatchNorm1d(feature_size),\n        nn.ELU(inplace=True),\n        nn.Linear(feature_size, classes_num),\n    )\n    # \u7b2c\u4e09\u9636\u6bb5\u7684Conv Block\u6a21\u5757\uff0c\u7531\u4e24\u4e2aBasicConv\u6784\u6210\uff0c\u7279\u5f81\u56fe\u6570\u4ece2048(\u7b2c\u4e09\u9636\u6bb5\u7684\u7279\u5f81\u56fe\u901a\u9053\u6570)\u5230512\u518d\u52301024\n    self.conv_block3 = nn.Sequential(\n        BasicConv(self.num_ftrs, feature_size, kernel_size=1, stride=1, padding=0, relu=True),\n        BasicConv(feature_size, self.num_ftrs//2, kernel_size=3, stride=1, padding=1, relu=True)\n    )\n    # \u7b2c\u4e09\u9636\u6bb5\u7684\u5206\u7c7b\u5668\uff0c\u4e0e\u4e0a\u8ff0\u5206\u7c7b\u5668\u6784\u6210\u7c7b\u4f3c\n    self.classifier3 = nn.Sequential(\n        nn.BatchNorm1d(self.num_ftrs//2),\n        nn.Linear(self.num_ftrs//2, feature_size),\n        nn.BatchNorm1d(feature_size),\n        nn.ELU(inplace=True),\n        nn.Linear(feature_size, classes_num),\n    )\n</code></pre>"},{"location":"fine-grained/code/PMG2/#_3","title":"\u524d\u5411\u4f20\u64ad","text":"<pre><code>def forward(self, x):\n    # \u9996\u5148\uff0c\u5c06\u539f\u59cb\u6570\u636e\u7ecf\u8fc7\u7279\u5f81\u63d0\u53d6\uff0c\u5f97\u5230\u7279\u5f81\u63d0\u53d6\u4e0d\u540c\u9636\u6bb5\u7684\u7279\u5f81\u56fe\n    # \u540e\u9762\u53ea\u7528\u5230\u4e86xf3, xf4, xf5\u4e09\u7ec4\u7279\u5f81\u56fe\uff0c\u5bf9\u5e94\u524d\u4e09\u4e2a\u9636\u6bb5\n    xf1, xf2, xf3, xf4, xf5 = self.features(x)\n    # \u7136\u540e\u4e09\u7ec4\u7279\u5f81\u56fe\u4f9d\u6b21\u7ecf\u8fc7\u9884\u5148\u5b9a\u4e49\u597d\u7684Conv Block\u6a21\u5757\n    xl1 = self.conv_block1(xf3)\n    xl2 = self.conv_block2(xf4)\n    xl3 = self.conv_block3(xf5)\n    # \u4e0b\u9762\u5bf9\u6bcf\u4e2a\u9636\u6bb5\u7684\u56fe\u505a\u5206\u7c7b\u9884\u6d4b\n    # \u7b2c\u4e00\u9636\u6bb5\uff0c\u9996\u5148\u7ecf\u8fc7\u6700\u5927\u6c60\u5316\uff0c\u7136\u540e\u7ecf\u8fc7\u5206\u7c7b\u5668\u8fdb\u884c\u5206\u7c7b\u9884\u6d4b\n    xl1 = self.max1(xl1)\n    xl1 = xl1.view(xl1.size(0), -1)\n    xc1 = self.classifier1(xl1)\n    # \u7b2c\u4e8c\u9636\u6bb5\uff0c\u8fc7\u7a0b\u4e0e\u7b2c\u4e00\u9636\u6bb5\u7c7b\u4f3c\n    xl2 = self.max2(xl2)\n    xl2 = xl2.view(xl2.size(0), -1)\n    xc2 = self.classifier2(xl2)\n    # \u7b2c\u4e09\u9636\u6bb5\uff0c\u8fc7\u7a0b\u540c\u6837\u4e0e\u7b2c\u4e00\u9636\u6bb5\u7c7b\u4f3c\n    xl3 = self.max3(xl3)\n    xl3 = xl3.view(xl3.size(0), -1)\n    xc3 = self.classifier3(xl3)\n    # \u5c06\u4e09\u4e2a\u9636\u6bb5\u5f97\u5230\u7684\u7279\u5f81\u56fe\u505a\u5806\u53e0\uff0c\u5408\u5e76\u5230\u4e00\u5757\uff0c\u4f5c\u4e3a\u7b2c\u56db\u9636\u6bb5\u7684\u7279\u5f81\u56fe\n    x_concat = torch.cat((xl1, xl2, xl3), -1)\n    # \u878d\u5408\u540e\u7684\u7279\u5f81\u56fe\uff0c\u7ecf\u8fc7\u5206\u7c7b\u5668\u505a\u5206\u7c7b\u9884\u6d4b\n    x_concat = self.classifier_concat(x_concat)\n    # \u4f9d\u6b21\u8fd4\u56de\u56db\u4e2a\u9636\u6bb5\u7684\u9884\u6d4b\u6982\u7387\n    return xc1, xc2, xc3, x_concat\n</code></pre>"},{"location":"fine-grained/code/PMG2/#_4","title":"\u7279\u5f81\u63d0\u53d6\u7f51\u7edc","text":"<p>\u8fd9\u91cc\u4ee5resnet50\u4e3a\u4f8b\uff0c\u7f51\u7edc\u521d\u59cb\u5316\u9636\u6bb5\u4e0e\u6b63\u5e38\u7684resnet\u7c7b\u4f3c\uff0c\u8fd9\u91cc\u4e0d\u518d\u91cd\u8ff0 \u524d\u5411\u4f20\u64ad\u9636\u6bb5 <pre><code>def forward(self, x):\n    x = self.conv1(x)\n    x = self.bn1(x)\n    x = self.relu(x)\n    # x1\u3001x2\u3001x3\u3001x4\u3001x5\u5206\u522b\u5bf9\u5e94\u4e0d\u540c\u9636\u6bb5\u7684\u7279\u5f81\u56fe\n    # \u9636\u6bb5\u7531\u4e0b\u91c7\u6837\u6c60\u5316\u64cd\u4f5c\u5212\u5206\n    # \u6bcf\u7ecf\u8fc7\u4e00\u6b21\u4e0b\u91c7\u6837\uff0c\u5c31\u4ee3\u8868\u4ece\u4e00\u4e2a\u9636\u6bb5\u8fc7\u6e21\u5230\u53e6\u4e00\u4e2a\u9636\u6bb5\n    x1 = self.maxpool(x)\n\n    x2 = self.layer1(x1)\n    x3 = self.layer2(x2)\n    x4 = self.layer3(x3)\n    x5 = self.layer4(x4)\n\n    x = self.avgpool(x5)\n    x = x.reshape(x.size(0), -1)\n    x = self.fc(x)\n    # \u6700\u540e\u8fd4\u56de\u4e94\u4e2a\u9636\u6bb5\u7684\u7279\u5f81\u56fe\n    return x1, x2, x3, x4, x5\n</code></pre></p>"},{"location":"fine-grained/code/PMG2/#_5","title":"\u5377\u79ef\u6a21\u5757","text":"<pre><code>class BasicConv(nn.Module):\n    # \u7528\u4e8e\u6784\u6210\u8bba\u6587\u4e2d\u7684Conv Block\u6a21\u5757\uff0c\u4f9d\u6b21\u7ecf\u8fc7\u5377\u79ef\u3001\u6279\u91cf\u5f52\u4e00\u5316\u3001relu\n    # \u7c7b\u4f3cresnet\u4e2d\u7684\u4e00\u4e2a\u5c0f\u6a21\u5757\n    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1, groups=1, relu=True, bn=True, bias=False):\n        super(BasicConv, self).__init__()\n        self.out_channels = out_planes\n        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size,\n                              stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        self.bn = nn.BatchNorm2d(out_planes, eps=1e-5,\n                                 momentum=0.01, affine=True) if bn else None\n        self.relu = nn.ReLU() if relu else None\n\n    def forward(self, x):\n        x = self.conv(x)\n        if self.bn is not None:\n            x = self.bn(x)\n        if self.relu is not None:\n            x = self.relu(x)\n        return x\n</code></pre>"},{"location":"fine-grained/code/PMG2/#_6","title":"\u635f\u5931\u51fd\u6570","text":"<p>\u672c\u6587\u53ea\u5229\u7528\u4e86\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u56e0\u6b64\u76f4\u63a5\u4ecenn\u6a21\u5757\u8c03\u53d6\u5373\u53ef</p> <pre><code>CELoss = nn.CrossEntropyLoss()\n</code></pre>"},{"location":"fine-grained/code/PMG2/#_7","title":"\u8bad\u7ec3\u6d41\u7a0b","text":""},{"location":"fine-grained/code/PMG2/#_8","title":"\u8bad\u7ec3\u521d\u59cb\u5316\u9636\u6bb5","text":"<pre><code>def train(nb_epoch, batch_size, store_name, resume=False, start_epoch=0, model_path=None):\n    # setup output\n    exp_dir = store_name\n    try:\n        os.stat(exp_dir)\n    except:\n        os.makedirs(exp_dir)\n\n    use_cuda = torch.cuda.is_available()\n    print(use_cuda)\n\n    # Data\n    # \u5b9a\u4e49\u6570\u636e\u96c6\u7684\u9884\u5904\u7406\u8fc7\u7a0b\n    print('==&gt; Preparing data..')\n    transform_train = transforms.Compose([\n        transforms.Scale((550, 550)),\n        transforms.RandomCrop(448, padding=8),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n    ])\n    # \u52a0\u8f7d\u6570\u636e\u96c6\n    trainset = torchvision.datasets.ImageFolder(root='./bird/train', transform=transform_train)\n    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)\n\n    # Model \u5982\u679c\u5b58\u5728\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u5c31\u52a0\u8f7d\uff0c\u5426\u5219\u521d\u59cb\u5316\u4e00\u4e2a\u6a21\u578b\n    if resume:\n        net = torch.load(model_path)\n    else:\n        net = load_model(model_name='resnet50_pmg', pretrain=True, require_grad=True)\n    # \u5e76\u884c\u8bad\u7ec3\uff0c\u5c06\u6a21\u578b\u540c\u65f6\u653e\u5165\u7f16\u53f7\u4e3a0,1\u7684\u663e\u5361\n    netp = torch.nn.DataParallel(net, device_ids=[0,1])\n\n    # GPU\n    device = torch.device(\"cuda:0,1\")\n    net.to(device)\n    # cudnn.benchmark = True\n    # \u5b9a\u4e49\u635f\u5931\u51fd\u6570\n    CELoss = nn.CrossEntropyLoss()\n    # \u5b9a\u4e49\u4f18\u5316\u5668\uff0c\u5206\u522b\u4ee5\u4e0d\u540c\u7684\u5b66\u4e60\u7387\u4f18\u5316\u4e0d\u540c\u7684\u6a21\u578b\u53c2\u6570\n    optimizer = optim.SGD([\n        {'params': net.classifier_concat.parameters(), 'lr': 0.002},\n        {'params': net.conv_block1.parameters(), 'lr': 0.002},\n        {'params': net.classifier1.parameters(), 'lr': 0.002},\n        {'params': net.conv_block2.parameters(), 'lr': 0.002},\n        {'params': net.classifier2.parameters(), 'lr': 0.002},\n        {'params': net.conv_block3.parameters(), 'lr': 0.002},\n        {'params': net.classifier3.parameters(), 'lr': 0.002},\n        {'params': net.features.parameters(), 'lr': 0.0002}\n\n    ],\n        momentum=0.9, weight_decay=5e-4)\n\n    max_val_acc = 0\n    # \u9ed8\u8ba4\u7684\u5b66\u4e60\u7387\n    lr = [0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.0002]\n</code></pre>"},{"location":"fine-grained/code/PMG2/#_9","title":"\u8bad\u7ec3\u8fc7\u7a0b","text":"<pre><code>for epoch in range(start_epoch, nb_epoch):\n    print('\\nEpoch: %d' % epoch)\n    net.train()\n    # \u521d\u59cb\u5316\u6240\u6709\u7684\u635f\u5931\u7b49\u53c2\u6570\n    train_loss = 0\n    train_loss1 = 0\n    train_loss2 = 0\n    train_loss3 = 0\n    train_loss4 = 0\n    correct = 0\n    total = 0\n    idx = 0\n    for batch_idx, (inputs, targets) in enumerate(trainloader):\n        idx = batch_idx\n        if inputs.shape[0] &lt; batch_size:\n            continue\n        if use_cuda:\n            # \u662f\u5426\u4f7f\u7528cuda\n            inputs, targets = inputs.to(device), targets.to(device)\n        inputs, targets = Variable(inputs), Variable(targets)\n\n        # update learning rate\n        # \u5b66\u4e60\u7387\u66f4\u65b0\u7b56\u7565\n        for nlr in range(len(optimizer.param_groups)):\n            # \u8c03\u6574\u5b66\u4e60\u7387\uff0c\u5177\u4f53\u8c03\u6574\u7b56\u7565\u89c1cosine_anneal_schedule\n            optimizer.param_groups[nlr]['lr'] = cosine_anneal_schedule(epoch, nb_epoch, lr[nlr])\n\n        # Step 1\n        optimizer.zero_grad()\n        # \u5c06\u539f\u56fe\u6253\u4e71\uff0c\u6bcf\u884c\u6bcf\u5217\u5206\u522b\u5212\u52068\u4efd\uff0c\u4e00\u517164\u4e2a\n        inputs1 = jigsaw_generator(inputs, 8)\n        # \u7f51\u7edc\u7b2c\u4e00\u5c42\u7684\u9884\u6d4b\u6982\u7387\n        output_1, _, _, _ = netp(inputs1)\n        # \u7b2c\u4e00\u9636\u6bb5\u9884\u6d4b\u6982\u7387\u4e0e\u6807\u7b7e\u505a\u4ea4\u53c9\u71b5\u635f\u5931\n        loss1 = CELoss(output_1, targets) * 1\n        # \u53cd\u5411\u4f20\u64ad\u3001\u66f4\u65b0\u68af\u5ea6\n        loss1.backward()\n        optimizer.step()\n\n        # \u4e0b\u8ff0\u7b2c2\u30013\u9636\u6bb5\u7684\u8bad\u7ec3\u8fc7\u7a0b\u4e0e\u7b2c1\u9636\u6bb5\u7c7b\u4f3c\n        # Step 2\n        optimizer.zero_grad()\n        # \u6253\u4e71\u539f\u56fe\uff0c\u6bcf\u884c\u6bcf\u5217\u5206\u522b\u5212\u52064\u4efd\n        inputs2 = jigsaw_generator(inputs, 4)\n        # \u5f97\u5230\u7f51\u7edc\u7b2c\u4e8c\u5c42\u7684\u9884\u6d4b\u6982\u7387\n        _, output_2, _, _ = netp(inputs2)\n        # \u6c42\u635f\u5931\u3001\u53cd\u5411\u4f20\u64ad\u3001\u66f4\u65b0\u53c2\u6570\n        loss2 = CELoss(output_2, targets) * 1\n        loss2.backward()\n        optimizer.step()\n\n        # Step 3\n        optimizer.zero_grad()\n        # \u540c\u4e0a\u6253\u4e71\u539f\u56fe\u3001\u6bcf\u884c\u6bcf\u5217\u5212\u5206\u4e24\u4efd\n        inputs3 = jigsaw_generator(inputs, 2)\n        # \u5f97\u5230\u7f51\u7edc\u7b2c\u4e09\u5c42\u7684\u9884\u6d4b\u6982\u7387(\u5373\u6700\u540e\u4e00\u5c42)\n        _, _, output_3, _ = netp(inputs3)\n        # \u6c42\u635f\u5931\u3001\u53cd\u5411\u4f20\u64ad\u3001\u66f4\u65b0\u53c2\u6570\n        loss3 = CELoss(output_3, targets) * 1\n        loss3.backward()\n        optimizer.step()\n\n        # Step 4 \u7b2c\u56db\u9636\u6bb5\n        optimizer.zero_grad()\n        # \u8f93\u5165\u539f\u56fe\uff0c\u4e0d\u8fdb\u884c\u6253\u4e71\uff0c\u5f97\u5230\u4e09\u4e2a\u9636\u6bb5\u878d\u5408\u540e\u7279\u5f81\u56fe\u7684\u9884\u6d4b\u6982\u7387\n        _, _, _, output_concat = netp(inputs)\n        # \u6c42\u635f\u5931\u3001\u53cd\u5411\u4f20\u64ad\u3001\u66f4\u65b0\u68af\u5ea6\n        concat_loss = CELoss(output_concat, targets) * 2\n        concat_loss.backward()\n        optimizer.step()\n\n        #  training log\n        # \u5229\u7528output_concat\u8ba1\u7b97\u6a21\u578b\u7684\u9884\u6d4b\u7cbe\u5ea6\n        _, predicted = torch.max(output_concat.data, 1)\n        # total\u4ee3\u8868\u56fe\u7247\u603b\u6570\n        total += targets.size(0)\n        # \u8ba1\u7b97\u9884\u6d4b\u6b63\u786e\u4e2a\u6570correct\n        correct += predicted.eq(targets.data).cpu().sum()\n        # \u8ba1\u7b97\u8bad\u7ec3\u603b\u635f\u5931\uff1a\u603b\u635f\u5931\u4ee5\u53ca\u5404\u9636\u6bb5\u635f\u5931\n        train_loss += (loss1.item() + loss2.item() + loss3.item() + concat_loss.item())\n        train_loss1 += loss1.item()\n        train_loss2 += loss2.item()\n        train_loss3 += loss3.item()\n        train_loss4 += concat_loss.item()\n        # batch_idx\u4ee3\u8868\u8bad\u7ec3\u6b21\u6570\uff0c\u6bcf50\u6b21\u8f93\u51fa\u4e00\u6b21\u4fe1\u606f\n        if batch_idx % 50 == 0:\n            print(\n                'Step: %d | Loss1: %.3f | Loss2: %.5f | Loss3: %.5f | Loss_concat: %.5f | Loss: %.3f | Acc: %.3f%% (%d/%d)' % (\n                batch_idx, train_loss1 / (batch_idx + 1), train_loss2 / (batch_idx + 1),\n                train_loss3 / (batch_idx + 1), train_loss4 / (batch_idx + 1), train_loss / (batch_idx + 1),\n                100. * float(correct) / total, correct, total))\n    # \u8ba1\u7b97\u8bad\u7ec3\u5e73\u5747\u7cbe\u5ea6\u4ee5\u53ca\u5e73\u5747\u635f\u5931\n    train_acc = 100. * float(correct) / total\n    train_loss = train_loss / (idx + 1)\n    # \u5c06\u8bad\u7ec3\u7ed3\u679c\u5199\u5165results_train.txt\u6587\u4ef6\uff0c\u7c7b\u4f3c\u8f93\u51fa\u65e5\u5fd7\n    with open(exp_dir + '/results_train.txt', 'a') as file:\n        file.write(\n            'Iteration %d | train_acc = %.5f | train_loss = %.5f | Loss1: %.3f | Loss2: %.5f | Loss3: %.5f | Loss_concat: %.5f |\\n' % (\n            epoch, train_acc, train_loss, train_loss1 / (idx + 1), train_loss2 / (idx + 1), train_loss3 / (idx + 1),\n            train_loss4 / (idx + 1)))\n    # \u6d4b\u8bd5\u4ee5\u53ca\u6a21\u578b\u4fdd\u5b58\u7b56\u7565\n    # \u8fd9\u91cc\u662f\u6e90\u7801\u9ed8\u8ba4\u7684\u7b56\u7565\uff1a\u8fed\u4ee3\u6b21\u6570\u5c0f\u4e8e5\u6b21\u6216\u5927\u4e8e\u7b49\u4e8e80\u6b21\u8fdb\u884c\u6d4b\u8bd5\n    # \u53ef\u4ee5\u901a\u8fc7\u4fee\u6539\u8fd9\u91cc\uff0c\u6765\u4fee\u6539\u6d4b\u8bd5\u4ee5\u53ca\u6a21\u578b\u4fdd\u5b58\u7b56\u7565\n    if epoch &lt; 5 or epoch &gt;= 80:\n        # \u6d4b\u8bd5\u5f97\u5230\u4e24\u79cd\u6d4b\u8bd5\u7cbe\u5ea6\uff0c\u5bf9\u5e94\u8bba\u6587\u4e2d\u516c\u5f0f(4)(5)\u4e24\u79cd\u8ba1\u7b97\u65b9\u6cd5\n        # \u4e00\u4e2a\u662f\u53ea\u7528\u878d\u5408\u7279\u5f81\u56fe\u5f97\u5230\u7684\u9884\u6d4b\u6982\u7387\uff0c\u4e00\u4e2a\u662f\u7efc\u5408\u6240\u6709\u7684\u9884\u6d4b\u6982\u7387\n        # \u5e76\u4e14\u5f97\u5230\u6d4b\u8bd5\u635f\u5931\n        val_acc, val_acc_com, val_loss = test(net, CELoss, 3)\n        # \u5982\u679c\u5f53\u524d\u6d4b\u8bd5\u7cbe\u5ea6\u5927\u4e8emax\uff0c\u5c31\u4fdd\u5b58\u4e00\u6b21\u6a21\u578b\n        if val_acc_com &gt; max_val_acc:\n            # \u66f4\u65b0\u5f53\u524d\u6700\u5927\u7684\u7cbe\u5ea6\n            max_val_acc = val_acc_com\n            net.cpu()\n            # \u53ea\u4fdd\u5b58\u6a21\u578b\uff0c\u53ef\u4ee5\u901a\u8fc7\u4fee\u6539\u8fd9\u91cc\uff0c\u6765\u4fee\u6539\u4fdd\u5b58\u5185\u5bb9\n            torch.save(net, './' + store_name + '/model.pth')\n            net.to(device)\n        # \u8f93\u51fa\u65e5\u5fd7\n        with open(exp_dir + '/results_test.txt', 'a') as file:\n            file.write('Iteration %d, test_acc = %.5f, test_acc_combined = %.5f, test_loss = %.6f\\n' % (\n            epoch, val_acc, val_acc_com, val_loss))\n    else:\n        # \u5982\u679c\u4e0d\u6d4b\u8bd5\uff0c\u5c31\u6bcf\u8bad\u7ec3\u4e00\u6b21\uff0c\u4fdd\u5b58\u4e00\u6b21\u6a21\u578b\n        net.cpu()\n        torch.save(net, './' + store_name + '/model.pth')\n        net.to(device)\n</code></pre>"},{"location":"fine-grained/code/PMG2/#_10","title":"\u62fc\u56fe\u7684\u751f\u6210","text":"<pre><code>def jigsaw_generator(images, n):\n    # n\u4ee3\u8868\u6bcf\u884c\u3001\u6bcf\u5217\u88ab\u5206\u5272\u7684\u4efd\u6570\uff0c\u5fc5\u987b\u53ef\u4ee5\u6574\u9664\u539f\u56fe\u50cf\u7684\u957f\u5bbd\uff0c\u4e00\u5171\u88ab\u5206\u5272\u6210n^2\u4e2a\u5c0f\u533a\u57df\n    # l\u4ee3\u8868\u533a\u57df\u7684\u6a2a\u7eb5\u4f4d\u7f6e\uff0c\u9996\u5148\u5b9a\u4e49\uff0c\u7136\u540e\u8fdb\u884c\u6253\u4e71\n    l = []\n    for a in range(n):\n        for b in range(n):\n            l.append([a, b])\n    # \u6bcf\u4e2a\u533a\u57df\u7684\u5c3a\u5bf8\n    block_size = 448 // n\n    # \u4e00\u5171\u5f97\u5230n^2\u4e2a\u533a\u57df\n    rounds = n ** 2\n    # \u5c06l\u4e2d\u7684\u5143\u7d20\u968f\u673a\u6253\u4e71\n    random.shuffle(l)\n    # \u590d\u5236\u4e00\u4efd\u539f\u56fe\u50cf\uff0c\u9632\u6b62\u6539\u53d8jigsaws\u7684\u540c\u65f6\u6539\u53d8images(\u89c6\u56fe)\n    jigsaws = images.clone()\n    # \u6253\u4e71\u540e\u7684\u533a\u57df\u4e3a\u987a\u5e8f\uff0c\u505a\u904d\u5386\n    for i in range(rounds):\n        # \u5f97\u5230\u533a\u57df\u7684\u6a2a\u7eb5\u4f4d\u7f6e\n        x, y = l[i]\n        # \u50a8\u5b58\u5de6\u4e0a\u89d2\u7684\u533a\u57df\uff0c\u4fbf\u4e8e\u540e\u7eed\u7684\u4f7f\u7528\n        temp = jigsaws[..., 0:block_size, 0:block_size].clone()\n        # \u5c06\u5de6\u4e0a\u89d2\u533a\u57df\u7684\u6570\u636e\u8d4b\u503c\u4e3a\u6307\u5b9a\u533a\u57df\u7684\u6570\u636e\n        jigsaws[..., 0:block_size, 0:block_size] = jigsaws[..., x * block_size:(x + 1) * block_size,\n                                                y * block_size:(y + 1) * block_size].clone()\n        # \u518d\u5c06\u6307\u5b9a\u533a\u57df\u7684\u6570\u636e\u8d4b\u503c\u4e3a\u539f\u5de6\u4e0a\u89d2\u533a\u57df\u7684\u6570\u636e\n        jigsaws[..., x * block_size:(x + 1) * block_size, y * block_size:(y + 1) * block_size] = temp\n        # \u4e0a\u8ff0\u8fc7\u7a0b\u76f8\u5f53\u4e8e\uff0c\u5c06\u5de6\u4e0a\u89d2\u7684\u533a\u57df\u548c\u6307\u5b9a\u7684\u533a\u57df(l[i]\u5b9a\u4f4d\u7684\u533a\u57df)\u505a\u4ea4\u6362\uff0c\u4ece\u800c\u8fbe\u5230\u6253\u4e71\u539f\u56fe\u7684\u6548\u679c\n    return jigsaws\n</code></pre>"},{"location":"fine-grained/code/PMG2/#_11","title":"\u6d4b\u8bd5\u6d41\u7a0b","text":"<p><pre><code>def test(net, criterion, batch_size):\n    # \u6a21\u578b\u8f6c\u5316\u4e3a\u6d4b\u8bd5\u9636\u6bb5\n    net.eval()\n    use_cuda = torch.cuda.is_available()\n    # \u521d\u59cb\u5316\u4e00\u4e9b\u5217\u6307\u6807\u53d8\u91cf\n    test_loss = 0\n    correct = 0\n    correct_com = 0\n    total = 0\n    idx = 0\n    device = torch.device(\"cuda:0,1\")\n    # \u5b9a\u4e49\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\u6570\u636e\u7684\u9884\u5904\u7406\n    transform_test = transforms.Compose([\n        transforms.Scale((550, 550)),\n        transforms.CenterCrop(448),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n    ])\n    # \u52a0\u8f7d\u6d4b\u8bd5\u6570\u636e\n    testset = torchvision.datasets.ImageFolder(root='./bird/test',\n                                               transform=transform_test)\n    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=4)\n    # \u904d\u5386\u6570\u636e\u96c6\n    for batch_idx, (inputs, targets) in enumerate(testloader):\n        idx = batch_idx\n        # \u662f\u5426\u5229\u7528cuda\n        if use_cuda:\n            inputs, targets = inputs.to(device), targets.to(device)\n        inputs, targets = Variable(inputs, volatile=True), Variable(targets)\n        # \u5c06\u8f93\u5165\u56fe\u7247\u76f4\u63a5\u4f20\u5165\u7f51\u7edc\uff0c\u5f97\u5230\u56db\u7ec4\u9884\u6d4b\u6982\u7387\n        # \u6ce8\u610f\u3001\u6d4b\u8bd5\u9636\u6bb5\u65e0\u9700\u7ecf\u8fc7\u62fc\u56fe\u64cd\u4f5c\n        output_1, output_2, output_3, output_concat= net(inputs)\n        # \u8ba1\u7b97C2\u9884\u6d4b\u6982\u7387\uff0c\u5373\u8bba\u6587\u4e2d\u7684\u516c\u5f0f(5)\uff0c\u7efc\u5408\u4e86\u6240\u6709\u7684\u9884\u6d4b\u6982\u7387\n        outputs_com = output_1 + output_2 + output_3 + output_concat\n        # \u8ba1\u7b97C1\u9884\u6d4b\u6982\u7387(\u53ea\u5229\u7528\u878d\u5408\u70ed\u56fe\u8fdb\u884c\u5206\u7c7b\u9884\u6d4b)\u7684\u635f\u5931\n        loss = criterion(output_concat, targets)\n        # \u8ba1\u7b97\u6d4b\u8bd5\u635f\u5931\n        test_loss += loss.item()\n        # \u5f97\u5230output_concat(C1)\u9884\u6d4b\u7684\u6807\u7b7e\n        _, predicted = torch.max(output_concat.data, 1)\n        # \u5f97\u5230C2\u9884\u6d4b\u7684\u6807\u7b7e\n        _, predicted_com = torch.max(outputs_com.data, 1)\n        # total\u8868\u793a\u6d4b\u8bd5\u96c6\u56fe\u7247\u603b\u6570\n        total += targets.size(0)\n        # \u4f9d\u6b21\u8ba1\u7b97\uff0c\u5f97\u5230C1\u51c6\u786e\u9884\u6d4b\u7684\u6837\u672c\u4e2a\u6570\uff0c\u4ee5\u53caC2\u51c6\u786e\u9884\u6d4b\u7684\u6837\u672c\u4e2a\u6570\n        correct += predicted.eq(targets.data).cpu().sum()\n        correct_com += predicted_com.eq(targets.data).cpu().sum()\n        # \u6bcf\u6d4b\u8bd550\u7ec4\uff0c\u8f93\u51fa\u4e00\u6b21\u4fe1\u606f\n        if batch_idx % 50 == 0:\n            print('Step: %d | Loss: %.3f | Acc: %.3f%% (%d/%d) |Combined Acc: %.3f%% (%d/%d)' % (\n            batch_idx, test_loss / (batch_idx + 1), 100. * float(correct) / total, correct, total, 100. * float(correct_com) / total, correct_com, total))\n    # \u6d4b\u8bd5\u96c6\u904d\u5386\u5b8c\u4e4b\u540e\uff0c\u5206\u522b\u8ba1\u7b97\u5f97\u5230C1\u51c6\u786e\u7387\uff0cC2\u51c6\u786e\u7387\u3001\u6d4b\u8bd5\u635f\u5931\n    test_acc = 100. * float(correct) / total\n    test_acc_en = 100. * float(correct_com) / total\n    test_loss = test_loss / (idx + 1)\n    # \u5c06\u4e0a\u8ff0\u4e09\u4e2a\u6307\u6807\u8fd4\u56de\n    return test_acc, test_acc_en, test_loss\n</code></pre> \u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u5927\u5bb6\u6279\u8bc4\u6307\u6b63</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e7411\u670814\u65e5</p>"},{"location":"fine-grained/code/RA-CNN2/","title":"\u7ec6\u7c92\u5ea6\uff1aRA-CNN","text":""},{"location":"fine-grained/code/RA-CNN2/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aIEEE Conference on Computer Vision and Pattern Recognition 2017 (CVPR, 2017)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content_cvpr_2017/papers/Fu_Look_Closer_to_CVPR_2017_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740(PyTorch\u7248\u672c)\uff1ahttps://github.com/jeong-tae/RACNN-pytorch</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u7c7b(FGVC)</p>"},{"location":"fine-grained/code/RA-CNN2/#ra-cnn_1","title":"RA-CNN\u7f51\u7edc\u6574\u4f53\u7ed3\u6784","text":""},{"location":"fine-grained/code/RA-CNN2/#_2","title":"\u521d\u59cb\u5316\u9636\u6bb5","text":"<pre><code>def __init__(self, num_classes, pretrained = True):\n    super(RACNN, self).__init__()\n    # \u5224\u65ad\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u662f\u5426\u4f7f\u7528\u9884\u8bad\u7ec3\u53c2\u6570\n    if pretrained:\n        pretrained = True\n    else:\n        pretrained = False\n    # \u5b9a\u4e49\u597d\u4e09\u4e2a\u5c3a\u5ea6\u7684\u7279\u5f81\u63d0\u53d6\u5c42\uff0c\u5206\u522b\u8fdb\u884c\u4e0d\u540c\u7684\u7279\u5f81\u63d0\u53d6\u64cd\u4f5c\n    self.b1 = vgg19_bn(num_classes = 1000, pretrained = pretrained)\n    self.b2 = vgg19_bn(num_classes = 1000, pretrained = pretrained)\n    self.b3 = vgg19_bn(num_classes = 1000, pretrained = pretrained)\n    # \u5b9a\u4e49\u597d\u4e24\u4e2a\u6c60\u5316\u5c42\uff0c\u7528\u4e8e\u7279\u5f81\u63d0\u53d6\u540e\u7b2c1\u6761\u5206\u652f(\u5206\u7c7b)\u7684\u5168\u5c40\u6c60\u5316\u64cd\u4f5c\n    # \u7531\u4e8e\u7b2c\u4e00\u5c3a\u5ea6\u8f93\u5165\u5c3a\u5bf8\u4e3a448*448\uff0c\u4e8c\u4e09\u5c3a\u5ea6\u8f93\u5165\u5c3a\u5bf8\u4e3a224*224\n    # \u4e24\u8005\u8f93\u5165\u5c3a\u5bf8\u4e0d\u540c\u56e0\u6b64\u9700\u8981\u5b9a\u4e49\u4e24\u79cd\u6c60\u5316\u7f51\u7edc\n    # \u7b2c\u4e00\u5c3a\u5ea6\u7684\u56fe\u50cf\u7ecf\u8fc7\u7279\u5f81\u63d0\u53d6\u540e\u5f97\u523028*28\u7684\u7279\u5f81\u56fe\n    self.feature_pool1 = nn.AvgPool2d(kernel_size = 28, stride = 28)\n    # \u4e8c\u4e09\u5c3a\u5ea6\u7684\u56fe\u50cf\u7ecf\u8fc7\u7279\u5f81\u63d0\u53d6\u540e\u5f97\u523014*14\u7684\u7279\u5f81\u56fe\n    self.feature_pool2 = nn.AvgPool2d(kernel_size = 14, stride = 14)\n    # \u7531\u4e8e\u7b2c\u4e00\u5c3a\u5ea6\u5f97\u523028*28\u7684\u56fe\u50cf\uff0c\u56e0\u6b64\u9700\u8981\u7ecf\u8fc7\u964d\u7ef4\n    # \u53d8\u4e3a14*14\u7684\u56fe\u50cf\uff0c\u518d\u751f\u6210\u6ce8\u610f\u529b\u533a\u57df\n    self.atten_pool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n    # \u751f\u6210\u7528\u4e8e\u5b9a\u4f4d\u6ce8\u610f\u529b\u533a\u57df\u7684\u5750\u6807(\u4e09\u4e2a\u6570\u503c)\n    # \u7b2c\u4e00\u5c3a\u5ea6\u5230\u7b2c\u4e8c\u5c3a\u5ea6\n    self.apn1 = nn.Sequential(\n        nn.Linear(512 * 14 * 14, 1024),\n        nn.Tanh(),\n        nn.Linear(1024, 3),#\u6700\u7ec8\u5f97\u5230\u4e09\u4e2a\u6570\n        nn.Sigmoid(),\n    )\n    # \u7b2c\u4e8c\u5c3a\u5ea6\u5230\u7b2c\u4e09\u5c3a\u5ea6\n    self.apn2 = nn.Sequential(\n        nn.Linear(512 * 14 * 14, 1024),\n        nn.Tanh(),\n        nn.Linear(1024, 3),\n        nn.Sigmoid(),\n    )\n    # \u7528\u4e8e\u88c1\u526a\u64cd\u4f5c\uff0cAttentionCropLayer\u7684\u5b9a\u4e49\u89c1\u4e0b\u6587\n    self.crop_resize = AttentionCropLayer()\n    # \u5404\u4e2a\u5c3a\u5ea6\u7684\u7b2c\u4e00\u6761\u5206\u652f\uff0c\u5373\u7ecf\u8fc7\u5168\u8fde\u63a5\u5c42\u8fdb\u884c\u5206\u7c7b\n    self.classifier1 = nn.Linear(512, num_classes)\n    self.classifier2 = nn.Linear(512, num_classes)\n    self.classifier3 = nn.Linear(512, num_classes)\n</code></pre>"},{"location":"fine-grained/code/RA-CNN2/#_3","title":"\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b","text":"<pre><code>def forward(self, x):\n    # \u9996\u5148\u5c06\u56fe\u7247\u8f93\u5165\u5230\u7b2c\u4e00\u5c3a\u5ea6\u7684\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u4e2d\uff0c\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\u64cd\u4f5c\n    conv5_4 = self.b1.features[:-1](x)\n    # \u7b2c\u4e00\u6761\u5206\u652f\uff0c\u5c06\u7279\u5f81\u56fe\u8fdb\u884c\u5168\u5c40\u6c60\u5316\u64cd\u4f5c\uff0c\u7528\u4e8e\u540e\u671f\u8f93\u5165\u5230\u5168\u8fde\u63a5\u5c42\n    pool5 = self.feature_pool1(conv5_4)\n    # \u7b2c\u4e8c\u6761\u5206\u652f\uff0c\u5c06\u7279\u5f81\u56fe\u5148\u7ecf\u8fc7\u6c60\u5316\uff0c\u518d\u8f93\u5165\u5230\u5b9a\u4e49\u597d\u7684APN1\u6a21\u5757\n    # \u751f\u6210\u7528\u4e8e\u5b9a\u4f4d\u7684\u6ce8\u610f\u529b\u533a\u57df\u5750\u6807\n    atten1 = self.apn1(self.atten_pool(conv5_4).view(-1, 512 * 14 * 14))\n    # \u7531\u4e8e\u5750\u6807\u7ecf\u8fc7\u4e86\u5f52\u4e00\u5316\u64cd\u4f5c\uff0c\u56e0\u6b64\u9700\u8981\u4e58\u4e0a\u539f\u56fe\u5927\u5c0f(448)\u590d\u539f\n    # \u518d\u5c06\u539f\u56fe\u50cf\u4e0e\u5750\u6807\u8f93\u5165\u5230\u5b9a\u4e49\u597d\u7684\u88c1\u526a\u51fd\u6570\u91cc\uff0c\u88c1\u526a\u751f\u6210\u7528\u4e8e\u7b2c\u4e8c\u5c3a\u5ea6\u5b66\u4e60/\u9884\u6d4b\u7684\u6ce8\u610f\u529b\u533a\u57df(\u56fe\u50cf2)\n    scaledA_x = self.crop_resize(x, atten1 * 448)\n\n    # \u7b2c\u4e00\u5c3a\u5ea6\u5927\u90e8\u5206\u5de5\u4f5c\u5c31\u7ed3\u675f\u4e86\uff0c\u63a5\u4e0b\u6765\u662f\u7b2c\u4e8c\u5c3a\u5ea6\u7684\u5de5\u4f5c\n    # \u7b2c\u4e8c\u5c3a\u5ea6\u4e0e\u7b2c\u4e00\u5c3a\u5ea6\u7c7b\u4f3c\uff0c\u9996\u5148\u5c06\u56fe\u50cf2\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\n    conv5_4_A = self.b2.features[:-1](scaledA_x)\n    # \u4e4b\u540e\u5c06\u7279\u5f81\u63d0\u53d6\u540e\u7684\u56fe\u50cf\u653e\u5165\u5168\u5c40\u6c60\u5316\u5c42(\u7b2c\u4e00\u5206\u652f)\n    pool5_A = self.feature_pool2(conv5_4_A)\n    # \u5c06\u7279\u5f81\u63d0\u53d6\u540e\u7684\u56fe\u50cf\u653e\u5165APN2\u51fd\u6570\uff0c\u518d\u751f\u6210\u6ce8\u610f\u529b\u533a\u57df\n    atten2 = self.apn2(conv5_4_A.view(-1, 512 * 14 * 14))\n    # \u518d\u5c06\u56fe\u50cf2\u8fdb\u884c\u88c1\u526a\uff0c\u751f\u6210\u7528\u4e8e\u7b2c\u4e09\u5c3a\u5ea6\u5b66\u4e60/\u9884\u6d4b\u7684\u6ce8\u610f\u529b\u533a\u57df(\u56fe\u50cf3)\n    scaledAA_x = self.crop_resize(scaledA_x, atten2 * 224)\n\n    # \u7b2c\u4e09\u5c3a\u5ea6\u53ea\u6709\u7279\u5f81\u63d0\u53d6\u64cd\u4f5c\uff0c\u5c06\u56fe\u50cf3\u653e\u5165\u7279\u5f81\u63d0\u53d6\u5c42\uff0c\u751f\u6210\u7279\u5f81\u56fe\n    # \u518d\u5c06\u7279\u5f81\u56fe\u7ecf\u8fc7\u4e00\u5c42\u5168\u5c40\u6c60\u5316\u64cd\u4f5c\uff0c\u7528\u4e8e\u8f93\u5165\u5230\u540e\u9762\u7684\u5168\u8fde\u63a5\u5c42\n    pool5_AA = self.feature_pool2(self.b3.features[:-1](scaledAA_x))\n\n    # \u5c06\u4e09\u4e2a\u5c3a\u5ea6\u5168\u5c40\u6c60\u5316\u5f97\u5230\u7684\u6570\u636e\u53d8\u5f62\uff0c\u53d8\u4e3aN\u884c512\u5217\u7684\u6570\u7ec4\n    pool5 = pool5.view(-1, 512)\n    pool5_A = pool5_A.view(-1, 512)\n    pool5_AA = pool5_AA.view(-1, 512)\n    # \u6700\u540e\u5c06\u6570\u7ec4\u4f20\u5165\u5168\u8fde\u63a5\u5c42\u8fdb\u884c\u5206\u7c7b\u9884\u6d4b\n    logits1 = self.classifier1(pool5)\n    logits2 = self.classifier2(pool5_A)\n    logits3 = self.classifier3(pool5_AA)\n    # \u8fd4\u56de\u4e09\u4e2a\u5c3a\u5ea6\u7684\u9884\u6d4b\u6982\u7387\u3001\u7279\u5f81\u56fe\u6570\u636e\u3001\u6ce8\u610f\u529b\u5efa\u8bae\u6570\u636e(\u7528\u4e8e\u5b9a\u4f4d\u7684\u5750\u6807)\u3001\u7ecf\u8fc7\u88c1\u526a\u5f97\u5230\u7684\u6ce8\u610f\u529b\u533a\u57df\n    return [logits1, logits2, logits3], [conv5_4, conv5_4_A], [atten1, atten2], [scaledA_x, scaledAA_x]\n</code></pre> <p>\u5728\u8fd4\u56de\u7684\u6570\u636e\u4e2d\uff0c\u4e09\u4e2a\u5c3a\u5ea6\u7684\u9884\u6d4b\u6982\u7387\u7528\u4e8e\u6700\u7ec8\u7684\u7269\u4f53\u79cd\u7c7b\u9884\u6d4b\u3001\u7279\u5f81\u56fe\u6570\u636e\u4e0e\u6ce8\u610f\u529b\u5efa\u8bae\u6570\u636e\u7528\u4e8eAPN\u53c2\u6570\u7684\u9884\u8bad\u7ec3\uff0c\u7ecf\u8fc7\u88c1\u526a\u5f97\u5230\u7684\u6ce8\u610f\u529b\u533a\u57df\u53ef\u7528\u4e8e\u6700\u540e\u7684\u9a8c\u8bc1\u3002</p>"},{"location":"fine-grained/code/RA-CNN2/#attentioncropfunction","title":"AttentionCropFunction\u88c1\u526a\u51fd\u6570","text":"<p>\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b</p> <pre><code>def forward(self, images, locs):\n    # \u63d0\u524d\u6784\u5efa\u597dh\u51fd\u6570\uff0c\u7528\u4e8e\u5f97\u5230\u88c1\u526a\u63a9\u6a21\n    h = lambda x: 1. / (1. + torch.exp(-10. * x))\n    in_size = images.size()[2]\n    unit = torch.stack([torch.arange(0, in_size)] * in_size).float()\n    x = torch.stack([unit.t()] * 3)\n    y = torch.stack([unit] * 3)\n    if isinstance(images, torch.cuda.FloatTensor):\n        # isinstance() \u51fd\u6570\u6765\u5224\u65ad\u4e00\u4e2a\u5bf9\u8c61\u662f\u5426\u662f\u4e00\u4e2a\u5df2\u77e5\u7684\u7c7b\u578b,\u5224\u65adimages\u662f\u5426\u662fcuda.FloatTensor\u7c7b\u578b\n        x, y = x.cuda(), y.cuda()\n\n    in_size = images.size()[2]\n    ret = []\n    # \u6309batch_size\u904d\u5386\n    for i in range(images.size(0)):\n        tx, ty, tl = locs[i][0], locs[i][1], locs[i][2]\n        tl = tl if tl &gt; (in_size/3) else in_size/3\n        # \u5bf9\u7a97\u53e3\u957f\u5ea6\u8fdb\u884c\u4fee\u6b63\uff0c\u9650\u5236tl\u4e0d\u80fd\u8fc7\u5c0f\uff0c\u6700\u5c0f\u662fin_size/3\n        # \u5982\u679c\u8ddd\u79bb\u8fc7\u5c0f\u7684\u8bdd\uff0c\u4f1a\u5bfc\u81f4\u88c1\u526a\u5f97\u5230\u7684\u7a97\u53e3\u5f88\u5c0f\uff0c\u5bb9\u6613\u4e22\u5931\u4fe1\u606f\n        tx = tx if tx &gt; tl else tl\n        # tx\u5fc5\u987b\u5927\u4e8etl\uff0c\u5373\u4e0d\u80fd\u5de6\u51fa\u754c\n        tx = tx if tx &lt; in_size-tl else in_size-tl\n        # \u88c1\u526a\u4e0d\u80fd\u53f3\u8d85\u754c\uff0c\u53ea\u80fd\u88c1\u5230\u5934\n        ty = ty if ty &gt; tl else tl\n        #\u7c7b\u4f3ctx\uff0c\u4fee\u6b63ty\uff0c\u4e0d\u80fd\u4e0a\u51fa\u754c\n        ty = ty if ty &lt; in_size-tl else in_size-tl\n        # \u4e0d\u80fd\u4e0b\u51fa\u754c\n\n        # \u4e0b\u9762\u5b9a\u4e49\u77e9\u5f62\u56db\u4e2a\u89d2\n        w_off = int(tx-tl) if (tx-tl) &gt; 0 else 0\n        h_off = int(ty-tl) if (ty-tl) &gt; 0 else 0\n        w_end = int(tx+tl) if (tx+tl) &lt; in_size else in_size\n        h_end = int(ty+tl) if (ty+tl) &lt; in_size else in_size\n        # \u5f97\u5230\u63a9\u6a21\u77e9\u9635mk\n        mk = (h(x-w_off) - h(x-w_end)) * (h(y-h_off) - h(y-h_end))\n        # \u70b9\u4e58\uff0c\u5f97\u5230\u88c1\u526a\u540e\u7684\u56fe\u7247\n        xatt = images[i] * mk\n\n        # \u53ea\u7559\u4e0b\u88c1\u526a\u540e\u7684\u56fe\u50cf\n        xatt_cropped = xatt[:, w_off:w_end, h_off:h_end]\n        # \u91c7\u6837\u4e4b\u524d\u5148\u6269\u7ef4\n        before_upsample = Variable(xatt_cropped.unsqueeze(0))\n        # \u91c7\u6837\uff0c\u89c4\u8303\u88c1\u526a\u540e\u56fe\u50cf\u7684\u5927\u5c0f\n        xamp = F.interpolate(before_upsample, size=(224,224), mode='bilinear', align_corners = True)\n        # \u518d\u538b\u7f29\uff0c\u4fbf\u4e8e\u540e\u671f\u7684\u62fc\u63a5\n        ret.append(xamp.data.squeeze())\n    # \u5c06batch_size\u6240\u6709\u7684\u56fe\u50cf\u62fc\u63a5\u8d77\u6765\uff0c\u4fbf\u4e8e\u540e\u7eed\u8fd4\u56de\n    ret_tensor = torch.stack(ret)\n    self.save_for_backward(images, ret_tensor)\n    # \u8fd4\u56de\u88c1\u526a\u540e\u7684\u56fe\u50cf\n    return ret_tensor\n</code></pre>"},{"location":"fine-grained/code/RA-CNN2/#_4","title":"\u635f\u5931\u51fd\u6570","text":"<p>\u5c3a\u5ea6\u5185\u5206\u7c7b\u635f\u5931\uff0c\u4e09\u4e2a\u5c3a\u5ea6\u6c42\u548c $$ L_1=\\sum^3_{s=1}L_{cls}(Y^{(s)},Y^*) $$  \u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\u53ef\u4ee5\u76f4\u63a5\u901a\u8fc7<code>torch.nn.functional</code>\u8c03\u7528</p> <pre><code>def multitask_loss(preds, labels):\n    loss = []\n    # \u904d\u5386\u6279\u6b21(batch_size)\n    for i in range(len(preds)):\n        # \u4f1a\u5f97\u5230\u4e09\u4e2a\u635f\u5931\uff0c\u6bcf\u4e2a\u635f\u5931\u5bf9\u5e94\u8be5\u5c3a\u5ea6\u4e0a\u7684\u5206\u7c7b\u635f\u5931\n        loss.append(F.cross_entropy(preds[i], labels))\n    return loss\n</code></pre> <p>\u5c3a\u5ea6\u95f4\u6210\u5bf9\u6392\u5e8f\u635f\u5931 $$ L_2=\\sum^2_{s=1}{L_{rank}(p^{s}_t,p^{(s+1)}_t)} $$  \u5176\u4e2d $$ L_{rank}(p^{s}_t,p^{(s+1)}_t)=max\\{0,p^{s}_t-p^{(s+1)}_t+margin\\} $$ </p> <pre><code>def pairwise_ranking_loss(preds, size_average = True):\n    \"\"\"\n    \u8f93\u5165preds\uff1a\u6bcf\u4e2a\u5c3a\u5ea6\u5bf9\u5e94labels\u7684\u9884\u6d4b\u503c\n    \u5982\u679c\u6709\u4e09\u4e2a\u5c3a\u5ea6\uff0c\u7b2c\u4e8c\u7ef4\u5ea6\u5c31\u662f3\n    preds = [logits1[class], logits2[class], logits2[class]]\n    \"\"\"\n    if len(preds[0]) &lt;= 1:\n        # preds\u7b2c\u4e00\u7ef4\u5ea6\u4ee3\u8868\u6279\u91cf\uff0c\u7b2c\u4e8c\u7ef4\u5ea6\u4ee3\u8868\u5c3a\u5ea6\n        # \u5982\u679c\u53ea\u6709\u4e00\u4e2a\u5c3a\u5ea6\uff0c\u5219\u4e0d\u5b58\u5728\u5c3a\u5ea6\u95f4\u6210\u5bf9\u6392\u5e8f\u635f\u5931\uff0c\u8fd4\u56de\u96f6\n        return torch.zeros(1).cuda()\n    else:\n        losses = []\n        for pred in preds:\n            # \u6309\u6279\u91cf\u8fdb\u884c\u904d\u5386\n            loss = []\n            for i in range(len(pred)-1):\n                rank_loss = (pred[i]-pred[i+1] + 0.05).clamp(min = 0)\n                # margin\u8bbe\u4e3a0.05\n                # \u524d\u540e\u4e24\u4e2a\u5c3a\u5ea6\u7684\u9884\u6d4b\u6982\u7387\u505a\u5dee\uff0c\u518d\u52a0\u4e0a\u9608\u503c\n                # clamp\u51fd\u6570\u76f8\u5f53\u4e8e\u5c06\u6570\u7ec4\u89c4\u5b9a\u5728\u67d0\u8303\u56f4\u5185\n                # \u8fd9\u91cc\u4ee3\u8868rank_loss\u6700\u5c0f\u503c\u5982\u679c\u5c0f\u4e8e0\uff0c\u5219\u88ab\u4ece\u65b0\u8d4b\u503c\u4e3a0\n                loss.append(rank_loss)\n                # \u4e24\u4e2a\u5c3a\u5ea6\u5bf9\u635f\u5931\u6c42\u548c\uff0c\u518d\u5e76\u5165\u603b\u635f\u5931\n            loss = torch.sum(torch.stack(loss))\n            losses.append(loss)\n            # \u62fc\u63a5\u8d77\u6765\uff0c\u4fbf\u4e8e\u6c42\u548c\u6216\u6c42\u5e73\u5747\u503c\n        losses = torch.stack(losses)\n        if size_average:\n            # \u662f\u5426\u5bf9\u635f\u5931\u6c42\u5e73\u5747\u503c\n            losses = torch.mean(losses)\n        else:\n            losses = torch.sum(losses)\n        # \u6700\u540e\u8fd4\u56de\u635f\u5931\n        return losses\n</code></pre>"},{"location":"fine-grained/code/RA-CNN2/#_5","title":"\u8bad\u7ec3\u6d41\u7a0b","text":""},{"location":"fine-grained/code/RA-CNN2/#_6","title":"\u540d\u8bcd\u89e3\u91ca\uff1a","text":"<ul> <li><code>cls</code>\uff1a\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u548c\u5168\u8fde\u63a5\u5c42\u53c2\u6570\u7684\u4f18\u5316\u8fc7\u7a0b</li> <li><code>apn</code>\uff1aANP\u6ce8\u610f\u529b\u533a\u57df\u5b9a\u4f4d\u53c2\u6570\u7684\u4f18\u5316\u8fc7\u7a0b</li> <li><code>cls_loss</code>\uff1a<code>cls</code>\u8bad\u7ec3\u8fc7\u7a0b\u7684\u635f\u5931\uff0c\u5bf9\u5e94\u5c3a\u5ea6\u5185\u5206\u7c7b\u635f\u5931</li> <li><code>anp_loss</code>\uff1a<code>anp</code>\u8bad\u7ec3\u8fc7\u7a0b\u7684\u635f\u5931\uff0c\u5bf9\u5e94\u5c3a\u5ea6\u95f4\u6392\u5e8f\u635f\u5931</li> <li><code>cls_iter</code>\uff1acls\u4e0a\u8bad\u7ec3\u6b21\u6570\uff0c\u5373\u53c2\u6570\u66f4\u65b0\u6b21\u6570(\u6bcf\u4e2abatch\u4ee3\u8868\u8bad\u7ec3\u4e00\u6b21)</li> <li><code>cls_epoch</code>\uff1acls\u4e0a\u6570\u636e\u96c6\u904d\u5386\u6b21\u6570</li> <li><code>cls_steps</code>\uff1acls\u4f18\u5316\u5668\u7684\u5b66\u4e60\u7387\u66f4\u65b0\u6b21\u6570</li> <li><code>old_cls_loss</code>\uff1a\u4e0a\u4e00\u6b21\u8bad\u7ec3\uff0ccls\u7684\u635f\u5931(\u65e7\u635f\u5931)</li> <li><code>new_cls_loss</code>\uff1a\u672c\u6b21\u8bad\u7ec3\uff0ccls\u7684\u635f\u5931(\u65b0\u635f\u5931)(\u7528\u4e8e\u8ba1\u7b97\u635f\u5931\u53d8\u5316)</li> <li><code>cls_tol</code>\uff1acls\u635f\u5931\u65e0\u53d8\u5316\u7684\u6b21\u6570(\u53d8\u5316\u5c0f\u4e8e\u67d0\u9608\u503c)</li> </ul> <p>\u5c06<code>cls</code>\u6362\u6210<code>anp</code>\uff0c\u5f62\u6210\u7684\u540d\u8bcd\u4e0e\u539f\u6765\u7684\u540d\u8bcd\u4ee3\u8868\u542b\u4e49\u7c7b\u4f3c\uff0c\u53ea\u662f\u6362\u4e86\u4e2a\u4f18\u5316\u5206\u652f\uff0c\u6362\u5230\u4e86APN\u7684\u4f18\u5316\u8fd9\u4e00\u5206\u652f</p> <ul> <li><code>iteration</code>\uff1a\u603b\u7684\u8bad\u7ec3\u6b21\u6570(\u53c2\u6570\u66f4\u65b0\u6b21\u6570)</li> <li><code>switch_step</code>\uff1a\u4e24\u4e2a\u8fc7\u7a0b\u7684\u4ea4\u66ff\u6b21\u6570</li> </ul>"},{"location":"fine-grained/code/RA-CNN2/#_7","title":"\u8bad\u7ec3\u521d\u59cb\u5316\u8fc7\u7a0b","text":"<pre><code># \u5b9a\u4e49\u4e00\u7cfb\u5217\u53ef\u53d8\u53c2\u6570\nparser = argparse.ArgumentParser(description = 'Training arguments')\nparser.add_argument('--cuda', default = True, type = bool, help = \"use cuda to train\")\nparser.add_argument('--lr', default = 0.01, type = float, help = \"initial learning rate\")\nnum_classes = 200\n# \u5b9a\u4e49\u6a21\u578b\nnet = RACNN(num_classes = num_classes)\n# \u5b9a\u4e49\u65e5\u5fd7\nlogger = Logger('./visual/' + 'CUB')\n</code></pre> <p>\u5b9a\u4e49\u4f18\u5316\u5668</p> <pre><code># \u7b2c\u4e00\u6761\u4f18\u5316\u8def\u7ebf\uff0c\u4f18\u5316\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u4ee5\u53ca\u5206\u7c7b\u5668(\u5168\u8fde\u63a5\u5c42)\ncls_params = list(net.b1.parameters()) + list(net.b2.parameters()) + list(net.b3.parameters()) + list(net.classifier1.parameters()) + list(net.classifier2.parameters()) + list(net.classifier3.parameters())\n\nopt1 = optim.SGD(cls_params, lr = args.lr, momentum = 0.9, weight_decay = 0.0005)\n# \u7b2c\u4e8c\u6761\u4f18\u5316\u8def\u7ebf\uff0c\u4f18\u5316\u5b9a\u4f4d\u6ce8\u610f\u529b\u533a\u57df\u7684\u53c2\u6570(APN)\napn_params = list(net.apn1.parameters()) + list(net.apn2.parameters())\n\nopt2 = optim.SGD(apn_params, lr = args.lr, momentum = 0.9, weight_decay = 0.0005)\n</code></pre> <p>\u4ee5\u4e0a\u5747\u662f\u5b9a\u4e49\u7684\u5168\u5c40\u53d8\u91cf</p> <p>\u8bfb\u53d6\u6570\u636e\u96c6</p> <pre><code>trainset = CUB200_loader(os.getcwd() + '/data/CUB_200_2011', split = 'train')\ntrainloader = data.DataLoader(trainset, batch_size = 4,\n        shuffle = True, collate_fn = trainset.CUB_collate, num_workers = 4)\ntestset = CUB200_loader(os.getcwd() + '/data/CUB_200_2011', split = 'test')\ntestloader = data.DataLoader(testset, batch_size = 4,\n        shuffle = False, collate_fn = testset.CUB_collate, num_workers = 4)\n</code></pre>"},{"location":"fine-grained/code/RA-CNN2/#apn","title":"APN\u7684\u9884\u8bad\u7ec3","text":"<pre><code>apn_iter, apn_epoch, apn_steps = pretrainAPN(trainset, trainloader)\n</code></pre> <p>\u9884\u8bad\u7ec3\u8fc7\u7a0b</p> <pre><code>def pretrainAPN(trainset, trainloader):\n    epoch_size = len(trainset) // 4\n    # \u8fd9\u91cc\u76844\u4ee3\u8868batch_size=4\uff0c\u53ef\u4ee5\u66ff\u6362\n    apn_steps, apn_epoch = 1, -1\n    # \u5c06trainloader\u751f\u6210\u8fed\u4ee3\u5668\n    batch_iterator = iter(trainloader)\n    for _iter in range(0, 20000):\n        iteration = _iter\n        # \u5f53\u524d\u7684\u66f4\u65b0\u6b21\u6570\n        if (not batch_iterator) or (iteration % epoch_size == 0):\n            # \u4ee3\u8868\u904d\u5386\u4e86\u4e00\u4e2abatch\n            batch_iterator = iter(trainloader)\n\n        if iteration % epoch_size == 0:\n            # \u904d\u5386\u4e86\u4e00\u4e2abatch\u65f6\uff0c\u8bb0\u5f55\u6b21\u6570\uff0c\u901a\u8fc7\u8be5\u6b21\u6570\u66f4\u65b0\u5b66\u4e60\u7387\n            apn_epoch += 1\n            if apn_epoch in decay_steps:\n                # \u5982\u679c\u5230\u4e86\u8bbe\u5b9a\u597d\u7684\u6b21\u6570\uff0c\u5c31\u66f4\u65b0\u4e00\u6b21\n                apn_steps += 1\n                adjust_learning_rate(opt2, 0.1, apn_steps, args.lr)\n        # \u8bfb\u53d6\u56fe\u7247\u548c\u6807\u7b7e\n        images, labels = next(batch_iterator)\n        images, labels = Variable(images, requires_grad = True), Variable(labels)\n        if args.cuda:\n            images, labels = images.cuda(), labels.cuda()\n\n        t0 = time.time()\n        # \u9884\u6d4b\uff0c\u5f97\u5230\u7279\u5f81\u56fe\u548c\u6ce8\u610f\u529b\u533a\u57df\u5b9a\u4f4d\u70b9\n        _, conv5s, attens, _ = net(images)\n\n        opt2.zero_grad()\n        # \u5728\u7279\u5f81\u56fe\u4e2d\u5bfb\u627e\u54cd\u5e94\u503c\u6700\u9ad8\u7684\u533a\u57df\n        weak_loc = []\n        for i in range(len(conv5s)):\n            # \u4e24\u4e2a\u5c3a\u5ea6\u7684\u7279\u5f81\u56fe\n            loc_label = torch.ones([images.size(0),3]) * 0.33 \n            # (\u6279\u91cf\uff0c\u5b9a\u4f4d\u70b9)\n            # 0.33\u4ee3\u8868\u5f52\u4e00\u5316\u540e\u7684\u8fb9\u957f\uff0cloc_label\u5177\u4f53\u610f\u4e49\u89c1\u4e0b\u9762\u4ee3\u7801\n            # tl = 0.25, fixed\n            resize = 448\n            if i &gt;= 1:\n                resize = 224\n            if args.cuda:\n                loc_label = loc_label.cuda()\n            for j in range(images.size(0)):\n                # batch\u904d\u5386\n                # \u7b2ci\u5c3a\u5ea6\u7684j\u6279\u91cf\n                response_map = conv5s[i][j]\n                # \u4e0a\u91c7\u6837\u653e\u5927\n                response_map = F.interpolate(response_map.unsqueeze(0), size = [resize, resize]).squeeze(0)\n                # \u5bf9\u7279\u5f81\u56fe\u6309\u7b2c\u4e00\u7ef4\u5ea6\u6c42\u5747\u503c(\u6bcf\u5f20\u56fe\u90fd\u6c42\u4e00\u6b21\u5747\u503c)\n                # \u5f97\u5230448*448\u7684\u77e9\u9635\n                response_map = response_map.mean(0)\n                # \u7279\u5f81\u56fe\u5148\u8f6c\u5316\u6210\u5411\u91cf\uff0c\u7136\u540e\u5f97\u5230\u6700\u5927\u503c(\u54cd\u5e94\u503c\u6700\u5927)\u7684\u4f4d\u7f6e(\u5373\u7d22\u5f15)\n                rawmaxidx = response_map.view(-1).max(0)[1]\n\n                idx = []\n                # \u524d\u9762\u5f97\u5230\u4e86\u54cd\u5e94\u503c\u5904\u6700\u5927\u7684\u7d22\u5f15\uff0c\u4f46\u53ea\u662f\u4e00\u4e2a\u5e8f\u53f7\u503c\n                # \u4e0b\u9762\u901a\u8fc7\u8fd0\u7b97\uff0c\u5c06\u5e8f\u53f7\u8f6c\u5316\u6210\u4e24\u70b9\u5750\u6807\n                for d in list(response_map.size())[::-1]:\n                    # d:448-&gt;448\uff0c\u5206\u522b\u4ee3\u8868\u5217\u5bbd\u548c\u884c\u9ad8\n                    idx.append(rawmaxidx % d)\n                    rawmaxidx = rawmaxidx / d\n                # \u7531\u4e8eANP\u5f97\u5230\u7684\u5750\u6807\u5c31\u662f\u5f52\u4e00\u5316\u4e4b\u540e\u7684\u5750\u6807(\u6700\u540e\u7ecf\u8fc7\u4e86sigmoid)\n                # \u56e0\u6b64\uff0c\u8fd9\u91cc\u4e5f\u9700\u8981\u5c06\u5f97\u5230\u7684\u5750\u6807\u8fdb\u884c\u5f52\u4e00\u5316\n                loc_label[j, 0] = (idx[1].float() + 0.5) / response_map.size(0)\n                loc_label[j, 1] = (idx[0].float() + 0.5) / response_map.size(1)\n                # loc_label\u91cc\u7684\u7b2c\u4e00\u4e8c\u4e2a\u503c\u5206\u522b\u4ee3\u8868\u54cd\u5e94\u503c\u6700\u9ad8\u7684\u6a2a\u5750\u6807\u548c\u7eb5\u5750\u6807\n                # \u7b2c\u4e09\u4e2a\u503c\u524d\u9762\u5df2\u7ecf\u5b9a\u597d\uff0c\u4e3a0.33\uff0c\u4ee3\u8868\u6b63\u65b9\u5f62\u8fb9\u957f\u7684\u4e00\u534a\n            # loc_label\u91cc\u9762\u7684\u4e09\u4e2a\u503c\u4ee3\u8868\u4e86\u54cd\u5e94\u503c\u9ad8\u7684\u533a\u57df\n            weak_loc.append(loc_label)\n        # smooth_l1_loss\u4e3a\u5e73\u6ed1\u540e\u7684\u7edd\u5bf9\u503c\u635f\u5931\u51fd\u6570\n        # loss1\u548closs2\u5206\u522b\u4ee3\u8868\u4e24\u4e2a\u5c3a\u5ea6\u7684\u635f\u5931(\u5750\u6807\u504f\u5dee)\n        weak_loss1 = F.smooth_l1_loss(attens[0], weak_loc[0])\n        weak_loss2 = F.smooth_l1_loss(attens[1], weak_loc[1])\n        # \u8ba9\u9884\u6d4b\u7684attens\u6240\u5728\u7684\u533a\u57df\uff0c\u548c\u7ecf\u8fc7VGG\u7279\u5f81\u63d0\u53d6\u540e\u54cd\u5e94\u6700\u5927\u7684\u533a\u57df(\u957f\u5bbd\u5747\u4e3a\u539f\u6765\u7684\u4e00\u534a)\u505a\u635f\u5931\u5bf9\u6bd4\n        # \u5373\uff0c\u8ba9attens\u8d8b\u4e8eVGG\u7279\u5f81\u63d0\u53d6\u540e\u7f51\u7edc\u5173\u6ce8\u7684\u90e8\u5206\n        apn_loss = weak_loss1 + weak_loss2\n        apn_loss.backward()\n        opt2.step()\n        # \u53c2\u6570\u66f4\u65b0\n        t1 = time.time()\n\n        if (iteration % 20) == 0:\n            print(\" [*] pre_apn_epoch[%d], || pre_apn_iter %d || pre_apn_loss: %.4f || Timer: %.4fsec\"%(apn_epoch, iteration, apn_loss.item(), (t1 - t0)))\n\n        logger.scalar_summary('pre_apn_loss', apn_loss.item(), iteration + 1)\n\n    return 20000, apn_epoch, apn_steps\n# 20000\u4ee3\u8868\u8bad\u7ec3\u4e8620000\u6b21\n</code></pre>"},{"location":"fine-grained/code/RA-CNN2/#_8","title":"\u4ea4\u66ff\u8bad\u7ec3","text":"<p>\u7d27\u8ddfAPN\u7684\u9884\u8bad\u7ec3\uff0c\u9996\u5148\u521d\u59cb\u5316\u53c2\u6570</p> <pre><code># cls_iter\u662f\u8bad\u7ec3\u6b21\u6570\uff0ccls_epoch\u662f\u6570\u636e\u96c6\ncls_iter, cls_epoch, cls_steps = 0, 0, 1\n\nswitch_step = 0\nold_cls_loss, new_cls_loss = 2, 1\nold_apn_loss, new_apn_loss = 2, 1\niteration = 0\nepoch_size = len(trainset) // 4 # (4\u4ee3\u8868batch_size)\ncls_tol = 0\napn_tol = 0\nbatch_iterator = iter(trainloader)\n</code></pre> <p>\u63a5\u4e0b\u6765\u8fdb\u884c\u4ea4\u66ff\uff0c\u5f53\u5206\u7c7b\u635f\u5931\u548c\u6ce8\u610f\u529b\u5b9a\u4f4d\u635f\u5931\u4e0d\u53d8(\u53d8\u5316\u5c0f\u4e8e\u7ed9\u5b9a\u7684\u9608\u503c)\u65f6\uff0c\u505c\u6b62\u8bad\u7ec3\u3002\u4e24\u7ec4\u53c2\u6570\u8bad\u7ec3\u4f18\u5316\u7684\u8fc7\u7a0b\u7c7b\u4f3c\uff0c\u5dee\u522b\u5c31\u5728\u4e8e\u635f\u5931\u7684\u8ba1\u7b97\u65b9\u6cd5\u4e0d\u540c\u4ee5\u53ca\u4f7f\u7528\u7684\u4f18\u5316\u5668\u4e0d\u540c\uff0c\u56e0\u6b64\u4e0b\u6587\u53ea\u5bf9cls\u7684\u8bad\u7ec3\u8fc7\u7a0b\u52a0\u4ee5\u6ce8\u91ca\u8bf4\u660e\u3002</p> <p>\u5c3a\u5ea6\u5185\u5206\u7c7b\u635f\u5931\uff1a\u53ea\u9700\u8981\u5f97\u5230\u5404\u4e2a\u5c3a\u5ea6\u7684\u9884\u6d4b\u6982\u7387\uff0c\u7136\u540e\u8ba1\u7b97\u4ea4\u53c9\u71b5\u635f\u5931 \u5c3a\u5ea6\u95f4\u6210\u5bf9\u6392\u5e8f\u635f\u5931\uff1a\u5148\u63d0\u53d6\u6bcf\u4e2a\u5c3a\u5ea6\u7684\u9884\u6d4b\u7ed3\u679c\u4e2d\uff0clabel\u7684\u6982\u7387\uff0c\u7136\u540e\u518d\u5c06\u4e0d\u540c\u5c3a\u5ea6\u7684\u6982\u7387\u7ed3\u679c\u52a0\u4ee5\u8ba1\u7b97\uff0c\u5f97\u5230\u635f\u5931\uff0c\u6700\u7ec8\u7528\u6765\u4f18\u5316</p> <p>\u4ea4\u66ff\u8bad\u7ec3\u6d41\u7a0b\u5982\u4e0b\uff1a</p> <pre><code>while ((old_cls_loss - new_cls_loss)**2 &gt; 1e-7) and ((old_apn_loss - new_apn_loss)**2 &gt; 1e-7) and (iteration &lt; 500000):\n    # until the two type of losses no longer change\n    print(' [*] Swtich optimize parameters to Class')\n    while ((cls_tol &lt; 10) and (cls_iter % 5000 != 0)):\n        # \u5f53\u8bad\u7ec3\u635f\u5931\u8fde\u7eed10\u6b21\u53d8\u5316\u6d6e\u52a8\u5c0f\u4e8e\u67d0\u4e2a\u9608\u503c(\u8fd9\u91cc\u8bbe\u4e3a1e-6)\n        # \u6216\u8005\u8bad\u7ec3\u6b21\u6570\u8fbe\u52305000\u6b21\uff0c\u5c31\u8df3\u8fc7\u7279\u5f81\u63d0\u53d6\u548c\u5206\u7c7b\u7684\u4f18\u5316\n        # \u8f6c\u5230\u4f18\u5316ANP\n        if (not batch_iterator) or (iteration % epoch_size == 0):\n            # \u5982\u679ctrainloader\u88ab\u904d\u5386\u5b8c(\u8bad\u7ec3\u96c6\u88ab\u5b8c\u6574\u5730\u904d\u5386\u4e86\u4e00\u6b21)\n            # \u5c31\u66f4\u65b0\u4e00\u6b21trainloader\n            batch_iterator = iter(trainloader)\n        if cls_iter % epoch_size == 0:\n            cls_epoch += 1\n            # \u6570\u636e\u96c6\u904d\u5386\u6b21\u6570\n            if cls_epoch in decay_steps:\n                cls_steps += 1\n                # cls_steps\u5b66\u4e60\u7387\u66f4\u65b0\u6b21\u6570\n                adjust_learning_rate(opt1, 0.1, cls_steps, args.lr)\n        # \u635f\u5931\u66f4\u65b0\n        old_cls_loss = new_cls_loss\n        # \u8bfb\u53d6\u6570\u636e\u96c6\n        images, labels = next(batch_iterator)\n        images, labels = Variable(images, requires_grad = True), Variable(labels)\n        if args.cuda:\n            images, labels = images.cuda(), labels.cuda()\n\n        t0 = time.time()\n        # \u9884\u6d4b\uff0c\u5f97\u5230\u5206\u7c7b\u6982\u7387\uff0c\u7528\u4e8e\u4f18\u5316\u7f51\u7edc\n        logits, _, _, _ = net(images)\n\n        opt1.zero_grad()\n        # \u5206\u522b\u8ba1\u7b97\u4e09\u4e2a\u5c3a\u5ea6\u6700\u540e\u9884\u6d4b\u7ed3\u679c\u7684\u5c3a\u5ea6\u95f4\u5206\u7c7b\u635f\u5931\n        new_cls_losses = multitask_loss(logits, labels)\n        # \u6c42\u548c\uff0c\u5f97\u5230\u603b\u635f\u5931\n        new_cls_loss = sum(new_cls_losses)\n        # \u53cd\u5411\u4f20\u64ad\uff0c\u8ba1\u7b97\u68af\u5ea6\n        new_cls_loss.backward()\n        # \u66f4\u65b0\u53c2\u6570\n        opt1.step()\n        t1 = time.time()\n        # \u6bd4\u8f83\u635f\u5931\u662f\u5426\u6709\u53d8\u5316\n        # cls_tol\u4ee3\u8868cls\u635f\u5931\u8fde\u7eed\u672a\u53d8\u5316\u7684\u6b21\u6570\n        if (old_cls_loss - new_cls_loss)**2 &lt; 1e-6:\n            cls_tol += 1\n        else:\n            cls_tol = 0\n        # \u8bb0\u5f55\u65e5\u5fd7\n        logger.scalar_summary('cls_loss', new_cls_loss.item(), iteration + 1)\n        logger.scalar_summary('cls_loss1', new_cls_losses[0].item(), iteration + 1)\n        logger.scalar_summary('cls_loss12', new_cls_losses[1].item(), iteration + 1)\n        logger.scalar_summary('cls_loss123', new_cls_losses[2].item(), iteration + 1)\n        # iteration\u3001cls_iter\u5206\u522b\u4ee3\u8868\u603b\u7684\u8bad\u7ec3\u6b21\u6570\u548ccls\u8bad\u7ec3\u6b21\u6570\n        iteration += 1\n        cls_iter += 1\n        # \u5b9a\u671f\u8f93\u51fa\u635f\u5931\n        if (cls_iter % 20) == 0:\n            print(\" [*] cls_epoch[%d], Iter %d || cls_iter %d || cls_loss: %.4f || Timer: %.4fsec\"%(cls_epoch, iteration, cls_iter, new_cls_loss.item(), (t1 - t0)))\n\n    # cls\u8bad\u7ec3\u5b8c\u6210\u4e4b\u540e\uff0c\u6d4b\u8bd5\u4e00\u4e0b\u5c3a\u5ea6\u95f4\u6392\u5e8f\u635f\u5931,\u5373new_apn_loss\n    # \u8bfb\u6570\u636e\u96c6+\u9884\u6d4b\n    images, labels = next(batch_iterator)\n    if args.cuda:\n        images, labels = images.cuda(), labels.cuda()\n    logits, _, _, _ = net(images)\n    preds = []\n    # \u5c3a\u5ea6\u95f4\u6392\u5e8f\u635f\u5931\u8ba1\u7b97\u65b9\u6cd5\u4e0e\u5c3a\u5ea6\u5185\u5206\u7c7b\u635f\u5931\u8ba1\u7b97\u65b9\u6cd5\u4e0d\u540c\n    # \u5c3a\u5ea6\u95f4\u6392\u5e8f\u635f\u5931\u9700\u8981\u5148\u63d0\u53d6\u6bcf\u4e2a\u5c3a\u5ea6\u7684\u9884\u6d4b\u7ed3\u679c\u4e2d\uff0clabel\u7684\u6982\u7387\n    # \u7136\u540e\u518d\u5c06\u4e0d\u540c\u5c3a\u5ea6\u7684\u6982\u7387\u7ed3\u679c\u52a0\u4ee5\u8ba1\u7b97\uff0c\u5f97\u5230\u635f\u5931\uff0c\u6700\u7ec8\u7528\u6765\u4f18\u5316\n    for i in range(len(labels)):\n        # \u5c06\u6807\u7b7e\u5bf9\u5e94\u7684\u9884\u6d4b\u6982\u7387\u63d0\u53d6\u51fa\u6765\n        pred = [logit[i][labels[i]] for logit in logits]\n        preds.append(pred)\n    new_apn_loss = pairwise_ranking_loss(preds)\n    logger.scalar_summary('rank_loss', new_apn_loss.item(), iteration + 1)\n    iteration += 1\n    # \u5f97\u5230\u5c3a\u5ea6\u5efa\u6392\u5e8f\u635f\u5931\u540e\uff0c\u5728\u8fdb\u5165\u6d4b\u8bd5\u6a21\u5757\uff0c\u6d4b\u8bd5\u6a21\u5757\u89c1\u4e0b\u6587\u4ee3\u7801\u8bb2\u89e3\n    test(testloader, iteration)\n\n\n    print(' [*] Swtich optimize parameters to APN')\n    # \u63a5\u4e0b\u6765\u8fdb\u5165APN\u6a21\u5757\u7684\u53c2\u6570\u4f18\u5316\uff0c\u8fd9\u91cc\u4e0ecls\u7c7b\u4f3c\n    # \u53ea\u662f\u6362\u4e86\u4e00\u79cd\u635f\u5931\u7684\u8ba1\u7b97\u65b9\u6cd5\uff0c\u5e76\u4e14\u6362\u4e86\u4e00\u4e2a\u4f18\u5316\u5668\n    switch_step += 1\n    # \u8fd9\u91cc\u4e0ecls\u8bad\u7ec3\u8fc7\u7a0b\u7c7b\u4f3c\uff0c\u5f53apn_tol\u8fde\u7eed10\u6b21\u53d8\u5316\u9608\u503c\u5c0f\u4e8e1e-6\n    # \u6216\u8005apn\u7684\u8bad\u7ec3\u6b21\u6570\u8fbe\u52305000\u6b21\u65f6\uff0c\u624d\u505c\u6b62\u8bad\u7ec3\n    # \u518d\u5f80\u4e0b\u4e0e\u4e0a\u534a\u9636\u6bb5(cls)\u7c7b\u4f3c\uff0c\u8fd9\u91cc\u4e0d\u5728\u8fc7\u591a\u91cd\u590d\n    while ((apn_tol &lt; 10) and apn_iter % 5000 != 0):\n        if (not batch_iterator) or (iteration % epoch_size == 0):\n            batch_iterator = iter(trainloader)\n\n        if apn_iter % epoch_size == 0:\n            apn_epoch += 1\n            if apn_epoch in decay_steps:\n                apn_steps += 1\n                adjust_learning_rate(opt2, 0.1, apn_steps, args.lr)\n\n        old_apn_loss = new_apn_loss\n\n        images, labels = next(batch_iterator)\n        images, labels = Variable(images, requires_grad = True), Variable(labels)\n        if args.cuda:\n            images, labels = images.cuda(), labels.cuda()\n\n        t0 = time.time()\n        logits, _, _, _ = net(images)\n\n        opt2.zero_grad()\n        preds = []\n        for i in range(len(labels)):\n            # i\u4ee3\u8868\u904d\u5386batch_size\n            pred = [logit[i][labels[i]] for logit in logits]\n            preds.append(pred)\n        new_apn_loss = pairwise_ranking_loss(preds)\n        new_apn_loss.backward()\n        opt2.step()\n        t1 = time.time()\n\n        if (old_apn_loss - new_apn_loss)**2 &lt; 1e-6:\n            apn_tol += 1\n        else:\n            apn_tol = 0\n\n        logger.scalar_summary('rank_loss', new_apn_loss.item(), iteration + 1)\n        iteration += 1\n        apn_iter += 1\n        if (apn_iter % 20) == 0:\n            print(\" [*] apn_epoch[%d], Iter %d || apn_iter %d || apn_loss: %.4f || Timer: %.4fsec\"%(apn_epoch, iteration, apn_iter, new_apn_loss.item(), (t1 - t0)))\n\n    switch_step += 1\n    # \u4e0b\u9762\u6d4b\u8bd5\u7ecf\u8fc7apn\u8bad\u7ec3\u540e\uff0ccls\u7684\u635f\u5931\n    images, labels = next(batch_iterator)\n    if args.cuda:\n        images, labels = images.cuda(), labels.cuda()\n    logits, _, _ = net(images)\n    new_cls_losses = multitask_loss(logits, labels)\n    new_cls_loss = sum(new_cls_losses)\n    logger.scalar_summary('cls_loss', new_cls_loss.item(), iteration + 1)\n    iteration += 1\n    cls_iter += 1\n    apn_iter += 1\n    # \u6d4b\u8bd5\n    test(testloader, iteration)\n    _, _, _, crops = net(test_sample)\n    x1, x2 = crops[0].data, crops[1].data\n    # visualize cropped inputs\uff0c\u8f93\u51fa\u88c1\u526a\u56fe\u7247\n    save_img(x1, path=f'samples/iter_{iteration}@2x.jpg', annotation=f'loss = {avg_loss:.7f}, step = {iteration}')\n    save_img(x2, path=f'samples/iter_{iteration}@4x.jpg', annotation=f'loss = {avg_loss:.7f}, step = {iteration}')\n    # \u4fdd\u5b58\u6a21\u578b\n    torch.save(net.state_dict, 'ckpt/RACNN_vgg_CUB200_iter%d.pth'%iteration)\n</code></pre>"},{"location":"fine-grained/code/RA-CNN2/#_9","title":"\u6d4b\u8bd5\u6d41\u7a0b","text":"<pre><code>def test(testloader, iteration):\n    # \u6a21\u578b\u8c03\u6210\u6d4b\u8bd5\u8fc7\u7a0b\n    net.eval()\n    with torch.no_grad():\n        # corrects\u5206\u522b\u4e3a3\u4e2a\u5c3a\u5ea6\u6b63\u786e\u9884\u6d4b\u7684\u4e2a\u6570\n        corrects1 = 0\n        corrects2 = 0\n        corrects3 = 0\n        # cnt\u4e3a\u6d4b\u8bd5\u96c6\u56fe\u7247\u603b\u6570\n        cnt = 0\n        # \u8bb0\u5f55\u635f\u5931\n        test_cls_losses = []\n        test_apn_losses = []\n        # \u8bfb\u53d6\u6570\u636e\n        for test_images, test_labels in testloader:\n            if args.cuda:\n                test_images = test_images.cuda()\n                test_labels = test_labels.cuda()\n            cnt += test_labels.size(0)\n            # \u9884\u6d4b\uff0c\u5f97\u5230\u6982\u7387\n            logits, _, _, _ = net(test_images)\n\n            preds = []\n            # \u8ba1\u7b97\u5c3a\u5ea6\u5185\u5206\u7c7b\u635f\u5931\u4ee5\u53ca\u5c3a\u5ea6\u95f4\u6392\u5e8f\u635f\u5931\n            for i in range(len(test_labels)):\n                pred = [logit[i][test_labels[i]] for logit in logits]\n                preds.append(pred)\n            test_cls_losses = multitask_loss(logits, test_labels)\n            test_apn_loss = pairwise_ranking_loss(preds)\n            test_cls_losses.append(sum(test_cls_losses))\n            test_apn_losses.append(test_apn_loss)\n            # \u5206\u522b\u5f97\u5230\u9884\u6d4b\u503c\uff0c\u518d\u548clabel\u505a\u6bd4\u8f83\uff0c\u5f97\u5230\u6b63\u786e\u9884\u6d4b\u7684\u4e2a\u6570\n            _, predicted1 = torch.max(logits[0], 1)\n            correct1 = (predicted1 == test_labels).sum()\n            corrects1 += correct1\n            _, predicted2 = torch.max(logits[1], 1)\n            correct2 = (predicted2 == test_labels).sum()\n            corrects2 += correct2\n            _, predicted3 = torch.max(logits[2], 1)\n            correct3 = (predicted3 == test_labels).sum()\n            corrects3 += correct3\n        # \u6700\u540e\u635f\u5931\u505a\u5e73\u5747\n        test_cls_losses = torch.stack(test_cls_losses).mean()\n        test_apn_losses = torch.stack(test_apn_losses).mean()\n        # \u8ba1\u7b97\u51c6\u786e\u7387\n        accuracy1 = corrects1.float() / cnt\n        accuracy2 = corrects2.float() / cnt\n        accuracy3 = corrects3.float() / cnt\n        # \u5199\u5165\u65e5\u5fd7\n        logger.scalar_summary('test_cls_loss', test_cls_losses.item(), iteration + 1)\n        logger.scalar_summary('test_rank_loss', test_apn_losses.item(), iteration + 1)\n        logger.scalar_summary('test_acc1', accuracy1.item(), iteration + 1)\n        logger.scalar_summary('test_acc2', accuracy2.item(), iteration + 1)\n        logger.scalar_summary('test_acc3', accuracy3.item(), iteration + 1)\n        print(\" [*] Iter %d || Test accuracy1: %.4f, Test accuracy2: %.4f, Test accuracy3: %.4f\"%(iteration, accuracy1.item(), accuracy2.item(), accuracy3.item()))\n    # \u7ed3\u675f\u6d4b\u8bd5\uff0c\u6a21\u578b\u8c03\u6210\u8bad\u7ec3\u8fc7\u7a0b\n    net.train()\n</code></pre>"},{"location":"fine-grained/code/RA-CNN2/#_10","title":"\u8865\u5145","text":"<p>save_img\u51fd\u6570\u7684\u5b9a\u4e49\uff0c\u4f4d\u4e8eutils.py\u4e2d</p> <p><pre><code># \u4fdd\u5b58\u5c3a\u5ea6\u56fe\u50cf\ndef save_img(x, path, annotation=''):\n    fig = plt.gcf()  # generate outputs\n    plt.imshow(tensor_to_img(x[0]), aspect='equal'), plt.axis('off'), fig.set_size_inches(448/100.0/3.0, 448/100.0/3.0)\n    plt.gca().xaxis.set_major_locator(plt.NullLocator()), plt.gca().yaxis.set_major_locator(plt.NullLocator()), plt.subplots_adjust(top=1, bottom=0, left=0, right=1, hspace=0, wspace=0), plt.margins(0, 0)\n    plt.text(0, 0, annotation, color='white', size=4, ha=\"left\", va=\"top\", bbox=dict(boxstyle=\"square\", ec='black', fc='black'))\n    plt.savefig(path, dpi=300, pad_inches=0)    # visualize masked image\n\ndef tensor_to_img(x, imtype=np.uint8):\n   # \u56fe\u50cf\u7684\u5747\u503c\u548c\u65b9\u5dee\uff0c\u7528\u4e8e\u53cd\u6807\u51c6\u5316\uff0c\u53ef\u4ee5\u4fee\u6539\n   mean = [109.97 / 255., 127.34 / 255., 123.88 / 255.]\n   std = [1. / 255., 1. / 255., 1. / 255.]\n\n   if not isinstance(x, np.ndarray):\n      if isinstance(x, torch.Tensor):  # get the data from a variable\n         image_tensor = x.data\n      else:\n         return x\n      image_numpy = image_tensor.cpu().float().numpy()  # convert it into a numpy array\n      if image_numpy.shape[0] == 1:  # grayscale to RGB\n         image_numpy = np.tile(image_numpy, (3, 1, 1))\n      for i in range(len(mean)):\n         # \u53cd\u6807\u51c6\u5316(\u6807\u51c6\u5316\u7684\u53cd\u8fd0\u7b97)\n         image_numpy[i] = image_numpy[i] * std[i] + mean[i]\n      # \u518d\u4e58\u56de\u5230255\u7684\u6807\u51c6\u91cf\u7eb2\uff0c\u8fd4\u56de\u5230\u6b63\u5e38\u56fe\u50cf\n      image_numpy = image_numpy * 255\n      # \u4ea4\u6362\u6570\u7ec4\u7684\u7ef4\u5ea6\uff0c0,1,2-&gt;1,2,0\uff0c\u53733,448,448-&gt;448,448,3(\u8f6c\u5316\u6210cv2\u7684\u683c\u5f0f)\n      image_numpy = np.transpose(image_numpy, (1, 2, 0))  # post-processing: tranpose and scaling\n   else:  # if it is a numpy array, do nothing\n      image_numpy = x\n   return image_numpy.astype(imtype)\n</code></pre> \u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u5927\u5bb6\u6279\u8bc4\u6307\u6b63\u3002</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e749\u670824\u65e5</p>"},{"location":"fine-grained/code/S3N2/","title":"\u7ec6\u7c92\u5ea6\uff1aS3N","text":""},{"location":"fine-grained/code/S3N2/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aIEEE International Conference on Computer Vision 2019 (ICCV, 2019)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttp://openaccess.thecvf.com/content_ICCV_2019/papers/Ding_Selective_Sparse_Sampling_for_Fine-Grained_Image_Recognition_ICCV_2019_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740(PyTorch\u7248\u672c)\uff1ahttps://github.com/Yao-DD/S3N</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u7c7b(FGVC)</p> <p>\u5173\u952e\u8bcd\uff1a\u7ec6\u7c92\u5ea6\u8bc6\u522b\u3001\u663e\u8457\u6027\u91c7\u6837</p>"},{"location":"fine-grained/code/S3N2/#s3n_1","title":"S3N\u7f51\u7edc\u7ed3\u6784","text":""},{"location":"fine-grained/code/S3N2/#_2","title":"\u521d\u59cb\u5316\u9636\u6bb5","text":"<pre><code>def __init__(self, base_model, num_classes, task_input_size, base_ratio, radius, radius_inv):\n    super(S3N, self).__init__()\n    # \u91c7\u7528\u56fe\u7684\u5c3a\u5bf8\n    self.grid_size = 31\n    # \u7528\u4e8e\u5bf9\u91c7\u6837\u56fe\u7684\u586b\u5145\n    self.padding_size = 30\n    # \u91c7\u6837\u56fe\u7ecf\u8fc7\u6269\u5145\u540e\u7684\u957f\u5bbd\u5c3a\u5bf8\n    self.global_size = self.grid_size + 2*self.padding_size\n    # \u56fe\u7247\u8f93\u5165\u7684\u5c3a\u5bf8\uff0c\u9ed8\u8ba4448\n    self.input_size_net = task_input_size\n    # \u9ad8\u65af\u6838\uff0c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f(8)\u4e2d\u7684k\n    gaussian_weights = torch.FloatTensor(makeGaussian(2*self.padding_size+1, fwhm = 13))\n    # \u57fa\u7840\u7684\u5e45\u5ea6\n    self.base_ratio = base_ratio\n    # radius\u4e0eradius_inv\u4e3a\u4e24\u4e2a\u53ef\u5b66\u4e60\u7684\u53c2\u6570\uff0c\u5bf9\u5e94\u8bba\u6587\u4e2d\u516c\u5f0f(5)\u91cc\u7684\u03b21,\u03b22\n    self.radius = ScaleLayer(radius)\n    self.radius_inv = ScaleLayer(radius_inv)\n    # \u8f93\u5165\u8f93\u51fa\u5747\u4e3a1\u7684\u5377\u79ef\u8fd0\u7b97\uff0ckernel_size\u4e3a61*61\uff0c\u7528\u4e8e\u516c\u5f0f(7,8)\u7684\u8ba1\u7b97\n    # \u56e0\u4e3af,g\u4e2d\u6bcf\u4e2a\u503c\u90fd\u7531\u539f\u663e\u8457\u56fe\u6bcf\u4e2a\u70b9\u8ba1\u7b97\uff0c\u5e76\u4e14\u6c42\u548c\u5f97\u5230\n    self.filter = nn.Conv2d(1, 1, kernel_size=(2*self.padding_size+1,2*self.padding_size+1),bias=False)\n    # \u5c06\u5377\u79ef\u53c2\u6570\u5b9a\u4e49\u4e3a\u9ad8\u65af\u6838\u53c2\u6570\uff0c\u5373\u516c\u5f0f\u4e2d\u7684k\n    self.filter.weight[0].data[:,:,:] = gaussian_weights# \u9ad8\u65af\u6838\uff0c\u5bf9\u5e94\u8bba\u6587\u4e2d\u7684\u8ddd\u79bb\u6838k\uff0c\u8be5\u5377\u79ef\u64cd\u4f5c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f(8)\uff0c\u4e58\u79ef+\u6c42\u548c\n\n    # \u521d\u59cb\u5316\u68af\u5ea6\u77e9\u9635\uff0c\u4e24\u5f20\u68af\u5ea6\u56fe\uff0c\u5206\u522b\u4ee3\u8868x\u7684\u68af\u5ea6\u548cy\u7684\u68af\u5ea6\n    # \u6570\u503c\u4ece-1\u52302\u5747\u5300\u53d8\u5316\n    self.P_basis = torch.zeros(2,self.grid_size+2*self.padding_size, self.grid_size+2*self.padding_size)\n    for k in range(2):\n        for i in range(self.global_size):\n            for j in range(self.global_size):\n                self.P_basis[k,i,j] = k*(i-self.padding_size)/(self.grid_size-1.0)+(1.0-k)*(j-self.padding_size)/(self.grid_size-1.0)\n    # \u5b9a\u4e49\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\n    self.features = base_model.features\n    # \u5f97\u5230\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u6700\u540e\u8f93\u51fa\u7684\u7279\u5f81\u6570\u91cf\n    self.num_features = base_model.num_features\n    # \u5b9a\u4e49\u539f\u59cb\u5206\u652f\u5168\u8fde\u63a5\u5c42\n    self.raw_classifier = nn.Linear(2048, num_classes)\n    # \u7528\u4e8e\u5c06\u7ecf\u8fc7\u91c7\u6837\u5f97\u5230\u7684\u56fe\u50cf\uff0c\u7279\u5f81\u63d0\u53d6\u540e\u518d\u7ecf\u8fc7\u4e00\u6b21\u5377\u79ef\uff0c\u6bd4\u539f\u59cb\u56fe\u50cf\u591a\u4e00\u6b21\u5377\u79ef\u64cd\u4f5c\uff0c\u8fd9\u91cc\u7528\u4e8e\u5224\u522b\u5206\u652f\n    self.sampler_buffer = nn.Sequential(nn.Conv2d(2048, 2048, kernel_size=3, stride=2, padding=1, bias=False),\n        nn.BatchNorm2d(2048),\n        nn.ReLU(),\n        )\n    # \u5b9a\u4e49\u5224\u522b\u5206\u652f\u7684\u5206\u7c7b\u5668\n    self.sampler_classifier = nn.Linear(2048, num_classes)\n    # \u4e92\u8865\u5206\u652f\u7684\u5377\u79ef\uff0c\u539f\u7406\u540c\u5224\u522b\u5206\u652f\u4e00\u6837\n    self.sampler_buffer1 = nn.Sequential(nn.Conv2d(2048, 2048, kernel_size=3, stride=2, padding=1, bias=False),\n        nn.BatchNorm2d(2048),\n        nn.ReLU(),\n        )\n    # \u5b9a\u4e49\u4e92\u8865\u5206\u652f\u7684\u5206\u7c7b\u5668\n    self.sampler_classifier1 = nn.Linear(2048, num_classes)\n    # \u7528\u4e8e\u6700\u7ec8\u5206\u7c7b\u7684\u5206\u7c7b\u5668\uff0c\u8f93\u5165\u4e09\u7ec4\u6982\u7387\uff0c\u8f93\u51fa\u4e00\u7ec4\u5206\u7c7b\u6982\u7387\n    self.con_classifier = nn.Linear(int(self.num_features*3), num_classes)\n    # \u5168\u5c40\u5e73\u5747\u6c60\u5316\n    self.avg = nn.AdaptiveAvgPool2d(1)\n    # \u5168\u5c40\u6700\u5927\u6c60\u5316\n    self.max_pool = nn.AdaptiveMaxPool2d(1)\n    # \u7528\u4e8e\u8ba1\u7b97\u6743\u91cd\u4e0e\u7279\u5f81\u56fe\u505a\u70b9\u4e58(\u5377\u79ef\u6838\u4e3a1*1)\uff0c\u5f97\u5230\u54cd\u5e94\u56fe\n    self.map_origin = nn.Conv2d(2048, num_classes, 1, 1, 0)\n</code></pre>"},{"location":"fine-grained/code/S3N2/#_3","title":"\u524d\u5411\u4f20\u64ad\u9636\u6bb5","text":"<p>\u53c2\u6570\u89e3\u8bfb\uff1a</p> <p><code>input_x</code>\uff1a\u8f93\u5165\u7684\u56fe\u50cf</p> <p><code>x_sampled_zoom</code>\uff1a\u5224\u522b\u5206\u652f\u56fe\u50cf</p> <p><code>x_sampled_inv</code>\uff1a\u4e92\u8865\u5206\u652f\u56fe\u50cf</p> <pre><code>def forward(self, input_x, p):\n    # \u9996\u5148\uff0c\u83b7\u53d6\u5168\u8fde\u63a5\u5c42\u7684\u6743\u91cd\u53c2\u6570\u548c\u504f\u7f6e\u53c2\u6570\uff0c\u52a0\u8f7d\u5230\u5377\u79ef\u6838\u4e3a1*1\u7684\u5377\u79ef\u5c42\u4e2d\uff0c\u4fbf\u4e8e\u5b9e\u73b0\u516c\u5f0f(1)\u7684\u8ba1\u7b97\n    self.map_origin.weight.data.copy_(self.raw_classifier.weight.data.unsqueeze(-1).unsqueeze(-1))\n    self.map_origin.bias.data.copy_(self.raw_classifier.bias.data)\n    # \u7ecf\u8fc7\u7279\u5f81\u63d0\u53d6\n    feature_raw = self.features(input_x)\n    # \u518d\u7ecf\u8fc7\u5168\u8fde\u63a5\u5c42\n    agg_origin = self.raw_classifier(self.avg(feature_raw).view(-1, 2048))\n    # \u6c42\u54cd\u5e94\u56fe\u7684\u8fc7\u7a0b\u4e0d\u662f\u53ef\u5bfc\u7684\u8fc7\u7a0b\n    with torch.no_grad():\n        # \u6743\u91cd\u4e0e\u539f\u7279\u5f81\u56fe\u505a\u70b9\u4e58\u8fd0\u7b97\uff0c\u518d\u6c42\u548c\u5f97\u5230200\u5f20(\u4ee5CUB\u6570\u636e\u96c6\u4e3a\u4f8b)\u54cd\u5e94\u56fe\uff0c\u6700\u65b9\u4fbf\u7684\u8fd0\u7b97\u5c31\u662f\u5377\u79ef\u8fd0\u7b97(\u5377\u79ef\u6838\u5927\u5c0f\u4e3a1)\n        # \u5f97\u5230\u54cd\u5e94\u56fe\u4e4b\u540e\uff0c\u518d\u8fdb\u884c\u653e\u5927\u64cd\u4f5c\n        # \u653e\u5927\u5230N*C*31*31,C\u4e3a\u5206\u7c7b\u6570\n        class_response_maps = F.interpolate(self.map_origin(feature_raw), size=self.grid_size, mode='bilinear', align_corners=True)\n    # \u8f93\u5165\u54cd\u5e94\u56fe\u57df\u539f\u59cb\u56fe\u50cf\uff0c\u5f97\u5230\u5224\u522b\u5206\u652f\u56fe\u50cf\u548c\u4e92\u8865\u5206\u652f\u56fe\u50cf\n    x_sampled_zoom, x_sampled_inv = self.generate_map(input_x, class_response_maps, p)\n    # \u9996\u5148\u5c06\u5224\u522b\u5206\u652f\u7ecf\u8fc7\u7279\u5f81\u63d0\u53d6\u4ee5\u53ca\u5168\u8fde\u63a5\u5c42\uff0c\u5f97\u5230\u5206\u7c7b\u6982\u7387\n    feature_D = self.sampler_buffer(self.features(x_sampled_zoom))\n    agg_sampler = self.sampler_classifier(self.avg(feature_D).view(-1, 2048))\n    # \u518d\u5c06\u4e92\u8865\u5206\u652f\u7ecf\u8fc7\u7279\u5f81\u63d0\u53d6\u4ee5\u53ca\u5168\u8fde\u63a5\u5c42\uff0c\u5f97\u5230\u5206\u7c7b\u6982\u7387\n    feature_C = self.sampler_buffer1(self.features(x_sampled_inv))\n    agg_sampler1 = self.sampler_classifier1(self.avg(feature_C).view(-1, 2048))\n    # \u5c06\u4e09\u4e2a\u5206\u652f\u5f97\u5230\u7684\u5206\u7c7b\u6982\u7387(\u539f\u59cb\u56fe\u50cf\u3001\u5224\u522b\u56fe\u50cf\u3001\u4e92\u8865\u56fe\u50cf)\u878d\u5408\uff0c\u4e00\u5757\u4f20\u5165\u5206\u7c7b\u5668\u8fdb\u884c\u5206\u7c7b\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u5206\u7c7b\u6982\u7387\n    aggregation = self.con_classifier(torch.cat([self.avg(feature_raw).view(-1, 2048), self.avg(feature_D).view(-1, 2048), self.avg(feature_C).view(-1, 2048)], 1))\n    # \u6a21\u578b\u6700\u540e\u8fd4\u56de\u56db\u4e2a\u9884\u6d4b\u6982\u7387\n    return aggregation, agg_origin, agg_sampler, agg_sampler1\n</code></pre>"},{"location":"fine-grained/code/S3N2/#_4","title":"\u968f\u673a\u663e\u8457\u6027\u91c7\u6837","text":"<p>\u53c2\u6570\u89e3\u8bfb\uff1a</p> <p><code>p</code>\uff1a0\u4e3a\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u7b2c\u4e00\u9636\u6bb5\uff0c1\u4e3a\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u7b2c\u4e8c\u9636\u6bb5\u6216\u8005\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\u7684\u7b2c\u4e00\u9636\u6bb5\uff0c2\u4e3a\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\u7684\u7b2c\u4e8c\u9636\u6bb5\u3002\u7b2c\u4e00\u9636\u6bb5\u4e3a\u8bad\u7ec3\u521d\u59cb\u9636\u6bb5\uff0c\u7b2c\u4e8c\u9636\u6bb5\u4e3a\u8bad\u7ec3\u540e\u671f\u3002</p> <p><code>xs</code>\uff1a\u4ee3\u8868\u9274\u522b\u5206\u652f\u7684\u91c7\u6837\u56fe</p> <p><code>xs_inv</code>\uff1a\u4ee3\u8868\u4e92\u8865\u5206\u652f\u7684\u91c7\u6837\u56fe</p> <pre><code>def generate_map(self, input_x, class_response_maps, p):\n    # \u5f97\u5230\u5c3a\u5bf8\n    N, C, H, W = class_response_maps.size()\n    # class_response_maps\u6c42\u5168\u5c40\u5e73\u5747\uff0c\u518d\u7ecf\u8fc7softmax\u5c31\u76f8\u5f53\u4e8e\u5f97\u5230\u4e86\u9884\u6d4b\u6982\u7387(\u548c\u539f\u6765\u76f8\u6bd4\uff0c\u53ea\u662f\u6362\u4e86\u4e2a\u987a\u5e8f\uff0c\u6700\u540e\u7684\u7ed3\u679c\u662f\u4e00\u6837\u7684)\n    # \u518d\u5c06\u9884\u6d4b\u5206\u6570\u6392\u5e8f\n    score_pred, sort_number = torch.sort(F.softmax(F.adaptive_avg_pool2d(class_response_maps, 1), dim=1), dim=1, descending=True)\n    # \u524d\u4e94\u540d\u9884\u6d4b\u6982\u7387\u505a\u4e00\u4e2a\u6c42\u4ea4\u53c9\u71b5\uff0c\u5f97\u5230H\uff0c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f(2)\n    # H\u76f8\u5f53\u4e8e\u662f\u9884\u6d4b\u7ed3\u679c\u7684\u53ef\u4fe1\u5ea6\n    gate_score = (score_pred[:, 0:5]*torch.log(score_pred[:, 0:5])).sum(1)\n\n    xs = []\n    xs_inv = []\n    # \u6309batch_size\u904d\u5386\n    for idx_i in range(N):\n        # \u6839\u636eH\u6765\u5224\u65ad\uff0c\u6700\u7ec8\u9009\u62e9\u54ea\u79cd\u8ba1\u7b97\u65b9\u5f0f\uff0c\u7528\u4e8e\u8ba1\u7b97\u6700\u7ec8\u7684\u54cd\u5e94\u56fe\uff0c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f(3)\n        # \u5982\u679cgate_score\u5927\uff0c\u5219\u8bf4\u660e\u6700\u7ec8\u7684\u9884\u6d4b\u6982\u7387\u6700\u5927\u503c\u975e\u5e38\u5927\uff0c\u5373\u9884\u6d4b\u7684\u53ef\u4fe1\u5ea6\u975e\u5e38\u9ad8\n        # \u4ee3\u8868\u7b2c\u4e00\u5f20\u54cd\u5e94\u56fe\u5c31\u53ef\u4ee5\u8986\u76d6\u539f\u56fe\u7684\u6709\u533a\u5206\u5ea6\u7684\u90e8\u5206\n        # \u5f97\u5230\u7684decide_map\u7ef4\u6570\u4e3a\u4e24\u7ef4\n        if gate_score[idx_i] &gt; -0.2:\n            decide_map = class_response_maps[idx_i, sort_number[idx_i, 0],:,:]\n        # \u5426\u5219\uff0c\u8bf4\u660e\u9884\u6d4b\u6982\u7387\u6700\u5927\u503c\u4e0d\u9ad8\uff0c\u53ef\u4fe1\u5ea6\u4e0d\u9ad8\n        # \u7b2c\u4e00\u5f20\u54cd\u5e94\u56fe\u4e0d\u8db3\u4ee5\u8986\u76d6\u539f\u56fe\u7684\u6709\u533a\u5206\u5ea6\u7684\u90e8\u5206\uff0c\u7528\u524d\u4e94\u5f20\u56fe\u7684\u5747\u503c\u66ff\u4ee3\n        else:\n            decide_map = class_response_maps[idx_i, sort_number[idx_i, 0:5],:,:].mean(0)\n\n        # \u6c42\u5f97\u54cd\u5e94\u56fe\u7684\u6700\u5927\u503c\u548c\u6700\u5c0f\u503c\u70b9\uff0c\u7528\u4e8e\u5f52\u4e00\u5316\u64cd\u4f5c\n        min_value, max_value = decide_map.min(), decide_map.max()\n        # \u54cd\u5e94\u56fe\u7684\u5f52\u4e00\u5316\n        # \u6b64\u65f6\u5728\u6bcf\u4e2a\u6279\u6b21\u4e2d\uff0cdecide_map\u4ee3\u8868\u4e00\u5f20\u56fe\uff0c\u5927\u5c0f\u4e3a31*31\uff0c\u4e4b\u524d\u5b9a\u4e49\u7684\n        decide_map = (decide_map-min_value)/(max_value-min_value)\n\n        # _mean_filter\u76f8\u5f53\u4e8e\u4e00\u4e2a\u5e73\u5747\u503c\u8fd0\u7b97\uff0c\u5bf9\u8f93\u5165\u7684\u90e8\u5206\u56fe\u50cf\u6c42\u5e73\u5747\u503c\n        # peak_stimulation\u7684\u4f5c\u7528\u662f\u5bfb\u627e\u5cf0\u503c\u70b9\uff0c\u8f93\u5165\u54cd\u5e94\u56fe\u4e0e\uff0c\u5177\u4f53\u89e3\u8bfb\u89c1\u65b9\u6cd5\u51fd\u6570\u5c0f\u8282\n        # peak_list\u4e3a\u5cf0\u503c\u70b9\u5750\u6807\uff0caggregation\u4e3a\u5cf0\u503c\u54cd\u5e94\u7684\u5e73\u5747\u503c\n        peak_list, aggregation = peak_stimulation(decide_map, win_size=3, peak_filter=_mean_filter)\n\n        # \u5bf9\u6bcf\u4e2a\u54cd\u5e94\u56fe\u505a\u538b\u7f29\u64cd\u4f5c\uff0c\u538b\u7f29\u65e0\u7528\u7684\u7ef4\u5ea6\uff0c\u5f97\u5230\u5c3a\u5bf8\u4e3a31*31\u7684\u4e8c\u7ef4\u54cd\u5e94\u56fe\n        decide_map = decide_map.squeeze(0).squeeze(0)\n        # \u5f97\u5230\u54cd\u5e94\u56fe\u7684\u5cf0\u503c\u70b9\u7684\u6570\u636e\u5927\u5c0f\uff0c\u6839\u636e\u5750\u6807\u70b9\u8fdb\u884c\u5b9a\u4f4d\n        score = [decide_map[item[2], item[3]] for item in peak_list]\n        # x\u662f\u6240\u6709\u5cf0\u503c\u54cd\u5e94\u70b9\u7684\u6a2a\u5750\u6807\n        x = [item[3] for item in peak_list]\n        # y\u662f\u6240\u6709\u5cf0\u503c\u54cd\u5e94\u70b9\u7684\u7eb5\u5750\u6807\n        y = [item[2] for item in peak_list]\n\n        if score == []:\n            # \u5982\u679c\u6ca1\u6709\u5cf0\u503c\u76f8\u5e94\u70b9\uff0c\u5219\u65e0\u6cd5\u8ba1\u7b97Qd\u4e0eQc\n            # \u5219\u4ed6\u4eec\u5747\u53d8\u4e3a\u9ed8\u8ba4\u503c\n            temp = torch.zeros(1, 1, self.grid_size,self.grid_size).cuda()\n            temp += self.base_ratio\n            # xs\u4e0ex_inv\u5206\u522b\u4ee3\u8868Qd\u4e0eQc\u7684\u96c6\u5408\n            xs.append(temp)\n            xs_inv.append(temp)\n            continue\n        # \u5cf0\u503c\u54cd\u5e94\u6570\u91cf\n        peak_num = torch.arange(len(score))\n        # \u4e0b\u9762\u7684\u64cd\u4f5c\u5bf9\u5e94\u8bba\u6587\u4e2d\u7684\u516c\u5f0f(4)(5)(6)\n        # temp\u5bf9\u5e94Qd,temp_w\u5bf9\u5e94Qc\n        # \u5747\u9884\u8bbe\u4e3a\u57fa\u7840\u7684\u5e45\u5ea6\n        temp = self.base_ratio\n        temp_w = self.base_ratio\n\n        if p == 0:\n            # \u5f53\u521a\u5f00\u59cb\u8bad\u7ec3\u7684\u65f6\u5019(\u8bad\u7ec3\u6b21\u6570\u5c0f\u4e8e20)p=0\uff0c\u6b64\u65f6\u533a\u57df\u54cd\u5e94\u8fd8\u4e0d\u662f\u5f88\u660e\u663e\n            # \u56fe\u50cf\u7684\u54cd\u5e94\u503c\u5e76\u4e0d\u80fd\u786e\u5b9a\u4fe1\u606f\u662f\u5426\u4e30\u5bcc\uff0c\u56e0\u6b64\u4e0d\u8bbe\u7f6e\u9608\u503c\u52a0\u4ee5\u533a\u5206\n            # \u6c42Qd\u3001Qc\u7684\u65f6\u5019\u7528\u6240\u6709\u7684\u54cd\u5e94\u56fe\u6c42\n            for i in peak_num:\n                # \u9996\u5148\u6c42\u53d6A\uff0c\u5373\u8bba\u6587\u4e2d\u516c\u5f0f(5)\uff0c\u7136\u540e\u518d\u505a\u4e00\u4e2a\u6c42\u548c\u64cd\u4f5c\n                # self.radius(torch.sqrt(score[i]))\u8868\u793a\u5c06\u8f93\u5165(\u54cd\u5e94\u503c)\u4e0e\u4e00\u4e2a\u53ef\u5b66\u4e60\u7684\u53c2\u6570\u76f8\u4e58\n                # kernel_generate\u5373\u9ad8\u65af\u6838\u7684\u8ba1\u7b97\uff0c\u8f93\u5165\u53ef\u5b66\u4e60\u7684\u53c2\u6570\u3001\u54cd\u5e94\u56fe\u5927\u5c0f\u3001\u5cf0\u503c\u54cd\u5e94\u5750\u6807\u70b9\uff0c\u5f97\u5230Ai\n                # \u5f97\u5230Ai\u540e\uff0c\u518d\u8fdb\u884c\u6c42\u548c\u64cd\u4f5c\uff0c\u5c06\u5229\u7528\u6240\u6709\u5cf0\u503c\u5f97\u5230\u7684Ai\u8fdb\u884c\u6c42\u548c,\u6700\u7ec8\u5f97\u5230Q\uff0c\u5373\u5f97\u5230\u91c7\u6837\u56fe\n                temp += score[i] * kernel_generate(self.radius(torch.sqrt(score[i])), H, (x[i].item(), y[i].item())).unsqueeze(0).unsqueeze(0).cuda()\n                temp_w += 1/score[i] * \\\n                kernel_generate(self.radius_inv(torch.sqrt(score[i])), H, (x[i].item(), y[i].item())).unsqueeze(0).unsqueeze(0).cuda()\n        elif p == 1:\n            for i in peak_num:\n                # \u968f\u673a\u57280,1\u5185\u9009\u4e00\u4e2a\u9608\u503c\uff0c\u8fdb\u884c\u5bf9Td\u3001Tc\u7684\u5206\u7c7b\n                # \u7531\u4e8e\u9608\u503c\u7684\u968f\u673a\u5f15\u5165\uff0c\u53ef\u4ee5\u8ba9\u8bad\u7ec3\u8fc7\u7a0b\u4fdd\u6301\u52a8\u6001\u5316\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u7a33\u5b9a\u6027\n                rd = random.uniform(0, 1)\n                # \u5982\u679c\u5927\u4e8e\u9608\u503c\uff0c\u4ee3\u8868\u4e3a\u9ad8\u54cd\u5e94\u533a\u57df\u7684\u70b9\uff0c\u5c5e\u4e8eTd,\u5426\u5219\u5c5e\u4e8eTc\uff0c\u5bf9\u5e94\u8bba\u6587\u4e2d\u7684\u516c\u5f0f(4)\n                # \u6c42Ai,\u548c\u6c42Q\u7684\u8fc7\u7a0b\u4e0ep=0\u8fc7\u7a0b\u7c7b\u4f3c\n                if score[i] &gt; rd:\n                    temp += score[i] * kernel_generate(self.radius(torch.sqrt(score[i])), H, (x[i].item(), y[i].item())).unsqueeze(0).unsqueeze(0).cuda()\n                else:\n                    temp_w += 1/score[i] * \\\n                    kernel_generate(self.radius_inv(torch.sqrt(score[i])), H, (x[i].item(), y[i].item())).unsqueeze(0).unsqueeze(0).cuda()\n        # \u6d4b\u8bd5\u9636\u6bb5\u7531\u4e8e\u53ea\u9700\u8981\u4fdd\u8bc1\u9884\u6d4b\u6982\u7387\u6700\u9ad8\n        # \u56e0\u6b64\u9700\u8981\u76f4\u63a5\u53d6\u4e24\u4e2a\u6781\u7aef\u503c\uff0c\u5c06\u54cd\u5e94\u503c\u6700\u9ad8\u7684\u90e8\u5206\u5f53\u6210\u6709\u533a\u5206\u5ea6\u7684\u90e8\u5206\uff0c\u5c06\u54cd\u5e94\u503c\u6700\u4f4e\u7684\u90e8\u5206\u5f53\u6210\u8865\u5145\u90e8\u5206\n        # \u8fd9\u91cc\u4e0e\u8bad\u7ec3\u8fc7\u7a0b\u4e0d\u540c\uff0c\u8bad\u7ec3\u8fc7\u7a0b\u7684\u968f\u673a\u9009\u62e9\u9608\u503c\u662f\u4e3a\u4e86\u8ba9\u8bad\u7ec3\u4fdd\u6301\u52a8\u6001\u5316\uff0c\u63d0\u9ad8\u6a21\u578b\u7a33\u5b9a\u6027\uff0c\u4f46\u6d4b\u8bd5\u9636\u6bb5\u53ea\u8981\u4fdd\u6301\u9884\u6d4b\u7cbe\u5ea6\u6700\u9ad8\u5373\u53ef\n        # \u8be5\u90e8\u5206\u53ea\u7528\u4e8e\u6d4b\u8bd5\u8fc7\u7a0b\n        elif p == 2:\n            # \u5f97\u5230\u54cd\u5e94\u503c\u6700\u9ad8\u70b9\u5904\u7684\u7d22\u5f15\uff0c\u4fbf\u4e8e\u4e0b\u9762\u76f4\u63a5\u5b9a\u4f4d\n            index = score.index(max(score))\n            temp += score[index] * kernel_generate(self.radius(score[index]), H, (x[index].item(), y[index].item())).unsqueeze(0).unsqueeze(0).cuda()\n            # \u540c\u4e0a\uff0c\u5f97\u5230\u54cd\u5e94\u503c\u6700\u4f4e\u70b9\u5904\u7684\u7d22\u5f15\n            index = score.index(min(score))\n            temp_w += 1/score[index] * \\\n            kernel_generate(self.radius_inv(torch.sqrt(score[index])), H, (x[index].item(), y[index].item())).unsqueeze(0).unsqueeze(0).cuda()\n\n        if type(temp) == float:\n            # \u5982\u679c\u662f\u4e00\u4e2a\u503c(\u6ca1\u8ba1\u7b97\u9ad8\u65af\u6838\uff0c\u5373\u6ca1\u6709\u5cf0\u503c\u54cd\u5e94)\uff0c\u5219\u521d\u59cb\u5316\u4e00\u4e2a\u77e9\u9635\uff0c\u6b64\u65f6\u77e9\u9635\u91cc\u7684\u503c\u5168\u662f\u57fa\u7840\u503c\n            temp += torch.zeros(1, 1, self.grid_size,self.grid_size).cuda()\n        # \u5b58\u50a8\u5f97\u5230\u7684Qd\n        xs.append(temp)\n        # \u4e0b\u6b21\u64cd\u4f5c\u7c7b\u4f3c\n        if type(temp_w) == float:\n            temp_w += torch.zeros(1, 1, self.grid_size,self.grid_size).cuda()\n        xs_inv.append(temp_w)\n    # \u5c06\u6240\u6709batch\u7684\u56fe\u50cf\u5408\u5e76\uff0c\u5f97\u5230\u6240\u6709\u7684\u5224\u522b\u5206\u652f\n    xs = torch.cat(xs, 0)\n    # \u5c06\u91c7\u6837\u56fe\u505a\u4e00\u4e2a\u586b\u5145\uff0c\u4fbf\u4e8e\u4e0b\u9762\u5bf9f,v\u7684\u8ba1\u7b97\n    xs_hm = nn.ReplicationPad2d(self.padding_size)(xs)\n    # \u901a\u8fc7\u91c7\u6837\u56fe\uff0c\u5f97\u5230\u91c7\u6837\u7f51\u683c\u56fe\uff0c\u7f51\u683c\u56fe\u5177\u4f53\u751f\u6210\u8fc7\u7a0b\u7684\u89e3\u8bfb\u89c1\u663e\u8457\u91c7\u6837\u5c0f\u8282\n    grid = self.create_grid(xs_hm).to(input_x.device)\n    # \u5229\u7528\u5f97\u5230\u7684\u7f51\u683c\u56fe\u5bf9\u8f93\u5165\u56fe\u50cf\u505a\u4e00\u4e2a\u7f51\u683c\u91c7\u6837\uff0c\u5373\u663e\u8457\u91c7\u6837\u8fc7\u7a0b\n    x_sampled_zoom = F.grid_sample(input_x, grid)\n    # \u4e0b\u9762\u8ba1\u7b97\u4e92\u8865\u5206\u652f\uff0c\u4e0e\u5224\u522b\u5206\u652f\u8fc7\u7a0b\u7c7b\u4f3c\n    xs_inv = torch.cat(xs_inv, 0)\n    xs_hm_inv = nn.ReplicationPad2d(self.padding_size)(xs_inv)\n    grid_inv = self.create_grid(xs_hm_inv).to(input_x.device)\n    x_sampled_inv = F.grid_sample(input_x, grid_inv)\n    # \u5c06\u7ecf\u8fc7\u663e\u8457\u91c7\u6837\u5f97\u5230\u7684\u56fe\u50cf\u8fd4\u56de\n    return x_sampled_zoom, x_sampled_inv\n</code></pre>"},{"location":"fine-grained/code/S3N2/#_5","title":"\u91c7\u6837\u7f51\u683c\u56fe\u7684\u751f\u6210","text":"<pre><code>def create_grid(self, x):\n    # \u8f93\u5165\uff1ax \u6269\u5145\u540e\u7684\u91c7\u6837\u56fe\n    # \u9884\u5148\u5b9a\u4e49\u4e00\u4e2a\u548c\u91c7\u6837\u56fe\u5c3a\u5bf8\u76f8\u540c\u7684\u5168\u96f6\u77e9\u9635\n    P = torch.autograd.Variable(torch.zeros(1,2,self.grid_size+2*self.padding_size, self.grid_size+2*self.padding_size).cuda(),requires_grad=False)\n    # \u521d\u59cb\u5316\u4e3a\u5747\u5300\u7684\u7f51\u683c\u56fe\n    P[0,:,:,:] = self.P_basis\n    # \u5c06P\u6269\u5c55\u7ef4\u5ea6\uff0c\u7b2c\u4e00\u7ef4\u5ea6\u5927\u5c0f\u4ece1\u6269\u5c55\u5230batch_size\uff0c\u5373\u5c06\u6240\u6709batch\u7684\u68af\u5ea6\u56fe\u90fd\u505a\u4e00\u4e2a\u521d\u59cb\u5316\n    P = P.expand(x.size(0),2,self.grid_size+2*self.padding_size, self.grid_size+2*self.padding_size)\n    # \u5c06\u8f93\u5165\u8fdb\u884c\u5806\u53e0\uff0c\u53d8\u6210\u4e24\u5f20\u56fe\uff0c\u6b64\u65f6x_cat\u7684\u5c3a\u5bf8\u4e3abatch*2*91*91\n    x_cat = torch.cat((x,x),1)\n    # \u5377\u79ef\u540e\u5f97\u5230\u7684\u5c3a\u5bf8\u4e3abatch*1*31*31\uff0c\u5377\u79ef\u6838\u5c3a\u5bf8\u4e3a61*61\uff0c\u8fd9\u91cc\u5377\u79ef\u6838\u53c2\u6570\u88ab\u8bbe\u7f6e\u4e3a\u9ad8\u65af\u6838\uff0c\u5373\u516c\u5f0f(7,8)\u4e2d\u7684\u8ddd\u79bb\u6838k\n    # \u8fd9\u91cc\u7684\u5377\u79ef\u76f8\u5f53\u4e8e\u8bba\u6587\u4e2d\u7684\u516c\u5f0f(7,8)\u4e2d\u7684\u5206\u6bcd\uff0c\u91c7\u6837\u56fe\u4e0e\u8ddd\u79bb\u6838\u4e58\u79ef\u518d\u6c42\u548c\n    p_filter = self.filter(x)\n    # \u8fd9\u91cc\u5f97\u5230(2*batch)*1*91*91\u7684\u77e9\u9635\uff0c\u521d\u59cb\u5316\u7684\u5747\u5300\u7f51\u683c\u56fe\u4e0e\u91c7\u6837\u56fe\u505a\u70b9\u4e58\uff0c\u76f8\u5f53\u4e8e\u516c\u5f0f(7,8)\u4e2d\u5206\u5b50\u7684\u4e00\u90e8\u5206\n    x_mul = torch.mul(P,x_cat).view(-1,1,self.global_size,self.global_size)\n    # \u8fd9\u91cc\u5f97\u5230batch*2*31*31\u7684\u77e9\u9635\uff0c\u518d\u6b21\u5229\u7528\u5377\u79ef\u64cd\u4f5c\u5b9e\u73b0\u6c42\u548c\u518d\u76f8\u52a0\uff0c\u6700\u7ec8\u5f97\u5230\u516c\u5f0f(7,8)\u4e2d\u7684\u5206\u5b50\n    all_filter = self.filter(x_mul).view(-1,2,self.grid_size,self.grid_size)\n    # \u5c06all_filter\u5206\u79bb\uff0c\u5206\u51fax\u65b9\u5411\u548cy\u65b9\u5411\n    x_filter = all_filter[:,0,:,:].contiguous().view(-1,1,self.grid_size,self.grid_size)\n    y_filter = all_filter[:,1,:,:].contiguous().view(-1,1,self.grid_size,self.grid_size)\n    # \u5c06\u7ed3\u679c\u76f8\u9664\uff0c\u5206\u522b\u5f97\u5230f\u4e0ev\n    x_filter = x_filter/p_filter\n    y_filter = y_filter/p_filter\n\n    xgrids = x_filter*2-1\n    ygrids = y_filter*2-1\n    # \u8303\u56f4\u63a7\u5236\u5230-1\u52301\u4e4b\u95f4\n    xgrids = torch.clamp(xgrids,min=-1,max=1)\n    ygrids = torch.clamp(ygrids,min=-1,max=1)\n\n    xgrids = xgrids.view(-1,1,self.grid_size,self.grid_size)\n    ygrids = ygrids.view(-1,1,self.grid_size,self.grid_size)\n    # \u6b64\u65f6grid\u4e3abatch*2*31*31\uff0c\u4e3a\u91c7\u6837\u7f51\u683c\n    grid = torch.cat((xgrids,ygrids),1)\n    # \u4e0a\u91c7\u6837\uff0c\u5c06\u68af\u5ea6\u56fe\u653e\u5927\n    grid = F.interpolate(grid, size=(self.input_size_net,self.input_size_net), mode='bilinear', align_corners=True)\n    # \u6700\u7ec8\u53d8\u6210batch*448*448*2\n    grid = torch.transpose(grid,1,2)\n    grid = torch.transpose(grid,2,3)\n\n    return grid\n</code></pre>"},{"location":"fine-grained/code/S3N2/#_6","title":"\u65b9\u6cd5\u51fd\u6570","text":""},{"location":"fine-grained/code/S3N2/#_7","title":"\u751f\u6210\u9ad8\u65af\u6838","text":"<pre><code>def makeGaussian(size, fwhm = 3, center=None):\n    # x\u4e3a0\u523060\uff0c\u4e00\u517161\u4e2a\u6570\n    x = np.arange(0, size, 1, float)\n    # np.newaxis\u8868\u793a\u589e\u52a0\u4e00\u4e2a\u7ef4\u5ea6\n    # \u6b64\u65f6y\u7684\u7ef4\u5ea6\u4e3a(61,1)\n    y = x[:,np.newaxis]\n    # \u662f\u5426\u8f93\u5165\u4e2d\u5fc3\n    if center is None:\n        x0 = y0 = size // 2\n    else:\n        x0 = center[0]\n        y0 = center[1]\n    # \u8ba1\u7b97\u9ad8\u65af\u6838\n    return np.exp(-4*np.log(2) * ((x-x0)**2 + (y-y0)**2) / fwhm**2)\n</code></pre>"},{"location":"fine-grained/code/S3N2/#_8","title":"\u8ba1\u7b97\u7a00\u758f\u6ce8\u610f\u529b","text":"<pre><code>class KernelGenerator(nn.Module):\n    def __init__(self, size, offset=None):\n        super(KernelGenerator, self).__init__()\n        # \u54cd\u5e94\u56fe\u5c3a\u5bf8\n        self.size = self._pair(size)\n        # \u751f\u6210\u7f51\u683c\u70b9\u5750\u6807\u77e9\u9635\n        xx, yy = np.meshgrid(np.arange(0, size), np.arange(0, size))\n        if offset is None:# offset\u662f\u54cd\u5e94\u503c\u5750\u6807\u70b9\n            offset_x = offset_y = size // 2# \u5982\u679c\u672a\u6307\u5b9a\u5750\u6807\u70b9\uff0c\u5373\u65e0\u5cf0\u503c\u7684\u8bdd\uff0c\u5c31\u4ee5\u4e2d\u5fc3\u70b9\u4e3a\u76f8\u5e94\u70b9\n        else:\n            offset_x, offset_y = self._pair(offset)\n        # power\u6307\u6570\u8ba1\u7b97\uff0cnp.power(a,b)\uff0c\u8fd4\u56dea^b\n        self.factor = torch.from_numpy(-(np.power(xx - offset_x, 2) + np.power(yy - offset_y, 2)) / 2).float()\n        # \u6c42\u5f97\u76f8\u5e94\u70b9\u4e0e\u5468\u56f4\u70b9\u7684\u8ddd\u79bb\uff0c\u4ee3\u8868\u8bba\u6587\u516c\u5f0f(5)\u4e2de\u7684\u6307\u6570\u4e0a\u5206\u5b50\u7684\u7ed3\u679c\n    @staticmethod\n    def _pair(x):\n        return (x, x) if isinstance(x, int) else x\n\n    def forward(self, theta):\n        # \u8fd9\u91cctheta\u5373\u53ef\u5b66\u4e60\u7684\u53c2\u6570\uff0cpow2\u4ee3\u8868e\u7684\u6307\u6570\u4e0a\u7684\u5206\u6bcd\n        pow2 = torch.pow(theta * self.size[0], 2)\n        # kernel\u5c3a\u5bf8\u4e3a31*31,\u4e3a\u6700\u7ec8\u8ba1\u7b97\u5f97\u5230\u7684Ai\n        kernel = 1.0 / (2 * np.pi * pow2) * torch.exp(self.factor.to(theta.device) / pow2)\n        return kernel / kernel.max()\n</code></pre>"},{"location":"fine-grained/code/S3N2/#_9","title":"\u5cf0\u503c\u54cd\u5e94\u70b9\u7684\u8ba1\u7b97","text":"<pre><code>class PeakStimulation(Function):\n\n    @staticmethod\n    def forward(ctx, input, return_aggregation, win_size, peak_filter):\n        ctx.num_flags = 4\n\n        # \u7a97\u53e3\u5927\u5c0f\u5fc5\u987b\u662f\u5947\u6570\uff0c\u5bf9\u5e94\u4e8e\u8bba\u6587\u4e2d\u7684\u53c2\u6570r\n        assert win_size % 2 == 1, 'Window size for peak finding must be odd.'\n        # offset\u8868\u793a\u586b\u5145\u5bbd\u5ea6\uff0c\u5177\u4f53\u7528\u6cd5\u89c1\u4e0b\u9762\u8c03\u7528\u8fc7\u7a0b\n        offset = (win_size - 1) // 2\n        # \u5b9a\u4e49\u4e8c\u7ef4\u586b\u5145\u51fd\u6570\n        padding = torch.nn.ConstantPad2d(offset, float('-inf'))\n        # \u5bf9\u539f\u56fe\u8fdb\u884c\u586b\u5145\n        padded_maps = padding(input)\n        # \u5f97\u5230\u586b\u5145\u56fe\u50cf\u540e\u7684\u5c3a\u5bf8\n        batch_size, num_channels, h, w = padded_maps.size()\n        # long()\u65b9\u6cd5\u8868\u793a\u5c06\u6570\u636e\u8f6c\u4e3ain64\u578b(\u957f\u6574\u578b)\n        # \u5148\u5b9a\u4e49\u4e00\u4e2a\u4e0e\u6269\u5145\u540e\u56fe\u50cf\u5927\u5c0f\u76f8\u540c\u7684\u6570\u7ec4\uff0c\u7136\u540e\u518d\u53d6\u51fa\u4e4b\u95f4\u7684\u5143\u7d20\u89c6\u56fe(\u8be5\u89c6\u56fe\u6307\u5411\u5143\u7d20\uff0c\u5ffd\u7565\u6269\u5145\u7684\u90e8\u5206)\n        element_map = torch.arange(0, h * w).long().view(1, 1, h, w)[:, :, offset: -offset, offset: -offset]\n        # \u5c06\u6570\u636e\u653e\u5165\u548c\u8f93\u5165\u4e00\u6837\u7684\u5730\u65b9\u4e2d(\u540c\u4e00\u4e2a\u663e\u5361\uff0c\u4fbf\u4e8e\u591a\u5361\u8bad\u7ec3)\n        element_map = element_map.to(input.device)\n        _, indices = F.max_pool2d(# indices\u5927\u5c0f\u4e3a31*31\uff0c\u50a8\u5b58\u7740\u5468\u56f4\u6781\u5927\u503c\u70b9\u7684\u4f4d\u7f6e(\u8be5\u4f4d\u7f6e\u6b63\u597d\u4e0e\u4e4b\u524d\u521b\u5efa\u7684\u6570\u7ec4\u5bf9\u5e94)\n            padded_maps,\n            kernel_size = win_size,\n            stride = 1,\n            return_indices = True)\n        peak_map = (indices == element_map)# \u627e\u51fa\u5c40\u90e8\u6700\u5927\u503c\uff0c\u5373\u5f53\u524d\u70b9\u5c31\u662f\u5468\u56f4\u7684\u6700\u5927\u503c\u70b9\uff0c\u4e5f\u5c31\u662f\u5cf0\u503c\u70b9\uff0c\u8ba1\u7b97\u65b9\u6cd5\u5f88\u5de7\u5999\n        # \u4fdd\u5b58\u4f4d\u7f6e\u70b9\n        if peak_filter:\n            # \u5982\u679c\u6307\u5b9apeak_filter\u4e3a\u5747\u503c\u8ba1\u7b97\n            # \u5219\u4e0b\u8ff0\u64cd\u4f5c\u4ee3\u8868\u5cf0\u503c\u54cd\u5e94\u5fc5\u987b\u5927\u4e8e\u8f93\u5165\u56fe\u7247\u7684\u5747\u503c\n            mask = input &gt;= peak_filter(input)\n            peak_map = (peak_map &amp; mask)\n        # \u8fd4\u56depeak_map\u975e\u96f6\u5143\u7d20\u7684\u5750\u6807,\u4e8c\u7ef4\u6570\u7ec4\uff0c\u7b2c\u4e00\u7ef4\u5ea6\u5927\u5c0f\u662f\u5750\u6807\u70b9\u4e2a\u6570\uff0c\u7b2c\u4e8c\u7ef4\u5ea6\u662f\u539f\u6570\u7ec4\u7684\u7ef4\u6570\uff0c\u5728\u8fd9\u91cc\u7b2c\u4e8c\u7ef4\u5ea6\u5c3a\u5bf8\u662f4\n        peak_list = torch.nonzero(peak_map)\n        # mark_non_differentiable\u5c06\u8f93\u51fa\u6807\u8bb0\u4e3a\u4e0d\u53ef\u5fae\n        # \u5373peak_list\u4e0d\u53ef\u5fae\n        ctx.mark_non_differentiable(peak_list)\n\n        # \u662f\u5426\u505a\u4e00\u4e2a\u805a\u96c6\uff0c\u9ed8\u8ba4\u662f\n        if return_aggregation:\n            peak_map = peak_map.float()# \u8f6c\u5316\u62100-1\u6570\uff0cTrue\u5bf9\u5e941\uff0cFalse\u4ee3\u88680\n            # save_for_backward\u4fdd\u5b58\u7ed9\u5b9a\u7684\u5f20\u91cf\uff0c\u4fbf\u4e8e\u5c06\u6765\u8c03\u7528\u51fd\u6570\u7684\u53cd\u5411\u4f20\u64ad\n            ctx.save_for_backward(input, peak_map)\n            # \u7b2c\u4e00\u8fd4\u56de\u5cf0\u503c\u70b9\u7684\u5750\u6807\uff0c\u7b2c\u4e8c\u8fd4\u56de\u6240\u6709\u5cf0\u503c\u70b9\u54cd\u5e94\u7684\u5e73\u5747\u503c\n            return peak_list, (input * peak_map).view(batch_size, num_channels, -1).sum(2) / \\\n                peak_map.view(batch_size, num_channels, -1).sum(2)\n        else:\n            return peak_list\n\n    @staticmethod\n    def backward(ctx, grad_peak_list, grad_output):\n        # \u5c06\u4e4b\u524d\u5b58\u50a8\u7684\u54cd\u5e94\u56fe\u548c\u8f6c\u5316\u4e3a0-1\u77e9\u9635\u7684\u5cf0\u503c\u56fe\u63d0\u53d6\u51fa\u6765\uff0c\u7528\u4e8e\u672c\u9636\u6bb5\u53cd\u5411\u4f20\u64ad\u7684\u8ba1\u7b97\n        input, peak_map, = ctx.saved_tensors\n        batch_size, num_channels, _, _ = input.size()\n        # \u68af\u5ea6\u4e0e\u5cf0\u503c\u56fe\u505a\u70b9\u4e58\uff0c\u5f97\u5230\u5cf0\u503c\u5904\u7684\u68af\u5ea6\uff0c\u7136\u540e\u518d\u9664\u4ee5\u5cf0\u503c\u70b9\u7684\u4e2a\u6570\uff1f\n        grad_input = peak_map * grad_output.view(batch_size, num_channels, 1, 1)/ \\\n        (peak_map.view(batch_size, num_channels, -1).sum(2).view(batch_size, num_channels, 1, 1) + 1e-6)\n        return (grad_input,) + (None,) * ctx.num_flags\n</code></pre>"},{"location":"fine-grained/code/S3N2/#_10","title":"\u5747\u503c\u6ee4\u6ce2","text":"<pre><code>def _mean_filter(input):\n    batch_size, num_channels, h, w = input.size()\n    # \u6c42\u5e73\u5747\u503c\n    threshold = torch.mean(input.view(batch_size, num_channels, h * w), dim=2)\n    # contiguous\u8fd4\u56de\u8fde\u7eed\u7684\u5f20\u91cf\n    return threshold.contiguous().view(batch_size, num_channels, 1, 1)  \n</code></pre> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u5927\u5bb6\u6279\u8bc4\u6307\u6b63\u3002</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e7411\u67083\u65e5</p>"},{"location":"fine-grained/code/SPS2/","title":"\u7ec6\u7c92\u5ea6\uff1aSPS","text":""},{"location":"fine-grained/code/SPS2/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aIEEE International Conference on Computer Vision 2021 (ICCV, 2021)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content/ICCV2021/papers/Huang_Stochastic_Partial_Swap_Enhanced_Model_Generalization_and_Interpretability_for_Fine-Grained_ICCV_2021_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740(PyTorch\u7248\u672c)\uff1ahttps://github.com/Shaoli-Huang/SPS</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u7c7b(FGVC)</p>"},{"location":"fine-grained/code/SPS2/#_2","title":"\u7f51\u7edc\u7ed3\u6784","text":"<p>\u4ee5ResNet\u4e3a\u4f8b</p> <pre><code>class ResNet(nn.Module):\n\n    def __init__(self,conf):\n        super(ResNet, self).__init__()\n        basenet = eval('models.'+conf.netname)(pretrained=conf.pretrained)\n        # self.conv3\u8868\u793aresnet\u4ece\u6700\u521d\u7684\u5377\u79ef\u5c42\u5230layer2\u5c42\u4e4b\u95f4\u7684\u4e00\u7cfb\u5217\u5377\u79ef\u6c60\u5316\u64cd\u4f5c\n        self.conv3 = nn.Sequential(*list(basenet.children())[:-4])\n        # self.conv4\u8868\u793aresnet\u4e2dlayer3\u5c42\n        self.conv4 = list(basenet.children())[-4]\n        self.midlevel = False\n        self.isdetach = True\n        if 'midlevel' in conf:\n            self.midlevel = conf.midlevel\n        if 'isdetach' in conf:\n            self.isdetach = isdetach\n        # \u4e2d\u6c34\u5e73\u7279\u5f81\u56fe\u901a\u9053\u6570\n        mid_dim = 1024\n        # \u9ad8\u6c34\u5e73\u7279\u5f81\u56fe\u901a\u9053\u6570\n        feadim = 2048\n        # \u5982\u679c\u662f['resnet18','resnet34']\uff0c\u5219\u901a\u9053\u6570\u51cf\u534a\n        if conf.netname in ['resnet18','resnet34']:\n            mid_dim = 256\n            feadim = 512\n\n        if self.midlevel:\n            # \u5b9a\u4e49\u4e2d\u6c34\u5e73\u5206\u7c7b\u5206\u652f\n            self.midnet = MidNet(conf,mid_dim)\n        # self.conv5\u8868\u793aresnet\u4e2dlayer4\u5c42\n        self.conv5 = list(basenet.children())[-3]\n        # \u5b9a\u4e49\u5168\u5c40\u5e73\u5747\u6c60\u5316\u64cd\u4f5c\n        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n        # \u5b9a\u4e49\u5168\u8fde\u63a5\u5c42\uff0c\u7528\u4e8e\u9884\u6d4b\u9ad8\u6c34\u5e73\u7279\u5f81\u56fe\u5f97\u5230\u7684\u7279\u5f81\u5411\u91cf\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u7c7b\u522b\u6982\u7387\n        self.classifier = nn.Linear(feadim, conf.num_class)\n\n    def set_detach(self,isdetach=True):\n        self.isdetach = isdetach\n\n    def forward(self, x):\n        # \u524d\u534a\u6bb5\u7279\u5f81\u63d0\u53d6\u64cd\u4f5c\uff0c\u5373\u4ece\u7b2c\u4e00\u5c42\u5377\u79ef\u5c42\u5f00\u59cb\u5230layer2\u5c42\u7ed3\u675f\n        x = self.conv3(x)\n        # \u518d\u7ecf\u8fc7layer3\u5c42\uff0c\u5f97\u5230\u4e2d\u6c34\u5e73\u7279\u5f81\u56fe\n        conv4 = self.conv4(x)\n        # \u4e2d\u6c34\u5e73\u7279\u5f81\u56fe\u7ecf\u8fc7layer4\u5c42\uff0c\u5f97\u5230\u9ad8\u6c34\u5e73\u7279\u5f81\u56fe\n        x = self.conv5(conv4)\n        # \u9ad8\u6c34\u5e73\u7279\u5f81\u56fe\u7ecf\u8fc7\u6c60\u5316\u3001\u5168\u8fde\u63a5\uff0c\u5f97\u5230\u539f\u59cb\u56fe\u50cf\u7684\u9884\u6d4b\u6982\u7387\n        fea_pool = self.avg_pool(x).view(x.size(0), -1)\n        logits = self.classifier(fea_pool)\n\n        if self.midlevel:\n            if self.isdetach:\n                conv4_1 = conv4.detach()\n            else:\n                conv4_1 = conv4\n            # \u5c06\u4e2d\u6c34\u5e73\u7279\u5f81\u56fe\u4f20\u5165\u5b9a\u4e49\u597d\u7684\u4e2d\u6c34\u5e73\u5206\u7c7b\u5206\u652f\n            mlogits = self.midnet(conv4_1)\n        else:\n            mlogits = None\n        # \u4f9d\u6b21\u8fd4\u56de\u9ad8\u6c34\u5e73\u7279\u5f81\u56fe\u5f97\u5230\u7684\u9884\u6d4b(\u4e0e\u539f\u59cb\u6a21\u578b\u7684\u8f93\u51fa\u4e00\u6837)\u3001\u9ad8\u6c34\u5e73\u7279\u5f81\u56fe\u3001\u4e2d\u6c34\u5e73\u7279\u5f81\u56fe\u5f97\u5230\u7684\u9884\u6d4b\n        return logits,x.detach(),mlogits\n</code></pre>"},{"location":"fine-grained/code/SPS2/#_3","title":"\u4e2d\u6c34\u5e73\u5206\u7c7b\u5206\u652f","text":"<pre><code>class MidNet(nn.Module):\n    def __init__(self,conf,mid_dim=1024):\n        super(MidNet, self).__init__()\n        # \u4e2d\u6c34\u5e73\u5206\u7c7b\u5206\u652f\u6570\u91cf\n        self.numbranch = len(conf.sp)\n        # \u521d\u59cb\u5316\u4e00\u4e2a\u6a21\u5757\n        self.spsBranchs = nn.ModuleList()\n        for sp in conf.sp:\n            # \u6309\u5206\u652f\u6570\u91cf\uff0c\u5f80\u6a21\u5757\u91cc\u6dfb\u52a0\u4e2d\u6c34\u5e73\u5206\u652f\n            # sp\u8868\u793a\u6bcf\u4e2a\u5206\u652f\u91cc\u9762\u7684\u03b1\u548c\u03b2\uff0cconf.numswap\u8868\u793a\u6253\u4e71\u6b21\u6570\n            # mid_dim\u8868\u793a\u4e2d\u6c34\u5e73\u7279\u5f81\u56fe\u901a\u9053\u6570\uff0cconf.num_class\u8868\u793a\u5206\u7c7b\u6570\n            self.spsBranchs.append(MidBlock(sp,conf.numswap,mid_dim,conf.num_class))\n    def forward(self,x):\n        logits = []\n        # \u6309\u5206\u652f\u6570\u91cf\u8fdb\u884c\u904d\u5386\n        for i in range(self.numbranch):\n            # \u6bcf\u6b21\u90fd\u8fd4\u56de\"\u6253\u4e71\u7279\u5f81\"\u7684\u9884\u6d4b\u7ed3\u679c\n            logits.append(self.spsBranchs[i](x))\n        return logits\n</code></pre>"},{"location":"fine-grained/code/SPS2/#_4","title":"\u968f\u673a\u6253\u4e71\u7279\u5f81\u5143\u7d20","text":"<pre><code>class MidBlock(nn.Module):\n    def __init__(self,sp, numswap, mid_dim=1024, num_class=200):\n        super(MidBlock, self).__init__()\n        # \u5168\u8fde\u63a5\u5c42\uff0c\u7528\u4e8e\u5bf9\u6253\u4e71\u540e\u7684\u7279\u5f81\u8fdb\u884c\u5206\u7c7b\u9884\u6d4b\n        self.mcls = nn.Linear(mid_dim, num_class)\n        self.max_pool = nn.AdaptiveMaxPool2d((1, 1))\n        # 1*1\u7684\u5377\u79ef\u4e0eReLU\u76f8\u7ec4\u5408\n        self.conv4_1 = nn.Sequential(nn.Conv2d(mid_dim, mid_dim, 1, 1), nn.ReLU())\n        # minp\u5bf9\u5e94\u8bba\u6587\u4e2d\u7684\u03b1\n        self.minp = sp[0]\n        # maxp\u5bf9\u5e94\u8bba\u6587\u4e2d\u7684\u03b2\n        self.maxp = sp[1]\n        self.numswap = numswap\n    def swap(self,x):\n        # \u8f93\u51fa\u4e3a\u4e8c\u7ef4\u7684\u7279\u5f81\u5411\u91cf\uff0c\u7b2c\u4e00\u7ef4\u5ea6\u5927\u5c0f\u4e3abatch\uff0c\u7b2c\u4e8c\u7ef4\u5ea6\u5927\u5c0f\u4e0e\u901a\u9053\u6570\u76f8\u540c\n        bs = x.size(0)\n        # \u72c4\u5229\u514b\u96f7\u5206\u5e03\n        lam = np.random.beta(1, 1)\n        # \u8fd9\u91cc\u8ba1\u7b97\u5f97\u5230\u7684sp\u5bf9\u5e94\u8bba\u6587\u4e2d\u516c\u5f0f(2)\u7684\u03c1\n        sp = self.minp + lam * (self.maxp - self.minp)\n        # np.random.permutation\u8868\u793a\u968f\u673a\u6392\u5e8f\n        # \u4ee5np.random.permutation(4)\u4e3a\u4f8b:\u9996\u5148\u4ea7\u751f[0,1,2,3]\u5e8f\u5217\uff0c\u4e4b\u540e\u518d\u5c06\u5b83\u4eec\u6253\u4e71\n        # \u8fd9\u91cc\u5f97\u5230\u7684\u4e71\u5e8f\u76f8\u5f53\u4e8e\u5c06\u539fbatch\u7684\u987a\u5e8f\u6253\u4e71\uff0c\u4e4b\u540e\u518d\u8ba1\u7b97\u5f97\u5230M\uff0c\u7528\u4e8e\u5224\u65ad\u54ea\u4e9b\u6570\u503c\u5bf9\u5e94\u7684batch\u9700\u8981\u88ab\u6253\u4e71\n        # \u9700\u8981\u88ab\u6253\u4e71\u7684\u76f4\u63a5\u7528rp\u8d4b\u503c\u5373\u53ef\u3002\n        rp = torch.from_numpy(np.random.permutation(x.size(0))).cuda()\n        # \u968f\u673a\u751f\u6210\u6570\u91cf\u4e3ax.size(1)\u5e76\u4e14\u6570\u503c\u4e3a0\u52301\u4e4b\u95f4\u7684\u4e00\u7ec4\u6570\uff0c\u6570\u636e\u6570\u91cf\u4e0e\u56fe\u7247\u7279\u5f81\u76f8\u540c\n        # \u7528\u4e8e\u9010\u4e00\u5224\u65ad\u5143\u7d20\u662f\u5426\u9700\u8981\u88ab\u6253\u4e71\n        # \u4e0e\u8bba\u6587\u4e2d\u516c\u5f0f(2)\u4e2d\u7684rand(0,1)\u5bf9\u5e94\n        actidx = torch.rand(x.size(1))\n        # \u505a\u5bf9\u6bd4\uff0c\u5f97\u5230\u8bba\u6587\u4e2d\u7684M\uff0csidx\u4e3aTrue\u65f6\uff0c\u8868\u793a\u5f53\u524d\u4f4d\u7f6e\u7684\u5143\u7d20\u9700\u8981\u88ab\u6253\u4e71\n        sidx = actidx &lt; sp\n        sidx.to(x.device)\n        # \u6253\u4e71\u539f\u7279\u5f81\u5411\u91cf\uff0c\u6ce8\u610f:\u8fd9\u91cc\u53ea\u6cbf\u6279\u6b21\u6253\u4e71(batch\uff0c\u5373\u7b2c\u4e00\u7ef4\u5ea6)\n        x[:,sidx] = x[rp[:,None],sidx]\n        # \u5c06\u6253\u4e71\u7684\u5411\u91cf\u8fd4\u56de\n        return x\n    def forward(self, x):\n        # \u7279\u5f81\u56fe\u9996\u5148\u7ecf\u8fc71*1\u7684\u5377\u79ef\u4e0eReLU\u6fc0\u6d3b\u51fd\u6570\n        conv4_1 = self.conv4_1(x)\n        # \u518d\u7ecf\u8fc7\u5168\u5c40\u5e73\u5747\u6c60\u5316\u5f97\u5230\u7279\u5f81\u5411\u91cf\n        pool4_1 = self.max_pool(conv4_1).view(conv4_1.size(0),-1)\n        # mlogits\u7528\u4e8e\u5b58\u50a8\u6240\u6709\u9884\u6d4b\u7ed3\u679c(\u6253\u4e71\u540e\u7279\u5f81\u5411\u91cf\u7684\u9884\u6d4b\u7ed3\u679c)\n        mlogits = []\n        if self.training:\n           for i in range(self.numswap):\n               # \u5148\u5c06\u7279\u5f81\u5411\u91cf\u4e2d\u7684\u5143\u7d20\u987a\u5e8f\u6253\u4e71\uff0c\u518d\u7ecf\u8fc7\u5168\u8fde\u63a5\u5c42\u5f97\u5230\u5206\u7c7b\u6982\u7387\n               # \u6ce8\u610f\uff0c\u8fd9\u91cc\u4f7f\u7528.clone()\u65b9\u6cd5\uff0c\u5c06\u6570\u636e\u590d\u5236\u4e00\u904d\uff0c\u5e76\u4e14\u4e0d\u5207\u65ad\u53cd\u5411\u4f20\u64ad\n               mslogit = self.mcls(self.swap(pool4_1.clone()))\n               mlogits.append(mslogit)\n        else:\n            # \u5982\u679c\u662f\u6d4b\u8bd5\u9636\u6bb5\uff0c\u5219\u65e0\u9700\u6253\u4e71\u7279\u5f81\u56fe\uff0c\u76f4\u63a5\u8fd4\u56de\u4e2d\u6c34\u5e73\u7279\u5f81\u7684\u9884\u6d4b\u7ed3\u679c\u5c31\u53ef\u4ee5\n            mlogits = self.mcls(pool4_1)\n        return mlogits\n</code></pre> <p>\u8bad\u7ec3\u8fc7\u7a0b\u4e0e\u4e00\u822c\u7684\u6a21\u578b\u8bad\u7ec3\u7c7b\u4f3c\uff0c\u8fd9\u91cc\u5c31\u4e0d\u518d\u91cd\u590d\u8bf4\u660e\u4e86\uff0c\u611f\u5174\u8da3\u7684\u540c\u5b66\u53ef\u4ee5\u770b\u4e00\u4e0b\u6211\u4e4b\u524d\u7684\u6e90\u7801\u7b14\u8bb0\u3002</p> <p>\u6ce8\uff1a\u4ee5\u4e0a\u5185\u5bb9\u4ec5\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u89c2\u70b9\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u5927\u5bb6\u6279\u8bc4\u6307\u6b63\u3002</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e7412\u670826\u65e5</p>"},{"location":"fine-grained/code/WS-DAN2/","title":"\u7ec6\u7c92\u5ea6\uff1aWS-DAN","text":""},{"location":"fine-grained/code/WS-DAN2/#_1","title":"\u7efc\u8ff0","text":"<p>\u8bba\u6587\u5730\u5740\uff1ahttps://arxiv.org/pdf/1901.09891v2.pdf</p> <p>\u6e90\u7801\u5730\u5740(PyTorch\u7248\u672c)\uff1ahttps://github.com/GuYuc/WS-DAN.PyTorch</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u7c7b(FGVC)</p> <p>\u5173\u952e\u8bcd\uff1a\u6570\u636e\u589e\u5e7f\u3001\u5f31\u76d1\u7763\u5b66\u4e60\u3001\u6ce8\u610f\u529b\u673a\u5236\u3001\u53cc\u7ebf\u6027\u6c60\u5316</p>"},{"location":"fine-grained/code/WS-DAN2/#ws-dan_1","title":"WS-DAN\u7f51\u7edc\u6574\u4f53\u7ed3\u6784","text":""},{"location":"fine-grained/code/WS-DAN2/#_2","title":"\u7f51\u7edc\u521d\u59cb\u5316\u9636\u6bb5","text":"<pre><code>def __init__(self, num_classes, M=32, net='inception_mixed_6e', pretrained=False):\n    # \u5206\u7c7b\u6570\u76ee\uff0cM\uff1aattention mps\u7684\u6570\u91cf\uff0cnet\uff1a\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\uff0cpretrained\u662f\u5426\u9884\u8bad\u7ec3\n    super(WSDAN, self).__init__()\n    # \u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u7684\u5b9a\u4e49\n    self.num_classes = num_classes\n    self.M = M\n    self.net = net\n    # net\u4e3a\u9884\u5148\u4f20\u5165\u7684\u7279\u5f81\u63d0\u53d6\u5c42\u5b57\u7b26\u4e32\u540d\u79f0\n    # Network Initialization\n    # \u7f51\u7edc\u6a21\u578b\u7684\u9009\u62e9\n    if 'inception' in net:\n        if net == 'inception_mixed_6e':\n            # \u8bfb\u53d6\u5e76\u8c03\u7528inception_v3\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u3002\u4f7f\u7528\u4e0e\u8bad\u7ec3\u7684mixed_6e\u5c42\u83b7\u53d6\u7279\u5f81\u3002\n            self.features = inception_v3(pretrained=pretrained).get_features_mixed_6e()\n            self.num_features = 768\n        elif net == 'inception_mixed_7c':\n            self.features = inception_v3(pretrained=pretrained).get_features_mixed_7c()\n            self.num_features = 2048\n        else:\n            raise ValueError('Unsupported net: %s' % net)\n    elif 'vgg' in net:\n        self.features = getattr(vgg, net)(pretrained=pretrained).get_features()\n        self.num_features = 512\n    elif 'resnet' in net:\n        self.features = getattr(resnet, net)(pretrained=pretrained).get_features()\n        self.num_features = 512 * self.features[-1][-1].expansion\n        # self.num_features\u4e3a\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u901a\u9053\u6570\u91cf\uff0c\u6b64\u65f6\u4f4d2048\n    else:\n        raise ValueError('Unsupported net: %s' % net)\n\n    # Attention Maps\n    # \u5377\u79ef\u6838\u5927\u5c0f\u4e3a1*1\u7684\u5377\u79ef\u5c42\u610f\u4e49\u5c31\u662f\u6539\u53d8\u901a\u9053\u6570\uff0c\u5728\u8fd9\u91cc\uff0c\u7ecf\u8fc7\u5377\u79ef\u3001\u6807\u51c6\u5316\u3001ReLU\u6539\u53d8\u540e\u7684\u7279\u5f81\u56fe\u6211\u4eec\u547d\u540d\u4e3a\u6ce8\u610f\u529b\u56fe\n    # BasicConv2d\u7684\u5b9a\u4e49\u89c1\u6ce8\u610f\u529b\u56fe\u7684\u751f\u6210\n    self.attentions = BasicConv2d(self.num_features, self.M, kernel_size=1)\n\n    # \u53cc\u7ebf\u6027\u6c60\u5316\uff0c\u8fd9\u91cc\u4ee5\u5168\u5c40\u5e73\u5747\u4e3a\u4f8b\n    # BAP\u7684\u5b9a\u4e49\u89c1\u53cc\u7ebf\u6027\u6c60\u5316\n    self.bap = BAP(pool='GAP')\n\n    # \u5168\u8fde\u63a5\u5c42\u7684\u5b9a\u4e49\uff0c\u8f93\u5165\u5927\u5c0f\u4e3a\u6ce8\u610f\u529b\u56fe\u6570\u91cfM\u4e58\u4ee5\u7279\u5f81\u63d0\u53d6\u540e\u7684\u901a\u9053\u6570\uff0c\u8f93\u51fa\u5927\u5c0f\u4e3a\u79cd\u7c7b\u6570\u91cf\n    self.fc = nn.Linear(self.M * self.num_features, self.num_classes, bias=False)\n    # \u8f93\u51fa\u65e5\u5fd7\n    logging.info('WSDAN: using {} as feature extractor, num_classes: {}, num_attentions: {}'.format(net, self.num_classes, self.M))\n</code></pre>"},{"location":"fine-grained/code/WS-DAN2/#_3","title":"\u524d\u5411\u4f20\u64ad\u9636\u6bb5","text":"<pre><code>def forward(self, x):\n    # \u524d\u5411\u4f20\u64ad\n    batch_size = x.size(0)\n    # \u5148\u5f97\u5230\u7279\u5f81\u56fe\uff0c768*26*26\n    feature_maps = self.features(x)\n    # \u518d\u5f97\u5230\u6ce8\u610f\u529b\u56fe\n    if self.net != 'inception_mixed_7c':\n        attention_maps = self.attentions(feature_maps)# 32*26*26\n    else:\n        attention_maps = feature_maps[:, :self.M, ...]\n    # \u901a\u8fc7\u7279\u5f81\u56fe\u4e0e\u6ce8\u610f\u529b\u56fe\u751f\u6210feature_matrix\n    feature_matrix = self.bap(feature_maps, attention_maps)\n\n    # \u5c06feature_matrix\u4f20\u5165\u5168\u8fde\u63a5\u8fdb\u884c\u9884\u6d4b\n    p = self.fc(feature_matrix * 100.)\n\n    # Generate Attention Map\n    if self.training:\n        # \u968f\u673a\u9009\u62e9\u6ce8\u610f\u529b\u56fe\uff0c\u8fdb\u884c\u4e0b\u4e00\u6b65\u64cd\u4f5c\n        # Randomly choose one of attention maps Ak\n        attention_map = []\n        for i in range(batch_size):\n            # \u4e00\u7ec4batch\u4e2d\uff0c\u6bcf\u5f20\u56fe\u6309\u987a\u5e8f\u751f\u6210\n            attention_weights = torch.sqrt(attention_maps[i].sum(dim=(1, 2)).detach() + EPSILON)\n            # \u5148\u5c06\u6ce8\u610f\u529b\u56fe\u5168\u5c40\u6c42\u548c(\u5206\u522b\u6cbf1,2\u7ef4\u5ea6\u6c42\u548c)\uff0c\u9010\u5143\u7d20\u5bf9\u5f20\u91cf\u8fdb\u884c\u5f00\u6839\u8fd0\u7b97\n            attention_weights = F.normalize(attention_weights, p=1, dim=0)\n            # \u8fdb\u4e00\u6b65\u8fdb\u884c\uff0c\u5f52\u4e00\u5316\u5f97\u5230\u6ce8\u610f\u529b\u56fe\u7684\u6743\u91cd\n            k_index = np.random.choice(self.M, 2, p=attention_weights.cpu().numpy())\n            # \u8fd9\u91cc\u7684\u53c2\u65702\u4ee3\u8868\u56de\u4f20\u4e24\u5f20\u6ce8\u610f\u529b\u56fe\n            # \u6309\u6982\u7387p\uff0c\u968f\u673a\u572832\u5185\u9009\u4fe9\u503c(\u6743\u91cd\u8d8a\u5927\uff0c\u88ab\u9009\u7684\u6982\u7387\u8d8a\u9ad8)\uff0c\u5f97\u5230\u7d22\u5f15\n            # p\u662f\u6982\u7387\uff0c\u901a\u8fc7\u5bf9\u56fe\u7247\u50cf\u7d20\u52a0\u6743\u7684\u5e73\u65b9\u5f97\u5230\u3002\n            attention_map.append(attention_maps[i, k_index, ...])\n        # \u6700\u540e\u5c06\u6ce8\u610f\u529b\u56fe\u5806\u53e0\n        attention_map = torch.stack(attention_map)\n\n    else:\n        #val\u6216test\u65f6\uff0c\u5bf9\u6240\u6709\u6ce8\u610f\u529b\u56fe\u6c42\u5747\u503c\n        attention_map = torch.mean(attention_maps, dim=1, keepdim=True)  # (B, 1, H, W)\n\n    return p, feature_matrix, attention_map\n</code></pre>"},{"location":"fine-grained/code/WS-DAN2/#_4","title":"\u6ce8\u610f\u529b\u56fe\u7684\u751f\u6210","text":"<pre><code>class BasicConv2d(nn.Module):\n    # \u5728\u7f51\u7edc\u4e2d\u8f93\u51fa\u7684feature map \u7684\u5c3a\u5bf8\u4e3a B*C*H*W\uff0c\u7ecf\u8fc7\u5904\u7406\u540e\uff0c\u5c3a\u5bf8\u53d8\u4e3aB*M*H*W\uff0c\u5176\u4e2dM\u4e3a\u9884\u5148\u5b9a\u4e49\u597d\u7684\u6ce8\u610f\u529b\u56fe\u7684\u6570\u91cf\u3002\n    def __init__(self, in_channels, out_channels, **kwargs):\n        # \u8fd9\u91cckernel_size\u4e3a1(\u5b58\u5728\u4e86kwargs,\u524d\u9762\u5df2\u7ecf\u4f20\u5165\u4e86)\n        super(BasicConv2d, self).__init__()\n        # \u4ee3\u8868\u5377\u79ef\u6838\u5927\u5c0f\u7684\u53c2\u6570\u5b58\u5728\u4e8e**kwargs\u4e2d\n        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n        # \u5f52\u4e00\u5316\u64cd\u4f5c\n        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        return F.relu(x, inplace=True)\n        # \u5f52\u4e00\u5316\u4e4b\u540e\u518d\u7ecf\u8fc7relu\uff0c\u6b63\u597d\u5c06\u663e\u8457\u6027\u4f4e\u7684\u533a\u57df\u53d8\u4e3a\u96f6\uff0c\u53ea\u4fdd\u7559\u663e\u8457\u6027\u9ad8\u7684\u533a\u57df\n</code></pre>"},{"location":"fine-grained/code/WS-DAN2/#_5","title":"\u53cc\u7ebf\u6027\u6ce8\u610f\u529b\u6c60\u5316","text":"<pre><code>class BAP(nn.Module):\n    def __init__(self, pool='GAP'):\n        super(BAP, self).__init__()\n        assert pool in ['GAP', 'GMP']#\u91c7\u6837\u7b56\u7565\uff0cGAP\u662f\u5168\u5c40\u5e73\u5747\uff0cGMP\u662f\u5168\u5c40\u6700\u5927\n        if pool == 'GAP':\n            self.pool = None\n        else:\n            self.pool = nn.AdaptiveMaxPool2d(1)\n\n    def forward(self, features, attentions):\n        B, C, H, W = features.size()\n        _, M, AH, AW = attentions.size()\n\n        # match size\n        if AH != H or AW != W:\n            attentions = F.upsample_bilinear(attentions, size=(H, W))# \u5c06\u6ce8\u610f\u529b\u56fe\u8c03\u6574\u6210\u548c\u7279\u5f81\u56fe\u4e00\u6837\u7684\u5927\u5c0f\u5c3a\u5bf8\n            # \u5982\u679cattention maps\u548cfeature\u9ad8\u548c\u5bbd\u4e0d\u4e00\u81f4\uff0c\u91c7\u7528\u53cc\u7ebf\u6027\u63d2\u503c\u8c03\u6574\u3002\n        # feature_matrix: (B, M, C) -&gt; (B, M * C)\n        if self.pool is None:# \u5982\u679c\u662f\u5168\u5c40\u5e73\u5747\n            feature_matrix = (torch.einsum('imjk,injk-&gt;imn', (attentions, features)) / float(H * W)).view(B, -1)\n            # \u628a\u5c3a\u5bf8\u4e3ai,m,j,k \u7684attention\u548c\u5c3a\u5bf8\u4e3ai,n,j,k\u7684feature\uff0c\u505a\u53cc\u7ebf\u6027\u6c60\u5316\n            # injk\u4e2di\u4e0d\u53d8\uff0cn\u548cjk\u4ea4\u6362\u4f4d\u7f6e\uff08\u8f6c\u7f6e\uff09\uff0c\u4e4b\u540e\u505a\u77e9\u9635\u4e58\u6cd5\uff08\u77e9\u9635\u5916\u79ef\uff0c\u975e\u70b9\u4e58\uff09\uff0c\u5f97\u5230imn\u7684\u77e9\u9635\n            # \u5f97\u5230B*M*C\u7684\u4e09\u7ef4\u77e9\u9635\u3002\u9664\u4ee5H*W\u540e\uff0c\u7528\u51fd\u6570view\u53d8\u4e3aB\u884c\uff0cM*C\u5217\u7684\u4e8c\u7ef4\u77e9\u9635\n            # \u505a\u5b8c\u8fd9\u4e9b\u53d8\u6362\u540e\u5f97\u5230\u7684feature_matrix\uff0c\u76f8\u5f53\u4e8e\u628a\u6bcf\u4e2a\u901a\u9053\u7684\u56fe\u7247\u5c55\u6210\u4e00\u7ef4\u77e9\u9635\uff0c\u7136\u540eM\u4e2a\u4e00\u7ef4\u77e9\u9635\u62fc\u63a5\u7ec4\u6210\u4e00\u884c\u3002\n            # feature_matrix\u7684\u6bcf\u4e00\u884c\u662f\u4e00\u5f20\u56fe\u7247\u7684\u6240\u6709\u7279\u5f81\u3002\n        else:\n            feature_matrix = []\n            for i in range(M):\n                AiF = self.pool(features * attentions[:, i:i + 1, ...]).view(B, -1)\n                #\u9996\u5148\uff0c\u628aM\u5f20\u5c3a\u5bf8\u4e3aB*1*H*W\u7684attention map, \u4f9d\u6b21\u548cB*C*H*W\u7684feature maps\u76f8\u4e58\u3002\n                # \u5f97\u5230M\u4efdB*C*H*W \u7684part Feature maps\u3002\n                #\u63a5\u7740\uff0c\u505a\u81ea\u9002\u5e94\u6c60\u5316\uff08AdaptiveAvgPool2d(1)\uff09\uff0c\u5c3a\u5bf8\u53d8\u4e3aB*C*1*1\u3002\u7136\u540e\u7528\u51fd\u6570view(B, -1) \u53d8\u4e3a\u5927\u5c0f\u4e3aB*C\u7684\u77e9\u9635\u3002\n                # \uff08x.view(batchsize, -1) \u4e2dbatchsize\u6307\u8f6c\u6362\u540e\u6709\u51e0\u884c\uff0c\u800c-1\u6307\u5728\u4e0d\u544a\u8bc9\u51fd\u6570\u6709\u591a\u5c11\u5217\u7684\u60c5\u51b5\u4e0b\uff0c\n                # \u6839\u636e\u539ftensor\u6570\u636e\u548cbatchsize\u81ea\u52a8\u5206\u914d\u5217\u6570\u3002\uff09\n                feature_matrix.append(AiF)\n                #\u5faa\u73af\u7ed3\u675f\u540efeature_matrix\u7684\u5927\u5c0f\u4e3aM\u4e2aB*C\u7684\u77e9\u9635\u3002\n            feature_matrix = torch.cat(feature_matrix, dim=1)\n            #\u628afeature_mareix \u91cd\u65b0\u6392\u5217\u4e3aB\u884c\uff0cC*M\u5217\u7684\u77e9\u9635\u3002\n\n        # sign-sqrt\n        feature_matrix = torch.sign(feature_matrix) * torch.sqrt(torch.abs(feature_matrix) + EPSILON)\n        #\u5bf9\u4e0a\u9762\u7684\u7ed3\u679c\u505a\u5904\u7406\u3002EPSILON = 1e-12 \u4f7f\u6839\u53f7\u4e0b\u4e0d\u4e3a\u96f6\u3002\n        #\u8fd9\u4e2a\u5904\u7406\u662f\u4e3a\u4e86\u5f97\u5230\u6700\u663e\u8457\u7684\u7279\u5f81\u3002\n        # l2 normalization along dimension M and C\n        feature_matrix = F.normalize(feature_matrix, dim=-1)#\u5f52\u4e00\u5316\u3002\n        return feature_matrix\n</code></pre>"},{"location":"fine-grained/code/WS-DAN2/#_6","title":"\u635f\u5931\u51fd\u6570","text":"<p>\u6ce8\u610f\u529b\u6b63\u5219\u5316\u635f\u5931\uff0c\u5373\uff1a $$ L_A=\\sum^M_{k=1}{||f_k-c_k||^2_2} $$ </p> <pre><code># \u5177\u4f53\u5b9e\u73b0\u8fc7\u7a0b\nclass CenterLoss(nn.Module):\n    def __init__(self):\n        super(CenterLoss, self).__init__()\n        self.l2_loss = nn.MSELoss(reduction='sum')\n    def forward(self, outputs, targets):\n        # \u4f20\u5165\u8f93\u51fa\u7684\u7279\u5f81\u77e9\u9635\u4e0e\u7279\u5f81\u4e2d\u5fc3\n        return self.l2_loss(outputs, targets) / outputs.size(0)\n        # \u9664\u4ee5batch_size\uff0c\u5f97\u5230\u6bcf\u5f20\u56fe\u7684\u5e73\u5747\u635f\u5931\n</code></pre> <p>\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u53ef\u4ee5\u76f4\u63a5\u4ecetorch.nn\u8c03\u7528</p> <pre><code>cross_entropy_loss = nn.CrossEntropyLoss()\n</code></pre>"},{"location":"fine-grained/code/WS-DAN2/#_7","title":"\u8bad\u7ec3\u6d41\u7a0b","text":""},{"location":"fine-grained/code/WS-DAN2/#_8","title":"\u8bad\u7ec3\u521d\u59cb\u5316\u8fc7\u7a0b","text":"<pre><code>##################################\n# Initialize saving directory \u521b\u5efa\u6a21\u578b\u7684\u5b58\u50a8\u5730\u5740\n##################################\nif not os.path.exists(config.save_dir):\n    os.makedirs(config.save_dir)\n\n##################################\n# Logging setting \u5b9a\u4e49\u65e5\u5fd7\n##################################\nlogging.basicConfig(\n    filename=os.path.join(config.save_dir, config.log_name),# \u6307\u5b9a\u65e5\u5fd7\u6587\u4ef6\u540d\n    filemode='w',# \u6307\u5b9a\u65e5\u5fd7\u6587\u4ef6\u6253\u5f00\u6a21\u5f0f\n    format='%(asctime)s: %(levelname)s: [%(filename)s:%(lineno)d]: %(message)s',\n    #\u6307\u5b9a\u8f93\u51fa\u7684\u683c\u5f0f\u548c\u5185\u5bb9\u3002\n    level=logging.INFO)\nwarnings.filterwarnings(\"ignore\")\n\n##################################\n# Load dataset \u52a0\u8f7d\u6570\u636e\u96c6\n##################################\ntrain_dataset, validate_dataset = get_trainval_datasets(config.tag, config.image_size)\ntrain_loader, validate_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True,\n                                           num_workers=config.workers, pin_memory=True), \\\n                                DataLoader(validate_dataset, batch_size=config.batch_size * 4, shuffle=False,\n                                           num_workers=config.workers, pin_memory=True)\n#batch_size\u8c03\u7528config.batch_size\uff0cshuffle=False\u4e0d\u6253\u4e71\u6570\u636e\u987a\u5e8f\uff0cnum_workers= 4\u4f7f\u7528config.workers\u4e2a\u5b50\u8fdb\u7a0b\u3002\n# pin_memory=True\u610f\u5473\u7740\uff0c\u751f\u6210\u7684Tensor\u6570\u636e\u6700\u5f00\u59cb\u662f\u5c5e\u4e8e\u5185\u5b58\u4e2d\u7684\u9501\u9875\u5185\u5b58\uff0c\u8fd9\u6837\u5c06\u5185\u5b58\u7684Tensor\u8f6c\u4e49\u5230GPU\u7684\u663e\u5b58\u5c31\u4f1a\u66f4\u5feb\u4e00\u4e9b\u3002\nnum_classes = train_dataset.num_classes\n\n##################################\n# Initialize model \u6a21\u578b\u521d\u59cb\u5316\n##################################\nlogs = {}\nstart_epoch = 0\n# \u5b9a\u4e49WS-DAN\u4f20\u5165\u5bf9\u5e94\u7684\u53c2\u6570\nnet = WSDAN(num_classes=num_classes, M=config.num_attentions, net=config.net, pretrained=True)\n# \u521d\u59cb\u5316\u7279\u5f81\u4e2d\u5fc3\nfeature_center = torch.zeros(num_classes, config.num_attentions * net.num_features).to(device)\n\n# \u8bfb\u53d6\u9884\u8bad\u7ec3\u6a21\u578b(\u5982\u679c\u6709\u7684\u8bdd)\nif config.ckpt:\n    # \u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b\n    checkpoint = torch.load(config.ckpt)\n\n    # \u5f97\u5230\u8bad\u7ec3\u9636\u6bb5(\u5df2\u7ecf\u8fed\u4ee3\u4e86\u591a\u5c11\u6b21)\u4ee5\u53ca\u65e5\u5fd7\n    logs = checkpoint['logs']\n    start_epoch = int(logs['epoch'])\n\n    # \u52a0\u8f7d\u6743\u91cd\u53c2\u6570\n    state_dict = checkpoint['state_dict']\n    net.load_state_dict(state_dict)\n    logging.info('Network loaded from {}'.format(config.ckpt))\n\n    # \u52a0\u8f7d\u7279\u5f81\u4e2d\u5fc3\n    if 'feature_center' in checkpoint:\n        feature_center = checkpoint['feature_center'].to(device)\n        logging.info('feature_center loaded from {}'.format(config.ckpt))\n\nlogging.info('Network weights save to {}'.format(config.save_dir))\n\n##################################\n# Use cuda \u662f\u5426\u4f7f\u7528\u663e\u5361\n##################################\nnet.to(device)\n#\u628anet\u52a0\u8f7d\u5230device\u4e2d\u8ba1\u7b97\uff0c\u5982\u679cCUDA\u4e2ddevice\u7684\u6570\u91cf\u5927\u4e8e1\uff0c\u5219\u4f7f\u7528\u5e76\u884c\u8ba1\u7b97\u3002\nif torch.cuda.device_count() &gt; 1:\n    net = nn.DataParallel(net)\n\n##################################\n# Optimizer, LR Scheduler \u4f18\u5316\u5668\u53ca\u5b66\u4e60\u7387\u4e0b\u964d\u7b56\u7565\n##################################\nlearning_rate = logs['lr'] if 'lr' in logs else config.learning_rate\noptimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=1e-5)\n# \u91c7\u7528\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u3002lr\u5b66\u4e60\u901f\u7387\u3002momentum\u51b2\u91cf\u3002 \n# \u66f4\u65b0\u91cf\uff1a(\u5f53\u672c\u6b21\u68af\u5ea6\u4e0b\u964d- dx * lr\u7684\u65b9\u5411\u4e0e\u4e0a\u6b21\u66f4\u65b0\u91cfv\u7684\u65b9\u5411\u76f8\u540c\u65f6\uff0c\u4e0a\u6b21\u7684\u66f4\u65b0\u91cf\u80fd\u591f\u5bf9\u672c\u6b21\u7684\u641c\u7d22\u8d77\u5230\u4e00\u4e2a\u6b63\u5411\u52a0\u901f\u7684\u4f5c\u7528\u3002\n# \u5f53\u672c\u6b21\u68af\u5ea6\u4e0b\u964d- dx * lr\u7684\u65b9\u5411\u4e0e\u4e0a\u6b21\u66f4\u65b0\u91cfv\u7684\u65b9\u5411\u76f8\u53cd\u65f6\uff0c\u4e0a\u6b21\u7684\u66f4\u65b0\u91cf\u80fd\u591f\u5bf9\u672c\u6b21\u7684\u641c\u7d22\u8d77\u5230\u4e00\u4e2a\u51cf\u901f\u7684\u4f5c\u7528\u3002)\n\n# \u6bcf\u8fed\u4ee3\u4e24\u6b21\uff0c\u5b66\u4e60\u7387\u53d8\u4e3a\u539f\u6765\u76840.9\u500d\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.9)\n\n##################################\n# ModelCheckpoint \n##################################\n# \u76d1\u63a7\u5e76\u4fdd\u5b58\u6700\u597d\u7684\u6a21\u578b\u3002\u8c03\u7528 class ModelCheckpoint(Callback)\n# ModelCheckpoint\u89c1\u6a21\u578b\u4fdd\u5b58\u7b56\u7565\ncallback_monitor = 'val_{}'.format(raw_metric.name)\ncallback = ModelCheckpoint(savepath=os.path.join(config.save_dir, config.model_name),\n                           monitor=callback_monitor,\n                           mode='max')\nif callback_monitor in logs:\n    callback.set_best_score(logs[callback_monitor])\nelse:\n    callback.reset()\n\n##################################\n# TRAINING\n##################################\nlogging.info('Start training: Total epochs: {}, Batch size: {}, Training size: {}, Validation size: {}'.format(config.epochs, config.batch_size, len(train_dataset), len(validate_dataset)))\nlogging.info('')\n#\u8f93\u51fa\u8fd0\u884c\u65e5\u5fd7\n</code></pre>"},{"location":"fine-grained/code/WS-DAN2/#_9","title":"\u6574\u4f53\u6d41\u7a0b","text":"<pre><code>for epoch in range(start_epoch, config.epochs):\n    callback.on_epoch_begin()\n    # \u4ece\u8d77\u59cbepoch \u5230\u8bbe\u5b9a\u7684\u6700\u540e\u4e00\u4e2aepoch\uff0ccallback.on_epoch_begin()\u662f\u7b2c\u4e00\u4e2aepoch\u7684\u8bdd\u5c31pass\u3002\n    logs['epoch'] = epoch + 1\n    logs['lr'] = optimizer.param_groups[0]['lr']\n    # \u8bb0\u5f55\u65e5\u5fd7\n    logging.info('Epoch {:03d}, Learning Rate {:g}'.format(epoch + 1, optimizer.param_groups[0]['lr']))\n\n    # \u52a0\u8f7d\u8fdb\u5ea6\u6761\u63d0\u793a\u3002\n    pbar = tqdm(total=len(train_loader), unit=' batches')\n    pbar.set_description('Epoch {}/{}'.format(epoch + 1, config.epochs))\n    # \u8bad\u7ec3\u8fc7\u7a0b\n    train(logs=logs,\n          data_loader=train_loader,\n          net=net,\n          feature_center=feature_center,\n          optimizer=optimizer,\n          pbar=pbar)\n    # \u6d4b\u8bd5\u8fc7\u7a0b\n    validate(logs=logs,\n             data_loader=validate_loader,\n             net=net,\n             pbar=pbar)\n\n    # isinstance() \u51fd\u6570\uff1a\u51fd\u6570\u6765\u5224\u65ad\u4e00\u4e2a\u5bf9\u8c61\u662f\u5426\u662f\u4e00\u4e2a\u5df2\u77e5\u7684\u7c7b\u578b\uff08\u8003\u8651\u7ee7\u627f\u5173\u7cfb\uff09\u3002\n    if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n        # scheduler.step()\u5bf9\u5b66\u4e60\u901f\u7387\u8fdb\u884c\u8c03\u6574\u3002\n        scheduler.step(logs['val_loss'])\n    else:\n        scheduler.step()\n\n    callback.on_epoch_end(logs, net, feature_center=feature_center)\n    pbar.close()\n</code></pre>"},{"location":"fine-grained/code/WS-DAN2/#_10","title":"\u8bad\u7ec3\u8fc7\u7a0b","text":"<pre><code>def train(**kwargs):\n    # **kwargs: **\u4f1a\u4ee5\u952e/\u503c\u5bf9\u7684\u5f62\u5f0f\u89e3\u5305\u4e00\u4e2a\u5b57\u5178\uff0c\u4f7f\u5176\u6210\u4e3a\u72ec\u7acb\u7684\u5173\u952e\u5b57\u53c2\u6570\u3002\n    # \u8bfb\u53d6\u5404\u79cd\u53c2\u6570\n    logs = kwargs['logs']\n    data_loader = kwargs['data_loader']\n    net = kwargs['net']\n    feature_center = kwargs['feature_center']\n    optimizer = kwargs['optimizer']\n    pbar = kwargs['pbar']\n\n    #\u53c2\u6570\u8c03\u7528reset\uff08\uff09\u51fd\u6570\uff0c\u56de\u5230\u6700\u521d\u8bbe\u7f6e\uff08\u5168\u96f6\u77e9\u9635\uff09\u3002\n    loss_container.reset()\n    raw_metric.reset()\n    crop_metric.reset()\n    drop_metric.reset()\n\n    # \u5f00\u59cb\u8bad\u7ec3\n    start_time = time.time()\n    net.train()\n    for i, (X, y) in enumerate(data_loader):\n        # enumerate() \u51fd\u6570\u7528\u4e8e\u5c06\u4e00\u4e2a\u53ef\u904d\u5386\u7684\u6570\u636e\u5bf9\u8c61(\u5982\u5217\u8868\u3001\u5143\u7ec4\u6216\u5b57\u7b26\u4e32)\n        # \u7ec4\u5408\u4e3a\u4e00\u4e2a\u7d22\u5f15\u5e8f\u5217\uff0c\u540c\u65f6\u5217\u51fa\u6570\u636e\u548c\u6570\u636e\u4e0b\u6807.\n        optimizer.zero_grad()\n        # optimizer.zero_grad()\u5c06\u68af\u5ea6\u521d\u59cb\u5316\u4e3a\u96f6\u3002\n        # X\u662f\u8bad\u7ec3\u56fe\u7247\uff0cy\u662f\u5bf9\u5e94\u6807\u7b7e\n        X = X.to(device)\n        y = y.to(device)\n\n        ##################################\n        # Raw Image\n        ##################################\n        # \u9996\u5148\u4f20\u5165X\uff0c\u5f97\u5230\u9884\u6d4b\u6982\u7387\u3001\u7279\u5f81\u77e9\u9635\u4ee5\u53ca\u6ce8\u610f\u529b\u56fe\n        y_pred_raw, feature_matrix, attention_map = net(X)\n\n        # Update Feature Center\n        feature_center_batch = F.normalize(feature_center[y], dim=-1)\n        # \u7279\u5f81\u4e2d\u5fc3\u5f52\u4e00\u5316\uff0c\u66f4\u65b0\u7279\u5f81\u4e2d\u5fc3(feature_center)\n        feature_center[y] += config.beta * (feature_matrix.detach() - feature_center_batch)\n        # detach()\u8fd4\u56de\u4e00\u4e2a\u65b0\u7684Variable\uff0c\u4ece\u5f53\u524d\u8ba1\u7b97\u56fe\u4e2d\u5206\u79bb\u4e0b\u6765\u7684\uff0c\u4f46\u662f\u4ecd\u6307\u5411\u539f\u53d8\u91cf\u7684\u5b58\u653e\u4f4d\u7f6e\u3002\n        # \u4f5c\u5dee\u4e4b\u540e\uff0c\u4e0d\u65ad\u53e0\u52a0\u53d8\u5316\u91cf\u5230feature_matrix\n\n        ##################################\n        # Attention Cropping\n        ##################################\n        with torch.no_grad():\n            # torch.no_grad()\u4e0d\u9700\u8981\u68af\u5ea6\n            # batch_augment\u7684\u89e3\u8bfb\u89c1\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u6570\u636e\u589e\u5e7f\n            crop_images = batch_augment(X, attention_map[:, :1, :, :], mode='crop', theta=(0.4, 0.6), padding_ratio=0.1)\n            # crop\u4e2d\u8f93\u5165\u7684attention map\u662fattention_map[:, :1, :, :] attention maps\u7684\u7b2c\u4e00\u5f20\u56fe\u7247\u3002\n        # crop\u53ea\u8981\u5f97\u5230\u4e00\u4e2a\u7279\u5f81\u7684\u653e\u5927\u56fe\uff0c\u53ea\u9700\u8981\u627e\u5230min\u548cmax\u50cf\u7d20\u7684\u4f4d\u7f6e\uff0c\u6240\u4ee5\u4e00\u5f20\u7279\u5f81\u56fe\u8db3\u591f\u3002\n\n        # \u88c1\u526a\u56fe\u50cf\u4f20\u5165\u7f51\u7edc\u8fdb\u884c\u9884\u6d4b\n        y_pred_crop, _, _ = net(crop_images)\n\n        ##################################\n        # Attention Dropping\n        ##################################\n        with torch.no_grad():\n            drop_images = batch_augment(X, attention_map[:, 1:, :, :], mode='drop', theta=(0.2, 0.5))\n            # drop\u4e2d\u8f93\u5165\u7684attention map\u662fattention_map[:, 1\uff1a, :, :] attention maps:\u9664\u53bb\u7b2c\u4e00\u5f20\u56fe\u7247\u5916\u7684\u6240\u6709\u56fe\u7247\u3002(\u4e00\u822c\u662f1\u4e2a\uff0c\u8ddf\u7f51\u7edc\u5b9a\u7684\u53c2\u6570\u6709\u5173\u7cfb)\n        # drop\u662f\u628a\u6240\u6709\u5c0f\u4e8e\u9608\u503c\u7684\u50cf\u7d20\u7f6e0\uff0c\u64cd\u4f5c\u662f\u50cf\u7d20\u7ea7\uff0c\u7528\u6570\u91cf\u591a\u7684attention maps\u53ef\u4ee5\u6db5\u76d6\u5c3d\u91cf\u5927\u4e14\u51c6\u786e\u7684\u7279\u5f81\u533a,\u56e0\u6b64\u53ef\u4ee5\u4f20\u5165\u591a\u5f20\u6ce8\u610f\u529b\u56fe\u8fdb\u884c\u5220\u9664\u64cd\u4f5c\u3002\n\n        # \u6ce8\u610f\u529b\u5220\u9664\u56fe\u50cf\u4f20\u5165\u7f51\u7edc\u8fdb\u884c\u9884\u6d4b\n        y_pred_drop, _, _ = net(drop_images)\n        # batch_loss\u7684\u8ba1\u7b97\u91c7\u7528\u4ea4\u53c9\u71b5\u635f\u5931\u3002\u8003\u8651\u56db\u4e2a\u9884\u6d4b\u90e8\u5206\uff0c\u7ed3\u679c\u76f8\u52a0\u3002\n        # loss\n        batch_loss = cross_entropy_loss(y_pred_raw, y) / 3. + \\\n                     cross_entropy_loss(y_pred_crop, y) / 3. + \\\n                     cross_entropy_loss(y_pred_drop, y) / 3. + \\\n                     center_loss(feature_matrix, feature_center_batch)\n\n        # backward\n        #backward\u53cd\u5411\u4f20\u64ad\uff0coptimizer.step() \u6839\u636e\u7f51\u7edc\u53cd\u5411\u4f20\u64ad\u7684\u68af\u5ea6\u6765\u66f4\u65b0\u7f51\u7edc\u53c2\u6570\u3002\n        batch_loss.backward()\n        optimizer.step()\n\n        # \u8ba1\u7b97\u635f\u5931\u548c\u7cbe\u5ea6\n        with torch.no_grad():\n            epoch_loss = loss_container(batch_loss.item())\n            epoch_raw_acc = raw_metric(y_pred_raw, y)\n            epoch_crop_acc = crop_metric(y_pred_crop, y)\n            epoch_drop_acc = drop_metric(y_pred_drop, y)\n            # metrics \uff1aepoch_loss\u91c7\u7528AverageMeter\uff0c\u8ba1\u7b97\u591a\u4e2a\u7c7b\u7684\u5e73\u5747\u503c\u3002\n            # epoch_raw\uff0ccrop\uff0cdrop\u91c7\u7528TopKAccuracyMetric\uff08\u9009\u53d6\u6982\u7387\u6700\u5927\u7684 k \u4e2a\u6807\u7b7e\uff09\u8ba1\u7b97\u5e73\u5747\u503c\u3002\n\n        # end of this batch \u66f4\u65b0\u8fdb\u5ea6\u6761\n        batch_info = 'Loss {:.4f}, Raw Acc ({:.2f}, {:.2f}), Crop Acc ({:.2f}, {:.2f}), Drop Acc ({:.2f}, {:.2f})'.format(\n            epoch_loss, epoch_raw_acc[0], epoch_raw_acc[1],\n            epoch_crop_acc[0], epoch_crop_acc[1], epoch_drop_acc[0], epoch_drop_acc[1])\n        pbar.update()\n        pbar.set_postfix_str(batch_info)\n\n    # \u5c06\u8bad\u7ec3\u7cbe\u5ea6\u4e0e\u635f\u5931\u4fdd\u5b58\u5230\u65e5\u5fd7\u91cc\u9762\n    logs['train_{}'.format(loss_container.name)] = epoch_loss\n    logs['train_raw_{}'.format(raw_metric.name)] = epoch_raw_acc\n    logs['train_crop_{}'.format(crop_metric.name)] = epoch_crop_acc\n    logs['train_drop_{}'.format(drop_metric.name)] = epoch_drop_acc\n    logs['train_info'] = batch_info\n    end_time = time.time()\n\n    # \u8f93\u51fa\u8bad\u7ec3\u4fe1\u606f\n    logging.info('Train: {}, Time {:3.2f}'.format(batch_info, end_time - start_time))\n</code></pre>"},{"location":"fine-grained/code/WS-DAN2/#_11","title":"\u9a8c\u8bc1\u8fc7\u7a0b","text":"<pre><code>def validate(**kwargs):\n    # \u52a0\u8f7d\u53c2\u6570\n    logs = kwargs['logs']\n    data_loader = kwargs['data_loader']\n    net = kwargs['net']\n    pbar = kwargs['pbar']\n\n    # \u521d\u59cb\u5316\u77e9\u9635\n    loss_container.reset()\n    raw_metric.reset()\n    #\u52a0\u8f7d\u65e5\u5fd7\u3002loss_container\uff0craw_metric\u5f52\u96f6\u3002\n    # \u5f00\u59cb\u9a8c\u8bc1\n    start_time = time.time()\n    net.eval()\n    with torch.no_grad():\n        for i, (X, y) in enumerate(data_loader):\n            # \u8bfb\u53d6\u6570\u636e\n            X = X.to(device)\n            y = y.to(device)\n\n            ##################################\n            # Raw Image\n            ##################################\n            y_pred_raw, _, attention_map = net(X)\n            #\u52a0\u8f7d\u6570\u636e\uff0c\u83b7\u53d6\u9884\u6d4b\u503c\u548cattention_map\uff0c\u6ce8\u610f\u529b\u56fe\u4e3a\u4e86\u4e0b\u4e00\u6b65\u7684\u88c1\u526a\u64cd\u4f5c\u3002\n            ##################################\n            # Object Localization and Refinement\n            ##################################\n            # \u5c06\u539f\u56fe\u50cf\u8fdb\u884c\u88c1\u526a\uff0c\u83b7\u5f97\u88c1\u526a\u540e\u7684\u56fe\u50cf\u8fdb\u884c\u9884\u6d4b\n            crop_images = batch_augment(X, attention_map, mode='crop', theta=0.1, padding_ratio=0.05)\n            y_pred_crop, _, _ = net(crop_images)\n\n            ##################################\n            # Final prediction\n            ##################################\n             \u6700\u540e\u7684\u9884\u6d4b\u503c\u7b49\u4e8eraw image\u7684\u9884\u6d4b\u503c\u548ccrop image\u7684\u9884\u6d4b\u503c\u3002\n            y_pred = (y_pred_raw + y_pred_crop) / 2.\n            #\u8ba1\u7b97loss \u548c acc\u3002\n            batch_loss = cross_entropy_loss(y_pred, y)\n            epoch_loss = loss_container(batch_loss.item())\n\n            # metrics: top-1,5 error\n            # \u5f97\u5230\u7cbe\u5ea6\n            epoch_acc = raw_metric(y_pred, y)\n\n    # \u6700\u540e\u4fdd\u5b58\u6d4b\u8bd5\u635f\u5931\u4e0e\u7cbe\u5ea6\n    logs['val_{}'.format(loss_container.name)] = epoch_loss\n    logs['val_{}'.format(raw_metric.name)] = epoch_acc\n    end_time = time.time()\n\n    batch_info = 'Val Loss {:.4f}, Val Acc ({:.2f}, {:.2f})'.format(epoch_loss, epoch_acc[0], epoch_acc[1])\n    pbar.set_postfix_str('{}, {}'.format(logs['train_info'], batch_info))\n\n    # \u8f93\u51fa\u4fe1\u606f\n    logging.info('Valid: {}, Time {:3.2f}'.format(batch_info, end_time - start_time))\n    logging.info('')\n</code></pre>"},{"location":"fine-grained/code/WS-DAN2/#_12","title":"\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u6570\u636e\u589e\u5e7f","text":"<pre><code>def batch_augment(images, attention_map, mode='crop', theta=0.5, padding_ratio=0.1):\n    batches, _, imgH, imgW = images.size()\n    if mode == 'crop':\n        # copy\u6a21\u5f0f\n        crop_images = []\n        for batch_index in range(batches):\n            # \u6bcf\u5f20\u56fe\u7247\u5206\u522b\u8fdb\u884c\u88c1\u526a\n            atten_map = attention_map[batch_index:batch_index + 1]\n            if isinstance(theta, tuple):\n                theta_c = random.uniform(*theta) * atten_map.max()\n                # .max()\u4e3a\u6700\u5927\u503c\u64cd\u4f5c\n                # theta\u4e3a\u6570\u7ec4\u65f6\uff0c\u6bcf\u6b21\u4ecetheta\u7ed9\u51fa\u7684\u8303\u56f4\u4e2d\u968f\u673a\u751f\u6210\u4e00\u4e2a\u5b9e\u6570\u3002\n                # uniform()\u65b9\u6cd5\u4e3a\u968f\u673a\u751f\u6210\u4e0b\u4e00\u4e2a\u5b9e\u6570\u3002\n            else:\n                theta_c = theta * atten_map.max()\n                # \u9608\u503c\u4e3atheta * atten_map.max()\n            # theta_c\u76f8\u5f53\u4e8e\u5f97\u5230\u4e00\u4e2a\u9608\u503c\uff0c\u5927\u4e8e\u8be5\u9608\u503c\u7684\u533a\u57df\u5f53\u505a\u88ab\u88c1\u526a\u533a\u57df\n            crop_mask = F.upsample_bilinear(atten_map, size=(imgH, imgW)) &gt;= theta_c\n            # \u5bf9atten_map\uff08\u6bcf\u6b21\u5faa\u73af\uff0c\u4eceattention maps \u53d61\u5f20\u56fe\u7247\u4f5c\u4e3aatten_map\uff09\u9996\u5148\u505a\u53cc\u7ebf\u6027\u4e0a\u91c7\u6837\uff0c\u4f7f\u5176\u5927\u5c0f\u53d8\u4e3a\u6807\u51c6\u5927\u5c0f\n            # \u7136\u540e\u505a\u4e00\u4e2a\u9608\u503c\u5224\u65ad\uff0c\u5927\u4e8e\u9608\u503c\u7684\u90e8\u5206\u7f6e\u4e3atrue\uff081\uff09\uff0c\u5c0f\u4e8e\u9608\u503c\u7684\u90e8\u5206\u7f6e\u4e3afalse\uff080\uff09\u3002\n            nonzero_indices = torch.nonzero(crop_mask[0, 0, ...])\n            # \u5f97\u5230\u975e\u96f6\u5143\u7d20\u7684\u7d22\u5f15\uff0c\u5373\u9700\u8981\u88c1\u526a\u7684\u90e8\u5206\n            # crop_mask\u7684\u7b2c\u4e00\u4e2a\u901a\u9053\uff0c\u975e\u96f6\u503c\u7684\u4f4d\u7f6e\u3002\u7ed3\u679c\u7684\u7b2c\u4e00\u5217\u662f\u56fe\u7247\u7684\u884c\u53f7\uff0c\u7b2c\u4e8c\u5217\u662f\u5217\u53f7\u3002\n\n            height_min = max(int(nonzero_indices[:, 0].min().item() - padding_ratio * imgH), 0)\n            height_max = min(int(nonzero_indices[:, 0].max().item() + padding_ratio * imgH), imgH)\n            width_min = max(int(nonzero_indices[:, 1].min().item() - padding_ratio * imgW), 0)\n            width_max = min(int(nonzero_indices[:, 1].max().item() + padding_ratio * imgW), imgW)\n            # \u7136\u540e\u627e\u5230\u7b2c\u4e00\u5217\u7684\u6700\u5927\u503c\u548c\u6700\u5c0f\u503c\u7684\u5dee\u503c\u4f5c\u4e3a\u9ad8\uff0c\u7b2c\u4e8c\u5217\u7684\u6700\u5927\u503c\u4e0e\u6700\u5c0f\u503c\u7684\u5dee\u503c\u4f5c\u4e3a\u5bbd\u3002\n            # \u4e24\u90e8\u5206\u5747\u5411\u5916\u6269\u5f20padding_ratio * imgH\u4f5c\u4e3a\u9884\u7559\u90e8\u5206\n\n            crop_images.append(\n                F.upsample_bilinear(images[batch_index:batch_index + 1, :, height_min:height_max,                                               width_min:width_max], size=(imgH, imgW)))\n            # \u9996\u5148\u6309\u5f97\u5230\u7684\u6307\u6807\u8fdb\u884c\u622a\u53d6\u56fe\u50cf(\u622a\u53d6\u56fe\u50cf\u6570\u636e\u5927\u4e8e\u9608\u503c\u7684\u90e8\u5206)\uff0c\u7136\u540e\u518d\u8fdb\u884c\u4e0a\u91c7\u6837\u653e\u5927\uff0c\u653e\u7f29\u6210\u539f\u56fe\u50cf\u5927\u5c0f\n        crop_images = torch.cat(crop_images, dim=0)# \u5c06\u88c1\u526a\u597d\u7684\u56fe\u7247\u62fc\u63a5\n        return crop_images\n    elif mode == 'drop':\n        # drop\u6a21\u5f0f\n        drop_masks = []\n        for batch_index in range(batches):\n            atten_map = attention_map[batch_index:batch_index + 1]\n            if isinstance(theta, tuple):\n                theta_d = random.uniform(*theta) * atten_map.max()\n            else:\n                theta_d = theta * atten_map.max()\n           # \u548c\u88c1\u526a\u7c7b\u4f3c\uff0c\u5f97\u5230\u7528\u4e8e\u5224\u65ad\u7684\u9608\u503c\n\n            drop_masks.append(F.upsample_bilinear(atten_map, size=(imgH, imgW)) &lt; theta_d)\n            # \u505a\u53cc\u7ebf\u6027\u4e0a\u91c7\u6837\uff0c\u5c0f\u4e8e\u9608\u503c\u7f6e\u4e3a0\uff0c\u5927\u4e8e\u7f6e\u4e3a1\u3002\n        drop_masks = torch.cat(drop_masks, dim=0)\n        # \u628adrop_mask\u6309\u5217\u5408\u5e76\uff0c\u53d8\u6210B*\uff08M-1\uff09*H*W\u3002\n        drop_images = images * drop_masks.float()\n        # drop_mask\u4e0eimage\u76f8\u4e58\uff0c\u5f97\u5230dropping\u540e\u7684\u56fe\u7247\u3002\n        # \u76f4\u63a5\u505a\u70b9\u4e58\u5c31\u53ef\u4ee5(torch\u4e2d\u7684*\u5c31\u662f\u70b9\u4e58)\n        return drop_images\n    else:\n        # \u5426\u5219\u62a5\u9519\uff0c\u6570\u636e\u589e\u5e7f\u7b56\u7565\u5fc5\u987b\u662f\u88c1\u526a\u6216\u8005\u5220\u9664\n        raise ValueError('Expected mode in [\\'crop\\', \\'drop\\'], but received unsupported augmentation method %s' % mode)\n</code></pre>"},{"location":"fine-grained/code/WS-DAN2/#_13","title":"\u6a21\u578b\u4fdd\u5b58\u7b56\u7565","text":"<pre><code># \u4fdd\u5b58\u7b56\u7565\u5b9a\u4e49\uff0c\u6bcf\u6b21\u4fdd\u5b58\u6700\u597d\u7684\u6a21\u578b\nclass ModelCheckpoint(Callback):\n    def __init__(self, savepath, monitor='val_topk_accuracy', mode='max'):\n        self.savepath = savepath\n        # \u6a21\u578b\u4fdd\u5b58\u5730\u5740\n        self.monitor = monitor\n        # \u76d1\u63a7\u65b9\u5f0f\uff0c\u76d1\u63a7\u6d4b\u8bd5\u7cbe\u5ea6\n        self.mode = mode\n        # \u4fdd\u5b58\u7b56\u7565\uff0c\u9ed8\u8ba4\u4fdd\u5b58\u7cbe\u5ea6\u6700\u9ad8\u7684\u6a21\u578b\n        # \u8fd8\u6709\u4e00\u79cd\u5224\u65ad\u63aa\u65bd\u5c31\u662f\u76d1\u63a7\u6d4b\u8bd5\u7684\u635f\u5931\uff0c\u4fdd\u5b58\u635f\u5931\u6700\u5c0f\u7684\u6a21\u578b\n        self.reset()\n        super(ModelCheckpoint, self).__init__()\n\n    def reset(self):\n        if self.mode == 'max':\n            self.best_score = float('-inf')\n            # \u521d\u59cb\u5316\u6700\u9ad8\u7cbe\u5ea6\u4e3a\u8d1f\u65e0\u7a77\n        else:\n            self.best_score = float('inf')\n\n    def set_best_score(self, score):\n        if isinstance(score, np.ndarray):\n            self.best_score = score[0]\n        else:\n            self.best_score = score\n\n    def on_epoch_begin(self):\n        pass\n\n    def on_epoch_end(self, logs, net, **kwargs):\n        current_score = logs[self.monitor]\n        # \u5f97\u5230\u5f53\u524d\u7684\u6d4b\u8bd5\u7cbe\u5ea6\n        if isinstance(current_score, np.ndarray):\n            current_score = current_score[0]\n\n        if (self.mode == 'max' and current_score &gt; self.best_score) or \\\n            (self.mode == 'min' and current_score &lt; self.best_score):\n            # \u5982\u679c\u5728\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\uff0c\u6d4b\u8bd5\u7cbe\u5ea6\u6bd4\u73b0\u6709\u7684\u6700\u9ad8\u7cbe\u5ea6\u90fd\u9ad8\uff0c\u5c31\u9700\u8981\u66f4\u65b0\u6700\u9ad8\u7684\u7cbe\u5ea6\uff0c\u5e76\u4fdd\u5b58\u6a21\u578b\n            self.best_score = current_score\n\n            if isinstance(net, torch.nn.DataParallel):\n            # \u5982\u679c\u662f\u591aGPU\u5e76\u884c\u8bad\u7ec3\uff0c\u5219\u9700\u8981\u591a\u52a0\u4e00\u5c42module\n                state_dict = net.module.state_dict()\n            else:\n                state_dict = net.state_dict()\n\n            for key in state_dict.keys():\n                state_dict[key] = state_dict[key].cpu()\n                # \u628a\u6a21\u578b\u53c2\u6570\u4f20\u56de\u5230CPU\n\n            if 'feature_center' in kwargs:\n                feature_center = kwargs['feature_center']\n                feature_center = feature_center.cpu()\n                # \u7279\u5f81\u4e2d\u5fc3\u53c2\u6570\u4e5f\u8981\u4f20\u56decpu\n                torch.save({\n                    'logs': logs,\n                    'state_dict': state_dict,\n                    'feature_center': feature_center}, self.savepath)\n            else:\n                torch.save({\n                    'logs': logs,\n                    'state_dict': state_dict}, self.savepath)\n            # \u6700\u540e\u4fdd\u5b58\u6a21\u578b\n# \u8c03\u7528\u8fc7\u7a0b\ncallback = ModelCheckpoint(savepath=os.path.join(config.save_dir, config.model_name),\n                               monitor=callback_monitor,\n                               mode='max')\n</code></pre> <p>\u6ce8\uff1a\u4ee5\u4e0a\u5185\u5bb9\u4ec5\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u5927\u5bb6\u6279\u8bc4\u6307\u6b63\u3002</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e749\u67085\u65e5</p>"},{"location":"fine-grained/paper/ACNet1/","title":"\u7ec6\u7c92\u5ea6\uff1aACNet","text":""},{"location":"fine-grained/paper/ACNet1/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aIEEE Conference on Computer Vision and Pattern Recognition 2020 (CVPR, 2020)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content_CVPR_2020/papers/Ji_Attention_Convolutional_Binary_Neural_Tree_for_Fine-Grained_Visual_Categorization_CVPR_2020_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740(PyTorch\u7248\u672c)\uff1ahttps://github.com/FlyingMoon-GitHub/ACNet</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u7c7b(FGVC)</p>"},{"location":"fine-grained/paper/ACNet1/#_2","title":"\u4e3b\u8981\u601d\u60f3","text":"<p>\u2003\u2003\u7531\u4e8e\u906e\u6321\u3001\u5149\u7167\u3001\u53d8\u5f62\u5f15\u8d77\u7684\u9ad8\u7c7b\u5185\u65b9\u5dee\u4e0e\u4f4e\u7c7b\u95f4\u65b9\u5dee\uff0c\u4f7f\u5f97\u7ec6\u7c92\u5ea6\u5206\u7c7b\u53d8\u5f97\u975e\u5e38\u5177\u6709\u6311\u6218\u6027\u3002\u5bf9\u6b64\uff0c\u4f5c\u8005\u8bbe\u8ba1\u4e00\u79cd\u7528\u4e8e\u7ec6\u7c92\u5ea6\u5206\u7c7b\u7684\u6ce8\u610f\u529b\u5377\u79ef\u4e8c\u5143\u795e\u7ecf\u6811(attention convolutional binary neural tree architecture, ACNet)\uff0c\u5b83\u6cbf\u7740\u6811\u7ed3\u6784\u7684\u8fb9\u7f18\u8fdb\u884c\u5377\u79ef\u8fd0\u7b97\uff0c\u5e76\u4e14\u5728\u6bcf\u4e2a\u7ed3\u70b9\u4e2d\u4f7f\u7528\u8def\u7531\u51fd\u6570\u6765\u51b3\u5b9a\u4ece\u6839\u7ed3\u70b9\u5230\u53f6\u7ed3\u70b9\u7684\u6bcf\u4e2a\u8def\u5f84\u6982\u7387\u3002\u8fd9\u79cd\u4f53\u7cfb\u7ed3\u6784\u4f7f\u5f97\u7f51\u7edc\u7ee7\u627f\u4e86\u6df1\u5ea6\u5377\u79ef\u6a21\u578b\u7684\u7279\u5f81\u8868\u793a\u80fd\u529b\uff0c\u5e76\u4e14\u8fd8\u53ef\u4ee5\u5b66\u4e60\u7531\u7c97\u5230\u7ec6\u7684\u5206\u5c42\u7279\u5f81\u5b66\u4e60\u8fc7\u7a0b\u3002\u5728\u8fd9\u79cd\u65b9\u6cd5\u4e0b\uff0c\u6811\u7684\u4e0d\u540c\u5206\u652f\u5173\u6ce8\u7269\u4f53\u7684\u4e0d\u540c\u533a\u57df\uff0c\u5e76\u4e14\u53ef\u4ee5\u4e3b\u8981\u5b66\u4e60\u5173\u6ce8\u533a\u57df\u7684\u7279\u5f81\u8868\u793a\uff0c\u6700\u7ec8\u7684\u7c7b\u522b\u6982\u7387\u7531\u6240\u6709\u53f6\u7ed3\u70b9\u7684\u9884\u6d4b\u6982\u7387\u4ee5\u53ca\u76f8\u5e94\u7684\u8def\u5f84\u79ef\u7d2f\u6982\u7387\u4e58\u79ef\u518d\u6c42\u548c\u5f97\u5230\u3002\u53e6\u5916\uff0c\u4f5c\u8005\u8fd8\u5728\u6811\u7684\u6bcf\u4e2a\u5206\u652f\u4e0a\u8bbe\u8ba1\u4e86\u6ce8\u610f\u529b\u8f6c\u6362\u5668\uff0c\u6765\u5f3a\u5236\u6811\u7f51\u7edc\u53bb\u6355\u6349\u6709\u5224\u522b\u529b\u7684\u7279\u5f81(discriminative features)\uff0c\u4ece\u800c\u8fdb\u4e00\u6b65\u5730\u63d0\u9ad8\u8bc6\u522b\u7cbe\u5ea6\u3002</p>"},{"location":"fine-grained/paper/ACNet1/#_3","title":"\u7f51\u7edc\u7ed3\u6784","text":"<p>\u2003\u2003ACNet\u7f51\u7edc\u4e3b\u8981\u7531\u56db\u4e2a\u6a21\u5757\u7ec4\u6210\uff1a\u4e3b\u5e72\u7f51\u7edc(backbone network)\u3001\u5206\u652f\u8def\u7531(branch routing)\u3001\u6ce8\u610f\u529b\u8f6c\u6362\u5668(attention transformer)\u4ee5\u53ca\u6807\u7b7e\u9884\u6d4b(Label prediction)\u3002\u5c06ACNet\u5b9a\u4e49\u4e3a(T, O)\uff0c\u5176\u4e2dT\u5b9a\u4e49\u4e86\u6811\u7684\u62d3\u6251\u7ed3\u6784\uff0cO\u8868\u793a\u6cbf\u8fb9\u7684\u4e00\u7cfb\u5217\u64cd\u4f5c\uff0c\u4f5c\u8005\u4f7f\u7528\u7684\u662f\u5168\u4e8c\u53c9\u6811T=\\{V, \\xi\\}\uff0c\u5176\u4e2dV=\\{v_1,\\dots,v_n\\}\u8868\u793a\u7ed3\u70b9\u96c6\uff0cn\u8868\u793a\u7ed3\u70b9\u6570\u91cf\uff0c\\xi=\\{e_1,\\dots,e_k\\}\u8868\u793a\u7ed3\u70b9\u95f4\u7684\u8fb9\u96c6\uff0ck\u8868\u793a\u8fb9\u7684\u603b\u6570\u3002\u5728\u5168\u4e8c\u53c9\u6811T\u4e2d\uff0c\u6709\u5982\u4e0b\u5173\u7cfb\uff1an=2^h-1\u548ck=2^h-2\uff0c\u5176\u4e2dh\u8868\u793a\u4e8c\u53c9\u6811T\u7684\u9ad8\u5ea6(\u9884\u5148\u5b9a\u4e49\u597d)\uff0c\u6bcf\u4e2a\u7ed3\u70b9\u90fd\u662f\u7531\u51b3\u5b9a\u6837\u672c\u53d1\u9001\u8def\u5f84(\u5373\u51b3\u5b9a\u6837\u672c\u8be5\u8d70\u54ea\u4e2a\u5206\u652f)\u7684\u8def\u7531\u6a21\u5757\u7ec4\u6210\u7684\uff0c\u7ed3\u70b9\u4e4b\u95f4\u7684\u8fb9\u7531\u6ce8\u610f\u529b\u8f6c\u5316\u5668\u7ec4\u6210\u3002\u5e76\u4e14\u5728\u5b8c\u5168\u4e8c\u53c9\u6811T\u4e2d\uff0c\u4f7f\u7528\u4e86\u975e\u5bf9\u79f0\u67b6\u6784\uff0c\u5373\u5728\u5de6\u8fb9\u7f18\u4f7f\u7528\u4e24\u4e2a\u6ce8\u610f\u529b\u8f6c\u6362\u5668\uff0c\u5728\u53f3\u8fb9\u7f18\u4f7f\u7528\u4e00\u4e2a\u6ce8\u610f\u529b\u8f6c\u6362\u5668\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u7f51\u7edc\u80fd\u591f\u6355\u6349\u4e0d\u540c\u5c3a\u5ea6\u7684\u7279\u5f81\uff0c\u4ece\u800c\u83b7\u5f97\u51c6\u786e\u7684\u5206\u7c7b\u7ed3\u679c\uff0c\u7f51\u7edc\u5177\u4f53\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p> \u4e3b\u5e72\u7f51\u7edc\u7528\u4e8e\u63d0\u53d6\u539f\u59cb\u56fe\u50cf\u7684\u7279\u5f81\uff0c\u8bba\u6587\u4e2d\u4f5c\u8005\u4f7f\u7528VGG16\u548cResNet50\u4f5c\u4e3a\u672c\u5b9e\u9a8c\u7684\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\uff1b\u5206\u652f\u8def\u7531\u7528\u4e8e\u4ea7\u751f\u6bcf\u6761\u8def\u5f84\u7684\u79ef\u7d2f\u6982\u7387\uff0c\u4ee5\u9ad8\u5ea6\u4e3a3\u7684\u4e8c\u53c9\u6811\u4e3a\u4f8b\uff0c\u6811\u6700\u7ec8\u4f1a\u4ea7\u751f\u56db\u4e2a\u53f6\u5b50\u7ed3\u70b9\uff0c\u6bcf\u4e2a\u53f6\u5b50\u7ed3\u70b9\u5206\u522b\u4ee3\u8868\u4e86\u4e0d\u540c\u7684\u8def\u5f84(\u4ece\u6839\u7ed3\u70b9\u5230\u53f6\u7ed3\u70b9\u7684\u8def\u5f84)\uff0c\u56e0\u6b64\u6bcf\u6761\u8def\u5f84\u4f1a\u5bf9\u5e94\u4e00\u4e2a\u79ef\u7d2f\u6982\u7387\uff0c\u5373\u6839\u7ed3\u70b9\u7279\u5f81\u9009\u62e9\u5f53\u524d\u8def\u5f84\u5230\u8fbe\u53f6\u7ed3\u70b9\u7684\u6982\u7387(\u8fd9\u91cc\u4e5f\u53ef\u4ee5\u770b\u4f5c\u6bd4\u4f8b\uff0c\u5373\u5f53\u524d\u8def\u5f84\u5f97\u5230\u7684\u9884\u6d4b\u6982\u7387\u5360\u603b\u6982\u7387\u7684\u767e\u5206\u4e4b\u591a\u5c11)\uff0c\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u56db\u4e2a\u53f6\u7ed3\u70b9\u7684\u79ef\u7d2f\u6982\u7387\u6c42\u548c\u5e94\u5f53\u4e3a1\uff0c\u4e0b\u6587\u4e2d\u4f1a\u6709\u8bc1\u660e\uff1b\u6ce8\u610f\u529b\u8f6c\u6362\u5668\u7528\u4e8e\u9f13\u52b1\u7f51\u7edc\u6355\u6349\u6709\u5224\u522b\u529b\u7684\u533a\u57df\uff0c\u7279\u5f81\u56fe\u6bcf\u7ecf\u8fc7\u4e00\u6b21\u6ce8\u610f\u529b\u8f6c\u6362\u5668\uff0c\u90fd\u4f1a\u6355\u6349\u4e00\u6b21\u6709\u5224\u522b\u529b\u7279\u5f81\u7684\u533a\u57df\uff0c\u76f8\u5e94\u6539\u53d8\u4e00\u6b21\u7279\u5f81\u56fe\u4e0a\u7684\u6570\u636e\uff1b\u6807\u7b7e\u9884\u6d4b\u6a21\u5757\u6839\u636e\u53f6\u5b50\u7ed3\u70b9\u4e0a\u7684\u7279\u5f81\u56fe\u6765\u9884\u6d4b\u7c7b\u522b\u6982\u7387\uff0c\u56e0\u6b64\u6700\u540e\u6bcf\u4e2a\u53f6\u5b50\u7ed3\u70b9\u90fd\u4f1a\u4ea7\u751f\u4e00\u4e2a\u9884\u6d4b\u6982\u7387\uff0c\u6bcf\u4e2a\u53f6\u5b50\u7ed3\u70b9\u7684\u9884\u6d4b\u6982\u7387\u4e58\u4ee5\u76f8\u5e94\u53f6\u5b50\u7ed3\u70b9\u7684\u79ef\u7d2f\u6982\u7387\u518d\u6c42\u548c\u5c31\u5f97\u5230\u4e86\u7f51\u7edc\u6700\u7ec8\u7684\u9884\u6d4b\u6982\u7387\u3002</p> <p>\u5206\u652f\u8def\u7531\u6a21\u5757\uff1a</p> <p>\u2003\u2003\u4f5c\u8005\u901a\u8fc7\u8bbe\u8ba1\u5206\u652f\u8def\u7531\u6a21\u5757\u6765\u51b3\u5b9a\u6bcf\u4e2a\u6837\u672c\u5177\u4f53\u5e94\u8be5\u88ab\u9001\u5230\u54ea\u4e2a\u5206\u652f(\u8be5\u6a21\u5757\u751f\u6210\u88ab\u9001\u5230\u5de6\u5206\u652f\u7684\u6982\u7387\u548c\u88ab\u9001\u5230\u53f3\u5206\u652f\u7684\u6982\u7387)\uff0c\u5982\u4e0a\u56fe(b)\u6240\u793a\u3002\u5047\u8bbe\u7b2ci\u4e2a\u8def\u7531\u6a21\u5757\u547d\u540d\u4e3aR^k_i(\u00b7)\uff0c\u9996\u5148\u7279\u5f81\u56fe\u5148\u7ecf\u8fc7\u4e00\u4e2a\u5168\u5c40\u4e0a\u4e0b\u6587\u6a21\u5757(global context block, GC)\uff0c\u8be5\u6a21\u5757\u7684\u6846\u67b6\u7531\u4e0a\u4e0b\u6587\u6a21\u5757(Context Modeling)\u548c\u8f6c\u6362\u5668\u6a21\u5757(Transform)\u6784\u6210(\u5982\u4e0b\u56fe\u4e2da\u6240\u793a)\uff0c\u5c06\u7b80\u5316\u7684NL\u6a21\u5757\u7684\u524d\u534a\u90e8\u5206\u64cd\u4f5c\u63d0\u53d6\u51fa\u6765(\u5982\u4e0b\u56feb\u6240\u793a)\uff0c\u7528\u4e8e\u6784\u6210\u4e0a\u4e0b\u6587\u6a21\u5757\uff0c\u518d\u5c06\u6700\u540e\u5377\u79ef\u6838\u5c3a\u5bf8\u4e3a1\\times 1\u7684\u5377\u79ef\u5c42\u5220\u6389\uff0c\u6362\u6210SE\u6a21\u5757(Squeeze-Excitation block\uff0c\u5982\u4e0b\u56fec\u6240\u793a)\uff0c\u7528\u4e8e\u6784\u6210\u8f6c\u6362\u5668\uff0c\u6700\u7ec8\u5168\u5c40\u4e0a\u4e0b\u6587\u6a21\u5757\u7684\u7ed3\u6784\u5982\u4e0b\u56fed\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u4e0a\u56fe\u8f6c\u81ea\u8bba\u6587\u300aGCNet: Non-local Networks Meet Squeeze-Excitation Networks and Beyond\u300b</p> <p>\u2003\u2003\u56fe\u7247\u7ecf\u8fc7\u5168\u5c40\u4e0a\u4e0b\u6587\u6a21\u5757\u53ef\u4ee5\u66f4\u597d\u5730\u96c6\u6210\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u4ece\u800c\u4f7f\u7f51\u7edc\u53ef\u4ee5\u66f4\u597d\u5730\u63cf\u8ff0\u7269\u4f53\u3002\u4e4b\u540e\u518d\u4f9d\u6b21\u7ecf\u8fc7\u5982\u4e0b\u64cd\u4f5c\uff1a\u2460\u5168\u5c40\u5e73\u5747\u6c60\u5316(GAP)\uff1b\u2461\u5143\u7d20\u5f00\u6839\u518d\u6807\u51c6\u5316(L2)\uff1b\u2462\u5168\u8fde\u63a5\u5c42(FC)\uff1b\u2463Sigmoid\u6fc0\u6d3b\u51fd\u6570\u3002\u6700\u540e\u5f97\u5230\u4f4d\u4e8e[0,1]\u4e4b\u95f4\u7684\u6982\u7387\u503c\uff0c\u8be5\u503c\u8868\u793a\u4e86\u6837\u672c\u88ab\u9001\u5230\u5de6\u4fa7\u5b50\u7ed3\u70b9\u6216\u8005\u53f3\u4fa7\u5b50\u7ed3\u70b9\u7684\u6982\u7387\u3002\u5047\u8bbe\\phi^k_i(x_j)\u8868\u793a\u7b2cj\u4e2a\u6837\u672c\u88ab\u9001\u5230\u53f3\u4fa7\u5b50\u7ed3\u70b9\u7684\u6982\u7387\uff0c\u8be5\u6982\u7387\u7531\u5206\u652f\u8def\u7531\u6a21\u5757R^k_i(x_j)\u4ea7\u751f\uff0c\u5176\u4e2d\\phi^k_i(x_j)\\in[0,1], i=1,\\dots,2^{k-1}\u3002\u5bf9\u5e94\u7684\uff0c\u6837\u672cx_j\u88ab\u9001\u5230\u5de6\u4fa7\u5b50\u7ed3\u70b9\u7684\u6982\u7387\u5c31\u662f1-\\phi^k_i(x_j)\uff0c\u8fd9\u4e9b\u6982\u7387\u5c06\u4f1a\u5728\u6700\u7ec8\u7269\u4f53\u7c7b\u522b\u9884\u6d4b\u7684\u65f6\u5019\u7528\u5230\u3002</p> <p>\u6ce8\u610f\u529b\u8f6c\u6362\u5668\uff1a</p> <p>\u2003\u2003\u6ce8\u610f\u529b\u8f6c\u5316\u5668\u7528\u4e8e\u5e2e\u52a9\u7f51\u7edc\u6355\u6349\u5177\u6709\u5224\u522b\u529b\u7684\u7279\u5f81\uff0c\u7531\u4e8e\u7ecf\u9a8c\u611f\u53d7\u91ce(\u5b9e\u9645\u7684\u611f\u53d7\u91ce)\u8981\u6bd4\u7406\u8bba\u611f\u53d7\u91ce\u5c0f\uff0c\u56e0\u6b64\u4e3a\u4e86\u589e\u5927\u611f\u53d7\u91ce\u4ece\u800c\u6355\u6349\u5224\u522b\u533a\u57df\uff0c\u4f5c\u8005\u5c06ASPP(Atrous Spatial Pyramid Pooling, ASPP)\u6a21\u5757\u6574\u5408\u5230\u6ce8\u610f\u529b\u8f6c\u6362\u5668\u4e2d\u3002\u5177\u4f53\u7684\u6765\u8bf4\uff0cASPP\u6a21\u5757\u63d0\u4f9b\u5177\u6709\u4e0d\u540c\u5c3a\u5ea6(\u611f\u53d7\u91ce)\u548c\u6ce8\u610f\u529b\u6a21\u5757\u7684\u7279\u5f81\u56fe\uff0c\u591a\u5c3a\u5ea6\u7279\u5f81\u56fe\u5c06\u7531\u56db\u4e2a\u5e76\u884c\u7684\u6269\u5f20\u5377\u79ef\u751f\u6210\uff0c\u6269\u5f20\u7387\u5206\u522b\u8bbe\u7f6e\u4e3a1,6,12,18\u3002\u4e4b\u540e\uff0c\u518d\u5229\u7528\u5377\u79ef\u6838\u5c3a\u5bf8\u4e3a1\\times 1\u4ee5\u53ca\u6b65\u957f\u4e3a1\u7684\u5377\u79ef\u64cd\u4f5c\u5c06\u6240\u5f97\u7684\u56db\u7ec4\u7279\u5f81\u56fe\u878d\u5408\u3002\u5728ASPP\u6a21\u5757\u4e4b\u540e\uff0c\u4f5c\u8005\u53c8\u63d2\u5165\u4e86\u4e00\u4e2a\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u7528\u4e8e\u751f\u6210\u5c3a\u5bf8\u4e3aR^{C\\times 1\\times 1}\u7684\u901a\u9053\u6ce8\u610f\u529b\u56fe\uff0c\u6ce8\u610f\u529b\u6a21\u5757\u7531\u5982\u4e0b\u516d\u4e2a\u6a21\u5757\u6784\u6210\uff1a\u2460\u6279\u91cf\u5f52\u4e00\u5316\u64cd\u4f5c(BN)\uff1b\u2461\u5168\u5c40\u5e73\u5747\u6c60\u5316\u64cd\u4f5c(GAP)\uff1b\u2462\u5168\u8fde\u63a5\u5c42(FC)\uff1b\u2463ReLU\u6fc0\u6d3b\u51fd\u6570\uff1b\u2464\u5168\u8fde\u63a5\u5c42(FC)\uff1b\u2465Sigmoid\u6fc0\u6d3b\u51fd\u6570\u3002\u5229\u7528\u901a\u9053\u6ce8\u610f\u529b\u56fe\u53ef\u4ee5\u6307\u5bfc\u7f51\u7edc\u53bb\u5173\u6ce8\u6709\u610f\u4e49\u7684\u7279\u5f81\u4ee5\u83b7\u5f97\u51c6\u786e\u7684\u7ed3\u679c\uff0c\u6ce8\u610f\u529b\u8f6c\u6362\u5668\u5177\u4f53\u7ed3\u6784\u5982\u4e0b\uff1a</p> <p> <p></p> <p></p> <p>\u6807\u7b7e\u9884\u6d4b\u6a21\u5757\uff1a</p> <p>\u2003\u2003\u5bf9\u4e8e\u6bcf\u4e2a\u53f6\u5b50\u7ed3\u70b9\uff0c\u4f5c\u8005\u4f7f\u7528\u6807\u7b7e\u9884\u6d4b\u6a21\u5757P_i(i=1,\\dots,2^{h-1})\u53bb\u9884\u6d4b\u5bf9\u8c61x_j\u7684\u4ece\u5c5e\u7c7b\u522b\u3002\u5047\u8bber_i^k(x_j)\u4e3a\u7269\u4f53x_j\u4ece\u6839\u7ed3\u70b9\u5230\u7b2ci\u4e2a\u53f6\u5b50\u7ed3\u70b9\u7684\u79ef\u7d2f\u6982\u7387\uff0c\u4f8b\u5982\uff1a\u5982\u679c\u6811\u4e2d\u6839\u7ed3\u70b9\u5230\u53f6\u5b50\u7ed3\u70b9R^k_i(\u00b7)\u7684\u8def\u5f84\u662fR^1_1,R^2_1,\\dots,R^k_1\uff0c\u5373\u7269\u4f53x_j\u603b\u662f\u88ab\u9001\u5f80\u5de6\u8fb9\uff0c\u5219\u4f1a\u5f97\u5230r^k_i(x_j)=\\sum^k_{i=1}\\phi_1^i(x_j)(\u8fd9\u91cc\u8ba1\u7b97\u5f97\u5230\u7684\u503c\u4e3a\u7279\u5f81\u6bcf\u6b21\u90fd\u8d70\u5de6\u8fb9\u7684\u6982\u7387)\u3002</p> <p>\u2003\u2003\u5982\u7f51\u7edc\u7ed3\u6784\u56fe\u4e2d(d)\u6240\u793a\uff0c\u6807\u7b7e\u9884\u6d4b\u6a21\u5757\u5f97\u5230\u7279\u5f81\u56fe\u4e4b\u540e\uff0c\u5c06\u7279\u5f81\u56fe\u4f9d\u6b21\u7ecf\u8fc7\u5982\u4e0b\u51e0\u4e2a\u6a21\u5757\uff1a\u2460\u6279\u91cf\u5f52\u4e00\u5316\u5c42(BN)\uff1b\u2461\u5377\u79ef\u6838\u5c3a\u5bf8\u4e3a1\\times 1\u7684\u5377\u79ef\u5c42\uff1b\u2462\u5168\u5c40\u5e73\u5747\u6c60\u5316\u5c42\uff1b\u2463\u5c06\u7279\u5f81\u5f00\u6839\u518d\u6807\u51c6\u5316\uff1b\u2464\u5168\u8fde\u63a5\u5c42(FC\uff0c\u7528\u4e8e\u9884\u6d4b\u6982\u7387)\u3002\u7136\u540e\uff0c\u6700\u7ec8\u7b2cj\u4e2a\u7269\u4f53x_j\u7684\u9884\u6d4bC(x_j)\u7531\u6240\u6709\u7684\u53f6\u5b50\u7ed3\u70b9\u7684\u9884\u6d4b\u548c\u76f8\u5e94\u7684\u79ef\u7d2f\u6982\u7387(\u7531\u5206\u652f\u8def\u7531\u6a21\u5757\u751f\u6210\u7684)\u4e58\u79ef\u518d\u6c42\u548c\u5f97\u5230\uff1a $$ C(x_j)=\\sum^{2^{h-1}}_{i=1}P_i(x_j)r_i^h(x_j) $$  \u7531\u4e0a\u8ff0\u516c\u5f0f\u6613\u77e5||C(x_j)||_1=1\uff0c\u5373\u7269\u4f53x_j\u6700\u7ec8\u9884\u6d4b\u5f97\u5230\u7684\u6240\u6709\u6982\u7387\u6c42\u548c\u4e3a1\uff1a $$ ||C(x_j)||_1=||\\sum^{2^{h-1}}_{i=1}P_i(x_j)r_i^h(x_j)||_1=1 $$ </p> <p>\u8bc1\u660e\u5982\u4e0b\uff1a</p> <p>\u2003\u2003\u8bber^k_i(\u00b7)\u4e3a\u7b2ck\u5c42\uff0c\u7b2ci\u4e2a\u5206\u652f\u8def\u7531\u6a21\u5757R^k_i(\u00b7)\u7684\u79ef\u7d2f\u6982\u7387\uff0c\u56e0\u6b64\uff0c\u5bf9\u5e94\u4e8eR^k_i(\u00b7)\u7684\u5de6\u53f3\u5b50\u7ed3\u70b9\u7684\u79ef\u7d2f\u6982\u7387\u5206\u522b\u4e3ar^{k+1}_{2i-1}(\u00b7)\u548cr^{k+1}_{2i}(\u00b7)\uff0c\u9996\u5148\u8bc1\u660e\u4e24\u4e2a\u5b50\u7ed3\u70b9\u7684\u79ef\u7d2f\u6982\u7387\u4e4b\u548c\u7b49\u4e8e\u5176\u7236\u7ed3\u70b9\u7684\u79ef\u7d2f\u6982\u7387r^k_i(x_j)\uff1a</p>  \\begin{aligned} &amp;r^{k+1}_{2i-1}(x_j)+r_{2i}^{k+1}(x_j)\\\\ &amp;=\\phi^{k+1}_{2i-1}(x_j)\u00b7r_i^k(x_j)+\\phi_{2i}^{k+1}(x_j)\u00b7r_i^k(x_j)\\\\ &amp;=\\phi^{k+1}_{2i-1}(x_j)\u00b7r_i^k(x_j)+(1-\\phi_{2i-1}^{k+1}(x_j))\u00b7r_i^k(x_j)\\\\ &amp;=r^k_i(x_j) \\end{aligned}  <p>\u2003\u2003\u540c\u65f6\uff0c\u7531\u4e8eACNet\u4e2d\u7684\u6811\u7ed3\u6784\u662f\u5b8c\u5168\u4e8c\u53c9\u6811\uff0c\u56e0\u6b64\u6709\\sum^{2^{h-1}}_{i=1}r^h_i(x_j)=\\sum^{2^{h-2}}_{i-1}(r^h_{2i-1}(x_j)+r^h_{2i}(x_j))\uff0c\u8fdb\u4e00\u6b65\u53ef\u4ee5\u5f97\u5230\\sum^{2^{h-1}}_{i=1}r^h_i(x_j)=\\sum^{2^{h-2}}_{i=1}r^{h-1}_i(x_j)\uff0c\u5373\u5f53\u524d\u5c42\u6240\u6709\u7ed3\u70b9\u7684\u79ef\u7d2f\u6982\u7387\u4e4b\u548c\u4e3a\u4e0a\u4e00\u5c42\u6240\u6709\u7ed3\u70b9\u7684\u79ef\u7d2f\u6982\u7387\u4e4b\u548c\uff0c\u9010\u6b65\u9012\u63a8\uff0c\u53ef\u4ee5\u5f97\u5230\\sum^{2^{h-1}}_{i=1}r^h_i(x_j)=\\dots=r^1_1(x_j)=1\u3002\u5e76\u4e14\u7c7b\u522b\u7684\u9884\u6d4bP_i(x_j)\u7531softmax\u751f\u6210\uff0c\u56e0\u6b64\u6709||P_i(x_j)||_1=1\uff0c\u5373\u6bcf\u4e2a\u7ed3\u70b9\u6240\u6709\u7c7b\u522b\u7684\u9884\u6d4b\u6982\u7387\u4e4b\u548c\u4e3a1\uff0c\u56e0\u6b64\u6709\u5982\u4e0b\u516c\u5f0f\u6210\u7acb\uff1a</p>  \\begin{aligned} ||C(x_j)||_1&amp;=||\\sum^{2^{h-1}}_{i=1}P_i(x_j)r_i^h(x_j)||_1\\\\ &amp;=\\sum^{2^{h-1}}_{i=1}||P_i(x_j)||_1r_i^h(x_j)=1 \\end{aligned}  <p>\u2003\u2003\u6700\u7ec8\u7684\u7f51\u7edc\u7ed3\u6784\u5982\u4e0a\u56fe\u53f3\u4fa7\u6240\u793a\uff0cACNet\u7f51\u7edc\u4f7f\u7528\u4ece\u7c97\u5230\u7ec6\u7684\u5206\u5c42\u7279\u5f81\u5b66\u4e60\u5f97\u5230\u7684\u5224\u522b\u7279\u5f81\u8fdb\u884c\u5206\u7c7b\uff0c\u7531\u56fe\u4e2d\u6700\u540e\u53f6\u5b50\u7ed3\u70b9\u7684\u53ef\u89c6\u5316\u53ef\u4ee5\u53d1\u73b0\uff0c\u975e\u5bf9\u79f0\u6ce8\u610f\u529b\u8f6c\u5316\u5668\u7684\u52a0\u5165\uff0c\u4f7f\u5f97\u6bcf\u4e2a\u7ed3\u70b9\u90fd\u96c6\u4e2d\u5173\u6ce8\u4e0d\u540c\u5c3a\u5ea6\u7684\u7279\u5f81\u533a\u57df\uff0c\u7efc\u5408\u6240\u6709\u7ed3\u70b9\u5173\u6ce8\u7684\u7279\u5f81\uff0c\u53ef\u4ee5\u51c6\u786e\u5730\u8bc6\u522b\u56fe\u7247\u7684\u7c7b\u522b\u3002</p>"},{"location":"fine-grained/paper/ACNet1/#_4","title":"\u635f\u5931\u51fd\u6570","text":"<p>\u2003\u2003ACNet\u7684\u635f\u5931\u51fd\u6570\u7531\u4e24\u90e8\u5206\u7ec4\u6210\uff0c\u5206\u522b\u4e3a\u6bcf\u4e2a\u7ed3\u70b9\u7684\u9884\u6d4b\u635f\u5931\u548c\u6700\u7ec8\u9884\u6d4b\u7ed3\u679c\u7684\u635f\u5931\uff0c\u6700\u7ec8\u7684\u635f\u5931\u7531\u4e24\u90e8\u5206\u6c42\u548c\u5f97\u5230\uff1a $$ L=L(C(x_j),y^*)+\\sum^{2^{h-1}}_{i=1}L(P_i(x_j),y^*) $$  \u5176\u4e2d\uff0ch\u8868\u793a\u6811T\u7684\u9ad8\uff0cL(C(x_j),y^*)\u8868\u793a\u6700\u7ec8\u7684\u9884\u6d4b\u6982\u7387C(x_j)\u548c\u771f\u5b9e\u6807\u7b7ey^*\u7684\u8d1f\u5bf9\u6570\u4f3c\u7136\u51fd\u6570\u635f\u5931\uff0cL(P_i(x_j),y^*)\u8868\u793a\u7b2ci\u4e2a\u7ed3\u70b9\u7684\u9884\u6d4b\u548c\u771f\u5b9e\u6807\u7b7ey^*\u7684\u8d1f\u5bf9\u6570\u4f3c\u7136\u51fd\u6570\u635f\u5931\u3002</p>"},{"location":"fine-grained/paper/ACNet1/#_5","title":"\u5b9e\u9a8c","text":""},{"location":"fine-grained/paper/ACNet1/#_6","title":"\u7cbe\u5ea6\u5bf9\u6bd4","text":"<p>CUB-200-2011</p> <p> <p></p> <p></p> <p>Stanford Cars</p> <p> <p></p> <p></p> <p>Aircraft</p> <p> <p></p> <p></p>"},{"location":"fine-grained/paper/ACNet1/#_7","title":"\u603b\u7ed3","text":"<p>\u2003\u2003\u672c\u6587\u63d0\u51fa\u4e86\u7528\u4e8e\u7ec6\u7c92\u5ea6\u5206\u7c7b\u7684\u6ce8\u610f\u529b\u5377\u79ef\u4e8c\u5143\u795e\u7ecf\u6811(ACNet)\uff0c\u5177\u4f53\u7684\u6765\u8bf4\uff0c\u6811\u7f51\u7edc\u4e2d\u4ece\u6839\u7ed3\u70b9\u5230\u53f6\u7ed3\u70b9\u5177\u6709\u591a\u79cd\u8def\u5f84\uff0c\u6bcf\u6761\u8def\u5f84\u5747\u63d2\u5165\u4e86\u6ce8\u610f\u529b\u8f6c\u6362\u5668\uff0c\u7528\u4e8e\u8ba9\u7f51\u7edc\u5728\u4e0d\u540c\u7684\u6839\u8282\u70b9\u4e0a\u805a\u7126\u4e8e\u4e0d\u540c\u7684\u5224\u522b\u529b\u533a\u57df\uff0c\u6700\u7ec8\u7684\u9884\u6d4b\u6982\u7387\u7531\u6bcf\u4e2a\u53f6\u8282\u70b9\u4e0e\u5176\u76f8\u5e94\u7684\u79ef\u7d2f\u6982\u7387\u51b3\u5b9a\uff0c\u6982\u7387\u6700\u5927\u7684\u7c7b\u522b\u5c31\u662f\u6700\u7ec8\u7684\u56fe\u7247\u7c7b\u522b\u3002</p> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u89c2\u70b9\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u5927\u5bb6\u6279\u8bc4\u6307\u6b63\u3002</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e7412\u670818\u65e5</p>"},{"location":"fine-grained/paper/API-Net1/","title":"\u7ec6\u7c92\u5ea6\uff1aAPI-Net","text":""},{"location":"fine-grained/paper/API-Net1/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aAmerican Association for Artificial Intelligence 2020 (AAAI, 2020)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://arxiv.org/pdf/2002.10191v1.pdf</p> <p>\u6e90\u7801\u5730\u5740(PyTorch\u7248\u672c)\uff1ahttps://github.com/PeiqinZhuang/API-Net</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u7c7b(FGVC)</p>"},{"location":"fine-grained/paper/API-Net1/#_2","title":"\u4e3b\u8981\u601d\u60f3","text":"<p>\u2003\u2003\u4ee5\u5f80\u7684\u7ec6\u7c92\u5ea6\u5206\u7c7b\u7b97\u6cd5\u5f80\u5f80\u662f\u901a\u8fc7\u5b66\u4e60\u5355\u4e2a\u8f93\u5165\u56fe\u50cf\u7684\u5fae\u5c0f\u7279\u5f81\u6765\u5b9e\u73b0\u7684\uff0c\u4f46\u5355\u5f20\u56fe\u7247\u6240\u8574\u542b\u7684\u79cd\u7c7b\u4fe1\u606f\u6709\u9650\uff0c\u5e76\u4e14\u96be\u4ee5\u6316\u6398\u91cc\u9762\u7684\u7cbe\u7ec6\u7279\u5f81\u3002\u76f8\u53cd\uff0c\u4eba\u4eec\u5e38\u5e38\u901a\u8fc7\u6bd4\u8f83\u4e24\u5f20\u56fe\u50cf\uff0c\u6765\u5b66\u4e60\u91cc\u9762\u7684\u7ec6\u5fae\u5dee\u5f02\uff0c\u6bd4\u5982\u4e0b\u56fe\u4e2d\u7684\u7ea2\u5634\u5de8\u9e25\u548c\u4e3d\u8272\u51e4\u5934\u71d5\u9e25\u5c5e\u4e8e\u4e24\u79cd\u9ad8\u5ea6\u76f8\u4f3c\u7684\u9e1f\u7c7b\uff0c\u5982\u679c\u4ec5\u68c0\u67e5\u5355\u4e2a\u56fe\u50cf\uff0c\u5219\u5f88\u96be\u8fa8\u8bc6\u5b83\u5c5e\u4e8e\u54ea\u4e00\u7c7b\uff0c\u5982\u679c\u6211\u4eec\u5c06\u8fd9\u4e24\u5f20\u56fe\u7247\u653e\u5728\u4e00\u8d77\uff0c\u901a\u8fc7\u5bf9\u6bd4\u89c2\u5bdf\u56fe\u50cf\u4e2d\u7684\u7ec6\u5fae\u5dee\u5f02\uff0c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u7406\u89e3\u6bcf\u4e00\u5f20\u56fe\u7247\u6240\u8574\u542b\u7684\u7279\u5f81\u4fe1\u606f\u3002\u4f8b\u5982\uff0c\u9e1f\u7684\u8eab\u4f53\u662f\u5de6\u56fe\u50cf\u7684\u91cd\u8981\u90e8\u5206\uff0c\u800c\u9e1f\u7684\u5634\u90e8\u662f\u53f3\u56fe\u50cf\u7684\u5173\u952e\u7279\u5f81\u3002\u5728\u8fd9\u79cd\u6709\u533a\u522b\u6027\u7684\u5f15\u5bfc\u4e0b\uff0c\u6211\u4eec\u5bf9\u9e1f\u7684\u8eab\u4f53\u548c\u5634\u90e8\u7ed9\u4e88\u4e86\u4e0d\u540c\u7a0b\u5ea6\u7684\u5173\u6ce8\u3002\u6ce8\u610f\uff0c\u5bf9\u4e8e\u6bcf\u53ea\u9e1f\uff0c\u6211\u4eec\u4e0d\u4ec5\u8981\u68c0\u67e5\u5b83\u7684\u7a81\u51fa\u90e8\u5206\uff0c\u8fd8\u8981\u770b\u4e00\u770b\u4e0e\u53e6\u4e00\u53ea\u9e1f\u4e0d\u540c\u7684\u90e8\u4f4d\u3002\u901a\u8fc7\u8fd9\u79cd\u5bf9\u6bd4\uff0c\u53ef\u4ee5\u544a\u8bc9\u6211\u4eec\u7ea2\u5634\u5de8\u9e25\u8eab\u4f53\u66f4\u80d6\uff0c\u4e3d\u8272\u51e4\u5934\u71d5\u9e25\u5634\u66f4\u5f2f\u3002</p> <p> <p></p> <p></p> <p>\u2003\u2003\u53d7\u4e0a\u8ff0\u601d\u60f3\u7684\u542f\u53d1\uff0c\u4f5c\u8005\u8bbe\u8ba1\u4e86\u7528\u4e8e\u7ec6\u7c92\u5ea6\u5206\u7c7b\u7684\u6210\u5bf9\u4ea4\u4e92\u7f51\u7edc(API-Net)\uff0c\u5b83\u53ef\u4ee5\u81ea\u9002\u5e94\u5730\u4ece\u4e00\u5bf9\u7ec6\u7c92\u5ea6\u56fe\u50cf\u4e2d\u53d1\u73b0\u5bf9\u6bd4\u7ebf\u7d22\uff0c\u5e76\u4e14\u901a\u8fc7\u6210\u5bf9\u4ea4\u4e92\u6a21\u578b\u533a\u5206\u5b83\u4eec\u3002\u5177\u4f53\u5730\u8bf4\uff0cAPI-Net\u53ef\u4ee5\u50cf\u4eba\u4e00\u6837\uff0c\u901a\u8fc7\u6bd4\u8f83\u4e24\u5e45\u76f8\u4f3c\u7684\u7ec6\u7c92\u5ea6\u56fe\u50cf\u6765\u5b66\u4e60\u91cc\u9762\u7684\u7279\u5f81\u5dee\u5f02\uff0c\u8be5\u7f51\u7edc\u4e3b\u8981\u7531\u4e09\u4e2a\u6a21\u5757\u7ec4\u6210\uff0c\u5373\u76f8\u4e92\u5411\u91cf(mutual vector)\u5b66\u4e60\u6a21\u5757\u3001\u95e8\u5411\u91cf\u751f\u6210\u6a21\u5757\u548c\u6210\u5bf9\u4ea4\u4e92\u6a21\u5757\u3002\u901a\u8fc7\u5c06\u4e00\u5bf9\u539f\u59cb\u56fe\u50cf\u4f5c\u4e3a\u8f93\u5165\uff0cAPI\u9996\u5148\u5b66\u4e60\u5f97\u5230\u4e00\u4e2a\u76f8\u4e92\u5411\u91cf\uff0c\u5f97\u5230\u8f93\u5165\u56fe\u50cf\u5bf9\u7684\u5bf9\u6bd4\u7ebf\u7d22\u3002\u7136\u540e\u5c06\u76f8\u4e92\u5411\u91cf\u4e0e\u5355\u4e2a\u5411\u91cf\u505a\u6bd4\u8f83\uff0c\u5f97\u5230\u4e0d\u540c\u7684\u95e8\u5411\u91cf\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u4ece\u6bcf\u4e2a\u5355\u72ec\u7684\u56fe\u50cf\u89d2\u5ea6\u6765\u7a81\u51fa\u8bed\u4e49\u5dee\u5f02\u3002\u4e4b\u540e\uff0cAPI\u5e94\u7528\u8fd9\u4e9b\u95e8\u5f97\u5230\u533a\u5206\u6ce8\u610f\u529b\uff0c\u6700\u540e\u4f20\u5165\u6210\u5bf9\u4ea4\u4e92\u6a21\u5757\u8fdb\u884c\u4ea4\u4e92\u5b66\u4e60\uff0c\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u6bcf\u4e2a\u56fe\u50cf\u53ef\u4ee5\u751f\u6210\u4e24\u4e2a\u589e\u5f3a\u7684\u7279\u5f81\u5411\u91cf\uff0c\u8fd9\u4e24\u4e2a\u5411\u91cf\u5206\u522b\u4ece\u5b83\u81ea\u5df1\u7684\u95e8\u5411\u91cf\u548c\u53e6\u4e00\u4e2a\u56fe\u7684\u95e8\u5411\u91cf\u4e2d\u6fc0\u6d3b\uff0c\u5e76\u4e14\u6bcf\u4e2a\u589e\u5f3a\u540e\u7684\u7279\u5f81\u5411\u91cf\u90fd\u53ef\u4ee5\u5f97\u5230\u4e00\u4e2a\u9884\u6d4b\u7ed3\u679c\u3002\u6700\u540e\uff0c\u6839\u636e\u6bcf\u4e2a\u589e\u5f3a\u7279\u5f81\u5411\u91cf\u7684\u9884\u6d4b\u7ed3\u679c\u6765\u4f18\u5316\u7f51\u7edc\u6574\u4f53\u7684\u53c2\u6570\uff0c\u8fdb\u4e00\u6b65\u63d0\u9ad8\u7f51\u7edc\u533a\u5206\u8fd9\u4e9b\u7279\u5f81\u7684\u80fd\u529b\u3002\u53e6\u5916\uff0c\u503c\u5f97\u4e00\u63d0\u7684\u662f\uff0c\u8be5API\u6a21\u5757\u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u5d4c\u5165\u5230\u4efb\u4f55CNN\u7f51\u7edc\u4e2d\u8fdb\u884c\u7ec6\u7c92\u5ea6\u5206\u7c7b\uff0c\u5e76\u4e14\u5728\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\u53ef\u4ee5\u5728\u4e0d\u635f\u5931\u6cdb\u5316\u80fd\u529b\u7684\u524d\u63d0\u4e0b\uff0c\u5c06\u8be5\u6a21\u5757\u5378\u8f7d\u4e0b\u6765\u4ee5\u63d0\u9ad8\u6d4b\u8bd5\u7cbe\u5ea6\u3002</p>"},{"location":"fine-grained/paper/API-Net1/#_3","title":"\u7f51\u7edc\u7ed3\u6784","text":"<p>\u2003\u2003\u7f51\u7edc\u4e3b\u8981\u7531\u4e09\u4e2a\u6a21\u5757\u6784\u6210\uff1a\u76f8\u4e92\u5411\u91cf\u5b66\u4e60\u6a21\u5757\u3001\u95e8\u5411\u91cf\u751f\u6210\u6a21\u5757\u548c\u6210\u5bf9\u4ea4\u4e92\u6a21\u5757\uff0c\u7f51\u7edc\u6574\u4f53\u6846\u67b6\u5982\u4e0b\u56fe\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u9996\u5148\uff0cAPI\u4ece\u5355\u4e2a\u56fe\u7247x_1\u548cx_2\u5b66\u4e60\u5f97\u5230\u4e00\u4e2a\u76f8\u4e92\u5411\u91cfxm\uff0c\u8be5\u5411\u91cf\u53ef\u4ee5\u603b\u7ed3\u6210\u5bf9\u7684\u5bf9\u6bd4\u7ebf\u7d22\u3002\u7136\u540e\uff0cAPI\u8fdb\u4e00\u6b65\u5c06x_m\u548cx_1\u3001x_2\u505a\u6bd4\u8f83\uff0c\u751f\u6210\u4e24\u4e2a\u4e0d\u540c\u7684\u95e8\u5411\u91cfg_1\u3001g_2\uff0c\u8fd9\u4e9b\u95e8\u5141\u8bb8API\u5206\u522b\u4ece\u5355\u72ec\u7684\u56fe\u50cf\u4e2d\u53d1\u73b0\u4e0d\u540c\u7684\u89c6\u89c9\u7ebf\u7d22\u3002\u4e4b\u540e\uff0cAPI\u5728\u95e8\u5411\u91cf\u7684\u6307\u5bfc\u4e0b\u5206\u522b\u5bf9\u4e24\u4e2a\u5411\u91cfx_1\u3001x_2\u6267\u884c\u6210\u5bf9\u4ea4\u4e92\u64cd\u4f5c\uff0c\u6700\u540e\u901a\u8fc7\u4ea4\u53c9\u71b5\u635f\u5931\u548c\u6392\u5e8f\u635f\u5931\u6765\u4f18\u5316\u7f51\u7edc\u6574\u4f53\u7684\u53c2\u6570\u3002\u6ce8\u610f\uff1aAPI\u662f\u4e00\u4e2a\u5b9e\u7528\u7684\u5373\u63d2\u5373\u7528\u6a21\u5757\uff0c\u5728\u8bad\u7ec3\u65f6\u53ef\u4ee5\u5c06API\u4e0eCNN\u7ed3\u5408\uff0c\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\u53ef\u4ee5\u5c06\u5176\u5378\u8f7d\uff0c\u53ea\u4fdd\u7559CNN\uff0c\u5e76\u4e14\u4e0d\u635f\u5931\u7cbe\u5ea6\u3002</p> <p>\u76f8\u4e92\u5411\u91cf\u7684\u5b66\u4e60</p> <p>\u2003\u2003\u9996\u5148\uff0c\u5c06\u4e24\u4e2a\u7ec6\u7c92\u5ea6\u56fe\u50cf\u4f20\u5165\u540c\u4e00\u4e2a\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u4e2d\u63d0\u53d6\u7279\u5f81\uff0c\u5f97\u5230\u7279\u5f81\u5411\u91cfx_1\u3001x_2\uff0c\u4e4b\u540e\u518d\u5c06\u4e24\u4e2a\u7279\u5f81\u5411\u91cf\u8fdb\u884c\u5806\u53e0\uff0c\u4f20\u5165\u9884\u5148\u6784\u5efa\u597d\u7684MLP\u4e2d\uff0c\u5f97\u5230\u76f8\u4e92\u5411\u91cf\uff1a $$ x_m=f_m([x_1,x_2])\\\\ \u5176\u4e2d\uff0cx_i\\in R^{2048},i\\in\\{1,2\\},x_m\\in R^{2048} $$  \u2003\u2003\u5176\u4e2d\uff0c\u4f5c\u8005\u4f7f\u7528\u4e24\u5c42\u7684MLP\u7ed3\u6784(FC(4096-&gt;512)-&gt;FC(512-&gt;2048))\uff0c\u901a\u8fc7\u5c06\u4e24\u7ec4\u7279\u5f81\u5411\u91cf\u5806\u53e0\uff0c\u518d\u8fdb\u884c\u4e00\u7cfb\u5217\u7684\u975e\u7ebf\u6027\u53d8\u6362\u5f97\u5230x_m\uff0cx_m\u53ef\u4ee5\u81ea\u9002\u5e94\u5730\u4ecex_1\u3001x_2\u4e24\u8005\u4e2d\u603b\u7ed3\uff0c\u6240\u4ee5\u5b83\u901a\u5e38\u5305\u542b\u4e00\u5bf9\u56fe\u7247(x_1\u3001x_2)\u4e2d\u7684\u9ad8\u7ea7\u5bf9\u6bd4\u7ebf\u7d22\u3002</p> <p>\u95e8\u5411\u91cf\u7684\u751f\u6210</p> <p>\u2003\u2003\u5728\u5b66\u4e60\u4e86\u76f8\u4e92\u5411\u91cf\u4e4b\u540e\uff0c\u4e3a\u4e86\u8fdb\u4e00\u6b65\u5206\u522b\u4ece\u6bcf\u4e2a\u4e2a\u4f53\u56fe\u50cf\u7684\u89d2\u5ea6\u751f\u6210\u4e0d\u540c\u7684\u7ebf\u7d22\uff0c\u4ee5\u4fbf\u540e\u7eed\u533a\u5206\u8fd9\u5bf9\u56fe\u50cf\uff0c\u4f5c\u8005\u53c8\u5c06\u76f8\u4e92\u5411\u91cfx_m\u5206\u522b\u4e0ex_1\u3001x_2\u505a\u6bd4\u8f83\u3002\u5177\u4f53\u7684\u6765\u8bf4\uff0c\u4f5c\u8005\u8ba9x_m\u4e0exi\u5728\u901a\u9053\u7ef4\u5ea6\u4e0a\u505a\u70b9\u79ef\uff0c\u5229\u7528x_m\u6765\u6307\u5bfc\u53d1\u73b0\u5355\u72ec\u7684xi\u4e2d\u54ea\u4e9b\u901a\u9053\u5177\u6709\u5bf9\u6bd4\u7ebf\u7d22\u3002\u7136\u540e\uff0c\u6dfb\u52a0\u4e00\u4e2asigmoid\u51fd\u6570(\u8be5\u51fd\u6570\u5177\u6709\u5f52\u4e00\u5316\u7684\u529f\u80fd)\u6765\u751f\u6210\u95e8\u5411\u91cfg_i\uff1a $$ g_i=sigmoid(x_m\u2299x_i),i\\in\\{1,2\\} $$  \u2003\u2003\u5f97\u5230\u7684g_i\u662f\u4e00\u79cd\u533a\u522b\u6027\u6ce8\u610f\u529b\uff0c\u5b83\u7a81\u51fa\u4e86\u6bcf\u4e2axi\u4e2a\u4f53\u7684\u4e0d\u540c\u89c6\u89d2\u4e0a\u7684\u8bed\u4e49\u5dee\u5f02\u3002</p> <p>\u6210\u5bf9\u4ea4\u4e92\u6a21\u5757</p> <p>\u2003\u2003\u4e3a\u4e86\u6355\u6349\u4e00\u5bf9\u7cbe\u7ec6\u56fe\u50cf\u7684\u7ec6\u5fae\u5dee\u5f02\uff0c\u4eba\u4eec\u4e0d\u4ec5\u9700\u8981\u68c0\u67e5\u6bcf\u5e45\u56fe\u50cf\u7684\u7a81\u51fa\u90e8\u5206(\u5bf9\u5e94self)\uff0c\u8fd8\u8981\u68c0\u67e5\u4e0e\u53e6\u4e00\u5e45\u56fe\u50cf\u4e0d\u540c\u7684\u90e8\u5206(\u5bf9\u5e94other)\u3002\u53d7\u4e0a\u8ff0\u601d\u60f3\u7684\u542f\u53d1\uff0c\u4f5c\u8005\u901a\u8fc7\u6b8b\u5dee\u6ce8\u610f\u529b\u5f15\u5165\u4e86\u4e00\u79cd\u4ea4\u4e92\u673a\u5236\uff1a $$ x_1^{self}=x_1+x_1\u2299g_1\\\\ x_2^{self}=x_2+x_2\u2299g_2\\\\ x_1^{other}=x_1+x_1\u2299g_2\\\\ x_2^{other}=x_2+x_2\u2299g_1\\\\ $$  \u2003\u2003\u5982\u516c\u5f0f\u6240\u89c1\uff0c\u8be5\u5bf9\u56fe\u50cf\u4e2d\u7684\u6bcf\u4e2a\u7279\u5f81\u56fe\u90fd\u4f1a\u4ea7\u751f\u4e24\u4e2a\u5173\u6ce8(self \u548c other)\u7684\u7279\u5f81\u5411\u91cf(\u5177\u4f53\u53ef\u89c1\u7f51\u7edc\u7ed3\u6784\u56fe)\u3002\u5176\u4e2d\uff0cself\u8868\u793a\u7531\u672c\u56fe\u50cf\u7684\u95e8\u5411\u91cf\u7a81\u51fa\u7684\u7279\u5f81\u5411\u91cf\uff0cother\u8868\u793a\u7531\u53e6\u4e00\u4e2a\u56fe\u50cf\u7684\u95e8\u5411\u91cf\u6fc0\u6d3b\u5f97\u5230\u7684\u7279\u5f81\u5411\u91cf\u3002\u4f5c\u8005\u4f7f\u7528\u4e24\u5e45\u56fe\u50cf\u7684\u533a\u522b\u6027\u7ebf\u7d22\u6765\u589e\u5f3axi\uff0c\u8fdb\u4e00\u6b65\u901a\u8fc7\u8054\u5408\u533a\u5206\u6240\u6709\u7684\u8fd9\u4e9b\u7279\u5f81\uff0c\u6765\u964d\u4f4e\u8fd9\u5bf9\u7ec6\u7c92\u5ea6\u56fe\u50cf\u7684\u6df7\u6dc6\u3002</p>"},{"location":"fine-grained/paper/API-Net1/#_4","title":"\u8bad\u7ec3\u4e0e\u6d4b\u8bd5","text":""},{"location":"fine-grained/paper/API-Net1/#_5","title":"\u8bad\u7ec3\u8fc7\u7a0b","text":"<p>\u2003\u2003\u5f97\u5230\u56db\u4e2a\u6ce8\u610f\u7279\u5f81(attentive features)\u4e4b\u540e\uff0c\u518d\u5206\u522b\u5c06\u5176\u4f20\u5165\u5206\u7c7b\u5668(fc)\u548csoftmax\u5c42\uff1a $$ p^j_i=softmax(Wx^j_i+b)\\\\ \u5176\u4e2d\uff0cx^j_i\u8868\u793a\u6ce8\u610f\u7279\u5f81\uff0ci\\in \\{1,2\\}\uff0cj\\in \\{self,other\\}\\\\ p^j_i\\in R^C\u8868\u793a\u9884\u6d4b\u5f97\u5206\u5411\u91cf\uff0cC\u662f\u7c7b\u522b\u6570\uff0c\\{W,b\\}\u8868\u793a\u5206\u7c7b\u5668\u7684\u53c2\u6570 $$ </p>"},{"location":"fine-grained/paper/API-Net1/#_6","title":"\u635f\u5931\u51fd\u6570","text":"<p>\u2003\u2003\u4e3a\u4e86\u6709\u6548\u5730\u8bad\u7ec3API-Net\uff0c\u4f5c\u8005\u4e3a\u56fe\u50cf\u5bf9\u8bbe\u8ba1\u4e86\u5982\u4e0b\u7684\u635f\u5931\uff1a $$ L=L_{ce}+\\lambda L_{rk}\\\\ \u5176\u4e2d\uff0cL_{ce}\u8868\u793a\u4ea4\u53c9\u71b5\u635f\u5931\uff0cL_{rk}\u8868\u793a\u6392\u5e8f\u6b63\u5219\u5316\u635f\u5931 $$ \u4ea4\u53c9\u71b5\u635f\u5931 $$ L_{ce}=-\\sum_{i\\in\\{1,2\\}}\\sum_{j\\in \\{self,other\\}}y^T_ilog(p^j_i) $$  \u2003\u2003\u5176\u4e2dyi\u662f\u56fe\u50cf\u4e2d\u56fei\u7684\u6807\u7b7e\uff0c\u901a\u8fc7\u8fd9\u4e2a\u635f\u5931\uff0cAPI-Net\u53ef\u4ee5\u5728\u6807\u7b7ey_i\u7684\u76d1\u7763\u4e0b\uff0c\u9010\u6e10\u8bc6\u522b\u6240\u6709\u7684\u6ce8\u610f\u7279\u5f81</p> <p>\u6392\u5e8f\u6b63\u5219\u5316\u635f\u5931 $$ L_{rk}=\\sum_{i\\in\\{1,2\\}}max(0,p_i^{other}(c_i)-p_i^{self}(c_i)+\\epsilon)\\\\ \u5176\u4e2dp_i^j\u8868\u793a\u9884\u6d4b\u5206\u6570\uff0cc_i\u8868\u793a\u56fe\u50cfi\u7684\u5730\u9762\u771f\u5b9e\u6807\u7b7e\u5bf9\u5e94\u7684\u7d22\u5f15 $$  \u2003\u2003\u8be5\u635f\u5931\u8bbe\u8ba1\u7684\u76ee\u7684\uff1a\u7531\u4e8ex^{self}\u662f\u7531\u81ea\u5df1\u7684\u95e8\u5411\u91cf\u6fc0\u6d3b\u7684\uff0c\u56e0\u6b64\u4e0ex^{other}\u76f8\u6bd4\uff0cself\u5728\u8bc6\u522b\u56fe\u50cf\u4e0a\u5e94\u8be5\u66f4\u5177\u6709\u533a\u522b\u6027\uff0c\u5373self\u7684\u9884\u6d4b\u8981\u597d\u4e8eother\u7684\u9884\u6d4b\u3002\u901a\u8fc7\u8be5\u635f\u5931\uff0cAPI-Net\u53ef\u4ee5\u81ea\u9002\u5e94\u5730\u8003\u8651\u7279\u5f81\u7684\u4f18\u5148\u7ea7\u6765\u5b66\u4e60\u8bc6\u522b\u56fe\u50cf\u5bf9\u4e2d\u6bcf\u4e00\u4e2a\u56fe\u50cf\u3002</p>"},{"location":"fine-grained/paper/API-Net1/#_7","title":"\u56fe\u50cf\u914d\u5bf9","text":"<p>\u2003\u2003\u9996\u5148\uff0c\u5728\u4e00\u4e2abatch\u4e2d\uff0c\u968f\u673a\u62bd\u53d6N_{cl}\u4e2a\u7c7b\u522b\uff0c\u5bf9\u4e8e\u6bcf\u4e2a\u7c7b\uff0c\u518d\u968f\u673a\u62bd\u53d6N_{im}\u4e2a\u56fe\u50cf\u6837\u672c(\u6570\u636e\u5177\u4f53\u7684\u91c7\u6837\u5b9e\u73b0\u8fc7\u7a0b\u53ef\u89c1\u6e90\u7801\u7b14\u8bb0)\u3002\u7136\u540e\u4f5c\u8005\u518d\u5c06\u8fd9\u4e9b\u56fe\u50cf\u4f20\u5165\u4e3b\u5e72\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u4e2d\u751f\u6210\u7279\u5f81\u5411\u91cf\u3002\u5bf9\u4e8e\u6bcf\u5e45\u56fe\u50cf\uff0c\u4f5c\u8005\u5229\u7528\u6b27\u6c0f\u8ddd\u79bb\u5c06\u5176\u7279\u5f81\u5411\u91cf\u4e0e\u8be5\u6279\u6b21\u4e2d\u5176\u4ed6\u7684\u56fe\u50cf\u8fdb\u884c\u6bd4\u8f83\uff0c\u8ddd\u79bb\u8d8a\u5c0f\uff0c\u4ee3\u8868\u4e24\u7ec4\u7279\u5f81\u8d8a\u76f8\u8fd1\uff0c\u5373\u4e24\u5e45\u56fe\u50cf\u8d8a\u76f8\u4f3c\u3002\u56e0\u6b64\uff0c\u5bf9\u4e8e\u6bcf\u5e45\u56fe\u50cfX\uff0c\u53ef\u4ee5\u627e\u51fa\u4e24\u5e45\u76f8\u4f3c\u7684\u56fe\u50cf\u5206\u522b\u6784\u9020\u4e24\u5bf9\u56fe\u50cf\uff0c\u5373X\u4e0e\u8be5\u6279\u6b21\u4e2d\u5c5e\u4e8e\u540c\u4e00\u7c7b\u7684\u76f8\u4f3c\u56fe\u50cf(\u7c7b\u5185\u76f8\u4f3c)\u3001X\u4e0e\u8be5\u6279\u6b21\u4e2d\u5c5e\u4e8e\u4e0d\u540c\u7c7b\u7684\u76f8\u4f3c\u56fe\u50cf(\u7c7b\u95f4\u76f8\u4f3c)\u3002\u56e0\u6b64\uff0c\u6bcf\u4e2a\u6279\u6b21\u4e2d\u67092\\times N_{cl}\\times N_{im}\u5bf9\u56fe\u50cf\uff0c\u6700\u540e\u5c06\u5176\u5747\u4f20\u9012\u5230API-Net\u4e2d\uff0c\u5e76\u4e14\u603b\u7ed3\u6240\u6709\u56fe\u50cf\u5bf9\u7684\u635f\u5931\u6765\u5b9e\u73b0\u7aef\u5230\u7aef\u7684\u8bad\u7ec3\u3002</p>"},{"location":"fine-grained/paper/API-Net1/#_8","title":"\u6d4b\u8bd5","text":"<p>\u2003\u2003API\u662f\u4e00\u4e2a\u7528\u4e8e\u7ec6\u7c92\u5ea6\u5206\u7c7b\u7684\u5373\u63d2\u5373\u7528\u6a21\u5757\u3002\u5728\u8bad\u7ec3\u9636\u6bb5\u53ef\u4ee5\u4ece\u4e00\u5bf9\u56fe\u50cf\u4e2d\u603b\u7ed3\u5bf9\u6bd4\u7ebf\u7d22\uff0c\u8fdb\u4e00\u6b65\u9010\u6e10\u6982\u62ecCNN\u5bf9\u6bcf\u4e2a\u5355\u72ec\u56fe\u50cf\u7684\u8fa8\u8bc6\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u5728\u6d4b\u8bd5\u9636\u6bb5\uff0c\u53ef\u4ee5\u5c06API\u6a21\u578b\u5378\u8f7d\uff0c\u5e76\u4e14\u4e0d\u4f1a\u6709\u592a\u5927\u7684\u6cdb\u5316\u635f\u5931\u3002\u5177\u4f53\u7684\u6765\u8bf4\uff0c\u6211\u4eec\u53ea\u9700\u8981\u5c06\u6d4b\u8bd5\u56fe\u50cf\u8f93\u5165\u5230CNN\u4e3b\u5e72\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u4e2d\u63d0\u53d6\u7279\u5f81\uff0c\u7136\u540e\u5c06\u5f97\u5230\u7684\u7279\u5f81\u56fe\u76f4\u63a5\u4f20\u5165\u5206\u7c7b\u5668\u8fdb\u884c\u5206\u7c7b\uff0c\u6700\u540e\u5f97\u5230\u5206\u7c7b\u7ed3\u679c\u3002\u672c\u6587\u6d4b\u8bd5\u65b9\u6cd5\u4e0e\u666e\u901a\u7684CNN\u7f51\u7edc\u5b8c\u5168\u76f8\u540c\uff0c\u56e0\u6b64\u6781\u5927\u5730\u63d0\u5347\u4e86API-Net\u5bf9\u7ec6\u7c92\u5ea6\u5206\u7c7b\u7684\u4ef7\u503c\u3002</p>"},{"location":"fine-grained/paper/API-Net1/#_9","title":"\u7cbe\u5ea6\u5bf9\u6bd4","text":"<p>CUB-200-2011</p> <p> <p></p> <p></p> <p>Stanford Cars</p> <p> <p></p> <p></p> <p>Aircraft</p> <p> <p></p> <p></p>"},{"location":"fine-grained/paper/API-Net1/#_10","title":"\u603b\u7ed3","text":"<p>\u2003\u2003\u672c\u6587\u7b97\u6cd5\u7684\u63d0\u51fa\u59cb\u7ec8\u56f4\u7ed5\u7740\u4e00\u4e2a\u6838\u5fc3\u7684\u601d\u60f3\uff1a\u901a\u8fc7\u8054\u5408\u6bd4\u8f83\u4e00\u5bf9\u56fe\u50cf\u6765\u533a\u5206\u76f8\u4f3c\u7269\u4f53\u4e4b\u95f4\u7684\u7ec6\u5fae\u5dee\u5f02\uff0c\u53ef\u4ee5\u66f4\u597d\u5730\u63d0\u5347\u6a21\u578b\u5bf9\u7269\u4f53\u7cbe\u7ec6\u7279\u5f81\u7684\u8868\u793a\u80fd\u529b\u3002\u4f5c\u8005\u4f9d\u636e\u4e0a\u8ff0\u601d\u60f3\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u7ec6\u7c92\u5ea6\u5206\u7c7b\u7684\u6210\u5bf9\u4ea4\u4e92\u7f51\u7edc(API-Net)\uff0c\u4ed6\u53ef\u4ee5\u81ea\u9002\u5e94\u5730\u4ece\u4e00\u5bf9\u56fe\u50cf\u4e2d\u53d1\u73b0\u5bf9\u6bd4\u7ebf\u7d22\uff0c\u5e76\u4e14\u901a\u8fc7\u6210\u5bf9\u4ea4\u4e92\u6a21\u5757\u6765\u533a\u5206\u5b83\u4eec\u3002</p> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u89c2\u70b9\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u5927\u5bb6\u6279\u8bc4\u6307\u6b63\u3002</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e7411\u670825\u65e5</p>"},{"location":"fine-grained/paper/B-CNN1/","title":"\u7ec6\u7c92\u5ea6\uff1aB-CNN","text":""},{"location":"fine-grained/paper/B-CNN1/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aIEEE International Conference on Computer Vision 2015 (ICCV 2015)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Lin_Bilinear_CNN_Models_ICCV_2015_paper.pdf</p> <p>\u4ee3\u7801\u94fe\u63a5\uff08PyTorch\u7248\u672c\uff0c\u975e\u5b98\u65b9\uff09\uff1ahttps://github.com/HaoMood/bilinear-cnn</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u7c7b(FGVC)</p> <p>\u2003\u2003\u672c\u6587\u53ea\u4ecb\u7ecd\u4e86\u53cc\u7ebf\u6027\u6a21\u578b\u7684\u7f51\u7edc\u7ed3\u6784\uff0c\u539f\u8bba\u6587\u4e2d\u8fd8\u63a8\u5e7f\u4e86\u5404\u79cd\u65e0\u987a\u5e8f\u7eb9\u7406\u7684\u63cf\u8ff0(texture descriptors)\uff0c\u611f\u5174\u8da3\u7684\u540c\u5b66\u53ef\u4ee5\u53bb\u770b\u4e00\u4e0b\u539f\u6587\u3002</p>"},{"location":"fine-grained/paper/B-CNN1/#_2","title":"\u4e3b\u8981\u601d\u60f3","text":"<p>\u2003\u2003\u672c\u6587\u4f5c\u8005\u63d0\u51fa\u4e86\u53cc\u7ebf\u6027\u6a21\u578b(bilinear models)\uff0c\u7531\u4e24\u4e2a\u7279\u5f81\u63d0\u53d6\u5668\u7ec4\u6210(\u5982CNN)\uff0c\u5c06\u5b83\u4eec\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u5728\u56fe\u50cf\u7684\u6bcf\u4e2a\u4f4d\u7f6e\u5229\u7528\u5916\u79ef\u76f8\u4e58\uff0c\u5e76\u4e14\u4f7f\u7528\u8de8\u4f4d\u7f6e\u6c60\u5316(pooled across locations)\u6765\u83b7\u5f97\u56fe\u50cf\u7684\u63cf\u8ff0\u3002\u6700\u7ec8\u8f93\u51fa\u7684\u56fe\u50cf\u63cf\u8ff0\u53ef\u4ee5\u6355\u83b7\u4e24\u7ec4\u7279\u5f81\u56fe\u4e2d\u7279\u5f81\u901a\u9053\u95f4\u7684\u6210\u5bf9\u76f8\u4e92\u5173\u7cfb(pairwise correlation)\uff0c\u53ef\u4ee5\u4ee5\u5e73\u79fb\u4e0d\u53d8\u7684\u65b9\u5f0f\u5bf9\u672c\u5730\u6210\u5bf9\u7279\u5f81\u4ea4\u4e92\u8fdb\u884c\u5efa\u6a21\uff0c\u6709\u5229\u4e8e\u63a2\u7d22\u96f6\u4ef6\u7279\u5f81\u4e4b\u95f4\u7684\u4ea4\u4e92\u5173\u7cfb\uff0c\u5177\u4f53\u7f51\u7edc\u7ed3\u6784\u5982\u4e0b\u56fe\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u5982\u679c\u7f51\u7edcA\u7684\u4f5c\u7528\u662f\u7528\u4e8e\u7269\u4f53\u7684\u5b9a\u4f4d(\u5373\u5b9a\u4f4d\u5224\u522b\u90e8\u4f4d)\uff0c\u7f51\u7edcB\u7684\u4f5c\u7528\u662f\u7528\u4e8e\u63d0\u53d6\u56fe\u50cf\u7279\u5f81(\u5373\u63d0\u53d6\u5224\u522b\u90e8\u4f4d\u7684\u7279\u5f81)\uff0c\u5219\u4e24\u4e2a\u7f51\u7edc\u53ef\u4ee5\u901a\u8fc7\u53cc\u7ebf\u6027\u6a21\u578b\u76f8\u4e92\u534f\u8c03\u4f5c\u7528\uff0c\u4ece\u800c\u66f4\u597d\u5730\u5b8c\u6210\u7ec6\u7c92\u5ea6\u5206\u7c7b\u4efb\u52a1\uff0c\u5982WS-DAN(\u8bba\u6587\u7b14\u8bb0)\u4e2d\u7684\u53cc\u7ebf\u6027\u6ce8\u610f\u529b\u6c60\u5316\u6a21\u5757\u5c31\u662f\u5e94\u7528\u4e86\u8fd9\u4e00\u65b9\u6cd5\u3002</p> <p>\u6ce8\uff1a\u7b80\u5355\u6765\u8bf4\uff0c\u53cc\u7ebf\u6027\u6c60\u5316\u5c31\u662f\u4e24\u7ec4\u7279\u5f81\u56fe\u4e92\u76f8\u505a\u4e58\u79ef\uff0cA\u4e2d\u6bcf\u5f20\u7279\u5f81\u56fe\u548cB\u4e2d\u6bcf\u5f20\u7279\u5f81\u56fe\u505a\u4e58\u79ef\uff0c\u4e00\u5171\u4f1a\u5f97\u5230C_A\u548cC_B\u5f20\u7279\u5f81\u56fe\uff08C\u8868\u793a\u901a\u9053\u6570\uff09\uff0c\u4e4b\u540e\u6bcf\u5f20\u7279\u5f81\u56fe\u518d\u505a\u5168\u5c40\u5e73\u5747\u6c60\u5316\uff0c\u5bf9\u5e94\u77e9\u9635\u4e58\u79ef\u4e2d\u7684\u6c42\u548c\uff0c\u4ee5\u53ca\u5f52\u4e00\u5316\u64cd\u4f5c\uff08\u9664\u4ee5\u957f\u5bbd\u4e4b\u79ef\uff09\uff0c\u6700\u7ec8\u5f97\u5230\u7684\u7279\u5f81\u6570\u636e\u5c3a\u5bf8\u4e3a(B,C_A,C_B)\u3002\uff08\u53ef\u4ee5\u7ed3\u5408WS-DAN\u4e2d\u7684\u5e94\u7528\u6765\u7406\uff0cWS-DAN\u5c31\u662f\u4e3a\u4e86\u5145\u5206\u5229\u7528\u6240\u6709\u7684\u6ce8\u610f\u529b\u56fe\u624d\u91c7\u7528\u53cc\u7ebf\u6027\u6c60\u5316\u64cd\u4f5c\u3002\uff09</p>"},{"location":"fine-grained/paper/B-CNN1/#_3","title":"\u65b9\u6cd5","text":""},{"location":"fine-grained/paper/B-CNN1/#_4","title":"\u7528\u4e8e\u56fe\u50cf\u5206\u7c7b\u7684\u53cc\u7ebf\u6027\u6a21\u578b","text":"<p>\u6ce8\u610f\uff1a\u8fd9\u91cc\u4ecb\u7ecd\u7684\u53cc\u7ebf\u6027\u6a21\u578b\u4e3a\u901a\u7528\u7684\u65b9\u6cd5\uff0c\u6240\u4f7f\u7528\u7684\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5\u4e0d\u4e00\u5b9a\u4e3aCNN\u3002</p> <p>\u2003\u2003\u4e00\u4e2a\u7528\u4e8e\u56fe\u7247\u5206\u7c7b\u7684\u53cc\u7ebf\u6027\u6a21\u578b\\mathcal B\u53ef\u4ee5\u8868\u793a\u4e3a\\mathcal B=(f_A,f_B,\\mathcal P,\\mathcal C)\uff0c\u5176\u4e2df_A\u548cf_B\u5206\u522b\u8868\u793a\u7279\u5f81\u51fd\u6570(feature functions)\uff0c\u5373\u7279\u5f81\u63d0\u53d6\u7684\u8fc7\u7a0b\uff0c\\mathcal P\u8868\u793a\u6c60\u5316\u51fd\u6570\uff0c\\mathcal C\u8868\u793a\u5206\u7c7b\u51fd\u6570\u3002\u4e00\u4e2a\u7279\u5f81\u51fd\u6570\u53c8\u53ef\u4ee5\u8868\u793a\u4e3a\u4e00\u4e2a\u6620\u5c04\uff1af:\\mathcal L\\times \\mathcal I \\rightarrow \\mathbb R^{K\\times D}\uff0c\u5176\u4e2d\uff0c\u8f93\u5165\u56fe\u50cf\u4e3aI\\in \\mathcal I\uff0c\u6570\u636e\u4f4d\u7f6e\u4e3al\\in \\mathcal L(\u4e5f\u53ef\u4ee5\u7406\u89e3\u4e3a\u56fe\u50cf\u4e0a\u50cf\u7d20\u70b9\u7684\u4f4d\u7f6e)\uff0c\u8f93\u51fa\u7279\u5f81\u7684\u5c3a\u5bf8\u4e3aK\\times D\u3002\u4f7f\u7528\u5916\u79ef\u5c06\u6bcf\u4e2a\u4f4d\u7f6e\u7684\u7279\u5f81\u76f8\u7ec4\u5408\uff0c\u5373\u4f4d\u7f6el\u5904\u7684f_A\u548cf_B\u53cc\u7ebf\u6027\u7ec4\u5408\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ bilinear(l,I,f_A,f_B)=f_A(l,I)^Tf_B(l,I) $$ f_A\u548cf_B\u5fc5\u987b\u5177\u6709\u76f8\u540c\u7684\u7279\u5f81\u5c3a\u5bf8K\u624d\u80fd\u517c\u5bb9(\u5426\u5219\u65e0\u6cd5\u8ba1\u7b97\u5916\u79ef)\uff0cK\u7684\u53d6\u503c\u53d6\u51b3\u4e8e\u5177\u4f53\u7684\u5206\u7c7b\u7b97\u6cd5\u6a21\u578b\uff0c\u6bd4\u5982\u5728CNN\u4e2d\uff0cK\u53ef\u4ee5\u8868\u793a\u4e3a\u8f93\u51fa\u7279\u5f81\u56fe\u7684\u957f\u4e58\u4ee5\u5bbd(\u5373\u7279\u5f81\u56fe\u4e0a\u7684\u6570\u636e\u6570\u91cf)\uff0c\u800c\u6b64\u65f6D\u53ef\u4ee5\u8868\u793a\u4e3a\u7279\u5f81\u56fe\u901a\u9053\u6570\u3002\u6c60\u5316\u51fd\u6570\\mathcal P\u7528\u4e8e\u805a\u96c6\u56fe\u50cf\u4e2d\u6240\u6709\u4f4d\u7f6e\u7684\u53cc\u7ebf\u6027\u7ec4\u5408\u7ed3\u679c\uff0c\u4ece\u800c\u83b7\u5f97\u5168\u5c40\u56fe\u50cf\u8868\u793a\\Phi(I)\uff0c\u672c\u6587\u4e2d\uff0c\u4f5c\u8005\u4f7f\u7528\u6c42\u548c\u65b9\u6cd5\u6765\u6c47\u805a\u4fe1\u606f\uff1a $$ \\Phi(I)=\\sum_{l\\in \\mathcal L}bilinear(l,I,f_A,f_B)=\\sum_{l\\in \\mathcal L}f_A(l,I)^Tf_B(l,I) $$  \u2003\u2003\u7531\u4e8e\u5728\u6c60\u5316\u8fc7\u7a0b\u4e2d\u4f1a\u5ffd\u7565\u4f4d\u7f6e\u4fe1\u606f\uff0c\u56e0\u6b64\u53cc\u7ebf\u6027\u7279\u5f81\\Phi(I)\u662f\u4e00\u79cd\u65e0\u5e8f\u8868\u793a\uff0c\u5982\u679cf_A\u548cf_B\u5206\u522b\u63d0\u53d6\u5927\u5c0f\u4e3aK\\times M\u548cK\\times N\u7684\u7279\u5f81\uff0c\u5219\\Phi(I)\u7684\u5927\u5c0f\u4e3aM\\times N\u3002</p>"},{"location":"fine-grained/paper/B-CNN1/#cnn","title":"\u57fa\u4e8eCNN\u7684\u53cc\u7ebf\u6027\u6a21\u578b","text":"<p>\u2003\u2003\u7279\u5f81\u51fd\u6570f\u6700\u81ea\u7136\u7684\u9009\u62e9\u5c31\u662f\u4f7f\u7528\u7531\u5377\u79ef\u5c42\u548c\u6c60\u5316\u5c42\u7ec4\u6210\u7684CNN\uff0c\u5982ResNet\uff0cVGG\u7b49\u7b49\uff0c\u4f5c\u8005\u5728\u8bba\u6587\u4e2d\u4f7f\u7528\u5728ImageNet\u6570\u636e\u96c6\u4e0a\u9884\u5148\u8bad\u7ec3\u597d\u7684CNN\u4f5c\u4e3a\u7279\u5f81\u51fd\u6570f_A\u548cf_B\u3002f_A\u548cf_B\u6709\u4e09\u79cd\u6784\u5efa\u65b9\u5f0f\uff1a</p> <ul> <li>\u5982\u4e0b\u56fea\u6240\u793a\uff0c\u4e24\u4e2a\u7279\u5f81\u51fd\u6570\u4e2d\u7684\u53c2\u6570\u4e92\u4e0d\u5e72\u9884\uff0c\u5373\u7531\u4e24\u4e2a\u5b8c\u5168\u4e0d\u540c\u7684\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u6784\u6210\uff1b</li> <li>\u5982\u4e0b\u56feb\u6240\u793a\uff0c\u4e24\u4e2a\u7279\u5f81\u51fd\u6570\u4e2d\u524d\u534a\u90e8\u5206\u53c2\u6570\u5171\u4eab\uff0c\u540e\u534a\u90e8\u5206\u53c2\u6570\u4e92\u4e0d\u5e72\u9884\uff1b</li> <li>\u5982\u4e0b\u56fec\u6240\u793a\uff0c\u4e24\u4e2a\u7279\u5f81\u51fd\u6570\u5171\u4eab\u4e00\u7ec4\u53c2\u6570\uff0c\u5373\u7531\u4e00\u4e2a\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u6784\u6210\uff1b  \u4f5c\u8005\u5728\u6587\u4e2d\u7ed9\u51fa\u4e86\u4e0d\u540c\u7ec4\u5408\u4e0b\u7684\u8bad\u7ec3\u7ed3\u679c\uff0c\u611f\u5174\u8da3\u7684\u540c\u5b66\u53ef\u4ee5\u53bb\u770b\u4e00\u4e0b\u3002</li> </ul> <p>\u5f52\u4e00\u5316\u548c\u5206\u7c7b\uff1a</p> <p>\u2003\u2003\u4f5c\u8005\u5bf9\u5f97\u5230\u7684\u53cc\u7ebf\u6027\u7279\u5f81x=\\Phi(I)\u6267\u884c\u989d\u5916\u7684\u5f52\u4e00\u5316\u64cd\u4f5c(Normalization)\u6765\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6a21\u578b\u7684\u6027\u80fd\uff1a $$ y\\leftarrow sign(x)\\sqrt{|x|}\\\\ z\\leftarrow y/||y||_2 $$  \u5bf9\u4e8e\u5206\u7c7b\u51fd\u6570\\mathcal C\uff0c\u4f5c\u8005\u4f7f\u7528\u903b\u8f91\u56de\u5f52\u548cSVM\uff0c\u8fd9\u91cc\u4e5f\u53ef\u4ee5\u4f7f\u7528\u5168\u8fde\u63a5\u5c42fc\u4f5c\u4e3a\u5206\u7c7b\u5668\u3002</p> <p>\u7aef\u5230\u7aef\u7684\u8bad\u7ec3\uff1a</p> <p>\u2003\u2003\u6574\u4e2a\u53cc\u7ebf\u6027\u6a21\u578b\u53ef\u4ee5\u770b\u4f5c\u4e00\u4e2a\u6709\u5411\u65e0\u73af\u56fe\uff0c\u56e0\u6b64\u53ef\u4ee5\u4f7f\u7528\u53cd\u5411\u4f20\u64ad\u8ba1\u7b97\u7684\u5206\u7c7b\u635f\u5931\u6765\u8bad\u7ec3\u53c2\u6570\u3002\u53cc\u7ebf\u6027\u5f62\u5f0f\u7b80\u5316\u4e86\u68af\u5ea6\u7684\u8ba1\u7b97\uff0c\u5047\u8bbe\u4e24\u4e2a\u7f51\u7edc\u7684\u8f93\u51fa\u4e3aA\u548cB\uff0c\u5e76\u4e14\u5c3a\u5bf8\u4f9d\u6b21\u4e3aL\\times M\u548cL\\times N\uff0c\u5219\u53cc\u7ebf\u6027\u7279\u5f81x=A^TB\u7684\u5c3a\u5bf8\u4e3aM\\times N\u3002\u5047\u8bbe\\frac{dl}{dx}\u8868\u793a\u635f\u5931l\u76f8\u5bf9\u4e8ex\u7684\u68af\u5ea6\uff0c\u5219\u901a\u8fc7\u94fe\u5f0f\u6cd5\u5219\u53ef\u4ee5\u5f97\u5230\uff1a $$ \\frac{dl}{dA}=B(\\frac{dl}{dx})^T,\\quad\\frac{dl}{dB}=A(\\frac{dl}{dx}) $$  \u2003\u2003\u53ea\u8981\u53ef\u4ee5\u6709\u6548\u5730\u8ba1\u7b97A\u548cB\u7684\u68af\u5ea6\uff0c\u5c31\u53ef\u4ee5\u4ee5\u7aef\u5230\u7aef\u7684\u65b9\u5f0f\u8bad\u7ec3\u6574\u4e2a\u6a21\u578b\uff1a</p> <p> <p></p> <p></p>"},{"location":"fine-grained/paper/B-CNN1/#_5","title":"\u7cbe\u5ea6\u5bf9\u6bd4","text":"<p> <p></p> <p></p>"},{"location":"fine-grained/paper/B-CNN1/#_6","title":"\u603b\u7ed3","text":"<p>\u2003\u2003\u4f5c\u8005\u63d0\u51fa\u4e86\u7528\u4e8e\u805a\u5408\u4e8c\u9636\u7edf\u8ba1\u6570\u636e\u7684B-CNN\u67b6\u6784\uff0c\u4ee5\u77e9\u9635\u5916\u79ef\u7684\u5f62\u5f0f\u7ec4\u5408\u4e00\u5e45\u56fe\u7247\u7684\u4e24\u79cd\u7279\u5f81\uff0c\u4f7f\u7f51\u7edc\u5145\u5206\u63a2\u7d22\u96f6\u4ef6\u7279\u5f81\u4e4b\u95f4\u7684\u4ea4\u4e92\u5173\u7cfb\uff0c\u4ece\u800c\u4f7f\u7f51\u7edc\u66f4\u597d\u5730\u7406\u89e3\u56fe\u50cf\uff0c\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u3002</p> <p>\u6ce8\uff1a\u4ee5\u4e0a\u5185\u5bb9\u4ec5\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u5927\u5bb6\u6279\u8bc4\u6307\u6b63\u3002</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e741\u67089\u65e5</p>"},{"location":"fine-grained/paper/CAL1/","title":"\u7ec6\u7c92\u5ea6\uff1aCAL","text":""},{"location":"fine-grained/paper/CAL1/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aIEEE International Conference on Computer Vision 2021 (ICCV, 2021)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content/ICCV2021/papers/Rao_Counterfactual_Attention_Learning_for_Fine-Grained_Visual_Categorization_and_Re-Identification_ICCV_2021_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740(PyTorch\u7248\u672c)\uff1ahttps://github.com/raoyongming/CAL</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u7c7b(FGVC)\u3001\u884c\u4eba\u91cd\u8bc6\u522b</p>"},{"location":"fine-grained/paper/CAL1/#_2","title":"\u4e3b\u8981\u601d\u60f3","text":"<p>\u2003\u2003\u6ce8\u610f\u529b\u662f\u4eba\u7c7b\u89c6\u89c9\u611f\u77e5\u6700\u57fa\u672c\u7684\u673a\u5236\u4e4b\u4e00\uff0c\u9762\u5bf9\u590d\u6742\u7684\u573a\u666f\u65f6\uff0c\u4eba\u7c7b\u80fd\u591f\u9009\u62e9\u611f\u5174\u8da3\u7684\u533a\u57df\uff0c\u5e76\u4e14\u5229\u7528\u6ce8\u610f\u529b\u6765\u7f29\u5c0f\u641c\u7d22\u8303\u56f4\u548c\u52a0\u5feb\u8bc6\u522b\u901f\u5ea6\u3002\u73b0\u6709\u7684\u7814\u7a76\u4e2d\uff0c\u6709\u5f88\u591a\u65b9\u6cd5\u6765\u6a21\u62df\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\u4eba\u7c7b\u7684\u6ce8\u610f\u529b\u673a\u5236\uff0c\u901a\u8fc7\u53d1\u73b0\u6709\u533a\u522b\u7684\u533a\u57df\u6765\u4fc3\u8fdb\u9ad8\u6027\u80fd\u7684\u8bc6\u522b\uff0c\u5e76\u4e14\u51cf\u8f7b\u7531\u4e0d\u540c\u56e0\u7d20\u5e26\u6765\u7684\u8d1f\u9762\u5f71\u54cd(\u5982\u6742\u4e71\u7684\u80cc\u666f\u3001\u906e\u6321\u3001\u59ff\u6001\u4e0d\u4e00\u81f4\u7b49\u7b49)\u3002\u7531\u4e8e\u7ec6\u5fae\u7684\u5dee\u5f02\u662f\u533a\u5206\u5b50\u7c7b\u522b\u7684\u5173\u952e\uff0c\u56e0\u6b64\u6ce8\u610f\u529b\u673a\u5236\u5728\u7ec6\u7c92\u5ea6\u5206\u7c7b\u4e2d\u5177\u6709\u91cd\u8981\u7684\u5e94\u7528\u3002</p> <p>\u2003\u2003\u867d\u7136\u5f53\u524d\u5df2\u7ecf\u7814\u7a76\u51fa\u4e86\u591a\u79cd\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u7ec6\u7c92\u5ea6\u5206\u7c7b\u7b97\u6cd5\uff0c\u4f46\u662f\u5982\u4f55\u5b66\u4e60\u6709\u6548\u7684\u6ce8\u610f\u529b\u51e0\u4e4e\u6ca1\u6709\u88ab\u7814\u7a76\u8fc7\u3002\u73b0\u6709\u7684\u57fa\u4e8e\u5f31\u76d1\u7763\u7684\u6ce8\u610f\u529b\u5b66\u4e60\u65b9\u6cd5\u4e2d\uff0c\u6ce8\u610f\u529b\u6a21\u5757\u7684\u4f18\u5316\u5f80\u5f80\u662f\u7b80\u5355\u5730\u5229\u7528\u6700\u540e\u7684\u9884\u6d4b\u635f\u5931\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7f3a\u5c11\u4e00\u4e2a\u6709\u6548\u7684\u76d1\u7763\u4fe1\u53f7\u3002\u8fd9\u79cd\u57fa\u4e8e\u4f3c\u7136\u6027\u7684\u65b9\u6cd5\u4ec5\u4ec5\u76d1\u7763\u6700\u540e\u7684\u9884\u6d4b(\u5982\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u4ec5\u4ec5\u8981\u6c42\u6700\u540e\u9884\u6d4b\u7684\u7c7b\u522b\u6982\u7387\u5411\u6807\u7b7e\u9760\u62e2)\uff0c\u5ffd\u7565\u4e86\u6700\u7ec8\u7684\u9884\u6d4b\u548c\u6ce8\u610f\u529b\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\u3002\u5e76\u4e14\u4ee5\u524d\u7684\u65b9\u6cd5\u4e5f\u6ca1\u6709\u6559\u673a\u5668\u53bb\u533a\u5206\u4e3b\u8981\u7ebf\u7d22\u548c\u504f\u5dee\u7ebf\u7d22\uff0c\u4f8b\u5982\uff0c\u4e00\u4e2a\u7279\u5b9a\u7684\u7c7b\u522b\u4e2d\u5927\u90e8\u5206\u6837\u672c\u90fd\u662f\u4ee5\u5929\u7a7a\u4e3a\u80cc\u666f\uff0c\u90a3\u4e48\u6ce8\u610f\u529b\u6a21\u578b\u4e5f\u8bb8\u4f1a\u8ba4\u4e3a\u5929\u7a7a\u6709\u533a\u522b\u6027\u7684\u533a\u57df\u3002\u867d\u7136\u8fd9\u4e9b\u504f\u5dee\u6ce8\u610f\u529b\u53ef\u80fd\u4e5f\u4f1a\u5bf9\u5f53\u524d\u6570\u636e\u96c6\u7684\u5206\u7c7b\u6709\u5229\uff0c\u4f46\u662f\u6ce8\u610f\u529b\u6a21\u578b\u5e94\u8be5\u53ea\u5173\u6ce8\u6709\u533a\u522b\u7684\u6a21\u5f0f\uff0c\u5373\u5173\u6ce8\u4e3b\u8981\u7ebf\u7d22\u3002\u53e6\u5916\uff0c\u76f4\u63a5\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u6216\u8bb8\u4f1a\u9f13\u52b1\u6a21\u578b\u53ea\u5173\u6ce8\u7269\u4f53\u7684\u67d0\u4e9b\u5c5e\u6027\u800c\u4e0d\u662f\u6240\u6709\u7684\u5c5e\u6027\uff0c\u8fd9\u9650\u5236\u4e86\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u79cd\u6ce8\u610f\u529b\u5b66\u4e60\u65b9\u6848\u662f\u6b21\u4f18\u7684\uff0c\u56e0\u4e3a\u6240\u5b66\u7684\u6ce8\u610f\u529b\u5e76\u4e0d\u80fd\u5f97\u5230\u4fdd\u969c\uff0c\u5e76\u4e14\u6ce8\u610f\u529b\u53ef\u80fd\u7f3a\u4e4f\u8fa8\u522b\u80fd\u529b\u3001\u660e\u786e\u7684\u610f\u4e49\u4ee5\u53ca\u9c81\u68d2\u6027\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u8bad\u7ec3\u597d\u7684\u6ce8\u610f\u529b\u6a21\u578b(\u57fa\u7ebf\u6ce8\u610f\u529b)\u4ecd\u53ef\u80fd\u4f1a\u4ea7\u751f\u8bef\u5bfc\u3001\u5206\u6563\u7684\u6ce8\u610f\u529b\uff0c\u5e76\u4e14\u53ef\u80fd\u4f1a\u5bfc\u81f4\u9519\u8bef\u7684\u5206\u7c7b\u3002</p> <p> <p></p> <p> </p> <p>\u2003\u2003\u4e3a\u4e86\u66f4\u597d\u5730\u7406\u89e3\u8fd9\u79cd\u73b0\u8c61\uff0c\u4f5c\u8005\u5206\u6790\u4e86CUB\u6570\u636e\u96c6\u4e2d\u7684\u5185\u90e8\u5c5e\u6027\u548c\u5916\u90e8\u73af\u5883\u7684\u7edf\u8ba1\u6570\u636e\uff0c\u5177\u4f53\u5982\u4e0b\u56fe\u6240\u793a\u3002\u4f5c\u8005\u4f7f\u7528\u4e86\u6570\u636e\u96c6\u63d0\u4f9b\u7684\u5c5e\u6027\u5e76\u4e14\u624b\u52a8\u6536\u96c6\u73af\u5883\u7684\u7edf\u8ba1\u6570\u636e\uff0c\u4ece\u56fe\u4e2d\u53ef\u4ee5\u770b\u5230\u5c5e\u6027\u548c\u73af\u5883\u90fd\u6709\u504f\u5dee\uff0c\u8bad\u7ec3\u96c6\u4e2d\u5360\u6bd4\u9ad8\u7684\u5c5e\u6027(\u6216\u73af\u5883)\u5728\u6d4b\u8bd5\u96c6\u4e2d\u4e0d\u4e00\u5b9a\u5360\u6bd4\u9ad8\u3002\u8fd9\u8868\u660e\u80cc\u666f\u548c\u5355\u4e2a\u90e8\u4ef6\u90fd\u4e0d\u662f\u53ef\u9760\u7684\u5206\u7c7b\u7ebf\u7d22\uff0c\u56e0\u6b64\u9700\u8981\u8bbe\u8ba1\u4e00\u79cd\u8d85\u8d8a\u4f20\u7edf\u4f3c\u7136\u6700\u5927\u5316\u7684\u65b0\u6ce8\u610f\u529b\u5b66\u4e60\u65b9\u6cd5\u6765\u51cf\u8f7b\u6570\u636e\u504f\u5dee\u7684\u5f71\u54cd\u3002</p> <p> <p></p> <p> </p> <p>\u4e0a\u56fe\u4e2d\uff0c\u4f5c\u8005\u4ee5\u73af\u7eb9\u7fe0\u9e1f(Ringed Kingfisher)\u4e3a\u4f8b\uff0c\u7edf\u8ba1\u4e86\u4e0d\u540c\u5c5e\u6027\u4e0e\u4e0d\u540c\u73af\u5883\u51fa\u73b0\u7684\u9891\u7387\uff0c\u6765\u9a8c\u8bc1\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\u7684\u504f\u5dee\u73b0\u8c61\u3002</p> <p>\u2003\u2003\u7531\u4e8e\u7f3a\u4e4f\u6709\u6548\u7684\u6ce8\u610f\u529b\u8bc4\u4f30\u5de5\u5177\uff0c\u56e0\u6b64\u7ea0\u6b63\u9519\u8bef\u7684\u6ce8\u610f\u529b\u662f\u4e00\u9879\u5177\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1\u3002\u4e00\u4e2a\u76f4\u63a5\u7684\u65b9\u6cd5\u5c31\u662f\u4f7f\u7528\u989d\u5916\u7684\u6807\u6ce8\u6846\u6216\u8005\u8bed\u4e49\u63a9\u6a21\u53bb\u660e\u786e\u7684\u83b7\u5f97\u611f\u5174\u8da3\u7684\u533a\u57df\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u7684\u4eba\u529b\u6807\u6ce8\uff0c\u5f88\u96be\u6269\u5927\u89c4\u6a21\u3002</p> <p>\u2003\u2003\u672c\u6587\u4e2d\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56e0\u679c\u63a8\u7406\u7684\u53cd\u4e8b\u5b9e\u6ce8\u610f\u529b\u5b66\u4e60\u65b9\u6cd5(counterfactual attention learning, CAL)\u6765\u589e\u5f3a\u6ce8\u610f\u529b\u7684\u5b66\u4e60\u3002\u5177\u4f53\u7684\u6765\u8bf4\uff0c\u4f5c\u8005\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5de5\u5177\u6765\u5206\u6790\u5177\u6709\u53cd\u4e8b\u5b9e\u56e0\u679c\u5173\u7cfb\u7684\u4e60\u5f97\u6027\u89c6\u89c9\u6ce8\u610f\u529b(learned visual attention)\uff0c\u57fa\u672c\u7684\u601d\u60f3\u662f\u901a\u8fc7\u5bf9\u6bd4\u4e8b\u5b9e(\u5b66\u4e60\u5f97\u5230\u7684\u6ce8\u610f\u529b)\u548c\u53cd\u4e8b\u5b9e(\u672a\u6821\u6b63\u7684\u6ce8\u610f\u529b)\u5bf9\u6700\u7ec8\u9884\u6d4b\u7684\u5f71\u54cd\u6765\u91cf\u5316(\u8bc4\u4f30)\u6ce8\u610f\u529b\u7684\u8d28\u91cf\u3002\u7136\u540e\uff0c\u901a\u8fc7\u6700\u5927\u5316\u4e8c\u8005\u7684\u4e0d\u540c\u6765\u9f13\u52b1\u7f51\u7edc\u53bb\u5b66\u4e60\u66f4\u6709\u6548\u7684\u89c6\u89c9\u6ce8\u610f\u529b\uff0c\u5e76\u4e14\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u964d\u4f4e\u6570\u636e\u96c6\u7684\u504f\u5dee\u5f71\u54cd\u3002</p> <p>\u2003\u2003\u4f5c\u8005\u63d0\u51fa\u7684\u6846\u67b6\u5177\u6709\u975e\u5e38\u5e7f\u6cdb\u7684\u5e94\u7528\u6027\uff0c\u53ef\u4ee5\u4f5c\u4e3a\u5373\u63d2\u5373\u7528(plug-and-play)\u6a21\u5757\u6765\u6539\u8fdb\u5927\u90e8\u5206\u7684\u89c6\u89c9\u6ce8\u610f\u529b\u6a21\u578b\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4ec5\u5f15\u5165\u5c11\u91cf\u7684\u989d\u5916\u8ba1\u7b97\u6210\u672c\uff0c\u5e76\u4e14\u5728\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\u4e0d\u5f15\u4eba\u989d\u5916\u7684\u8ba1\u7b97\u6210\u672c\u3002</p>"},{"location":"fine-grained/paper/CAL1/#_3","title":"\u65b9\u6cd5","text":""},{"location":"fine-grained/paper/CAL1/#_4","title":"\u7f51\u7edc\u7ed3\u6784","text":"<p>\u2003\u2003\u9996\u5148\u9009\u7528\u4e00\u79cd\u5e26\u6709\u6ce8\u610f\u529b\u673a\u5236\u7684\u57fa\u7ebf\u6a21\u578b\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u539f\u56fe\u7ecf\u8fc7\u7279\u5f81\u63d0\u53d6\u5f97\u5230\u7279\u5f81\u56feX\uff0c\u4e4b\u540e\u7ecf\u8fc7\u6ce8\u610f\u529b\u6a21\u578b\u751f\u6210\u6ce8\u610f\u529b\u56feA\uff0c\u4e4b\u540e\u6ce8\u610f\u529b\u56fe\u4e0e\u7279\u5f81\u56fe\u76f8\u4e58(\u5982\u4e0b\u56fe\u7b2c\u4e00\u884c)\uff0c\u7528\u4e8e\u5f97\u5230\u6700\u7ec8\u7684\u5206\u7c7bY\u3002\u4f5c\u8005\u8bbe\u8ba1\u4e86\u4e00\u79cd\u5bb9\u6613\u5d4c\u5165\u5230\u5927\u90e8\u5206\u6ce8\u610f\u529b\u673a\u5236\u6a21\u578b\u4e2d\u7684\u6846\u67b6\uff0c\u5bf9\u4e8e\u539f\u59cb\u6ce8\u610f\u529b\u56fe\u50cf\uff0c\u76f8\u5e94\u5730\u751f\u6210\u4e00\u4e9b\u968f\u673a\u6ce8\u610f\u529b\u56fe\\overline{A}\uff0c\u901a\u8fc7\u5c06\u8be5\u968f\u673a\u6ce8\u610f\u529b\u56fe\u4e0e\u7279\u5f81\u56fe\u505a\u4e58\u79ef(\u5982\u4e0b\u56fe\u7b2c\u4e8c\u884c)\uff0c\u8fbe\u5230\u4e00\u4e2a\u53cd\u4e8b\u5b9e\u5e72\u9884\u7684\u6548\u679c\uff0c\u5f97\u5230\u53cd\u4e8b\u5b9e\u5206\u7c7bY(\\overline{A})\uff0c\u4e4b\u540eY\u4e0eY(\\overline{A})\u505a\u5dee\uff0c\u4ece\u800c\u5206\u6790\u6ce8\u610f\u529b\u56fe\u7684\u89c6\u89c9\u6548\u679c(\u8bc4\u4f30\u6ce8\u610f\u529b\u56fe\u7684\u597d\u574f)\uff0c\u6700\u540e\u518d\u4ece\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6700\u5927\u5316\u4e8c\u8005\u5dee\u5f02\u3002</p> <p> <p></p> <p> </p>"},{"location":"fine-grained/paper/CAL1/#_5","title":"\u7ec6\u7c92\u5ea6\u5206\u7c7b\u4e2d\u7684\u6ce8\u610f\u529b","text":"<p>\u2003\u2003\u9996\u5148\u56de\u987e\u4e00\u4e0b\u7ec6\u7c92\u5ea6\u5206\u7c7b\u4efb\u52a1\u4e2d\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u7f51\u7edc\u6a21\u578b\uff0c\u7ed9\u4e00\u4e2a\u8f93\u51fa\u56fe\u50cfI\u4ee5\u53ca\u76f8\u5e94\u7684\u7279\u5f81\u56feX=f(I)\uff0c\u7279\u5f81\u56fe\u5c3a\u5bf8\u4e3aH\\times W\\times C\u3002\u89c6\u89c9\u7a7a\u95f4\u6ce8\u610f\u529b\u6a21\u578b(visual spatial attention model) \\mathcal M\u901a\u8fc7\u7ed3\u5408\u7269\u4f53\u7684\u7ed3\u6784\u77e5\u8bc6\u6765\u53d1\u73b0\u6709\u533a\u5206\u5ea6\u7684\u533a\u57df\u5e76\u4e14\u6539\u8fdb\u7279\u5f81\u56feX\u3002\u76ee\u524d\u6709\u5f88\u591a\u65b9\u6cd5\u53bb\u6784\u9020\\mathcal M\uff0c\u4f5c\u8005\u5927\u81f4\u5c06\u4ed6\u4eec\u5206\u4e3a\u4e86\u4e24\u7c7b\uff1a\u2460\u5b66\u4e60\u201d\u786c\u201d\u6ce8\u610f\u529b\u56fe\uff0c\u6bcf\u4e2a\u6ce8\u610f\u529b\u90fd\u53ef\u4ee5\u8868\u793a\u4e3a\u4e00\u4e2a\u8fb9\u754c\u6846\u6216\u8005\u8bed\u4e49\u5206\u5272\u63a9\u6a21\uff0c\u901a\u8fc7\u67d0\u4e9b\u65b9\u6cd5\u5c06\u611f\u5174\u8da3\u7684\u533a\u57df\u6807\u6ce8\u51fa\u6765\uff0c\u7136\u540e\u8fdb\u4e00\u6b65\u5b66\u4e60\u8be5\u533a\u57df\u7684\u7279\u5b9a\u4fe1\u606f\u3002\u8fd9\u7ec4\u65b9\u6cd5\u901a\u5e38\u4e0e\u76ee\u6807\u68c0\u6d4b\u6216\u8bed\u4e49\u5206\u5272\u7684\u65b9\u6cd5\u76f8\u5173\u3002\u4f8b\u5982\uff1aRA-CNN(\u8bba\u6587\u7b14\u8bb0)\u3001FCAN(\u8bba\u6587)\u7b49\u7b49\u3002\u2461\u5b66\u4e60\u201d\u8f6f\u201d\u6ce8\u610f\u529b\u56fe\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5e94\u7528\u66f4\u5e7f\u6cdb\uff0c\u5e76\u4e14\u66f4\u5bb9\u6613\u4f18\u5316\u3002\u5728\u672c\u6587\u4e2d\uff0c\u4f5c\u8005\u7684\u7814\u7a76\u4e3b\u8981\u57fa\u4e8e\u5b66\u4e60\u8f6f\u6ce8\u610f\u529b\u56fe\u7684\u65b9\u6cd5\uff0c\u4f8b\u5982\uff1aWS-DAN(\u8bba\u6587\u7b14\u8bb0)\u3001MA-CNN(\u8bba\u6587)\u3001MAMC(\u8bba\u6587)\uff0c\u5728\u672c\u7814\u7a76\u7684\u5b9e\u9a8c\u4e2d\uff0c\u4f5c\u8005\u91c7\u7528\u7684\u57fa\u7ebf\u6a21\u578b(baseline model)\u4e3aWS-DAN\u3002</p> <p>\u2003\u2003\u6ce8\u610f\u529b\u6a21\u578b\u7528\u4e8e\u5b66\u4e60\u7269\u4f53\u90e8\u4ef6(\u4e5f\u53eb\u7269\u4f53\u96f6\u4ef6)\u7684\u7a7a\u95f4\u5206\u5e03\uff0c\u5373\u5b66\u4e60\u56fe\u7247\u4e2d\u54ea\u91cc\u662f\u5206\u7c7b\u7684\u5173\u952e\uff0c\u54ea\u4e9b\u533a\u57df\u662f\u8be5\u7c7b\u522b\u4e2d\u201d\u72ec\u4e00\u65e0\u4e8c\u201d\u7684\u533a\u57df\uff0c\u53ef\u4ee5\u5c06\u5176\u8868\u793a\u4e3a\u6ce8\u610f\u529b\u56feA\\in \\mathbb R^{H\\times W\\times M}_+\uff0c\u5176\u4e2d\uff0cM\u8868\u793a\u6ce8\u610f\u529b\u7684\u6570\u91cf\uff0c\u6ce8\u610f\u529b\u56fe\u7684\u8ba1\u7b97\u53ef\u8868\u793a\u4e3a\uff1a $$ A=\\{A_1,A_2,\\dots,A_M\\}=\\mathcal M(X) $$  \u5176\u4e2d\uff0cA_i\\in \\mathbb R^{H\\times W}_+\u8868\u793a\u8986\u76d6\u4e86\u539f\u56fe\u67d0\u4e00\u90e8\u5206\u7684\u6ce8\u610f\u529b\u56fe(\u4f8b\u5982\u9e1f\u7684\u7fc5\u8180\u3001\u4eba\u7684\u8863\u670d)\u3002\u6ce8\u610f\u529b\u6a21\u578b\\mathcal M\u4f7f\u75282D\u5377\u79ef\u5c42\u4ee5\u53ca\u7d27\u8ddf\u4e00\u4e2aReLU\u6fc0\u6d3b\u51fd\u6570\u751f\u6210\u6ce8\u610f\u529b\u56fe\u3002\u4e4b\u540e\u6ce8\u610f\u529b\u56fe\u88ab\u7528\u4e8e\u5bf9\u7279\u5f81\u56fe\u505a\u52a0\u6743\u64cd\u4f5c\uff0c\u5373\u6ce8\u610f\u529b\u56fe\u4e0e\u7279\u5f81\u56fe\u505a\u70b9\u79ef\uff0c\u7a81\u51fa\u539f\u7279\u5f81\u56fe\u4e0a\u611f\u5174\u8da3\u7684\u533a\u57df(\u6ce8\u610f\u529b\u56fe\u6240\u5173\u6ce8\u7684\u533a\u57df)\u3002\u4e4b\u540e\u518d\u901a\u8fc7\u5168\u5c40\u5e73\u5747\u6c60\u5316\u64cd\u4f5c\\varphi\u5bf9\u7279\u5f81\u56fe\u505a\u805a\u5408\uff0c\u5f97\u5230\u7b2ci\u5f20\u6ce8\u610f\u529b\u56fe\u7684\u7279\u5f81\u8868\u793ah_i\uff1a $$ h_i=\\varphi(X*A_i)=\\frac{1}{HW}\\sum^H_{h=1}\\sum^W_{w=1}X^{h,w}A^{h,w}_i $$  \u5176\u4e2d\uff0c*\u8868\u793a\u5143\u7d20\u70b9\u4e58\uff0c\u4e4b\u540e\u5229\u7528\u5982\u4e0b\u516c\u5f0f\u5408\u5e76\u4e0d\u540c\u90e8\u5206\u7684\u7279\u5f81\u8868\u793a(representation)\uff0c\u518d\u7ecf\u8fc7\u6807\u51c6\u5316\u64cd\u4f5c\uff0c\u8fdb\u4e00\u6b65\u5f97\u5230\u5168\u5c40\u8868\u5f81h\uff1a $$ h=normalize([h_1,h_2,\\dots,h_M]) $$  \u6700\u540e\uff0c\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u53ef\u4ee5\u5c06h\u4f20\u5165\u5206\u7c7b\u5668\u4ece\u800c\u5f97\u5230\u7c7b\u522b\u6982\u7387\uff0c\u5728\u56fe\u50cf\u68c0\u7d22\u4efb\u52a1\u4e2d\uff0c\u53ef\u4ee5\u5c06h\u4f20\u5165\u8ddd\u79bb\u5ea6\u91cf(distance metric)\u4ece\u800c\u5f97\u5230\u76f8\u4f3c\u5ea6\u5ea6\u91cf\u3002</p> <p>\u2003\u2003\u4e0b\u56fe\u4e3aWS-DAN\u4e2d\u6ce8\u610f\u529b\u6a21\u5757\u7684\u7f51\u7edc\u7ed3\u6784\u56fe\uff0c\u5728\u8bba\u6587\u4e2d\u88ab\u79f0\u4e3a\u53cc\u7ebf\u6027\u6ce8\u610f\u529b\u6c60\u5316\u6a21\u5757(Bilinear Attention Pooling)\uff0c\u5176\u4e2d\uff0c\u7279\u5f81\u56fe(Features Maps)\u5bf9\u5e94\u672c\u6587\u4e2d\u7684X\uff0c\u6ce8\u610f\u529b\u56fe(Attention Maps)\u5bf9\u5e94\u672c\u6587\u4e2d\u7684A\u3002\u9996\u5148\u7279\u5f81\u56fe\u4e0e\u6ce8\u610f\u529b\u56fe\u4e24\u4e24\u505a\u70b9\u4e58\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff0cA_i\u4e0e\u6240\u6709\u7684\u7279\u5f81\u56fe\u505a\u70b9\u4e58\uff0c\u5f97\u5230A_iF\uff0c\u6700\u540e\u4e00\u5171\u4f1a\u5f97\u5230M\u7ec4\u90e8\u4ef6\u7279\u5f81\u56fe(Part Feature Maps)\uff0c\u5206\u522b\u5bf9\u5e94M\u5f20\u6ce8\u610f\u529b\u56fe\u3002\u4e4b\u540e\u7ecf\u8fc7\u5168\u5c40\u5e73\u5747\u6c60\u5316\u64cd\u4f5c\uff0c\u5f97\u5230\u90e8\u4ef6\u7279\u5f81\u5411\u91cf\uff0c\u5bf9\u5e94\u672c\u6587\u4e2d\u7684h_i\uff0c\u6700\u540e\u7ecf\u8fc7\u5408\u5e76\u5f97\u5230\u7279\u5f81\u77e9\u9635\uff0c\u5bf9\u5e94\u672c\u6587\u4e2d\u7684h\uff0c\u611f\u5174\u8da3\u7684\u53ef\u4ee5\u770b\u4e00\u4e0b\u300aWS-DAN\u8bba\u6587\u7b14\u8bb0\u300b\u3002</p> <p> <p></p> <p> </p>"},{"location":"fine-grained/paper/CAL1/#_6","title":"\u56e0\u679c\u56fe\u4e2d\u7684\u6ce8\u610f\u529b\u6a21\u578b","text":"<p>\u2003\u2003\u5728\u4ecb\u7ecd\u53cd\u4e8b\u5b9e\u65b9\u6cd5\u4e4b\u524d\uff0c\u5148\u4ecb\u7ecd\u4e00\u4e0b\u5982\u4f55\u4f7f\u7528\u56e0\u679c\u56fe\u7684\u8bed\u8a00\u91cd\u6784\u4e0a\u8ff0\u6ce8\u610f\u529b\u6a21\u578b\u3002\u56e0\u679c\u56fe\u4e5f\u79f0\u4e3a\u7ed3\u6784\u56e0\u679c\u6a21\u578b\uff0c\u53ef\u4ee5\u7528\u4e00\u4e2a\u6709\u5411\u65e0\u73af\u56fe\\mathcal {G=\\{N, E\\}}\u8868\u793a\uff0c\u6a21\u578b\u4e2d\u6bcf\u4e2a\u53d8\u91cf\u90fd\u5bf9\u5e94\u4e00\u4e2a\u8282\u70b9\\mathcal N\uff0c\u5176\u4e2d\uff0c\u56e0\u679c\u8054\u7cfb\\mathcal E\u63cf\u8ff0\u4e86\u53d8\u91cf\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002\u5982CAL\u7ed3\u6784\u56fe\u6240\u793a(\u7b2c\u4e00\u4e2a\u56fe)\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u56e0\u679c\u56fe\u4e2d\u7684\u8282\u70b9\u6765\u8868\u793a\u6ce8\u610f\u529b\u6a21\u578b\uff0c\u5176\u4e2d\u7279\u5f81\u56fe(\u6216\u8f93\u5165\u7684\u56fe\u7247)\u4e3aX\uff0c\u5b66\u4e60\u5230\u7684\u6ce8\u610f\u529b\u56fe\u4e3aA\uff0c\u6700\u540e\u7684\u9884\u6d4b\u6982\u7387\u4e3aY\u3002X\\rightarrow A\u8868\u793a\u8f93\u5165\u7279\u5f81\u56fe\uff0c\u751f\u6210\u6ce8\u610f\u529b\u56fe\u3002(X, A)\\rightarrow Y\u8868\u793a\u7279\u5f81\u56fe\u548c\u6ce8\u610f\u529b\u56fe\u5171\u540c\u51b3\u5b9a\u6700\u7ec8\u7684\u9884\u6d4b\u3002\u8282\u70b9\u4e4b\u95f4\u7684\u56e0\u679c\u8054\u7cfb\u88ab\u7f16\u7801\u5728\u8054\u7cfb\\mathcal E\u4e2d\uff0c\u6211\u4eec\u79f0\u8282\u70b9X\u662f\u8282\u70b9A\u7684\u7236\u56e0\u679c(causal parent)\uff0cY\u662fX\u548cA\u7684\u5b50\u56e0\u679c(causal child)\u3002\u6ce8\u610f\uff0c\u4f5c\u8005\u5e76\u6ca1\u6709\u5bf9\u4e3b\u5e72\u7f51\u7edc\u548c\u6ce8\u610f\u529b\u6a21\u578b\u6dfb\u52a0\u4efb\u4f55\u7ea6\u675f\uff0c\u56e0\u6b64\u8be5\u56e0\u679c\u56fe\u4e5f\u53ef\u4ee5\u8868\u793a\u5176\u4ed6\u6ce8\u610f\u529b\u6a21\u578b\uff0c\u5373\u53ef\u4ee5\u6269\u5c55\u5230\u66f4\u5e7f\u6cdb\u7684\u6ce8\u610f\u529b\u5b66\u4e60\u95ee\u9898\u4e2d\u3002</p>"},{"location":"fine-grained/paper/CAL1/#_7","title":"\u53cd\u4e8b\u5b9e\u6ce8\u610f\u529b\u5b66\u4e60","text":"<p>\u53cd\u4e8b\u5b9e\u6ce8\u610f\u529b\u5e72\u9884\uff1a</p> <p>\u2003\u2003\u4f20\u7edf\u7684\u6a21\u578b\u4f18\u5316\u7b56\u7565\u4ec5\u901a\u8fc7\u76d1\u7763\u6700\u7ec8\u7684\u9884\u6d4bY\u6765\u4f18\u5316\u6ce8\u610f\u529b\uff0c\u5e76\u4e14\u5c06\u6a21\u578b\u89c6\u4e3a\u4e00\u4e2a\u201d\u9ed1\u76d2\u201d\uff0c\u5ffd\u7565\u4e86\u6240\u5b66\u7684\u6ce8\u610f\u529b\u56fe\u5bf9\u6700\u7ec8\u9884\u6d4b\u7684\u5f71\u54cd\u3002\u76f8\u53cd\uff0c\u56e0\u679c\u63a8\u7406\u65b9\u6cd5\u901a\u8fc7\u5206\u6790\u53d8\u91cf\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u5e2e\u52a9\u6211\u4eec\u8df3\u51fa\u201d\u9ed1\u76d2\u601d\u60f3\u201d\u7684\u5de5\u5177\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u56e0\u679c\u5173\u7cfb\u6765\u8861\u91cf\u6240\u5b66\u6ce8\u610f\u529b\u8d28\u91cf\u7684\u65b9\u6cd5\uff0c\u5e76\u4e14\u9f13\u52b1\u7f51\u7edc\u63d0\u4f9b\u66f4\u6709\u6548\u7684\u6ce8\u610f\u529b\u56fe\u4ece\u800c\u6539\u8fdb\u6a21\u578b\u3002</p> <p>\u2003\u2003\u901a\u8fc7\u5f15\u5165\u56e0\u679c\u56fe\uff0c\u6211\u4eec\u53ef\u4ee5\u76f4\u63a5\u5730\u64cd\u7eb5\u51e0\u4e2a\u53d8\u91cf\u7684\u503c\u5e76\u4e14\u89c2\u5bdf\u6548\u679c\u6765\u5206\u6790\u56e0\u679c\u5173\u7cfb\uff0c\u8be5\u64cd\u4f5c\u5728\u56e0\u679c\u63a8\u7406\u6587\u732e\u4e2d\u88ab\u79f0\u4e3a\u5e72\u9884(intervention)\uff0c\u53ef\u4ee5\u5c06\u5176\u547d\u540d\u4e3ado(\u00b7)\u3002\u5f53\u6211\u4eec\u60f3\u8981\u7814\u7a76\u53d8\u91cf\u7684\u5f71\u54cd\u65f6\uff0c\u5e72\u9884\u64cd\u4f5c\u53ef\u4ee5\u6e05\u9664\u53d8\u91cf\u7684\u6240\u6709\u8f93\u5165\u8054\u7cfb(in-coming links)\u5e76\u4e14\u4e3a\u53d8\u91cf\u91cd\u65b0\u8d4b\u503c\u3002\u4f8b\u5982\uff0c\u5728\u6211\u4eec\u7684\u56e0\u679c\u56fe\u4e2d\uff0cdo(A=\\overline{A})\u8868\u793a\u5229\u7528\u6570\u503c\\overline{A}\u6765\u4ee3\u66ff\u53d8\u91cfA\uff0c\u5e76\u4e14\u5207\u65adX\\rightarrow A\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u4ece\u800c\u8feb\u4f7f\u8be5\u53d8\u91cf\u4e0d\u518d\u7531\u7236\u56e0\u679cX\u5f15\u8d77(X\u4e0d\u518d\u5f71\u54cd\u8be5\u53d8\u91cf\u7684\u53d8\u5316)\u3002</p> <p>\u2003\u2003\u672c\u6587\u4e2d\uff0c\u4f5c\u8005\u91c7\u7528\u53cd\u4e8b\u5b9e\u5e72\u9884(counterfactual intervention)\u6765\u7814\u7a76\u6240\u5b66\u89c6\u89c9\u6ce8\u610f\u529b\u7684\u6548\u679c\u3002\u4f5c\u8005\u6784\u9020\u4e86\u5e72\u9884do(A=\\overline{A})\uff0c\u901a\u8fc7\u5047\u8c61\u4e00\u4e2a\u4e0d\u5b58\u5728\u7684\u6ce8\u610f\u529b\u56fe\\overline{A}\u6765\u66ff\u4ee3\u539f\u6765\u5b66\u5230\u7684\u6ce8\u610f\u529b\u56fe\uff0c\u5e76\u4e14\u4fdd\u6301\u7279\u5f81\u56fe\u4e0d\u53d8\u3002\u53ef\u4ee5\u8fdb\u4e00\u6b65\u5f97\u5230\u6ce8\u610f\u529b\u56fe\u88ab\u5e72\u9884\u4e4b\u540e\u7684\u6700\u7ec8\u9884\u6d4bY\u4e3a\uff1a $$ Y(do(A=\\overline{A}),X)=\\mathcal C([\\varphi(X*\\overline{A}_1),\\dots,\\varphi(X*\\overline{A}_M)]) $$  \u5176\u4e2d\uff0c\\mathcal C\u4e3a\u5206\u7c7b\u5668\u3002\u672c\u6587\u4e2d\uff0c\u4f5c\u8005\u4f7f\u7528\u4e86\u56db\u79cd\u6ce8\u610f\u529b\u5e72\u9884\u63aa\u65bd\u6765\u9a8c\u8bc1\u8bba\u70b9\uff0c\u5206\u522b\u4e3a\u968f\u673a\u6ce8\u610f\u529b\u3001\u5747\u5300\u6ce8\u610f\u529b\u3001\u53cd\u8f6c\u6ce8\u610f\u529b\u4ee5\u53ca\u6253\u4e71\u6ce8\u610f\u529b\uff1a</p> <ul> <li>\u968f\u673a\u6ce8\u610f\u529b\uff1a\u4f7f\u7528\u968f\u673a\u751f\u6210\u7684\u6ce8\u610f\u529b\u56fe\u5f53\u505a\u53cd\u4e8b\u5b9e\u6ce8\u610f\u529b\u56fe\uff0c\u6ce8\u610f\u529b\u56fe\u7684\u6570\u636e\u5206\u5e03\u670d\u4ece\u5747\u5300\u5206\u5e03\\mathcal U(0,2)\uff1b</li> <li>\u5747\u5300\u6ce8\u610f\u529b\uff1a\u9996\u5148\u8ba1\u7b97\u771f\u5b9e\u6ce8\u610f\u529b\u56fe\u6570\u636e\u7684\u5e73\u5747\u503c\uff0c\u4e4b\u540e\u5229\u7528\u8be5\u503c\u586b\u5145\u539f\u6ce8\u610f\u529b\u56fe\uff0c\u5373\u751f\u6210\u4e00\u5f20\u503c\u552f\u4e00\u7684\u56fe\uff1b</li> <li>\u53cd\u8f6c\u6ce8\u610f\u529b\uff1a\u901a\u8fc7\u5c06\u539f\u6ce8\u610f\u529b\u56fe\u51cf\u53bb\u8be5\u6ce8\u610f\u529b\u56fe\u4e0a\u7684\u6700\u5927\u503c\uff0c\u6765\u53cd\u8f6c\u6ce8\u610f\u529b\u7684\u5173\u6ce8\u533a\u57df\uff1b</li> <li>\u6253\u4e71\u6ce8\u610f\u529b\uff1a\u6cbf\u6279\u6b21(batch)\u7ef4\u5ea6\u968f\u673a\u6253\u4e71\u6ce8\u610f\u529b\u56fe\u3002</li> </ul> <p>\u5b9e\u9a8c\u8bc1\u660e\uff0c\u968f\u673a\u6ce8\u610f\u529b\u548c\u6253\u4e71\u6ce8\u610f\u529b\u6548\u679c\u8f83\u597d\u3002</p> <p>\u8bc4\u4f30\u6ce8\u610f\u529b\u6548\u679c\uff1a</p> <p>\u2003\u2003\u6240\u5b66\u6ce8\u610f\u529b\u5728\u5b9e\u9645\u9884\u6d4b\u4e2d\u7684\u6548\u679c\u53ef\u4ee5\u88ab\u8868\u793a\u4e3a\u4e24\u4e2a\u9884\u6d4b\u7684\u5dee\u5f02\uff0c\u5373\u901a\u8fc7\u8ba1\u7b97\u6ce8\u610f\u529b\u89c2\u6d4b\u5f97\u5230\u7684\u9884\u6d4bY(A=\\mathbf A,X=\\mathbf X)\u4e0e\u5bf9\u5e94\u7684\u53cd\u4e8b\u5b9e\u9009\u62e9\u5f97\u5230\u7684\u9884\u6d4bY(do(A=\\overline{A}),X=\\mathbf X)\u4e4b\u95f4\u7684\u8ddd\u79bb\uff0c\u6765\u8bc4\u4f30\u6240\u5b66\u6ce8\u610f\u529b\u56fe\u7684\u8d28\u91cf\u6548\u679c\uff1a $$ Y_{effect}=\\mathbb E_{\\overline{A}\\sim \\gamma}[Y(A=\\mathbf A,X=\\mathbf X)-Y(do(A=\\overline{A}),X=\\mathbf X)] $$  \u5176\u4e2d\uff0cY_{effect}\u4e3a\u9884\u6d4b\u6548\u679c\uff0c\\gamma\u4e3a\u53cd\u4e8b\u5b9e\u6ce8\u610f\u529b\u7684\u5206\u5e03(\u5e72\u9884\u7c7b\u578b)\u3002\u76f4\u89c2\u5730\u6765\u8bf4\uff0c\u6ce8\u610f\u529b\u7684\u6709\u6548\u6027\u53ef\u4ee5\u89e3\u91ca\u4e3a\u4e0e\u9519\u8bef\u7684\u6ce8\u610f\u529b\u76f8\u6bd4\uff0c\u771f\u6b63\u7684\u6ce8\u610f\u529b\u5982\u4f55\u6539\u5584\u6700\u7ec8\u7684\u9884\u6d4b\uff0c\u56e0\u6b64\u53ef\u4ee5\u4f7f\u7528Y_{effect}\u6765\u8861\u91cf\u6240\u5b66\u6ce8\u610f\u529b\u7684\u6548\u679c\u3002</p> <p>\u635f\u5931\u4f18\u5316\uff1a</p> <p>\u2003\u2003\u5f97\u5230\u6ce8\u610f\u529b\u56fe\u6548\u679c\u7684\u8d28\u91cf\u8bc4\u4f30\u4e4b\u540e\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u4f7f\u7528\u6ce8\u610f\u529b\u7684\u8d28\u91cf\u4f5c\u4e3a\u76d1\u7763\u4fe1\u53f7\uff0c\u6765\u660e\u786e\u5730\u6307\u5bfc\u6ce8\u610f\u529b\u7684\u5b66\u4e60\u8fc7\u7a0b\uff1a $$ L=L_{ce}(Y_{effect},y)+L_{others} $$  \u5176\u4e2d\uff0cy\u8868\u793a\u5206\u7c7b\u6807\u7b7e\uff0cL_{ce}\u8868\u793a\u4ea4\u53c9\u71b5\u635f\u5931\uff0cL_{other}\u8868\u793a\u539f\u59cb\u7f51\u7edc\u6a21\u578b\u4e2d\u5176\u4ed6\u7684\u635f\u5931\uff0c\u5982\u6807\u51c6\u7684\u5206\u7c7b\u635f\u5931\u3002\u901a\u8fc7\u4f18\u5316\u65b0\u7684\u76ee\u6807\u635f\u5931\uff0c\u53ef\u4ee5\u5b9e\u73b0\u4e24\u4e2a\u76ee\u6807\uff1a\u2460\u6ce8\u610f\u529b\u6a21\u578b\u53ef\u4ee5\u5c3d\u53ef\u80fd\u5730\u6539\u8fdb\u57fa\u4e8e\u9519\u8bef\u6ce8\u610f\u529b\u7684\u9884\u6d4b\uff0c\u4ece\u800c\u9f13\u52b1\u6ce8\u610f\u529b\u53bb\u53d1\u73b0\u6700\u5177\u6709\u533a\u5206\u5ea6\u7684\u533a\u57df\u5e76\u4e14\u907f\u514d\u4e86\u6b21\u4f18\u7ed3\u679c\uff1b\u2461\u60e9\u7f5a\u57fa\u4e8e\u9519\u8bef\u6ce8\u610f\u529b\u7684\u9884\u6d4b\uff0c\u4ece\u800c\u8feb\u4f7f\u5206\u7c7b\u5668\u66f4\u591a\u7684\u57fa\u4e8e\u4e3b\u8981\u7684\u7ebf\u7d22\u505a\u51b3\u5b9a\uff0c\u5ffd\u7565\u4e86\u5177\u6709\u504f\u5dee\u7684\u7ebf\u7d22\uff0c\u5e76\u4e14\u964d\u4f4e\u4e86\u5e26\u6709\u504f\u5dee\u7684\u8bad\u7ec3\u6570\u636e\u5bf9\u6a21\u578b\u8bad\u7ec3\u7684\u5f71\u54cd\u3002</p>"},{"location":"fine-grained/paper/CAL1/#_8","title":"\u5b9e\u9a8c","text":""},{"location":"fine-grained/paper/CAL1/#_9","title":"\u53ef\u89c6\u5316","text":"<p>\u2003\u2003\u4e3a\u4e86\u66f4\u597d\u5730\u7406\u89e3\u53cd\u4e8b\u5b9e\u6ce8\u610f\u529b\u5b66\u4e60\u65b9\u6cd5\uff0c\u4f5c\u8005\u5bf9\u6bd4\u4e86\u57fa\u7ebf\u6a21\u578b\u5f97\u5230\u7684\u6ce8\u610f\u529b\u56fe\u548c\u5f15\u5165\u4e86CAL\u7684\u6a21\u578b\u5f97\u5230\u7684\u6ce8\u610f\u529b\u56fe\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u4f5c\u8005\u63d0\u51fa\u7684\u65b9\u6cd5\u901a\u8fc7\u2460\u51cf\u5c11\u8bef\u5bfc\u6ce8\u610f\u529b\u548c\u5206\u6563\u6ce8\u610f\u529b\u2461\u9f13\u52b1\u6a21\u578b\u5173\u6ce8\u5206\u7c7b\u7684\u4e3b\u8981\u7ebf\u7d22\u5e76\u4e14\u63a2\u7d22\u66f4\u591a\u6709\u533a\u5206\u5ea6\u7684\u533a\u57df\uff0c\u6765\u5e2e\u52a9\u6a21\u578b\u505a\u51fa\u6b63\u786e\u9884\u6d4b\u3002</p> <p> <p></p> <p> </p>"},{"location":"fine-grained/paper/CAL1/#_10","title":"\u7cbe\u5ea6\u5bf9\u6bd4","text":"<p> <p></p> <p></p>"},{"location":"fine-grained/paper/CAL1/#_11","title":"\u603b\u7ed3","text":"<p>\u2003\u2003\u5728\u672c\u6587\u4e2d\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56e0\u679c\u63a8\u7406\u7684\u53cd\u4e8b\u5b9e\u6ce8\u610f\u529b\u5b66\u4e60\u65b9\u6cd5\uff0c\u53ef\u4ee5\u8ba9\u7f51\u7edc\u5b66\u5230\u66f4\u6709\u6548\u7684\u6ce8\u610f\u529b\u3002\u901a\u8fc7\u6bd4\u8f83\u4e8b\u5b9e\u6ce8\u610f\u529b\u548c\u53cd\u4e8b\u5b9e\u6ce8\u610f\u529b\u5bf9\u6700\u7ec8\u7684\u5f71\u54cd\u6765\u8bc4\u4f30\u6ce8\u610f\u529b\u7684\u8d28\u91cf\uff0c\u540c\u65f6\u6700\u5927\u5316\u4e8c\u8005\u7684\u5dee\u5f02\u6765\u9f13\u52b1\u7f51\u7edc\u5b66\u4e60\u66f4\u6709\u6548\u7684\u89c6\u89c9\u6ce8\u610f\u529b\u3002CAL\u4ec5\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5f15\u5165\u4e86\u53ef\u5ffd\u7565\u7684\u989d\u5916\u8ba1\u7b97\u6210\u672c\uff0c\u5728\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\u4e0d\u4f1a\u5f15\u5165\u4efb\u4f55\u8ba1\u7b97\u6210\u672c\uff0c\u5e76\u4e14\u8be5\u65b9\u6cd5\u662f\u4e00\u4e2a\u4e0e\u6a21\u578b\u65e0\u5173\u7684\u6846\u67b6\uff0c\u53ef\u4ee5\u8f7b\u677e\u5730\u5d4c\u5165\u5230\u5927\u90e8\u5206\u7684\u6ce8\u610f\u529b\u673a\u5236\u4e2d\uff0c\u7528\u4e8e\u589e\u5f3a\u6ce8\u610f\u529b\u7684\u5b66\u4e60\u548c\u51cf\u8f7b\u6570\u636e\u96c6\u504f\u5dee\u7684\u5f71\u54cd\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u7ec6\u7c92\u5ea6\u7684\u89c6\u89c9\u8bc6\u522b\u4efb\u52a1\u3002</p> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u89c2\u70b9\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u5927\u5bb6\u6279\u8bc4\u6307\u6b63\u3002</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e7412\u670825\u65e5</p>"},{"location":"fine-grained/paper/Cross-X1/","title":"\u7ec6\u7c92\u5ea6\uff1aCross-X","text":""},{"location":"fine-grained/paper/Cross-X1/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aIEEE International Conference on Computer Vision 2019 (ICCV, 2019)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttp://openaccess.thecvf.com/content_ICCV_2019/papers/Luo_Cross-X_Learning_for_Fine-Grained_Visual_Categorization_ICCV_2019_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740(PyTorch\u7248\u672c)\uff1ahttps://github.com/cswluo/CrossX</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u7c7b(FGVC)</p>"},{"location":"fine-grained/paper/Cross-X1/#_2","title":"\u4e3b\u8981\u601d\u60f3","text":"<p>\u2003\u2003\u7531\u4e8e\u7c7b\u5185\u5dee\u5f02\u6bd4\u8f83\u5927\u5e76\u4e14\u7c7b\u95f4\u76f8\u4f3c\u5ea6\u6bd4\u8f83\u9ad8\uff0c\u4ece\u5177\u6709\u7ec6\u5fae\u5dee\u5f02\u7684\u5b50\u7c7b\u522b\u4e2d\u8bc6\u522b\u5bf9\u8c61\u4ecd\u662f\u4e00\u9879\u5177\u6709\u6311\u6218\u7684\u4efb\u52a1\u3002\u6700\u8fd1\u7684\u5de5\u4f5c\u4e2d\uff0c\u4ee5\u5f31\u76d1\u7763\u5b66\u4e60\u7684\u8bc6\u522b\u65b9\u6cd5\u5927\u4f53\u601d\u8def\u90fd\u662f\u5148\u68c0\u6d4b\u51fa\u7269\u4f53\u7684\u90e8\u4ef6\u533a\u57df(part region)\uff0c\u4e4b\u540e\u63d0\u53d6\u76f8\u5e94\u7279\u5b9a\u4e8e\u90e8\u4ef6(part)\u7684\u7279\u5f81\u8fdb\u884c\u7ec6\u7c92\u5ea6\u5206\u7c7b\u3002\u7136\u800c\u8fd9\u4e9b\u65b9\u6cd5\u901a\u5e38\u5b64\u7acb\u5730\u5904\u7406\u6bcf\u4e2a\u56fe\u50cf\u7279\u5b9a\u4e8e\u90e8\u4ef6\u7684\u7279\u5f81\uff0c\u5ffd\u7565\u4e86\u4ed6\u4eec\u5728\u4e0d\u540c\u56fe\u50cf\u4e4b\u95f4\u7684\u76f8\u5173\u6027\uff0c\u4f46\u5b9e\u9645\u4e0a\uff0c\u4e0d\u540c\u56fe\u50cf\u4e4b\u95f4\u7684\u76f8\u5173\u8054\u7cfb\u5f80\u5f80\u8574\u542b\u4e86\u4e00\u4e9b\u5bf9\u5206\u7c7b\u5177\u6709\u91cd\u8981\u610f\u4e49\u7684\u8bed\u4e49\u4fe1\u606f\u3002\u4f5c\u8005\u6839\u636e\u8fd9\u4e2a\u601d\u60f3\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684Cross-X\u7f51\u7edc\u7ed3\u6784\uff0c\u901a\u8fc7\u63a2\u7d22\u4e0d\u540c\u56fe\u50cf\u4ee5\u53ca\u4e0d\u540c\u7f51\u7edc\u5c42\u4e4b\u95f4\u7684\u8054\u7cfb\u6765\u8fdb\u884c\u7a33\u5b9a\u7684\u7ec6\u7c92\u5ea6\u8bc6\u522b\u3002</p> <p>\u2003\u2003\u7f51\u7edc\u9996\u5148\u901a\u8fc7\u591a\u6fc0\u52b1\u6a21\u5757(excitation modules)\u751f\u6210\u6ce8\u610f\u529b\u533a\u57df\u7279\u5f81(attention region features)\uff0c\u4e4b\u540e\u518d\u8ba9\u6ce8\u610f\u529b\u533a\u57df\u7279\u5f81\u7ecf\u8fc7\u4e24\u4e2a\u6a21\u5757\uff1a\u8de8\u7c7b\u522b\u8de8\u8bed\u4e49\u6b63\u5219\u5316\u5668(cross-category cross-semantic regularizer, C3S)\u548c\u8de8\u5c42\u6b63\u5219\u5316\u5668(cross-layer, CL)\u3002C^3S\u7528\u4e8e\u5f15\u5bfc\u4e0d\u540c\u6fc0\u52b1\u6a21\u5757\u4ea7\u751f\u7684\u6ce8\u610f\u529b\u7279\u5f81\u53bb\u8868\u793a\u4e0d\u540c\u7684\u8bed\u4e49\u90e8\u4ef6\u3002\u5177\u4f53\u7684\u6765\u8bf4\uff0c\u6765\u81ea\u76f8\u540c\u8bed\u4e49\u90e8\u4ef6(\u7269\u4f53\u7684\u76f8\u540c\u90e8\u4f4d)\u7684\u6ce8\u610f\u529b\u7279\u5f81\u5e94\u8be5\u6bd4\u4e0d\u540c\u8bed\u4e49\u90e8\u4ef6\u7684\u7279\u5f81\u66f4\u5177\u6709\u76f8\u5173\u6027\uff0c\u5373\u4f7f\u4ed6\u4eec\u6765\u81ea\u4e0d\u540c\u7c7b\u522b\u4e2d\u7684\u4e0d\u540c\u56fe\u50cf\u3002\u56e0\u6b64C^3S\u901a\u8fc7\u5982\u4e0b\u65b9\u6cd5\u6765\u4f18\u5316\u7279\u5f81\u7684\u5b66\u4e60\uff1a\u6700\u5927\u5316\u76f8\u540c\u6fc0\u52b1\u6a21\u5757\u5f97\u5230\u7684\u7279\u5f81\u6ce8\u610f\u529b\u4e4b\u95f4\u7684\u76f8\u5173\u6027\uff0c\u5e76\u4e14\u6700\u5c0f\u5316\u4e0d\u540c\u6fc0\u52b1\u6a21\u5757\u5f97\u5230\u7684\u7279\u5f81\u6ce8\u610f\u529b\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u3002</p> <p>\u2003\u2003\u540c\u65f6\uff0c\u4f5c\u8005\u8fd8\u63a2\u7d22\u4e86\u7f51\u7edc\u4e0d\u540c\u5c42\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u6765\u5b66\u4e60\u66f4\u7a33\u5b9a\u7684\u591a\u5c3a\u5ea6\u6ce8\u610f\u529b\u7279\u5f81\u3002\u9996\u5148\u5229\u7528FPN\u7f51\u7edc\u53bb\u751f\u6210\u7efc\u5408\u7279\u5f81(merged features)\uff0c\u7efc\u5408\u7279\u5f81\u53ef\u4ee5\u8ba9\u7f51\u7edc\u53d1\u73b0\u5177\u6709\u7cbe\u7ec6\u7684\u7a7a\u95f4\u5206\u8fa8\u7387\u4ee5\u53ca\u4e30\u5bcc\u9ad8\u7ea7\u7684\u8bed\u4e49\u4fe1\u606f\u7684\u5c40\u90e8\u8fa8\u8bc6\u529b\u7ed3\u6784\u3002\u4e3a\u4e86\u8fdb\u4e00\u6b65\u63d0\u9ad8\u591a\u5c3a\u5ea6\u7279\u5f81\u7684\u9c81\u68d2\u6027\uff0c\u4f5c\u8005\u8bbe\u8ba1\u4e86\u8de8\u5c42\u6b63\u5219\u5316\u5668(CL)\uff0c\u7528\u4e8e\u5339\u914d\u4e2d\u5c42\u7279\u5f81\u548c\u9ad8\u5c42\u7279\u5f81\u7684\u9884\u6d4b\u5206\u5e03\u3002</p>"},{"location":"fine-grained/paper/Cross-X1/#_3","title":"\u7f51\u7edc\u7ed3\u6784","text":"<p>\u2003\u2003Cross-X\u4e3b\u8981\u7531\u4e24\u90e8\u5206\u6784\u6210\uff1a\u2460\u8de8\u7c7b\u522b\u8de8\u8bed\u4e49\u6b63\u5219\u5316\u5668(C^3S)\uff0c\u901a\u8fc7\u5229\u7528\u4e0d\u540c\u56fe\u50cf\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u6765\u5b66\u4e60\u90e8\u4ef6\u8bed\u4e49\u7279\u5f81(semantic part features)\uff1b\u2461\u8de8\u5c42\u6b63\u5219\u5316\u5668(CL)\uff0c\u901a\u8fc7\u5339\u914d\u4e0d\u540c\u5c42\u4e4b\u95f4\u7684\u9884\u6d4b\u5206\u5e03\u6765\u5b66\u4e60\u9c81\u68d2\u6027\u7279\u5f81(robust features)\uff0c\u7f51\u7edc\u7ed3\u6784\u56fe\u5982\u4e0b\uff1a</p> <p> <p></p> <p></p> <p>\u901a\u8fc7\u5e94\u7528OSME\u6a21\u5757\u6765\u8f93\u51fa\u591a\u4e2a\u7279\u5f81\u56fe\uff0c\u5728\u4e3b\u5e72\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u6700\u540e\u4e24\u4e2a\u9636\u6bb5\u5206\u522b\u5e94\u7528OSME\u6a21\u5757\uff0c\u5e76\u4e14\u5206\u522b\u8f93\u51fa\u4e24\u4e2a\u6fc0\u52b1(excitation, \u53c8\u53eb\u7279\u5f81\u6ce8\u610f\u529b\u56fe)\u3002L-1\u9636\u6bb5\u7684\u7279\u5f81\u56fe(\u84dd\u8272)\u4e0eL\u9636\u6bb5\u7684\u7279\u5f81\u56fe(\u7ea2\u8272)\u5408\u5e76\u751f\u6210\u65b0\u7684\u7279\u5f81\u56fe(\u6a59\u8272)\uff0c\u5de6\u4e0a\u89d2\u662f\u5408\u5e76\u7684\u5177\u4f53\u64cd\u4f5c\u3002\u4e4b\u540e\uff0c\u901a\u8fc7GAP\u6216\u8005GMP\u6c47\u603b\uff0c\u83b7\u5f97\u76f8\u5e94\u7684\u6c60\u5316\u7279\u5f81\u3002\u6765\u81ea\u540c\u4e00\u9636\u6bb5\u7684\u6c60\u5316\u7279\u5f81\u901a\u8fc7C^3S\u6b63\u5219\u5316\u5668\u76f8\u4e92\u7ea6\u675f\uff0c\u5e76\u4e14\u540c\u65f6\u88ab\u8fde\u63a5\u4ee5\u4f20\u5165\u5168\u8fde\u63a5\u5c42\u6765\u751f\u6210\u9884\u6d4b\uff0c\u4e4b\u540e\u5229\u7528CL\u6b63\u5219\u5316\u5668\u6765\u7ea6\u675f\u8be5\u9884\u6d4b\uff0c\u5e76\u5c06\u5176\u7ec4\u5408\u7528\u4e8e\u5206\u7c7b\u3002</p>"},{"location":"fine-grained/paper/Cross-X1/#osme","title":"OSME\u6a21\u5757","text":"<p>\u2003\u2003\u4f5c\u8005\u5f15\u7528\u4e86\u8bba\u6587\u300aMulti-attention multi-class constraint for fine-grained image recognition\u300b(\u8bba\u6587\u94fe\u63a5)\u4e2d\u8bbe\u8ba1\u7684OSME\u6a21\u5757\u6765\u4e3a\u6bcf\u5f20\u8f93\u5165\u56fe\u50cf\u751f\u6210\u591a\u4e2a\u6ce8\u610f\u529b\u7279\u5f81\u533a\u57df\u3002\u5047\u8bbeU=[u_1,\\dots,u_C]\\in R^{W\\times H \\times C}\u8868\u793a\u6b8b\u5dee\u6a21\u5757\\tau\u8f93\u51fa\u7684\u7279\u5f81\u56fe\uff0c\u4e3a\u4e86\u751f\u6210\u591a\u4e2a\u7279\u5f81\u6ce8\u610f\u529b\u56fe(attention-specific features)\uff0cOSME\u6a21\u5757\u901a\u8fc7\u5229\u7528\u5355\u538b\u7f29\u548c\u591a\u6fc0\u52b1\u64cd\u4f5c(one-squeeze and multiple-excitation operations)\u6765\u6269\u5c55\u539f\u59cb\u7684\u6b8b\u5dee\u6a21\u5757\u3002</p> <p>\u2003\u2003\u9996\u5148\u5229\u7528\u5168\u5c40\u5e73\u5747\u6c60\u5316\u53bb\u538b\u7f29\u7279\u5f81\u56feU\u5e76\u4e14\u751f\u6210\u4e00\u7cfb\u5217\u901a\u9053\u5143\u7d20z=[z_1,\\dots,z_C]\\in R^C\u3002\u4e4b\u540e\uff0c\u5bf9\u6bcf\u4e2a\u6fc0\u52b1\u6a21\u5757\u5206\u522b\u5728\u901a\u9053\u5143\u7d20z\u4e0a\u5e94\u7528\u95e8\u63a7\u673a\u5236(gating mechanism)\uff08\u5373\u7ebf\u6027\u56de\u5f52\u5c42\uff09\uff0c\u7528p\u8868\u793a\u6fc0\u52b1\u6a21\u5757\u7684\u6570\u91cf\uff0cp=1,\\dots,P\uff1a $$ m^p=\\sigma(W^p_2\\delta(W^p_1z))=[m_1^p,\\dots,m^p_C]\\in R^C $$  \u5176\u4e2d\uff0c\\sigma\u548c\\delta\u5206\u522b\u8868\u793aSigmoid\u6fc0\u6d3b\u51fd\u6570\u548cReLU\u6fc0\u6d3b\u51fd\u6570\uff0cW\u8868\u793a\u7ebf\u6027\u56de\u5f52\u8fd0\u7b97\u4e2d\u7684\u53c2\u6570\u3002\u6700\u540e\uff0c\u5229\u7528\u5f97\u5230\u7684\u6570\u636e\u5bf9\u539f\u59cb\u7279\u5f81\u56feU\u505a\u91cd\u52a0\u6743\u5904\u7406\uff0c\u751f\u6210\u7279\u5f81\u6ce8\u610f\u529b\u56feU_p\uff0c\u8fd9\u91cc\u5f88\u7c7b\u4f3c\u901a\u9053\u6ce8\u610f\u529b\u6a21\u5757\uff1a $$ U_p=[m_1^pu_1,\\dots,m_C^pu_C]\\in R^{W\\times H\\times C} $$  \u2003\u2003\u867d\u7136OSME\u6a21\u5757\u53ef\u4ee5\u751f\u6210\u7279\u5f81\u6ce8\u610f\u529b\u56fe\uff0c\u4f46\u662f\u7531\u4e8e\u7f3a\u5c11\u5173\u952e\u533a\u57df\u7684\u5b9a\u4f4d\uff0c\u56e0\u6b64OSME\u6a21\u5757\u7684\u7ebf\u6027\u56de\u5f52\u90e8\u5206\u7684\u53c2\u6570\u4e0d\u597d\u76f4\u63a5\u4f18\u5316\uff0c\u6240\u4ee5\u95ee\u9898\u5c31\u8f6c\u4e3a\u4e86\u5982\u4f55\u5f15\u5bfc\u8fd9\u4e9b\u7279\u5f81\u56fe\u5177\u6709\u8bed\u4e49\u610f\u4e49\uff0c\u5373\u5982\u4f55\u8ba9\u6a21\u578b\u751f\u6210\u7684\u7279\u5f81\u6ce8\u610f\u529b\u56fe\u5173\u6ce8\u6709\u7528\u7684\u4f4d\u7f6e\u3002\u539f\u8bba\u6587\uff08\u63d0\u51faOSME\u6a21\u5757\u7684\u8bba\u6587\uff09\u4e2d\u901a\u8fc7\u4f18\u5316\u5ea6\u91cf\u5b66\u4e60\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u5b83\u8ba9\u6765\u81ea\u76f8\u540c\u6fc0\u52b1\u7684\u7279\u6027\u9760\u8fdb\uff0c\u8ba9\u6765\u81ea\u4e0d\u540c\u6fc0\u52b1\u7684\u7279\u6027\u8fdc\u79bb\uff0c\u4f46\u4f18\u5316\u8fd9\u6837\u7684\u635f\u5931\u4ecd\u5177\u6709\u6311\u6218\u6027\u3002</p>"},{"location":"fine-grained/paper/Cross-X1/#c3s","title":"C3S\u6b63\u5219\u5316\u5668","text":"<p>\u2003\u2003\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u63a2\u7d22\u4e0d\u540c\u56fe\u7247\u548c\u4e0d\u540c\u6fc0\u52b1\u4e4b\u95f4\u7279\u5f81\u56fe\u7684\u76f8\u5173\u6027\u6765\u5b66\u4e60\u8bed\u4e49\u7279\u5f81\u3002\u7406\u60f3\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u5e0c\u671b\u4ece\u76f8\u540c\u7684\u6fc0\u52b1\u6a21\u5757\u4e2d\u63d0\u53d6\u7684\u7279\u5f81\u5177\u6709\u76f8\u540c\u7684\u8bed\u4e49\u4fe1\u606f\uff0c\u5373\u4f7f\u4ed6\u4eec\u53ef\u80fd\u6765\u81ea\u4e0d\u540c\u7684\u56fe\u7247\uff0c\u5e76\u4e14\u5177\u6709\u4e0d\u540c\u7684\u7c7b\u522b\u6807\u7b7e\uff0c\u4ee5\u53ca\u4ece\u4e0d\u540c\u7684\u6fc0\u52b1\u6a21\u5757\u4e2d\u63d0\u53d6\u7684\u7279\u5f81\u5177\u6709\u4e0d\u540c\u7684\u8bed\u4e49\u4fe1\u606f\uff0c\u5373\u4f7f\u4ed6\u4eec\u6765\u81ea\u76f8\u540c\u7684\u56fe\u7247(\u5982\u4e0b\u56fe)\u3002\u4e3a\u4e86\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\uff0c\u4f5c\u8005\u8bbe\u8ba1\u4e86\u4ea4\u4e92\u7c7b\u522b\u4ea4\u4e92\u8bed\u4e49\u6b63\u5219\u5316\u5668\uff0c\u7528\u4e8e\u6700\u5927\u5316\u76f8\u540c\u6fc0\u52b1\u6a21\u5757\u4e4b\u95f4\u7684\u76f8\u5173\u6027\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u4e0d\u540c\u6fc0\u52b1\u6a21\u5757\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u3002</p> <p> <p></p> <p></p> <p>\u4ee5\u4e2d\u95f4\u7684\u56fe\u50cf\u4e3a\u4f8b\uff0cC^3S\u901a\u8fc7\u5229\u7528\u6765\u81ea\u4e0d\u540c\u56fe\u50cf\u7684\u7279\u5f81(\u6a59\u8272\u865a\u7ebf\u6846)\u548c\u6765\u81ea\u4e0d\u540c\u6fc0\u52b1\u6a21\u5757\u7684\u7279\u5f81(\u84dd\u8272\u9634\u5f71)\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u9f13\u52b1\u6fc0\u52b1\u6a21\u5757U_1\u548cU_2\u5728\u4e0d\u540c\u8bed\u4e49\u4e0a\u88ab\u6fc0\u6d3b\u3002</p> <p>\u2003\u2003\u5177\u4f53\u7684\u6765\u8bf4\uff0c\u9996\u5148\u5229\u7528\u5168\u5c40\u5e73\u5747\u6c60\u5316(\u6216\u8005\u5168\u5c40\u6700\u5927\u6c60\u5316)\u64cd\u4f5c\u538b\u7f29U_p\uff0c\u6765\u5f97\u5230\u5bf9\u5e94\u7684\u6c60\u5316\u7279\u5f81f_p\\in R^C\uff0c\u4e4b\u540e\u518d\u7ecf\u8fc7L2\u6807\u51c6\u5316\u8fd0\u7b97(f_p\\gets f_p/||f_p||)\u3002\u7136\u540e\u5229\u7528\u4e0b\u9762\u7684\u516c\u5f0f\u8ba1\u7b97\u6240\u6709\u6fc0\u52b1\u6a21\u5757\u5bf9(p\u548cp')\u4e4b\u95f4\u7684\u76f8\u5173\u6027\uff0c\u4ece\u800c\u5f62\u6210\u76f8\u5173\u6027\u77e9\u9635S\uff1a $$ S_{p,p'}=\\frac{1}{N^2}\\sum F^T_pF_{p'} $$  \u5176\u4e2d\uff0cT\u8868\u793a\u8f6c\u7f6e\u64cd\u4f5c\uff0cN\u8868\u793a\u6bcf\u6b21\u8fed\u4ee3\u7684\u6279\u6b21(batch size)\uff0cF_p=[f_{p,1},\\dots,f_{p,N}]\\in R^{C\\times N}\u8868\u793a\u5b58\u50a8\u6279\u6b21\u4e2d\u6240\u6709\u6837\u672c\u4ece\u6fc0\u52b1\u6a21\u5757p\u4e2d\u5f97\u5230\u7684\u96c6\u5408\u7279\u5f81\u77e9\u9635\u3002</p> <p> C^3S\u6b63\u5219\u5316\u635f\u5931\u4e3b\u8981\u7531\u4e24\u90e8\u5206\u6784\u6210\uff1a\u2460\u6700\u5927\u5316S\u7684\u4e3b\u5bf9\u89d2\u7ebf\u5143\u7d20\uff0c\u4ece\u800c\u4f7f\u540c\u4e00\u6fc0\u52b1\u6a21\u5757\u5185\u7684\u76f8\u5173\u6027\u6700\u5927\u5316\uff1b\u2461\u60e9\u7f5aS\u7684\u8303\u6570\uff0c\u4f7f\u4e0d\u540c\u6fc0\u52b1\u6a21\u5757\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u6700\u5c0f\uff1a $$ L_{C3S}(S)=\\frac{1}{2}(||S||^2_F-2||diag(S)||^2_2) $$  \u5176\u4e2d\uff0c||\u00b7||\u8868\u793aFrobenius\u8303\u6570\uff0cdiag(\u00b7)\u8868\u793a\u63d0\u53d6\u77e9\u9635\u4e2d\u4e3b\u5bf9\u89d2\u7ebf\u4e0a\u7684\u5143\u7d20\uff0c\u5e76\u4e14\u6784\u6210\u5411\u91cf\u3002C^3S\u635f\u5931\u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u96c6\u6210\u5230OSME\u6a21\u5757\u4e2d\uff0c\u5e76\u4e14\u65e0\u9700\u4efb\u4f55\u91c7\u6837\u7a0b\u5e8f\u5c31\u53ef\u8f7b\u677e\u4f18\u5316\u3002</p>"},{"location":"fine-grained/paper/Cross-X1/#cl","title":"CL\u6b63\u5219\u5316\u5668","text":"<p>\u2003\u2003\u63a2\u7d22CNN\u4e2d\u4e0d\u540c\u5c42\u4e4b\u95f4\u7684\u8bed\u4e49\u7279\u5f81\u5bf9\u5f88\u591a\u89c6\u89c9\u4efb\u52a1\u90fd\u6709\u597d\u5904\u3002\u5728\u7ec6\u7c92\u5ea6\u5206\u7c7b\u4e2d\uff0c\u6700\u7b80\u5355\u7684\u65b9\u6cd5\u5c31\u662f\u5c06\u4e0d\u540c\u5c42\u7684\u9884\u6d4b\u8f93\u51fa\u7ec4\u5408\u8d77\u6765\u8fdb\u884c\u6700\u7ec8\u7684\u9884\u6d4b\u3002\u7136\u800c\u4f5c\u8005\u5728\u5b9e\u9a8c\u4e2d\u89c2\u5bdf\u5230\uff0c\u8fd9\u79cd\u7b80\u5355\u7684\u7b56\u7565\u4f1a\u5bfc\u81f4\u8f83\u5dee\u7684\u6027\u80fd(\u6a21\u578b\u8bc6\u522b\u7cbe\u5ea6\u4e0d\u9ad8)\uff0c\u5047\u8bbe\u8be5\u73b0\u8c61\u662f\u7531\u4e24\u4e2a\u539f\u56e0\u9020\u6210\u7684\uff1a\u2460\u4e2d\u6c34\u5e73\u7684\u7279\u5f81\u5bf9\u6570\u636e\u7684\u8f93\u5165\u975e\u5e38\u654f\u611f\uff0c\u7531\u4e8e\u7ec6\u7c92\u5ea6\u56fe\u7247\u5177\u6709\u8f83\u5927\u7684\u7c7b\u5185\u5dee\u5f02\uff0c\u540c\u4e00\u7c7b\u522b\u4e2d\u56fe\u7247\u7684\u4fe1\u606f\u91cf\u5177\u6709\u591a\u53d8\u6027\uff0c\u56e0\u6b64\u4f1a\u964d\u4f4e\u6a21\u578b\u7684\u9c81\u68d2\u6027\uff1b\u2461\u7279\u5f81\u56fe\u9884\u6d4b\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u6ca1\u6709\u88ab\u63a2\u7d22\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4f5c\u8005\u91c7\u7528\u4e86\u7279\u5f81\u91d1\u5b57\u5854\u7f51\u7edc(FPN\uff0c\u5177\u4f53\u89c1\u8bba\u6587\u300aFeature Pyramid Networks for Object Detection\u300b\uff0c\u8bba\u6587\u94fe\u63a5)\u53bb\u5408\u5e76\u4e0d\u540c\u5c42\u4e4b\u95f4\u7684\u7279\u5f81\u6570\u636e\uff0c\u5e76\u4e14\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8de8\u5c42\u6b63\u5219\u5668(cross-layer regularizer, CL)\uff0c\u901a\u8fc7\u5339\u914d\u4e0d\u540c\u5c42\u4e4b\u95f4\u7684\u9884\u6d4b\u5206\u5e03\uff0c\u6765\u5b66\u4e60\u9c81\u68d2\u6027\u7279\u5f81\u3002</p> <p>\u2003\u2003\u5177\u4f53\u7684\u6765\u8bf4\uff0c\u5047\u8bbeU^L=\\{U^L_p\\}^P_{p=1}\u4e3a\u7b2cL\u9636\u6bb5\u7684\u7279\u5f81\u56fe\uff0cU^{L-1}=\\{U^{L-1}_p\\}^P_{p=1}\u4e3a\u7b2cL-1\u9636\u6bb5\u7684\u7279\u5f81\u56fe(\u8fd9\u91cc\u7684\u9636\u6bb5\u8868\u793a\u4ea7\u751f\u5927\u5c0f\u76f8\u540c\u7279\u5f81\u56fe\u7684\u4e00\u7ec4\u7f51\u7edc\u5c42)\u3002\u4f5c\u8005\u5229\u7528\u4e0eFPN\u4e2d\u7c7b\u4f3c\u7684\u65b9\u6cd5\u751f\u6210\u5408\u5e76\u7684\u7279\u5f81\u56feU^G_p\uff0c\u4f46\u76f8\u5bf9\u539f\u6765\u7684FPN\uff0c\u6709\u5982\u4e0b\u4e24\u70b9\u4e0d\u540c\uff1a\u2460U_p^L\u5148\u8fdb\u884c\u964d\u7ef4\uff0c\u540e\u8fdb\u884c\u4e0a\u91c7\u6837\u64cd\u4f5c\uff1b\u2461\u5bf9\u5408\u5e76\u540e\u7684\u7279\u5f81\u56fe\u8fdb\u884c\u6279\u91cf\u5f52\u4e00\u5316\u64cd\u4f5c(BN)\uff0c\u5177\u4f53\u7684\u8fc7\u7a0b\u53ef\u603b\u7ed3\u6210\u5982\u4e0b\u516c\u5f0f\uff1a $$ U^G_p=BN(K_2*(U_p^{L-1}+Bilinear(K_1*U_p^L))) $$  \u5176\u4e2d\uff0c*\u8868\u793a\u5377\u79ef\u64cd\u4f5c\uff0cBilinear(\u00b7)\u8868\u793a\u53cc\u7ebf\u6027\u63d2\u503c\u64cd\u4f5c(\u7528\u4e8e\u4e0a\u91c7\u6837)\uff0cK_1, K_2\u5206\u522b\u662f\u5c3a\u5bf8\u4e3a1\\times 1\u548c3\\times 3\u7684\u5377\u79ef\u6838\u3002U^G\u7efc\u5408\u4e86\u4e2d\u5c42\u7cbe\u7ec6\u7a7a\u95f4\u5206\u8fa8\u7387\u7279\u6027\u548c\u9876\u5c42\u4e30\u5bcc\u7684\u7684\u9ad8\u7ea7\u8bed\u4e49\u7279\u6027\u3002</p> <p>\u2003\u2003\u4e3a\u4e86\u8fdb\u4e00\u6b65\u5229\u7528\u7279\u5f81\u9884\u6d4b\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86CL\u6b63\u5219\u5316\u5668\uff0c\u7528\u4e8e\u5339\u914d\u4e0d\u540c\u5c42\u4e4b\u95f4\u7684\u9884\u6d4b\u5206\u5e03\u3002\u8bbePr^L=\\sigma(f(U^L))\u4ee5\u53caPr^{L-1}=\\sigma(f(U^{L-1}))\u5206\u522b\u4e3a\u7b2cL\u9636\u6bb5\u548c\u7b2cL-1\u9636\u6bb5\u7684\u9884\u6d4b\u8f93\u51fa\uff0c\u5176\u4e2d\\sigma(\u00b7)\u8868\u793asoftmax\u6fc0\u6d3b\u51fd\u6570\uff0cf(\u00b7)\u8868\u793a\u4e3b\u5e72\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u6700\u540e\u7684\u8f93\u51fa\u5c42\u3002CL\u6b63\u5219\u5316\u5668\u901a\u8fc7\u6700\u5c0f\u5316KL\u635f\u5931\u6765\u9f13\u52b1Pr^{L-1}\u53bb\u5339\u914dPr^L\uff1a $$ L_{CL}(Pr^L,Pr^{L-1})=KL(Pr^L||Pr^{L-1})=\\frac{1}{N}\\sum^N_{n=1}\\sum^K_{k=1}p^L_{nk}log\\frac{p^L_{nk}}{p^{L-1}_{nk}} $$  \u5176\u4e2d\uff0cK\u8868\u793a\u7c7b\u522b\u6570\u91cf\uff0c\u53ef\u4ee5\u6dfb\u52a0\u7c7b\u4f3c\u7684\u6b63\u5219\u5316\u5668\u6765\u7ea6\u675f\u7279\u5f81\u56feU^L\u548cU^G\u3002CL\u6b63\u5219\u5316\u5668\u53ef\u4ee5\u770b\u505a\u77e5\u8bc6\u63d0\u70bc\u5668\uff0c\u901a\u8fc7\u4f7f\u7528\u6765\u81eaU^L\u7684\u8f6f\u76ee\u6807\u4ee5\u53ca\u4e30\u5bcc\u7684\u7ed3\u6784\u4fe1\u606f\u6765\u6307\u5bfcU^{L-1}\u548cU^G\u7684\u7279\u5f81\u5b66\u4e60\u3002</p>"},{"location":"fine-grained/paper/Cross-X1/#_4","title":"\u635f\u5931\u4f18\u5316","text":"<p>\u2003\u2003\u7f51\u7edc\u6700\u7ec8\u5f97\u5230\u4e09\u7ec4\u7279\u5f81\u56feU^L\uff0cU^{L-1}\u548cU^G\uff0c\u7f51\u7edc\u6700\u7ec8\u7684\u9884\u6d4b\u53ef\u4ee5\u901a\u8fc7\u7ed3\u5408\u8fd9\u4e09\u7ec4\u7684\u9884\u6d4b\u5f97\u5230\uff1a $$ Pr=\\sigma(f(U^L)+f(U^{L-1})+f(U^G)) $$  \u7efc\u4e0a\u6240\u8ff0\uff0cCross-X\u7f51\u7edc\u603b\u635f\u5931\u53ef\u7531\u5982\u4e0b\u516c\u5f0f\u5b9a\u4e49\uff1a $$ L=L_{data}+\\gamma L_{C^3S}+\\lambda L_{CL}\\\\ L_{data}=-\\frac{1}{N}\\sum^N_{n=1}\\sum^K_{k=1}c_{nk}logp_{nk}\\\\ L_{C^3S}=\\gamma_1L_{C^3S}(S^L)+\\gamma_2L_{C^3}(S^{L-1})+\\gamma_3L_{C^3S}(S^G)\\\\ L_{CL}=\\lambda_1L_{CL}(Pr^L,P^{L-1})+\\lambda_2L_{CL}(Pr^L,Pr^G) $$  \u5176\u4e2d\uff0cL_{data}\u8868\u793a\u5206\u7c7b\u635f\u5931\uff0c\\gamma\u548c\\lambda\u4e3a\u5e73\u8861\u4e0d\u540c\u635f\u5931\u7684\u8d85\u53c2\u6570\u3002</p>"},{"location":"fine-grained/paper/Cross-X1/#_5","title":"\u5b9e\u9a8c","text":""},{"location":"fine-grained/paper/Cross-X1/#_6","title":"\u53ef\u89c6\u5316\u5206\u6790","text":"<p>\u2003\u2003\u4e0b\u56fe\u4e3a\u6fc0\u6d3b\u56fe\u7684\u53e0\u52a0\u663e\u793a\uff0c(a)\u4e3a\u539f\u59cb\u56fe\u50cf\uff0c(b)\u4e3aU_p^{L-1}\uff0c\u00a9\u4e3aU^L_p\uff0c(d)\u4e3aU_p^G\uff0c(e)\u4e3aU_p^{L-1},U^L_p\u4e0eU_p^G\u7ed3\u5408\u7684\u6fc0\u6d3b\u56fe\u3002(b)-(e)\u5c55\u793a\u4e86\u54cd\u5e94\u5c42\u7684\u4e24\u4e2a\u6fc0\u52b1\u6a21\u5757\u7684\u6fc0\u6d3b\u56fe\u3002</p> <p> <p></p> <p></p> <p>\u2003\u2003\u4e0a\u56fe\u5206\u522b\u5c55\u793a\u4e86\u4e09\u4e2a\u6570\u636e\u96c6\u4e2d\u7684\u53ef\u89c6\u5316\u56fe\u50cf\uff0c\u4ece\u56fe\u4e2d\u53ef\u4ee5\u6e05\u695a\u5730\u53d1\u73b0\uff0c(b)-(d)\u5bf9\u5e94\u7684\u5217\u4e2d\uff0c\u6fc0\u6d3b\u56fe\u8986\u76d6\u4e86\u4e0d\u540c\u5c3a\u5ea6\u4e0b\u4e0d\u540c\u5bf9\u8c61\u7684\u76f8\u540c\u90e8\u5206\u3002\u4e0e\u6fc0\u6d3b\u56fe\u00a9U^L\u76f8\u6bd4\uff0c\u9ad8\u5ea6\u6fc0\u6d3b\u7684\u533a\u57df(b)U^{L-1}\u548c(d)U^G\u5206\u522b\u5177\u6709\u76f8\u5bf9\u8f83\u5c0f\u7684\u6bd4\u4f8b\u548c\u7a81\u51fa\u7684\u4e2d\u5fc3\u3002\u6fc0\u6d3b\u56feU^G\u53ef\u4ee5\u8fdb\u4e00\u6b65\u770b\u4f5c\u662f\u6fc0\u6d3b\u56feU^{L}\u4eceU^{L-1}\u7684\u589e\u5f3a\uff0c\u8fd9\u4e0eFPN\u4e2d\u7cbe\u7ec6\u7a7a\u95f4\u7684\u5206\u8fa8\u7387(L-1\u9636\u6bb5)\u548c\u4e30\u5bcc\u7684\u9ad8\u7ea7\u8bed\u4e49\u7279\u5f81(L\u9636\u6bb5)\u7684\u8bbe\u8ba1\u662f\u4e00\u81f4\u7684\u3002GMP\u4e0eGAP\u5f15\u8d77\u7684\u5dee\u5f02\u4e5f\u53ef\u4ee5\u5728(b)\u4e2d\u89c2\u5bdf\u5f97\u5230\uff0cGMP\u4f1a\u5bfc\u81f4\u5355\u4e2a\u533a\u57df(\u524d\u4e24\u884c)\u7684\u4e00\u81f4\u6fc0\u6d3b(\u6fc0\u6d3b\u90e8\u4f4d\u6bd4\u8f83\u96c6\u4e2d)\uff0cGAP\u4f1a\u5bfc\u81f4\u591a\u4e2a\u533a\u57df(\u540e\u56db\u884c)\u7684\u5206\u6563\u6fc0\u6d3b(\u6fc0\u6d3b\u90e8\u4f4d\u6bd4\u8f83\u5206\u6563)\u3002\u56e0\u6b64\uff0c\u5728\u8fa8\u8bc6\u529b\u533a\u57df\u662f\u5c40\u90e8(\u6bd4\u8f83\u96c6\u4e2d)\u7684\u6570\u636e\u96c6\u4e2d(\u5982CUB)\uff0c\u901a\u5e38\u5728U^{L-1}\u9636\u6bb5\u4f7f\u7528GMP\u4ee3\u66ffGAP\u6c47\u805a\u6570\u636e(\u5176\u4f59\u9636\u6bb5\u5747\u7528GAP)\u3002</p>"},{"location":"fine-grained/paper/Cross-X1/#_7","title":"\u7cbe\u5ea6\u5bf9\u6bd4","text":"<p>CUB-200-2011</p> <p> <p></p> <p></p> <p>Stanford Cars</p> <p> <p></p> <p></p> <p>Aircraft</p> <p> <p></p> <p></p>"},{"location":"fine-grained/paper/Cross-X1/#_8","title":"\u603b\u7ed3","text":"<p>\u2003\u2003\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u7ec6\u7c92\u5ea6\u5206\u7c7b\u7684Cross-X\u7f51\u7edc\u7ed3\u6784\uff0c\u901a\u8fc7\u63a2\u7d22\u4e0d\u540c\u56fe\u50cf\u3001\u4e0d\u540c\u5c42\u7279\u5f81\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u6765\u5b66\u4e60\u7a33\u5b9a\u7684\u7ec6\u7c92\u5ea6\u7279\u5f81\u3002\u901a\u8fc7\u56f4\u7ed5\u5982\u4e0b\u601d\u60f3\uff1a\u76f8\u540c\u8bed\u4e49\u90e8\u5206\u7684\u7279\u5f81\u867d\u7136\u6765\u81ea\u4e0d\u540c\u7c7b\u522b\u7684\u4e0d\u540c\u56fe\u50cf\uff0c\u4f46\u5e94\u8be5\u6bd4\u4e0d\u540c\u8bed\u4e49\u90e8\u5206\u7684\u7279\u5f81\u66f4\u76f8\u5173\uff0c\u8bbe\u8ba1\u4e86C3S\u6b63\u5219\u5316\u5668\u6765\u4f18\u5316\u7f51\u7edc\u8bed\u4e49\u7279\u5f81\u7684\u63d0\u53d6\u80fd\u529b\uff0c\u5e76\u4e14\u8bbe\u8ba1\u4e86CL\u635f\u5931\u6765\u8ba9\u7f51\u7edc\u5b66\u4e60\u66f4\u7a33\u5b9a\u7684\u7279\u5f81\uff0c\u63d0\u9ad8\u4e86\u9c81\u68d2\u6027\u3002</p> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u6307\u6b63\u3002</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e7412\u670816\u65e5</p>"},{"location":"fine-grained/paper/DCL1/","title":"\u7ec6\u7c92\u5ea6\uff1aDCL","text":""},{"location":"fine-grained/paper/DCL1/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aIEEE Conference on Computer Vision and Pattern Recognition 2019 (CVPR, 2019)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content_CVPR_2019/papers/Chen_Destruction_and_Construction_Learning_for_Fine-Grained_Image_Recognition_CVPR_2019_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740(PyTorch\u7248\u672c)\uff1ahttps://github.com/JDAI-CV/DCL</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u7c7b(FGVC)</p>"},{"location":"fine-grained/paper/DCL1/#_2","title":"\u4e3b\u8981\u601d\u60f3","text":"<p>\u2003\u2003\u5728\u6709\u8fa8\u8bc6\u529b\u7684\u533a\u57df(discriminative parts)\u5b66\u4e60\u8fa8\u8bc6\u529b\u7279\u5f81(discriminative feature)\u5bf9\u7ec6\u7c92\u5ea6\u56fe\u7247\u5206\u7c7b\u5177\u6709\u91cd\u8981\u7684\u610f\u4e49\u3002\u73b0\u6709\u7684\u7ec6\u7c92\u5ea6\u8bc6\u522b\u65b9\u6cd5\u5927\u81f4\u53ef\u4ee5\u5206\u4e3a\u4e24\u7c7b\uff1a\u2460\u9996\u5148\u5b9a\u4f4d\u7269\u4f53\u5177\u6709\u8fa8\u8bc6\u529b\u7684\u90e8\u4f4d\uff0c\u5e76\u4e14\u518d\u57fa\u4e8e\u8fd9\u4e9b\u90e8\u4f4d\u505a\u8fdb\u4e00\u6b65\u7684\u5206\u7c7b(\u5982\u4e0b\u56fe\u7684a)\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u5f80\u5f80\u9700\u8981\u989d\u5916\u7684\u4eba\u529b\u6807\u6ce8\uff0c\u589e\u52a0\u4e86\u8bad\u7ec3\u6210\u672c\uff1b\u2461\u5c1d\u8bd5\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u4ee5\u65e0\u76d1\u7763\u7684\u65b9\u5f0f\u81ea\u52a8\u7684\u5b9a\u4f4d\u6709\u533a\u522b\u7684\u90e8\u4f4d(\u5982\u4e0b\u56fe\u7684b)\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u5f80\u5f80\u9700\u8981\u989d\u5916\u7684\u7f51\u7edc\u7ed3\u6784\uff0c\u589e\u52a0\u4e86\u8ba1\u7b97\u5f00\u9500\u3002</p> <p>\u2003\u2003\u672c\u6587\u4e2d\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7ec6\u7c92\u5ea6\u8bc6\u522b\u6846\u67b6\u2014\u2014\u201c\u7834\u574f\u548c\u6784\u9020\u5b66\u4e60\u201d(Destruction and Construction Learning)(\u5982\u4e0b\u56fec)\u3002\u9664\u4e86\u6807\u51c6\u7684\u5206\u7c7b\u7f51\u7edc\u4e4b\u5916\uff0c\u4f5c\u8005\u8fd8\u5f15\u5165\u4e86DCL\u7ed3\u6784\u6765\u81ea\u52a8\u5730\u5728\u6709\u8fa8\u8bc6\u529b\u7684\u533a\u57df\u5b66\u4e60\u3002\u8f93\u5165\u56fe\u50cf\u9996\u5148\u88ab\u7834\u574f\uff0c\u4ece\u800c\u8ba9\u7f51\u7edc\u5b66\u4e60\u91cc\u9762\u7684\u5c40\u90e8\u7ec6\u8282\uff0c\u4e4b\u540e\u518d\u5c06\u4ed6\u4eec\u91cd\u6784\uff0c\u8ba9\u7f51\u7edc\u53bb\u5b66\u4e60\u533a\u57df\u4e4b\u95f4\u7684\u8bed\u4e49\u76f8\u5173\u6027\u3002</p> <p> <p></p> <p> </p> <p>\u2003\u2003\u5bf9\u4e8e\u201c\u7834\u574f\u201d\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u533a\u57df\u6df7\u6dc6\u673a\u5236\u6765\u6545\u610f\u201c\u6df7\u6dc6\u201d\u5168\u5c40\u7684\u7ed3\u6784\uff0c\u8be5\u673a\u5236\u9996\u5148\u5c06\u8f93\u5165\u7684\u56fe\u7247\u5212\u5206\u6210\u5c40\u90e8\u7684\u5c0f\u533a\u57df\uff0c\u4e4b\u540e\u518d\u5c06\u5b83\u4eec\u968f\u673a\u5730\u6253\u4e71\u3002\u5bf9\u4e8e\u7ec6\u7c92\u5ea6\u8bc6\u522b\uff0c\u5c40\u90e8\u7ec6\u8282\u8981\u6bd4\u5168\u5c40\u7ed3\u6784\u8d77\u7740\u66f4\u91cd\u8981\u7684\u4f5c\u7528\uff0c\u968f\u673a\u6253\u4e71\u53ef\u4ee5\u4f7f\u56fe\u7247\u4e22\u5f03\u5168\u5c40\u7ed3\u6784\uff0c\u5e76\u4fdd\u7559\u5c40\u90e8\u7684\u7ec6\u8282\uff0c\u4ece\u800c\u8feb\u4f7f\u7f51\u7edc\u5728\u6709\u8bc6\u522b\u529b\u7684\u5c40\u90e8\u533a\u57df\u8fdb\u884c\u8bc6\u522b\u3002\u4f46\u4f7f\u7528RCM\u6253\u4e71\u56fe\u50cf\u7684\u540c\u65f6\uff0c\u4f1a\u8ba9\u56fe\u50cf\u7684\u5916\u89c2\u53d1\u751f\u5b9e\u8d28\u6027\u7684\u53d8\u5316\uff0c\u63d0\u9ad8\u4e86\u8bc6\u522b\u7684\u96be\u5ea6\uff0c\u56e0\u6b64\uff0c\u7f51\u7edc\u9700\u8981\u6316\u6398\u56fe\u50cf\u4e2d\u7684\u7ec6\u8282\u5dee\u5f02\u6765\u5bf9\u7834\u574f\u7684\u56fe\u50cf\u8fdb\u884c\u5206\u7c7b\u3002</p> <p>\u2003\u2003\u4f46\u5b66\u4e60\u6253\u4e71\u540e\u7684\u56fe\u50cf\u5e76\u4e0d\u90fd\u662f\u6709\u76ca\u7684\uff0c\u6253\u4e71\u56fe\u50cf\u7684\u540c\u65f6\uff0c\u4f1a\u5f15\u5165\u4e00\u90e8\u5206\u4e0d\u786e\u5b9a\u7684\u566a\u58f0\u89c6\u89c9\u6a21\u5f0f(noisy visual pattern)\uff0c\u4e3a\u4e86\u62b5\u6d88\u8d1f\u9762\u5f71\u54cd\uff0c\u4f5c\u8005\u8bbe\u8ba1\u4e86\u4e00\u79cd\u5bf9\u6297\u635f\u5931\uff0c\u8ba9\u566a\u58f0\u6a21\u5f0f\u7684\u5f71\u54cd\u6700\u5c0f\u5316\uff0c\u4ec5\u4fdd\u7559\u5bf9\u5206\u7c7b\u6709\u76ca\u7684\u5c40\u90e8\u7ec6\u8282\uff0c\u8fc7\u6ee4\u65e0\u5173\u56e0\u7d20\u3002\u5bf9\u6297\u635f\u5931\u4e0e\u5206\u7c7b\u635f\u5931\u4ee5\u5bf9\u6297\u6027\u7684\u65b9\u5f0f\u5de5\u4f5c\uff0c\u4ee5\u4fbf\u4ece\u7834\u574f\u7684\u56fe\u50cf\u4e2d\u4ed4\u7ec6\u5b66\u4e60\u5dee\u5f02\u3002</p> <p>\u2003\u2003\u5bf9\u4e8e\u201c\u6784\u5efa\u201d\uff0c\u5f15\u5165\u4e86\u533a\u57df\u5bf9\u9f50\u7f51\u7edc\u6765\u6062\u590d\u539f\u59cb\u533a\u57df\u7684\u6392\u5217\uff0c\u901a\u8fc7\u5b66\u4e60\u5982\u4f55\u590d\u539f\u56fe\u50cf\u539f\u59cb\u7684\u5e03\u5c40\uff0c\u53ef\u4ee5\u8ba9\u7f51\u7edc\u7406\u89e3\u6bcf\u4e2a\u533a\u57df\u7684\u8bed\u4e49\uff0c\u4fbf\u4e8e\u5bf9\u4e0d\u540c\u5c40\u90e8\u533a\u57df\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u8fdb\u884c\u5efa\u6a21\u3002</p>"},{"location":"fine-grained/paper/DCL1/#_3","title":"\u7f51\u7edc\u7ed3\u6784","text":"<p>\u2003\u2003\u7f51\u7edc\u7ed3\u6784\u56fe\u5982\u4e0b\u56fe\uff0c\u4e3b\u8981\u7531\u56db\u4e2a\u6a21\u5757\u7ec4\u6210\uff1a\u2460\u533a\u57df\u6df7\u6dc6\u673a\u5236(Region Confusion Mechanism)\uff1a\u968f\u673a\u6253\u4e71\u8f93\u5165\u56fe\u50cf\u7684\u5c40\u90e8\u533a\u57df\uff1b\u2461\u5206\u7c7b\u7f51\u7edc(Classification Network)\uff1a\u5c06\u8f93\u5165\u7684\u7ec6\u7c92\u5ea6\u56fe\u50cf\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u6700\u540e\u4f20\u5165\u5168\u8fde\u63a5\u5c42\u9884\u6d4b\u7c7b\u522b\u6982\u7387\uff1b\u2462\u5bf9\u6297\u5b66\u4e60\u7f51\u7edc(Adversarial Learning Network)\uff1a\u8bbe\u7f6e\u5bf9\u6297\u635f\u5931\uff0c\u7528\u4e8e\u533a\u5206\u662f\u539f\u59cb\u56fe\u50cf\u8fd8\u662f\u6253\u4e71\u540e\u7684\u56fe\u50cf\uff1b\u2463\u533a\u57df\u5bf9\u9f50\u7f51\u7edc(region alignment network)\uff1a\u9644\u52a0\u5728\u5206\u7c7b\u7f51\u7edc\u4e4b\u540e\uff0c\u7528\u4e8e\u6062\u590d\u7a7a\u95f4\u5c40\u90e8\u533a\u57df\u7684\u7a7a\u95f4\u5e03\u5c40\u3002\u56db\u4e2a\u6a21\u5757\u540c\u65f6\u53c2\u4e0e\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u800c\u5728\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\uff0c\u53ea\u9700\u8981\u4f7f\u7528\u5206\u7c7b\u7f51\u7edc\u5bf9\u539f\u59cb\u56fe\u50cf\u505a\u51fa\u7c7b\u522b\u9884\u6d4b\u3002</p> <p> <p></p> <p> </p>"},{"location":"fine-grained/paper/DCL1/#_4","title":"\u201c\u7834\u574f\u201d\u5b66\u4e60","text":"<p>\u2003\u2003\u5bf9\u4e8e\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u7c7b\u6765\u8bf4\uff0c\u5c40\u90e8\u7684\u7ec6\u8282\u8981\u6bd4\u5168\u5c40\u7684\u7ed3\u6784\u91cd\u8981\u5f88\u591a\uff0c\u5927\u591a\u6570\u60c5\u51b5\u4e0b\uff0c\u7ec6\u7c92\u5ea6\u7c7b\u522b\u901a\u5e38\u62e5\u6709\u76f8\u4f3c\u7684\u5168\u5c40\u7ed3\u6784\u5e76\u4e14\u4ec5\u5728\u5c40\u90e8\u7684\u7ec6\u8282\u4e0a\u8868\u73b0\u51fa\u5dee\u5f02\u6765\u3002\u672c\u6587\u4e2d\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u6253\u4e71\u5c40\u90e8\u533a\u57df\u6765\u7834\u574f\u5168\u5c40\u7ed3\u6784\u7684\u65b9\u6cd5(\u79f0\u4e3aRCM)\uff0c\u53ef\u4ee5\u66f4\u597d\u5730\u533a\u5206\u5c40\u90e8\u6709\u8fa8\u8bc6\u529b\u7684\u533a\u57df\u4ee5\u53ca\u5b66\u4e60\u5176\u4e2d\u7684\u8fa8\u8bc6\u529b\u7279\u5f81\u3002\u8fdb\u4e00\u6b65\u5730\uff0c\u4f5c\u8005\u53c8\u8bbe\u8ba1\u4e86\u4e00\u79cd\u5bf9\u6297\u635f\u5931\uff0c\u6765\u9632\u6b62\u7f51\u7edc\u5b66\u4e60\u6253\u4e71\u56fe\u50cf\u4e2d\u7684\u566a\u58f0\u6a21\u5f0f\u3002</p> <p>\u533a\u57df\u6df7\u6dc6\u673a\u5236(RCM)\uff1a</p> <p>\u2003\u2003\u4e0e\u81ea\u7136\u8bed\u8a00\u5904\u7406\u505a\u7c7b\u522b\uff0c\u6253\u4e71\u4e00\u4e2a\u53e5\u5b50\u4e2d\u5355\u8bcd\u7684\u987a\u5e8f\uff0c\u53ef\u4ee5\u8ba9\u7f51\u7edc\u53bb\u5173\u6ce8\u6709\u8fa8\u8bc6\u529b\u7684\u5355\u8bcd\uff0c\u5e76\u4e14\u5ffd\u7565\u6389\u65e0\u5173\u7684\u5355\u8bcd\u3002\u7c7b\u4f3c\u7684\uff0c\u6253\u4e71\u56fe\u7247\u7684\u5c40\u90e8\u533a\u57df\uff0c\u540c\u6837\u53ef\u4ee5\u8ba9\u7f51\u7edc\u53bb\u5b66\u4e60\u5c40\u90e8\u533a\u57df\u4e2d\u5bf9\u6700\u7ec8\u5206\u7c7b\u6709\u8d21\u732e\u7684\u7ec6\u8282\uff0c\u672c\u6587\u4e2d\u4f5c\u8005\u91c7\u7528\u76f8\u90bb\u6253\u4e71\u7b56\u7565(\u6bcf\u4e2a\u5c0f\u533a\u57df\u5728\u76f8\u90bb\u4f4d\u7f6e\u53d8\u52a8)\u3002</p> <p>\u2003\u2003\u9996\u5148\u5f97\u5230\u539f\u59cb\u8f93\u5165\u56fe\u50cfI\uff0c\u5c06\u5176\u5e73\u5747\u5212\u5206\u6210N\u00d7N\u4e2a\u5c0f\u533a\u57df\uff0c\u5c06\u5176\u547d\u540d\u4e3a\uff1a $$ R_{i,j}\\quad 1&lt;i,j&lt;N\uff0c\u5176\u4e2di\u8868\u793a\u6c34\u5e73\u7684\u7d22\u5f15\uff0cj\u8868\u793a\u5782\u76f4\u7684\u7d22\u5f15 $$ </p> <p>\u5bf9\u4e8eR\u4e2d\u7684\u7b2cj\u884c\uff0c\u751f\u6210\u4e00\u4e2a\u5c3a\u5bf8\u4e3aN\u7684\u968f\u673a\u5411\u91cfq_j\uff0c\u5176\u4e2d\u7b2ci\u4e2a\u5143\u7d20q_{j,i}=i+r\uff0cr\\sim U(-k,k)\u670d\u4ece\u4e8e[-k,k]\u5185\u7684\u5747\u5300\u5206\u5e03\uff0ck\u662f\u53ef\u8c03\u8282\u7684\u8d85\u53c2\u6570(1\u2264k&lt;N)\uff0c\u51b3\u5b9a\u4e86\u5c40\u90e8\u533a\u57df\u53d8\u52a8\u7684\u8303\u56f4\uff0ck\u8d8a\u5927\uff0c\u6bcf\u4e2a\u5c40\u90e8\u533a\u57df\u504f\u79bb\u5f53\u524d\u4f4d\u7f6e\u7684\u8303\u56f4\u5c31\u8d8a\u5927(\u6362\u53e5\u8bdd\u8bf4k\u8d8a\u5927\uff0c\u56fe\u7247\u6253\u4e71\u7684\u529b\u5ea6\u5c31\u8d8a\u5927)\u3002\u4e4b\u540e\uff0c\u5229\u7528\u5f97\u5230\u7684\u968f\u673a\u5411\u91cfq_i\u5bf9\u7b2cj\u884c\u8fdb\u884c\u91cd\u65b0\u6392\u5217\uff0c\u5f97\u5230\u4e86\u4e00\u7ec4\u65b0\u7684\u6392\u5217\\delta^{row}_j\uff0c\u9a8c\u8bc1\u5982\u4e0b\uff1a $$ \\forall i\\in\\{1,\\dots,N\\},|\\delta^{row}_j(i)-i|&lt;2k $$  \u7c7b\u4f3c\u7684\uff0c\u901a\u8fc7\u4e0a\u8ff0\u6b65\u9aa4\uff0c\u5bf9\u4e8e\u7b2ci\u5217\uff0c\u6211\u4eec\u540c\u6837\u4f1a\u5f97\u5230\u4e00\u7ec4\u65b0\u7684\u6392\u5217\\delta^{col}_i\uff0c\u9a8c\u8bc1\u5982\u4e0b\uff1a $$ \\forall j\\in\\{1,\\dots,N\\},|\\delta^{col}_i(j)-j|&lt;2k $$  \u56e0\u6b64\uff0c\u539f\u56fe(i,j)\u4e0a\u7684\u533a\u57df\u88ab\u653e\u5230\u65b0\u7684\u4f4d\u7f6e\uff1a $$ \\delta(i,j)=(\\delta^{row}_j(i),\\delta_i^{col}(j)) $$  \u4f5c\u8005\u5229\u7528\u8fd9\u79cd\u65b9\u6cd5\uff0c\u5c06\u539f\u56fe\u8fdb\u884c\u6253\u4e71\uff0c\u7834\u574f\u539f\u6709\u7684\u5168\u5c40\u7ed3\u6784\uff0c\u5e76\u4e14\u4fdd\u8bc1\u5c40\u90e8\u533a\u57df\u5728\u4e00\u5b9a\u8303\u56f4\u5185\u8fdb\u884c\u6296\u52a8\uff0c\u5177\u4f53\u6548\u679c\u5982\u4e0b\u56fe\uff1a</p> <p> <p></p> <p> </p> <p>\u2003\u2003\u539f\u59cb\u56fe\u50cfI\u3001\u76f8\u5e94\u88ab\u6253\u4e71\u7684\u56fe\u50cf\\phi(I)\u4e0e\u6807\u7b7el\u540c\u65f6\u7528\u4e8e\u7f51\u7edc\u53c2\u6570\u7684\u8bad\u7ec3\uff0c\u5206\u7c7b\u7f51\u7edc\u5c06\u56fe\u50cf\u6620\u5c04\u5230\u76f8\u5e94\u7684\u6982\u7387\u5206\u5e03\u5411\u91cfC(I,\\theta_{cls})\uff0c\u5176\u4e2d\\theta_{cls}\u8868\u793a\u5206\u7c7b\u5668\u7684\u53c2\u6570\uff0c\u4e4b\u540e\u5229\u7528\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\u8ba1\u7b97\u5f97\u5230\u5206\u7c7b\u635f\u5931L_{cls}\uff0c\u8fdb\u4e00\u6b65\u5229\u7528\u8be5\u635f\u5931\u4f18\u5316\u7f51\u7edc\uff1a $$ L_{cls}=-\\sum_{I\\in \\mathrm I}l\u00b7log[C(I)C(\\phi(I))] $$  \u5176\u4e2d\uff0c\\mathrm I\u8868\u793a\u8bad\u7ec3\u96c6\u56fe\u7247\u3002</p> <p>\u5bf9\u6297\u5b66\u4e60\uff1a</p> <p>\u2003\u2003\u5229\u7528RCM\u6253\u4e71\u539f\u59cb\u56fe\u50cf\u5e76\u4e0d\u603b\u662f\u5f97\u5230\u5bf9\u7ec6\u7c92\u5ea6\u5206\u7c7b\u6709\u76ca\u7684\u4fe1\u606f\uff0c\u5728\u6253\u4e71\u539f\u56fe\u7684\u540c\u65f6\uff0c\u4e5f\u8bb8\u4f1a\u5f15\u5165\u4e00\u4e9b\u89c6\u89c9\u4e0a\u7684\u566a\u58f0\u6a21\u5f0f(\u5982\u4e0a\u56fe\uff0c\u88ab\u6253\u4e71\u7684\u56fe\u50cf\u4e0e\u539f\u56fe\u5177\u6709\u4e0d\u540c\u7684\u6a21\u5f0f\u5e03\u5c40)\uff0c\u5b66\u4e60\u8fd9\u4e9b\u566a\u58f0\u6a21\u5f0f\u7684\u7279\u5f81\uff0c\u4f1a\u5f71\u54cd\u5bf9\u5b8c\u6574\u56fe\u50cf\u7684\u5206\u7c7b\u9884\u6d4b\u3002\u4e3a\u6b64\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u5bf9\u6297\u635f\u5931L_{Adv}\uff0c\u7528\u4e8e\u9632\u6b62RCM\u5f15\u8d77\u7684\u566a\u58f0\u6a21\u5f0f\u201c\u5077\u5077\u8fdb\u5165\u7279\u5f81\u7a7a\u95f4\u201d\u3002</p> <p>\u2003\u2003\u8003\u8651\u5230\u539f\u59cb\u56fe\u50cf\u4e0e\u88ab\u7834\u574f\u7684\u56fe\u50cf\u5c5e\u4e8e\u4e24\u4e2a\u4e0d\u540c\u7684\u9886\u57df(\u4e00\u4e2a\u662f\u5b8c\u6574\u7684\u9886\u57df\u3001\u4e00\u4e2a\u662f\u4e0d\u5b8c\u6574\u7684\u9886\u57df)\uff0c\u56e0\u6b64\u5bf9\u6297\u635f\u5931\u4e0e\u5206\u7c7b\u635f\u5931\u4ee5\u5bf9\u6297\u7684\u65b9\u5f0f\u53bb\u89e3\u51b3\u5982\u4e0b\u4e24\u4e2a\u95ee\u9898\uff1a\u2460\u4fdd\u6301\u5404\u81ea\u9886\u57df\u4e0d\u53d8\uff1b\u2461\u62d2\u7eddI\u4e0e\\phi(I)\u4e4b\u95f4\u9886\u57df\u7684\u7279\u6b8a\u6a21\u5f0f\u3002(\u6362\u53e5\u8bdd\u8bf4\u5c31\u662f\u8ba9\u7f51\u7edc\u80fd\u591f\u6e05\u695a\u7684\u5206\u5f00\u4e24\u4e2a\u9886\u57df\u7684\u56fe\u50cf\uff0c\u53ef\u4ee5\u6b63\u786e\u5730\u5224\u65ad\u56fe\u50cf\u662f\u88ab\u7834\u574f\u7684\u56fe\u50cf\\phi(I)\u8fd8\u662f\u672a\u88ab\u7834\u574f\u7684\u56fe\u50cfI)</p> <p>\u2003\u2003\u56e0\u6b64\uff0c\u4f5c\u8005\u4e3a\u6bcf\u5f20\u56fe\u7247\u989d\u5916\u7684\u751f\u6210\u4e00\u4e2a\u6807\u7b7ed\\in\\{0,1\\}^2\uff0c\u8be5\u6807\u7b7e\u8868\u793a\u4e86\u56fe\u7247\u662f\u5426\u88ab\u7834\u574f\uff0c1\u8868\u793a\u56fe\u7247\u672a\u88ab\u7834\u574f\uff0c0\u8868\u793a\u56fe\u7247\u88ab\u7834\u574f\u3002\u4f5c\u8005\u53c8\u5728\u7f51\u7edc\u4e2d\u589e\u52a0\u4e86\u4e00\u4e2a\u65b0\u7684\u5224\u522b\u5668(discriminator)\u5206\u652f\uff0c\u7528\u4e8e\u5224\u65ad\u56fe\u7247I\u662f\u5426\u88ab\u7834\u574f\uff1a $$ D(I,\\theta_{adv})=softmax(\\theta_{adv}C(I,\\theta^{[1,m]}_{cls})) $$  \u5176\u4e2d\uff0cC(I,\\theta^{[1,m]}_{cls})\u662f\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u7b2cm\u5c42\u8f93\u51fa\u63d0\u53d6\u7684\u7279\u5f81\u5411\u91cf\uff0c\\theta^{[1,m]}_{cls}\u8868\u793a\u5206\u7c7b\u7f51\u7edc\u4e2d\u7b2c1\u5c42\u5230\u7b2cm\u5c42\u4e2d\u53ef\u5b66\u4e60\u7684\u53c2\u6570\uff0c\\theta_{adv}\\in R^{d\\times 2}\u8868\u793a\u4e00\u5c42\u7ebf\u6027\u6620\u5c04\u5c42\u3002\u6700\u7ec8\uff0c\u5224\u522b\u5668\u7f51\u7edc\u7684\u5bf9\u6297\u635f\u5931L_{adv}\u5982\u4e0b\uff1a $$ L_{adv}=-\\sum_{I\\in \\mathrm I}d\u00b7log[D(I)]+(1-d)\u00b7log[D(\\phi(I))] $$ \u5bf9\u6297\u5b66\u4e60\u5408\u7406\u6027\u9a8c\u8bc1\uff1a</p> <p>\u2003\u2003\u4e3a\u4e86\u66f4\u597d\u5730\u7406\u89e3\u5bf9\u6297\u635f\u5931\u8c03\u6574\u7279\u5f81\u5b66\u4e60\u7684\u8fc7\u7a0b\uff0c\u4f5c\u8005\u8fdb\u4e00\u6b65\u5c06\u4e24\u7ec4\u4e3b\u5e72\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u8f93\u51fa\u7684\u7279\u5f81\u53ef\u89c6\u5316\uff0c\u5206\u522b\u662f\u5e26\u6709\u5bf9\u6297\u635f\u5931\u8bad\u7ec3\u548c\u4e0d\u5e26\u5bf9\u6297\u635f\u5931\u8bad\u7ec3\u5f97\u5230\u7684\u7f51\u7edc\u3002\u7ed9\u4e00\u4e2a\u8f93\u5165\u56fe\u50cfI\uff0c\u4f5c\u8005\u5c06m\u5c42\u8f93\u51fa\u7684\u7b2ck\u5f20\u7279\u5f81\u56fe\u547d\u540d\u4e3aF^k_m(I)\u3002\u5bf9\u4e8eResNet50\uff0c\u4f5c\u8005\u63d0\u53d6\u4e86\u6700\u540e\u4e00\u5c42\u6c60\u5316\u5c42\u8f93\u51fa\u7684\u7279\u5f81\u5411\u91cf(\u5168\u8fde\u63a5\u5c42\u7684\u8f93\u5165)\u7528\u4e8e\u53ef\u89c6\u5316\u5c55\u793a\uff0c\u5012\u6570\u7b2c\u4e00\u5c42\u5377\u79ef\u5c42\u4e2d\uff0c\u7b2ck\u4e2a\u8fc7\u6ee4\u5668(filter)\u5bf9\u771f\u5b9e\u6807\u7b7ec\u7684\u7279\u5f81\u54cd\u5e94\u8868\u793a\u4e3a\uff1a $$ r^k(I,c)=\\overline{F}^k_m(I)\\times \\theta^{[m+1]}_{cls}[k,c] $$ </p> <p>\u5176\u4e2d\uff0c\\theta^{[m+1]}_{cls}[k,c]\u8868\u793a\u4e3a\u7b2ck\u5f20\u7279\u5f81\u56fe\u4e0e\u6807\u7b7e\u7c7b\u522bc\u4e4b\u95f4\u7684\u6743\u91cd(\u5168\u8fde\u63a5\u5c42\u4e2d\u7684\u6743\u91cd)</p> <p>\u2003\u2003\u4f5c\u8005\u8ba1\u7b97\u4e86\u4e0d\u540c\u8fc7\u6ee4\u5668\u5bf9\u539f\u59cb\u56fe\u50cf\u548c\u88ab\u7834\u574f\u7684\u56fe\u50cf\u7684\u54cd\u5e94\u503c\uff0c\u5e76\u4e14\u753b\u51fa\u4e86\u6563\u70b9\u56fe\uff0c\u6bcf\u4e2a\u5e26\u6709\u79ef\u6781\u54cd\u5e94\u7684\u8fc7\u6ee4\u5668\u90fd\u88ab\u6620\u5c04\u5230\u4e86\u6563\u70b9\u56fe\u4e2d\uff0c\u5750\u6807\u4e3a(r(I,c),r(\\phi(I),c))(\u6a2a\u5750\u6807\u8868\u793a\u5bf9\u539f\u56fe\u7684\u54cd\u5e94\uff0c\u7eb5\u5750\u6807\u8868\u793a\u5bf9\u7834\u574f\u540e\u56fe\u50cf\u7684\u54cd\u5e94)\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u4ec5\u901a\u8fc7\u5206\u7c7b\u635f\u5931(L_{cls})\u8bad\u7ec3\u5f97\u5230\u7684\u8fc7\u6ee4\u5668\u5728\u6563\u70b9\u56fe\u4e0a\u7684\u54cd\u5e94\u70b9\u66f4\u52a0\u5bc6\u96c6\uff0c\u8fd9\u610f\u5473\u7740\u5728\u88ab\u7834\u574f\u7684\u56fe\u50cf\u5b66\u4e60\u5230\u7684\u566a\u70b9\u6a21\u5f0f(\u8fb9\u7f18\u98ce\u683c\u7684\u89c6\u89c9\u6a21\u5f0f\u6216\u7531RCM\u5f15\u5165\u7684\u4e0d\u76f8\u5173\u7684\u89c6\u89c9\u6a21\u5f0f)\u5bf9\u539f\u56fe(\u5177\u6709\u5b8c\u6574\u7269\u4f53\u7684\u6a21\u5f0f)\u7684\u5206\u7c7b\u6709\u6bd4\u8f83\u5927\u7684\u5f71\u54cd\uff0c\u6709\u53ef\u80fd\u4f1a\u8bef\u5bfc\u9884\u6d4b\u7ed3\u679c\u3002\u56e0\u6b64\u9700\u8981\u52a0\u4ee5\u5904\u7406\uff0c\u8ba9\u7f51\u7edc\u533a\u5206\u51fa\u8be5\u56fe\u662f\u539f\u56fe\u8fd8\u662f\u88ab\u7834\u574f\u7684\u56fe\uff0c\u8fdb\u4e00\u6b65\u8fc7\u6ee4\u88ab\u7834\u574f\u7684\u56fe\u50cf\u4e2d\u4e0d\u76f8\u5173\u7684\u89c6\u89c9\u6a21\u5f0f\u3002</p> <p>\u2003\u2003\u4f5c\u8005\u8fdb\u4e00\u6b65\u5c06\u5229\u7528L_{cls}+L_{adv}\u7ed3\u5408\u8bad\u7ec3\u5f97\u5230\u7684\u8fc7\u6ee4\u5668\u6240\u7ed8\u5236\u7684\u6563\u70b9\u56fe\u4e0a\u7684\u70b9\u6807\u6ce8\u4e0a\u989c\u8272\uff0c\u6309\u7279\u5b9a\u6570\u503c\u4e0a\u8272\uff0c\u4ece\u84dd\u5230\u7ea2\u7684\u8fc7\u6e21\u4ee3\u8868\u6570\u503c\u4ece\u4f4e\u5230\u9ad8\u7684\u53d8\u5316\uff0c\u6563\u70b9\u56fe\u989c\u8272\u6570\u503c\u8ba1\u7b97\u516c\u5f0f\u5982\u4e0b\uff1a $$ \\delta_k=\\overline{F}^k_m(I)\\times \\theta_{adv}[k,1]-\\overline{F}^k_m(\\phi(I))\\times \\theta_{adv}[k,2] $$  \u5176\u4e2d\uff0c\\theta_{adv}[k,1]\u8868\u793a\u5728\u5224\u522b\u5668\u4e2d\uff0c\u7279\u5f81\u56feF_m^k(\u00b7)\u5230\u8868\u793a\u539f\u59cb\u56fe\u50cf\u6807\u7b7e\u4e4b\u95f4\u7684\u6743\u91cd\uff0c\u76f8\u5e94\u7684\\theta_{adv}[k,2]\u4e3a\u7279\u5f81\u56feF_m^k(\u00b7)\u5230\u8868\u793a\u88ab\u7834\u574f\u7684\u56fe\u50cf\u6807\u7b7e\u4e4b\u95f4\u7684\u6743\u91cd\u3002\\delta_k\u8bc4\u4ef7\u4e86\u7b2ck\u4e2a\u8fc7\u6ee4\u5668\u662f\u5426\u503e\u5411\u4e8e\u539f\u56fe\u7684\u89c6\u89c9\u6a21\u5f0f\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u7f51\u7edc\u8fc7\u6ee4\u5668\u5bf9\u566a\u70b9\u6a21\u5f0f\u7684\u54cd\u5e94\u53ef\u4ee5\u5229\u7528\u5bf9\u6297\u635f\u5931\uff0c\u6210\u529f\u5730\u5c06\u5176\u533a\u5206\u51fa\u6765(D VS. F)\u3002\u56fe\u4e0a\u7684\u70b9\u53ef\u4ee5\u88ab\u5212\u5206\u4e3a\u4e09\u4e2a\u90e8\u5206\u3002D\uff1a\u8d8b\u5411\u4e8e\u566a\u70b9\u6a21\u5f0f\u7684\u8fc7\u6ee4\u5668(\u566a\u70b9\u6a21\u5f0f\uff1a\u88ab\u7834\u574f\u7684\u56fe\u50cf\u6240\u7279\u6709\u7684\u56fe\u50cf\u7279\u5f81\uff0c\u7531RCM\u5f15\u8d77)\uff0c\u5bf9\u7834\u574f\u540e\u7684\u56fe\u5177\u6709\u8f83\u9ad8\u7684\u54cd\u5e94\uff1bF\uff1a\u8d8b\u5411\u4e8e\u5168\u5c40\u4e0a\u4e0b\u6587\u63cf\u8ff0\u7684\u8fc7\u6ee4\u5668(\u5168\u5c40\u63cf\u8ff0\uff1a\u539f\u59cb\u56fe\u50cf\u7279\u6709\u7684\u56fe\u50cf\u7279\u5f81\uff0c\u5373\u7269\u4f53\u7684\u5168\u5c40\u7ed3\u6784)\uff0c\u5bf9\u539f\u59cb\u56fe\u50cf\u5177\u6709\u8f83\u9ad8\u7684\u54cd\u5e94\uff1bE\uff1a\u7531\u5206\u7c7b\u635f\u5931L_{cls}\u589e\u5f3a\u5e76\u4e14\u8d8b\u5411\u4e8e\u5c40\u90e8\u63cf\u8ff0(\u7ec6\u8282)\u7684\u8fc7\u6ee4\u5668\uff0c\u5360\u7edd\u5927\u591a\u6570\u7684\u8fc7\u6ee4\u5668(\u5c40\u90e8\u7ec6\u8282\u63cf\u8ff0\uff1a\u539f\u59cb\u56fe\u50cf\u4e0e\u88ab\u7834\u574f\u7684\u56fe\u50cf\u4e4b\u95f4\u516c\u5171\u7684\u56fe\u50cf\u7279\u5f81)</p> <p> <p></p> <p> </p> <p>\u4e0a\u56fe\u4e2d\uff0c\u5206\u522b\u53ef\u89c6\u5316\u4e86\u7531L_{cls}\u8bad\u7ec3\u548c\u7531L_{cls}+L_{adv}\u8bad\u7ec3\u5f97\u5230\u7684\u8fc7\u6ee4\u5668\u3002\u7b2c\u4e00\u884c\u5c55\u793a\u4e86\u539f\u59cb\u56fe\u50cfI\u548c\u88ab\u88ab\u7834\u574f\u7684\u56fe\u50cf\\phi(I)\u3002\u53f3\u8fb9\u76842\u30013\u884c\u5206\u522b\u5c55\u793a\u4e86\u4e24\u79cd\u8fc7\u6ee4\u5668\u5bf9I\u548c\\phi(I)\u7684\u54cd\u5e94\u3002\u53f3\u8fb9\u5206\u522b\u5c55\u793a\u4e86\u53ef\u89c6\u5316\u540e\u7684\u7279\u5f81\u56fe\u3002\u6563\u70b9\u56fe\u4e2d\uff0cA,D\uff1a\u8fc7\u6ee4\u5668\u5bf9\\phi(I)\u5177\u6709\u9ad8\u54cd\u5e94\uff1bC,F\uff1a\u8fc7\u6ee4\u5668\u5bf9I\u5177\u6709\u9ad8\u54cd\u5e94\uff1bB,E\uff1a\u8fc7\u6ee4\u5668\u5bf9I\u548c\\phi(I)\u90fd\u5177\u6709\u9ad8\u54cd\u5e94\u3002</p> <p> L_{cls}\u4e0eL_{adv}\u5171\u540c\u6784\u6210\u7834\u574f\u5b66\u4e60\uff0c\u8ba9\u7f51\u7edc\u4e0d\u4ec5\u53ef\u4ee5\u589e\u5f3a\u5c40\u90e8\u8fa8\u8bc6\u529b\u7684\u5b66\u4e60\uff0c\u8fd8\u53ef\u4ee5\u8fc7\u6ee4\u6389\u65e0\u5173\u7684\u7279\u5f81\u3002</p>"},{"location":"fine-grained/paper/DCL1/#_5","title":"\u201c\u6784\u5efa\u201d\u5b66\u4e60","text":"<p>\u2003\u2003\u8003\u8651\u5230\u76f8\u5173\u533a\u57df\u7684\u7ec4\u5408\u6784\u5efa\u4e86\u590d\u6742\u591a\u6837\u7684\u89c6\u89c9\u6a21\u5f0f\uff0c\u4f5c\u8005\u53c8\u8bbe\u8ba1\u4e86\u4e00\u79cd\u6a21\u578b\u5b66\u4e60\u65b9\u6cd5\u6765\u5efa\u6a21\u5c40\u90e8\u533a\u57df\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u3002\u5177\u4f53\u5730\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u5229\u7528\u533a\u57df\u5bf9\u9f50\u635f\u5931L_{loc}\u4f18\u5316\u7684\u533a\u57df\u5bf9\u9f50\u7f51\u7edc\uff0c\u8be5\u7f51\u7edc\u6d4b\u91cf\u56fe\u50cf\u4e2d\u4e0d\u540c\u533a\u57df\u7684\u4f4d\u7f6e\u7cbe\u5ea6(\u5bf9\u539f\u56fe\u505a\u4e00\u4e2a\u91cd\u6784)\uff0c\u901a\u8fc7\u7aef\u5230\u7aef\u7684\u8bad\u7ec3\uff0c\u53ef\u4ee5\u8ba9\u9aa8\u5e72\u7f51\u7edc(backbone network)\u5bf9\u533a\u57df\u4e4b\u95f4\u7684\u8bed\u4e49\u76f8\u5173\u6027\u8fdb\u884c\u5efa\u6a21(\u5b66\u4e60\u4e0d\u540c\u533a\u57df\u4f4d\u7f6e\u95f4\u7684\u5173\u8054)\u3002</p> <p>\u2003\u2003\u7ed9\u51fa\u4e00\u5f20\u56fe\u7247I\u548c\u5bf9\u5e94\u7834\u574f\u7684\u56fe\u7247\\phi(I)\uff0c\u56fe\u7247I\u4e2d\u5750\u6807\u4e3a(i,j)\u7684\u533a\u57dfR_{i,j}\u5bf9\u5e94\u4e8e\u56fe\u7247\\phi(I)\u4e2d\u7684\u533a\u57dfR_{\\delta(i,j)}\uff0c\u533a\u57df\u5bf9\u9f50\u7f51\u7edc\u5904\u7406\u5206\u7c7b\u7f51\u7edcC(\u00b7,\\theta^{[1,n]}_{cls})\u4e2d\u4e00\u4e2a\u5377\u79ef\u5c42\u7684\u8f93\u51fa\u7279\u5f81\uff0c\u5176\u4e2dn\u8868\u793a\u5206\u7c7b\u7f51\u7edc\u7684\u5c42\u6570\u3002\u8f93\u51fa\u7684\u7279\u5f81\u7ecf\u8fc7\u4e00\u5c42\u5377\u79ef\u6838\u5c3a\u5bf8\u4e3a1\\times 1\u7684\u5377\u79ef\u5c42\uff0c\u5c06\u539f\u7279\u5f81\u56fe\u538b\u7f29\u6210\u901a\u9053\u4e3a2\u7684\u7279\u5f81\u56fe\uff0c\u5e76\u4e14\u4e0d\u6539\u53d8\u539f\u56fe\u7684\u5927\u5c0f\uff0c\u4e4b\u540e\u518d\u5c06\u5f97\u5230\u7684\u7279\u5f81\u56fe\u4f9d\u6b21\u7ecf\u8fc7ReLU\u6fc0\u6d3b\u3001\u5e73\u5747\u6c60\u5316\u5c42\u4e0b\u91c7\u6837\uff0c\u5f97\u5230\u5c3a\u5bf8\u4e3a2\\times N\\times N\u7684\u5bf9\u9f50\u56fe\uff0c\u5bf9\u9f50\u7f51\u7edc\u7684\u8f93\u51fa\u53ef\u4ee5\u7528\u5982\u4e0b\u516c\u5f0f\u8868\u793a\uff1a $$ M(I)=h(C(I,\\theta^{[1,n]}_{cls},\\theta_{loc})) $$  \u5176\u4e2d\uff0cM(I)\u4e2d\u4e24\u4e2a\u901a\u9053\u7684\u5143\u7d20\u5bf9\u5e94\u4e8e\u533a\u57df\u7684\u5b9a\u4f4d\u5750\u6807\u3002h\u662f\u4f5c\u8005\u63d0\u51fa\u7684\u5bf9\u9f50\u7f51\u7edc\uff0c\\theta_{loc}\u8868\u793a\u5bf9\u9f50\u7f51\u7edc\u4e2d\u7684\u53c2\u6570\u3002\u4e4b\u540e\uff0c\u518d\u5c06\u533a\u57dfR_{\\delta(i,j)}\u9884\u6d4b\u7684\u4f4d\u7f6e(R_{\\delta(i,j)}\u4f4d\u4e8e\u539f\u56feI\u7684\u54ea\u4e2a\u4f4d\u7f6e)\u547d\u540d\u4e3aM_{\\delta(i,j)}(\\phi(I))\uff0c\u533a\u57dfR_{i,j}\u9884\u6d4b\u7684\u4f4d\u7f6e(R_{i,j}\u4f4d\u4e8e\u539f\u56fe\u7684\u54ea\u4e2a\u4f4d\u7f6e)\u547d\u540d\u4e3aM_{i,j}(I,i,j)\u3002\u8fd9\u4e24\u4e2a\u9884\u6d4b\u503c\u7684\u6807\u7b7e\u5747\u4e3a(i,j)\u3002\u533a\u57df\u5bf9\u9f50\u635f\u5931L_{loc}\u7531\u9884\u6d4b\u5750\u6807\u548c\u539f\u59cb\u56fe\u50cf\u5750\u6807\u7684L1\u8ddd\u79bb\u6784\u6210\uff1a $$ L_{loc}=\\sum_{I\\in\\mathrm I}\\sum^N_{i=1}\\sum^N_{j=1}|M_{\\delta(i,j)}(\\phi(I))-\\begin{bmatrix} i\\\\ j \\end{bmatrix}|_1 +|M_{(i,j)}(I)- \\begin{bmatrix} i\\\\ j \\end{bmatrix}|_1 $$  \u2003\u2003\u533a\u57df\u6784\u5efa\u635f\u5931\u6709\u5229\u4e8e\u5b9a\u4f4d\u56fe\u50cf\u4e2d\u4e3b\u8981\u7684\u5bf9\u8c61\uff0c\u5e76\u4e14\u503e\u5411\u4e8e\u53d1\u73b0\u5b50\u533a\u57df\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u3002\u901a\u8fc7\u7aef\u5230\u7aef\u7684\u8bad\u7ec3\uff0c\u533a\u57df\u6784\u5efa\u635f\u5931\u53ef\u4ee5\u5e2e\u52a9\u5206\u7c7b\u9aa8\u5e72\u7f51\u7edc\u5efa\u7acb\u5bf9\u7269\u4f53\u7684\u6df1\u523b\u7406\u89e3\uff0c\u5e76\u4e14\u8ba9\u7f51\u7edc\u5efa\u6a21\u5bf9\u8c61\u7684\u7ed3\u6784\u4fe1\u606f\uff0c\u5982\u5bf9\u8c61\u7684\u5f62\u72b6\u548c\u5bf9\u8c61\u5404\u90e8\u5206\u4e4b\u95f4\u7684\u8bed\u4e49\u5173\u8054\u3002</p>"},{"location":"fine-grained/paper/DCL1/#_6","title":"\u8bad\u7ec3\u4e0e\u6d4b\u8bd5","text":"<p> \u8bad\u7ec3\u8fc7\u7a0b\uff1a\u5728\u8be5\u7f51\u7edc\u7ed3\u6784\u4e2d\uff0c\u5206\u7c7b\u635f\u5931\u3001\u5bf9\u6297\u635f\u5931\u4ee5\u53ca\u533a\u57df\u5bf9\u9f50\u635f\u5931\u5171\u540c\u53c2\u4e0e\u5230\u7f51\u7edc\u7aef\u5230\u7aef\u7684\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u4f7f\u7f51\u7edc\u53ef\u4ee5\u5229\u7528\u589e\u5f3a\u7684\u5c40\u90e8\u7ec6\u8282\u548c\u5efa\u6a21\u826f\u597d\u7684\u5bf9\u8c61\u90e8\u4ef6\u6765\u8fdb\u884c\u7ec6\u7c92\u5ea6\u7684\u8bc6\u522b\uff0c\u6700\u540e\u603b\u7684\u635f\u5931\u8ba1\u7b97\u516c\u5f0f\u4e3a\uff1a $$ L=\\alpha L_{cls}+\\beta L_{adv}+ \\gamma L_{loc} $$  \u2003\u2003\u201c\u7834\u574f\u201d\u5b66\u4e60\u53ef\u4ee5\u5e2e\u52a9\u7f51\u7edc\u4ece\u6709\u8fa8\u8bc6\u529b\u7684\u533a\u57df\u5b66\u4e60\u56fe\u7247\u7684\u7ec6\u8282\uff0c\u5e76\u4e14\u6784\u5efa\u5b66\u4e60\u5b66\u4e60\u6839\u636e\u533a\u57df\u95f4\u8bed\u4e49\u7684\u76f8\u5173\u6027\uff0c\u91cd\u65b0\u6392\u5217\u5b66\u4e60\u5230\u7684\u5c40\u90e8\u7ec6\u8282\u3002\u56e0\u6b64\uff0cDCL\u53ef\u4ee5\u57fa\u4e8e\u6765\u81ea\u8fa8\u522b\u533a\u57df\u7ed3\u6784\u826f\u597d\u7684\u7ec6\u8282\u7279\u5f81\u6765\u751f\u6210\u4e00\u7cfb\u5217\u590d\u6742\u591a\u6837\u7684\u89c6\u89c9\u8868\u793a\u3002</p> <p> \u6d4b\u8bd5\u8fc7\u7a0b\uff1a\u6d4b\u8bd5\u8fc7\u7a0b\u53ea\u9700\u8981\u5c06\u539f\u56fe\u8f93\u5165\u5230\u5206\u7c7b\u7f51\u7edc\uff0c\u5229\u7528\u53c2\u6570$f(\u00b7,\\theta^{[1,l]}_{cls})\u6765\u5bf9\u539f\u56fe\u7684\u7c7b\u522b\u8fdb\u884c\u9884\u6d4b\uff0c\u56e0\u6b64\uff0c\u9664\u4e86\u4e3b\u5e72\u5206\u7c7b\u7f51\u7edc\u7528\u4e8e\u8ba1\u7b97\u4e4b\u5916\uff0c\u65e0\u9700\u989d\u5916\u7684\u8ba1\u7b97\u5f00\u9500\u3002</p>"},{"location":"fine-grained/paper/DCL1/#_7","title":"\u5b9e\u9a8c","text":""},{"location":"fine-grained/paper/DCL1/#_8","title":"\u53ef\u89c6\u5316\u5206\u6790","text":"<p>\u2003\u2003\u4e3a\u4e86\u8fdb\u4e00\u6b65\u8bc1\u660eDCL\u7684\u6709\u6548\u6027\uff0c\u4f5c\u8005\u5c06\u57fa\u7ebf\u65b9\u6cd5(\u53ea\u6709\u5206\u7c7b\u7f51\u7edc)\u4e0eDCL\u7f51\u7edc\u5f97\u5230\u7684\u7279\u5f81\u56fe\u505a\u4e86\u6bd4\u8f83\uff0c\u5bf9\u6bd4\u56fe\u5982\u4e0b\uff0c\u53ef\u4ee5\u770b\u5230DCL\u4ea7\u751f\u7684\u7279\u5f81\u56fe\u66f4\u80fd\u96c6\u4e2d\u5728\u5224\u522b\u533a\u57df\uff0c\u7ecf\u8fc7\u968f\u673a\u7684\u7834\u574f\uff0c\u7f51\u7edc\u4e5f\u4e00\u81f4\u7684\u7a81\u51fa\u6709\u8fa8\u8bc6\u529b\u7684\u533a\u57df\uff0c\u8fd9\u8fdb\u4e00\u6b65\u8bc1\u660e\u4e86DCL\u5177\u6709\u826f\u597d\u7684\u9c81\u68d2\u6027\u3002</p> <p> <p></p> <p> </p>"},{"location":"fine-grained/paper/DCL1/#_9","title":"\u7cbe\u5ea6\u5bf9\u6bd4","text":""},{"location":"fine-grained/paper/DCL1/#_10","title":"\u603b\u7ed3","text":"<p>\u2003\u2003\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u7ec6\u7c92\u5ea6\u5206\u7c7b\u7684DCL\u7f51\u7edc\u3002\u9996\u5148\u901a\u8fc7\u7834\u574f\u5b66\u4e60\uff0c\u63d0\u9ad8\u4e86\u8bc6\u522b\u7684\u96be\u5ea6\uff0c\u4ece\u800c\u5f15\u5bfc\u7f51\u7edc\u5b66\u4e60\u7ec6\u7c92\u5ea6\u8bc6\u522b\u4e2d\u7684\u4e13\u4e1a\u77e5\u8bc6(\u7ec6\u8282\u5dee\u5f02)\u3002\u800c\u6784\u5efa\u5b66\u4e60\u53ef\u4ee5\u6a21\u62df\u7269\u4f53\u5404\u90e8\u5206\u4e4b\u95f4\u7684\u8bed\u4e49\u5173\u8054\uff0c\u4ece\u800c\u5f15\u5bfc\u7f51\u7edc\u5b66\u4e60\u7269\u4f53\u5404\u90e8\u5206\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u3002\u540c\u65f6\uff0c\u8be5\u7f51\u7edc\u5728\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\u53ea\u9700\u8981\u5c06\u56fe\u7247\u4f20\u5165\u4e3b\u5e72\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u4e2d\u8fdb\u884c\u5206\u7c7b\u9884\u6d4b\uff0c\u8ba1\u7b97\u91cf\u5c0f\uff0c\u5177\u6709\u5f88\u597d\u7684\u5b9e\u7528\u4ef7\u503c\u3002</p> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u89c2\u70b9\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u5927\u5bb6\u6279\u8bc4\u6307\u6b63\u3002</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e7412\u670811\u65e5</p>"},{"location":"fine-grained/paper/MA-CNN1/","title":"\u7ec6\u7c92\u5ea6\uff1aMA-CNN","text":""},{"location":"fine-grained/paper/MA-CNN1/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aIEEE International Conference on Computer Vision 2017 (ICCV 2017)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttp://openaccess.thecvf.com/content_ICCV_2017/papers/Zheng_Learning_Multi-Attention_Convolutional_ICCV_2017_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/Jianlong-Fu/Multi-Attention-CNN\uff08\u5b98\u65b9\u4ee3\u7801\uff0ccaffe\u7248\u672c\uff09\u3001https://github.com/liangnjupt/Multi-Attention-CNN-pytorch\uff08PyTorch\u7248\u672c\uff09</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u7c7b(FGVC)</p>"},{"location":"fine-grained/paper/MA-CNN1/#_2","title":"\u4e3b\u8981\u601d\u60f3","text":"<p>\u2003\u2003\u5728\u6ca1\u6709\u663e\u5f0f\u90e8\u5206\u7ea6\u675f\u7684\u5f31\u76d1\u7763\u5b66\u4e60\u4e2d\uff08\u65e0\u989d\u5916\u6807\u6ce8\uff09\uff0c\u666e\u901a\u7684CNN\u5177\u6709\u8f83\u5dee\u7684\u5c40\u90e8\u5b9a\u4f4d\u80fd\u529b\uff08\u5b9a\u4f4d\u7269\u4f53\u5173\u952e\u90e8\u4f4d\u7684\u80fd\u529b\uff09\u548c\u7ec6\u7c92\u5ea6\u7279\u5f81\u5b66\u4e60\u80fd\u529b\u3002\u672c\u6587\u4f5c\u8005\u53d1\u73b0\u96f6\u4ef6\u5b9a\u4f4d\u548c\u7279\u5f81\u5b66\u4e60\u53ef\u4ee5\u76f8\u4e92\u4fc3\u8fdb\uff0c\u5982\u4e0b\u56fe\u4e2d\uff0c\u6700\u521d\u5934\u90e8\u7684\u5b9a\u4f4d\u53ef\u4ee5\u4fc3\u8fdb\u5934\u90e8\u5468\u56f4\u7279\u5f81\u7684\u5b66\u4e60\uff0c\u8fdb\u4e00\u6b65\u53cd\u8fc7\u6765\u6709\u52a9\u4e8e\u7cbe\u786e\u5b9a\u4f4d\u5934\u90e8\u3002</p> <p> <p></p> <p></p> <p>\u2003\u2003\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u6ce8\u610f\u529b\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08 multi-attention convolutional neural network\uff0c MA-CNN\uff09\u7684\u5c40\u90e8\uff08part\uff09\u5b66\u4e60\u65b9\u6cd5\u3002\u9996\u5148\uff0c\u5377\u79ef\u7279\u5f81\u901a\u9053\u901a\u5e38\u5bf9\u5e94\u4e8e\u67d0\u79cd\u7c7b\u578b\u7684\u89c6\u89c9\u6a21\u5f0f\uff08visual pattern\uff09\uff0c\u56e0\u6b64\uff0c\u4f5c\u8005\u8bbe\u8ba1\u4e86\u901a\u9053\u5206\u7ec4\u5c42\uff08channel grouping layers\uff09\u5c06\u7a7a\u95f4\u76f8\u5173\u7684\u6a21\u5f0f\u52a0\u6743\u805a\u7c7b\u6210\u591a\u4e2a\u5c40\u90e8\u6ce8\u610f\u529b\u56fe\uff0c\u8fdb\u4e00\u6b65\u5f97\u5230\u5c40\u90e8\u5efa\u8bae\uff08part proposals\uff09\uff0c\u5c40\u90e8\u5206\u7c7b\u5b50\u7f51\u7edc\uff08part classification sub-networks\uff09\u8fdb\u4e00\u6b65\u5bf9\u5c40\u90e8\u7279\u5f81\u8fdb\u884c\u5206\u7c7b\uff0c\u4ece\u800c\u4f18\u5316\u67d0\u4e00\u90e8\u4f4d\u76f8\u5173\u7684\u4e00\u7ec4\u7279\u5f81\u901a\u9053\uff0c\u6d88\u9664\u5bf9\u5176\u4ed6\u90e8\u4f4d\u7684\u4f9d\u8d56\uff0c\u4ece\u800c\u53ef\u4ee5\u5b66\u5230\u66f4\u597d\u7684\u7ec6\u7c92\u5ea6\u7279\u5f81\u3002\u540c\u65f6\u4f5c\u8005\u8fd8\u8bbe\u8ba1\u4e86\u901a\u9053\u5206\u7ec4\u635f\u5931\uff0c\u9f13\u52b1\u901a\u9053\u5206\u7ec4\u5c42\u751f\u6210\u591a\u4e2a\u7d27\u51d1\u5e76\u4e14\u591a\u6837\u7684\u5c40\u90e8\u6ce8\u610f\u529b\u56fe\uff0c\u5e76\u4e14\u5229\u7528\u901a\u9053\u635f\u5931\u548c\u5206\u7c7b\u635f\u5931\u4ea4\u66ff\u4f18\u5316\u7f51\u7edc\uff0c\u4f7f\u7f51\u7edc\u7684\u5b9a\u4f4d\u80fd\u529b\u7684\u5b66\u4e60\u548c\u7ec6\u7c92\u5ea6\u7279\u5f81\u8868\u793a\u7684\u5b66\u4e60\u76f8\u4e92\u4fc3\u8fdb\u3002</p>"},{"location":"fine-grained/paper/MA-CNN1/#_3","title":"\u65b9\u6cd5","text":"<p>\u2003\u2003\u672c\u6587\u63d0\u51fa\u7684\u7f51\u7edc\u7ed3\u6784\u4e3b\u8981\u7531\u4e09\u4e2a\u90e8\u5206\u7ec4\u6210\uff1a\u5377\u79ef\u5c42\uff08conv layers\uff09\u3001\u901a\u9053\u5206\u7ec4\u5c42\u548c\u5c40\u90e8\u5206\u7c7b\u5b50\u7f51\u7edc\uff0c\u5177\u4f53\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u9996\u5148\u5c06\u56fe\u7247\u4f20\u5165\u5377\u79ef\u5c42(b)\u4e2d\uff0c\u63d0\u53d6\u57fa\u4e8e\u533a\u57df\u7684\u7279\u5f81\u8868\u793a\uff08feature representation\uff09\uff0c\u4e4b\u540e\u5c06\u5f97\u5230\u7684\u7279\u5f81\u4f20\u5165\u901a\u9053\u5206\u7ec4\u548c\u52a0\u6743\u5c42(d)\uff0c\u5f97\u5230\u591a\u4e2a\u5c40\u90e8\u6ce8\u610f\u529b\u56fe(e)\uff0c\u518d\u5c06\u5c40\u90e8\u6ce8\u610f\u529b\u56fe\u548c\u7279\u5f81\u76f8\u4e58\u5f97\u5230\u5c40\u90e8\u7279\u5f81\u8868\u793a\uff08part representation\uff09\uff0c\u6700\u540e\u5c06\u6bcf\u4e2a\u90e8\u5206\u7684\u7279\u5f81\u8868\u793a\u4f20\u5165\u5168\u8fde\u63a5\u5c42\uff0c\u9884\u6d4b\u7c7b\u522b\u6982\u7387\u3002\u4f5c\u8005\u8fd8\u63d0\u51fa\u4e86\u4ea4\u66ff\u5b66\u4e60\u7b56\u7565\u6765\u4f18\u5316\u8be5\u7f51\u7edc\uff0c\u5229\u7528\u5206\u7c7b\u635f\u5931\u6765\u4f18\u5316\u7279\u5f81\u8868\u793a\uff0c\u5229\u7528\u901a\u9053\u5206\u7ec4\u635f\u5931\u6765\u4f18\u5316\u6ce8\u610f\u529b\u56fe\u7684\u751f\u6210\uff0c\u4ece\u800c\u8fbe\u5230\u5c40\u90e8\u5b9a\u4f4d\uff08part localization\uff09\u7684\u5b66\u4e60\u548c\u7279\u5f81\u8868\u793a\uff08feature representation\uff09\u7684\u5b66\u4e60\u76f8\u4e92\u4fc3\u8fdb\u7684\u6548\u679c\u3002</p>"},{"location":"fine-grained/paper/MA-CNN1/#_4","title":"\u591a\u6ce8\u610f\u529b\u7f51\u7edc","text":"<p>\u2003\u2003\u7ed9\u5b9a\u4e00\u4e2a\u8f93\u5165\u56fe\u50cfX\uff0c\u9996\u5148\u5c06\u5176\u4f20\u5165\u9884\u8bad\u7ec3\u597d\u7684\u5377\u79ef\u5c42\u6765\u63d0\u53d6\u57fa\u4e8e\u533a\u57df\u7684\u6df1\u5ea6\u7279\u5f81\uff0c\u5047\u8bbe\u5f97\u5230\u7684\u7279\u5f81\u8868\u793a\u4e3aW*X\uff0c\u5176\u4e2dW\u8868\u793a\u4e3a\u5377\u79ef\u53c2\u6570\uff0c\u7279\u5f81\u5c3a\u5bf8\u4e3aw\\times h\\times c\uff0c\u5176\u4e2dw,h,c\u4f9d\u6b21\u8868\u793a\u7279\u5f81\u56fe\u7684\u5bbd\u3001\u9ad8\u548c\u901a\u9053\u6570\u3002\u5355\u4e00\u901a\u9053\u7684\u7279\u5f81\u5f88\u96be\u8868\u793a\u4e30\u5bcc\u7684\u5c40\u90e8\u4fe1\u606f\uff0c\u56e0\u6b64\u4f5c\u8005\u63d0\u51fa\u4e86\u901a\u9053\u5206\u7ec4\u548c\u52a0\u6743\u5b50\u7f51\u7edc\uff0c\u5c06\u7a7a\u95f4\u76f8\u5173\u7684\u6a21\u5f0f\u4ece\u4e00\u7ec4\u5cf0\u503c\u54cd\u5e94\u51fa\u73b0\u5728\u76f8\u90bb\u4f4d\u7f6e\u7684\u901a\u9053\u4e2d\u805a\u7c7b\u4e3a\u7d27\u51d1\u3001\u6709\u533a\u522b\u7684\u90e8\u5206\u3002</p> <p>\u2003\u2003\u76f4\u89c2\u5730\u6765\u8bf4\uff0c\u6bcf\u4e2a\u901a\u9053\u7684\u7279\u5f81\u56fe\u53ef\u4ee5\u8868\u793a\u4e3a\u6240\u6709\u8bad\u7ec3\u56fe\u50cf\u7684\u5cf0\u503c\u54cd\u5e94\u5750\u6807\uff08\u8fd9\u91cc\u6307\u5c06c\u4e2a\u901a\u9053\u62c6\u5f00\uff0c\u5355\u4e2a\u901a\u9053\u5355\u4e2a\u901a\u9053\u5730\u770b\uff09\uff0c\u5373\uff1a $$ \\left[ t^1_x, t^1_y,t^2_x,t^2_y,\\dots,t^{\\Omega}_x,t^{\\Omega}_y \\right] $$  \u5176\u4e2dt^i_x,t^i_y\u8868\u793a\u7b2ci\u5f20\u8bad\u7ec3\u56fe\u50cf\u7684\u5cf0\u503c\u54cd\u5e94\u5750\u6807\uff0c\\Omega\u8868\u793a\u8bad\u7ec3\u56fe\u7247\u7684\u6570\u91cf\u3002\u4e4b\u540e\u5c06\u4f4d\u7f6e\u5411\u91cf\u505a\u4e3a\u5f53\u524d\u7279\u5f81\u56fe\u7684\u7279\u5f81\uff0c\u5c06\u4e0d\u540c\u901a\u9053\u805a\u5408\u6210N\u7ec4\u7279\u5f81\uff0c\u4f5c\u4e3aN\u4e2a\u5c40\u90e8\u68c0\u6d4b\u5668\uff0c\u5373\u5c06\u5cf0\u503c\u5750\u6807\u76f8\u8fd1\u7684\u7279\u5f81\u901a\u9053\u805a\u6210\u4e00\u7c7b\uff0c\u4e00\u5171\u805a\u6210N\u7c7b\u3002\u6bcf\u7ec4\u76f8\u5173\u7279\u5f81\u7531\u6240\u6709\u7279\u5f81\u901a\u9053\u8868\u793a\u800c\u6210\uff0c\u7279\u5f81\u901a\u9053\u4e0a\u7684\u6307\u793a\u5668\u51fd\u6570\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ \\left[1\\{1\\},\\dots,1\\{j\\},\\dots,1\\{c\\}  \\right] $$  \u5176\u4e2d\uff0c\u5f53\u7b2cj\u4e2a\u901a\u9053\u5c5e\u4e8e\u7b2ci\u4e2a\u5206\u7ec4\u65f6\uff0c1\\{\\cdot\\}\u7b49\u4e8e1\uff0c\u5426\u52191\\{\\cdot\\}\u7b49\u4e8e0\u3002</p> <p>\u2003\u2003\u4e0a\u8ff0\u5c5e\u4e8e\u6700\u7406\u60f3\u7684\u60c5\u51b5\uff0c\u76f4\u63a5\u6307\u5b9a\u901a\u9053\u7684\u5206\u7ec4\u60c5\u51b5\u3002\u4f46\u8ba1\u7b97\u673a\u5f80\u5f80\u4e0d\u80fd\u4f18\u5316\u79bb\u6563\u7684\u8fc7\u7a0b\uff0c\u56e0\u4e3a\u53ea\u6709\u51fd\u6570\u8fde\u7eed\uff0c\u624d\u80fd\u6c42\u5bfc\uff0c\u4ece\u800c\u8fdb\u4e00\u6b65\u5229\u7528\u68af\u5ea6\u4e0b\u964d\u6cd5\u4f18\u5316\u7f51\u7edc\u6a21\u578b\uff0c\u56e0\u6b64\u5728\u795e\u7ecf\u7f51\u7edc\u4e2d\u5f80\u5f80\u4ee5\u52a0\u6743\u7684\u60c5\u51b5\u6765\u8fbe\u5230\u5206\u7ec4\u7684\u6548\u679c\uff0c\u5f53\u7b2ci\u4e2a\u901a\u9053\u8d8a\u5c5e\u4e8e\u7b2cj\u4e2a\u5206\u7ec4\u65f6\uff0c\u8fd9\u4e00\u6743\u91cd\u8d8a\u5927\uff0c\u53cd\u4e4b\u8d8a\u4e0d\u5c5e\u4e8e\u8be5\u5206\u7ec4\u65f6\uff0c\u8fd9\u4e00\u6743\u91cd\u8d8a\u5c0f\u3002</p> <p>\u2003\u2003\u56e0\u6b64\u4f5c\u8005\u63d0\u51fa\u4e86\u901a\u9053\u5206\u7ec4\u5c42\u6765\u8fd1\u4f3c\u5b9e\u73b0\u5206\u7ec4\u7684\u60c5\u51b5\uff0c\u4e3a\u4e86\u5206\u6210N\u4e2a\u7ec4\u522b\uff0c\u9996\u5148\u5b9a\u4e49\u4e00\u7ec4\u5168\u8fde\u63a5\u5c42\u51fd\u6570\uff1a $$ F(\\cdot)=\\left[f_1(\\cdot),\\dots,f_N(\\cdot) \\right] $$  \u5176\u4e2d\u6bcf\u4e2a\u5168\u8fde\u63a5\u51fd\u6570f_i(\\cdot)\u4ee5\u5377\u79ef\u7279\u5f81\u4f5c\u4e3a\u8f93\u5165\uff0c\u751f\u6210\u4e00\u7ec4\u6743\u91cd\u5411\u91cfd_i\uff0cd_i\u4e2d\u6bcf\u4e2a\u5143\u7d20\u8868\u793a\u4e0d\u540c\u901a\u9053\u5bf9\u5e94\u7b2ci\u4e2a\u5206\u7ec4\u7684\u6743\u91cd\uff0c\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ d_i(X)=f_i(W*X) $$  \u4e4b\u540e\u518d\u5c06\u5f97\u5230\u7684\u6743\u91cd\u5411\u91cf\u4e0e\u7279\u5f81\u505a\u70b9\u4e58\uff0c\u518d\u6cbf\u901a\u9053\u65b9\u5411\u6c42\u548c\uff0c\u6700\u540e\u4f20\u5165\\text{Sigmoid}\u51fd\u6570\u505a\u5f52\u4e00\u5316\u5904\u7406\uff0c\u5f97\u5230\u7b2ci\u4e2a\u5206\u7ec4\u7684\u5c40\u90e8\u6ce8\u610f\u529b\u56feM_i(X)\uff1a $$ M_i(X)=\\text{sigmoid}(\\sum^c_{j=1}d_j\\left[W*X \\right]_j) $$  \u5176\u4e2d\\left[\\cdot\\right]_j\u8868\u793a\u7b2cj\u4e2a\u901a\u9053\u7684\u5377\u79ef\u7279\u5f81\u3002\u5f97\u5230\u5c40\u90e8\u6ce8\u610f\u529b\u56fe\u4e4b\u540e\uff0c\u518d\u5c06\u5c40\u90e8\u6ce8\u610f\u529b\u4e0e\u56fe\u50cf\u7279\u5f81\u505a\u70b9\u4e58\uff0c\u4e4b\u540e\u518d\u505a\u6c60\u5316\u8fd0\u7b97\uff0c\u6700\u540e\u5f97\u5230\u7b2ci\u4e2a\u5206\u7ec4\u7684\u5c40\u90e8\u7279\u5f81P_i(X)\uff1a $$ P_i(X)=\\sum^c_{j=1}(\\left[W*X \\right]_j\\cdot M_i) $$ </p> <p>\u8fd9\u91cc\u6211\u611f\u89c9\u8bba\u6587\u516c\u5f0f\u5e94\u8be5\u5199\u9519\u4e86\uff0c\u4e0d\u662f\u6cbf\u901a\u9053\u6c42\u548c\uff0c\u5e94\u8be5\u662f\u505a\u5168\u5c40\u6c60\u5316\u3002</p> <p>\u6700\u540e\u518d\u5229\u7528P_i(X)\uff0c\u5f97\u5230\u5c40\u90e8\u9884\u6d4b\uff0c\u4f8b\u5982\u5c06P_i(X)\u4f20\u5165\u5168\u8fde\u63a5\u5c42\u3002</p>"},{"location":"fine-grained/paper/MA-CNN1/#_5","title":"\u4f18\u5316\u7b56\u7565","text":""},{"location":"fine-grained/paper/MA-CNN1/#_6","title":"\u635f\u5931\u51fd\u6570","text":"<p>\u2003\u2003\u672c\u6587\u4e2d\u7684MA-CNN\u901a\u8fc7\u5c40\u90e8\u5206\u7c7b\u635f\u5931\u548c\u901a\u9053\u5206\u7ec4\u635f\u5931\u5171\u540c\u76d1\u7763\u4f18\u5316\uff0c\u603b\u635f\u5931\u5b9a\u4e49\u4e3a\uff1a $$ L(X)=\\sum^N_{i=1}\\left[L_{cls}(Y^{(i)},Y^*) \\right] +L_{cng}(M_1,\\dots,M_N) $$  \u5176\u4e2dL_{cls}\u8868\u793a\u4e3a\u5c40\u90e8\u5206\u7c7b\u635f\u5931\uff0c\u5373\u4ea4\u53c9\u71b5\u635f\u5931\uff0cY^{(i)}\u8868\u793a\u7b2ci\u4e2a\u90e8\u5206\u7684\u9884\u6d4b\u7c7b\u522b\u5411\u91cf\uff0cY^*\u8868\u793a\u56fe\u50cf\u7684\u6807\u7b7e\uff0cL_{cng}\u8868\u793a\u901a\u9053\u5206\u7ec4\u635f\u5931\u3002</p> <p>\u2003\u2003\u6bcf\u4e2a\u5206\u652f\u6240\u5b9a\u4f4d\u7684\u533a\u57df\u9700\u8981\u6709\u5f88\u5f3a\u7684\u8fa8\u8bc6\u80fd\u529b\uff0c\u5e76\u4e14\u6700\u597d\u53ef\u4ee5\u96c6\u4e2d\u4e8e\u4e00\u4e2a\u4f4d\u7f6e\uff08\u6bcf\u4e2a\u5c40\u90e8\u6ce8\u610f\u529b\u56fe\u6240\u5173\u6ce8\u7684\u70b9\u6bd4\u8f83\u96c6\u4e2d\uff09\uff0c\u5e76\u4e14\u4e0d\u540c\u5206\u652f\u4e4b\u95f4\u6240\u5b9a\u4f4d\u7684\u533a\u57df\u6700\u597d\u4e0d\u4e00\u6837\uff08\u4e0d\u540c\u6ce8\u610f\u529b\u56fe\u5173\u6ce8\u4e0d\u540c\u7684\u533a\u57df\uff09\u3002\u5982\u679c\u4e00\u4e2a\u6a21\u578b\u6240\u6709\u7684\u5206\u652f\u53ea\u80fd\u5b9a\u4f4d\u4e00\u4e2a\u6709\u52a9\u4e8e\u5206\u7c7b\u7684\u533a\u57df\uff0c\u90a3\u4e48\u8be5\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u5c31\u6bd4\u8f83\u5dee\uff08\u7c7b\u4f3c\u8fc7\u62df\u5408\uff09\uff0c\u4e00\u65e6\u8be5\u90e8\u4f4d\u88ab\u906e\u6321\uff0c\u90a3\u4e48\u5c06\u4e25\u91cd\u5f71\u54cd\u7f51\u7edc\u5bf9\u8be5\u7269\u4f53\u7684\u5206\u7c7b\u51b3\u7b56\u3002\u56e0\u6b64\u9700\u8981\u8bbe\u8ba1\u4e00\u79cd\u635f\u5931\uff0c\u65e2\u53ef\u4ee5\u8981\u6c42\u7f51\u7edc\u540c\u4e00\u4e2a\u5206\u652f\u53ef\u4ee5\u5b9a\u4f4d\u76f8\u540c\u7684\u533a\u57df\uff0c\u8fd8\u53ef\u4ee5\u8981\u6c42\u7f51\u7edc\u4e0d\u540c\u5206\u652f\u4e4b\u95f4\u5b9a\u4f4d\u4e0d\u540c\u7684\u533a\u57df\uff0c\u4ece\u800c\u63d0\u9ad8\u7f51\u7edc\u7684\u9c81\u68d2\u6027\uff0c\u5bf9\u6b64\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u8ddd\u79bb\u635f\u5931Dis(\\cdot)\u548c\u591a\u6837\u6027\u635f\u5931Div(\\cdot)\uff0c\u5171\u540c\u7ec4\u6210\u901a\u9053\u5206\u7ec4\u635f\u5931\uff1a $$ L_{cng}(M_i)=Dis(M_i)+\\lambda Div(M_i) $$  \u5176\u4e2d\\lambda\u7528\u4e8e\u5e73\u8861\u4e8c\u8005\u4e4b\u95f4\u7684\u6743\u91cd\u3002</p> <p>\u8ddd\u79bb\u635f\u5931</p> <p> Dis(\\cdot)\u7528\u4e8e\u9f13\u52b1\u901a\u9053\u5206\u7ec4\u5c42\u6240\u751f\u6210\u7684\u5c40\u90e8\u6ce8\u610f\u529b\u56feM_i\u5177\u6709\u7d27\u5bc6\u7684\u5206\u5e03\uff0c\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ Dis(M_i)=\\sum_{(x,y)\\in M_i}m_i(x,y)\\left[||x-t_x||^2+||y-t_y||^2 \\right] $$  \u5176\u4e2d\uff0cx\u548cy\u8868\u793a\u5c40\u90e8\u6ce8\u610f\u56feM_i\u4e0a\u7684\u5750\u6807\uff0cm_i(x,y)\u8868\u793a\u5728(x,y)\u5904M_i\u7684\u54cd\u5e94\u503c\uff0ct_x\u548ct_y\u8868\u793a\u6ce8\u610f\u529b\u56fe\u4e0a\u7684\u5cf0\u503c\u54cd\u5e94\u5750\u6807\u3002\u8be5\u635f\u5931\u8981\u6c42M_i\u4e0a\u7684\u54cd\u5e94\u6570\u636e\u90fd\u5f80\u5cf0\u503c\u54cd\u5e94\u5904\u9760\u62e2\uff0c\u4e0a\u8ff0\u516c\u5f0f\u540e\u534a\u90e8\u5206\u53ef\u4ee5\u770b\u6210\u4e00\u4e2a\u8ddd\u79bb\u77e9\u9635\uff0c\u8be5\u77e9\u9635\u6bcf\u4e2a\u70b9\u4e0a\u7684\u6570\u636e\u90fd\u662f\u8be5\u70b9\u548c\u5cf0\u503c\u5750\u6807\u7684\u8ddd\u79bb\uff0c\u4e5f\u5c31\u662f\u4ece\u5cf0\u503c\u54cd\u5e94\u5904\u5411\u56db\u5468\u6269\u6563\u7684\u77e9\u9635\uff0c\u8ddd\u79bb\u8d8a\u8fdc\uff0c\u503c\u8d8a\u5927\u3002\u56e0\u6b64\u82e5\u60f3\u964d\u4f4eDis\u635f\u5931\uff0cM_i\u4e0a\u7684\u9ad8\u54cd\u5e94\u6570\u636e\u5fc5\u987b\u96c6\u4e2d\u4e8e\u5cf0\u503c\u54cd\u5e94\u5904\uff0c\u5f53\u54cd\u5e94\u503c\u8d8a\u5927\u65f6\uff0c\u5fc5\u987b\u548c\u5cf0\u503c\u54cd\u5e94\u70b9\u8d8a\u8fd1\uff0c\u6b64\u65f6\u548c\u8ddd\u79bb\u76f8\u4e58\u624d\u4f1a\u5f97\u5230\u5c0f\u635f\u5931\uff0c\u4ece\u800c\u6700\u7ec8\u5f97\u5230\u5bc6\u96c6\u7684\u54cd\u5e94\u5206\u5e03\u3002</p> <p>\u591a\u6837\u6027\u635f\u5931</p> <p> Div(\\cdot)\u7528\u4e8e\u9f13\u52b1\u901a\u9053\u5206\u7ec4\u5c42\u751f\u6210\u5206\u5e03\u591a\u6837\u7684\u5c40\u90e8\u6ce8\u610f\u529b\u56feM_i\uff0c\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ Div(M_i)=\\sum_{(x,y)\\in M_i}m_i(x,y)\\left[\\max_{k\\neq i}m_k(x,y)-mrg \\right] $$  \u5176\u4e2di,k\u8868\u793a\u4e0d\u540c\u7684\u5c40\u90e8\u6ce8\u610f\u529b\u56fe\uff0cmrg\u8868\u793a\u8fb9\u7f18\u53c2\u6570\uff0c\u7528\u4e8e\u964d\u4f4e\u635f\u5931\u5bf9\u566a\u58f0\u7684\u654f\u611f\u5ea6\uff0c\u63d0\u5347\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002\u8be5\u635f\u5931\u8981\u6c42\u4e0d\u540c\u7684\u6ce8\u610f\u529b\u56fe\u53bb\u5173\u6ce8\u4e0d\u540c\u7684\u533a\u57df\uff0c\u901a\u4fd7\u6765\u8bb2\uff0c\u5c06\u6240\u6709\u6ce8\u610f\u529b\u56fe\u53e0\u8d77\u6765\uff0c\u6cbf\u901a\u9053\u65b9\u5411\u770b\uff0c\u540c\u4e00\u4e2a\u4f4d\u7f6e(x,y)\u4e0a\uff0c\u6700\u591a\u53ea\u80fd\u6709\u4e00\u5f20\u6ce8\u610f\u529b\u56fe\u4e0a\u7684\u6570\u636e\u662f\u9ad8\u54cd\u5e94\u6570\u636e\uff0c\u964d\u4f4e\u4e86\u533a\u57df\u5197\u4f59\u5ea6\u3002\u6362\u4e2a\u89d2\u5ea6\u601d\u8003\uff0c\u4e4b\u6240\u4ee5\u7f51\u7edc\u88ab\u8bbe\u8ba1\u6210\u591a\u4e2a\u5206\u652f\uff08\u5bf9\u5e94\u201c\u591a\u6ce8\u610f\u529b\u201d\uff09\uff0c\u5c31\u662f\u5e0c\u671b\u7f51\u7edc\u53ef\u4ee5\u5b9a\u4f4d\u591a\u4e2a\u5173\u952e\u533a\u57df\uff0c\u8ba9\u4e0d\u540c\u533a\u57df\u540c\u65f6\u53c2\u4e0e\u7269\u4f53\u7c7b\u522b\u7684\u51b3\u7b56\uff0c\u56e0\u6b64\u591a\u6837\u6027\u635f\u5931\u4e0e\u7f51\u7edc\u7ed3\u6784\u662f\u5bc6\u4e0d\u53ef\u5206\u7684\u3002</p>"},{"location":"fine-grained/paper/MA-CNN1/#_7","title":"\u4ea4\u66ff\u4f18\u5316","text":"<p>\u2003\u2003\u4e3a\u4e86\u4f7f\u6a21\u578b\u5c40\u90e8\u5b9a\u4f4d\u548c\u7279\u5f81\u5b66\u4e60\u7684\u80fd\u529b\u76f8\u4e92\u4fc3\u8fdb\uff0c\u4f5c\u8005\u91c7\u7528\u4ea4\u66ff\u4f18\u5316\u7684\u8bad\u7ec3\u7b56\u7565\u3002\u9996\u5148\u56fa\u5b9a\u4f4f\u5377\u79ef\u5c42(b)\u7684\u53c2\u6570\uff0c\u5229\u7528\u901a\u9053\u5206\u7ec4\u635f\u5931L_{cng}\u6765\u4f18\u5316\u901a\u9053\u5206\u7ec4\u5c42(d)\u7684\u53c2\u6570\uff0c\u4ece\u800c\u63d0\u9ad8\u6a21\u578b\u7684\u5b9a\u4f4d\u80fd\u529b\uff1b\u4e4b\u540e\u56fa\u5b9a\u4f4f\u901a\u9053\u5206\u7ec4\u5c42(d)\u7684\u53c2\u6570\uff0c\u5229\u7528\u5206\u7c7b\u635f\u5931L_{cls}\u6765\u4f18\u5316\u5377\u79ef\u5c42(b)\u7684\u53c2\u6570\uff0c\u4ece\u800c\u63d0\u9ad8\u6a21\u578b\u7684\u7ec6\u7c92\u5ea6\u7279\u5f81\u8868\u793a\u7684\u80fd\u529b\u3002\u4e24\u79cd\u4f18\u5316\u8fc7\u7a0b\u4ea4\u66ff\u8fdb\u884c\uff0c\u76f4\u5230\u4e24\u7c7b\u635f\u5931\u4e0d\u518d\u53d8\u5316\uff08\u5373\u53d8\u5316\u5e45\u5ea6\u5c0f\u4e8e\u67d0\u4e2a\u9608\u503c\uff0c\u7c7b\u4f3cRA-CNN\u4e2d\u7684\u4f18\u5316\u7b56\u7565\uff09\u3002</p> <p>\u2003\u2003\u4e3a\u4e86\u66f4\u597d\u5730\u8bf4\u660e\u8ddd\u79bb\u635f\u5931Dis\u548c\u591a\u6837\u6027\u635f\u5931Div\u7684\u673a\u5236\uff0c\u4f5c\u8005\u53ef\u89c6\u5316\u4e86\u6ce8\u610f\u529b\u56fe\u4ee5\u53ca\u6bcf\u4e2a\u4f4d\u7f6e\u7684\u5bfc\u6570\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u533a\u57df\u8d8a\u4eae\uff0c\u8868\u793a\u6ce8\u610f\u529b\u56fe\u7684\u54cd\u5e94\u503c\u8d8a\u9ad8\uff0c\u9ec4\u8272\u7684\u201d+\u201d\u8868\u793a\u9700\u8981\u52a0\u5f3a\u7684\u533a\u57df\uff0c\u84dd\u8272\u7684\u201d-\u201c\u8868\u793a\u9700\u8981\u524a\u5f31\u7684\u533a\u57df\uff0c\u7070\u8272\u7684\u201d\u00b7\u201d\u8868\u793a\u4e0d\u53d8\u3002\u4ece\u56fe\u4e2d\u53ef\u4ee5\u53d1\u73b0\uff0c\u968f\u7740\u4f18\u5316\u7684\u8fdb\u884c\uff0c\u6ce8\u610f\u529b\u56fe(a)\u7684\u5173\u6ce8\u533a\u57df\u9010\u6e10\u5411\u5934\u90e8\u9760\u62e2\uff0c\u6ce8\u610f\u529b\u56fe(b)\u7684\u5173\u6ce8\u533a\u57df\u9010\u6e10\u5411\u7fc5\u8180\u90e8\u5206\u9760\u62e2\uff0c\u4e24\u8005\u91cd\u53e0\u7684\u533a\u57df\u8d8a\u6765\u8d8a\u5c0f\u3002</p>"},{"location":"fine-grained/paper/MA-CNN1/#_8","title":"\u8054\u5408\u7279\u5f81\u8868\u793a","text":"<p>\u2003\u2003\u7531\u4e8e\u5355\u4e2a\u5c40\u90e8\u7684\u5c3a\u5bf8\u6bd4\u8f83\u5c0f\uff0c\u96be\u4ee5\u8868\u793a\u5c40\u90e8\u533a\u57df\u5b58\u5728\u7684\u7ec6\u5fae\u5dee\u5f02\uff0c\u5bf9\u6b64\u4f5c\u8005\u5e94\u7528\u5c40\u90e8\u7f29\u653e\uff0c\u5c06\u539f\u59cb\u5c0f\u7684\u5c40\u90e8\u653e\u5927\u6210\u6bd4\u8f83\u5927\u7684\u90e8\u5206\u3002\u5047\u8bbe\u8f93\u5165\u56fe\u50cfX\u5c3a\u5bf8\u4e3a448\\times448\uff0c\u9996\u5148\u5c06\u5176\u4f20\u5165MA-CNN\u4e2d\uff0c\u5f97\u5230N\u4e2a\u5cf0\u503c\u5750\u6807\u70b9\uff08N\u8868\u793a\u5206\u652f\u4e2a\u6570\uff09\uff0c\u4ee5\u6bcf\u4e2a\u5cf0\u503c\u5750\u6807\u4e3a\u4e2d\u5fc3\uff0c\u88c1\u526a96\\times96\u7684\u5c0f\u533a\u57df\uff0c\u518d\u5c06\u5c0f\u533a\u57df\u653e\u5927\u6210224\\times224\uff0c\u8f93\u5165\u5230CNN\u4e2d\u63d0\u53d6\u7279\u5f81\uff0c\u5f97\u5230\u5c40\u90e8\u7279\u5f81\u8868\u793a\uff0c\u4e4b\u540e\u5c06\u5c40\u90e8\u7279\u5f81\u548c\u5168\u5c40\u7279\u5f81\uff08\u5373\u6574\u5f20\u56fe\u50cf\uff09\u5408\u5e76\uff1a $$ \\{P_1,P_2,\\dots,P_N,P_O\\} $$  \u6700\u540e\u4f20\u5165\u5168\u8fde\u63a5\u5c42\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u9884\u6d4b\u7ed3\u679c\u3002</p>"},{"location":"fine-grained/paper/MA-CNN1/#_9","title":"\u5b9e\u9a8c","text":""},{"location":"fine-grained/paper/MA-CNN1/#_10","title":"\u53ef\u89c6\u5316\u5206\u6790","text":"<p>\u2003\u2003\u4f5c\u8005\u53ef\u89c6\u5316\u4e86\u96f6\u4ef6\u5b9a\u4f4d\u60c5\u51b5\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u5176\u4e2d(a)\u8868\u793a\u53ea\u4f7f\u7528\u521d\u59cb\u7684\u901a\u9053\u5206\u7ec4\u5c42\u805a\u7c7b\uff0c(b)\u8868\u793a\u53ea\u4f7f\u7528L_{cng}\u4f18\u5316\u7f51\u7edc\uff0c\u00a9\u8868\u793a\u4f7f\u7528L_{cng}\u548cL_{cls}\u4ea4\u66ff\u4f18\u5316\u7f51\u7edc\u3002</p> <p>\u2003\u2003\u4f5c\u8005\u8fd8\u53ef\u89c6\u5316\u4e86\u5c40\u90e8\u6ce8\u610f\u529b\u56fe\u7684\u5173\u6ce8\u533a\u57df\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p>"},{"location":"fine-grained/paper/MA-CNN1/#_11","title":"\u7cbe\u5ea6\u5bf9\u6bd4","text":"<p>CUB-200-2011</p> <p> <p></p> <p></p> <p>Aircraft</p> <p> <p></p> <p></p> <p>Stanford Cars</p> <p> <p></p> <p></p>"},{"location":"fine-grained/paper/MA-CNN1/#_12","title":"\u603b\u7ed3","text":"<p>\u2003\u2003\u672c\u6587\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u7ec6\u7c92\u5ea6\u8bc6\u522b\u7684\u591a\u91cd\u6ce8\u610f\u529b\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u540c\u65f6\u63d0\u51fa\u4e86\u8ddd\u79bb\u635f\u5931\u548c\u591a\u6837\u6027\u635f\u5931\u6765\u4f18\u5316\u4e0d\u540c\u5206\u652f\u7684\u6ce8\u610f\u529b\uff0c\u4f7f\u5f97\u751f\u6210\u7684\u5c40\u90e8\u6ce8\u610f\u529b\u56fe\u5177\u6709\u7d27\u5bc6\u5ea6\u9ad8\u3001\u591a\u6837\u6027\u5f3a\u7684\u7279\u70b9\uff0c\u5e76\u4e14\u5229\u7528\u4ea4\u66ff\u4f18\u5316\u7b56\u7565\u5b9e\u73b0\u5224\u522b\u533a\u57df\u7684\u5b9a\u4f4d\u548c\u7ec6\u7c92\u5ea6\u7279\u5f81\u7684\u8868\u793a\u76f8\u4e92\u4fc3\u8fdb\u5b66\u4e60\u3002</p> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u6307\u6b63\u3002</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2023\u5e741\u670810\u65e5</p>"},{"location":"fine-grained/paper/MC-Loss1/","title":"MC-Loss","text":""},{"location":"fine-grained/paper/MC-Loss1/#_1","title":"\u7efc\u8ff0","text":"<p>\u671f\u520a\u4e0e\u65f6\u95f4\uff1aIEEE Transactions on Image Processing 2020 (TIP 2020)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://arxiv.org/pdf/2002.04264</p> <p>\u6e90\u7801\u5730\u5740(PyTorch\u7248\u672c)\uff1ahttps://github.com/dongliangchang/Mutual-Channel-Loss</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u7c7b(FGVC)</p>"},{"location":"fine-grained/paper/MC-Loss1/#_2","title":"\u4e3b\u8981\u601d\u60f3","text":"<p>\u2003\u2003\u7ec6\u7c92\u5ea6\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u7531\u4e8e\u7c7b\u522b\u95f4\u7684\u89c6\u89c9\u5dee\u5f02\u5f80\u5f80\u5f88\u5fae\u5c0f\uff0c\u5e76\u4e14\u901a\u5e38\u5b58\u5728\u4e8e\u5c40\u90e8\u7ec6\u8282\u4e2d\uff0c\u56e0\u6b64\u4ece\u5e26\u6709\u7ec6\u5fae\u5dee\u5f02\u7684\u5c40\u90e8\u7ec6\u8282\u4e2d\u63d0\u53d6\u4fe1\u606f\u662f\u89e3\u51b3\u7ec6\u7c92\u5ea6\u5206\u7c7b\u7684\u5173\u952e\u3002\u65e9\u671f\u7684\u5de5\u4f5c\u5f88\u5927\u7a0b\u5ea6\u4e0a\u4f9d\u8d56\u4e8e\u5bf9\u56fe\u7247\u96f6\u4ef6\u7684\u6807\u6ce8\uff0c\u4f46\u7531\u4e8e\u4eba\u5de5\u6ce8\u91ca\u83b7\u53d6\u975e\u5e38\u9ebb\u70e6\uff0c\u5e76\u4e14\u901a\u5e38\u5e26\u6709\u4e3b\u89c2\u6027\uff0c\u56e0\u6b64\u8be5\u65b9\u6cd5\u4e0d\u4fbf\u4e8e\u5b9e\u9645\u63a8\u5e7f\u3002\u56e0\u6b64\uff0c\u6700\u8fd1\u7684\u7814\u7a76\u90fd\u96c6\u4e2d\u4e0e\u4ee5\u5f31\u76d1\u7763\u5b66\u4e60\u7684\u65b9\u5f0f\u53d1\u73b0\u96f6\u4ef6\u533a\u57df\uff0c\u8fd9\u4e9b\u4e0d\u9700\u8981\u4eba\u5de5\u989d\u5916\u6807\u6ce8\u7684\u65b9\u6cd5\u6240\u8fbe\u5230\u7684\u6027\u80fd\u751a\u81f3\u8981\u66f4\u597d\uff0c\u56e0\u4e3a\u5b83\u4eec\u53ef\u4ee5\u6316\u6398\u4eba\u7c7b\u6807\u6ce8\u6846\u4e2d\u4e0d\u51c6\u786e\u6216\u8005\u7f3a\u5931\u7684\u5224\u522b(discriminative)\u533a\u57df\u3002\u4e3a\u4e86\u51c6\u786e\u6709\u6548\u5730\u5b9a\u4f4d\u7269\u4f53\u7684\u8fa8\u8bc6\u529b\u90e8\u4f4d\uff0c\u4eba\u4eec\u63d0\u51fa\u4e86\u8d8a\u6765\u8d8a\u590d\u6742\u7684\u7f51\u7edc\uff0c\u8fd9\u4e9b\u7f51\u7edc\u5927\u81f4\u90fd\u7531\u4e24\u4e2a\u7ec4\u4ef6\u6784\u6210\uff1a\u2460\u6267\u884c\u90e8\u4ef6\u68c0\u6d4b\u7684\u7f51\u7edc\u7ec4\u4ef6\uff1b\u2461\u786e\u4fdd\u6240\u5b66\u7684\u7279\u5f81\u5177\u6709\u6700\u5927\u533a\u5206\u5ea6\u7684\u7ec4\u4ef6\u3002</p> <p>\u2003\u2003\u672c\u6587\u4e2d\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u7ea6\u675f\u7279\u5f81\u901a\u9053\u7684\u901a\u9053\u4ea4\u4e92\u635f\u5931(Mutual-Channel Loss, MC-Loss)\uff0c\u5229\u7528\u635f\u5931\u6765\u540c\u65f6\u5b9e\u73b0\u5224\u522b\u7279\u5f81(discriminative features)\u7684\u5b9a\u4f4d\u548c\u5b66\u4e60\uff0c\u76f4\u63a5\u5728\u901a\u9053\u7279\u5f81\u4e2d\u7814\u7a76\u7ec6\u7c92\u5ea6\u7684\u96f6\u4ef6\u7ea7\u7279\u5f81(part-level features)\uff0c\u8be5\u65b9\u6cd5\u5177\u6709\u5982\u4e0b\u4e24\u4e2a\u597d\u5904\uff1a</p> <ul> <li>\u4e0d\u6dfb\u52a0\u4efb\u4f55\u989d\u5916\u7684\u7f51\u7edc\u53c2\u6570\u548c\u7f51\u7edc\u7ec4\u4ef6\uff0c\u4fbf\u4e8e\u8bad\u7ec3\uff1b</li> <li>\u53ef\u4ee5\u5f88\u597d\u5730\u5e94\u7528\u5230\u73b0\u6709\u7684\u7f51\u7edc\u4f53\u7cfb\u6216\u8005\u672a\u6765\u7684\u7f51\u7edc\u7ed3\u6784\u4e2d\u3002</li> </ul> <p>\u2003\u2003\u9996\u5148\u5047\u8bbe\u56fa\u5b9a\u6570\u91cf\u7684\u7279\u5f81\u901a\u9053\u6765\u8868\u793a\u6bcf\u4e00\u7c7b\uff0c\u56e0\u6b64\uff0c\u4f5c\u8005\u5e76\u4e0d\u662f\u5bf9\u6700\u7ec8\u7684\u7279\u5f81\u56fe\u65bd\u52a0\u7ea6\u675f\uff0c\u800c\u662f\u76f4\u63a5\u5bf9\u7279\u5f81\u901a\u9053\u65bd\u52a0\u7ea6\u675f\uff0c\u4f7f\u5f97\u540c\u4e00\u7c7b\u522b\u7684\u6240\u6709\u7279\u5f81\u901a\u9053\u5177\u6709\u5982\u4e0b\u4e24\u4e2a\u7279\u70b9\uff1a\u2460\u5c5e\u4e8e\u540c\u4e00\u7c7b\u522b\u7684\u6240\u6709\u7279\u5f81\u901a\u9053\u5177\u6709\u533a\u5206\u6027\uff0c\u5b83\u4eec\u5404\u81ea\u6709\u52a9\u4e8e\u5c06\u8be5\u7c7b\u522b\u4e0e\u5176\u4ed6\u7c7b\u522b\u533a\u5206\u5f00\u6765\uff1b\u2461\u5177\u6709\u4e92\u65a5\u6027\uff0c\u5373\u540c\u7c7b\u522b\u4e2d\u6bcf\u4e2a\u901a\u9053\u90fd\u5173\u6ce8\u4e0d\u540c\u7684\u5c40\u90e8\u533a\u57df\u3002\u56e0\u6b64\uff0c\u6700\u7ec8\u4f1a\u5f97\u5230\u4e00\u7ec4\u7c7b\u522b\u5bf9\u9f50(class-aligned)\u7684\u7279\u5f81\u56fe\uff0c\u6bcf\u4e2a\u901a\u9053\u5728\u76f8\u4e92\u4e0d\u540c\u7684\u5c40\u90e8\u533a\u57df\u4e0a\u5177\u533a\u522b\u3002\u5176\u4ed6\u65b9\u6cd5\u4e0eMC-Loss\u7684\u5bf9\u6bd4\u5982\u4e0b\u56fe\u6240\u793a\uff0cMC-Loss\u4e2d\uff0c\u84dd\u3001\u7ea2\u3001\u7eff\u5206\u522b\u8868\u793a\u4e0d\u540c\u7684\u7c7b\u522b\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003MC-Loss\u5177\u4f53\u6709\u4e24\u4e2a\u7ec4\u4ef6\u6784\u6210\uff0c\u5373\u5224\u522b\u7ec4\u4ef6(discriminality component)\u548c\u591a\u6837\u6027\u7ec4\u4ef6(diversity component)\uff1a</p> <p>\u2003\u2003\u9996\u5148\uff0c\u5224\u522b\u7ec4\u4ef6\u5f3a\u5236\u8ba9\u4e00\u4e2a\u7c7b\u522b\u4e2d\u6240\u6709\u7684\u7279\u5f81\u901a\u9053\u72ec\u7acb\u5730\u9884\u6d4b\u76f8\u5e94\u7684\u7c7b\u522b\u5206\u6570(\u7c7b\u522b\u6982\u7387)\uff0c\u5982\u4e0a\u56fe\u4e2d\uff0c\u8ba9\u4e09\u5f20\u7ea2\u8272\u7279\u5f81\u56fe\u6765\u9884\u6d4b\u53f3\u56fe\u4e2d\u9e1f\u7684\u7c7b\u522b\u5206\u6570\u3002\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u5f15\u5165\u4e00\u79cd\u65b0\u7684\u6ce8\u610f\u529b\u589e\u5f3a\u624b\u6bb5\uff0c\u901a\u8fc7\u968f\u673a\u5c4f\u853d\u7279\u5b9a\u767e\u5206\u6bd4\u7684\u901a\u9053\u6570\u91cf\uff0c\u8feb\u4f7f\u5269\u4f59\u7684\u901a\u9053\u5bf9\u7ed9\u5b9a\u7684\u7c7b\u522b\u5177\u6709\u533a\u5206\u6027\uff0c\u4e4b\u540e\u5e94\u7528\u8de8\u901a\u9053(cross-channel)\u6700\u5927\u6c60\u5316\u6765\u878d\u5408\u7279\u5f81\u901a\u9053\uff0c\u5e76\u4e14\u751f\u6210\u6700\u540e\u5177\u6709\u7c7b\u522b\u5bf9\u9f50\u6027\u8d28\u548c\u6700\u4f73\u533a\u5206\u6027\u7684\u7279\u5f81\u56fe\u3002</p> <p>\u2003\u2003\u867d\u7136\u7ecf\u8fc7\u4e0a\u8ff0\u5224\u522b\u7ec4\u4ef6\u7684\u4f18\u5316\uff0c\u6bcf\u4e2a\u7279\u5f81\u901a\u9053\u90fd\u53ea\u5173\u6ce8\u4e00\u4e2a\u7c7b\u522b\u4e0a\u7684\u5224\u522b\u533a\u57df\uff0c\u4f46\u662f\u4f1a\u5b58\u5728\u533a\u57df\u5197\u4f59\u7684\u73b0\u8c61\uff0c\u5373\u591a\u4e2a\u901a\u9053\u7684\u7279\u5f81\u56fe\u540c\u65f6\u5173\u6ce8\u4e00\u4e2a\u5224\u522b\u533a\u57df(\u5177\u4f53\u53ef\u89c1\u540e\u9762\u7684\u53ef\u89c6\u5316\u5206\u6790)\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u53c8\u8bbe\u8ba1\u4e86\u8be5\u635f\u5931\u7684\u7b2c\u4e8c\u4e2a\u7ec4\u4ef6\u2014\u2014\u591a\u6837\u6027\u7ec4\u4ef6\uff0c\u8be5\u7ec4\u4ef6\u53ef\u4ee5\u8ba9\u6bcf\u7ec4\u901a\u9053\u90fd\u5173\u6ce8\u4e0d\u540c\u7684\u5c40\u90e8\u533a\u57df\u3002\u53ef\u4ee5\u901a\u8fc7\u964d\u4f4e\u5c5e\u4e8e\u540c\u4e00\u7c7b\u522b\u901a\u9053\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u6765\u5b9e\u73b0\uff0c\u5373\u5148\u518d\u6b21\u5e94\u7528\u8de8\u901a\u9053\u6700\u5927\u6c60\u5316\uff0c\u4e4b\u540e\u518d\u6700\u5927\u5316\u7a7a\u95f4\u7279\u5f81\u7684\u6c42\u548c\u6570\u636e\u3002\u6700\u7ec8\uff0c\u53ef\u4ee5\u786e\u4fdd\u5c3d\u53ef\u80fd\u591a\u5730\u5224\u522b\u90e8\u4ef6(discriminative parts)\u5f97\u5230\u5173\u6ce8\u3002\u6ce8\u610f\uff0c\u5982\u679c\u6ca1\u6709\u5224\u522b\u7ec4\u4ef6\uff0c\u5219\u7f51\u7edc\u4e0d\u80fd\u5f88\u597d\u5730\u5b9a\u4f4d\u5224\u522b\u533a\u57df\uff0c\u6700\u7ec8\u4f1a\u5bfc\u81f4\u591a\u6837\u6027\u7ec4\u4ef6\u635f\u5931\u65e0\u6cd5\u6b63\u5e38\u6536\u655b\uff0c\u56e0\u6b64\uff0c\u5224\u522b\u7ec4\u4ef6\u7684\u5e94\u7528\u662f\u591a\u6837\u6027\u7ec4\u4ef6\u5de5\u4f5c\u7684\u524d\u63d0\u6761\u4ef6\u3002</p>"},{"location":"fine-grained/paper/MC-Loss1/#_3","title":"\u65b9\u6cd5","text":""},{"location":"fine-grained/paper/MC-Loss1/#_4","title":"\u7f51\u7edc\u7ed3\u6784","text":"<p>\u2003\u2003\u672c\u6587\u4e2d\uff0c\u4f5c\u8005\u4e3b\u8981\u63d0\u51fa\u4e86\u901a\u9053\u4ea4\u4e92\u635f\u5931\u51fd\u6570\u6765\u8ba9\u7f51\u7edc\u6709\u6548\u5730\u5173\u6ce8\u4e0d\u540c\u7684\u5224\u522b\u533a\u57df\uff0c\u8bad\u7ec3\u9636\u6bb5\u7684\u7f51\u7edc\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u7ed9\u5b9a\u4e00\u4e2a\u8f93\u5165\u56fe\u7247\uff0c\u9996\u5148\u4f20\u5165\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u63d0\u53d6\u7279\u5f81\uff0c\u5f97\u5230\u7279\u5f81\u56fe\\mathcal F\\in R^{N\\times W\\times H}\uff0c\u4e4b\u540e\u518d\u5c06\u7279\u5f81\u56fe\u5206\u6210c\u7ec4\uff0c\u5373N=c\\times \\xi\uff0c\u5176\u4e2dc\u548c\\xi\u5206\u522b\u8868\u793a\u7c7b\u522b\u6570\u91cf\u548c\u7528\u4e8e\u8868\u793a\u6bcf\u4e2a\u7c7b\u522b\u7684\u901a\u9053\u6570\u91cf\uff0c\\xi\u662f\u4e00\u4e2a\u6700\u597d\u5927\u4e8e2\u7684\u8d85\u53c2\u6570\uff0c\u7279\u5f81\u56fe\\mathcal F\u7b2cn\u4e2a\u901a\u9053\u7684\u7279\u5f81\u5411\u91cf\u8868\u793a\u4e3a\\mathcal F_n\\in R^{WH}, n=1,2,\\dots,N\uff0c\u6ce8\u610f\uff0c\u6b64\u65f6\u5c06\u6bcf\u4e2a\u901a\u9053\u7684\u4e8c\u7ef4\u77e9\u9635(\u5c3a\u5bf8\u4e3aW\\times H)\u8f6c\u6362\u6210\u4e86\u4e00\u7ef4\u5411\u91cf(\u957f\u5ea6\u4e3aWH)\u3002\u5bf9\u5e94\u4e8e\u7b2ci\u4e2a\u7c7b\u522b\u7684\u4e00\u7ec4\u7279\u5f81\u901a\u9053\u8868\u793a\u4e3aF_i\\in R^{\\xi\\times WH},i=0,1,\\dots,c-1\uff0c\u5177\u4f53\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ F_i=\\{\\mathcal F_{i\\times\\xi+1},\\mathcal F_{i\\times\\xi+2},\\dots,\\mathcal F_{i\\times\\xi+\\xi} \\} $$  \u2003\u2003\u968f\u540e\uff0c\u7279\u5f81\u56feF=\\{F_0,F_1,\\dots,F_{c-1}\\}\u8fdb\u5165\u5230\u7f51\u7edc\u7684\u4e24\u4e2a\u5206\u652f\uff0c\u5206\u522b\u5bf9\u5e94\u4e8e\u9488\u5bf9\u4e24\u4e2a\u4e0d\u540c\u76ee\u6807\u800c\u5236\u5b9a\u7684\u4e24\u4e2a\u5b50\u635f\u5931\u3002\u5982\u4e0a\u56fe\u6240\u793a\uff0c\u4ea4\u53c9\u71b5\u5206\u652f\u4e2d\uff0c\u7279\u5f81\u56fe\u5148\u7ecf\u8fc7\u5168\u8fde\u63a5\u5c42(FC)\uff0c\u4e4b\u540e\u518d\u8ba1\u7b97\u4f20\u7edf\u7684\u4ea4\u53c9\u71b5\u635f\u5931L_{CE}\uff0c\u8fd9\u91cc\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u7528\u4e8e\u9f13\u52b1\u7f51\u7edc\u63d0\u53d6\u4e3b\u8981\u96c6\u4e2d\u5728\u5168\u5c40\u5224\u522b\u533a\u57df(global discriminative regions)\u7684\u4fe1\u606f\u3002MC-Loss\u5206\u652f\u4e2d\uff0c\u901a\u8fc7\u8ba1\u7b97MC\u635f\u5931\u6765\u76d1\u7763\u7f51\u7edc\u7a81\u51fa\u4e0d\u540c\u7684\u5c40\u90e8\u5224\u522b\u533a\u57df(different local discriminative regions)\u3002\u8bad\u7ec3\u9636\u6bb5\uff0c\u603b\u635f\u5931\u4e3aMC\u635f\u5931\u4e58\u4ee5\u6743\u91cd\u7cfb\u6570\\mu\u518d\u4e0eCE\u635f\u5931\u76f8\u52a0\uff1a $$ Loss(F)=L_{CE}(F)+\\mu\\times L_{MC}(F) $$  \u5176\u4e2d\uff0cMC-Loss\u7531\u5224\u522b\u7ec4\u4ef6\u635f\u5931L_{dis}\u4e0e\u591a\u6837\u6027\u7ec4\u4ef6\u635f\u5931L_{div}\u52a0\u6743\u6c42\u548c\u5f97\u5230\uff1a $$ L_{MC}(F)=L_{dis}(F)-\\lambda\\times L_{div}(F) $$ <p></p> <p></p>"},{"location":"fine-grained/paper/MC-Loss1/#_5","title":"\u5224\u522b\u7ec4\u4ef6","text":"<p>\u2003\u2003\u5728\u4f5c\u8005\u6784\u5efa\u7684\u6846\u67b6\u4e2d\uff0c\u6bcf\u4e2a\u7c7b\u90fd\u7531\u4e00\u4e9b\u56fa\u5b9a\u6570\u91cf\u7684\u7279\u5f81\u901a\u9053\u8868\u793a\uff0c\u5224\u522b\u7ec4\u4ef6\u5c31\u662f\u8981\u5f3a\u8feb\u7279\u5f81\u901a\u9053\u5177\u6709\u7c7b\u522b\u5bf9\u9f50\u6027\u8d28\uff0c\u5e76\u4e14\u5bf9\u5e94\u4e8e\u7279\u5b9a\u7c7b\u522b\u7684\u6bcf\u4e2a\u7279\u5f81\u901a\u9053\u5e94\u8be5\u5177\u6709\u8db3\u591f\u7684\u5224\u522b\u6027\u3002\u56e0\u6b64\uff0c\u5224\u522b\u7ec4\u4ef6\u4e2d\u7684\u635f\u5931L_{dis}\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ L_{dis}(F)=L_{CE}(y,\\underbrace{\\frac{[e^{g(F_0)},e^{g(F_1)},\\dots,e^{g(F_{c-1})}]^T}{\\sum^{c-1}_{i=0}e^{g(F_i)}}}_\\text{Softmax}) $$  \u5176\u4e2d\uff0cg(\u00b7)\u8868\u793a\u4e3a\uff1a $$ g(F_i)=\\underbrace{\\frac{1}{WH}\\sum^{WH}_{k=1}}_\\text{GAP}\\underbrace{\\mathop{\\max}\\limits_{j=1,2,\\dots,\\xi}}_\\text{CCMP}\\underbrace{[M_i\\sdot F_{i,j,k}]}_\\text{CWA} $$  \u5176\u4e2d\uff0cGAP\u3001CCMP\u4e0eCWA\u4f9d\u6b21\u8868\u793a\u4e3a\u5168\u5c40\u5e73\u5747\u6c60\u5316\u3001\u8de8\u901a\u9053\u6700\u5927\u6c60\u5316\u4e0e\u5168\u901a\u9053\u6ce8\u610f\u529b(channel-wise attention)\u3002L_{CE}(\\sdot,\\sdot)\u4e3a\u56fe\u7247\u6807\u7b7ey\u4e0eGAP\u8f93\u51fa\u4e4b\u95f4\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u3002M_i=diag(Mask_i)\uff0c\u5176\u4e2dM_i\\in R^{\\xi}\u662f\u4e00\u4e2a\u968f\u673a\u5e26\u67090-1\u7684\u63a9\u7801\uff0c\u8be5\u63a9\u7801\u5171\u6709\\lfloor \\frac{\\xi}{2} \\rfloor\u4e2a0\uff0c\\lceil \\frac{\\xi}{2} \\rceil\u4e2a1\uff0cdiag(\\sdot)\u8868\u793a\u628a\u5143\u7d20\u653e\u5728\u5bf9\u89d2\u77e9\u9635\u7684\u4e3b\u5bf9\u89d2\u7ebf\u4e0a\uff0c\u5224\u522b\u7ec4\u4ef6\u5177\u4f53\u7ed3\u6784\u5982\u4e0b\u56fe\u5de6\u4fa7\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u20031)CWA\uff1a\u5f53\u5229\u7528\u4ea4\u53c9\u71b5\u635f\u5931\u53bb\u8bad\u7ec3\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u65f6\uff0c\u7279\u5f81\u901a\u9053\u53ea\u6709\u4e00\u90e8\u5206\u5b50\u96c6\u5305\u542b\u5224\u522b\u4fe1\u606f\uff0c\u5e76\u4e0d\u662f\u6240\u6709\u901a\u9053\u90fd\u5305\u542b\u5224\u522b\u4fe1\u606f\uff0c\u56e0\u6b64\u4f5c\u8005\u63d0\u51fa\u4e86\u5168\u901a\u9053\u6ce8\u610f\u529b\u64cd\u4f5c\uff0c\u4ece\u800c\u5f3a\u5236\u7f51\u7edc\u6bcf\u4e2a\u901a\u9053\u90fd\u540c\u7b49\u5730\u6355\u6349\u5224\u522b\u4fe1\u606f\uff0c\u4f7f\u5f97\u4e00\u7ec4\u901a\u9053\\xi\u4e2d\u6240\u6709\u7684\u7279\u5f81\u56fe\u90fd\u53ef\u4ee5\u6355\u6349\u76f8\u5e94\u7c7b\u522b\u7684\u5224\u522b\u4fe1\u606f\u3002\u4e3a\u6240\u6709\u7684\u7279\u5f81\u901a\u9053\u968f\u673a\u5206\u914d\u4e8c\u8fdb\u5236\u6743\u91cd\uff0c\u8fdb\u4e00\u6b65\u5728\u6bcf\u6b21\u8fed\u4ee3\u8fc7\u7a0b\u4e2d\uff0c\u4ece\u6bcf\u4e2a\u7279\u5f81\u7ec4F_i\u4e2d\u53ea\u9009\u62e9\u4e00\u90e8\u5206\u7279\u5f81\u901a\u9053\u8fdb\u5165\u540e\u7eed\u7684\u64cd\u4f5c\uff0c\u8fd9\u91cc\u7c7b\u4f3c\u4e8eDropOut\u64cd\u4f5c\uff0c\u5373\u968f\u673a\u4e22\u5f03\u4e00\u90e8\u5206\u7279\u5f81\u6570\u636e\uff0c\u4ece\u800c\u9f13\u52b1\u6240\u6709\u7684\u7279\u5f81\u56fe\u90fd\u5177\u6709\u6fc0\u6d3b\u4fe1\u606f\u3002\u6ce8\u610f\uff0cCWA\u4ec5\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4f7f\u7528\uff0c\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\u4e0d\u4f7f\u7528MC-Loss\u6a21\u5757\uff0c\u56e0\u6b64\u5728\u8bad\u7ec3\u4e0e\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\uff0c\u5206\u7c7b\u5c42\u5747\u63a5\u53d7\u76f8\u540c\u7684\u6570\u636e\u3002</p> <p>\u2003\u20032\uff09CCMP\uff1a\u8de8\u901a\u9053\u6700\u5927\u6c60\u5316\u88ab\u7528\u4e8e\u8ba1\u7b97\u5bf9\u5e94\u4e8e\u7279\u5b9a\u7c7b\u522b\u7684F_i\u4e2d\u6bcf\u4e2a\u7279\u5f81\u901a\u9053\u4e0a\u6bcf\u4e2a\u5143\u7d20\u7684\u6700\u5927\u54cd\u5e94\uff0c\u8fdb\u4e00\u6b65\u5f97\u5230\u4e0e\u7279\u5b9a\u7c7b\u522b\u4e00\u81f4\u7684\u4e00\u7ef4WH\u5927\u5c0f\u7684\u5411\u91cf\uff0c\u6bd4\u5982\uff1a\u5982\u679c\\xi=3\uff0c\u5373\u4e09\u4e2a\u901a\u9053\u8868\u793a\u4e00\u7c7b\uff0c\u5219\u7ecf\u8fc7CCMP\u4e4b\u540e\uff0c\u901a\u9053\u4e0a\u7684\u5143\u7d20\u4f1a\u6309\u987a\u5e8f\u9010\u4e2a\u904d\u5386\uff0c\u53d6\u76f8\u5e94\u7684\u4e09\u4e2a\u5143\u7d20\u4e2d\u7684\u6700\u5927\u503c\uff0c\u6700\u540e\u5f97\u5230\u4e00\u4e2a\u901a\u9053\u6570\u636e(\u4e0a\u9762\u7684\u5143\u7d20\u5747\u662f\u4e09\u4e2a\u901a\u9053\u4e2d\u76f8\u5e94\u4f4d\u7f6e\u7684\u6700\u5927\u503c)\u3002\u8de8\u901a\u9053\u5e73\u5747\u6c60\u5316(CCAP)\u662fCCMP\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5b83\u4ec5\u7528\u5e73\u5747\u6c60\u5316\u4ee3\u66ff\u6700\u5927\u6c60\u5316\uff0c\u4f46CCAP\u66f4\u503e\u5411\u4e8e\u5728\u6574\u4e2a\u7ec4\u4e2d\u5e73\u5747\u6bcf\u4e2a\u5143\u7d20\uff0c\u6709\u53ef\u80fd\u6291\u5236\u7279\u5f81\u901a\u9053\u7684\u5cf0\u503c\uff0c\u5373\u6291\u5236\u5c40\u90e8\u7684\u5173\u6ce8\u533a\u57df\u3002\u76f8\u53cd\uff0cCCMP\u53ef\u4ee5\u4fdd\u6301\u8fd9\u4e9b\u5173\u6ce8\uff0c\u5e76\u4e14\u8fdb\u4e00\u6b65\u53d1\u73b0\u5bf9\u7ec6\u7c92\u5ea6\u5206\u7c7b\u6709\u7528\u7684\u4fe1\u606f\u3002</p> <p>\u2003\u20033\uff09GAP\uff1a\u5168\u5c40\u5e73\u5747\u6c60\u5316\u7528\u4e8e\u8ba1\u7b97\u6bcf\u4e2a\u7279\u5f81\u901a\u9053\u7684\u5e73\u5747\u54cd\u5e94\uff0c\u6700\u540e\u8fd4\u56de\u7ef4\u5ea6\u5927\u5c0f\u4e3ac\u7684\u4e00\u7ef4\u5411\u91cf\uff0c\u5176\u4e2d\u6bcf\u4e2a\u5143\u7d20\u4ee3\u8868\u4e00\u4e2a\u5355\u72ec\u7684\u7c7b\u3002</p> <p> GAP\u7684\u8f93\u51fa\u518d\u7ecf\u8fc7softmax\u51fd\u6570\u5f97\u5230\u9884\u6d4b\u6982\u7387\uff0c\u6700\u540e\uff0c\u4f7f\u7528\u4ea4\u53c9\u71b5\u635f\u5931L_{CE}\u8ba1\u7b97\u771f\u5b9e\u6807\u7b7e\u548c\u9884\u6d4b\u6982\u7387\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u5f97\u5230\u5224\u522b\u7ec4\u4ef6\u7684\u635f\u5931L_{dis}\u3002</p>"},{"location":"fine-grained/paper/MC-Loss1/#_6","title":"\u591a\u6837\u6027\u7ec4\u4ef6","text":"<p>\u2003\u2003\u591a\u6837\u6027\u7ec4\u4ef6\u4e3b\u8981\u662f\u8861\u91cf\u7279\u5f81\u901a\u9053\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\uff0c\u7528\u4e8e\u8ba1\u7b97\u6240\u6709\u901a\u9053\u7684\u603b\u76f8\u4f3c\u5ea6\u3002\u4e0e\u5176\u4ed6\u5e38\u7528\u7684\u5ea6\u91cf\u65b9\u6cd5(\u5982\u6b27\u6c0f\u8ddd\u79bb\u3001K-L\u6563\u5ea6)\u76f8\u6bd4\uff0c\u4f5c\u8005\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u6052\u5b9a\u590d\u6742\u5ea6\u7684\u8ba1\u7b97\u4e2d\u8ba1\u7b97\u5f00\u9500\u66f4\u5c0f\u3002\u7ecf\u8fc7\u591a\u6837\u6027\u7ec4\u4ef6\u635f\u5931\u7684\u4f18\u5316\uff0c\u53ef\u4ee5\u4f7f\u5f97\u4e00\u7ec4\u7279\u5f81F_i\u4e2d\u7684\u7279\u5f81\u901a\u9053\u53d8\u5f97\u5f7c\u6b64\u4e0d\u540c\uff0c\u6362\u53e5\u8bdd\u8bf4\u5c31\u662f\u4e00\u4e2a\u7c7b\u7684\u4e0d\u540c\u7279\u5f81\u901a\u9053\u4f1a\u805a\u7126\u5173\u6ce8\u56fe\u50cf\u7684\u4e0d\u540c\u533a\u57df\uff0c\u800c\u4e0d\u662f\u6240\u6709\u901a\u9053\u90fd\u5173\u6ce8\u4e00\u4e2a\u6700\u5177\u6709\u5224\u522b\u6027\u7684\u533a\u57df\uff0c\u56e0\u6b64\u5b83\u901a\u8fc7\u4f7f\u6bcf\u4e2a\u7ec4\u7684\u7279\u5f81\u901a\u9053\u591a\u6837\u5316\u6765\u51cf\u5c11\u5197\u4f59\u4fe1\u606f\uff0c\u5e76\u4e14\u6709\u52a9\u4e8e\u53d1\u73b0\u5173\u4e8e\u56fe\u50cf\u4e2d\u4e0d\u540c\u7c7b\u522b\u7684\u4e0d\u540c\u5224\u522b\u533a\u57df\u3002\u8be5\u64cd\u4f5c\u4e5f\u79f0\u4e3a\u8de8\u901a\u9053\u53bb\u76f8\u5173(decorrelation)\u64cd\u4f5c\uff0c\u7528\u4e8e\u4ece\u540c\u4e00\u5f20\u56fe\u7247\u4e2d\u7684\u4e0d\u540c\u533a\u57df\u6355\u6349\u7ec6\u8282\u4fe1\u606f\u3002\u9996\u5148\u4f9d\u6b21\u7ecf\u8fc7softmax\u548cCCMP\uff0c\u4e4b\u540e\u518d\u8fdb\u884c\u7a7a\u95f4\u7ef4\u5ea6\u6c42\u548c\u6765\u6d4b\u91cf\u76f8\u4ea4\u5ea6\uff0c\u5177\u4f53\u7ed3\u6784\u5982\u4e0a\u56fe\u7684\u53f3\u4fa7\u5206\u652f\uff0c\u591a\u6837\u6027\u635f\u5931L_{div}\u53ef\u4ee5\u5229\u7528\u5982\u4e0b\u516c\u5f0f\u8ba1\u7b97\uff1a $$ L_{div}(F)=\\frac{1}{c}\\sum^{c-1}_{i=0}h(F_i) $$  \u5176\u4e2dh(\\sdot)\u7531\u5982\u4e0b\u516c\u5f0f\u5b9a\u4e49\uff1a $$ h(F_i)=\\sum^{WH}_{k=1}\\underbrace{\\mathop{\\max}\\limits_{j=1,2,\\dots,\\xi}}_\\text{CCMP}\\underbrace{[\\frac{e^{F_{i,j,k'}}}{\\sum^{WH}_{k'=1}e^{F_{i,j,k'}}}]}_\\text{Softmmax} $$  \u5176\u4e2d\uff0csoftmax\u51fd\u6570\u7528\u4e8e\u5f52\u4e00\u5316\u7a7a\u95f4\u7279\u5f81\u6570\u636e\uff0cCCMP\u7684\u4f5c\u7528\u4e8e\u5224\u522b\u7ec4\u4ef6\u4e2d\u76f8\u540c\u3002</p> <p>\u2003\u2003\u6781\u7aef\u60c5\u51b5\u4e0b\uff0c\u5f53\u4e00\u7ec4\u7279\u5f81\u56fe\u4e2d\u5173\u6ce8\u7684\u533a\u57df\u90fd\u4e0d\u540c\u65f6\uff0cL_{div}=\\xi\uff0c\u5982\u4e0b\u56fe\u5de6\u4fa7\u7684\u60c5\u51b5\uff1b\u5f53\u4e00\u7ec4\u7279\u5f81\u56fe\u4e2d\u5747\u5173\u6ce8\u540c\u4e00\u4e2a\u4f4d\u7f6e\u65f6\uff0cL_{div}=1\uff0c\u5982\u4e0b\u56fe\u53f3\u4fa7\u7684\u60c5\u51b5\u3002\u6240\u4ee5\u8981\u6700\u5927\u5316L_{div}\u7ed3\u679c\uff0c\u56e0\u6b64\u603b\u635f\u5931\u4e2dL_{div}\u7684\u7cfb\u6570\u662f\u8d1f\u6570\u3002</p> <p> <p></p> <p></p> <p>\u2003\u2003\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u591a\u6837\u6027\u7ec4\u4ef6\u635f\u5931\u4e0d\u80fd\u5355\u72ec\u7528\u4e8e\u4f18\u5316\u7f51\u7edc\uff0c\u4e0e\u5224\u522b\u7ec4\u4ef6\u635f\u5931\u76f8\u6bd4\uff0c\u5b83\u5145\u5f53\u7684\u662f\u4e00\u79cd\u6b63\u5219\u5316\u7684\u4f5c\u7528\uff0c\u7528\u4e8e\u8fdb\u4e00\u6b65\u7ea6\u675f\u7f51\u7edc\u6765\u5173\u6ce8\u56fe\u50cf\u4e0d\u540c\u7684\u5224\u522b\u533a\u57df\u3002</p>"},{"location":"fine-grained/paper/MC-Loss1/#_7","title":"\u5b9e\u9a8c","text":""},{"location":"fine-grained/paper/MC-Loss1/#_8","title":"\u53ef\u89c6\u5316\u5206\u6790","text":"<p>\u2003\u2003\u4e3a\u4e86\u8fdb\u4e00\u6b65\u8bf4\u660eMC-Loss\u7684\u6709\u6548\u6027\uff0c\u4f5c\u8005\u5229\u7528Grad-CAM\u6765\u5b9e\u73b0\u901a\u9053\u7684\u53ef\u89c6\u5316\uff0c\u5177\u4f53\u5bf9\u6bd4\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u57fa\u7ebf\u6a21\u578b\u4e3aVGG16\u5e76\u4e14\\xi=3\uff0c\u7b2c\u4e00\u884c\u53ef\u89c6\u5316\u4e86\u5229\u7528MC-Loss\u4f18\u5316\u7f51\u7edc\u5f97\u5230\u7684\u6a21\u578b\uff0c\u4ece\u56fe\u4e2d\u53ef\u4ee5\u770b\u51fa\u4e09\u79cd\u7279\u5f81\u56fe\u5747\u53ef\u4ee5\u5173\u6ce8\u9e1f\u7c7b\u7684\u4e0d\u540c\u5224\u522b\u533a\u57df\uff1b\u7b2c\u4e8c\u884c\u53ef\u89c6\u5316\u4e86\u53ea\u4f7f\u7528\u5224\u522b\u7ec4\u4ef6\u635f\u5931\u4f18\u5316\u7f51\u7edc\u5f97\u5230\u7684\u6a21\u578b\uff0c\u4ece\u4e2d\u53ef\u4ee5\u53d1\u73b0\u4e09\u5f20\u7279\u5f81\u56fe\u5b66\u4e60\u5230\u7684\u5224\u522b\u533a\u57df\u5f80\u5f80\u5f7c\u6b64\u90fd\u5f88\u76f8\u4f3c\uff0c\u5b58\u5728\u5f88\u5927\u7684\u533a\u57df\u5197\u4f59\u95ee\u9898\uff0c\u964d\u4f4e\u4e86\u7ec6\u7c92\u5ea6\u5206\u7c7b\u80fd\u529b\uff1b\u7b2c\u4e09\u884c\u53ef\u89c6\u5316\u4e86\u4e0d\u52a0CWA\u7ed3\u6784\u7684MC-Loss\u635f\u5931\uff0c\u4ece\u4e2d\u53ef\u4ee5\u53d1\u73b0\uff0c\u5982\u679c\u79fb\u9664CWA\uff0c\u5219\u4e09\u4e2a\u7279\u5f81\u901a\u9053\u53ea\u6709\u4e00\u4e2a\u4ee3\u8868\u4e86\u6b63\u786e\u7684\u5224\u522b\u533a\u57df\uff0c\u5176\u4ed6\u7684\u901a\u9053\u867d\u7136\u5f7c\u6b64\u4e0d\u540c\uff0c\u4f46\u4e0d\u4e00\u5b9a\u5bf9\u6700\u7ec8\u7684\u5206\u7c7b\u6709\u7528\u3002</p> <p> <p></p> <p></p>"},{"location":"fine-grained/paper/MC-Loss1/#_9","title":"\u7cbe\u5ea6\u5bf9\u6bd4","text":"<p> <p></p> <p></p>"},{"location":"fine-grained/paper/MC-Loss1/#_10","title":"\u603b\u7ed3","text":"<p>\u2003\u2003\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5b66\u4e60\u5c40\u90e8\u5224\u522b\u7279\u5f81\u7684\u635f\u5931\u51fd\u6570\u2014\u2014\u901a\u9053\u4ea4\u4e92\u635f\u5931(MC-Loss)\uff0c\u8be5\u635f\u5931\u53ef\u4ee5\u6709\u6548\u5730\u9a71\u52a8\u7279\u5f81\u901a\u9053\u66f4\u5177\u6709\u533a\u5206\u6027\uff0c\u5e76\u4e14\u8ba9\u5176\u805a\u7126\u4e8e\u5404\u4e2a\u533a\u57df\u3002\u66f4\u91cd\u8981\u7684\u662f\u5728\u4e0d\u5f15\u5165\u989d\u5916\u53c2\u6570\u7684\u524d\u63d0\u4e0b\uff0c\u53ef\u4ee5\u5c06\u8be5\u635f\u5931\u5e94\u7528\u5230\u4e0d\u540c\u7684\u7f51\u7edc\u67b6\u6784\u4e2d\uff0c\u63d0\u5347\u7f51\u7edc\u7684\u7ec6\u7c92\u5ea6\u7279\u5f81\u63d0\u53d6\u80fd\u529b\u3002</p> <p>\u6ce8\uff1a\u4ee5\u4e0a\u5185\u5bb9\u4ec5\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u89c2\u70b9\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u5927\u5bb6\u6279\u8bc4\u6307\u6b63\u3002</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e7412\u670831\u65e5</p>"},{"location":"fine-grained/paper/MGE-CNN1/","title":"\u7ec6\u7c92\u5ea6\uff1aMGE-CNN","text":""},{"location":"fine-grained/paper/MGE-CNN1/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aIEEE International Conference on Computer Vision 2019 (ICCV 2019)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content_ICCV_2019/papers/Zhang_Learning_a_Mixture_of_Granularity-Specific_Experts_for_Fine-Grained_Categorization_ICCV_2019_paper.pdf</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u7c7b(FGVC)</p>"},{"location":"fine-grained/paper/MGE-CNN1/#_2","title":"\u4e3b\u8981\u601d\u60f3","text":"<p>\u2003\u2003\u7531\u4e8e\u7ec6\u7c92\u5ea6\u6570\u636e\u96c6\u5177\u6709\u590d\u6742\u7684\u80cc\u666f\u548c\u591a\u76ee\u6807\u5c3a\u5ea6(multiple object scale)\uff0c\u56e0\u6b64\u7ec6\u7c92\u5ea6\u4efb\u52a1\u4e2d\u7684\u5bf9\u8c61\u901a\u5e38\u5177\u6709\u8f83\u5c0f\u7684\u7c7b\u95f4\u5dee\u5f02\u548c\u8f83\u5927\u7684\u7c7b\u5185\u5dee\u5f02\u3002\u672c\u6587\u4e2d\uff0c\u4f5c\u8005\u5229\u7528\u6df7\u5408\u4e13\u5bb6\u795e\u7ecf\u7f51\u7edc(mixture of neural network experts, ME)\u5c06\u7ec6\u7c92\u5ea6\u95ee\u9898\u7a7a\u95f4\u5212\u5206\u4e3a\u4e0d\u540c\u7684\u5b50\u95ee\u9898\u7a7a\u95f4\uff0c\u5e76\u4e14\u5728ME\u7684\u57fa\u7840\u4e0a\u505a\u4e86\u8fdb\u4e00\u6b65\u7684\u6539\u8fdb\uff0c\u63d0\u51fa\u4e86MGE-CNN\u7f51\u7edc\u6a21\u578b(Mixture of Granularity-Specific Experts convolutional neural network)\u3002\u57fa\u4e8eME\u7684\u7f51\u7edc\u901a\u5e38\u9075\u5faa\u201d\u5212\u5206\u201d(partition)\u548c\u201d\u5f81\u670d\u201d(conquer)\u4e24\u4e2a\u65b9\u6848\uff0c\u5176\u4e2d\u95ee\u9898\u7a7a\u95f4\u88ab\u5212\u4e3a\u5b50\u7a7a\u95f4\u3002\u4f20\u7edf\u7684ME\u65b9\u6cd5\u662f\u5c06\u6570\u636e\u96c6\u6309\u7279\u5f81\u5212\u5206\u4e3a\u4e0d\u540c\u7684\u5b50\u96c6\uff0c\u4e4b\u540e\u8ba9\u6a21\u578b\u5728\u4e0d\u540c\u7684\u5b50\u96c6\u4e0a\u5b66\u4e60\uff0c\u8fdb\u4e00\u6b65\u5f97\u5230\u64c5\u957f\u4e0d\u540c\u6570\u636e\u9886\u57df(\u6216\u8005\u64c5\u957f\u4e0d\u540c\u6570\u636e\u7279\u6027)\u7684\u4e13\u5bb6\u6a21\u578b(experts)\uff0c\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\u5c06\u6240\u6709\u4e13\u5bb6\u6a21\u578b\u7684\u9884\u6d4b\u8fdb\u884c\u52a0\u6743\u6c42\u548c\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u9884\u6d4b\u3002\u4f46\u7531\u4e8e\u7ec6\u7c92\u5ea6\u6570\u636e\u96c6\u6bd4\u8f83\u6709\u9650\uff0c\u56e0\u6b64\u4e0d\u80fd\u5c06\u6570\u636e\u96c6\u5212\u5206\u6210\u5b50\u96c6\uff0c\u5426\u5219\u6bcf\u4e2a\u4e13\u5bb6\u6a21\u578b\u5bb9\u6613\u51fa\u73b0\u8fc7\u62df\u5408\u7684\u95ee\u9898\u3002</p> <p>\u2003\u2003\u4e3a\u4e86\u514b\u670d\u4ece\u6709\u9650\u7684\u6570\u636e\u96c6\u4e2d\u5b66\u4e60\u4e0d\u540c\u4e13\u5bb6\u6a21\u578b\u7684\u56f0\u96be\uff0c\u4f5c\u8005\u8bbe\u8ba1\u4e86\u9010\u6e10\u589e\u5f3a(gradually enhancing)\u7684\u8bad\u7ec3\u7b56\u7565\uff0c\u5e76\u4e14\u5728\u4e13\u5bb6\u6a21\u578b\u4e4b\u95f4\u5f15\u5165KL\u6563\u5ea6\u7ea6\u675f\uff0c\u6765\u63d0\u9ad8\u4e13\u5bb6\u6a21\u578b\u4e4b\u95f4\u7684\u591a\u6837\u6027\u3002\u9010\u6e10\u589e\u5f3a\u7b56\u7565\u7684\u4e3b\u8981\u601d\u60f3\u5982\u4e0b\uff1a\u65b0\u5f97\u4e13\u5bb6\u6a21\u578b\u662f\u5b66\u4e60\u989d\u5916\u7684\u4fe1\u606f\u77e5\u8bc6\u6216\u8005\u4ece\u4ee5\u524d\u7684\u4e13\u5bb6\u90a3\u91cc\u83b7\u5f97\u7684\u5148\u9a8c\u4fe1\u606f\uff0c\u56e0\u6b64\u5bf9\u5f85\u95ee\u9898\u66f4\u52a0\u4e13\u4e1a\u3002\u56e0\u6b64\uff0c\u9996\u5148\u8981\u8003\u8651\u7684\u662f\u4e13\u5bb6\u5982\u4f55\u5c06\u4e00\u4e9b\u4efb\u52a1\u76f8\u5173\u7684\u77e5\u8bc6\u4f20\u9012\u7ed9\u4e0b\u4e00\u4e2a\u4e13\u5bb6\uff0c\u672c\u6587\u4e2d\u4f5c\u8005\u4ece\u5377\u79ef\u7f51\u7edc\u6a21\u5757\u4e2d\u9009\u62e9\u6ce8\u610f\u529b\u56fe\u4f5c\u4e3a\u77e5\u8bc6\u7684\u8f7d\u4f53\uff0c\u56e0\u4e3a\u5b83\u53ef\u4ee5\u8868\u660e\u795e\u7ecf\u7f51\u7edc\u5982\u4f55\u5c06\u56fe\u7247\u7684\u67d0\u4e9b\u533a\u57df\u4e0e\u4efb\u52a1\u52a0\u4ee5\u5173\u8054\u3002</p> <p>\u2003\u2003\u7136\u800c\uff0c\u7531\u4e8e\u7ec6\u7c92\u5ea6\u5206\u7c7b\u4efb\u52a1\u4e2d\u6570\u636e\u96c6\u6570\u91cf\u7684\u9650\u5236\uff0c\u6240\u6709\u7684\u4e13\u5bb6\u6a21\u578b\u503e\u5411\u4e8e\u4ea7\u751f\u4e00\u4e2a\u63a5\u8fd1\u5355\u70ed\u70b9(one-hot)\u7684\u5411\u91cf\uff0c\u5373\u6bcf\u4e2a\u4e13\u5bb6\u6240\u64c5\u957f\u7684\u9886\u57df\u90fd\u4e00\u6837\uff0c\u8fdb\u4e00\u6b65\u5bfc\u81f4\u6a21\u578b\u4e0d\u80fd\u5f88\u597d\u7684\u63cf\u8ff0\u6570\u636e\u5185\u5728\u7684\u7ed3\u6784\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u53c8\u5f15\u5165\u4e86\u4e00\u79cd\u60e9\u7f5a\u9879\uff0c\u5373\u60e9\u7f5a\u5404\u4e2a\u6982\u7387\u5206\u5e03\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\uff0c\u8fdb\u4e00\u6b65\u4fc3\u8fdb\u4e13\u5bb6\u6a21\u578b\u4e4b\u95f4\u7684\u591a\u6837\u6027\u3002\u9996\u5148\u6392\u9664\u9884\u6d4b\u7684\u6700\u5927\u503c\uff0c\u5e76\u4e14\u518d\u5c06\u5269\u4f59\u7684\u9884\u6d4b\u8fdb\u884c\u5f52\u4e00\u5316\u64cd\u4f5c\uff0c\u5f97\u5230\u65b0\u7684\u9884\u6d4b\u5206\u5e03\u53ef\u4ee5\u5f88\u597d\u5730\u53cd\u5e94\u6a21\u578b\u5bf9\u6570\u636e\u7684\u63cf\u8ff0(\u4f8b\u5982\u6570\u636e\u548c\u7c7b\u522b\u4e4b\u95f4\u7684\u5173\u7cfb)\u3002\u800c\u8861\u91cf\u4e24\u4e2a\u6982\u7387\u5206\u5e03\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\u6700\u5e38\u7528\u7684\u5c31\u662f\u8ba1\u7b97KL\u6563\u5ea6\uff0cKL\u6563\u5ea6\u8d8a\u5c0f\uff0c\u4e24\u4e2a\u6982\u7387\u5206\u5e03\u8d8a\u76f8\u4f3c\uff0c\u56e0\u6b64\uff0c\u901a\u8fc7\u6700\u5927\u5316\u4e24\u4e2a\u4e13\u5bb6\u6a21\u578b\u9884\u6d4b\u6982\u7387\u5206\u5e03\u4e4b\u95f4\u7684KL\u6563\u5ea6\uff0c\u53ef\u4ee5\u5f88\u597d\u5730\u9f13\u52b1\u4e24\u4e2a\u6a21\u578b\u5bf9\u6570\u636e\u5177\u6709\u4e0d\u540c\u7684\u63cf\u8ff0\u3002\u7efc\u4e0a\u6240\u8ff0\uff0c\u5229\u7528\u9010\u6b65\u589e\u5f3a\u7684\u8bad\u7ec3\u7b56\u7565\u548cKL\u6563\u5ea6\u60e9\u7f5a\u9879\u8bad\u7ec3\u6a21\u578b\uff0c\u53ef\u4ee5\u4ece\u6709\u9650\u7684\u6570\u636e\u96c6\u4e2d\u5b66\u4e60\u591a\u4e2a\u591a\u6837\u5316\u7684\u4e13\u5bb6\u6a21\u578b\uff0c\u6709\u5229\u4e8e\u63d0\u9ad8\u7ec6\u7c92\u5ea6\u5206\u7c7b\u4efb\u52a1\u7684\u6027\u80fd\u3002</p> <p>\u2003\u2003\u4e0b\u56fe\u662fMGE-CNN\u7684\u6982\u8ff0\u6846\u67b6\uff1a</p> <p> <p></p> <p></p> <p>\u7f51\u7edc\u4e3b\u8981\u7531\u591a\u4e2a\u4e13\u5bb6\u6a21\u578b\u548c\u4e00\u4e2a\u95e8\u63a7\u7f51\u7edc\u6784\u6210\uff0c\u6bcf\u4e2a\u4e13\u5bb6\u6a21\u578b\u5b66\u4e60\u524d\u4e00\u4e2a\u4e13\u5bb6\u6a21\u578b\u7684\u5148\u9a8c\u77e5\u8bc6\u3002\u95e8\u63a7\u7f51\u7edc\u7528\u4e8e\u51b3\u5b9a\u6bcf\u4e2a\u4e13\u5bb6\u6a21\u578b\u5bf9\u6700\u7ec8\u9884\u6d4b\u7684\u8d21\u732e\u5ea6\uff0c\u751f\u6210\u6743\u91cdg_i\uff0c\u6700\u540e\u6240\u6709\u7684\u4e13\u5bb6\u6a21\u578b\u4e0e\u76f8\u5e94\u7684\u6743\u91cd\u76f8\u4e58\u518d\u6c42\u548c\u5f97\u5230\u6700\u7ec8\u7684\u9884\u6d4b\u7ed3\u679c\u3002</p>"},{"location":"fine-grained/paper/MGE-CNN1/#_3","title":"\u65b9\u6cd5","text":""},{"location":"fine-grained/paper/MGE-CNN1/#_4","title":"\u7f51\u7edc\u7ed3\u6784","text":"<p>\u2003\u2003\u4f5c\u8005\u8bbe\u8ba1\u4e13\u5bb6\u6a21\u578b\u9075\u5faa\u4e24\u4e2a\u539f\u5219\uff1a\u2460\u4e3a\u4e86\u66f4\u597d\u5730\u6267\u884c\u7ec6\u7c92\u5ea6\u8bc6\u522b\u4efb\u52a1\uff0c\u9700\u8981\u5b66\u4e60\u66f4\u597d\u7684\u7279\u5f81\u8868\u793a(representation)\uff0c\u800c\u8fd9\u79cd\u8868\u793a\u9700\u8981\u5305\u542b\u66f4\u591a\u7684\u7ec6\u8282\u4fe1\u606f\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u63d0\u53d6\u4e86\u5927\u96f6\u4ef6\u7279\u5f81(large-part features)\u548c\u5c0f\u96f6\u4ef6\u7279\u5f81(small-part features)\uff0c\u6bcf\u4e2a\u4e13\u5bb6\u6a21\u578b\u5747\u57fa\u4e8e\u8fd9\u4e24\u4e2a\u7279\u5f81\u7684\u7ec4\u5408\u505a\u51b3\u5b9a\uff1b\u2461\u4e00\u4e2a\u4e13\u5bb6\u6a21\u578b\u53ef\u4ee5\u4e3a\u4e0b\u4e00\u4e2a\u4e13\u5bb6\u6a21\u578b\u5efa\u7acb\u63d0\u4f9b\u5148\u9a8c\u77e5\u8bc6\uff0c\u6240\u6709\u7684\u4e13\u5bb6\u6a21\u578b\u90fd\u53ef\u4ee5\u505a\u51fa\u591a\u6837\u5316\u7684\u9884\u6d4b\u3002</p> <p>\u2003\u2003MGE-CNN\u5177\u4f53\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u7f51\u7edc\u4e3b\u8981\u7531\u591a\u4e2a\u4e13\u5bb6\u5b50\u7f51\u7edc\u6784\u6210\uff0c\u6bcf\u4e2a\u5b50\u7f51\u7edc\u90fd\u7531\u4e00\u4e2a\u7279\u5f81\u8868\u793a\u5b66\u4e60\u7ec4\u4ef6(feature representation learning)\u548c\u533a\u57df\u6ce8\u610f\u529b\u63d0\u53d6\u7ec4\u4ef6\u6784\u6210\u3002\u7b2c\u4e00\u4e2a\u7ec4\u4ef6\u4f7f\u7528\u4e24\u4e2a\u4e0d\u540c\u7684\u5377\u79ef\u6a21\u5757(Conv Block)\uff0c\u5206\u522b\u5728\u4e24\u4e2a\u5377\u79ef\u5757\u4e0a\u4f7f\u7528\u4e0d\u540c\u7684\u6c60\u5316\u65b9\u6cd5\u6765\u63d0\u53d6\u4e0d\u540c\u7c7b\u578b\u7684\u7279\u5f81\uff0c\u4e4b\u540e\u518d\u5c06\u5b83\u4eec\u8fde\u63a5\u8d77\u6765\uff0c\u5f62\u6210\u6574\u4f53\u8868\u793a\u3002\u7b2c\u4e8c\u4e2a\u7ec4\u4ef6\u662f\u57fa\u4e8e\u68af\u5ea6\u7684\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u7528\u4e8e\u63d0\u53d6\u6ce8\u610f\u529b\u533a\u57df\uff0c\u5e76\u5c06\u8bad\u7ec3\u6570\u636e\u8f6c\u6362\u4e3a\u65b0\u7684\u6ce8\u610f\u533a\u57df\uff0c\u4e4b\u540e\u7528\u4e8e\u540e\u7eed\u4e13\u5bb6\u4f7f\u7528\u3002</p> <p> <p></p> <p></p>"},{"location":"fine-grained/paper/MGE-CNN1/#_5","title":"\u7528\u4e8e\u7ec6\u7c92\u5ea6\u5206\u7c7b\u7684\u4e13\u5bb6\u6a21\u578b","text":"<p>\u2003\u2003\u5bf9\u4e8e\u4e13\u5bb6\u6a21\u578bE_t\uff0c\u4f7f\u7528\u5e26\u6709\u5168\u5c40\u5e73\u5747\u6c60\u5316\u7684\u5377\u79ef\u6a21\u5757\u6765\u63d0\u53d6\u5927\u96f6\u4ef6\u533a\u57df\u7279\u5f81f_g^t\uff0c\u540c\u65f6\uff0c\u4f7f\u7528\u5e26\u6709\u5168\u5c40\u6700\u5927\u6c60\u5316\u7684\u5377\u79ef\u6a21\u5757\u6765\u63d0\u53d6\u5c0f\u96f6\u4ef6\u533a\u57df\u7279\u5f81f^t_l\u3002\u901a\u8fc7\u5728\u4e24\u4e2a\u72ec\u7acb\u7684\u5377\u79ef\u6a21\u5757\u4e0a\u5e94\u7528\u4e0d\u540c\u7684\u5168\u5c40\u6c60\u5316\u65b9\u6cd5\uff0c\u7f51\u7edc\u53ef\u4ee5\u4ece\u540c\u4e00\u5f20\u56fe\u7247\u4e2d\u5b66\u5230\u4e0d\u540c\u7c7b\u578b\u7684\u7279\u5f81\u3002\u4e13\u5bb6\u7684\u7edf\u4e00\u7279\u5f81f^t\u53ef\u4ee5\u901a\u8fc7\u5408\u5e76\u4e0a\u8ff0\u4e24\u4e2a\u6807\u51c6\u5316\u7279\u5f81(f_g^t\u4e0ef_l^t\u5206\u522b\u7ecf\u8fc7\u6807\u51c6\u5316)\u6765\u5f97\u5230\uff1a $$ f^t=(\\frac{f^t_g}{||f^t_g||_2},\\frac{f^t_l}{||f^t_l||_2}) $$  \u2003\u2003\u4e13\u5bb6\u6a21\u578b\u7684\u5206\u7c7b\u635f\u5931\u7531\u4e24\u4e2a\u8f85\u52a9\u635f\u5931(\u5927\u96f6\u4ef6\u7279\u5f81\u4ee5\u53ca\u5c0f\u96f6\u4ef6\u7279\u5f81\u7684\u9884\u6d4b\u635f\u5931)\u4ee5\u53ca\u4e00\u4e2a\u51b3\u7b56\u635f\u5931\u6784\u6210\uff1a $$ L_{cls}^t=-\\frac{1}{N}\\sum_{\\theta_j\\in\\{\\theta^t_g,\\theta^t_l,\\theta^t_c\\}}\\sum_{i=1}^Ny_ilog(f(x^t_i,\\theta_j)) $$  \u5176\u4e2dx_i^t\u8868\u793a\u4e13\u5bb6\u6a21\u578bE_t\u7684\u8f93\u5165\uff0cy_i\u4e3a\u8f93\u5165\u7684\u6807\u7b7e\uff0c\\theta^t_g,\\theta^t_l,\\theta^t_c\u5206\u522b\u8868\u793a\u5927\u533a\u57df\u5206\u652f(\u5e26\u6709GAP\u7684\u5206\u652f)\u3001\u5c0f\u533a\u57df\u5206\u652f(\u5e26\u6709GMP\u7684\u5206\u652f)\u4ee5\u53ca\u8054\u5408\u5206\u652f\u7684\u53c2\u6570\u3002N\u4e3a\u6570\u636e\u603b\u91cf\uff0c\u4e09\u4e2a\u5206\u652f\u7684\u635f\u5931\u5747\u7531\u4ea4\u53c9\u71b5\u635f\u5931\u8ba1\u7b97\u5f97\u5230\u3002</p> <p>\u2003\u2003\u540e\u4e00\u4e13\u5bb6\u4ece\u5177\u6709\u6765\u81ea\u524d\u4e00\u4f4d\u4e13\u5bb6\u5148\u9a8c\u4fe1\u606f\u7684\u6570\u636e\u4e2d\u5b66\u4e60\uff0c\u5148\u9a8c\u77e5\u8bc6\u901a\u8fc7\u57fa\u4e8e\u68af\u5ea6\u7684\u6ce8\u610f\u529b\u6a21\u5757\u4f20\u9012\u7ed9\u540e\u4e00\u4e2a\u4e13\u5bb6\u6a21\u578b\u3002\u4f5c\u8005\u5229\u7528Grad-CAM(\u8bba\u6587\u94fe\u63a5)\u6765\u6784\u9020\u6ce8\u610f\u529b\u56fe\uff0cGrad-CAM\u5229\u7528\u5377\u79ef\u5c42\u7684\u68af\u5ea6\u4fe1\u606f\u53bb\u7406\u89e3\u6bcf\u4e2a\u795e\u7ecf\u5143\u5bf9\u4e8e\u51b3\u7b56\u7684\u91cd\u8981\u6027\u3002\u4e3a\u4e86\u83b7\u5f97\u4efb\u4f55\u7c7b\u522b\u4e3ac\uff0c\u5bbd\u4e3au\uff0c\u9ad8\u4e3av\u7684\u7c7b\u7279\u5b9a\u6ce8\u610f\u529b\u56fe\uff0c\u9996\u5148\u9700\u8981\u8ba1\u7b97c\u7c7b\u7684\u68af\u5ea6\uff0c\u5047\u8bbey^c\u4e3a\u7c7b\u522bc\u7684\u9884\u6d4b\u503c\uff0cA^k\u4e3a\u5377\u79ef\u5c42\u7684\u4e2d\u901a\u9053\u4e3ak\u7684\u7279\u5f81\u56fe\uff0c\u5219\u68af\u5ea6\u53ef\u4ee5\u8868\u793a\u4e3a\\frac{\\partial y^c}{\\partial A^k_{ij}}\u3002\u8fd9\u4e9b\u56de\u6d41(flow back)\u7684\u68af\u5ea6\u88ab\u5168\u5c40\u5e73\u5747\u6c60\u5316\u6c47\u96c6\uff0c\u4ece\u800c\u83b7\u5f97\u795e\u7ecf\u5143\u7684\u91cd\u8981\u6027\\alpha^c_k\uff1a $$ \\alpha^c_k=\\frac{1}{Z}\\sum^u_{i=1}\\sum^v_{j=1}\\frac{\\partial y^c}{\\partial A^k_{ij}} $$ </p> <p>\u5176\u4e2d\uff0c\u6743\u91cd\\alpha^c_k\u8868\u793a\u901a\u8fc7\u5c06\u6fc0\u6d3b\u5377\u79ef\u5c42A\u4e0b\u6e38\u7684\u7f51\u7edc\u90e8\u5206\u7ebf\u6027\u5316\uff0c\u6765\u5f97\u5230\u7279\u5f81\u56feA\u4e2d\u7b2ck\u4e2a\u901a\u9053\u5bf9\u76ee\u6807\u7c7b\u522bc\u9884\u6d4b\u7684\u91cd\u8981\u6027\uff0cZ\u4e3a\u4e00\u4e2a\u901a\u9053\u4e2d\u795e\u7ecf\u5143\u7684\u6570\u91cf(u\\times v)\u3002</p> <p>\u2003\u2003\u5728\u5168\u5c40\u6c47\u805a\u4e4b\u524d\uff0c\u5bf9\u68af\u5ea6\u5e94\u7528ReLU\u64cd\u4f5c\uff0c\u53ea\u4fdd\u7559\u68af\u5ea6\u4e3a\u6b63\u7684\u90e8\u5206\uff0c\u8fdb\u4e00\u6b65\u5f97\u5230\u6700\u7ec8\u7684\u901a\u9053\u91cd\u8981\u6027\uff1a $$ \\beta^c_k=\\frac{1}{Z}\\sum^u_{i=1}\\sum^v_{j=1}ReLU(\\frac{\\partial y^c}{\\partial A^k_{ij}}) $$  \u2003\u2003\u7c7b\u522b\u6fc0\u6d3b\u56fe\u53ef\u4ee5\u901a\u8fc7\u5bf9\u6765\u81ea\u5377\u79ef\u5c42\u7684\u8de8\u901a\u9053\u524d\u5411\u6fc0\u6d3b\u56fe\u8fdb\u884c\u52a0\u6743\u6c42\u548c\u6765\u6784\u5efa(\u4ee5\u91cd\u8981\u6027\\beta^c_k\u4e3a\u6743\u91cd)\u3002\u8bad\u7ec3\u9636\u6bb5\u4f7f\u7528\u5730\u9762\u771f\u5b9e\u6807\u7b7e\u7c7b\u522b(c\u4e3a\u6807\u7b7e\u7c7b\u522b)\uff0c\u6d4b\u8bd5\u9636\u6bb5\u4f7f\u7528\u9884\u6d4b\u7c7b\u522b\uff0c\u56e0\u6b64\uff0c\u4e13\u5bb6\u6a21\u578bE_t\u6700\u7ec8\u7684\u6ce8\u610f\u529b\u6fc0\u6d3b\u56fe\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ S^c=\\sum^K_{k=1}\\beta^c_kA^k $$  \u2003\u2003\u5f97\u5230\u6ce8\u610f\u529b\u56fe\u4e4b\u540e\uff0c\u518d\u901a\u8fc7\u5c06\u503c\u7f29\u653e\u52300\u52301\u4e4b\u95f4\u6765\u8fdb\u4e00\u6b65\u5f52\u4e00\u5316\u5b83\uff0c\u4e4b\u540e\u53ef\u4ee5\u5229\u7528\u4e00\u4e2a\u9608\u503c\u6765\u4f30\u8ba1\u8fb9\u754c\u6846\uff0c\u4ee5\u5b9a\u4f4d\u56fe\u50cf\u4e2d\u7684\u91cd\u8981\u533a\u57df\uff1a $$ S^c_{norm}=\\frac{S^c-min(S^c)}{max(S^c)-min(S^c)} $$  \u2003\u2003\u901a\u8fc7\u5c06\u6ce8\u610f\u529b\u56fe\u4e0a\u91c7\u6837\u5230\u8f93\u5165\u56fe\u50cf\u7684\u5c3a\u5bf8\u5927\u5c0f\uff0c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u8bc6\u522b\u4e0e\u7c7b\u522b\u6807\u7b7e\u6700\u76f8\u5173\u7684\u56fe\u50cf\u533a\u57df\u3002\u5728\u8bad\u7ec3\u9636\u6bb5\uff0c\u901a\u8fc7\u53cd\u5411\u4f20\u64ad\u6807\u7b7e\u7c7b\u522b\u7684\u9884\u6d4b\u6765\u8ba1\u7b97\u6ce8\u610f\u529b\u56fe\uff0c\u4f46\u5728\u6d4b\u8bd5\u9636\u6bb5\u65e0\u6cd5\u5f97\u5230\u56fe\u50cf\u6807\u7b7e\uff0c\u56e0\u6b64\u4f7f\u7528\u9884\u6d4b\u6807\u7b7e\u6765\u8ba1\u7b97\u6ce8\u610f\u529b\u56fe\u3002</p> <p>\u2003\u2003\u7ed9\u5b9a\u6ce8\u610f\u529b\u56fe\uff0c\u53ef\u4ee5\u901a\u8fc7\u7c7b\u4f3c\u5f31\u76d1\u7763\u76ee\u6807\u5b9a\u4f4d\u7684\u65b9\u6cd5\u6765\u4e3a\u4e0b\u4e00\u4e2a\u4e13\u5bb6\u6a21\u578b\u6784\u9020\u8f93\u5165\u3002\u9996\u5148\uff0c\u5728\u6ce8\u610f\u529b\u56fe\u4e2d\u5206\u5272\u51fa\u6570\u503c\u5927\u4e8e0.2\u7684\u533a\u57df(\u8fd9\u91cc\u6ce8\u610f\u529b\u56fe\u5df2\u7ecf\u88ab\u89c4\u6574\u81f30\u52301\u4e4b\u95f4)\uff0c\u7136\u540e\u518d\u53d6\u8986\u76d6\u8986\u76d6\u6700\u5927\u8fde\u901a\u533a\u57df\u7684\u5305\u56f4\u76d2(bounding box)\uff0c\u4e4b\u540e\u5c06\u5305\u56f4\u76d2\u7684\u5750\u6807\u91cd\u65b0\u6620\u5c04\u5230\u539f\u59cb\u56fe\u50cf\uff0c\u5148\u88c1\u526a\u76f8\u5e94\u7684\u533a\u57df\uff0c\u518d\u5c06\u6240\u5f97\u7684\u533a\u57df\u653e\u5927\uff0c\u653e\u5927\u5230\u539f\u59cb\u56fe\u5f62\u7684\u5927\u5c0f\uff0c\u4e0b\u56fe\u662f\u6ce8\u610f\u529b\u6a21\u5757\u7684\u7ed3\u6784\u6d41\u7a0b\uff0c\u5176\u4e2d\u767d\u8272\u5706\u5708\u8868\u793a\u88c1\u526a\u5f53\u524d\u4e13\u5bb6\u7684\u8f93\u5165\uff0c\u5e76\u4e14\u653e\u5927\u5230\u539f\u59cb\u5927\u5c0f\u518d\u4f20\u5165\u4e0b\u4e00\u4e2a\u4e13\u5bb6\u6a21\u578b\uff1a</p> <p> <p></p> <p></p>"},{"location":"fine-grained/paper/MGE-CNN1/#kl","title":"\u57fa\u4e8eKL\u6563\u5ea6\u7684\u60e9\u7f5a\u9879","text":"<p>\u2003\u2003\u4e3a\u4e86\u4fc3\u8fdb\u4e13\u5bb6\u6a21\u578b\u4e4b\u95f4\u7684\u591a\u6837\u6027\uff0c\u4f5c\u8005\u5f15\u5165\u4e86\u57fa\u4e8eKL\u6563\u5ea6\u7684\u60e9\u7f5a\u9879\uff0c\u6765\u60e9\u7f5a\u5177\u6709\u76f8\u540c\u6982\u7387\u5206\u5e03\u7684\u4e13\u5bb6\u6a21\u578b\u3002KL\u6563\u5ea6\u662f\u7528\u4e8e\u8861\u91cf\u4e0d\u540c\u6982\u7387\u5206\u5e03\u4e4b\u95f4\u5dee\u5f02\u6027\u7684\u65b9\u6cd5\uff0c\u4e24\u4e2a\u6982\u7387\u5206\u5e03\u5dee\u5f02\u8d8a\u5927\uff0cKL\u6563\u5ea6\u5c31\u8d8a\u5927\uff0cKL\u6563\u5ea6\u516c\u5f0f\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ \\begin{aligned} D_{KL}(P^t||P^{t+1})&amp;=\\sum_{x\\in X^t}P^t(x)log(\\frac{P^t(x)}{P^{t+1}(x)})\\\\ &amp;=\\sum_{x\\in X^t}(P^t(x)log(P^t(x))-P^t(x)log(P^{t+1}(x))) \\end{aligned} $$  \u5176\u4e2dP^t\u548cP^{t+1}\u5206\u522b\u8868\u793a\u4e24\u4e2a\u5f85\u6bd4\u8f83\u7684\u6982\u7387\u5206\u5e03\u3002</p> <p>\u2003\u2003\u7531\u4e8e\u53d7\u5230\u6570\u636e\u96c6\u7684\u9650\u5236\uff0c\u6bcf\u4e2a\u4e13\u5bb6\u6a21\u578b\u503e\u5411\u4e8e\u4ea7\u751f\u975e\u5e38\u81ea\u4fe1\u7684\u9884\u6d4b\uff0c\u5373\u4ea7\u751f\u4e00\u4e2a\u63a5\u8fd1\u5355\u70ed\u70b9\u7684\u5411\u91cf\u3002\u8fd9\u79cd\u7ed3\u679c\u4e0d\u80fd\u53cd\u6620\u6a21\u578b\u5bf9\u6570\u636e\u5185\u5728\u7ed3\u6784\u7684\u63cf\u8ff0\uff0c\u56e0\u6b64\u4f5c\u8005\u79fb\u9664\u4e86\u9884\u6d4b\u7684\u6700\u5927\u503c(\u76f8\u5f53\u4e8e\u628a\u9884\u6d4b\u7c7b\u522b\u7684\u503c\u79fb\u9664\u4e86)\uff0c\u5e76\u4e14\u5c06\u8be5\u7ed3\u679c\u89c4\u8303\u5316\u4e3a\u65b0\u7684\u5206\u5e03\uff0c\u5373\u91cd\u65b0\u505a\u4e00\u6b21\u5f52\u4e00\u5316\u64cd\u4f5c\uff0c\u65b0\u5f97\u5230\u7684\u6982\u7387\u5206\u5e03\u53ef\u4ee5\u66f4\u597d\u5730\u53cd\u5e94\u6a21\u578b\u5bf9\u6570\u636e\u7684\u63cf\u8ff0(\u5982\u6570\u636e\u548c\u7c7b\u522b\u4e4b\u95f4\u7684\u5173\u7cfb)\uff0c\u8fdb\u4e00\u6b65\u6700\u5927\u5316\u4e24\u4e2a\u8fd9\u79cd\u5206\u5e03\u7684KL\u6563\u5ea6\uff0c\u5373\u9f13\u52b1\u4e24\u4e2a\u4e13\u5bb6\u6a21\u578b\u5bf9\u6570\u636e\u5177\u6709\u4e0d\u540c\u7684\u63cf\u8ff0\u3002\u5177\u4f53\u7684\u6765\u8bf4\uff0c\u4f5c\u8005\u901a\u8fc7\u4e8c\u8fdb\u5236\u63a9\u7801\u6765\u6539\u53d8\u539f\u59cb\u5206\u5e03\uff1a $$ \\begin{aligned} M^t_i=\\left\\{ \\begin{matrix} 0,&amp;i=y^c\\\\ 1,&amp;otherwise \\end{matrix} \\right. \\end{aligned} $$  \u5176\u4e2di\u8868\u793aM\u4e2d\u5143\u7d20\u7684\u7d22\u5f15\uff0cM\u4e3a\u63a9\u7801\u5411\u91cf\uff0c\u5176\u4e2d\u91cc\u9762\u6bcf\u4e2a\u5143\u7d20\u5bf9\u5e94\u4e8e\u4e13\u5bb6\u6a21\u578bE_t\u7684\u6982\u7387P^t\u3002\u5b83\u4e5f\u53ef\u4ee5\u88ab\u89c6\u4e3a\u4e00\u4e2a\u95e8\u63a7\u64cd\u4f5c\u6765\u9009\u62e9\u5206\u5e03\u8fdb\u884c\u4f18\u5316\u3002</p> <p>\u2003\u2003\u56e0\u6b64\uff0c\u57fa\u4e8eKL\u6563\u5ea6\u7684\u7ea6\u675f\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ D^t_{KL}=\\langle M,D_{KL}(P^t||P^{t+1}) \\rangle $$  \u5176\u4e2d\uff0cP^t\u8868\u793a\u4e13\u5bb6\u6a21\u578bE_t\u5728\u6240\u6709\u7c7b\u522b\u4e0a\u7684\u9884\u6d4b\u6982\u7387\u5206\u5e03\uff0c\u57fa\u4e8eKL\u6563\u5ea6\u7ea6\u675f\u7684\u635f\u5931\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ L^t_{KL}=exp(-D^t_{KL}) $$ </p>"},{"location":"fine-grained/paper/MGE-CNN1/#_6","title":"\u6df7\u5408\u4e13\u5bb6\u6a21\u578b","text":"<p>\u2003\u2003\u7f51\u7edc\u6700\u7ec8\u7684\u4f18\u5316\u76ee\u6807(\u5373\u635f\u5931\u51fd\u6570)\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ L=\\sum^T_{t=1}L^t_{cls}+\\sum^T_{t=2}L_{KL}^t+L_{gate} $$  \u2003\u2003\u4f18\u5316\u76ee\u6807\u4e2d\u7684\u7b2c\u4e00\u9879\u8868\u793a\u6bcf\u4e2a\u4e13\u5bb6\u6a21\u578b\u5728\u76f8\u5e94\u5168\u5c3a\u5bf8\u6570\u636e\u96c6\u4e0a\u7684\u5206\u7c7b\u635f\u5931\uff0c\u6bcf\u4e2a\u6570\u636e\u96c6\u90fd\u662f\u5229\u7528\u524d\u4e00\u4e2a\u4e13\u5bb6\u6a21\u578b\u7684\u6ce8\u610f\u529b\u77e5\u8bc6\u6765\u8f6c\u6362\u6570\u636e\u800c\u6784\u5efa\u7684\u3002\u7b2c\u4e8c\u9879\u4e3a\u57fa\u4e8eKL\u6563\u5ea6\u7684\u60e9\u7f5a\u9879\uff0c\u7528\u4e8e\u9f13\u52b1\u4e13\u5bb6\u6a21\u578b\u4ea7\u751f\u591a\u6837\u5316\u7684\u6982\u7387\u5206\u5e03\u3002L_{gate}\u4e3a\u5b66\u4e60\u95e8\u63a7\u7f51\u7edc(gating network)\u7684\u635f\u5931\u51fd\u6570\uff0c\u8868\u793a\u4e3a\uff1a $$ L_{gate}=-\\frac1N\\sum^N_{i=1}y_ilog(\\sum^T_{t=1}g_t*E^t(x_i)) $$  \u5176\u4e2d\uff1a $$ E^t(x_i)=f(x_i^t,\\theta^t_c) $$ g_t\u4e3a\u95e8\u63a7\u7f51\u7edc\u9884\u6d4b\u7684\u4e00\u7ec4\u6982\u7387\u503c\uff0c\u95e8\u63a7\u7f51\u7edc\u76f8\u5f53\u4e8e\u4ea7\u751f\u4e00\u7ec4\u6743\u91cd\uff0c\u6bcf\u4e2a\u6743\u91cd\u5bf9\u5e94\u4e00\u4e2a\u4e13\u5bb6\u6a21\u578b\uff0c\u6d4b\u8bd5\u8fc7\u7a0b\uff0c\u6a21\u578b\u901a\u8fc7\u5c06\u6240\u6709\u4e13\u5bb6\u6a21\u578b\u7684\u9884\u6d4b\u6982\u7387\u52a0\u6743\u6c42\u548c\u6765\u5f97\u5230\u6700\u7ec8\u7684\u9884\u6d4b\uff1a $$ \\hat{y}_i=\\sum^T_{t=1}g_t*\\hat{y}_i^t $$  \u5176\u4e2d\uff0c\\hat{y}^t_i\u8868\u793a\u4e13\u5bb6\u6a21\u578bE^t\u7684\u9884\u6d4b\u3002</p> <p>\u2003\u2003\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u4f5c\u8005\u4ee5\u987a\u5e8f\u7684\u65b9\u5f0f\u5411\u524d\u4f20\u64ad\u6570\u636e\uff0c\u540c\u65f6\u5728\u4e13\u5bb6\u4e4b\u95f4\u540c\u6b65\u3001\u72ec\u7acb\u5730\u53cd\u5411\u4f20\u64ad\u68af\u5ea6\uff0c\u68af\u5ea6\u4e0d\u4f1a\u4ece\u540e\u9762\u7684\u4e13\u5bb6\u53cd\u5411\u4f20\u64ad\u5230\u524d\u9762\u7684\u4e13\u5bb6\u3002</p>"},{"location":"fine-grained/paper/MGE-CNN1/#_7","title":"\u5b9e\u9a8c","text":""},{"location":"fine-grained/paper/MGE-CNN1/#_8","title":"\u53ef\u89c6\u5316\u5206\u6790","text":"<p>\u2003\u2003\u4e0b\u56fe\u5c55\u793a\u4e86CUB\u6570\u636e\u96c6\u548cStandford Cars\u6570\u636e\u96c6\u7684\u53ef\u89c6\u5316\u6848\u4f8b\u3002\u4ece\u56fe\u4e2d\u53ef\u4ee5\u770b\u51fa\uff0c\u5bf9\u4e8e\u5c0f\u5c3a\u5ea6\u7684\u56fe\u7247\uff0c\u6574\u4e2a\u7269\u4f53\u90fd\u4f1a\u54cd\u5e94\uff0c\u8fd9\u610f\u5473\u7740\u7b2c\u4e00\u4e2a\u4e13\u5bb6(\u524d\u4e24\u5217)\u4e3b\u8981\u57fa\u4e8e\u7269\u4f53\u7684\u5168\u5c40\u4fe1\u606f\u6765\u8fdb\u884c\u9884\u6d4b\u3002\u540c\u65f6\u5b83\u4e5f\u63d0\u4f9b\u4e86\u5b9a\u4f4d\u4fe1\u606f\uff0c\u56e0\u4e3a\u4f7f\u7528\u5f31\u76d1\u7763\u7269\u4f53\u5b9a\u4f4d\u6280\u672f\u4f30\u8ba1\u91cd\u8981\u533a\u57df\u540e\uff0c\u53ef\u4ee5\u66f4\u7cbe\u786e\u5730\u5b9a\u4f4d\u6574\u4e2a\u6574\u4e2a\u7269\u4f53\u5bf9\u8c61\uff0c\u5982\u7b2c\u4e09\u5217\u6240\u793a\u3002\u5229\u7528\u6ce8\u610f\u529b\u56fe\u5c06\u539f\u59cb\u56fe\u50cf\u505a\u88c1\u526a\u653e\u5927\uff0c\u5f97\u5230\u7b2c\u4e8c\u4e2a\u4e13\u5bb6\u6a21\u578b\u7684\u8f93\u5165\uff0c\u56e0\u6b64\u7b2c\u4e8c\u4e2a\u4e13\u5bb6\u4ece\u5bf9\u8c61\u7ea7\u56fe\u7247(object level)\u5b66\u4e60\uff0c\u5e76\u4e14\u76f8\u5e94\u6ce8\u610f\u529b\u56fe\u7684\u5173\u6ce8\u70b9\u4e5f\u66f4\u52a0\u5177\u4f53(\u5982\u7b2c\u56db\u5217)\u3002</p> <p> <p></p> <p></p> <p>\u5927\u96f6\u4ef6\u4fe1\u606f\u4e0e\u5c0f\u96f6\u4ef6\u4fe1\u606f\u7684\u5f71\u54cd\uff1a</p> <p>\u2003\u2003\u4e3a\u4e86\u6bd4\u8f83\u5927\u5c0f\u96f6\u4ef6\u4fe1\u606f\u5bf9\u9884\u6d4b\u7684\u5f71\u54cd\uff0c\u4f5c\u8005\u5bf9\u6bd4\u4e86\u4e24\u79cd\u6c60\u5316\u65b9\u6cd5\uff0c\u5373\u5168\u5c40\u5e73\u5747\u6c60\u5316GAP\u4e0e\u5168\u5c40\u6700\u5927\u6c60\u5316GMP\uff0c\u5206\u522b\u53ef\u89c6\u5316\u4e86\u524d\u4e09\u5f20\u6fc0\u6d3b\u56fe\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u4ed6\u4eec\u5b66\u4e60\u4e86\u540c\u4e00\u5f20\u56fe\u7247\u4e2d\u4e0d\u540c\u65b9\u5f0f\u7684\u6fc0\u6d3b\u54cd\u5e94\u3002GAP\u8f93\u51fa\u503c\u7684\u5927\u5c0f\u4f9d\u8d56\u4e8e\u7279\u5f81\u56fe\u4e2d\u6709\u591a\u5c11\u7a7a\u95f4\u4f4d\u7f6e\u88ab\u76f8\u5e94\u7684\u6ee4\u6ce2\u5668\u6fc0\u6d3b\uff0c\u56e0\u6b64GAP\u5377\u79ef\u6a21\u5757\u901a\u5e38\u4f1a\u5b66\u4e60\u5bf9\u56fe\u50cf\u5927\u533a\u57df\u654f\u611f\u7684\u6ee4\u6ce2\u5668\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0cGMP\u5377\u79ef\u5757\u53ea\u5173\u6ce8\u56fe\u50cf\u67d0\u4e2a\u7a7a\u95f4\u4f4d\u7f6e\u662f\u5426\u88ab\u6ee4\u6ce2\u5668\u9ad8\u5ea6\u6fc0\u6d3b(highly activated)\uff0c\u56e0\u6b64\u5b83\u53d1\u73b0\u7684\u6a21\u5f0f\u901a\u5e38\u662f\u5c0f\u56fe\u7247\u533a\u57df\u3002\u901a\u8fc7\u8fd9\u79cd\u8bbe\u8ba1\uff0c\u4ea7\u751f\u7684\u7279\u5f81\u53ef\u4ee5\u7f16\u7801\u5927\u96f6\u4ef6\u548c\u5c0f\u96f6\u4ef6\u4fe1\u606f\uff0c\u6709\u5229\u4e8e\u5728\u8bc6\u522b\u7269\u4f53\u65f6\u63d0\u4f9b\u4e30\u5bcc\u7684\u7269\u4f53\u4fe1\u606f\u3002</p> <p> <p></p> <p></p>"},{"location":"fine-grained/paper/MGE-CNN1/#_9","title":"\u7cbe\u5ea6\u5bf9\u6bd4","text":"<p>CUB-200-2011\u4ee5\u53caStanford Cars</p> <p> <p></p> <p></p>"},{"location":"fine-grained/paper/MGE-CNN1/#_10","title":"\u603b\u7ed3","text":"<p>\u2003\u2003\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u7ec6\u7c92\u5ea6\u5206\u7c7b\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u4e3b\u8981\u57fa\u4e8e\u4e13\u5bb6\u6df7\u5408\u6a21\u578b\uff0c\u4f46\u662f\u4e0e\u4f20\u7edf\u7684\u65b9\u6cd5\u4e0d\u540c\uff0c\u4f5c\u8005\u901a\u8fc7\u8ba9\u540e\u4e00\u4e2a\u4e13\u5bb6\u5b66\u4e60\u524d\u4e00\u4e2a\u4e13\u5bb6\u7684\u5148\u9a8c\u4fe1\u606f\u6765\u5c06\u7ec6\u7c92\u5ea6\u95ee\u9898\u5212\u5206\u4e3a\u4e0d\u540c\u7684\u5b50\u7a7a\u95f4\u95ee\u9898\u3002\u4f5c\u8005\u901a\u8fc7\u7ed3\u5408\u9010\u6b65\u589e\u5f3a\u7684\u7b56\u7565\u548c\u57fa\u4e8eKL\u6563\u5ea6\u7684\u7ea6\u675f\u6765\u5b66\u4e60\u5177\u6709\u591a\u6837\u6027\u7684\u4e13\u5bb6\u6a21\u578b\uff0c\u6700\u7ec8\u7684\u9884\u6d4b\u662f\u901a\u8fc7\u4f7f\u7528\u7531\u95e8\u63a7\u7f51\u7edc\u751f\u6210\u7684\u6743\u91cd\u5bf9\u6240\u6709\u4e13\u5bb6\u7684\u9884\u6d4b\u8fdb\u884c\u52a0\u6743\u6c42\u548c\u800c\u5f97\u5230\u7684\u3002</p> <p>\u6ce8\uff1a\u4ee5\u4e0a\u5185\u5bb9\u4ec5\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u89c2\u70b9\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u5927\u5bb6\u6279\u8bc4\u6307\u6b63\u3002</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2022\u5e741\u67083\u65e5</p>"},{"location":"fine-grained/paper/NTS-Net1/","title":"\u7ec6\u7c92\u5ea6\uff1aNTS-Net","text":""},{"location":"fine-grained/paper/NTS-Net1/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aEuropean Conference on Computer Vision 2018 (ECCV, 2018)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content_ECCV_2018/papers/Ze_Yang_Learning_to_Navigate_ECCV_2018_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740(PyTorch\u7248\u672c)\uff1ahttps://github.com/yangze0930/NTS-Net</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u7c7b(FGVC)</p> <p>\u5173\u952e\u8bcd\uff1a\u7ec6\u7c92\u5ea6\u5206\u7c7b\u3001\u5bfc\u822a\u5b66\u4e60\u3001\u533a\u57df\u68c0\u6d4b</p>"},{"location":"fine-grained/paper/NTS-Net1/#_2","title":"\u4e3b\u8981\u601d\u60f3","text":"<p>\u2003\u2003\u5982\u4f55\u627e\u5230\u5177\u6709\u533a\u5206\u5ea6\u7684\u533a\u57df\u5bf9\u7ec6\u7c92\u5ea6\u5206\u7c7b\u5177\u6709\u91cd\u8981\u7684\u610f\u4e49\uff0c\u800c\u4f20\u7edf\u7684\u533a\u57df\u68c0\u6d4b\u65b9\u6cd5\u5927\u4f53\u53ef\u4ee5\u5206\u4e3a\u4e24\u79cd\uff1a\u4e00\u79cd\u662f\u57fa\u4e8e\u4eba\u5de5\u6807\u6ce8\u7684\u663e\u8457\u533a\u57df\u8fdb\u884c\u5b66\u4e60\uff0c\u8fd9\u6837\u505a\u4e0d\u4ec5\u9700\u8981\u6d88\u8017\u5927\u91cf\u7684\u4eba\u529b\u8d44\u6e90\uff0c\u800c\u4e14\u663e\u8457\u533a\u57df\u7684\u9009\u62e9\u8fd8\u4f1a\u53d7\u5230\u4e3b\u89c2\u56e0\u7d20\u7684\u5f71\u54cd\uff1b\u53e6\u4e00\u79cd\u662f\u57fa\u4e8e\u65e0\u76d1\u7763\u5b66\u4e60\u7684\u533a\u57df\u68c0\u6d4b\u65b9\u6cd5\uff0c\u4f46\u7531\u6a21\u578b\u7f3a\u4e4f\u4fdd\u8bc1\u6a21\u578b\u805a\u7126\u5728\u6b63\u786e\u533a\u57df\u7684\u673a\u5236\uff0c\u56e0\u6b64\u7cbe\u5ea6\u901a\u5e38\u96be\u4ee5\u63d0\u5347\u3002\u672c\u6587\u4e2d\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u81ea\u76d1\u7763\u673a\u5236\u6765\u6709\u6548\u5730\u76d1\u7763\u4fe1\u606f\u533a\u57df\u5b9a\u4f4d\u7684\u6a21\u5757\uff0c\u5e76\u4e14\u4e0d\u9700\u8981\u989d\u5916\u7684\u6807\u6ce8\u533a\u57df\u3002</p> <p>\u2003\u2003\u5728\u4ee5\u5f80\u7684\u65b9\u6cd5\u4e2d\uff0c\u5b9a\u4f4d\u5177\u6709\u533a\u5206\u5ea6\u7684\u533a\u57df\u4e00\u822c\u88ab\u8ba4\u4e3a\u662f\u5b9a\u4f4d\u4fe1\u606f\u91cf\u5927\u7684\u533a\u57df\uff0c\u56e0\u6b64\u901a\u5e38\u5229\u7528\u6ed1\u52a8\u7a97\u53e3\u7684\u601d\u60f3\u6765\u5b9e\u73b0\u533a\u57df\u7684\u68c0\u6d4b\uff0c\u5bf9\u539f\u56fe\u7684\u533a\u57df\u4fe1\u606f\u91cf\u8fdb\u884c\u4e00\u4e2a\u8bc4\u4f30\uff0c \u4e4b\u540e\u6311\u9009\u51fa\u4fe1\u606f\u91cf\u6700\u9ad8\u7684\u524d\u51e0\u4e2a\u533a\u57df\uff0c\u6700\u540e\u518d\u57fa\u4e8e\u8be5\u533a\u57df\u505a\u4e00\u7cfb\u5217\u7684\u64cd\u4f5c\uff0c\u5176\u4e2d\uff0c\u533a\u57df\u68c0\u6d4b\u6a21\u5757\u6700\u5173\u952e\u7684\u5c31\u662f\u5bf9\u539f\u56fe\u4fe1\u606f\u91cf\u7684\u8bc4\u4f30\uff0c\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u4e2d\uff0c\u7531\u4e8e\u76ee\u6807\u533a\u57df\u5177\u6709\u51c6\u786e\u7684\u6807\u7b7e\uff0c\u56e0\u6b64\u7f51\u7edc\u53ef\u4ee5\u5f97\u5230\u5f88\u597d\u5730\u4f18\u5316\u3002\u4f46\u662f\u5728\u7ec6\u7c92\u5ea6\u5206\u7c7b\u4e2d\uff0c\u53ea\u6709\u56fe\u50cf\u7ea7\u522b\u7684\u6807\u7b7e(\u5373\u7c7b\u522b\u6807\u7b7e)\uff0c\u6ca1\u6709\u989d\u5916\u7684\u533a\u57df\u5750\u6807\u6807\u7b7e(\u4e00\u822c\u8003\u8651\u57fa\u4e8e\u5f31\u76d1\u7763\u5b66\u4e60\u7684\u7b97\u6cd5)\uff0c\u56e0\u6b64\u8bc4\u4f30\u4fe1\u606f\u91cf\u7684\u6a21\u5757\u5f80\u5f80\u5f97\u4e0d\u5230\u5f88\u597d\u7684\u4f18\u5316\uff0c\u56e0\u6b64\uff0c\u7ec6\u7c92\u5ea6\u5206\u7c7b\u4e2d\u5982\u4f55\u4f18\u5316\u5b9a\u4f4d\u6a21\u5757\u5bf9\u5173\u952e\u533a\u57df\u7684\u5b9a\u4f4d\u662f\u89e3\u51b3\u95ee\u9898\u7684\u6838\u5fc3\u6240\u5728\u3002</p> <p>\u2003\u2003\u672c\u6587\u4e2d\uff0c\u4f5c\u8005\u5728\u533a\u57df\u68c0\u6d4b\u6a21\u5757(Navigator)\u7684\u57fa\u7840\u4e0a\uff0c\u53c8\u589e\u52a0\u4e86\u76d1\u7763\u6a21\u5757(Teacher)\uff0c\u7528\u4e8e\u4f18\u5316\u533a\u57df\u68c0\u6d4b\u7684\u4e00\u7cfb\u5217\u53c2\u6570\uff0c\u4f7f\u7f51\u7edc\u5f97\u5b9a\u4f4d\u66f4\u52a0\u51c6\u786e\u3002\u8be5\u76d1\u7763\u6a21\u5757\u56f4\u7ed5\u7740\u4e00\u4e2a\u4e2d\u5fc3\u601d\u60f3\uff1a\u4fe1\u606f\u91cf\u5927\u7684\u533a\u57df\u5f80\u5f80\u5305\u542b\u66f4\u591a\u7684\u8bed\u4e49\u7279\u5f81\u3001\u56e0\u6b64\u5e94\u5f53\u5177\u6709\u66f4\u9ad8\u7684\u9884\u6d4b\u6982\u7387\u3002\u5047\u8bbe\uff0cA\u4e3a\u6240\u6709\u533a\u57df\u7684\u96c6\u5408\uff0cI\u4e3a\u4fe1\u606f\u51fd\u6570\uff0c\u8868\u793a\u4fe1\u606f\u91cf\u7684\u5927\u5c0f\uff0cC\u4e3a\u7f6e\u4fe1\u5ea6\u51fd\u6570\uff0c\u8868\u793a\u533a\u57df\u5bf9\u771f\u5b9e\u7c7b\u522b\u7684\u9884\u6d4b\u6982\u7387\uff0c\u6709\u5982\u4e0b\u6761\u4ef6\u6210\u7acb\uff1a $$ \u5bf9\u4e8e\u4efb\u610fR_1\uff0cR_2\\in A,\u5982\u679cC(R_1)&gt;C(R_2),\u5219I(R_1)&gt;I(R_2) $$  \u57fa\u4e8e\u4e0a\u8ff0\u6761\u4ef6\uff0c\u4f5c\u8005\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u65b0\u7684\u6392\u5e8f\u635f\u5931\u6765\u4f18\u5316\u533a\u57df\u7684\u68c0\u6d4b\u6a21\u5757\uff0c\u4f7f\u533a\u57df\u4fe1\u606f\u91cf\u4e0e\u9884\u6d4b\u6982\u7387\u5177\u6709\u76f8\u540c\u7684\u987a\u5e8f\uff0c\u5373\u9f13\u52b1\u7f51\u7edc\u53bb\u68c0\u6d4b\u771f\u6b63\u5bf9\u6700\u540e\u5206\u7c7b\u6709\u7528\u7684\u533a\u57df\uff0c\u4ee5\u5e2e\u52a9\u540e\u7eed\u66f4\u597d\u5730\u9884\u6d4b\u56fe\u50cf\u7684\u7c7b\u522b\u6982\u7387\u3002\u8be5\u65b9\u6cd5\u53c8\u53ef\u4ee5\u770b\u4f5c\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684actor-critic(\u884c\u52a8\u8005-\u8bc4\u4ef7\u8005)\uff0cNavigator\u662f\u884c\u52a8\u8005\uff0c\u7528\u4e8e\u8bc4\u4f30\u533a\u57df\u4fe1\u606f\u91cf\uff0cTeacher\u662f\u8bc4\u4ef7\u8005\uff0c\u7528\u4e8e\u8bc4\u4ef7Navigator\u8bc4\u4f30\u7684\u533a\u57df\u4fe1\u606f\u91cf\u3002</p>"},{"location":"fine-grained/paper/NTS-Net1/#_3","title":"\u7f51\u7edc\u7ed3\u6784","text":""},{"location":"fine-grained/paper/NTS-Net1/#_4","title":"\u7f51\u7edc\u6d41\u7a0b","text":"<p>\u7f51\u7edc\u4e3b\u8981\u6d41\u7a0b\u5982\u4e0b\u56fe\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u4f5c\u8005\u8bbe\u8ba1\u4e86Navigator\u6a21\u5757\u6765\u8fd1\u4f3c\u4fe1\u606f\u51fd\u6570I\uff0cTeacher\u6a21\u5757\u6765\u8fd1\u4f3c\u7f6e\u4fe1\u5ea6\u51fd\u6570C\u3002\u9996\u5148Navigator\u5bf9\u539f\u56fe\u7684\u533a\u57df\u505a\u4e00\u4e2a\u8bc4\u4f30\uff0c\u8bc4\u4f30\u533a\u57df\u96c6A\u4e2d\u6bcf\u4e2a\u533a\u57dfR_i\u7684\u4fe1\u606f\u91cf\uff0c\u9009\u53d6\u524d\u51e0\u4e2a\u533a\u57df\u4fe1\u606f\u91cf\u5927\u5e76\u4e14\u533a\u57df\u95f4\u5197\u4f59\u5ea6\u4f4e\u7684M\u4e2a\u533a\u57df\uff0c\u4f20\u5165Teacher\u6a21\u5757\uff0c\u76f8\u5e94\u7684\u9884\u6d4b\u5176\u7f6e\u4fe1\u5ea6\uff0c\u5229\u7528M\u4e2a\u533a\u57df\u7684\u7f6e\u4fe1\u5ea6\u4e0e\u4fe1\u606f\u91cf\u95f4\u7684\u6392\u5e8f\u635f\u5931\u6765\u4f18\u5316Navigator\u6a21\u5757\uff0c\u5229\u7528M\u4e2a\u533a\u57df\u7684\u7f6e\u4fe1\u5ea6\u4e0e\u771f\u5b9e\u6807\u7b7e\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u6765\u4f18\u5316Teacher\u6a21\u5757\u3002\u968f\u7740\u7f51\u7edc\u9010\u6e10\u6536\u655b\uff0c\u5b83\u5c06\u51c6\u786e\u5730\u9884\u6d4b\u771f\u6b63\u5bf9\u5206\u7c7b\u6709\u7528\u7684\u533a\u57df\uff0c\u9009\u53d6\u524dK\u4e2a\u4fe1\u606f\u91cf\u9ad8\u7684\u533a\u57df\uff0c\u8fd9\u4e9b\u533a\u57df\u5c06\u4fc3\u8fdb\u7ec6\u7c92\u5ea6\u5206\u7c7b\uff0c\u518d\u5c06\u5b83\u4eec\u4e0e\u539f\u56fe\u4e00\u540c\u8f93\u5165\u5230Scrutinizer\u4e2d\uff0c\u7528\u4e8e\u9884\u6d4b\u6700\u7ec8\u7684\u7c7b\u522b\u6982\u7387\uff0c\u5229\u7528\u6700\u7ec8\u7684\u9884\u6d4b\u6982\u7387\u4e0e\u771f\u5b9e\u6807\u7b7e\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u6765\u4f18\u5316Scrutinizer\u6a21\u5757\u3002(\u6ce8\u610f\uff1a\u7528\u4e8e\u53cd\u9988\u3001\u4f18\u5316Navigator\u7684\u662f\u524dM\u4e2a\u533a\u57df\uff0c\u7528\u4e8e\u9884\u6d4b\u6700\u7ec8\u7c7b\u522b\u7684\u662f\u524dK\u4e2a\u533a\u57df\uff0c\u8fd9\u91cc\u6709\u4e24\u4e2a\u8d85\u53c2\u6570\uff0c\u4e0d\u8981\u5f04\u6df7\u4e86\uff0c\u5e76\u4e14M\u6700\u597d\u5927\u4e8e\u7b49\u4e8eK)</p>"},{"location":"fine-grained/paper/NTS-Net1/#navigator","title":"Navigator","text":"<p>\u2003\u2003Navigator\u4e3b\u8981\u662f\u7528\u4e8e\u5bf9\u539f\u56fe\u533a\u57df\u7684\u4fe1\u606f\u91cf\u505a\u4e00\u4e2a\u8bc4\u4f30\uff0c\u5e76\u4e14\u9009\u51fa\u524d\u51e0\u4e2a\u4fe1\u606f\u91cf\u9ad8\u7684\u533a\u57df\u7528\u4e8e\u540e\u7eed\u7684\u5206\u7c7b\u9884\u6d4b\u3002\u4f5c\u8005\u5229\u7528\u951a\u70b9(\u76ee\u6807\u68c0\u6d4b\u4e2d\u5e38\u7528\u7684\u533a\u57df\u68c0\u6d4b\u65b9\u6cd5)\u6765\u9884\u6d4b\u533a\u57df\u7684\u4fe1\u606f\u91cf\uff0c\u5bf9\u4e8e\u5927\u5c0f448\u00d7448\u7684\u56fe\u50cf\uff0c\u4f5c\u8005\u9009\u62e9\u5177\u6709\u5c3a\u5ea6\u4e3a{48,96,192}\u548c\u6bd4\u4f8b\u4e3a{1:1,3:2,2:3}\u7684\u951a\u70b9\u8fdb\u884c\u68c0\u6d4b\uff0c\u751f\u6210\u4e00\u5806\u77e9\u5f62\u533a\u57df\uff0c\u6bcf\u4e2a\u533a\u57df\u90fd\u6709\u4e00\u4e2a\u8868\u793a\u8be5\u533a\u57df\u4fe1\u606f\u91cf\u7684\u5206\u6570\u3002</p> <p>\u2003\u2003\u4f5c\u8005\u53d7FPN(\u7279\u5f81\u91d1\u5b57\u5854)\u7ed3\u6784\u7684\u542f\u53d1\uff0c\u8bbe\u8ba1\u4e86\u81ea\u4e0a\u5230\u4e0b\u5e26\u6709\u6a2a\u5411\u8fde\u63a5\u7684\u7ed3\u6784\u53bb\u68c0\u6d4b\u591a\u5c3a\u5ea6\u533a\u57df\uff08\u4f46\u6e90\u7801\u597d\u50cf\u6ca1\u6709\u8fd9\u4e00\u6a2a\u5411\u8fde\u63a5\u64cd\u4f5c\uff09\uff0c\u5229\u7528\u5377\u79ef\u53bb\u8ba1\u7b97\u7279\u5f81\uff0c\u901a\u8fc7\u63a7\u5236\u5377\u79ef\u6838\u7684\u5c3a\u5bf8\u4e0e\u6b65\u957f\u5927\u5c0f\uff0c\u6765\u7f29\u5c0f\u7279\u5f81\u56fe\u7684\u5c3a\u5bf8\uff0c\u589e\u5927\u611f\u53d7\u91ce\u3002\u5177\u4f53\u7ed3\u6784\u53ef\u89c1NTS\u63a8\u7406\u8fc7\u7a0b\u56fe(Scrutinizer\u5c0f\u8282\u4e2d)\uff0c\u4e0d\u540c\u5c3a\u5bf8\u7684\u7279\u5f81\u56fe\u4ee3\u8868\u4e86\u4e0d\u540c\u7684\u5c3a\u5ea6\u4fe1\u606f\uff0c\u8f83\u5927\u7279\u5f81\u56fe\u4e2d\u7684\u70b9\u5bf9\u5e94\u539f\u56fe\u4e2d\u8f83\u5c0f\u7684\u533a\u57df\u3002\u5728\u8bba\u6587\u4e2d\uff0c\u4f5c\u8005\u91c7\u7528{48\u00d748, 96\u00d796, 192\u00d7192}\u4e09\u79cd\u533a\u57df\u5c3a\u5ea6\uff08\u5373\u951a\u70b9\u5927\u5c0f\uff09\uff0c\u5bf9\u5e94\u4e8e\u7279\u5f81\u56fe\u5c3a\u5bf8\u4e3a{14\u00d714, 7\u00d77, 4\u00d74}\u3002(\u6ce8\u610f\uff0c\u5728\u7ecf\u8fc7Navigator\u6a21\u5757\u4e4b\u524d\uff0c\u539f\u56fe\u5df2\u7ecf\u7ecf\u8fc7\u4e86\u4e00\u6b21\u7279\u5f81\u63d0\u53d6\u64cd\u4f5c\uff0c\u5f97\u5230\u7684\u7279\u5f81\u56fe\u5c3a\u5bf8\u4e3a14\u00d714\uff0c\u518d\u4f9d\u6b21\u7ecf\u8fc7\u6b65\u957f\u4e3a2\u7684\u5377\u79ef\u5f97\u52307\u00d77\u548c4\u00d74\u7684\u7279\u5f81\u56fe\uff0c\u5177\u4f53\u5b9e\u73b0\u8fc7\u7a0b\u53ef\u89c1\u6e90\u7801\u7b14\u8bb0)</p> <p>\u2003\u2003\u5728\u5f97\u5230\u6bcf\u4e2a\u533a\u57df\u7684\u533a\u57df\u4fe1\u606f\u91cf\u540e\uff0c\u4f5c\u8005\u53c8\u5229\u7528\u975e\u6781\u5927\u503c\u6291\u5236(NMS)\u65b9\u6cd5\uff0c\u9009\u53d6\u4fe1\u606f\u91cf\u5927\u5e76\u4e14\u76f8\u4e92\u95f4\u5197\u4f59\u5ea6\u4f4e\u7684M\u4e2a\u533a\u57df\u548cK\u4e2a\u533a\u57df\uff0c\u524dM\u4e2a\u533a\u57df\u4f20\u5165Teacher\u6a21\u5757\uff0c\u7528\u4e8e\u5bf9Navigator\u7684\u9884\u6d4b\u7ed3\u679c\u505a\u8bc4\u5224\uff0c\u8fdb\u4e00\u6b65\u4f18\u5316\u8be5\u6a21\u5757\u7684\u53c2\u6570\uff1b\u524dK\u4e2a\u533a\u57df\u4f20\u5165Scrutinizer\u6a21\u5757\uff0c\u7528\u4e8e\u9884\u6d4b\u6700\u7ec8\u7684\u56fe\u50cf\u6982\u7387\u3002</p>"},{"location":"fine-grained/paper/NTS-Net1/#teacher","title":"Teacher","text":"<p>\u2003\u2003Teacher\u8fd1\u4f3c\u4e8e\u6620\u5c04C\uff1aA-&gt;[0,1]\uff0c\u5373\u8bc4\u4ef7\u6bcf\u4e2a\u533a\u57df\u7684\u7f6e\u4fe1\u5ea6\u3002\u63a5\u6536\u5230\u6765\u81eaNavigator\u6a21\u5757\u7684M\u4e2a\u533a\u57df\u4e4b\u540e\uff0c\u5c06\u5176\u8c03\u6574\u5230\u6307\u5b9a\u7684\u5927\u5c0f(\u4f5c\u8005\u8c03\u6574\u5230\u4e86224\u00d7224)\uff0c\u518d\u5206\u522b\u5c06\u5176\u4f20\u5165\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u63d0\u53d6\u7279\u5f81\uff0c\u6700\u540e\u4f20\u5165\u5168\u8fde\u63a5\u5c42\u8fdb\u884c\u5206\u7c7b\u9884\u6d4b\uff0c\u53d6\u51fa\u6807\u7b7e\u7c7b\u522b\u7684\u9884\u6d4b\u6982\u7387\uff0c\u4f5c\u4e3a\u8be5\u533a\u57df\u7684\u7f6e\u4fe1\u5ea6C\uff0c\u5177\u4f53\u6d41\u7a0b\u5982\u4e0b\u56fe(M\u53d63)\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u5f97\u5230\u533a\u57df\u7f6e\u4fe1\u5ea6\u540e\uff0c\u518d\u5c06\u533a\u57df\u7f6e\u4fe1\u5ea6C\u4e0e\u533a\u57df\u4fe1\u606f\u91cfI\u505a\u6392\u5e8f\u635f\u5931(\u635f\u5931\u51fd\u6570\u7684\u6784\u5efa\u53ef\u89c1\u635f\u5931\u4e0e\u4f18\u5316\u5c0f\u8282)\uff0c\u8fdb\u4e00\u6b65\u4f18\u5316Navigator\u7684\u6a21\u5757\u53c2\u6570\u3002</p>"},{"location":"fine-grained/paper/NTS-Net1/#scrutinizer","title":"Scrutinizer","text":"<p>\u2003\u2003Scrutinizer\u4e3b\u8981\u7528\u4e8e\u6700\u7ec8\u7684\u5206\u7c7b\u9884\u6d4b\u3002\u63a5\u6536\u5230\u6765\u81eaNavigator\u6a21\u5757\u7684K\u4e2a\u533a\u57df\u4e4b\u540e\uff0c\u4e0eTeacher\u6a21\u5757\u7c7b\u4f3c\uff0c\u5c06\u5176\u8c03\u6574\u5230\u6307\u5b9a\u7684\u5927\u5c0f(\u4f5c\u8005\u8c03\u6574\u5230\u4e86224\u00d7224)\uff0c\u7136\u540e\u518d\u4f20\u5165\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u63d0\u53d6\u7279\u5f81\u3002\u4e4b\u540e\uff0c\u518d\u5c06\u8fd9K\u7ec4\u7279\u5f81\u4e0e\u8f93\u5165\u56fe\u50cf\u7684\u7279\u5f81\u8fde\u63a5\u8d77\u6765\uff0c\u5e76\u5c06\u5176\u4f20\u5165\u5168\u8fde\u63a5\u5c42\u4e2d\uff0c\u9884\u6d4b\u6700\u7ec8\u7684\u7c7b\u522b\u6982\u7387\uff0c\u7f51\u7edc\u5177\u4f53\u7684\u63a8\u7406\u56fe\u5982\u4e0b\uff1a</p> <p> <p></p> <p></p>"},{"location":"fine-grained/paper/NTS-Net1/#_5","title":"\u635f\u5931\u4e0e\u4f18\u5316","text":"<p>Navigation loss\uff1a\u5047\u8bbe\u9884\u6d4b\u5f97\u5230M\u4e2a\u7a97\u53e3\uff0c\u4ed6\u4eec\u7684\u4fe1\u606f\u91cf\u4e3aI\uff0c\u5e76\u4e14\u7531Teacher\u5f97\u5230\u7684\u7f6e\u4fe1\u5ea6\u4e3aC\uff1a $$ I=\\{I_1,I_2,\\dots,I_M\\},C=\\{C_1,C_2,\\dots,C_M\\} $$  \u5219navigator\u6a21\u5757\u7684\u635f\u5931\u51fd\u6570\u53ef\u4ee5\u5b9a\u4e49\u4e3a\uff1a $$ L_I(I,C)=\\sum_{(i,s):C_i&lt;C_s}f(I_s-I_i) $$  \u5176\u4e2df\u662f\u975e\u589e\u7684\u51fd\u6570\uff0c\u5f53\u7f6e\u4fe1\u5ea6Cs&gt;Ci\u65f6\uff0c\u9f13\u52b1\u7f51\u7edc\u7684\u4fe1\u606f\u91cfIs&gt;Ii\uff0c\u4ece\u800c\u8fbe\u5230I\u3001C\u540c\u5e8f\u7684\u6548\u679c\uff0c\u5229\u7528\u6392\u5e8f\u635f\u5931\u4f18\u5316Navigator\u6a21\u5757\u3002\u672c\u6587\u4e2d\uff0c\u4f5c\u8005\u4f7f\u7528\u51fd\u6570f(x)=max{1-x,0}\u6765\u5f53\u505a\u635f\u5931\u51fd\u6570\u3002</p> <p>\u6ce8\uff1a\u8fd9\u91cc\u7684\u6392\u5e8f\u635f\u5931\u7531\u4e8e\u53ea\u6709\u4fe1\u606f\u91cf\u53c2\u4e0e\u8fd0\u7b97\uff0c\u56e0\u6b64\u8be5\u635f\u5931\u53ea\u53c2\u4e0e\u4f18\u5316\u5b9a\u4f4d\u6a21\u5757\uff0c\u5373\u6ed1\u52a8\u7a97\u53e3\u64cd\u4f5c\u3002</p> <p>Teaching loss\uff1a\u5b9a\u4e49Teacher\u6a21\u5757\u7684\u635f\u5931\u51fd\u6570\u5982\u4e0b\uff1a $$ L_C=-\\sum^M_{i=1}logC(R_i)-logC(X) $$  \u5176\u4e2d\uff0cC\u662f\u533a\u57df\u7684\u7f6e\u4fe1\u5ea6(\u5373\u9884\u6d4b\u6982\u7387)\u3002\u4e5f\u5c31\u662f\u5c06\u6240\u6709\u7684\u7a97\u53e3\u4e0e\u539f\u59cb\u56fe\u50cf\u6c42\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u6700\u540e\u518d\u6c42\u548c\uff0cM+1\u4e2a\u9884\u6d4b\u6982\u7387\u7528\u4e8e\u4f18\u5316Teacher\u6a21\u5757\u3002</p> <p>Scrutinizing loss\uff1aNavigator\u6a21\u5757\u9884\u6d4b\u5f97\u5230\u7684\u533a\u57df\u4e2d\uff0c\u9009\u53d6K\u4e2a\u533a\u57df\uff0c\u518d\u7ed3\u5408\u539f\u56feX\uff0cScrutinizer\u5c06\u6240\u6709\u7279\u5f81\u56fe\u878d\u5408\uff0c\u6700\u540e\u5f97\u5230\u4e00\u4e2a\u9884\u6d4b\u6982\u7387\uff1a $$ P=S(X,R_1,R_2,\\dots,R_K) $$  \u6700\u540e\uff0c\u5229\u7528P\u6c42\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u7528\u4e8e\u4f18\u5316Scrutinizer\u6a21\u5757\uff1a $$ L_S=-logP $$ \u8054\u5408\u635f\u5931\uff1a $$ L_{total}=L_I+\u03bb\u00b7L_S+\u03bc\u00b7L_C $$  \u5176\u4e2d\uff0c\u03bb\u548c\u03bc\u662f\u8d85\u53c2\u6570\uff0c\u7528\u4e8e\u63a7\u5236\u4e09\u4e2a\u6a21\u5757\u635f\u5931\u7684\u5360\u6bd4\uff0c\u4f5c\u8005\u5c06\u5176\u5747\u53d61\uff0c\u5373\u4e09\u79cd\u635f\u5931\u5360\u6bd4\u76f8\u540c\u3002</p>"},{"location":"fine-grained/paper/NTS-Net1/#_6","title":"\u7cbe\u5ea6\u5bf9\u6bd4","text":"<p>CUB-200-2011</p> <p> <p></p> <p></p> <p>Aircraft\u4ee5\u53caStanford Cars</p> <p> <p></p> <p></p>"},{"location":"fine-grained/paper/NTS-Net1/#_7","title":"\u603b\u7ed3","text":"<p>\u2003\u2003\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65e0\u9700\u8fb9\u754c\u6846\u6807\u6ce8\u7684\u7ec6\u7c92\u5ea6\u5206\u7c7b\u7b97\u6cd5\u3002\u7531navigator\u6a21\u5757\u9884\u6d4b\u533a\u57df\u4fe1\u606f\u91cf\uff0cTeahcer\u6a21\u5757\u5bf9\u9884\u6d4b\u7684\u4fe1\u606f\u91cf\u6253\u5206\uff0c\u5229\u7528\u533a\u57df\u7684\u4fe1\u606f\u91cf\u548c\u7f6e\u4fe1\u5ea6(\u5206\u6570)\u4e4b\u95f4\u7684\u6392\u5e8f\u635f\u5931\uff0c\u5bf9navigator\u8fdb\u884c\u4f18\u5316\uff0c\u6700\u540eScrutinizer\u6a21\u5757\u5c06\u7efc\u5408\u8003\u8651\u539f\u56fe\u7279\u5f81\u4ee5\u53ca\u4e00\u4e9b\u4fe1\u606f\u91cf\u5927\u7684\u533a\u57df\u7279\u5f81\uff0c\u5bf9\u56fe\u7247\u7684\u7c7b\u522b\u505a\u51fa\u6700\u7ec8\u7684\u5224\u65ad\uff0c\u4e09\u4e2a\u6a21\u5757\u4e92\u76f8\u5408\u4f5c\uff0c\u4e92\u76f8\u52a0\u5f3a\uff0c\u6709\u6548\u5730\u63d0\u9ad8\u4e86\u7f51\u7edc\u7ec6\u7c92\u5ea6\u7684\u5206\u7c7b\u80fd\u529b\u3002</p> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u5927\u5bb6\u6279\u8bc4\u6307\u6b63</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e7411\u670818\u65e5</p>"},{"location":"fine-grained/paper/PC1/","title":"\u7ec6\u7c92\u5ea6\uff1aPC","text":""},{"location":"fine-grained/paper/PC1/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aEuropean Conference on Computer Vision 2018 (ECCV, 18)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content_ECCV_2018/html/Abhimanyu_Dubey_Improving_Fine-Grained_Visual_ECCV_2018_paper.html</p> <p>\u6e90\u7801\u5730\u5740(PyTorch\u7248\u672c)\uff1ahttps://github.com/abhimanyudubey/confusion</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u7c7b(FGVC)</p>"},{"location":"fine-grained/paper/PC1/#_2","title":"\u4e3b\u8981\u601d\u60f3","text":"<p>\u2003\u2003\u7ec6\u7c92\u5ea6\u5206\u7c7b\u4e2d\uff0c\u4e4b\u524d\u7684\u5de5\u4f5c\u5927\u591a\u662f\u96c6\u4e2d\u5728\u5e94\u5bf9\u7531\u59ff\u52bf\u3001\u5149\u7167\u548c\u89c6\u70b9\u53d8\u5316\u5f15\u8d77\u7684\u7c7b\u5185\u5dee\u5f02\u6027\u5927\u7684\u95ee\u9898\uff0c\u5982\u5e94\u7528\u533a\u57df\u5b9a\u4f4d\u6280\u672f\u6216\u8005\u5229\u7528\u6765\u81ea\u7f51\u7edc\u9644\u52a0\u7684\u6570\u636e\u8fdb\u884c\u6269\u5145\u8bad\u7ec3\u96c6\u64cd\u4f5c\uff0c\u4f5c\u8005\u53d1\u73b0\u4ee5\u524d\u7684\u7814\u7a76\u5e76\u6ca1\u6709\u628a\u592a\u591a\u7684\u6ce8\u610f\u529b\u653e\u5728\u7531\u7c7b\u5185\u76f8\u4f3c\u6027\u9ad8\u800c\u53ef\u80fd\u5f15\u8d77\u7684\u95ee\u9898\u4e0a\u3002\u4e0e\u4f20\u7edf\u5927\u89c4\u6a21\u7684\u89c6\u89c9\u5206\u7c7b\u4efb\u52a1(large-scale visual classification, LSVC)\u7c7b\u4f3c\uff0c\u7ec6\u7c92\u5ea6\u5206\u7c7b\u4e5f\u662f\u5229\u7528\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\u8fdb\u884c\u8bad\u7ec3\u3002\u5728LSVC\u6570\u636e\u96c6\u4e2d(\u5982\uff1aImageNet)\uff0c\u7531\u4e8e\u6570\u636e\u96c6\u4e2d\u5b58\u5728\u8f83\u4e3a\u663e\u8457\u7684\u7c7b\u95f4\u5dee\u5f02\uff0c\u56e0\u6b64\u4f7f\u7528\u4ea4\u53c9\u71b5\u635f\u5931\u8fdb\u884c\u5f3a\u533a\u5206\u6027\u5b66\u4e60\u662f\u975e\u5e38\u6210\u529f\u7684\uff0c\u56e0\u4e3a\u795e\u7ecf\u7f51\u7edc\u53ef\u4ee5\u5b66\u4e60\u5230\u5177\u6709\u5927\u91cf\u6570\u636e\u7684\u5e7f\u6cdb\u8bed\u4e49\u7279\u5f81\u3002</p> <p>\u2003\u2003\u4f46\u7531\u4e8e\u7ec6\u7c92\u5ea6\u5206\u7c7b\u6570\u636e\u96c6\u5177\u6709\u9ad8\u7c7b\u5185\u5dee\u5f02\u548c\u9ad8\u7c7b\u95f4\u76f8\u4f3c\u5ea6\u7684\u7279\u70b9\uff0c\u4ea4\u53c9\u71b5\u635f\u5931\u5bf9\u4e8e\u7ec6\u7c92\u5ea6\u5206\u7c7b\u4efb\u52a1\u53ef\u80fd\u5e76\u4e0d\u9002\u7528\u3002\u5982\u679c\u5728\u8bad\u7ec3\u96c6\u4e2d\uff0c\u4e24\u4e2a\u6837\u672c\u5177\u6709\u975e\u5e38\u76f8\u4f3c\u7684\u89c6\u89c9\u5185\u5bb9\uff0c\u4f46\u662f\u5374\u6709\u4e0d\u540c\u7684\u7c7b\u522b\u6807\u7b7e\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u4ea4\u53c9\u71b5\u635f\u5931\u53ef\u80fd\u4f1a\u5f3a\u8feb\u7f51\u7edc\u53bb\u4ee5\u9ad8\u7f6e\u4fe1\u5ea6\u5b66\u4e60\u80fd\u591f\u533a\u5206\u8fd9\u4e24\u5f20\u56fe\u7247\u7684\u7279\u5f81\uff0c\u6781\u7aef\u60c5\u51b5\u4e0b\uff0c\u4e3a\u4e86\u6700\u5c0f\u5316\u8bad\u7ec3\u635f\u5931\uff0c\u7f51\u7edc\u53ef\u80fd\u4f1a\u5b66\u5230\u7279\u5b9a\u4e8e\u6837\u672c\u7684\u7279\u5f81(\u4ec5\u5728\u8be5\u6837\u672c\u4e2d\u5b58\u5728\uff0c\u56e0\u6b64\u5bf9\u4e8e\u8be5\u6837\u672c\u6765\u8bf4\u5177\u6709\u975e\u5e38\u5f3a\u7684\u8fa8\u522b\u6027)\uff0c\u800c\u4e0d\u662f\u7279\u5b9a\u4e8e\u7c7b\u522b\u7684\u7279\u5f81\uff0c\u8fdb\u4e00\u6b65\u6df7\u6dc6\u7f51\u7edc\u5bf9\u56fe\u7247\u7c7b\u522b\u7684\u5224\u65ad\uff0c\u7c7b\u4f3c\u4e8e\u8fc7\u62df\u5408\u73b0\u8c61\u3002\u5728\u7ec6\u7c92\u5ea6\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u7531\u4e8e\u80fd\u591f\u6982\u62ec\u7c7b\u522b\u7279\u5f81\u7684\u6837\u672c\u975e\u5e38\u5c11\uff0c\u56e0\u6b64\u8fd9\u79cd\u6548\u5e94\u4f1a\u66f4\u52a0\u7684\u660e\u663e\u3002</p> <p>\u2003\u2003\u57fa\u4e8e\u4e0a\u8ff0\u5047\u8bbe\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5f15\u5165\u6df7\u6dc6(confusion)\u7684\u65b9\u6cd5\uff0c\u4ece\u800c\u8feb\u4f7f\u7f51\u7edc\u53bb\u5b66\u4e60\u8fa8\u522b\u6027\u7a0d\u5dee\u7684\u7279\u5f81\uff0c\u8fdb\u4e00\u6b65\u9632\u6b62\u7f51\u7edc\u8fc7\u5ea6\u62df\u5408\u57fa\u4e8e\u6837\u672c\u7684\u7279\u5f81(\u8be5\u65b9\u6cd5\u7c7b\u4f3c\u4e8e\u4e00\u79cd\u6b63\u5219\u5316\u63aa\u65bd)\u3002\u5177\u4f53\u7684\u6765\u8bf4\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u968f\u673a\u6210\u5bf9\u6837\u672c\u4e4b\u95f4\u7684\u9884\u6d4b\u6982\u7387\u5206\u5e03\u4e4b\u95f4\u7684\u8ddd\u79bb\uff0c\u6765\u8fbe\u5230\u6df7\u6dc6\u6df1\u5c42\u7f51\u7edc\u7684\u4f5c\u7528\uff0c\u8fdb\u4e00\u6b65\u5e94\u5bf9\u9884\u6d4b\u4e2d\u8fc7\u5ea6\u81ea\u4fe1\u7684\u60c5\u51b5\uff0c\u63d0\u9ad8\u6cdb\u5316\u6027\u80fd\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u6210\u5bf9\u6df7\u6dc6(Pairwise Confusion, PC)\u7b97\u6cd5\u2014\u2014\u4e00\u79cd\u7528\u4e8e\u7aef\u5230\u7aef\u8bad\u7ec3\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u7ec6\u7c92\u5ea6\u5206\u7c7b\u7684\u7b97\u6cd5\u3002</p>"},{"location":"fine-grained/paper/PC1/#_3","title":"\u65b9\u6cd5","text":"<p>\u2003\u2003\u5c06\u201d\u6df7\u6dc6\u201d\u6761\u4ef6\u6982\u7387\u5206\u5e03\u7684\u60f3\u6cd5\u5f62\u8c61\u5316\uff0c\u5047\u8bbe\u4e24\u5f20\u8f93\u5165\u56fe\u7247x_1\u548cx_2\u7684\u6761\u4ef6\u6982\u7387\u5206\u5e03\u5206\u522b\u4e3ap_{\\theta}(y|x_1)\u548cp_{\\theta}(y|x_2)\uff0c\u5bf9\u4e8e\u5177\u6709N\u4e2a\u8f93\u51fa\u7c7b\u7684\u5206\u7c7b\u95ee\u9898\uff0c\u6bcf\u4e2a\u5206\u5e03\u90fd\u662f\u4e00\u4e2aN\u7684\u5411\u91cf\uff0c\u5143\u7d20i\u8868\u793a\u7ed9\u5b9a\u8f93\u5165x\u65f6\uff0c\u5206\u7c7b\u5668\u5728\u7c7b\u522by_i\u7684\u53ef\u4fe1\u5ea6\u3002\u5982\u679c\u5e0c\u671b\u6df7\u6dc6\u4e00\u5bf9\u56fe\u50cfx_1\u548cx_2\u7684\u8f93\u51fa\u7c7b\u522b\uff0c\u9996\u5148\u5c31\u5e94\u8be5\u5b66\u4e60\u4e00\u4e2a\u53c2\u6570\\theta(\u5206\u7c7b\u5668\u53c2\u6570)\uff0c\u8be5\u53c2\u6570\u5728\u67d0\u4e2a\u8ddd\u79bb\u5ea6\u91cf\u4e0b\u4f7f\u5f97\u8fd9\u4e9b\u6761\u4ef6\u6982\u7387\u5206\u5e03\u66f4\u63a5\u8fd1\uff0c\u8fdb\u4e00\u6b65\u4f7f\u5f97x_1\u548cx_2\u7684\u9884\u6d4b\u66f4\u52a0\u76f8\u4f3c\u3002</p> <p>KL\u6563\u5ea6\u6df7\u6dc6\uff1a</p> <p>\u2003\u2003\u5982\u679c\u60f3\u8981\u8861\u91cf\u4e24\u4e2a\u9884\u6d4b\u4e4b\u95f4\u7684\u6982\u7387\u5206\u5e03\uff0c\u6700\u81ea\u7136\u7684\u5c31\u662f\u60f3\u5230\u5229\u7528KL\u6563\u5ea6(Kullback-Liebler)\u8fdb\u884c\u8ba1\u7b97\uff1a $$ \\mathbb D_J(p_{\\theta}(y|x_1),p_{\\theta}(y|x_2))=\\sum^N_{i=1}[(p_{\\theta}(y_i|x_1)-p_{\\theta}(y_i|x_2))\u00b7log\\frac{p_{\\theta}(y|x_1)}{p_{\\theta}(y|x_2)}] $$  \u2003\u2003\u4f46\u8bba\u6587\u4e2d3.1\u5c0f\u8282\u8bc1\u660e\u4e86\u5f53\u4e00\u5bf9\u56fe\u7247\u5177\u6709\u4e0d\u540c\u7684\u7c7b\u522b\u65f6\uff0cKL\u4f1a\u4f7f\u5f97\u8bad\u7ec3\u53d1\u6563\uff0c\u5373\u9884\u6d4b\u8d8a\u63a5\u8fd1\u771f\u5b9e\u503c\u65f6\uff0cKL\u635f\u5931\u8d8a\u5927\uff0c\u4e0d\u80fd\u6b63\u5e38\u6536\u655b\u3002\u6362\u53e5\u8bdd\uff0c\u5982\u679c\u4e24\u4e2a\u56fe\u7247\u6807\u7b7e\u5c31\u4e0d\u4e00\u6837\uff0c\u5230\u4e86\u8bad\u7ec3\u540e\u671f\uff0c\u4f1a\u5f97\u5230\u4e24\u4e2a\u5b8c\u5168\u4e0d\u4e00\u6837\u7684\u5206\u5e03(\u5982\u4e00\u4e2a(0,1)\uff0c\u4e00\u4e2a(1,0))\uff0c\u5229\u7528KL\u6563\u5ea6\u8ba1\u7b97\u5f97\u5230\u7684\u635f\u5931\u4f1a\u8d8b\u4e8e\u65e0\u7a77\uff0c\u76f4\u63a5\u4e3b\u5bfc\u7f51\u7edc\u7684\u6536\u655b\uff0c\u800c\u4f5c\u8005\u5f15\u5165\u6df7\u6dc6\u4e3b\u8981\u662f\u8d77\u5230\u8f85\u52a9\u4f5c\u7528\uff0c\u7a0d\u5fae\u5e72\u9884\u4e00\u4e0b\u5373\u53ef\u3002\u56e0\u6b64\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0cKL\u635f\u5931\u4e0d\u80fd\u7528\u4e8e\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\uff0c\u5fc5\u987b\u5bfb\u627e\u53e6\u4e00\u79cd\u5ea6\u91cf\u6807\u51c6\u6765\u8861\u91cf\u6761\u4ef6\u6982\u7387\u5206\u90e8\u4e4b\u95f4\u7684\u201d\u6df7\u6dc6\u201d\uff0c\u611f\u5174\u8da3\u7684\u540c\u5b66\u53ef\u4ee5\u53bb\u770b\u4e00\u4e0b\u8bc1\u660e\u8fc7\u7a0b\uff0c\u8fd9\u91cc\u5c31\u4e0d\u518d\u8bf4\u660e\u4e86\u3002</p> <p>\u6b27\u6c0f\u8ddd\u79bb\u6df7\u6dc6\uff1a</p> <p>\u2003\u2003\u7531\u4e8eN\u4e2a\u7c7b\u522b\u7684\u6761\u4ef6\u6982\u7387\u5206\u5e03\u662f\\mathbb R^N(N\u7ef4\u5411\u91cf)\u4e2d\u7684\u4e00\u4e2a\u5143\u7d20\uff0c\u56e0\u6b64\uff0c\u4f5c\u8005\u4f7f\u7528\u4e86\u6b27\u6c0f\u8ddd\u79bb\u6765\u8861\u91cf\u4e24\u4e2a\u6761\u4ef6\u6982\u7387\u5206\u5e03\u7684\u6df7\u6dc6\uff0c\u5229\u7528\u5982\u4e0b\u7b49\u5f0f\u6765\u5b9a\u4e49\u4e00\u5bf9\u8f93\u5165\u56fe\u50cfx_1\u548cx_2\u7684\u6b27\u5f0f\u6df7\u6dc6(Euclidean Confusion)\\mathbb D_{EC}(\u00b7, \u00b7)\uff1a $$ \\mathbb D_{EC}(p_{\\theta}(y|x_1),p_{\\theta}(y|x_2))=\\sum^N_{i=1}(p_{\\theta}(y_i|x_1)-p_{\\theta}(y_i|x_2))^2=||p_{\\theta}(y|x_1)-p_{\\theta}(y|x_2)||_2^2 $$  \u4e0eKL\u6563\u5ea6\u4e0d\u540c\uff0c\u6b27\u5f0f\u6df7\u6dc6\u5e76\u4e0d\u4f1a\u968f\u7740\u8bad\u7ec3\u7684\u8fdb\u884c\u800c\u53d1\u6563\u3002\u8bba\u6587\u4e2d\u4f5c\u8005\u53c8\u505a\u4e86\u4e00\u4e9b\u8bf4\u660e\uff0c\u6765\u8bba\u8bc1\u4f7f\u7528\u6b27\u6c0f\u8ddd\u79bb\u6df7\u6dc6\u7684\u5408\u7406\u6027\uff0c\u611f\u5174\u8da3\u7684\u540c\u5b66\u53ef\u4ee5\u53bb\u770b\u4e00\u4e0b\u8bba\u6587\uff0c\u4f5c\u8005\u6700\u7ec8\u4f7f\u7528\u6b27\u5f0f\u8ddd\u79bb\u6765\u8861\u91cf\u4e24\u4e2a\u6982\u7387\u5206\u5e03\u4e4b\u95f4\u7684\u6df7\u6dc6\u3002</p> <p>\u8bad\u7ec3\u8fc7\u7a0b\uff1a</p> <p>\u2003\u2003\u7f51\u7edc\u7ed3\u6784\u5982\u4e0b\u56fe\uff0c\u9996\u5148\u5c06\u540c\u4e00\u6279\u6b21(batch)\u7684\u8f93\u5165\u5206\u6210\u4e24\u90e8\u5206\uff0c\u5bf9\u6bcf\u4e2a\u5b50\u6279\u6b21\u9884\u6d4b\u7684\u4ea4\u53c9\u71b5\u8fdb\u884c\u8bc4\u4f30\uff0c\u4e4b\u540e\u9488\u5bf9\u4e0d\u540c\u5b50\u6279\u6b21\u7684\u76f8\u5e94\u6837\u672c\u8ba1\u7b97\u6210\u5bf9\u6df7\u6dc6\u635f\u5931\uff0c\u5f53\u6837\u672c\u5c5e\u4e8e\u4e0d\u540c\u7c7b\u65f6\u6dfb\u52a0\u6b27\u5f0f\u6df7\u6dc6\uff0c\u5982\u679c\u6837\u672c\u5c5e\u4e8e\u76f8\u540c\u7c7b\uff0c\u5219\u4e0d\u6dfb\u52a0\u6df7\u6dc6\u635f\u5931\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u5bf9\u4e8e\u4e00\u5bf9\u56fe\u50cfx_1\u3001x_2\u4ee5\u53ca\u76f8\u5e94\u7684\u9884\u6d4b\u6982\u7387y_1\u3001y_2\uff0c\u6a21\u578b\u7684\u603b\u635f\u5931\u5982\u4e0b\uff1a $$ \\mathcal L_{pair}(x_1,x_2,y_1,y_2;\\theta)=\\sum^2_{i=1}[\\mathcal L_{CE}(p_{\\theta}(y|x_i),y_i)]+\\lambda \\gamma(y_1,y_2)\\mathbb D_{CE}(p_{\\theta}(y|x_1),p_{\\theta}(y|x_2)) $$  \u5176\u4e2d\uff0c\u5f53y_i\\neq y_j\u65f6\\gamma(y_1,y_2)=1\uff0c\u5426\u5219\u5c31\u4e3a0\uff0c\\theta\u8868\u793a\u7f51\u7edc\u7684\u53c2\u6570\uff0c\\lambda\u4e3a\u6743\u91cd\u53c2\u6570\uff0c\u4e00\u822c\u8bbe\u4e3a0.05N\u52300.15N\u4e4b\u95f4\uff0c\u5176\u4e2dN\u4e3a\u7c7b\u522b\u6570\u91cf\u3002</p>"},{"location":"fine-grained/paper/PC1/#_4","title":"\u5b9e\u9a8c","text":""},{"location":"fine-grained/paper/PC1/#_5","title":"\u53ef\u89c6\u5316\u5206\u6790","text":"<p>\u2003\u2003\u4e3a\u4e86\u5b9a\u6027\u5730\u7814\u7a76PC\u7684\u6709\u6548\u6027\uff0c\u4f5c\u8005\u53ef\u89c6\u5316\u4e86\u57fa\u7ebf\u6a21\u578b\u4e0e\u57fa\u7ebf\u6a21\u578b\u52a0PC\u7684\u5bf9\u6bd4\u56fe\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u5f15\u5165\u4e86PC\u6a21\u5757\u7684\u7f51\u7edc\u53ef\u4ee5\u4f7f\u6a21\u578b\u66f4\u52a0\u7cbe\u51c6\u3001\u7d27\u5bc6\u5730\u5b9a\u4f4d\u7269\u4f53\u7684\u6240\u5728\uff0c\u4f8b\u5982\u4e0b\u56fe\u7b2c\u4e00\u4e2a\u4f8b\u5b50\uff0c\u53f3\u4fa7\u662f\u4e00\u4e2a\u5361\u901a\u9e1f\uff0c\u5c5e\u4e8e\u7279\u5b9a\u4e8e\u6837\u672c\u7684\u7279\u5f81\uff0c\u5373\u566a\u70b9\uff0c\u4e0e\u57fa\u7ebf\u6a21\u578b\u76f8\u6bd4\uff0cPC\u6a21\u5757\u53ef\u4ee5\u5f88\u597d\u5730\u4f7f\u7f51\u7edc\u5ffd\u7565\u6389\u53f3\u4fa7\u7684\u5361\u901a\u9e1f\uff0c\u800c\u8ba9\u7f51\u7edc\u4e3b\u8981\u5173\u6ce8\u5de6\u4fa7\u7684\u771f\u5b9e\u9e1f\u3002</p> <p>\u2003\u2003\u4e0b\u56fe\u7b2c\u4e00\u5217\u7684\u4f8b\u5b50\u4e3a\uff1a\u57fa\u7ebf\u6a21\u578b\u4e0e\u5f15\u5165\u4e86PC\u6a21\u5757\u7684\u6a21\u578b\u90fd\u505a\u51fa\u4e86\u6b63\u786e\u7684\u51b3\u7b56\uff0c\u4f46\u662f\u7531\u56fe\u4e2d\u53ef\u4ee5\u770b\u51fa\uff0c\u57fa\u7ebf\u6a21\u578b\u5173\u6ce8\u70b9\u6bd4\u8f83\u5206\u6563\uff0c\u5e76\u4e14\u5bb9\u6613\u88ab\u6837\u672c\u566a\u58f0\u6240\u5438\u5f15\uff0c\u4e0d\u80fd\u5f88\u597d\u7684\u5173\u6ce8\u7c7b\u522b\u7269\u4f53\u6240\u5728\u7684\u4f4d\u7f6e\u3002\u7b2c\u4e8c\u5217\u7684\u4f8b\u5b50\u4e3a\uff1a\u57fa\u7ebf\u6a21\u578b\u505a\u51fa\u4e86\u9519\u8bef\u7684\u51b3\u7b56\uff0c\u800c\u901a\u8fc7\u5f15\u5165PC\u6a21\u5757\u6765\u7ea0\u6b63\u4e86\u6a21\u578b\u7684\u9884\u6d4b\u3002</p> <p> <p></p> <p></p>"},{"location":"fine-grained/paper/PC1/#_6","title":"\u7cbe\u5ea6\u5bf9\u6bd4","text":"<p> <p></p> <p></p>"},{"location":"fine-grained/paper/PC1/#_7","title":"\u603b\u7ed3","text":"<p>\u2003\u2003\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6210\u5bf9\u6df7\u6dc6(PC)\u4f18\u5316\u7b56\u7565\uff0c\u901a\u8fc7\u9f13\u52b1\u8f93\u51fa\u7684\u6df7\u6dc6\u6765\u63d0\u9ad8\u7ec6\u7c92\u5ea6\u89c6\u89c9\u5206\u7c7b\u4efb\u52a1\u7684\u6cdb\u5316\u80fd\u529b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u7ecf\u8fc7PC\u8bad\u7ec3\u51fa\u6765\u7684\u7f51\u7edc\u663e\u8457\u5730\u6539\u8fdb\u4e86\u6a21\u578b\u7684\u5b9a\u4f4d\u6027\u80fd\uff0c\u6709\u5229\u4e8e\u63d0\u9ad8\u5206\u7c7b\u7684\u7cbe\u5ea6\u3002\u4e0e\u4e00\u822c\u8bbe\u8ba1\u65b0\u7684\u3001\u590d\u6742\u7684\u7f51\u7edc\u7ed3\u6784\u76f8\u6bd4\uff0cPC\u6613\u4e8e\u5b9e\u73b0\uff0c\u4e0d\u4f1a\u5728\u8bad\u7ec3\u671f\u95f4\u589e\u52a0\u8fc7\u591a\u7684\u5f00\u652f\uff0c\u5e76\u4e14\u4fbf\u4e8e\u6dfb\u52a0\u5230\u5404\u79cd\u7f51\u7edc\u6a21\u578b\u4e2d\uff0c\u6765\u63d0\u9ad8\u6a21\u578b\u7684\u6027\u80fd\u3002 </p> <p>\u6ce8\uff1a\u4ee5\u4e0a\u5185\u5bb9\u4ec5\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u89c2\u70b9\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u5927\u5bb6\u6279\u8bc4\u6307\u6b63\u3002</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e7412\u670829\u65e5</p>"},{"location":"fine-grained/paper/PMG1/","title":"\u7ec6\u7c92\u5ea6\uff1aPMG","text":""},{"location":"fine-grained/paper/PMG1/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aEuropean Conference on Computer Vision 2020 (ECCV, 2020)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://arxiv.org/pdf/2003.03836.pdf</p> <p>\u6e90\u7801\u5730\u5740(PyTorch\u7248\u672c)\uff1ahttps://github.com/PRIS-CV/PMG-Progressive-Multi-Granularity-Training</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u7c7b(FGVC)</p> <p>\u5173\u952e\u8bcd\uff1a\u7ec6\u7c92\u5ea6\u5206\u7c7b\u3001\u6e10\u8fdb\u8bad\u7ec3\u3001\u62fc\u56fe\u8865\u4e01</p>"},{"location":"fine-grained/paper/PMG1/#_2","title":"\u4e3b\u8981\u601d\u60f3","text":"<p>\u2003\u2003\u5728\u4ee5\u524d\u7684\u7ec6\u7c92\u5ea6\u5206\u7c7b\u4e2d\uff0c\u7b97\u6cd5\u4e3b\u8981\u5173\u6ce8\u5982\u4f55\u5b9a\u4f4d\u6700\u6709\u533a\u5206\u5ea6\u7684\u533a\u57df\u3001\u4e92\u8865\u533a\u57df\u4ee5\u53ca\u591a\u7c92\u5ea6\u533a\u57df\uff0c\u4f46\u662f\u5f88\u5c11\u6709\u7b97\u6cd5\u5173\u6ce8\u5982\u4f55\u5c06\u4e0d\u540c\u7684\u7c92\u5ea6\u7279\u5f81\u878d\u5408\u8d77\u6765\u3002\u8de8\u8d8a\u591a\u7c92\u5ea6\u4fe1\u606f\uff0c\u63a2\u7d22\u4e0d\u540c\u7c92\u5ea6\u533a\u57df\u4e4b\u95f4\u7684\u4e92\u8865\u5173\u7cfb\u6709\u52a9\u4e8e\u63d0\u9ad8\u7b97\u6cd5\u7684\u9884\u6d4b\u7cbe\u5ea6\uff0c\u6bd4\u5982\u4e13\u5bb6\u5728\u8bc6\u522b\u9e1f\u7684\u7c7b\u522b\u4e2d\uff0c\u6709\u65f6\u9700\u8981\u7ed3\u5408\u9e1f\u5934\u90e8\u7684\u6574\u4f53\u7ed3\u6784(\u7c97\u7c92\u5ea6)\u4e0e\u9e1f\u5599\u5f62\u72b6\u7684\u7ec6\u8282(\u7ec6\u7c92\u5ea6)\u6765\u7efc\u5408\u5224\u65ad\u4e00\u4e2a\u9e1f\u7684\u79cd\u7c7b\u3002\u56e0\u6b64\uff0c\u4ec5\u5355\u72ec\u8003\u8651\u5982\u4f55\u8bc6\u522b\u6709\u533a\u5206\u5ea6\u7684\u533a\u57df(\u5355\u72ec\u5730\u5206\u6790\u4e0d\u540c\u7684\u7279\u5f81)\u5f80\u5f80\u662f\u4e0d\u591f\u7684\uff0c\u5c06\u4e0d\u540c\u7c92\u5ea6\u7684\u7279\u5f81\u4ee5\u534f\u540c\u7684\u65b9\u5f0f\u878d\u5408\u5728\u4e00\u8d77\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63d0\u5347\u7f51\u7edc\u7684\u8bc6\u522b\u6548\u679c\uff0c\u4f9d\u636e\u8fd9\u4e2a\u60f3\u6cd5\uff0c\u518d\u7ed3\u5408\u7ec6\u7c92\u5ea6\u7684\u533a\u5206\u6027\u4fe1\u606f\u5b58\u5728\u4e8e\u4e0d\u540c\u7684\u89c6\u89c9\u7c92\u5ea6\u4e2d\u8fd9\u4e00\u601d\u60f3\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65e2\u53ef\u4ee5\u8bc6\u522b\u6700\u5177\u6709\u533a\u522b\u6027\u7684\u7c92\u5ea6\uff0c\u53c8\u53ef\u4ee5\u5c06\u4e0d\u540c\u7c92\u5ea6\u7279\u5f81\u6709\u6548\u5730\u5408\u5e76\u7684\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u4e3b\u8981\u7531\u4e24\u90e8\u5206\u7ec4\u6210\uff1a\u2460\u6709\u6548\u878d\u5408\u4e86\u4e0d\u540c\u7c92\u5ea6\u7279\u5f81\u7684\u6e10\u8fdb\u8bad\u7ec3\u7b56\u7565\uff1b\u2461\u9f13\u52b1\u7f51\u7edc\u4ee5\u7279\u5b9a\u7c92\u5ea6\u5b66\u4e60\u7279\u5f81\u7684\u968f\u673a\u62fc\u56fe\u751f\u6210\u5668\u3002</p> <p> \u6e10\u8fdb\u8bad\u7ec3\u7b56\u7565\uff1a\u4e0e\u73b0\u6709\u7684\u6280\u672f\u4e0d\u540c(\u5148\u68c0\u6d4b\u96f6\u4ef6\uff0c\u540e\u4ee5\u7279\u5b9a\u65b9\u5f0f\u878d\u5408)\uff0c\u6e10\u8fdb\u8bad\u7ec3\u6846\u67b6\u5728\u8bad\u7ec3\u671f\u95f4\u5206\u6b65\u9aa4\u5de5\u4f5c\uff0c\u5176\u4e2d\u5728\u6bcf\u4e00\u6b65\uff0c\u8bad\u7ec3\u96c6\u4e2d\u4e8e\u5728\u7f51\u7edc\u76f8\u5e94\u9636\u6bb5\u57f9\u517b\u7279\u5b9a\u7684\u7c92\u5ea6\u4fe1\u606f\u3002\u9996\u5148\u4ece\u66f4\u7a33\u5b9a\uff0c\u66f4\u7cbe\u7ec6\u7684\u7c92\u5ea6(\u5c0f\u533a\u57df)\u5f00\u59cb\uff0c\u9010\u6e10\u8f6c\u5411\u7c97\u7cd9\u7684\u7c92\u5ea6(\u5927\u533a\u57df)\uff0c\u907f\u514d\u4e86\u5927\u533a\u57df\u4e2d\uff0c\u6bd4\u8f83\u5927\u7684\u7c7b\u5185\u53d8\u5316\u800c\u5e26\u6765\u7684\u6df7\u4e71\u3002\u5f53\u6bcf\u4e2a\u8bad\u7ec3\u6b65\u9aa4\u7ed3\u675f\u65f6\uff0c\u5f53\u524d\u6b65\u9aa4\u8bad\u7ec3\u7684\u53c2\u6570\u5c06\u4f5c\u4e3a\u5176\u53c2\u6570\u521d\u59cb\u5316\u4f20\u9012\u5230\u4e0b\u4e00\u4e2a\u8bad\u7ec3\u6b65\u9aa4\uff0c\u8fd9\u79cd\u4f20\u9012\u64cd\u4f5c\u672c\u8d28\u4e0a\u53ef\u4ee5\u8ba9\u7f51\u7edc\u80fd\u591f\u57fa\u4e8e\u5176\u5148\u524d\u8bad\u7ec3\u6b65\u9aa4\u4e2d\u5b66\u4e60\u7684\u533a\u57df\u6765\u6316\u6398\u66f4\u5927\u7684\u7c92\u5ea6\u7279\u5f81\u3002\u6240\u6709\u9636\u6bb5\u63d0\u53d6\u7684\u7279\u5f81\u518d\u7ecf\u8fc7\u6700\u540e\u4e00\u6b65\u8fde\u63a5\uff0c\u4ece\u800c\u786e\u4fdd\u8ba9\u7f51\u7edc\u5145\u5206\u63a2\u7d22\u4e92\u8865\u5173\u7cfb\uff0c\u878d\u5408\u591a\u7c92\u5ea6\u7279\u5f81\u3002</p> <p>\u2003\u2003\u4f46\u5982\u679c\u53ea\u5e94\u7528\u6e10\u8fdb\u8bad\u7ec3\u7b56\u7565\uff0c\u5219\u7f51\u7edc\u5b66\u4e60\u5230\u7684\u591a\u7c92\u5ea6\u4fe1\u606f\u53ef\u80fd\u4f1a\u96c6\u4e2d\u5728\u76f8\u4f3c\u7684\u533a\u57df(\u7c97\u7c92\u5ea6\u7279\u5f81\u4e0e\u7ec6\u7c92\u5ea6\u7279\u5f81\u96c6\u4e2d\u5728\u4e00\u5757\uff0c\u5bb9\u6613\u53d7\u5230\u7c97\u7c92\u5ea6\u4fe1\u606f\u7684\u5e72\u6270)\uff0c\u56e0\u6b64\uff0c\u4f5c\u8005\u53c8\u8bbe\u8ba1\u4e86\u62fc\u56fe\u751f\u6210\u5668\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002</p> <p> \u62fc\u56fe\u751f\u6210\u5668\uff1a\u901a\u8fc7\u5c06\u539f\u56fe\u8fdb\u884c\u5747\u5300\u5730\u5212\u5206\u5e76\u968f\u673a\u6253\u4e71(\u901a\u4fd7\u5730\u6765\u8bb2\u5c31\u662f\u5747\u5300\u5212\u5206\u6210\u62fc\u56fe\u788e\u7247\uff0c\u7136\u540e\u8fdb\u884c\u6253\u4e71)\uff0c\u53ef\u4ee5\u5f62\u6210\u4e0d\u540c\u7c92\u5ea6\u7ea7\u522b\u7684\u7279\u5f81\uff0c\u5176\u4e2d\u8865\u4e01\u5927\u5c0f\u4e0e\u7279\u5b9a\u7684\u7c92\u5ea6\u4e00\u4e00\u5bf9\u5e94\u3002\u5b83\u672c\u8d28\u4e0a\u8feb\u4f7f\u7f51\u7edc\u7684\u6bcf\u4e2a\u9636\u6bb5\u5173\u6ce8\u5c40\u90e8\u7684\u8865\u4e01\uff0c\u9650\u5236\u4e86\u7f51\u7edc\u7684\u5173\u6ce8\u533a\u57df\u5927\u5c0f\uff0c\u800c\u4e0d\u662f\u5173\u6ce8\u7f51\u7edc\u7684\u6574\u4f53\uff0c\u56e0\u6b64\u901a\u8fc7\u5b66\u4e60\u8be5\u201d\u62fc\u56fe\u201d\u53ef\u4ee5\u4f7f\u7f51\u7edc\u5b66\u4e60\u5230\u7279\u5b9a\u7684\u7c92\u5ea6\u7ea7\u522b\u4fe1\u606f\u3002\u4e0b\u56fe\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u6548\u679c\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u5176\u4e2d(a)\u548c(b)\u662f\u4e00\u822c\u65b9\u6cd5\uff0c( c )\u548c(d)\u662f\u6211\u4eec\u63d0\u51fa\u7684\u65b9\u6cd5\u3002\u901a\u8fc7\u5229\u7528\u4ea4\u53c9\u71b5\u635f\u5931\u8bad\u7ec3\u7684\u4f20\u7edf\u795e\u7ecf\u7f51\u7edc(a)\u503e\u5411\u4e8e\u627e\u5230\u6700\u6709\u533a\u5206\u5ea6\u7684\u90e8\u5206\u3002\u800c\u5176\u4ed6\u7b97\u6cd5(b)\u4fa7\u91cd\u4e8e\u5982\u4f55\u627e\u5230\u66f4\u591a\u6709\u533a\u522b\u7684\u90e8\u5206\u3002( c )\u662f\u6211\u4eec\u6e10\u8fdb\u5f0f\u8bad\u7ec3\u5f97\u5230\u7684\u7ed3\u679c\uff0c\u7531\u4f4e\u7ea7\u9636\u6bb5\u5230\u9ad8\u7ea7\u9636\u6bb5\u9010\u6e10\u5b9a\u4f4d\u8fa8\u522b\u4fe1\u606f\uff0c\u5e76\u4e14\u5c06\u6240\u6709\u8bad\u7ec3\u9636\u6bb5\u63d0\u53d6\u7684\u7279\u5f81\u8fde\u63a5\u5728\u4e00\u8d77\uff0c\u786e\u4fdd\u63a2\u7d22\u5176\u4e2d\u7684\u4e92\u8865\u5173\u7cfb\uff1b(d)\u8868\u793a\u5728\u62fc\u56fe\u751f\u6210\u5668\u7684\u5e2e\u52a9\u4e0b\uff0c\u5728\u6bcf\u6b65\u4e2d\u5b66\u4e60\u7684\u96f6\u4ef6\u7c92\u5ea6\u88ab\u9650\u5236\u5728\u8865\u4e01\u5927\u5c0f\u4e2d\u3002</p>"},{"location":"fine-grained/paper/PMG1/#_3","title":"\u7f51\u7edc\u7ed3\u6784","text":"<p>\u2003\u2003\u4e3a\u4e86\u89e3\u51b3\u5927\u7684\u7c7b\u5185\u53d8\u5316\uff0c\u4f5c\u8005\u9f13\u52b1\u6a21\u578b\u5728\u8f83\u6d45\u5c42\u4e2d\u5b66\u4e60\u7a33\u5b9a\u7684\u7ec6\u7c92\u5ea6\u4fe1\u606f\uff0c\u5e76\u968f\u7740\u8bad\u7ec3\u7684\u8fdb\u884c\u9010\u6e10\u5c06\u6ce8\u610f\u529b\u8f6c\u79fb\u5230\u8f83\u6df1\u7684\u5c42\u4e2d\u5b66\u4e60\u5927\u7c92\u5ea6\u7ea7\u522b\u7684\u62bd\u8c61\u4fe1\u606f\u3002</p> <p>\u2003\u2003\u8be5\u7f51\u7edc\u7684\u8bbe\u8ba1\u662f\u901a\u7528\u7684\uff0c\u53ef\u4ee5\u5d4c\u5165\u5230\u4efb\u4f55\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u4e2d\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u5206\u7c7b\u3002\u4ee5ResNet\u4e3a\u4f8b\uff0c\u5047\u8bbe\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u6709L\u4e2a\u9636\u6bb5\uff0c\u62bd\u53d6\u540eS\u4e2a\u9636\u6bb5\u8f93\u51fa\u7684\u7279\u5f81\u56fe\uff0c\u7528\u4e8e\u6e10\u8fdb\u8bad\u7ec3\uff0c\u5206\u522b\u5c06\u4ed6\u4eec\u4f20\u5165\u9884\u8bbe\u597d\u7684\u5377\u79ef\u6a21\u5757(Conv Block)\u5c06\u5176\u8f6c\u5316\u4e3a\u5411\u91cf\uff0c\u5f97\u5230S\u7ec4\u7279\u5f81\u5411\u91cf\u4e4b\u540e\uff0c\u4e00\u65b9\u9762\u5206\u522b\u5c06\u5176\u4f20\u5165\u4e0d\u540c\u7684\u5206\u7c7b\u6a21\u5757(classification module)\uff0c\u5f97\u5230\u4e0d\u540c\u7c92\u5ea6\u4fe1\u606f\u4e0b\u7684\u9884\u6d4b\u6982\u7387\uff0c\u53e6\u4e00\u65b9\u9762\u5c06\u6240\u6709\u7684\u7279\u5f81\u5411\u91cf\u5408\u5e76\uff0c\u4f20\u5165\u6700\u540e\u7684\u5206\u7c7b\u6a21\u5757\uff0c\u5f97\u5230\u878d\u5408\u4e86\u6240\u6709\u7c92\u5ea6\u4fe1\u606f\u4e0b\u7684\u9884\u6d4b\u6982\u7387\u3002\u5176\u4e2d\uff0c\u5377\u79ef\u6a21\u5757\u7531\u4e24\u5c42\u5377\u79ef\u4ee5\u53ca\u6700\u5927\u6c60\u5316\u7ec4\u5408\u800c\u6210\uff0c\u5206\u7c7b\u6a21\u5757\u7531\u4e24\u5c42\u5e26\u6709\u6807\u51c6\u5316\u64cd\u4f5c\u7684\u5168\u8fde\u63a5\u5c42\u4ee5\u53ca\u4e00\u5c42Elu\u6fc0\u6d3b\u51fd\u6570\u7ec4\u6210(\u5177\u4f53\u5b9e\u73b0\u65b9\u5f0f\u8bf7\u89c1\u6e90\u7801\u7b14\u8bb0)\uff0c\u5177\u4f53\u7684\u7f51\u7edc\u7ed3\u6784\u5982\u4e0b\u56fe\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u5047\u8bbe\u53d6\u51fa\u540eS\u5c42(\u56fe\u4e2d\u4ee5S=3\u4e3a\u4f8b)\u7684\u8f93\u51fa\u7528\u4e8e\u6e10\u8fdb\u8bad\u7ec3\uff0c\u5219\u7f51\u7edc\u6bcf\u6b21\u8fed\u4ee3\u90fd\u6709S+1\u6b65\uff0c\u5176\u4e2dConv Block\u8868\u793a\u6784\u5efa\u7684\u5377\u79ef\u6a21\u5757\u3002\u524dS\u6b65\u5206\u522b\u4ee5\u524dS\u5c42\u7684\u7279\u5f81\u4f5c\u4e3a\u7c7b\u522b\u9884\u6d4b\u7684\u4f9d\u636e\uff0c\u7528\u4e8e\u7f51\u7edc\u7684\u6e10\u8fdb\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u5e76\u4e14\u8bad\u7ec3\u6570\u636e\u7531\u62fc\u56fe\u751f\u6210\u5668\u5f97\u5230\uff1b\u6700\u540e\u4e00\u6b65\u5c06\u524dS\u5c42\u7684\u7279\u5f81\u878d\u5408\uff0c\u7528\u4e8e\u8ba9\u7f51\u7edc\u63a2\u7d22\u4e0d\u540c\u7c92\u5ea6\u4e4b\u95f4\u7684\u4e92\u8865\u8054\u7cfb\u3002\u5728\u6bcf\u4e00\u6b65\u4e2d\uff0c\u76f8\u5e94\u5206\u7c7b\u5668\u7684\u8f93\u51fa\u5c06\u7528\u4e8e\u635f\u5931\u7684\u8ba1\u7b97\u548c\u7f51\u7edc\u53c2\u6570\u7684\u66f4\u65b0\u3002</p>"},{"location":"fine-grained/paper/PMG1/#_4","title":"\u6e10\u8fdb\u8bad\u7ec3\u9636\u6bb5","text":"<p>\u2003\u2003\u6240\u8c13\u7684\u6e10\u8fdb\u8bad\u7ec3\u5c31\u662f\u5148\u8bad\u7ec3\u4f4e\u7ea7\u9636\u6bb5\uff0c\u7136\u540e\u9010\u6b65\u589e\u52a0\u65b0\u7684\u8bad\u7ec3\u9636\u6bb5\uff0c\u7531\u4e8e\u4f4e\u7ea7\u9636\u6bb5\u7684\u611f\u53d7\u91ce\u548c\u8868\u5f81\u80fd\u529b(\u7279\u5f81\u8868\u793a\u7684\u80fd\u529b)\u6709\u9650\uff0c\u56e0\u6b64\u7f51\u7edc\u88ab\u8feb\u9996\u5148\u63a2\u7d22\u5c40\u90e8\u7ec6\u8282\u7684\u8fa8\u522b\u4fe1\u606f(discriminative information)\u3002\u4e0e\u76f4\u63a5\u8bad\u7ec3\u6574\u4e2a\u7f51\u7edc\u76f8\u6bd4\uff0c\u6a21\u578b\u5728\u7279\u5f81\u9010\u6e10\u88ab\u9001\u5230\u66f4\u9ad8\u9636\u6bb5\u65f6\uff0c\u7f51\u7edc\u4f1a\u5b9a\u4f4d\u4ece\u5c40\u90e8\u7ec6\u8282\u5230\u5168\u5c40\u7ed3\u6784\u7684\u533a\u522b\u6027\u4fe1\u606f\uff0c\u800c\u4e0d\u662f\u540c\u65f6\u5b66\u4e60\u6240\u6709\u7c92\u5ea6\u7ea7\u522b\u7684\u4fe1\u606f\u3002</p> <p>\u2003\u2003\u4e3a\u4e86\u8bad\u7ec3\u6765\u81ea\u6bcf\u4e2a\u9636\u6bb5\u7684\u8f93\u51fa\u548c\u7ea7\u8054\u9636\u6bb5(\u5c06\u6240\u6709\u7279\u5f81\u878d\u5408\u540e\u7684\u9636\u6bb5)\u7684\u8f93\u51fa\uff0c\u4f5c\u8005\u91c7\u7528\u4ea4\u53c9\u71b5\u635f\u5931(CE)\u6765\u8ba1\u7b97\u771f\u5b9e\u6807\u7b7e\u548c\u9884\u6d4b\u6982\u7387\u4e4b\u95f4\u7684\u635f\u5931\uff1a $$ L_{CE}(y^l,y)=-\\sum^m_{i=1}y\\times log(y_i^l) $$  \u5176\u4e2d\uff0cy^l\u662f\u7b2cl\u9636\u6bb5\u8f93\u51fa\u7684\u6982\u7387\u503c\uff0c\u4ee5\u53ca $$ L_{CE}(y^{concat},y)=-\\sum^m_{i=1}y\\times log(y_i^{concat}) $$  \u5176\u4e2d\uff0cy^{concat}\u662f\u7ea7\u8054\u9636\u6bb5\u8f93\u51fa\u7684\u6982\u7387\u503c\u3002</p> <p>\u2003\u2003\u6bcf\u6b21\u8fed\u4ee3\u4e2d\uff0c\u4e00\u6279\u6570\u636e\u4f1a\u88ab\u4f7f\u7528S+1\u4e2a\u9636\u6bb5\uff0c\u5e76\u4e14\u6211\u4eec\u5728\u6bcf\u4e2a\u9636\u6bb5\u4e2d\u53ea\u8bad\u7ec3\u4e00\u4e2a\u9636\u6bb5\u7684\u8f93\u51fa\u3002\u6bcf\u6b21\u8bad\u7ec3\u4e2d\uff0c\u5f53\u524d\u9884\u6d4b\u7ed3\u679c\u6240\u4f7f\u7528\u7684\u53c2\u6570\u90fd\u5c06\u5f97\u5230\u4f18\u5316\uff0c\u56e0\u6b64\u524d\u51e0\u4e2a\u9636\u6bb5\u7684\u53c2\u6570\u53ef\u80fd\u4f1a\u88ab\u4f18\u5316\u591a\u6b21(\u540e\u51e0\u4e2a\u9636\u6bb5\u4e5f\u4f1a\u4f18\u5316\u524d\u51e0\u4e2a\u9636\u6bb5\u7684\u53c2\u6570)\uff0c\u8fd9\u53ef\u4ee5\u5e2e\u52a9\u6a21\u578b\u5728\u6bcf\u4e2a\u9636\u6bb5\u8fdb\u884c\u534f\u540c\u5de5\u4f5c\u3002</p>"},{"location":"fine-grained/paper/PMG1/#_5","title":"\u62fc\u56fe\u751f\u6210\u5668","text":"<p>\u2003\u2003\u4e3a\u4e86\u7ed9\u6e10\u8fdb\u8bad\u7ec3\u4e0d\u540c\u7684\u9636\u6bb5\u751f\u6210\u8f93\u5165\u56fe\u50cf\uff0c\u5f3a\u5236\u6a21\u578b\u5728\u6bcf\u4e2a\u8bad\u7ec3\u9636\u6bb5\u4e2d\u5b66\u4e60\u7279\u5b9a\u4e8e\u76f8\u5e94\u7c92\u5ea6\u7ea7\u522b\u7684\u4fe1\u606f\uff0c\u4f5c\u8005\u5229\u7528\u62fc\u56fe\u6e38\u620f\u7684\u601d\u60f3\uff0c\u8bbe\u8ba1\u4e86\u62fc\u56fe\u751f\u6210\u5668\u6a21\u5757\uff0c\u8be5\u6a21\u5757\u53ef\u4ee5\u5c06\u539f\u56fe\u7684\u7c92\u5ea6\u4fe1\u606f\u89c4\u5b9a\u5230\u4e00\u5b9a\u7684\u7ea7\u522b\u4e2d\uff0c\u751f\u6210\u7c7b\u4f3c\u6253\u4e71\u540e\u7684\u62fc\u56fe\u56fe\u50cf\uff0c\u62fc\u56fe\u5757\u7684\u5927\u5c0f\u53cd\u5e94\u4e86\u7c92\u5ea6\u7684\u7b49\u7ea7\uff0c\u901a\u8fc7\u5b66\u4e60\u8be5\u56fe\uff0c\u53ef\u4ee5\u8feb\u4f7f\u7f51\u7edc\u5b66\u4e60\u8be5\u7b49\u7ea7\u7684\u7c92\u5ea6\u4fe1\u606f\u3002</p> <p>\u2003\u2003\u7ed9\u5b9a\u4e00\u4e2a\u5bbd\u4e0e\u9ad8\u4e3aW\u548cH\u7684\u56fe\u50cf\uff0c\u6211\u4eec\u5c06\u5b83\u5e73\u5747\u5206\u6210n\u00d7n\u4e2a\u8865\u4e01\uff0c\u6bcf\u4efd\u56fe\u50cf\u5927\u5c0f\u5747\u4e3a(W/n, H/n)\uff0c\u9700\u6ce8\u610f\u7684\u662f\uff0cn\u5fc5\u987b\u53ef\u4ee5\u6574\u9664\u56fe\u50cf\u7684\u5bbdW\u4e0e\u9ad8H\u3002\u7136\u540e\u518d\u5c06\u8865\u4e01\u7684\u987a\u5e8f\u6253\u4e71\uff0c\u4f7f\u5176\u4ee5\u7279\u5b9a\u7684\u7c92\u5ea6\u7ea7\u522b\u8868\u793a\u539f\u56fe\u50cf\u7684\u4fe1\u606f\uff0c\u751f\u6210\u65b0\u7684\u56fe\u50cfP(d, n)\uff0c\u5176\u4e2d\uff0c\u56fe\u50cf\u7684\u7c92\u5ea6\u7ea7\u522b\u7531\u8d85\u53c2\u6570n\u63a7\u5236\u3002</p> <p>\u2003\u2003\u5173\u4e8e\u8d85\u53c2\u6570n\u7684\u9009\u62e9\uff0c\u9700\u6ee1\u8db3\u4ee5\u4e0b\u4e24\u4e2a\u6761\u4ef6\uff1a</p> <p>\u2003\u2003\uff081\uff09\u8865\u4e01(\u7c92\u5ea6\u7ea7\u522b)\u7684\u5927\u5c0f\u8981\u5c0f\u4e8e\u5bf9\u5e94\u9636\u6bb5\u7684\u611f\u53d7\u91ce\uff08\u4e5f\u5c31\u662fpatch\u7684\u5927\u5c0f\u8981\u5927\u4e8e\u611f\u53d7\u91ce\u5927\u5c0f\uff09\uff0c\u5426\u5219\u4f1a\u964d\u4f4e\u62fc\u56fe\u751f\u6210\u5668\u7684\u6027\u80fd\uff1b</p> <p>\u2003\u2003\uff082\uff09\u8865\u4e01\u7684\u5927\u5c0f\u9700\u8981\u968f\u7740\u5404\u9636\u6bb5\u611f\u53d7\u91ce\u7684\u589e\u52a0\u800c\u6210\u6bd4\u4f8b\u5730\u589e\u52a0\u3002</p> <p>\u2003\u2003\u6ce8\u610f\uff1a\u901a\u5e38\u4e24\u4e2a\u76f8\u90bb\u7684\u9636\u6bb5\u611f\u53d7\u91ce\u662f\u4e24\u500d\u7684\u5173\u7cfb\uff0c\u56e0\u6b64\u4e24\u4e2a\u76f8\u90bb\u9636\u6bb5\u7684\u7279\u5f81\u56fe\u7c92\u5ea6\u7b49\u7ea7\u4e5f\u662f\u4e24\u500d\u5173\u7cfb\uff0c\u6700\u540e\u4e00\u9636\u6bb5\u7684\u8f93\u5165\u4e3a\u539f\u56fe\u50cf\uff0c\u5373\u7c92\u5ea6\u7ea7\u522b\u6700\u5927\u7684\u56fe\u50cf\uff0c\u5012\u6570\u7b2c\u4e8c\u9636\u6bb5\u56fe\u50cf\u88ab\u5e73\u5747\u5212\u5206\u4e3a2\u00d72\u4efd(\u5177\u4f53\u53ef\u89c1\u7f51\u7edc\u7ed3\u6784\u56fe)\uff0c\u518d\u5f80\u524d\u56fe\u50cf\u88ab\u5e73\u5747\u5212\u5206\u4e3a4\u00d74\u4efd\uff0c\u4f9d\u6b21\u7c7b\u63a8\u3002</p> <p>\u2003\u2003\u9700\u6ce8\u610f\u7684\u662f\uff0c\u62fc\u56fe\u751f\u6210\u5668\u4e0d\u80fd\u603b\u662f\u4fdd\u8bc1\u6240\u6709\u5c0f\u4e8e\u8865\u4e01\u7684\u90e8\u5206\u662f\u5b8c\u6574\u7684\uff0c\u6709\u53ef\u80fd\u4f1a\u5c06\u67d0\u4e2a\u533a\u57df\u62c6\u5206\u3002\u4f46\u8fd9\u5e76\u4e0d\u4f1a\u59a8\u788d\u6a21\u578b\u7684\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u56e0\u4e3a\u4f5c\u8005\u91c7\u7528\u4e86\u968f\u673a\u88c1\u526a\u7b56\u7565\uff08\u7528\u4e8e\u6570\u636e\u7684\u6269\u5145\uff0c\u5177\u4f53\u5b9e\u73b0\u8fc7\u7a0b\u53ef\u89c1\u6e90\u7801\uff09\uff0c\u56e0\u6b64\u5373\u4f7f\u662f\u540c\u4e00\u5f20\u56fe\u7247\uff0c\u5b83\u6bcf\u6b21\u4e5f\u662f\u4ee5\u4e0d\u540c\u7684\u89d2\u5ea6\u53c2\u4e0e\u8bad\u7ec3\u7684\uff0c\u6240\u4ee5\u6bcf\u6b21\u5212\u5206\u7684\u8865\u4e01\u4e5f\u5e76\u4e0d\u662f\u5b8c\u5168\u4e00\u6837\u7684\uff0c\u62fc\u56fe\u751f\u6210\u5668\u5e76\u4e0d\u4f1a\u5728\u6bcf\u6b21\u8fed\u4ee3\u4e2d\u5c06\u8f83\u5c0f\u7684\u8fa8\u8bc6\u90e8\u4f4d\u5206\u5272\u3002\u8fd9\u53cd\u800c\u4f1a\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5e26\u6765\u4e00\u4e2a\u989d\u5916\u7684\u4f18\u52bf\uff0c\u8feb\u4f7f\u6a21\u578b\u5728\u7279\u5b9a\u7684\u7c92\u5ea6\u7ea7\u522b\u4e0a\u627e\u5230\u66f4\u591a\u6709\u533a\u522b\u7684\u90e8\u5206\u3002</p>"},{"location":"fine-grained/paper/PMG1/#_6","title":"\u6d4b\u8bd5","text":"<p>\u2003\u2003\u5728\u6d4b\u8bd5\u6b65\u9aa4\u4e2d\uff0c\u53ea\u9700\u8981\u5c06\u539f\u56fe\u8f93\u5165\u5230\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u4e2d\u5373\u53ef\uff0c\u4e0d\u9700\u8981\u5229\u7528\u62fc\u56fe\u751f\u6210\u5668\u5c06\u5176\u6253\u4e71\u3002\u8be5\u6a21\u578b\u53ef\u4ee5\u751f\u6210\u4e24\u79cd\u9884\u6d4b\u6982\u7387\uff1a</p> <p>\u2003\u2003\uff081\uff09C1\uff1a\u53ea\u4f7f\u7528\u878d\u5408\u540e\u7684\u7279\u5f81\u56fe\u6765\u9884\u6d4b\u6700\u7ec8\u7684\u7c7b\u522b\u6982\u7387\uff0c\u53ef\u4ee5\u5220\u9664\u524dS\u4e2a\u9636\u6bb5\u7684\u5168\u8fde\u63a5\u5c42\uff0c\u4ece\u800c\u51cf\u5c11\u8ba1\u7b97\u91cf\uff0c\u6700\u7ec8\u7ed3\u679cC1\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ C_1=argmax(y^{concat}) $$  \u5176\u4e2d\uff0cy^{concat}\u8868\u793a\u878d\u5408\u540e\u7279\u5f81\u56fe\u7684\u9884\u6d4b\u6982\u7387(\u7ea7\u8054\u9636\u6bb5\u7684\u9884\u6d4b)\u3002</p> <p>\u2003\u2003\uff082\uff09C2\uff1a\u57fa\u4e8e\u7279\u5b9a\u7c92\u5ea6\u4fe1\u606f\u7684\u8f93\u51fa\u9884\u6d4b\u662f\u552f\u4e00\u5e76\u4e14\u4e92\u8865\u7684\uff0c\u5f53\u4ee5\u76f8\u7b49\u7684\u6743\u91cd\u5c06\u6240\u6709\u7684\u8f93\u51fa\u7ec4\u5408\u5728\u4e00\u8d77\u65f6\uff0c\u53ef\u4ee5\u8fbe\u5230\u66f4\u597d\u7684\u6027\u80fd\uff0c\u591a\u8f93\u51fa\u7ec4\u5408\u9884\u6d4bC2\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ C_2=argmax(\\sum^L_{l=L-S+1}y^l+y^{concat}) $$ </p>"},{"location":"fine-grained/paper/PMG1/#_7","title":"\u5b9e\u9a8c","text":""},{"location":"fine-grained/paper/PMG1/#_8","title":"\u53ef\u89c6\u5316","text":"<p>\u2003\u2003\u4f5c\u8005\u5229\u7528\u4e86GradCAM\u5b9e\u73b0\u4e86\u5bf9PMG\u6a21\u578b\u548c\u57fa\u7ebf\u6a21\u578b(\u7eaf\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u8bad\u7ec3)\u6700\u540e\u4e09\u4e2a\u9636\u6bb5\u7684\u5377\u79ef\u5c42\u53ef\u89c6\u5316\uff0c\u5bf9\u6bd4\u56fe\u5982\u4e0b\uff1a</p> <p> <p></p> <p></p> <p>\u57fa\u7ebf\u7f51\u7edc\u4ee5ResNet50\u4e3a\u4f8b\uff0c\u5217(a)-\u00a9\u662fPMG\u6a21\u578b\u7684\u7b2c3\u9636\u6bb5\u5230\u7b2c\u4e94\u9636\u6bb5\u7684\u5377\u79ef\u5c42\u53ef\u89c6\u5316\uff0c\u5217(d)-(f)\u662f\u57fa\u7ebf\u7f51\u7edc\u7684\u7b2c\u4e09\u9636\u6bb5\u5230\u7b2c\u4e94\u9636\u6bb5\u7684\u5377\u79ef\u5c42\u53ef\u89c6\u5316\u3002</p> <p>\u2003\u2003\uff08a\uff09\u5217\u8868\u660e\uff0c\u6a21\u578b\u5728\u7b2c\u4e09\u9636\u6bb5\u96c6\u4e2d\u5173\u6ce8\u56fe\u50cf\u7684\u5c0f\u7c92\u5ea6\u5224\u522b\u533a\u57df\uff0c\u5982\u9e1f\u7684\u773c\u775b\u3001\u7fbd\u6bdb\u56fe\u6848\u6216\u8005\u7eb9\u7406\uff0c\u800c( c )\u8868\u660e\uff0c\u6a21\u578b\u5728\u7b2c\u4e94\u9636\u6bb5\u66f4\u4fa7\u91cd\u5173\u6ce8\u56fe\u7247\u7684\u6574\u4f53\u7ed3\u6784\u4fe1\u606f\uff0c\u56e0\u6b64\uff0c\u672c\u6a21\u578b\u53ef\u4ee5\u5f88\u597d\u5730\u7ed9\u51fa\u57fa\u4e8e\u5c0f\u7c92\u5ea6\u5230\u5927\u7c92\u5ea6\u7684\u533a\u5206\u90e8\u4f4d\u9884\u6d4b\u3002\u800c\u57fa\u7ebf\u6a21\u578b\u53ea\u663e\u793a\u4e86\u6700\u540e\u9636\u6bb5\u7684\u6b63\u786e\u6ce8\u610f\u529b\uff0c\u8fd9\u79cd\u5bf9\u6bd4\u8868\u660e\u6e10\u8fdb\u8bad\u7ec3\u7684\u4e2d\u95f4\u76d1\u7763\u8fc7\u7a0b\u53ef\u4ee5\u5f88\u597d\u5730\u5e2e\u52a9\u6a21\u578b\u5728\u65e9\u671f\u9636\u6bb5\u5b9a\u4f4d\u6709\u7528\u7684\u4fe1\u606f\u3002\u53e6\u5916\uff0c\u57fa\u7ebf\u6a21\u578b\u5728\u6700\u540e\u7684\u5173\u6ce8\u533a\u57df\u901a\u5e38\u53ea\u96c6\u4e2d\u5728\u7269\u4f53\u7684\u4e00\u4e24\u4e2a\u90e8\u5206\uff0c\u800c\u672c\u6a21\u578b\u7684\u6ce8\u610f\u529b\u5173\u6ce8\u533a\u57df\u51e0\u4e4e\u53ef\u4ee5\u8986\u76d6\u6574\u4e2a\u5bf9\u8c61\uff0c\u8fd9\u79cd\u5bf9\u6bd4\u8868\u660e\u62fc\u56fe\u751f\u6210\u5668\u751f\u6210\u7684\u56fe\u50cf\u53ef\u4ee5\u8feb\u4f7f\u6a21\u578b\u5728\u6bcf\u4e2a\u7c92\u5ea6\u7ea7\u522b\u5b66\u4e60\u66f4\u591a\u6709\u533a\u5206\u5ea6\u7684\u90e8\u4f4d\u3002</p>"},{"location":"fine-grained/paper/PMG1/#_9","title":"\u7cbe\u5ea6\u5bf9\u6bd4","text":"<p> <p></p> <p></p>"},{"location":"fine-grained/paper/PMG1/#_10","title":"\u603b\u7ed3","text":"<p>\u2003\u2003\u672c\u6587\u5c06\u6e10\u8fdb\u8bad\u7ec3\u7b56\u7565\u5e94\u7528\u5230\u7ec6\u7c92\u5ea6\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u7c92\u5ea6(PMG)\u8bad\u7ec3\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u4e3b\u8981\u7531\u4e24\u90e8\u5206\u7ec4\u6210\uff1a\u2460\u4ee5\u6e10\u8fdb\u65b9\u5f0f\u878d\u5408\u591a\u7c92\u5ea6\u7279\u5f81\u7684\u65b0\u578b\u8bad\u7ec3\u7b56\u7565\uff1b\u2461\u7528\u4e8e\u5f62\u6210\u5305\u542b\u4e0d\u540c\u7c92\u5ea6\u7ea7\u522b\u4fe1\u606f\u56fe\u50cf\u7684\u62fc\u56fe\u751f\u6210\u5668\u3002\u901a\u8fc7\u5c06\u8be5\u4e24\u4e2a\u6a21\u578b\u52a0\u4ee5\u7ec4\u5408\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u4f7f\u7f51\u7edc\u5b66\u4e60\u4e0d\u540c\u7ea7\u522b\u7684\u7c92\u5ea6\u4fe1\u606f\uff0c\u5e76\u4e14\u53ef\u4ee5\u4f7f\u5404\u7c92\u5ea6\u95f4\u7684\u7279\u5f81\u76f8\u878d\u5408\uff0c\u5145\u5206\u5730\u8ba9\u7f51\u7edc\u63a2\u7d22\u4ed6\u4eec\u4e4b\u95f4\u7684\u4e92\u8865\u5173\u7cfb\u3002</p> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u5927\u5bb6\u6279\u8bc4\u6307\u6b63\u3002</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e7411\u670822\u65e5</p>"},{"location":"fine-grained/paper/RA-CNN1/","title":"\u7ec6\u7c92\u5ea6\uff1aRA-CNN","text":""},{"location":"fine-grained/paper/RA-CNN1/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aIEEE Conference on Computer Vision and Pattern Recognition 2017 (CVPR, 2017)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content_cvpr_2017/papers/Fu_Look_Closer_to_CVPR_2017_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740(PyTorch\u7248\u672c)\uff1ahttps://github.com/jeong-tae/RACNN-pytorch</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u7c7b(FGVC)</p> <p>\u5173\u952e\u8bcd\uff1a\u6ce8\u610f\u529b\u673a\u5236\u3001\u7ec6\u7c92\u5ea6\u8bc6\u522b\u3001\u591a\u5c3a\u5ea6\u533a\u57df\u5b9a\u4f4d</p>"},{"location":"fine-grained/paper/RA-CNN1/#_2","title":"\u4e3b\u8981\u601d\u60f3","text":"<p>\u2003\u2003\u7ec6\u7c92\u5ea6\u8bc6\u522b\u4efb\u52a1\u4e3b\u8981\u5728\u4e8e\u6709\u533a\u5206\u5ea6\u533a\u57df\u7684\u5b9a\u4f4d\u548c\u7ec6\u7c92\u5ea6\u7279\u5f81\u7684\u5b66\u4e60\uff0c\u73b0\u6709\u7684\u65b9\u6cd5\u4e3b\u8981\u662f\u72ec\u7acb\u5730\u89e3\u51b3\u8fd9\u4e24\u4e2a\u95ee\u9898\uff0c\u5728\u533a\u57df\u5b9a\u4f4d\u7684\u5b66\u4e60\u4e2d\uff0c\u4f20\u7edf\u7684\u7ec6\u7c92\u5ea6\u8bc6\u522b\u7b97\u6cd5\u53c8\u9700\u8981\u989d\u5916\u7684\u4eba\u5de5\u6807\u6ce8\uff0c\u8fd9\u6837\u505a\u4e0d\u4ec5\u5de5\u4f5c\u91cf\u5927\uff0c\u800c\u4e14\u5bb9\u6613\u53d7\u5230\u4e3b\u89c2\u56e0\u7d20\u7684\u5e72\u9884\u3002\u4f5c\u8005\u53d1\u73b0\u533a\u57df\u5b9a\u4f4d\u548c\u7279\u5f81\u5b66\u4e60\u53ef\u4ee5\u76f8\u4e92\u4fc3\u8fdb\uff0c\u63d0\u51fa\u4e86\u5faa\u73af\u6ce8\u610f\u529b\u7f51\u7edc\uff0c\u7f51\u7edc\u7684\u6838\u5fc3\u7ed3\u6784\u662f\u6ce8\u610f\u529b\u5efa\u8bae\u5b50\u7f51\u7edc(APN\u6a21\u5757)\uff0c\u53ea\u9700\u8981\u63d0\u4f9b\u56fe\u7247\u7684\u6807\u7b7e\uff0c\u5c31\u53ef\u4ee5\u8ba9\u8be5\u5b50\u7f51\u7edc\u8fed\u4ee3\u4ea7\u751f\u7531\u7c97\u5230\u7ec6\u7684\u591a\u5c3a\u5ea6\u6ce8\u610f\u529b\u533a\u57df\uff0c\u8fdb\u4e00\u6b65\u5c06\u5176\u88c1\u526a\u653e\u5927\uff0c\u5b66\u4e60\u653e\u5927\u540e\u7684\u5fae\u5c0f\u5dee\u5f02\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u63d0\u9ad8\u7ec6\u7c92\u5ea6\u7279\u5f81\u63d0\u53d6\u7684\u80fd\u529b\uff1b\u5e76\u4e14\u63d0\u51fa\u4e86\u5229\u7528\u5c3a\u5ea6\u5185\u5206\u7c7b\u635f\u5931\u6765\u4f18\u5316\u7279\u5f81\u63d0\u53d6\u80fd\u529b\u3001\u5229\u7528\u5c3a\u5ea6\u95f4\u6392\u5e8f\u635f\u5931\u6765\u4f18\u5316\u533a\u57df\u5b9a\u4f4d\u80fd\u529b\uff0c\u5e76\u4e14\u8fd8\u63d0\u51fa\u4e86\u4ea4\u66ff\u5b66\u4e60\u7684\u8bad\u7ec3\u7b56\u7565\uff0c\u8ba9\u7279\u5f81\u63d0\u53d6\u5b66\u4e60\u548c\u533a\u57df\u5b9a\u4f4d\u5b66\u4e60\u4e92\u76f8\u4fc3\u8fdb\uff0c\u4ea4\u66ff\u4f18\u5316\u3002</p> <p> <p></p> <p></p> <p>\u2003\u2003\u9996\u5148\u539f\u56fe\u50cf\u8f93\u5165\u5230\u7f51\u7edc\u4e2d\uff0c\u4f5c\u4e3a\u7c97\u5c3a\u5ea6\uff0c\u7ecf\u8fc7\u6ce8\u610f\u529b\u7f51\u7edc\uff0c\u5f97\u5230\u6ce8\u610f\u529b\u533a\u57df\uff0c\u8fdb\u4e00\u6b65\u5c06\u8be5\u533a\u57df\u88c1\u526a\u653e\u5927\uff0c\u5f97\u5230\u7cbe\u7ec6\u5c3a\u5ea6\u3002</p>"},{"location":"fine-grained/paper/RA-CNN1/#_3","title":"\u7f51\u7edc\u7684\u4e3b\u8981\u6d41\u7a0b","text":"<p>\u5177\u4f53\u6d41\u7a0b\u89c1\u4e0b\u56fe\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u9996\u5148\uff0c\u5148\u5c06\u539f\u56fe\u50cf\u7ecf\u8fc7\u7ecf\u5178\u7684\u7279\u5f81\u63d0\u53d6\u7f51\u7edc(\u6d41\u7a0b\u56fe\u4e2d\u7684b1\u3001b2\u3001b3)\u8fdb\u884c\u63d0\u53d6\u7279\u5f81\uff0c\u5f97\u5230\u7279\u5f81\u56fe\uff0c\u5177\u4f53\u516c\u5f0f\u5982\u4e0b\uff1a $$ P(X)=f(W_c*X) $$ </p> <p>\u5176\u4e2dW_c\u8868\u793a\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u7684\u53c2\u6570\uff0c*\u8868\u793a\u5377\u79ef\u8fd0\u7b97\uff0cX\u8868\u793a\u539f\u56fe\u50cf</p> <p>\u2003\u2003\u4e4b\u540e\u7279\u5f81\u56fe\u6709\u4e24\u4e2a\u53bb\u5411\uff0c\u7b2c\u4e00\u662f\u7279\u5f81\u56fe\u518d\u7ecf\u8fc7\u5168\u8fde\u63a5\u5c42(\u6d41\u7a0b\u56fe\u4e2d\u7684c1\u3001c2\u3001c3)\u4ee5\u53casoftmax\u51fd\u6570\uff0c\u5f97\u5230\u7b2c\u4e00\u5c3a\u5ea6\u56fe\u50cf\u7684\u9884\u6d4b\u6982\u7387\uff1b\u7b2c\u4e8c\u662f\u901a\u8fc7\u5bf9\u539f\u7279\u5f81\u56fe\u8fdb\u884c\u67d0\u79cd\u8fd0\u7b97\uff0c\u5f97\u5230\u56fe\u50cf\u7684\u6ce8\u610f\u529b\u533a\u57df\uff0c\u6ce8\u610f\u529b\u533a\u57df\u53ef\u4ee5\u8fd1\u4f3c\u4e3a\u7531\u4e09\u4e2a\u53c2\u6570\u786e\u5b9a\u7684\u6b63\u65b9\u5f62\uff0c\u5177\u4f53\u8868\u8fbe\u5f0f\u5982\u4e0b\uff1a $$ [t_x,t_y,t_l]=g(W_c*X) $$  \u5176\u4e2d\uff0ct_x\u548ct_y\u8868\u793a\u6b63\u65b9\u5f62\u7684\u4e2d\u5fc3\u5750\u6807\uff0ct_l\u8868\u793a\u6b63\u65b9\u5f62\u8fb9\u957f\u7684\u4e00\u534a\uff0cg(\u00b7)\u53ef\u4ee5\u8868\u793a\u4e3a\u4e24\u4e2a\u5806\u53e0\u7684\u5168\u8fde\u63a5\u5c42\u6765\u8868\u793a\uff0c\u7531\u4e8e\u672c\u6587\u4e2d\u7684APN\u6a21\u5757(\u6d41\u7a0b\u56fe\u4e2d\u7684d_1\u3001d_2)\u662f\u4ee5\u5f31\u76d1\u7763\u7684\u65b9\u5f0f\u8bad\u7ec3\u7684\uff0c\u6ca1\u6709\u771f\u5b9e\u6807\u7b7e\u53ef\u4ee5\u505a\u6bd4\u5bf9\uff0c\u56e0\u6b64\uff0c\u5fc5\u987b\u901a\u8fc7\u7279\u6b8a\u7684\u635f\u5931\u51fd\u6570\u52a0\u4ee5\u7ea6\u675f\uff0c\u4ece\u800c\u8ba9\u7f51\u7edc\u7684\u6ce8\u610f\u529b\u533a\u57df\u671d\u7269\u4f53\u6240\u5728(\u6709\u533a\u5206\u5ea6\u533a\u57df)\u7684\u65b9\u5411\u79fb\u52a8\uff0c\u8bad\u7ec3\u8fc7\u7a0b\u4ee5\u53ca\u635f\u5931\u51fd\u6570\u5728\u4e0b\u6587\u4e2d\u8bb2\u89e3\u3002</p> <p>\u2003\u2003\u5f97\u5230\u6ce8\u610f\u529b\u533a\u57df\u4e4b\u540e\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u4ee5\u66f4\u9ad8\u7684\u5206\u8fa8\u7387\u5173\u6ce8\u90a3\u4e9b\u6709\u533a\u5206\u5ea6\u7684\u533a\u57df\uff0c\u5c06\u539f\u56fe\u50cf\u8fdb\u884c\u88c1\u526a\u653e\u5927\uff0c\u653e\u5927\u56fe\u50cf\u7684\u5fae\u5c0f\u5dee\u5f02\uff0c\u4ece\u800c\u66f4\u597d\u5730\u63d0\u53d6\u56fe\u50cf\u7684\u7ec6\u7c92\u5ea6\u7279\u5f81\u3002\u4e3a\u4e86\u80fd\u8ba9\u6ce8\u610f\u529b\u533a\u57df\u7684\u5b9a\u4f4d\u8fc7\u7a0b\u5728\u8bad\u7ec3\u4e2d\u5f97\u5230\u4f18\u5316\uff0c\u5373\u8ba9\u8be5\u8fc7\u7a0b\u53d8\u6210\u4e00\u7cfb\u5217\u7684\u8fde\u7eed\u51fd\u6570(\u53ea\u6709\u5f53\u51fd\u6570\u662f\u8fde\u7eed\u51fd\u6570\u65f6\uff0c\u624d\u80fd\u8fdb\u884c\u53cd\u5411\u4f20\u64ad\u3001\u66f4\u65b0\u53c2\u6570)\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u4e8c\u7ef4\u8109\u51b2\u51fd\u6570\u6765\u8fd1\u4f3c\u8ba1\u7b97\u5f97\u5230\u6ce8\u610f\u529b\u533a\u57df\u7684\u65b9\u6cd5\u3002</p>"},{"location":"fine-grained/paper/RA-CNN1/#_4","title":"\u4e8c\u7ef4\u8109\u51b2\u51fd\u6570\u2014\u2014\u6ce8\u610f\u529b\u63a9\u6a21","text":"<p>\u2003\u2003\u5047\u8bbe\u539f\u59cb\u56fe\u50cf\u4e2d\u7684\u5de6\u4e0a\u89d2\u662f\u539f\u70b9\uff0cx\u8f74\u4e0ey\u8f74\u5206\u522b\u4ee5\u4ece\u5de6\u5230\u53f3\u3001\u4ece\u4e0a\u5230\u4e0b\u7684\u65b9\u5411\u4e3a\u6b63\u65b9\u5411\uff0c\u88c1\u526a\u7684\u77e9\u5f62\u533a\u57df\u53ef\u4ee5\u7531\u5de6\u4e0a\u89d2\u548c\u53f3\u4e0b\u89d2\u4e24\u4e2a\u5750\u6807\u70b9\u8868\u793a\uff0c\u4e24\u4e2a\u70b9\u7684\u8ba1\u7b97\u516c\u5f0f\u5982\u4e0b\uff1a $$ t_{x(tl)}=t_x-t_l,\\quad t_{y(tl)}=t_y-t_l,\\\\ t_{x(br)}=t_x+t_l,\\quad t_{y(br)}=t_y+t_l. $$  \u5176\u4e2d\uff0ct_{x(tl)}\u4e0et_{y(tl)}\u786e\u5b9a\u5de6\u4e0a\u89d2\u7684\u70b9\uff0ct_{x(br)}\u4e0et_{y(br)}\u786e\u5b9a\u53f3\u4e0b\u89d2\u7684\u70b9\u3002</p> <p>\u2003\u2003\u5f53\u5f97\u5230\u6ce8\u610f\u529b\u533a\u57df\u7684\u5750\u6807\u65f6\uff0c\u53ef\u4ee5\u901a\u8fc7\u8be5\u5750\u6807\u786e\u5b9a\u4e00\u4e2a\u6ce8\u610f\u529b\u63a9\u6a21\u56fe\uff0c\u8be5\u56fe\u4e0e\u539f\u56fe\u50cf\u5927\u5c0f\u4e00\u81f4\uff0c\u56fe\u4e0a\u7684\u6570\u636e\u53ef\u4ee5\u6709\u6548\u5730\u4ee3\u8868\u539f\u56fe\u7684\u6ce8\u610f\u529b\u533a\u57df\u5206\u5e03\uff0c\u9760\u8fd1\u6ce8\u610f\u529b\u533a\u57df\u7684\u6570\u636e\u7cfb\u6570\u8d8b\u8fd1\u4e8e1\uff0c\u8fdc\u79bb\u6ce8\u610f\u529b\u533a\u57df\u7684\u6570\u636e\u7cfb\u6570\u8d8b\u8fd1\u4e8e0\u3002\u6700\u7406\u60f3\u7684\u662f\u901a\u8fc7\u9636\u8dc3\u51fd\u6570\u6765\u5b9e\u73b0\uff0c\u4f46\u7531\u4e8e\u9636\u8dc3\u51fd\u6570\u4e0d\u8fde\u7eed\uff0c\u56e0\u6b64\u53ea\u80fd\u9009\u4e00\u4e2a\u65e0\u9650\u63a5\u8fd1\u4e8e\u9636\u8dc3\u51fd\u6570\u7684\u8fde\u7eed\u51fd\u6570\u6765\u751f\u6210\u6ce8\u610f\u529b\u63a9\u6a21\u3002\u5728\u8fd9\u7bc7\u6587\u7ae0\u4e2d\uff0c\u4f5c\u8005\u5f15\u5165\u4e86\u5e26\u6709\u7cfb\u6570k\u7684sigmoid\u51fd\u6570\uff0c\u8be5\u51fd\u6570\u5b9a\u4e49\u5982\u4e0b\uff1a $$ h(x)=\\frac{1}{1+e^{-kx}} $$ </p> <p> <p></p> <p></p> <p>\u2003\u2003k\u8d8a\u5927\uff0c\u51fd\u6570\u56fe\u50cf\u8d8a\u9661\uff0c\u5f53k\u8db3\u591f\u5927\u65f6\uff0c\u5c31\u53ef\u4ee5\u8fd1\u4f3c\u6210\u9636\u8dc3\u51fd\u6570\u3002\u6784\u5efa\u597d\u8fd1\u4f3c\u9636\u8dc3\u51fd\u6570\u7684h(\u00b7)\u65f6\uff0c\u518d\u6784\u5efa\u5982\u4e0b\u51fd\u6570\uff0c\u8ba1\u7b97\u5f97\u5230\u6ce8\u610f\u529b\u63a9\u6a21\u56fe\uff1a $$ M(\u00b7)=[h(x-t_{x(tl)})-h(x-t_{x(br)})]\u00b7[h(y-t_{y(tl)})-h(y-t_{y(br)})] $$  \u5176\u4e2d\uff0cx\uff0cy\u662f\u5f53\u524d\u70b9\u7684\u5750\u6807</p> <p>\u6ce8\u610f\u529b\u63a9\u6a21\u56fe\u8ba1\u7b97\u8fc7\u7a0b\u7684\u901a\u4fd7\u89e3\u91ca\uff1a \u2003\u2003\u5b9a\u4f4d\u6ce8\u610f\u529b\u533a\u57df\u7684\u4e24\u4e2a\u5750\u6807\u70b9\u53ef\u4ee5\u5c06\u539f\u56fe\u50cf\u5212\u5206\u4e3a\u4e5d\u4e2a\u533a\u57df\uff0c\u5177\u4f53\u89c1\u4e0b\u56fe</p> <p> <p></p> <p></p> <p>\u5176\u4e2d\u2464\u53f7\u533a\u57df\u4e3a\u6ce8\u610f\u529b\u533a\u57df\uff0c\u4e24\u4e2a\u84dd\u70b9\u4e3a\u7528\u4e8e\u5b9a\u4f4d\u533a\u57df\u7684\u5750\u6807\u70b9</p> <p>\u4ee5x\u4e3a\u4f8b\uff1a</p> <ul> <li> <p>\u5f53x&lt;t_{x(tl)}\uff0c\u5373\u5750\u6807\u70b9\u4f4d\u4e8e\u2460\u2463\u2466\u65f6\uff0cx-t_{x(tl)}&lt;0\u5e76\u4e14x-t_{x(br)}&lt;0\uff0c\u56e0\u6b64h(x-t_{x(tl)})\u2248h(x-t_{x(br)})\u22480</p> </li> <li> <p>\u5f53t_{x(tl)}&lt;x&lt;t_{x(br)}\uff0c\u5373\u5750\u6807\u70b9\u4f4d\u4e8e\u2461\u2464\u2467\u65f6\uff0cx-t_{x(tl)}&gt;0\u5e76\u4e14x-t_{x(br)}&lt;0\uff0c\u56e0\u6b64h(x-t_{x(tl)})\u22481,h(x-t_{x(br)})\u22480</p> </li> <li> <p>\u5f53t_{x(br)}&lt;x\uff0c\u5373\u5750\u6807\u70b9\u4f4d\u4e8e\u2462\u2465\u2468\u65f6\uff0cx-t_{x(tl)}&gt;0\u5e76\u4e14x-t_{x(br)}&gt;0\uff0c\u56e0\u6b64h(x-t_{x(tl)})\u2248h(x-t_{x(br)})\u22481</p> </li> </ul> <p>\u2003\u2003\u56e0\u6b64\uff0c\u53ea\u6709\u5f53x\u4f4d\u4e8e\u2461\u2464\u2467\u8303\u56f4\u5185\u65f6\uff0cM(\u00b7)\u624d\u6709\u53ef\u80fd\u4e0d\u4e3a\u96f6\uff1b\u540c\u7406\uff0c\u53ea\u6709\u5f53y\u4f4d\u4e8e\u2463\u2464\u2465\u65f6\uff0cM(\u00b7)\u624d\u6709\u53ef\u80fd\u4e0d\u4e3a\u96f6\u3002\u7efc\u4e0a\u6240\u8ff0\uff0c\u53ea\u6709\u5f53x,y\u540c\u65f6\u4f4d\u4e8e\u6ce8\u610f\u529b\u6240\u5173\u6ce8\u7684\u533a\u57df\u65f6\uff0c\u6ce8\u610f\u529b\u63a9\u6a21\u56fe\u4e0a\u7684\u6570\u636e\u624d\u8d8b\u8fd1\u4e8e1\uff0c\u5426\u5219\u6570\u636e\u8d8b\u8fd1\u4e8e\u96f6\uff0c\u56e0\u6b64\uff0c\u8be5\u6ce8\u610f\u529b\u63a9\u6a21\u56fe\u53ef\u4ee5\u6709\u6548\u5730\u4ee3\u8868\u6ce8\u610f\u529b\u6240\u5173\u6ce8\u7684\u533a\u57df\u3002</p> <p>\u2003\u2003\u7531\u4e8e\u4e8c\u7ef4\u8109\u51b2\u51fd\u6570\u53ef\u4ee5\u5c06\u5173\u6ce8\u533a\u57df\u548c\u5750\u6807\u70b9\u5efa\u7acb\u8d77\u51fd\u6570\u89e3\u6790\u5f0f\uff0c\u56e0\u6b64\u5728\u53cd\u5411\u4f20\u64ad\u7684\u8fc7\u7a0b\u4e2d\uff0c\u53ef\u4ee5\u5f88\u597d\u5730\u4f18\u5316\u751f\u6210\u5750\u6807\u70b9\u7684\u8fc7\u7a0b\uff0c\u5373APN\u7f51\u7edc\u7684\u53c2\u6570</p>"},{"location":"fine-grained/paper/RA-CNN1/#_5","title":"\u88c1\u526a\u653e\u5927","text":"<p>\u2003\u2003\u57fa\u4e8e\u4e0a\u8ff0\u5f97\u5230\u7684\u6ce8\u610f\u529b\u63a9\u6a21\u56fe\uff0c\u9996\u5148\u5c06\u539f\u56fe\u50cf\u4e0e\u6ce8\u610f\u529b\u63a9\u6a21\u505a\u9010\u5143\u7d20\u70b9\u4e58\u64cd\u4f5c\uff0c\u8ba9\u539f\u56fe\u53ea\u4fdd\u7559\u6ce8\u610f\u529b\u6240\u5173\u6ce8\u7684\u90e8\u5206\uff0c\u5177\u4f53\u516c\u5f0f\u5982\u4e0b\uff1a $$ X^{att}=X\u2299M(t_x,t_y,t_l) $$ </p> <p>\u5176\u4e2d\uff0c\u2299\u8868\u793a\u77e9\u9635\u7684\u70b9\u4e58\u8fd0\u7b97\u3001X^{att}\u8868\u793a\u7ecf\u8fc7\u6ce8\u610f\u529b\u63a9\u6a21\u51f8\u663e\u540e\u7684\u56fe\u50cf</p> <p>\u2003\u2003\u7ecf\u8fc7\u70b9\u4e58\u64cd\u4f5c\u540e\uff0c\u539f\u56fe\u50cf\u7684\u5173\u6ce8\u533a\u57df\u5df2\u7ecf\u88ab\u51f8\u663e\u51fa\u6765\u4e86\uff0c\u4f46\u8fd8\u662f\u96be\u4ee5\u4ece\u56fe\u50cf\u4e2d\u63d0\u53d6\u6709\u6548\u7684\u7279\u5f81\u8868\u793a\uff0c\u56e0\u6b64\uff0c\u4f5c\u8005\u9996\u5148\u5c06\u5173\u6ce8\u533a\u57df\u88c1\u526a\u51fa\u6765\uff0c\u7136\u540e\u91c7\u7528\u4e86\u53cc\u7ebf\u6027\u63d2\u503c\u6620\u5c04\u5c06\u539f\u56fe\u50cf\u7684\u5173\u6ce8\u533a\u57df\u8fdb\u4e00\u6b65\u653e\u5927\uff0c\u8ba1\u7b97\u516c\u5f0f\u5982\u4e0b\uff1a $$ X^{amp}=\\sum^1_{\u03b1,\u03b2=0}|1-\u03b1-\\{\\frac{i}{\u03bb}\\}||1-\u03b2-\\{\\frac{j}{\u03bb}\\}|X^{att}_{(m,n)} $$  \u5176\u4e2d\uff0cX_{(i,j)}^{amp}\u4e3a\u88c1\u526a\u540e\u7684\u56fe\u50cf\uff0cm=[\\frac{i}{\u03bb}]+\u03b1\uff0cn=[\\frac{j}{\u03bb}]+\u03b2\uff0c\u03bb\u4e3a\u4e0a\u91c7\u6837\u56e0\u5b50\uff0c\u7b49\u4e8e\u653e\u5927\u7684\u5c3a\u5bf8\u9664t_l\uff0c[\u00b7]\u548c\\{\u00b7\\}\u5206\u522b\u8868\u793a\u6574\u6570\u90e8\u5206\u548c\u5c0f\u6570\u90e8\u5206</p> <p>\u2003\u2003\u539f\u56fe\u7ecf\u8fc7\u88c1\u526a\u653e\u5927\u64cd\u4f5c\uff0c\u4e0d\u4ec5\u8fc7\u6ee4\u4e86\u65e0\u5173\u7684\u533a\u57df\u4fe1\u606f\uff0c\u8fd8\u51f8\u663e\u4e86\u6709\u533a\u5206\u5ea6\u7684\u90e8\u4f4d\uff0c\u653e\u5927\u4e86\u5fae\u5c0f\u7684\u5dee\u5f02\uff0c\u6709\u5229\u4e8e\u4e0b\u4e00\u5c3a\u5ea6\u7ec6\u7c92\u5ea6\u7279\u5f81\u7684\u5b66\u4e60\u3002</p>"},{"location":"fine-grained/paper/RA-CNN1/#_6","title":"\u635f\u5931\u51fd\u6570","text":"<p>\u2003\u2003\u672c\u6587\u635f\u5931\u51fd\u6570\u4e3b\u8981\u7531\u5c3a\u5ea6\u5185\u5206\u7c7b\u635f\u5931\u4ee5\u53ca\u5c3a\u5ea6\u95f4\u6392\u5e8f\u635f\u5931\u6784\u6210\uff0c\u4e24\u4e2a\u635f\u5931\u4ea4\u66ff\u4f18\u5316\uff0c\u4f7f\u7f51\u7edc\u53ef\u4ee5\u51c6\u786e\u5730\u5b9a\u4f4d\u6ce8\u610f\u529b\u533a\u57df\u5e76\u4e14\u6709\u6548\u5730\u5b66\u4e60\u7ec6\u7c92\u5ea6\u7279\u5f81\u7684\u63d0\u53d6</p>"},{"location":"fine-grained/paper/RA-CNN1/#_7","title":"\u5c3a\u5ea6\u5185\u5206\u7c7b\u635f\u5931","text":"<p>\u2003\u2003\u5c3a\u5ea6\u5185\u5206\u7c7b\u635f\u5931\u5b9a\u4e49\u5982\u4e0b\uff1a $$ L_{cls}(X)=\\sum^3_{s=1}L_{cro}(Y^{(s)},Y^*)\\\\ \u5176\u4e2d\uff0cL_{cls}\u8868\u793a\u5c3a\u5ea6\u5185\u5206\u7c7b\u635f\u5931\uff0cL_{cro}\u8868\u793a\u4ea4\u53c9\u71b5\u635f\u5931\\\\ Y^{(s)}\u8868\u793a\u7b2cs\u5c3a\u5ea6\u7684\u9884\u6d4b\u503c\uff0cY^*\u8868\u793a\u771f\u5b9e\u6807\u7b7e $$  \u2003\u2003\u8be5\u635f\u5931\u4e3b\u8981\u4f18\u5316\u5377\u79ef\u5c42\u548c\u5206\u7c7b\u5c42\u7684\u53c2\u6570\uff0c\u786e\u4fdd\u5728\u6bcf\u4e2a\u5c3a\u5ea6\u4e0b\u90fd\u5177\u6709\u8db3\u591f\u7684\u7279\u5f81\u63d0\u53d6\u80fd\u529b\u3002</p>"},{"location":"fine-grained/paper/RA-CNN1/#_8","title":"\u5c3a\u5ea6\u95f4\u6392\u5e8f\u635f\u5931","text":"<p>\u2003\u2003\u5c3a\u5ea6\u95f4\u6392\u5e8f\u635f\u5931\u5b9a\u4e49\u5982\u4e0b\uff1a $$ L_{rank}(p^{(s)}_t,p^{(s+1)}_t)=max\\{0,p^{(s)}_t-p^{(s+1)}_t+margin\\}\\\\ \u5176\u4e2d\uff0cp^{s}_t\u548cp^{(s+1)}_t\u5206\u522b\u8868\u793a\u7b2cs\u5c3a\u5ea6\u548c\u7b2cs+1\u5c3a\u5ea6\u6b63\u786e\u7c7b\u522b\u4e0a\u7684\u9884\u6d4b\u6982\u7387\uff0cmargin\u4e3a\u8fb9\u754c\u503c $$  \u2003\u2003\u8fd9\u4e2a\u635f\u5931\u51fd\u6570\u8981\u6c42\u7ec6\u5c3a\u5ea6\u7684\u9884\u6d4b\u6982\u7387\u8981\u5927\u4e8e\u7c97\u5c3a\u5ea6\u7684\u9884\u6d4b\u6982\u7387\u52a0\u4e0a\u8fb9\u754c\u503cmargin\u3002\u901a\u8fc7\u8fd9\u4e2a\u635f\u5931\u7684\u4f18\u5316\uff0c\u7f51\u7edc\u4f1a\u4ee5\u7c97\u5c3a\u5ea6\u7684\u9884\u6d4b\u6982\u7387\u4e3a\u53c2\u8003\uff0c\u5e76\u4e14\u4f5c\u7528\u5230\u7ec6\u5c3a\u5ea6\u4e0a\uff0c\u4f7f\u7f51\u7edc\u7684\u6ce8\u610f\u529b\u533a\u57df\u9010\u6e10\u5173\u6ce8\u6700\u6709\u533a\u5206\u5ea6\u7684\u90e8\u4f4d\uff0c\u4ece\u800c\u751f\u6210\u66f4\u9ad8\u6982\u7387\u7684\u9884\u6d4b\u503c\u3002</p> <p>\u2003\u2003\u4e24\u79cd\u635f\u5931\u51fd\u6570\u5bf9\u5e94\u7684\u529f\u80fd\u4e0d\u540c\uff0c\u56e0\u6b64\u53c2\u4e0e\u7684\u4f18\u5316\u8fc7\u7a0b\u4e5f\u4e0d\u540c\uff0c\u5c3a\u5ea6\u5185\u5206\u7c7b\u635f\u5931\u4e3b\u8981\u7528\u4e8e\u7279\u5f81\u63d0\u53d6\u7684\u4f18\u5316\uff0c\u800c\u5c3a\u5ea6\u95f4\u6392\u5e8f\u635f\u5931\u4e3b\u8981\u7528\u4e8e\u6ce8\u610f\u529b\u533a\u57df\u5b9a\u4f4d\u7684\u4f18\u5316\uff0c</p>"},{"location":"fine-grained/paper/RA-CNN1/#_9","title":"\u8bad\u7ec3\u6d41\u7a0b","text":"<p>\u2003\u2003\u9996\u5148\uff0c\u4e09\u4e2a\u5c3a\u5ea6\u7684\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u90fd\u521d\u59cb\u5316\u4e3aVGG19(\u8fd9\u91cc\u4e5f\u53ef\u4ee5\u6362\u6210\u5176\u4ed6\u7684\u6a21\u578b)\uff0c\u5e76\u4e14\u52a0\u8f7dImageNet\u8bad\u7ec3\u597d\u7684\u9884\u8bad\u7ec3\u53c2\u6570</p> <p>APN\u7684\u9884\u8bad\u7ec3\uff1a</p> <p>\u2003\u2003\u9996\u5148\u5bf9APN\u7f51\u7edc\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u7531\u4e8e\u56fe\u50cf\u7ecf\u8fc7\u7279\u5f81\u63d0\u53d6\u540e\uff0c\u54cd\u5e94\u503c\u8d8a\u9ad8\u7684\u90e8\u4f4d\u8d8a\u6709\u53ef\u80fd\u5b58\u5728\u7269\u4f53\uff0c\u56e0\u6b64\uff0c\u4f5c\u8005\u5229\u7528\u4ee5\u4e0b\u89c4\u5219\u786e\u5b9a\u6807\u51c6\u7684\u77e9\u5f62\u6846\uff1a \u2003\u2003\u2460\u63d0\u53d6\u539f\u56fe\u50cf\u4e2d\u6700\u540e\u4e00\u4e2a\u5377\u79ef\u5c42\uff0c\u901a\u8fc7\u641c\u7d22\u54cd\u5e94\u503c\u6700\u9ad8\u7684\u70b9\u786e\u5b9a\u6b63\u65b9\u5f62\u6846\u7684\u4e2d\u5fc3\u70b9 \u2003\u2003\u2461\u6b63\u65b9\u5f62\u8fb9\u957f\u4e3a\u539f\u59cb\u56fe\u50cf\u8fb9\u957f\u7684\u4e00\u534a\u3001</p> <p>\u2003\u2003\u786e\u5b9a\u597d\u6807\u51c6\u7684\u5173\u6ce8\u533a\u57df\u540e\uff0c\u518d\u6784\u5efa\u635f\u5931\u51fd\u6570(\u53ef\u4ee5\u7528smooth L1\u51fd\u6570)\uff0c\u4e0d\u65ad\u4f18\u5316APN\u7f51\u7edc\u7684\u53c2\u6570\uff0c\u4f7f\u5176\u5173\u6ce8\u533a\u57df\u5f80\u54cd\u5e94\u503c\u9ad8\u7684\u533a\u57df\u9760\u62e2\u3002</p> <p>\u4ea4\u66ff\u8bad\u7ec3\uff1a</p> <p>\u2003\u2003\u5f53\u521d\u59cb\u5316\u5b8cAPN\u7f51\u7edc\u53c2\u6570\u65f6\uff0c\u5c31\u5230\u4e86\u7f51\u7edc\u6574\u4f53\u53c2\u6570\u7684\u8bad\u7ec3\u8fc7\u7a0b\u4e86\uff0c\u5177\u4f53\u8fc7\u7a0b\u5982\u4e0b\uff1a</p> <p>\u2003\u2003\u9996\u5148\u4fdd\u6301APN\u53c2\u6570\u7684\u4e0d\u53d8\uff0c\u5e76\u4e14\u5728\u4e09\u4e2a\u5c3a\u5ea6\u4e0a\u4f18\u5316\u5c3a\u5ea6\u5185\u5206\u7c7b\u635f\u5931\uff0c\u4ece\u800c\u8fbe\u5230\u4f18\u5316\u7f51\u7edc\u7684\u7279\u5f81\u63d0\u53d6\u5c42\u548c\u5206\u7c7b\u5c42\u53c2\u6570\u7684\u76ee\u7684\uff1b\u7136\u540e\u518d\u5c06\u7279\u5f81\u63d0\u53d6\u5c42\u548c\u5206\u7c7b\u5c42\u7684\u53c2\u6570\u56fa\u5b9a\uff0c\u5207\u6362\u5230\u4f18\u5316\u5c3a\u5ea6\u95f4\u6392\u5e8f\u635f\u5931\uff0c\u4ece\u800c\u4f18\u5316APN\u7684\u7f51\u7edc\u53c2\u6570\u3002\u8fd9\u4e24\u4e2a\u8fc7\u7a0b\u662f\u8fed\u4ee3\u8fdb\u884c\u7684\uff0c\u76f4\u5230\u4e24\u90e8\u5206\u635f\u5931\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4e0d\u518d\u53d8\u5316\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u4f7f\u7ec6\u7c92\u5ea6\u7279\u5f81\u63d0\u53d6\u7684\u5b66\u4e60\u4ee5\u53ca\u6ce8\u610f\u529b\u533a\u57df\u5b9a\u4f4d\u7684\u5b66\u4e60\u76f8\u4e92\u4fc3\u8fdb\uff0c\u5171\u540c\u4f18\u5316\u3002 $$ \u6ce8\u610f\uff1a\u6bcf\u4e2a\u5c3a\u5ea6\u9884\u6d4b\u7684t_l\u90fd\u88ab\u9650\u5236\u4e3a\u4e0d\u4f4e\u4e8e\u4e0a\u4e00\u5c3a\u5ea6\u7684\\frac{1}{3},\u907f\u514d\u88c1\u526a\u7684\u533a\u57df\u592a\u5c0f\u5bfc\u81f4\u7269\u4f53\u7ed3\u6784\u4e0d\u5b8c\u6574 $$ </p>"},{"location":"fine-grained/paper/RA-CNN1/#apn","title":"APN\u53c2\u6570\u4f18\u5316\u539f\u7406","text":"<p>\u2003\u2003\u6211\u4eec\u901a\u8fc7\u8ba1\u7b97tx,ty,tl\u7684\u5bfc\u6570\u6765\u8bf4\u660e\u6ce8\u610f\u529b\u5b66\u4e60\u7684\u673a\u5236\uff0c\u7531\u4e8e\u8fd9\u4e09\u8005\u6709\u7c7b\u4f3c\u7684\u63a8\u5bfc\u8fc7\u7a0b\uff0c\u56e0\u6b64\u8fd9\u91cc\u53ea\u4ee5tx\u4e3a\u4f8b\uff0c\u901a\u8fc7\u94fe\u5f0f\u6cd5\u5219\u6765\u8ba1\u7b97\u5bfc\u6570\uff0c\u4ee5\u56fe\u50cf\u5de6\u4e0a\u89d2\u4e3a\u539f\u70b9\u3002</p> <p>\u9996\u5148\uff0c\u6211\u4eec\u8ba1\u7b97h(x)\u7684\u5bfc\u6570\uff0c $$ h(x)=\\frac{1}{1+e^{-kx}}\\\\ h'(x)=\\frac{ke^{-kx}}{(1+e^{-kx})^2}=\\frac{k}{2+e^{kx}+e^{-kx}} $$  \u5206\u6790\u6613\u5f97\uff0ch\u2019(x)\u7684\u56fe\u50cf\u5982\u4e0b\uff1a</p> <p> <p></p> <p></p> <p>\u8fdb\u4e00\u6b65\u8ba1\u7b97M(\u00b7)\u5bf9tx\u7684\u504f\u5bfc\uff0c $$ M(\u00b7)=[h(x-t_x+t_l)-h(x-t_x-t_l)]\u00b7[h(y-t_{y(tl)})-h(y-t_{y(br)})]\\\\ M'(t_x)=[-h(x-t_x+t_l)+h(x-t_x-t_l)]\u00b7[h(y-t_{y(tl)})-h(y-t_{y(br)})] $$  \u8bbea=[h(y-t_{y(tl)})-h(y-t_{y(br)})]\uff0ca\\in R\uff0c\u53ef\u5f97M'(t_x)=a[-h(x-t_x+t_l)+h(x-t_x-t_l)]\uff0c\u7ed3\u5408h\u2019(x)\u7684\u56fe\u50cf\u5206\u6790\u6613\u5f97\uff0cM(\u00b7)\u5bf9t_x\u7684\u504f\u5bfc\u56fe\u50cf\u51fd\u6570\u5982\u4e0b\uff1a</p> <p> <p></p> <p></p> <p>\u7531\u56fe\u50cf\u53ef\u77e5\uff0c\u5f53x\u8d8b\u8fd1\u4e8et_x-t_l\uff0c\u5373\u8d8b\u8fd1\u4e8e\u6ce8\u610f\u529b\u533a\u57df\u7684\u5de6\u8fb9\u754c\u65f6\uff0c\u5bfc\u6570\u503c\u5c0f\u4e8e\u96f6\uff1b\u5f53x\u8d8b\u8fd1\u4e8et_x+t_l\uff0c\u5373\u8d8b\u8fd1\u4e8e\u6ce8\u610f\u529b\u533a\u57df\u7684\u53f3\u8fb9\u754c\u65f6\uff0c\u5bfc\u6570\u503c\u5927\u4e8e\u96f6\uff0ct_x\u6709\u589e\u5927\u7684\u8d8b\u52bf\u3002\u56e0\u6b64\uff0c\u53ef\u4ee5\u5c06M(\u00b7)\u5bf9t_x\u7684\u504f\u5bfc\u603b\u7ed3\u6210\u5982\u4e0b\u5f0f\u5b50\uff1a $$ M'(t_x)=\\left\\{ \\begin{matrix} &lt;0,\\quad &amp;x\\to t_{x(tl)} \\\\ &gt;0, \\quad &amp;x \\to t_{x(br)} \\\\ =0, \\quad &amp;otherwise \\end{matrix} \\right. $$  \u2003\u2003\u901a\u8fc7\u4e0a\u8ff0\u5206\u6790\uff0c\u6211\u4eec\u53ef\u4ee5\u5f97\u5230\uff0c\u5f53\u56fe\u50cf\u4e2d\u54cd\u5e94\u503c\u9ad8\u7684\u533a\u57df\u4f4d\u4e8e\u63a9\u6a21\u533a\u57df\u7684\u5de6\u4fa7\u65f6\uff0c\u63a9\u6a21\u4e2d\u5fc3\u4f1a\u6709\u5de6\u79fb(tx\u51cf\u5c0f)\u7684\u8d8b\u52bf\uff1b\u5f53\u56fe\u50cf\u4e2d\u54cd\u5e94\u503c\u9ad8\u7684\u533a\u57df\u4f4d\u4e8e\u63a9\u6a21\u533a\u57df\u7684\u53f3\u4fa7\u65f6\uff0c\u63a9\u6a21\u4e2d\u5fc3\u4f1a\u6709\u53f3\u79fb(tx\u589e\u5927)\u7684\u8d8b\u52bf\uff1b\u5176\u4ed6\u60c5\u51b5\u4e0b\u4e0d\u53d8\u3002</p> <p>\u540c\u7406\u53ef\u4ee5\u5206\u6790\u5f97\u5230M(\u00b7)\u5bf9t_y\u7684\u504f\u5bfc\u5f0f\u5b50\u5982\u4e0b\uff1a $$ M'(t_y)=\\left\\{ \\begin{matrix} &lt;0,\\quad &amp;y\\to t_{y(tl)} \\\\ &gt;0, \\quad &amp;y \\to t_{y(br)} \\\\ =0, \\quad &amp;otherwise \\end{matrix} \\right. $$  \u2003\u2003\u5f53\u56fe\u50cf\u4e2d\u54cd\u5e94\u503c\u9ad8\u7684\u533a\u57df\u4f4d\u4e8e\u63a9\u6a21\u533a\u57df\u7684\u4e0a\u4fa7\u65f6\uff0c\u63a9\u6a21\u4e2d\u5fc3\u4f1a\u6709\u4e0a\u79fb(t_y\u51cf\u5c0f)\u7684\u8d8b\u52bf\uff1b\u5f53\u56fe\u50cf\u4e2d\u54cd\u5e94\u503c\u9ad8\u7684\u533a\u57df\u4f4d\u4e8e\u63a9\u6a21\u533a\u57df\u7684\u4e0b\u4fa7\u65f6\uff0c\u63a9\u6a21\u4e2d\u5fc3\u4f1a\u6709\u4e0b\u79fb(t_y\u589e\u5927)\u7684\u8d8b\u52bf\uff1b\u5176\u4ed6\u60c5\u51b5\u4e0d\u53d8\u3002</p> <p>M(\u00b7)\u5bf9t_l\u7684\u504f\u5bfc\u5f0f\u5b50\u5982\u4e0b\uff1a $$ M'(t_l)=\\left\\{ \\begin{matrix} &gt;0,\\quad &amp; x\\to t_{x(tl)} \\quad or \\quad x \\to t_{x(br)}\\\\ &amp;or \\quad y\\to t_{y(br)}  \\quad or \\quad y\\to t_{y(tl)} \\\\ &lt;0, \\quad &amp;otherwise \\end{matrix} \\right. $$  \u2003\u2003\u5f53\u56fe\u50cf\u4e2d\u54cd\u5e94\u503c\u9ad8\u7684\u533a\u57df\u4f4d\u4e8e\u63a9\u6a21\u7684\u8fb9\u754c\u65f6\uff0c\u63a9\u6a21\u8fb9\u754c\u5927\u5c0f\u4f1a\u6709\u6269\u5927\u7684\u8d8b\u52bf(t_l\u589e\u5927)\uff1b\u5426\u5219\uff0c\u63a9\u6a21\u8fb9\u754c\u6536\u7f29(t_l\u51cf\u5c0f)\u3002</p> <p>\u5177\u4f53\u53d8\u6362\u6548\u679c\u53ef\u4ee5\u89c1\u4e0b\u56fe\uff0c\u9ed1\u8272\u70b9\u4e3a\u5bfc\u6570\u503c\u662f\u8d1f\u7684\u70b9\uff0c\u5373\u54cd\u5e94\u503c\u9ad8\u7684\u70b9\u3002</p> <p> <p></p> <p></p> <p>\u8865\u5145\uff1a \u2460\u5bfc\u6570\u503c\u662f\u8d1f\uff0c\u4ee3\u8868\u8be5\u5904\u7684\u503c\u5bf9\u6700\u7ec8\u7684\u635f\u5931\u662f\u8d1f\u5f71\u54cd\uff0c\u56e0\u6b64\u8be5\u5904\u70b9\u7684\u503c\u5bf9\u6700\u7ec8\u7684\u5206\u7c7b\u6709\u91cd\u8981\u7684\u79ef\u6781\u5f71\u54cd\uff0c\u5373\u8be5\u5904\u7684\u70b9\u662f\u6709\u533a\u5206\u5ea6\u7684\u533a\u57df\uff0c\u6ce8\u610f\u529b\u7684\u5173\u6ce8\u533a\u57df\u5e94\u8be5\u5f80\u8fd9\u4e9b\u70b9\u4e0a\u9760\u62e2\u3002 \u2461\u54cd\u5e94\u503c\u9ad8\u7684\u533a\u57df\uff1a\u5c31\u662f\u5bf9\u6700\u7ec8\u5206\u7c7b\u6709\u79ef\u6781\u5f71\u54cd\u7684\u533a\u57df\uff0c\u5f80\u5f80\u8fd9\u4e9b\u533a\u57df\u5bf9\u5e94\u7684\u6743\u91cd\u7cfb\u6570\u90fd\u6bd4\u8f83\u9ad8\u3002</p>"},{"location":"fine-grained/paper/RA-CNN1/#_10","title":"\u7cbe\u5ea6\u5bf9\u6bd4","text":"<p>CUB-200-2011</p> <p> <p></p> <p></p> <p>Stanford Cars</p> <p> <p></p> <p></p> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u5927\u5bb6\u6279\u8bc4\u6307\u6b63\u3002</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e749\u670829\u65e5</p>"},{"location":"fine-grained/paper/S3N1/","title":"\u7ec6\u7c92\u5ea6\uff1aS3N","text":""},{"location":"fine-grained/paper/S3N1/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aIEEE International Conference on Computer Vision 2019 (ICCV, 2019)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttp://openaccess.thecvf.com/content_ICCV_2019/papers/Ding_Selective_Sparse_Sampling_for_Fine-Grained_Image_Recognition_ICCV_2019_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740(PyTorch\u7248\u672c)\uff1ahttps://github.com/Yao-DD/S3N</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u7c7b(FGVC)</p> <p>\u5173\u952e\u8bcd\uff1a\u7ec6\u7c92\u5ea6\u8bc6\u522b\u3001\u663e\u8457\u6027\u91c7\u6837</p>"},{"location":"fine-grained/paper/S3N1/#_2","title":"\u4e3b\u8981\u601d\u60f3","text":"<p>\u2003\u2003\u7ec6\u7c92\u5ea6\u8bc6\u522b\u4e3b\u8981\u7528\u4e8e\u89e3\u51b3\u5728\u76f8\u5f53\u5927\u7684\u7c7b\u5185\u5dee\u5f02\u4e2d\uff0c\u6355\u6349\u7ec6\u5fae\u7684\u7c7b\u95f4\u5dee\u5f02\u3002\u4f20\u7edf\u7684\u65b9\u6cd5\u4e3b\u8981\u662f\u88c1\u526a\u5c40\u90e8\u533a\u57df\uff0c\u5e76\u4e14\u4ece\u8fd9\u4e9b\u533a\u57df\u4e2d\u5b66\u4e60\u8be6\u7ec6\u7684\u7279\u5f81\u8868\u793a\uff0c\u4f46\u662f\u88c1\u526a\u6570\u91cf\u9700\u8981\u4eba\u4e3a\u89c4\u5b9a\uff0c\u4e0d\u540c\u7684\u5c40\u90e8\u6570\u91cf\u53ef\u80fd\u4f1a\u5e26\u6765\u4e0d\u540c\u7684\u5b66\u4e60\u6548\u679c\uff0c\u8fd9\u4e00\u8d85\u53c2\u6570\u4e0d\u597d\u628a\u63a7\uff1b\u5e76\u4e14\u5982\u679c\u76f4\u63a5\u88c1\u526a\u7684\u8bdd\uff0c\u4f1a\u5220\u6389\u5468\u56f4\u7684\u73af\u5883\uff0c\u5468\u56f4\u73af\u5883\u7684\u7f3a\u5931\u4f1a\u9650\u5236\u7f51\u7edc\u6700\u7ec8\u7684\u7279\u5f81\u8868\u8fbe\u80fd\u529b\uff0c\u518d\u52a0\u4e4b\u5982\u679c\u533a\u57df\u5b9a\u4f4d\u51fa\u73b0\u9519\u8bef\uff0c\u5219\u4f1a\u5e72\u6270\u540e\u7eed\u7684\u5b66\u4e60\u8fc7\u7a0b\u3002</p> <p>\u2003\u2003\u4e0b\u56fe\u662f\u88c1\u526a\u65b9\u6cd5(MA-CNN)\u4e0e\u4f5c\u8005\u63d0\u51fa\u7684\u65b9\u6cd5\u505a\u7684\u5bf9\u6bd4\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u672c\u6587\u4e2d\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u6709\u6548\u5730\u7f51\u7edc\u6846\u67b6\uff0c\u79f0\u4e3a\u9009\u62e9\u6027\u7a00\u758f\u91c7\u6837\u7f51\u7edc(Selective Sparse Sampling Networks, S3Ns)\uff0c\u8be5\u7f51\u7edc\u6700\u6838\u5fc3\u7684\u5730\u65b9\u5c31\u662f\u9009\u62e9\u6027\u7a00\u758f\u91c7\u6837\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u6355\u83b7\u5e76\u51f8\u663e\u5404\u79cd\u5404\u6837\u7684\u7ec6\u7c92\u5ea6\u7ec6\u8282\uff0c\u5e76\u4e14\u4fdd\u5b58\u4e86\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002\u9996\u5148\u4ece\u7c7b\u54cd\u5e94\u56fe\u4e2d\u6536\u96c6\u5cf0\u503c\uff0c\u5373\u5c40\u90e8\u6700\u5927\u503c\uff0c\u7528\u4e8e\u4f30\u8ba1\u4fe1\u606f\u611f\u53d7\u91ce\uff0c\u5e76\u4e14\u5229\u7528\u8be5\u5cf0\u503c\u8ba1\u7b97\u5f97\u5230\u4e00\u7ec4\u7a00\u758f\u6ce8\u610f\u529b\uff0c\u7528\u4e8e\u4f30\u8ba1\u5cf0\u503c\u54cd\u5e94\u7684\u89c4\u6a21\u3002\u7136\u540e\u57fa\u4e8e\u5f97\u5230\u7684\u7a00\u758f\u6ce8\u610f\u529b\u56fe\uff0c\u5bf9\u539f\u56fe\u8fdb\u884c\u975e\u5747\u5300\u5730\u53d8\u6362\uff0c\u5373\u9009\u62e9\u6027\u91c7\u6837\uff0c\u4ee5\u7a81\u51fa\u54cd\u5e94\u7684\u533a\u57df\u3002\u6700\u7ec8\u5f97\u5230\u4e24\u5f20\u91cd\u91c7\u6837\u56fe\uff0c\u5206\u522b\u4e3a\u5224\u522b\u5206\u652f\u56fe\u50cf\u548c\u4e92\u8865\u5206\u652f\u56fe\u50cf\uff0c\u5206\u522b\u5f15\u5bfc\u7f51\u7edc\u5b66\u4e60\u56fe\u50cf\u7684\u533a\u522b\u6027\u7279\u5f81\u548c\u4e92\u8865\u6027\u7279\u5f81\uff0c\u663e\u8457\u5730\u63d0\u5347\u4e86\u7279\u5f81\u7684\u8868\u793a\u80fd\u529b\uff0c\u9f13\u52b1\u7f51\u7edc\u5b66\u4e60\u66f4\u591a\u7684\u89c6\u89c9\u7ebf\u7d22\u3002</p> <p> <p></p> <p></p>"},{"location":"fine-grained/paper/S3N1/#_3","title":"\u7f51\u7edc\u4e3b\u8981\u6d41\u7a0b","text":"<p>\u9009\u62e9\u6027\u7a00\u758f\u91c7\u6837\u7ed3\u6784\u56fe\u5982\u4e0b\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u539f\u59cb\u56fe\u50cf\u9996\u5148\u5f97\u5230\u4e00\u5f20\u7c7b\u54cd\u5e94\u56fe(Class Response Map)\uff0c\u7136\u540e\u901a\u8fc7\u8ba1\u7b97\u7c7b\u54cd\u5e94\u56fe\u7684\u5cf0\u503c\u54cd\u5e94\u70b9\uff0c\u6765\u5f97\u5230\u7528\u4e8e\u5b9a\u4f4d\u4fe1\u606f\u5bf9\u8c61\u7684\u4e24\u7ec4\u7a00\u758f\u6ce8\u610f\u529b\u56fe(Sparse Attention)\uff0c\u5206\u522b\u7528\u4e8e\u5b9a\u4f4d\u56fe\u50cf\u5177\u6709\u8fa8\u8bc6\u529b\u7684\u533a\u57df(discriminative evidence)\u548c\u5177\u6709\u4e92\u8865\u4fe1\u606f\u7684\u533a\u57df(complementary evidence)\u3002\u5229\u7528\u4e0a\u8ff0\u4e24\u79cd\u6ce8\u610f\u529b\u56fe\uff0c\u6765\u5bf9\u539f\u56fe\u8fdb\u884c\u7a00\u758f\u91c7\u6837\u64cd\u4f5c\uff0c\u5f97\u5230\u5224\u522b\u56fe\u50cf\u548c\u4e92\u8865\u56fe\u50cf\uff0c\u5224\u522b\u56fe\u50cf\u53ef\u4ee5\u63d0\u5347\u7f51\u7edc\u7ec6\u7c92\u5ea6\u7279\u5f81\u63d0\u53d6\u7684\u80fd\u529b\uff0c\u4e92\u8865\u56fe\u50cf\u53ef\u4ee5\u9f13\u52b1\u7f51\u7edc\u6316\u6398\u591a\u4e2a\u89c6\u89c9\u7ebf\u7d22(\u8fd9\u91cc\u7684\u4f5c\u7528\u7c7b\u4f3cWS-DAN\u4e2d\u7684\u6ce8\u610f\u529b\u5220\u9664\u64cd\u4f5c)\uff0c\u6700\u540e\u4e09\u79cd\u56fe\u50cf\u540c\u65f6\u7528\u4e8e\u4f18\u5316\u7f51\u7edc\u53c2\u6570\u3002</p>"},{"location":"fine-grained/paper/S3N1/#_4","title":"\u7c7b\u5cf0\u503c\u54cd\u5e94","text":"<p>\u2003\u2003\u9996\u5148\u5c06\u539f\u59cb\u56fe\u50cf\u4f20\u5165\u4e3b\u5e72\u7279\u5f81\u63d0\u53d6\u7f51\u7edcCNN\u8fdb\u884c\u63d0\u53d6\u7279\u5f81\uff0c\u5f97\u5230\u5c3a\u5bf8\u4e3aD\u00d7H\u00d7W\u7684\u7279\u5f81\u56feS\uff0c\u5176\u4e2dD\u8868\u793a\u7279\u5f81\u56fe\u7684\u901a\u9053\u6570(\u4e0b\u9762\u8981\u7528\u5230)\u3002\u4e4b\u540e\u5c06\u7279\u5f81\u56fe\u4f9d\u6b21\u7ecf\u8fc7\u5168\u5c40\u5e73\u5747\u6c60\u5316\u5c42\u4ee5\u53ca\u5168\u8fde\u63a5\u5c42(FC)\uff0c\u5f97\u5230\u4e00\u7ec4\u7c7b\u522b\u9884\u6d4b\u6982\u7387\u3002\u5047\u8bbe\u6709C\u79cd\u7c7b\u522b\uff0c\u5219\u5168\u8fde\u63a5\u5c42\u7684\u6743\u91cd\u53c2\u6570W\u5c3a\u5bf8\u4e3aD\u00d7C(\u53ef\u4ee5\u8fd9\u4e48\u7406\u89e3\uff0c\u7ebf\u6027\u56de\u5f52\u4e2d\u8f93\u5165D\u4e2a\u6570\uff0c\u8f93\u51faC\u4e2a\u6570\uff0c\u5219\u5171\u6709D\u00d7C\u4e2a\u6743\u91cd\u53c2\u6570)\uff0c\u7136\u540e\u8fdb\u4e00\u6b65\u5229\u7528\u4e0b\u9762\u7684\u516c\u5f0f\u8ba1\u7b97\u7c7b\u54cd\u5e94\u56fe\uff1a $$ M_c=\\sum^D_{d=1}W^{fc}_{d,c}\\times S_d $$ M_c\u8868\u793a\u7b2cc\u7c7b\u7684\u7c7b\u54cd\u5e94\u56fe\uff0cS_d\u8868\u793ad\u901a\u9053\u7684\u7279\u5f81\u56fe\uff0cW^{fc}_{d,c}\u8868\u793a\u5168\u8fde\u63a5\u5c42\u4e2d,\u7b2cd\u4e2a\u8f93\u5165(\u901a\u9053)\u6307\u5411\u7b2cc\u7c7b\u7684\u9884\u6d4b\u6982\u7387\u7684\u6743\u91cd\u53c2\u6570\u3002</p> <p>\u2003\u2003\u4ee5CUB\u6570\u636e\u96c6\u4e0eresnet50\u4e3a\u4f8b\uff0c\u7279\u5f81\u56feS\u901a\u9053\u6570\u4e3a2048\uff0c\u5373\u5168\u8fde\u63a5\u5c42\u8f93\u5165\u4e3a2048\uff0c\u8f93\u51fa\u662f200\uff0c\u6bcf\u4e2a\u8f93\u51fa\u5747\u662f2048\u4e2a\u8f93\u5165\u7684\u7ebf\u6027\u7ec4\u5408\uff0c\u4ee5\u7b2c\u4e00\u7c7b\u4e3a\u4f8b\uff0c2048\u5f20\u7279\u5f81\u56fe\u4e58\u4ee5\u5168\u8fde\u63a5\u5c42\u4e2d\u6307\u5411\u7b2c\u4e00\u7c7b\u7684\u6743\u91cd\u53c2\u6570\uff0c\u518d\u6c42\u548c\u5f97\u5230\u7b2c\u4e00\u7c7b\u7684\u7c7b\u54cd\u5e94\u56fe\uff0c\u4e0a\u8ff0\u516c\u5f0f\u4e00\u5171\u53ef\u4ee5\u5f97\u5230200\u5f20\u7c7b\u54cd\u5e94\u56fe(\u5bf9\u5e94200\u7c7b)</p> <p>\u2003\u2003\u7b2cc\u7c7b\u7684\u7c7b\u5cf0\u503c\u54cd\u5e94\u8868\u793a\u5176\u7c7b\u54cd\u5e94\u56fe\u7684\u5c40\u90e8\u6700\u5927\u503c\uff0c\u53ef\u4ee5\u7531\u7a97\u53e3\u5c3a\u5bf8\u4e3ar\u7684\u6700\u5927\u6c60\u5316\u8fd0\u7b97\u5f97\u5230\uff0c\u5cf0\u503c\u76f8\u5e94\u70b9\u5f80\u5f80\u4ee3\u8868\u4e86\u611f\u5174\u8da3\u533a\u57df\u5185\u7684\u5f3a\u89c6\u89c9\u7ebf\u7d22\u3002</p>"},{"location":"fine-grained/paper/S3N1/#_5","title":"\u7a00\u758f\u6ce8\u610f\u529b","text":"<p>\u2003\u2003\u7531\u4e8e\u4e0a\u8ff0\u8fc7\u7a0b\u5f97\u5230\u4e86C\u5f20\u54cd\u5e94\u56fe\uff0c\u5404\u54cd\u5e94\u56fe\u9488\u5bf9\u4e0d\u540c\u7684\u7c7b\u522b\uff0c\u5177\u6709\u4e0d\u540c\u7684\u5b9e\u9645\u610f\u4e49\uff0c\u56e0\u6b64\u4e0d\u80fd\u76f4\u63a5\u7528\u4e8e\u8ba1\u7b97\u7a00\u758f\u6ce8\u610f\u529b\uff0c\u9700\u8981\u52a0\u4ee5\u989d\u5916\u7684\u64cd\u4f5c\u5904\u7406\uff0c\u53d8\u6210\u4e00\u5f20\u54cd\u5e94\u56fe\uff0c\u6700\u7b80\u5355\u5730\u65b9\u6cd5\u5c31\u662f\u9009\u62e9\u9884\u6d4b\u6982\u7387\u8f83\u5927\u7684\u7c7b\u522b\u54cd\u5e94\u56fe\u3002\u4f46\u4f5c\u8005\u53d1\u73b0\u6982\u7387\u6700\u5927\u7684\u7c7b\u522b\u54cd\u5e94\u56fe\u7684\u5cf0\u503c\u54cd\u5e94\u6709\u65f6\u4e0d\u80fd\u5b8c\u5168\u8986\u76d6\u6709\u8bc6\u522b\u529b\u7684\u533a\u57df\uff0c\u800c\u524dk\u7ec4\u7c7b\u54cd\u5e94\u56fe\u4e0a\u6709\u5f88\u591a\u5cf0\u503c\u54cd\u5e94\u70b9\uff0c\u4f46\u540c\u65f6\u4e5f\u5b58\u5728\u4e00\u90e8\u5206\u566a\u70b9\u3002\u6700\u6839\u672c\u7684\u539f\u56e0\u8fd8\u662f\u7531\u6a21\u578b\u9884\u6d4b\u7ed3\u679c\u7684\u597d\u574f\u5bfc\u81f4\u7684\uff0c\u5982\u679c\u6a21\u578b\u5bf9\u539f\u56fe\u9884\u6d4b\u7684\u975e\u5e38\u597d\uff0c\u6700\u5927\u7684\u9884\u6d4b\u6982\u7387\u5f88\u5927\uff0c\u5219\u5176\u54cd\u5e94\u56fe\u4e0a\u7684\u7684\u6570\u636e\u8db3\u4ee5\u53cd\u5e94\u6709\u8bc6\u522b\u529b\u7684\u533a\u57df\uff0c\u5c31\u65e0\u9700\u7528\u524dk\u7ec4\u54cd\u5e94\u56fe\uff0c\u53cd\u4e4b\u4ea6\u7136\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u5229\u7528\u6a21\u578b\u9884\u6d4b\u7ed3\u679c\u7684\u7f6e\u4fe1\u5ea6\uff0c\u6765\u9009\u62e9\u7b2c1\u5f20\u7c7b\u54cd\u5e94\u56fe\u8fd8\u662f\u524d5\u5f20\u7c7b\u54cd\u5e94\u56fe\u4f5c\u4e3a\u6700\u7ec8\u7684\u54cd\u5e94\u56fe\u3002</p> <p>\u2003\u2003\u9996\u5148\u8ba9\u5168\u8fde\u63a5\u5c42\u7684\u8f93\u51fa\u7ecf\u8fc7softmax\uff0c\u5f97\u5230\u4e00\u7ec4\u9884\u6d4b\u6982\u7387P\uff0c\u518d\u5c06\u9884\u6d4b\u6982\u7387\u964d\u5e8f\u6392\u5e8f\uff0c\u5229\u7528\u5982\u4e0b\u516c\u5f0f\u8ba1\u7b97\u4fe1\u606f\u71b5\u503cH\uff1a $$ H=-\\sum^5_{i=1}p_ilog p_i,\\quad p_i \\in P $$  \u2003\u2003\u8fd9\u91cc\u7684\u4fe1\u606f\u71b5\u5c31\u7c7b\u4f3c\u635f\u5931\u503c\uff0c\u4fe1\u606f\u71b5\u8d8a\u5c0f\uff0c\u8868\u793a\u9884\u6d4b\u7ed3\u679c\u8d8a\u597d\uff0c\u7b2c\u4e00\u7c7b\u522b\u9884\u6d4b\u7684\u6b63\u786e\u6027\u5c31\u8d8a\u5927\uff0c\u6b64\u65f6\u9009\u62e9\u7b2c\u4e00\u5f20\u54cd\u5e94\u56fe\u505a\u4e3a\u6700\u7ec8\u7684\u7c7b\u54cd\u5e94\u56fe\u5373\u53ef\uff1b\u53cd\u4e4b\u9884\u6d4b\u7ed3\u679c\u5c31\u8d8a\u4e0d\u597d\uff0c\u7b2c\u4e00\u7c7b\u522b\u9884\u6d4b\u7684\u6b63\u786e\u6027\u8d8a\u4f4e\uff0c\u6b64\u65f6\u4e0d\u80fd\u5355\u7eaf\u4f7f\u7528\u7b2c\u4e00\u7c7b\u7684\u7c7b\u54cd\u5e94\u56fe\uff0c\u9700\u8981\u7efc\u5408\u524d\u51e0\u7c7b(\u6587\u7ae0\u4e2d\u7528\u524d5\u7c7b)\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u5229\u7528\u5982\u4e0b\u7684\u516c\u5f0f\u6784\u5efa\u4e86\u6700\u7ec8\u7684\u54cd\u5e94\u56feR\uff1a $$ R=\\left\\{ \\begin{matrix} \\widehat{M}_1, &amp;if \\quad H\u2264\\delta \\\\ \\sum^5_{k=1}\\widehat{M}_k\uff0c&amp;if \\quad H&gt; \\delta  \\end{matrix}  \\right. $$  \u5176\u4e2d\uff0c\\widehat{M}_5\\in R^{5\\times H\\times W}\u8868\u793a\u9884\u6d4b\u6982\u7387\u524d\u4e94\u7684\u7c7b\u54cd\u5e94\u56fe\uff0c\\delta\u4e3a\u5224\u65ad\u9608\u503c\uff0c\u4f5c\u8005\u7ecf\u8fc7\u5b9e\u9a8c\u5f97\u5230\uff0c\u9608\u503c\u53d6\u4e3a0.2\u6548\u679c\u6700\u597d\u3002</p> <p>\u2003\u2003\u8fdb\u4e00\u6b65\uff0c\u518d\u5229\u7528\u6700\u503c\u5f52\u4e00\u5316\u8fd0\u7b97\u5c06\u5f97\u5230\u7684\u54cd\u5e94\u56feR\u505a\u5f52\u4e00\u5316\u5904\u7406\uff0c\u516c\u5f0f\u5982\u4e0b\uff1a $$ R=\\frac{R=min(R)}{max(R)-min(R)} $$  \u2003\u2003\u6700\u540e\uff0c\u8fdb\u4e00\u6b65\u5229\u7528\u7a97\u53e3\u5927\u5c0f\u4e3ar(\u6587\u7ae0\u4e2dr\u53d6\u4e3a3)\u7684\u68c0\u6d4b\u7a97\u53e3\uff0c\u6765\u8ba1\u7b97\u5f97\u5230\u54cd\u5e94\u56feR\u7684\u5c40\u90e8\u6700\u5927\u503c\uff0c\u6362\u53e5\u8bdd\u8bf4\uff0c\u5229\u7528\u6c60\u5316\u6838\u5c3a\u5bf8\u4e3ar\u7684\u6700\u5927\u6c60\u5316\u8fd0\u7b97\uff0c\u5982\u679c\u5f53\u524d\u6c60\u5316\u7a97\u53e3\u7684\u6700\u5927\u503c\u4e3a\u7a97\u53e3\u7684\u4e2d\u5fc3\u70b9\uff0c\u5219\u6539\u70b9\u5c31\u4e3a\u5c40\u90e8\u6700\u5927\u503c\uff0c\u5373\u54cd\u5e94\u56fe\u7684\u5cf0\u503c\u54cd\u5e94\u3002\u8fdb\u4e00\u6b65\u5c06\u5cf0\u503c\u54cd\u5e94\u70b9\u96c6\u5b9a\u4e49\u4e3aT\uff1a $$ T=\\{(x_1,y_1),(x_2,y_2),\\dots,(x_{N_t},y_{N_t}) \\} $$  \u2003\u2003\u5bf9\u4e8e\u6240\u6709\u7684\u5cf0\u503c\u76f8\u5e94\uff0c\u4f5c\u8005\u57280-1\u5747\u5300\u5206\u5e03\u4e2d\u968f\u673a\u9009\u53d6\u4e00\u4e2a\u9608\u503c\uff0c\u7136\u540e\u5229\u7528\u8be5\u9608\u503c\u5c06\u5176\u5212\u5206\u6210\u4e86\u4e24\u90e8\u5206\uff0c\u5206\u522b\u662f\u54cd\u5e94\u503c\u8f83\u9ad8\u7684\u5cf0\u503c\uff0c\u548c\u54cd\u5e94\u503c\u8f83\u4f4e\u7684\u5cf0\u503c\u3002\u6ce8\u610f\uff1a\u9608\u503c\u7684\u9009\u53d6\u662f\u968f\u673a\u7684\uff0c\u5e76\u4e0d\u662f\u56fa\u5b9a\u7684\uff0c\u8fd9\u4fdd\u8bc1\u4e86\u8bad\u7ec3\u7684\u52a8\u6001\u6027\uff0c\u53ef\u4ee5\u52a8\u6001\u5730\u8fdb\u884c\u63d0\u53d6\u7279\u5f81\uff0c\u4e24\u90e8\u5206\u5212\u5206\u8fc7\u7a0b\u5982\u4e0b\uff1a $$ T_d=\\{(x,y)|(x,y)\\in T\\quad if \\quad R_{x,y}\u2265\\zeta \\}\\\\ T_c=\\{(x,y)|(x,y)\\in T\\quad if \\quad R_{x,y}\u2264\\zeta \\} $$  \u5176\u4e2d\uff0c\\zeta\u662f\u968f\u673a\u9009\u62e9\u7684\u9608\u503c\uff0cT_d\u54cd\u5e94\u503c\u8f83\u9ad8\u7684\u5cf0\u503c\uff0cT_c\u662f\u54cd\u5e94\u503c\u8f83\u4f4e\u7684\u5cf0\u503c</p> <p>\u2003\u2003\u54cd\u5e94\u503c\u8f83\u9ad8\u7684\u533a\u57df\u5f80\u5f80\u662f\u90a3\u4e9b\u5177\u6709\u8fa8\u8bc6\u529b\u7684\u533a\u57df(\u7ec6\u7c92\u5ea6\u79cd\u7c7b\u4e2d\u72ec\u4e00\u65e0\u4e8c\u7684\u90e8\u5206)\uff0c\u96c6\u4e2d\u5b66\u4e60\u8be5\u533a\u57df\uff0c\u53ef\u4ee5\u63d0\u9ad8\u7f51\u7edc\u7684\u7ec6\u7c92\u5ea6\u7279\u5f81\u63d0\u53d6\u7684\u80fd\u529b\uff1b\u54cd\u5e94\u503c\u8f83\u4f4e\u7684\u533a\u57df\u5f80\u5f80\u662f\u90a3\u4e9b\u5177\u6709\u4e92\u8865\u4fe1\u606f\u7684\u533a\u57df\uff0c\u96c6\u4e2d\u5b66\u4e60\u8be5\u533a\u57df\uff0c\u53ef\u4ee5\u9f13\u52b1\u7f51\u7edc\u5b66\u4e60\u66f4\u591a\u7684\u56fe\u50cf\u7279\u5f81\u8868\u793a\u80fd\u529b\uff0c\u5373\u63d0\u9ad8\u7f51\u7edc\u7684\u6cdb\u5316\u80fd\u529b\u3002</p> <p>\u2003\u2003\u6700\u540e\uff0c\u518d\u5229\u7528\u9ad8\u65af\u6838\u53bb\u8ba1\u7b97\u4e00\u7cfb\u5217\u7684\u7a00\u758f\u6ce8\u610f\u529bA\uff0c\u7528\u4e8e\u5173\u6ce8\u5cf0\u503c\u54cd\u5e94\uff1a $$ A_{i,x,y}=\\left \\{ \\begin{matrix} R_{x_i,y_i}e^{-\\frac{(x-x_i)^2+(y-y_i)^2}{R_{x_i,y_i}\\beta_1^2}}, \\quad if\\quad (x_i,y_i)\\in T_d \\\\ \\frac{1}{R_{x_i,y_i}}e^{-\\frac{(x-x_i)^2+(y-y_i)^2}{R_{x_i,y_i}\\beta_2^2}}, \\quad if\\quad (x_i,y_i)\\in T_c \\end{matrix}   \\right. $$  \u5176\u4e2d\uff0c\\beta_1\u548c\\beta_2\u662f\u4e00\u7ec4\u53ef\u5b66\u4e60\u7684\u53c2\u6570\uff0c\u53ef\u4ee5\u901a\u8fc7\u6765\u81ea\u91cd\u91c7\u6837\u56fe\u50cf\u7684\u5206\u7c7b\u635f\u5931\u8fdb\u884c\u66f4\u65b0\uff0cR_{x_i,y_i}\u662f\u54cd\u5e94\u56fe\u4e2d\u7b2ci\u4e2a\u5cf0\u503c\u54cd\u5e94\u7684\u54cd\u5e94\u503c\u3002</p> <p>\u2003\u2003\u6bcf\u4e2a\u7a00\u758f\u6ce8\u610f\u529b\u90fd\u63a7\u5236\u4e00\u5b9a\u7684\u91c7\u6837\u5c3a\u5ea6(\u7a00\u758f\u6ce8\u610f\u529b\u8d8a\u5927\uff0c\u91c7\u6837\u5e45\u5ea6\u5c31\u8d8a\u5927)\uff0c\u5e76\u4e14\u53d7\u5230\u5cf0\u503c\u54cd\u5e94\u503c\u7684\u5f71\u54cd\u3002\u4e92\u8865\u4fe1\u606f\u533a\u57df\u7684\u5cf0\u503c\u54cd\u5e94\u8f83\u5c0f\uff0c\u56e0\u6b64\u4f5c\u8005\u901a\u8fc7\u53d6\u5012\u6570\uff0c\u6765\u589e\u52a0\u5b83\u7684\u91c7\u6837\u5e45\u5ea6\uff0c\u4ee5\u9f13\u52b1\u7f51\u7edc\u5b66\u4e60\u7279\u5f81\u76f8\u5bf9\u4e0d\u660e\u663e\u7684\u533a\u57df\u3002</p>"},{"location":"fine-grained/paper/S3N1/#_6","title":"\u9009\u62e9\u6027\u91c7\u6837","text":"<p>\u2003\u2003\u5f97\u5230\u7a00\u758f\u6ce8\u610f\u529b\u4e4b\u540e\uff0c\u518d\u5229\u7528\u7a00\u758f\u6ce8\u610f\u529b\u5f97\u5230\u4e24\u5f20\u91c7\u6837\u56fe\uff0c\u901a\u8fc7\u5229\u7528\u91c7\u6837\u56fe\u5bf9\u539f\u56fe\u8fdb\u884c\u91cd\u91c7\u6837\uff0c\u4ece\u800c\u7a81\u51fa\u5c40\u90e8\u533a\u57df\u4e2d\u7684\u7ec6\u8282\uff0c\u5e76\u4e14\u4fdd\u7559\u4e86\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002\u4e24\u5f20\u91c7\u6837\u56fe\u5206\u522b\u7528\u4e8e\u5224\u522b\u5206\u652f\u548c\u4e92\u8865\u5206\u652f\uff0c\u5177\u4f53\u751f\u6210\u8fc7\u7a0b\u5982\u4e0b\uff1a $$ Q_d=\\sum A_i,\\quad if\\quad (x_i,y_i)\\in T_d\\\\ Q_c=\\sum A_i,\\quad if\\quad (x_i,y_i)\\in T_c. $$  \u5176\u4e2d\uff0cQ_d\u4e3a\u5224\u522b\u5206\u652f\u7684\u91c7\u6837\u56fe\uff0cQ_c\u4e3a\u4e92\u8865\u5206\u652f\u7684\u91c7\u6837\u56fe\u3002</p> <p>\u2003\u2003\u5982\u679c\u628a\u4e00\u822c\u7684\u666e\u901a\u91c7\u6837\u770b\u6210\u5747\u8861\u7684\u91c7\u6837\u8fc7\u7a0b\uff0c\u90a3\u4e48\u9009\u62e9\u6027\u91c7\u6837\u5c31\u53ef\u4ee5\u770b\u6210\u4e0d\u5747\u8861\u7684\u91c7\u6837\u8fc7\u7a0b\u3002\u5c06\u539f\u56feX\u770b\u6210\u4e00\u4e2a\u7f51\u683c\uff0c\u5c06\u7f51\u683c\u9876\u70b9\u8bbe\u7f6e\u4e3aV\uff0c\u666e\u901a\u7684\u91c7\u6837\u76f8\u5f53\u4e8e\u5728\u7f51\u683c\u4e0a\u5747\u5300\u53d6\u70b9\uff0c\u5982\u6bcf\u4e2a\u4e00\u4e2a\u70b9\u53d6\u4e00\u4e2a\u6570\u636e\uff0c\u6700\u540e\u7ecf\u8fc7\u4e0b\u91c7\u6837\u5f97\u5230\u7684\u56fe\u50cf\u957f\u5bbd\u5747\u662f\u539f\u6765\u7684\u4e00\u534a\uff0c\u5e76\u4e14\u56fe\u50cf\u6240\u8574\u542b\u7684\u4fe1\u606f\u5206\u5e03\u5927\u4f53\u4e0d\u53d8\uff1b\u9009\u62e9\u6027\u91c7\u6837\u4e5f\u662f\u5728\u7f51\u683c\u4e0a\u53d6\u70b9\uff0c\u4f46\u662f\u53d6\u70b9\u8fc7\u7a0b\u53d7\u91c7\u6837\u56fe\u7684\u5f71\u54cd\uff0c\u91c7\u6837\u56fe\u4e0a\u7684\u6570\u636e\u8d8a\u5927\uff0c\u5219\u5728\u8be5\u533a\u57df\u5468\u56f4\u53d6\u7684\u70b9\u5c31\u8d8a\u591a\uff0c\u6700\u540e\u7684\u91c7\u6837\u56fe\u4e2d\uff0c\u8be5\u533a\u57df\u4e0a\u7684\u4fe1\u606f\u5c31\u8d8a\u4e30\u5bcc\uff0c\u4e0e\u5229\u7528\u653e\u5927\u955c\u653e\u5927\u8be5\u533a\u57df\u7684\u6548\u679c\u7c7b\u4f3c\u3002\uff08\u5177\u4f53\u91c7\u6837\u539f\u7406\u89c1\u663e\u8457\u6027\u91c7\u6837\u7b14\u8bb0\uff09</p> <p>\u2003\u2003\u5229\u7528\u4e0a\u8ff0\u5f97\u5230\u7684\u91c7\u6837\u56fe\u53ef\u4ee5\u5f97\u5230\u4e24\u5e45\u91cd\u91c7\u6837\u56fe\u50cf\uff0c\u4e00\u4e2a\u5bf9\u5e94\u4e8e\u91c7\u6837\u56feQ_d\uff0c\u547d\u540d\u4e3a\u5224\u522b\u5206\u652f\u56fe\u50cf\uff0c\u7528\u4e8e\u7a81\u51fa\u5bf9\u5206\u7c7b\u6709\u91cd\u8981\u5f71\u54cd\u7684\u533a\u57df\uff1b\u53e6\u4e00\u4e2a\u5bf9\u5e94\u4e8e\u91c7\u6837\u56feQ_c\uff0c\u547d\u540d\u4e3a\u4e92\u8865\u5206\u652f\u56fe\u50cf\uff0c\u7528\u4e8e\u7a81\u51fa\u53ef\u80fd\u5b58\u5728\u5fae\u5c0f\u89c6\u89c9\u7ebf\u7d22\u7684\u533a\u57df\u3002\u5982\u56fe4\u6240\u793a\uff0c\u901a\u8fc7\u5b66\u4e60\u4e24\u79cd\u56fe\u50cf\uff0c\u5728\u63d0\u9ad8\u4e86\u7f51\u7edc\u6a21\u578b\u63d0\u53d6\u533a\u57df\u4fe1\u606f\u80fd\u529b\u7684\u540c\u65f6\uff0c\u8fd8\u53ef\u4ee5\u963b\u6b62\u5f3a\u5927\u7684\u7279\u5f81\u63a7\u5236\u68af\u5ea6\uff0c\u53bb\u9f13\u52b1\u6a21\u578b\u5b66\u4e60\u66f4\u591a\u7684\u56fe\u50cf\u8868\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u4f20\u7edf\u4e0d\u5e26\u6709\u9009\u62e9\u6027\u91c7\u6837\u7684\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u4e2d\uff0c\u6a21\u578b\u7684\u5b66\u4e60\u5bb9\u6613\u88ab\u5f3a\u7279\u5f81\u6240\u4e3b\u5bfc\uff0c\u5e76\u4e14\u4e0d\u80fd\u4fdd\u7559\u7ec6\u5fae\u7279\u5f81(\u5982\u4e0a\u56fe\u7b2c\u4e00\u884c\uff0c\u8fed\u4ee320\u6b21\u540e\uff0c\u70ed\u56fe\u53ea\u6709\u4e00\u4e2a\u660e\u663e\u7684\u5cf0\u503c\u54cd\u5e94)\u3002\u672c\u6587\u4e2d\u7684\u9009\u62e9\u6027\u91c7\u6837\u5e73\u8861\u4e86\u5224\u522b\u5206\u652f(\u7279\u5f81\u5f3a\u7684\u90e8\u5206)\u548c\u4e92\u8865\u5206\u652f(\u7279\u5f81\u76f8\u5bf9\u6bd4\u8f83\u5f31\u7684\u90e8\u5206)\uff0c\u7f51\u7edc\u6a21\u578b\u5177\u6709\u591a\u5143\u7684\u7279\u5f81\u8868\u793a\u80fd\u529b(\u5982\u4e0a\u56fe\u7b2c\u4e8c\u884c\uff0c\u52a0\u5165\u9009\u62e9\u6027\u91c7\u6837\u4e4b\u540e\uff0c\u540c\u6837\u8fed\u4ee320\u6b21\uff0c\u4f1a\u6709\u4e24\u4e2a\u660e\u663e\u7684\u5cf0\u503c)</p>"},{"location":"fine-grained/paper/S3N1/#_7","title":"\u8bad\u7ec3\u6d41\u7a0b","text":"<p>\u2003\u2003\u9996\u5148\u5c06\u539f\u56fe\u4f20\u5165\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u4e2d\u8fdb\u884c\u63d0\u53d6\u7279\u5f81\uff0c\u539f\u59cb\u56fe\u50cf\u7684\u7279\u5f81\u56fe\uff0c\u8fdb\u4e00\u6b65\u901a\u8fc7\u8ba1\u7b97\u5f97\u5230\u4e24\u4e2a\u91cd\u91c7\u6837\u56fe\u50cf\uff0c\u5206\u522b\u4e3a\u5224\u522b\u56fe\u50cf\u548c\u4e92\u8865\u56fe\u50cf\uff0c\u5176\u5927\u5c0f\u4e0e\u8f93\u5165\u56fe\u50cf\u5927\u5c0f\u76f8\u540c\uff0c\u7136\u540e\u4e24\u5f20\u56fe\u50cf\u518d\u6b21\u4f20\u5165\u76f8\u540c\u7684\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\uff0c\u5f97\u5230\u4e24\u7ec4\u7279\u5f81\u56fe\u3002\u4e0a\u8ff0\u5171\u5f97\u5230\u4e09\u7ec4\u7279\u5f81\u56fe\uff0c\u5206\u522b\u4e3a\u539f\u59cb\u56fe\u50cf\u7684\u7279\u5f81\u56fe\u3001\u5224\u522b\u56fe\u50cf\u7684\u7279\u5f81\u56fe\u3001\u4e92\u8865\u56fe\u50cf\u7684\u7279\u5f81\u56fe\uff0c\u5206\u522b\u5c06\u5176\u4f20\u5165\u5168\u8fde\u63a5\u5c42\uff0c\u5f97\u5230\u4e09\u7ec4\u5206\u7c7b\u9884\u6d4b\u7ed3\u679c\uff0c\u5e76\u4e14\u6700\u540e\u5c06\u4e09\u7ec4\u7279\u5f81\u56fe\u8fde\u63a5\u8d77\u6765\uff0c\u6700\u540e\u4f20\u5165\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42\u5f97\u5230\u7b2c\u56db\u7ec4\u9884\u6d4b\u7ed3\u679c\u3002</p>"},{"location":"fine-grained/paper/S3N1/#_8","title":"\u635f\u5931\u51fd\u6570","text":"<p>\u2003\u2003\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6574\u4e2a\u7f51\u7edc\u7684\u635f\u5931\u7531\u4e0a\u8ff0\u56db\u7ec4\u9884\u6d4b\u7ed3\u679c\u5171\u540c\u8ba1\u7b97\u5f97\u5230\uff1a $$ L(X)=\\sum_{i\\in {O,D,C}}L_{cls}(Y^i,Y^*)+L_{cls}(Y^j,Y^*) $$  \u5176\u4e2d\uff0cL_{cls}\u8868\u793a\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0cY^i\u548cY^j\u8868\u793a\u9884\u6d4b\u6982\u7387\uff0cY^*\u8868\u793a\u6807\u7b7e\u503c\uff0cO\u3001D\u3001C\u5206\u522b\u8868\u793a\u539f\u59cb\u56fe\u50cf\u3001\u5224\u522b\u56fe\u50cf\u3001\u4e92\u8865\u56fe\u50cf</p> <p>\u2003\u2003\u6700\u540e\u5229\u7528L(X)\u6765\u4f18\u5316\u7f51\u7edc\u7684\u53c2\u6570\u3002</p>"},{"location":"fine-grained/paper/S3N1/#_9","title":"\u5b9e\u9a8c","text":""},{"location":"fine-grained/paper/S3N1/#_10","title":"\u7a00\u758f\u6ce8\u610f\u529b\u5206\u6790","text":"<p> \u2003\u7a00\u758f\u6ce8\u610f\u529b\u6700\u91cd\u8981\u7684\u5c31\u662f\u5b9a\u4f4d\u7684\u80fd\u529b\uff0c\u53ea\u6709\u5f53\u5cf0\u503c\u54cd\u5e94\u70b9\u6b63\u786e\u5b9a\u4f4d\u5728\u7269\u4f53\u8eab\u4e0a\u624d\u80fd\u8bf4\u660e\u8be5\u6ce8\u610f\u529b\u662f\u6709\u6548\u7684\u3002\u4e3a\u6b64\uff0c\u4f5c\u8005\u7b5b\u9009\u4e86\u90e8\u5206\u56fe\u7247\uff0c\u5c06\u7a00\u758f\u6ce8\u610f\u529b\u6240\u5173\u6ce8\u7684\u5173\u952e\u70b9\u53ef\u89c6\u5316\u4e86\u51fa\u6765\uff0c\u5177\u4f53\u5982\u4e0b\u56fe\u53f3\u4fa7\u6240\u793a\uff0c\u6bcf\u4e2a\u5cf0\u503c\u54cd\u5e94\u70b9\u90fd\u843d\u5728\u7269\u4f53\u4e0a\u9762\uff0c\u5e76\u4e14\u5305\u542b\u5728\u5bf9\u8c61\u8fb9\u754c\u6846\u5185\u90e8\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u4f5c\u8005\u8fd8\u8fdb\u4e00\u6b65\u7edf\u8ba1\u4e86CUB\u6570\u636e\u96c6\u4e2d\u6bcf\u5e45\u56fe\u50cf\u7684\u6700\u5927\u548c\u6700\u5c0f\u7a00\u758f\u6ce8\u610f\u529b\uff0c\u5e76\u4e14\u7ed8\u5236\u4e86\u5982\u4e0b\u6761\u5f62\u56fe\uff1a</p> <p> <p></p> <p></p> <p>\u4ece\u56fe\u4e2d\u53ef\u4ee5\u53d1\u73b0\uff0c\u5728CUB\u6570\u636e\u96c6\u4e2d\uff0cS3N\u7684\u5224\u522b\u5206\u652f\u901a\u5e38\u5bf9\u4fe1\u606f\u4e30\u5bcc\u7684\u533a\u57df\u8fdb\u884c\u91c7\u6837\uff0c\u5982\u201d\u5589\u90e8\u201c\u3001\u201d\u9888\u80cc\u201c\u3001\u201d\u51a0\u90e8\u201c\u7b49\u4f5c\u4e3a\u6709\u529b\u7684\u5224\u65ad\u8bc1\u636e\uff0c\u4ece\u800c\u7ed9\u51fa\u7ec6\u7c92\u5ea6\u9e1f\u7c7b\u7c7b\u522b\u7684\u4e3b\u8981\u51b3\u7b56\uff1b\u800c\u4e92\u8865\u5206\u652f\u901a\u5e38\u91c7\u96c6\u4fe1\u606f\u8f83\u5f31\u7684\u533a\u57df\u6765\u63d0\u4f9b\u652f\u6301\u4fe1\u606f(supportive information)\uff0c\u5982\u201c\u7fc5\u8180\u201d\u3001\u201c\u817f\u201d\u7b49\u3002</p>"},{"location":"fine-grained/paper/S3N1/#_11","title":"\u53ef\u89c6\u5316\u5bf9\u6bd4","text":"<p>\u2003\u2003\u4e3a\u4e86\u8fdb\u4e00\u6b65\u8bc1\u660e\u7a00\u758f\u6ce8\u610f\u529b\u7684\u6709\u6548\u6027\uff0c\u4f5c\u8005\u5c06S3N\u4e0eResNet50\u4e2d\u95f4\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u505a\u4e86\u53ef\u89c6\u5316\u5bf9\u6bd4\u3002\u5982\u4e0b\u56fe\u524d\u56db\u884c\u6240\u793a\uff0c\u57fa\u7ebf\u6a21\u578b\u5927\u591a\u53ea\u80fd\u89c2\u5bdf\u5230\u4e00\u5c0f\u90e8\u5206\u533a\u57df\uff0c\u4e0d\u80fd\u5f88\u597d\u5730\u7ed3\u5408\u5bf9\u8c61\u6574\u4f53\u533a\u57df\u8fdb\u884c\u51b3\u7b56\uff08\u6709\u70b9\u7c7b\u4f3c\u8fc7\u62df\u5408\uff09\uff0c\u800cS3N\u53ef\u4ee5\u5c06\u5bf9\u8c61\u7684\u5927\u90e8\u5206\u533a\u57df\u4f5c\u4e3a\u5224\u65ad\u4f9d\u636e\uff0c\u901a\u8fc7\u8003\u8651\u7269\u4f53\u7684\u6574\u4f53\u7279\u5f81\u6765\u505a\u51fa\u66f4\u52a0\u51c6\u786e\u7684\u9884\u6d4b\u3002\u4f46\u540e\u4e24\u884c\u5c55\u793a\u4e86S3N\u5206\u7c7b\u5931\u8d25\u7684\u4f8b\u5b50\uff0c\u4f5c\u8005\u63a8\u6d4b\u53ef\u80fd\u662f\u80cc\u666f\u4e0e\u76ee\u6807\u76f8\u4f3c\u65f6\uff0c\u4e92\u8865\u5206\u652f\u6240\u5b66\u7684\u7279\u5f81\u5bf9\u4e8e\u5206\u7c7b\u51b3\u7b56\u6ca1\u6709\u7528\u5904\uff08\u751a\u81f3\u6709\u5bb3\uff09\u3002</p> <p> <p></p> <p></p>"},{"location":"fine-grained/paper/S3N1/#_12","title":"\u7cbe\u5ea6\u5bf9\u6bd4","text":"<p> <p></p> <p></p>"},{"location":"fine-grained/paper/S3N1/#_13","title":"\u603b\u7ed3","text":"<p>\u2003\u2003S3N\u6838\u5fc3\u601d\u60f3\u5c31\u662f\u5229\u7528\u56fe\u50cf\u5206\u7c7b\u7f51\u7edc\u5b66\u4e60\u5230\u7684\u7c7b\u5cf0\u503c\u54cd\u5e94\u6765\u4f30\u8ba1\u7ec6\u7c92\u5ea6\u56fe\u50cf\u7684\u4fe1\u606f\u533a\u57df\uff0c\u518d\u5229\u7528\u8be5\u533a\u57df\u6307\u5bfc\u5bf9\u539f\u56fe\u7684\u9009\u62e9\u6027\u91c7\u6837\u8fc7\u7a0b\uff0c\u4ece\u800c\u7a81\u51fa\u56fe\u50cf\u4e2d\u7684\u7ec6\u8282\u5e76\u4e14\u4e0d\u4e22\u5931\u5468\u56f4\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002\u901a\u8fc7\u5c06\u91cd\u91c7\u6837\u540e\u7684\u56fe\u50cf\u518d\u6b21\u4f20\u5165\u76f8\u540c\u7684\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u4e2d\uff0c\u6765\u66f4\u65b0\u6240\u5b66\u4e60\u7684\u7c7b\u5cf0\u503c\u54cd\u5e94\u3002\u8be5\u7f51\u7edc\u63d0\u51fa\u4e86\u4e24\u79cd\u91c7\u6837\u5206\u652f\uff0c\u4e00\u79cd\u662f\u5bf9\u56fe\u50cf\u5cf0\u503c\u54cd\u5e94\u70b9\u4e2d\u54cd\u5e94\u503c\u8f83\u9ad8\u7684\u5c40\u90e8\u533a\u57df\u8fdb\u884c\u91c7\u6837(\u5224\u522b\u5206\u652f)\uff0c\u901a\u8fc7\u51f8\u663e\u56fe\u50cf\u5177\u6709\u533a\u5206\u6027\u7684\u89c6\u89c9\u4fe1\u606f\uff0c\u4ece\u800c\u63d0\u9ad8\u7f51\u7edc\u7279\u5f81\u63d0\u53d6\u7684\u80fd\u529b\uff1b\u53e6\u4e00\u79cd\u662f\u5bf9\u56fe\u50cf\u5cf0\u503c\u54cd\u5e94\u70b9\u4e2d\u54cd\u5e94\u503c\u8f83\u4f4e\u7684\u5168\u5c40\u533a\u57df\u8fdb\u884c\u91c7\u6837(\u4e92\u8865\u5206\u652f)\uff0c\u901a\u8fc7\u51f8\u663e\u56fe\u50cf\u4e2d\u5dee\u5f02\u5c0f\u7684\u533a\u57df\uff0c\u8ba9\u7f51\u7edc\u63a2\u7d22\u56fe\u50cf\u4e2d\u7684\u5fae\u5c0f\u5dee\u5f02\uff0c\u9f13\u52b1\u7f51\u7edc\u6316\u6398\u5176\u4ed6\u7684\u89c6\u89c9\u7ebf\u7d22\uff0c\u4ece\u800c\u63d0\u9ad8\u7f51\u7edc\u591a\u5143\u7279\u5f81\u8868\u793a\u7684\u80fd\u529b\u3002\u4e0a\u8ff0\u4e24\u4e2a\u5206\u652f\u662f\u76f8\u8f85\u76f8\u6210\u7684\uff0c\u5728\u63d0\u9ad8\u7f51\u7edc\u8bc6\u522b\u7cbe\u5ea6\u7684\u540c\u65f6\u8fd8\u63d0\u9ad8\u4e86\u7f51\u7edc\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u63d0\u9ad8\u4e86\u8bc6\u522b\u5206\u7c7b\u7684\u7a33\u5b9a\u6027\u3002</p> <p>\u2003\u2003\u5e76\u4e14\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u7528\u4e8e\u5212\u5206\u5224\u522b\u533a\u57df\u548c\u4e92\u8865\u533a\u57df\u7684\u9608\u503c\u662f\u57280-1\u7684\u5747\u5300\u5206\u90e8\u5185\u968f\u673a\u9009\u53d6\u7684\uff0c\u5e76\u4e0d\u662f\u56fa\u5b9a\u5730\u9009\u53d6\u67d0\u4e00\u4e2a\u503c\u5f53\u505a\u5212\u5206\u9608\u503c\uff0c\u56e0\u6b64\uff0c\u4e24\u4e2a\u5206\u652f\u7684\u5212\u5206\u5177\u6709\u52a8\u6001\u6027\uff0c\u4e24\u4e2a\u7a00\u758f\u6ce8\u610f\u529b\u5173\u6ce8\u533a\u57df\u7684\u6570\u91cf\u662f\u52a8\u6001\u53d8\u5316\u7684\uff0c\u4e3a\u6a21\u578b\u7684\u8bad\u7ec3\u5f15\u5165\u4e86\u4e00\u5b9a\u7684\u968f\u673a\u6210\u5206\uff0c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63d0\u9ad8\u7f51\u7edc\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u63d0\u9ad8\u7a33\u5b9a\u6027\u3002</p> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u5927\u5bb6\u6279\u8bc4\u6307\u6b63\u3002</p> <p>\u521d\u6b65\u5b8c\u7a3f\uff1a2021\u5e7411\u67086\u65e5\uff0c\u6700\u540e\u4e00\u6b21\u4fee\u6539\uff1a2022\u5e743\u670823\u65e5</p>"},{"location":"fine-grained/paper/SPS1/","title":"\u7ec6\u7c92\u5ea6\uff1aSPS","text":""},{"location":"fine-grained/paper/SPS1/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aIEEE International Conference on Computer Vision 2021 (ICCV, 2021)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content/ICCV2021/papers/Huang_Stochastic_Partial_Swap_Enhanced_Model_Generalization_and_Interpretability_for_Fine-Grained_ICCV_2021_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740(PyTorch\u7248\u672c)\uff1ahttps://github.com/Shaoli-Huang/SPS</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u7c7b(FGVC)</p>"},{"location":"fine-grained/paper/SPS1/#_2","title":"\u4e3b\u8981\u601d\u60f3","text":"<p>\u2003\u2003\u7531\u4e8e\u540c\u4e00\u7c7b\u522b\u4e2d\u4e0d\u540c\u5b50\u7c7b\u7684\u5dee\u5f02\u901a\u5e38\u5b58\u5728\u4e8e\u5bf9\u8c61\u7684\u5fae\u5c0f\u90e8\u5206\uff0c\u56e0\u6b64\u7ec6\u7c92\u5ea6\u5206\u7c7b\u8981\u6bd4\u4e00\u822c\u7684\u7269\u4f53\u5206\u7c7b\u8981\u56f0\u96be\u3002\u4f20\u7edf\u9488\u5bf9\u5927\u7c7b\u522b\u5206\u7c7b\u7684\u7b97\u6cd5\u901a\u5e38\u4e0d\u80fd\u5728\u7ec6\u7c92\u5ea6\u5206\u7c7b\u4e2d\u53d6\u5f97\u6bd4\u8f83\u597d\u7684\u6548\u679c\uff0c\u56e0\u4e3a\u4ed6\u4eec\u5927\u90e8\u5206\u90fd\u53ea\u5173\u6ce8\u4e8e\u5b66\u4e60\u9ad8\u7ea7\u7279\u5f81\u8868\u793a\uff0c\u5ffd\u7565\u4e86\u7ec6\u5fae\u7684\u53d8\u5316\u3002\u8fd1\u51e0\u5e74\u7684\u7814\u7a76\u4e2d\uff0c\u57fa\u4e8e\u90e8\u4ef6\u5b9a\u4f4d\u548c\u57fa\u4e8e\u91c7\u6837\u7684\u65b9\u6cd5\u662f\u89e3\u51b3\u7ec6\u7c92\u5ea6\u4efb\u52a1\u6bd4\u8f83\u6d41\u884c\u7684\u65b9\u6cd5\u3002\u524d\u8005\u4e3b\u8981\u662f\u5229\u7528\u5f3a\u76d1\u7763\u68c0\u6d4b(\u5982\u4eba\u4e3a\u6807\u6ce8\u68c0\u6d4b\u6846)\u6216\u8005\u5229\u7528\u5f31\u76d1\u7763\u5b66\u4e60\u7684\u6846\u67b6\u6765\u5b9a\u4f4d\u7269\u4f53\u7684\u90e8\u4ef6\u533a\u57df(part regions)\uff0c\u5982\uff1aRA-CNN(\u8bba\u6587\u7b14\u8bb0)\u3001NTS-Net(\u8bba\u6587\u7b14\u8bb0)\uff1b\u540e\u8005\u4e3b\u8981\u662f\u5229\u7528\u6ce8\u610f\u529b\u56fe\u6765\u5bf9\u8f93\u5165\u56fe\u50cf\u505a\u975e\u5747\u5300\u91c7\u6837\uff0c\u4ece\u800c\u4e30\u5bcc\u8868\u5f81\u5b66\u4e60\uff0c\u5982S3N(\u8bba\u6587\u7b14\u8bb0)\u3001TASN(\u8bba\u6587)\u3002\u867d\u7136\u8fd9\u4e24\u79cd\u65b9\u6cd5\u90fd\u53ef\u4ee5\u6210\u529f\u5730\u63d0\u9ad8\u8bc6\u522b\u6027\u80fd\uff0c\u4f46\u662f\u4ed6\u4eec\u6709\u7684\u8bad\u7ec3\u8fc7\u7a0b\u975e\u5e38\u590d\u6742\uff0c\u6709\u7684\u5728\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\u5f15\u5165\u4e86\u5927\u91cf\u7684\u989d\u5916\u8ba1\u7b97\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u7684\u5e94\u7528\u3002</p> <p>\u2003\u2003\u6700\u8fd1\u7684\u7814\u7a76\u4e2d\u53d1\u73b0\uff0c\u7531\u4e8e\u4e2d\u7ea7\u6a21\u578b(mid-level model)\u72ec\u7279\u7684\u4f18\u70b9\uff0c\u5c06\u4e2d\u7ea7\u6a21\u578b\u7ed3\u5408\u5230\u7ec6\u7c92\u5ea6\u8bc6\u522b\u4e2d\u4e5f\u53ef\u4ee5\u83b7\u5f97\u5f88\u597d\u7684\u8bc6\u522b\u6548\u679c\uff0c\u5982Cross-X(\u8bba\u6587\u7b14\u8bb0)\u3001MGE-CNN(\u8bba\u6587)\u3001DFL-CNN(\u8bba\u6587)\u3002\u9996\u5148\uff0c\u7531\u4e8e\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u5c42\u6b21\u7ed3\u6784\uff0c\u4e2d\u7ea7\u6a21\u578b\u5bb9\u6613\u83b7\u5f97\uff0c\u5e76\u4e14\u5f00\u53d1\u7075\u6d3b\uff1b\u5176\u6b21\uff0c\u5b83\u4eec\u4e5f\u53ef\u4ee5\u5f88\u597d\u5730\u6355\u6349\u5c40\u90e8\u4fe1\u606f\uff0c\u5e76\u4e14\u4e3a\u7ec6\u7c92\u5ea6\u8bc6\u522b\u4e2d\u7684\u9ad8\u7ea7\u8868\u793a\u65b9\u6cd5\u505a\u91cd\u8981\u8865\u5145\u3002Cross-X\u6587\u7ae0\u4e2d\u8bc1\u660e\uff1a\u8026\u5408\u4e2d\u7ea7\u8868\u793a\u548c\u9ad8\u7ea7\u8868\u793a\u786e\u5b9e\u4f1a\u63d0\u9ad8\u6a21\u578b\u7684\u5206\u7c7b\u6027\u80fd\u3002\u5c3d\u7ba1\u4e2d\u7ea7\u8868\u793a\u5728\u7ec6\u7c92\u5ea6\u5206\u7c7b\u4e2d\u8868\u73b0\u51fa\u4e86\u826f\u597d\u7684\u6548\u679c\uff0c\u4f46\u662f\u4e4b\u524d\u7684\u7814\u7a76\u90fd\u662f\u4ee5\u5373\u63d2\u5373\u7528(plug-and-play)\u7684\u65b9\u5f0f\u91c7\u7528\u73b0\u6210\u7684\u4e2d\u7ea7\u6a21\u578b\u6765\u8fdb\u884c\u9884\u6d4b\uff0c\u800c\u4e0d\u662f\u589e\u5f3a\u4e2d\u7ea7\u6a21\u578b\u672c\u8eab\u7684\u6027\u80fd\u3002\u672c\u6587\u4e2d\uff0c\u4f5c\u8005\u56f4\u7ed5\u201c\u4e2d\u7ea7\u8868\u793a\u201d(mid-level representations)\u5c55\u5f00\u7814\u7a76\uff0c\u52aa\u529b\u8ba9\u6a21\u578b\u5b66\u4e60\u66f4\u597d\u7684\u4e2d\u7ea7\u8868\u793a\u6765\u8fdb\u884c\u7ec6\u7c92\u5ea6\u8bc6\u522b\u3002</p> <p>\u2003\u2003\u4f5c\u8005\u89c2\u5bdf\u5230\uff0c\u4e2d\u7ea7\u6a21\u578b\u4e3b\u8981\u57fa\u4e8e\u56fe\u7247\u4e2d\u5c11\u91cf\u7684\u56fe\u7247\u533a\u57df\u6765\u51b3\u5b9a\u6700\u7ec8\u7684\u6807\u7b7e\u3002\u5982\u4e0b\u56fe\u5de6\u4fa7\u6240\u793a\uff0c\u5bf9\u4e8e\u5728CUB\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684\u57fa\u7ebf\u6a21\u578b\uff0c\u4e2d\u7ea7\u7279\u5f81\u56fe\u5171\u6709784\u4e2a\u533a\u57df(\u4ee5\u8f93\u5165\u56fe\u50cf\u5c3a\u5bf8448\u4e3a\u4f8b)\uff0c\u5e73\u5747\u524d35.74\u4e2a\u54cd\u5e94\u503c\u6700\u5927\u7684\u533a\u57df\u8d21\u732e\u4e86\u6700\u7ec8\u9884\u6d4b\u5206\u6570\u768499%\uff0c\u56e0\u6b64\u4f5c\u8005\u63a8\u6d4b\uff0c\u8fd9\u53ef\u80fd\u662f\u7531\u4e8e\u4e00\u4e9b\u7a33\u5b9a\u7684\u7269\u4f53\u90e8\u4ef6(object parts)\u4f53\u73b0\u51fa\u4e86\u975e\u5e38\u5f3a\u5927\u7684\u53ef\u8fa8\u522b\u6027\uff0c\u56e0\u6b64\u795e\u7ecf\u7f51\u7edc\u66f4\u591a\u7684\u5c06\u6743\u91cd\u504f\u5411\u8fd9\u51e0\u4e2a\u6a21\u5757\u3002\u5982\u4e0b\u56fe\u53f3\u4fa7\u6240\u793a\uff0c\u7ea2\u8272\u548c\u9ec4\u8272\u662f\u7ea2\u7fc5\u9ed1\u9e42(Red-winged Blackbird)\u53ef\u8fa8\u8bc6\u7684\u90e8\u4f4d\u6a21\u5f0f\uff0c\u56e0\u6b64\u7f51\u7edc\u8d8b\u5411\u4e8e\u5b66\u4e60\u5bf9\u8fd9\u79cd\u6a21\u5f0f\u54cd\u5e94\u66f4\u9ad8\u7684\u795e\u7ecf\u5143\uff0c\u4f7f\u5176\u5bf9\u6700\u7ec8\u7684\u9884\u6d4b\u8d77\u5230\u4e3b\u5bfc\u4f5c\u7528\u3002\u56e0\u6b64\uff0c\u6240\u5b66\u5230\u7684\u6a21\u578b\u5c06\u4f1a\u975e\u5e38\u5bb9\u6613\u88ab\u6709\u9650\u7684\u90e8\u4ef6\u6a21\u5f0f\u6240\u4e3b\u5bfc\uff0c\u964d\u4f4e\u4e86\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002</p> <p> <p></p> <p></p> <p>\u2003\u2003\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u73b0\u8c61\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u968f\u673a\u90e8\u5206\u4ea4\u6362(Stochastic Partial Swap, SPS)\u7b56\u7565\u53bb\u589e\u5f3a\u4e2d\u7ea7\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u8be5\u7b56\u7565\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u968f\u673a\u9009\u62e9\u4e00\u4e2a\u6837\u672c\u7279\u5f81\u4f5c\u4e3a\u566a\u58f0\u6e90\u5e76\u4e14\u5c06\u5b83\u7684\u4e00\u4e9b\u7279\u5f81\u5143\u7d20\u4e0e\u53e6\u4e00\u4e2a\u6837\u672c\u76f8\u5e94\u4f4d\u7f6e\u7684\u7279\u5f81\u5143\u7d20\u505a\u4ea4\u6362\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u4e0e\u73b0\u6709\u7684\u6ce8\u5165\u566a\u58f0\u7b56\u7565\u4e0d\u540c\uff0c\u4f5c\u8005\u63d0\u51fa\u7684\u65b9\u6cd5\u662f\u5229\u7528\u6837\u672c\u7279\u5f81\u4f5c\u4e3a\u566a\u58f0\u6e90\uff0c\u800c\u6ce8\u5165\u566a\u58f0\u662f\u968f\u673a\u5728\u6837\u672c\u7279\u5f81\u4e2d\u6ce8\u5165\u5176\u4ed6\u7684\u503c\uff0c\u5982DropOut\u662f\u968f\u673a\u4e22\u5f03\u7279\u5f81\uff0c\u5373\u5728\u539f\u6837\u672c\u7279\u5f81\u4e2d\u6ce8\u5165\u96f6\uff0c\u7528\u4e8e\u964d\u4f4e\u8fc7\u62df\u5408\u98ce\u9669\u3002</p> <p> <p></p> <p></p> <p>\u2003\u2003\u4f5c\u8005\u63d0\u51fa\u7684\u7b56\u7565\u5728\u5b66\u4e60\u4e2d\u7ea7\u7279\u5f81\u8868\u793a\u65b9\u9762\u6709\u5982\u4e0b\u51e0\u4e2a\u4f18\u52bf\uff1a</p> <ul> <li>\u5982\u679c\u5927\u90e8\u5206\u6362\u5165\u7684\u795e\u7ecf\u5143\u90fd\u662f\u4e0d\u6d3b\u8dc3\u7684\uff0c\u5219\u8be5\u65b9\u6cd5\u5c31\u7c7b\u4f3cDropOut\uff0c\u53ef\u4ee5\u9f13\u52b1\u66f4\u591a\u7684\u795e\u7ecf\u5143\u8fdb\u884c\u7279\u5f81\u8868\u793a\uff1b</li> <li>\u5e2e\u52a9\u6291\u5236\u67d0\u4e9b\u4e3b\u5bfc\u9884\u6d4b\u7684\u795e\u7ecf\u5143\u3002\u4f8b\u5982\uff1a\u5982\u679c\u4e00\u4e9b\u5728\u9884\u6d4b\u4e00\u4e2a\u7279\u5b9a\u7684\u7c7b\u522b\u4e2d\u8d77\u4e3b\u5bfc\u4f5c\u7528\u7684\u795e\u7ecf\u5143\u88ab\u4ea4\u6362\u5230\u53e6\u4e00\u4e2a\u7c7b\u522b\u7684\u4e00\u4e2a\u6837\u672c\u7279\u5f81\u4e2d\uff0c\u5b83\u53ef\u80fd\u4f1a\u5bfc\u81f4\u8be5\u6837\u672c\u7684\u9519\u8bef\u9884\u6d4b\uff0c\u6700\u540e\uff0c\u635f\u5931\u51fd\u6570\u4f1a\u60e9\u7f5a\u8fd9\u4e9b\u795e\u7ecf\u5143\u8bef\u5bfc\u6027\u7684\u5f71\u54cd\uff1b</li> <li>\u589e\u5f3a\u6a21\u578b\u5206\u7c7b\u5668\u7684\u9c81\u68d2\u6027\u3002\u4f8b\u5982\uff1a\u4ea4\u6362\u7c7b\u5185\u7684\u6837\u672c\u7279\u5f81\uff0c\u4f1a\u8ba9\u5206\u7c7b\u5668\u770b\u5230\u8be5\u7c7b\u66f4\u591a\u7684\u7279\u5f81\u7ec4\u5408\u6a21\u5f0f\uff1b\u4ea4\u6362\u7c7b\u95f4\u7684\u6837\u672c\u7279\u5f81\uff0c\u4f1a\u8ba9\u795e\u7ecf\u5143\u4ea7\u751f\u4e00\u4e2a\u5305\u542b\u53e6\u4e00\u7c7b\u566a\u58f0\u6a21\u5f0f\u7684\u6837\u672c\u7279\u5f81\u3002\u540c\u65f6\u4e5f\u662f\u6a21\u62df\u771f\u5b9e\u566a\u58f0\u6570\u636e\u4ee5\u8bad\u7ec3\u5206\u7c7b\u5668\u7684\u66f4\u597d\u65b9\u6cd5\uff0c\u56e0\u4e3a\u4ee5\u5f80\u7684\u566a\u58f0\u6ce8\u5165\u65b9\u5f0f\u90fd\u662f\u6ce8\u5165\u4eba\u5de5\u566a\u58f0\uff0c\u800c\u5b83\u5c06\u4e00\u4e2a\u6837\u672c\u7684\u771f\u5b9e\u6fc0\u6d3b\u503c\u6ce8\u5165\u5230\u53e6\u4e00\u4e2a\u6837\u672c\uff0c\u66f4\u8d34\u5408\u5b9e\u9645\u60c5\u51b5\u3002</li> </ul>"},{"location":"fine-grained/paper/SPS1/#_3","title":"\u65b9\u6cd5","text":""},{"location":"fine-grained/paper/SPS1/#_4","title":"\u7f51\u7edc\u7ed3\u6784","text":"<p>\u2003\u2003\u7ec6\u7c92\u5ea6\u8bc6\u522b\u7684\u6807\u51c6\u65b9\u6cd5\u662f\u5728\u76ee\u6807\u8bad\u7ec3\u96c6\u4e0a\u5fae\u8c03\u4e3b\u5e72\u7f51\u7edc\uff0c\u6a21\u578b\u901a\u8fc7\u5728\u6700\u540e\u4e00\u5c42\u5377\u79ef\u5c42\u4e0a\u5e94\u7528\u5168\u5c40\u5e73\u5747\u6c60\u5316\u6765\u63d0\u53d6\u7279\u5f81\uff0c\u4ece\u800c\u6355\u6349\u76ee\u6807\u7684\u9ad8\u7ea7\u4fe1\u606f\u3002\u4f46\u662f\u5982\u4e0a\u6587\u6240\u8ff0\uff0c\u5728\u4ee5\u5f80\u7684\u7814\u7a76\u4e2d\u53d1\u73b0\uff0c\u7ec6\u7c92\u5ea6\u5206\u7c7b\u4efb\u52a1\u91cc\u4e2d\u7ea7\u8868\u793a\u5bf9\u9ad8\u7ea7\u8868\u793a\u5177\u6709\u8865\u5145\u6548\u679c\u3002\u53c2\u8003\u4e4b\u524d\u7684\u4e2d\u7ea7\u6a21\u578b\u7814\u7a76(Cross-X\u3001MGE-CNN\u3001DFL-CNN)\uff0c\u4f5c\u8005\u603b\u7ed3\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u5b66\u4e60\u6846\u67b6\u4f5c\u4e3a\u57fa\u7ebf\uff0c\u5177\u4f53\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\u3002\u57fa\u7ebf\u5c06\u4e00\u4e2a\u4e2d\u7ea7\u5206\u7c7b\u5206\u652f\u63d2\u5165\u5230\u6807\u51c6\u7684\u5206\u7c7b\u7f51\u7edc\u4e2d\uff0c\u65b0\u7684\u5206\u652f\u6a21\u5757\u75311\u00d71\u7684\u5377\u79ef\u5c42\u3001ReLU\u6fc0\u6d3b\u51fd\u6570\u5c42\u3001\u5168\u5c40\u6700\u5927\u6c60\u5316\u5c42\u6784\u6210\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u4e24\u4e2a\u5206\u652f\u8054\u5408\u8bad\u7ec3\u3002</p> <p> <p></p> <p></p>"},{"location":"fine-grained/paper/SPS1/#_5","title":"\u968f\u673a\u90e8\u5206\u4ea4\u6362","text":"<p>\u2003\u2003\u867d\u7136\u4e2d\u7ea7\u8868\u793a\u53ef\u4ee5\u8865\u5145\u9ad8\u7ea7\u8868\u793a\u4ee5\u63d0\u9ad8\u7cbe\u5ea6\uff0c\u4f46\u5355\u72ec\u4f7f\u7528\u65f6\u6027\u80fd\u4ecd\u4e0d\u80fd\u8ba9\u4eba\u6ee1\u610f\u3002\u5982\u4e0a\u6587\u5206\u6790\uff0c\u4e5f\u8bb8\u662f\u6240\u5b66\u7684\u4e2d\u7ea7\u6a21\u578b\u5f80\u5f80\u88ab\u5c11\u6570\u5177\u6709\u9ad8\u5ea6\u8fa8\u8bc6\u529b\u7684\u6a21\u5f0f(highly discriminative patterns)\u6240\u652f\u914d\uff0c\u4ece\u800c\u964d\u4f4e\u4e86\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u8fd9\u7c7b\u4f3c\u4e8e\u8fc7\u62df\u5408\u73b0\u8c61\uff0c\u6a21\u578b\u5224\u65ad\u56fe\u50cf\u7684\u7c7b\u522b\u8fc7\u5ea6\u4f9d\u8d56\u4e8e\u67d0\u4e2a\u795e\u7ecf\u5143(\u4e5f\u53ef\u4ee5\u8bf4\u662f\u8fc7\u5ea6\u4f9d\u8d56\u7269\u4f53\u7684\u67d0\u4e2a\u90e8\u4f4d\uff0c\u5982\u7b2c\u4e00\u5f20\u56fe\u7247\u4e2d\u7684\u7ea2\u8272\u533a\u57df)\u3002\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u6700\u81ea\u7136\u5730\u5c31\u662f\u60f3\u5230\u5728\u7279\u5f81\u5c42\u4e2d\u5e94\u7528DropOut\uff0c\u4f46\u7b80\u5355\u5730\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5c06\u4e00\u4e9b\u5143\u7d20\u62b9\u9664\u5e76\u4e0d\u4f1a\u6291\u5236\u67d0\u4e9b\u201c\u8fc7\u5ea6\u81ea\u4fe1\u7684\u201d\u795e\u7ecf\u5143(\u5e26\u6709\u975e\u5e38\u9ad8\u7684\u6fc0\u6d3b\u54cd\u5e94)\u3002\u56e0\u6b64\uff0c\u867d\u7136DropOut\u64cd\u4f5c\u53ef\u4ee5\u9f13\u52b1\u66f4\u591a\u7684\u795e\u7ecf\u5143\u8868\u793a\u4e00\u4e2a\u6982\u5ff5\uff0c\u4f46\u6700\u7ec8\u7684\u7279\u5f81\u8868\u793a\u4ecd\u53ef\u80fd\u4f1a\u7531\u67d0\u4e9b\u9ad8\u54cd\u5e94\u7684\u795e\u7ecf\u5143\u4e3b\u5bfc\u3002\u4e3a\u4e86\u7ea0\u6b63\u8fd9\u4e00\u73b0\u8c61\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u968f\u673a\u90e8\u5206\u4ea4\u6362\u5b66\u4e60\u7b56\u7565\uff0c\u4ed6\u5bf9\u4e0d\u540c\u6837\u672c\u4e4b\u95f4\u6267\u884c\u5143\u7d20\u4ea4\u6362\uff0c\u4ece\u800c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6ce8\u5165\u66f4\u52a0\u771f\u5b9e\u7684\u566a\u58f0\u3002</p> <p>\u566a\u58f0\u6ce8\u5165\uff1a</p> <p>\u2003\u2003SPS\u4e3b\u8981\u7684\u601d\u60f3\u5c31\u662f\u5c06\u4e00\u4e2a\u6837\u672c\u7684\u7279\u5f81\u6ce8\u5165\u5230\u53e6\u4e00\u4e2a\u6837\u672c\u4e2d\u3002\u5bf9\u4e8e\u5c0f\u6279\u91cf(mini-batch)\u4e2d\u7684\u6bcf\u4e2a\u6837\u672c\uff0c\u9996\u5148\u968f\u673a\u9009\u62e9\u5f53\u524d\u6279\u91cf\u4e2d\u7684\u53e6\u4e00\u4e2a\u6837\u672c\u4f5c\u4e3a\u566a\u58f0\u6e90\uff0c\u7136\u540e\u9010\u4e2a\u5143\u7d20\u5730\u4ea4\u6362\u4ed6\u4eec\u7684\u90e8\u5206\u7279\u5f81\u3002\u7ed9\u4e00\u4e2a\u6837\u672cx_i\uff0c\u5e76\u4e14\u5728\u540c\u4e00\u4e2a\u6279\u91cf\u4e2d\u968f\u673a\u9009\u62e9\u53e6\u5916\u4e00\u4e2a\u6837\u672cx_j\uff0c\u566a\u58f0\u6ce8\u5165\u7684\u64cd\u4f5c\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ \\tilde{f}^m_{\\rho\\sim U(\\alpha ,\\beta)}(x_i)=M\\odot f^m(x_i)+(1-M)\\odot f^m(x_j) $$  \u5176\u4e2d\uff0cU(\\alpha ,\\beta)\u8868\u793a\\alpha\u5230\\beta\u4e4b\u95f4\u7684\u5747\u5300\u5206\u5e03\uff0c\\odot\u8868\u793a\u5143\u7d20\u70b9\u4e58\uff0cf^m(\u00b7)\u8868\u793a\u4e2d\u7ea7\u5206\u652f\u7684\u7279\u5f81\u63d0\u53d6\u5668\uff0cM\\in \\mathbb R^{dim(f^m(x))}\u8868\u793a\u4e8c\u5143\u63a9\u6a21\u3002\u8fd9\u91cc\uff0c\u57fa\u4e8e\u5f97\u5230\u7684\u53c2\u6570\\rho\u6765\u751f\u6210M\uff0c\u901a\u8fc7M\u6765\u6307\u5b9a\u9700\u8981\u4ea4\u6362\u7684\u5143\u7d20\uff0cM\u8ba1\u7b97\u516c\u5f0f\u5982\u4e0b\uff1a $$ M[k]=\\left\\{ \\begin{matrix} 1\\quad rand(0,1)\u2264\\rho\\\\0\\quad rand(0,1)&gt;\\rho \\end{matrix} \\right. $$  \u5176\u4e2d\uff0ck\\in[0,dim(f^m(x))-1]\u4e3a\u7ef4\u5ea6\u7d22\u5f15\uff0c\\rho\u8d8a\u5927\uff0c\u8868\u793a\u5143\u7d20\u8d8a\u6709\u53ef\u80fd\u88ab\u4ea4\u6362\u3002</p> <p>\u8bad\u7ec3\u635f\u5931\uff1a</p> <p>\u2003\u2003\u5982\u4e0a\u6240\u8ff0\uff0c\u4f5c\u8005\u901a\u8fc7\u4ea4\u6362\u67d0\u4e9b\u7279\u5f81\u5355\u5143\u6765\u6ce8\u5165\u566a\u58f0\uff0c\u6709\u52a9\u4e8e\u7f51\u7edc\u9632\u6b62\u8fc7\u5ea6\u5173\u6ce8\u5c11\u91cf\u7684\u5224\u522b\u6a21\u5f0f(discriminative patterns)\u3002\u53e6\u5916\uff0c\u8be5\u7b56\u7565\u8fd8\u53ef\u4ee5\u63d0\u4f9b\u6a21\u62df\u566a\u58f0\u6a21\u5f0f\u7684\u6837\u672c\uff0c\u4ece\u800c\u589e\u5f3a\u5206\u7c7b\u5668\u5bf9\u566a\u58f0\u7684\u9c81\u68d2\u6027\u3002\u4e3a\u4e86\u653e\u5927\u8fd9\u4e9b\u7279\u5f81\uff0c\u4f5c\u8005\u8fd8\u591a\u6b21\u5e94\u7528\u566a\u58f0\u6ce8\u5165\u64cd\u4f5c\uff0c\u4ece\u800c\u5728\u6bcf\u4e2a\u5c0f\u6279\u91cf\u4e2d\u4ea7\u751f\u66f4\u591a\u7684\u6270\u52a8\u60c5\u51b5\u3002\u56e0\u6b64\uff0c\u5355\u4e2a\u8bad\u7ec3\u6837\u672c(x_i, y_i)\u7684\u8bad\u7ec3\u635f\u5931\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ \\sum^T_{t=1}\\mathcal L(C^m(\\tilde{f}^m_{\\rho\\sim U(\\alpha,\\beta)}),y_i)+\\lambda\\mathcal L(C^g(f^g(x_i)),y_i) $$  \u5176\u4e2d\uff0c\\mathcal L(\u00b7)\u8868\u793a\u4ea4\u53c9\u71b5\u635f\u5931\uff0cT\u8868\u793a\u566a\u58f0\u6ce8\u5165\u5e94\u7528\u4e8e\u6837\u672c\u7684\u6b21\u6570(\u7279\u5f81\u5143\u7d20\u4ea4\u6362\u7684\u6b21\u6570)\uff0cC(\u00b7)\u8868\u793a\u5206\u7c7b\u5668\uff0cf^g(\u00b7)\u8868\u793a\u9ad8\u7ea7\u5206\u652f\u7684\u7279\u5f81\u63d0\u53d6\u5668\u3002</p> <p>\u2003\u2003\u6ce8\uff1a\u566a\u58f0\u6ce8\u5165\u53ea\u662f\u4e00\u79cd\u63d0\u9ad8\u6a21\u578b\u7279\u5f81\u63d0\u53d6\u80fd\u529b\u7684\u7b56\u7565\uff0c\u56e0\u6b64\u5728\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\u4e0d\u9700\u8981\u6ce8\u5165\u566a\u58f0\u3002</p>"},{"location":"fine-grained/paper/SPS1/#_6","title":"\u5b9e\u9a8c\u5206\u6790","text":"<p>\u91cf\u5316\u56fe\u50cf\u533a\u57df\u5bf9\u9884\u6d4b\u7684\u8d21\u732e\uff1a</p> <p>\u2003\u2003\u4e3a\u4e86\u8fdb\u4e00\u6b65\u89c2\u6d4b\u5b66\u4e60\u4e2d\u7ea7\u7279\u5f81\u8868\u793a\u5e26\u6765\u7684\u95ee\u9898\uff0c\u4f5c\u8005\u7edf\u8ba1\u4e86\u56fe\u50cf\u4e2d\u4e3b\u8981\u4f7f\u7528\u591a\u5c11\u533a\u57df\u6765\u8fdb\u884c\u9884\u6d4b\u3002\u9996\u5148\u6307\u5b9a\u4e00\u5f20\u6807\u7b7e\u4e3ay\u7684\u56fe\u50cfI\uff0c\u5c06\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u8868\u793a\u4e3aF\\in \\mathcal R^{d\\times a\\times b}\uff0c\u5176\u4e2dd\u548c(a,b)\u5206\u522b\u8868\u793a\u8f93\u51fa\u7684\u901a\u9053\u6570\u548c\u56fe\u7247\u5c3a\u5bf8\u3002F\u7684\u6bcf\u4e2a\u7a7a\u95f4\u5b9a\u4f4d\u7d22\u5f15i\\in [1,a\\times b]\u5bf9\u5e94\u4e8e\u56fe\u7247\u4e2d\u7684\u4e00\u4e2a\u533a\u57dfR_i\uff0c\u4e00\u5f20\u56fe\u4e2d\u5171\u6709a\\times b\u4e2a\u5c0f\u533a\u57df\u3002\u5047\u8bbe\u6709\u4e2d\u7ea7\u7279\u5f81f\\in \\mathbb R^d\u4e0e\u4ed6\u5bf9\u5e94\u4e8e\u6807\u7b7ey\u7684\u5206\u7c7b\u5668\u6743\u91cdw\\in \\mathcal R^d\uff0c\u8f93\u51fa\u7684\u7c7b\u522b\u9884\u6d4b\u503c\u53ef\u4ee5\u8868\u793a\u4e3ao=w^t \u00b7 max(F)\uff0c\u5176\u4e2d\uff0cmax(\u00b7)\u8868\u793a\u5168\u5c40\u6700\u5927\u6c60\u5316\u64cd\u4f5c\u3002\u73b0\u5728\uff0c\u53ef\u4ee5\u8ba1\u7b97\u533a\u57dfR_i\u7684\u8d21\u732e\u91cf\uff1a $$ C(R_i)=\\sum_{\\begin{array}{c} k\\in[1,d]\\\\ argmax(F^k)=i\\end{array}}(max(F^k)\\times w^k)/o $$ </p> <p>\u5176\u4e2d\uff0cF^k\u548cw^k\u5206\u522b\u5bf9\u5e94\u4e8eF\u4e2d\u7b2ck\u4e2a\u901a\u9053\u7684\u7279\u5f81\u56fe\u548cw\u4e2d\u7b2ck\u4e2a\u4f4d\u7f6e\u7684\u6743\u91cd\uff0cargmax(F^k)=i\u8868\u793aF\u4e2d\u7b2ck\u5f20\u7279\u5f81\u56fe\u4e0a\u6700\u5927\u7684\u54cd\u5e94\u70b9\u4f4d\u4e8e\u7b2ci\u4e2a\u533a\u57df\u3002\u4e4b\u540e\uff0c\u6309\u964d\u5e8f\u5bf9\u533a\u57df\u7684\u8d21\u732e\u91cf\u8fdb\u884c\u6392\u5e8f\uff0c\u6700\u540e\u518d\u505a\u4e00\u4e2a\u7d2f\u52a0\uff0c\u5f97\u5230\u79ef\u7d2f\u8d21\u732e\uff0c\u8fdb\u4e00\u6b65\u786e\u5b9a\u81f3\u5c11\u6709\u591a\u5c11\u4e2a\u533a\u57df\u53ef\u4ee5\u8d21\u732e\u9884\u6d4b\u503c\u7684\u591a\u5c11\u767e\u5206\u6bd4\uff0c\u6700\u540e\u53ef\u4ee5\u753b\u51fa\u533a\u57df\u6570\u91cf\u4e0e\u8d21\u732e\u767e\u5206\u6bd4\u7684\u56fe\u3002</p> <p>\u2003\u2003\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u4f5c\u8005\u5c06\u57fa\u7ebf\u6a21\u578b\u3001\u6dfb\u52a0\u4e86DropOut\u7684\u6a21\u578b\u548c\u6dfb\u52a0\u4e86SPS\u7684\u6a21\u578b\u505a\u4e86\u5bf9\u6bd4\u3002\u4ee5\u6700\u7ec8\u9884\u6d4b\u503c\u768499%\u4e3a\u4f8b\uff0c\u57fa\u7ebf\u6a21\u578b\u4e2d\uff0c\u81f3\u5c11\u9700\u898135.73\u4e2a\u533a\u57df\uff0c\u800c\u5f15\u5165DropOut\u7684\u6a21\u578b\u81f3\u5c11\u9700\u898144.82\u4e2a\u533a\u57df\uff0c\u5f15\u5165\u4e86SPS\u7684\u6a21\u578b\u5219\u9700\u8981\u591a\u8fbe56.74\u4e2a\u533a\u57df\uff0c\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86SPS\u53ef\u4ee5\u4fc3\u8fdb\u591a\u4e2a\u795e\u7ecf\u5143\u8fdb\u884c\u7279\u5f81\u8868\u793a\uff0c\u5e76\u4e14\u5e2e\u52a9\u6291\u5236\u67d0\u4e9b\u4e3b\u5bfc\u9884\u6d4b\u7684\u795e\u7ecf\u5143\u3002</p> <p> <p></p> <p></p>"},{"location":"fine-grained/paper/SPS1/#_7","title":"\u53ef\u89c6\u5316\u5206\u6790","text":"<p>\u6ee4\u6ce2\u5668\u53ef\u89c6\u5316\uff1a</p> <p>\u2003\u2003\u4e3a\u4e86\u76f4\u89c2\u5730\u7406\u89e3SPS\u7684\u4f18\u8d8a\u6027\uff0c\u4f5c\u8005\u8fdb\u4e00\u6b65\u53ef\u89c6\u5316\u5e76\u4e14\u6bd4\u8f83\u4e86\u57fa\u7ebf\u6a21\u578b\u548cSPS\u7684\u524d\u4e94\u4e2a\u6ee4\u6ce2\u5668\uff0c\u5982\u4e0b\u56fe\u6240\u793a\u3002\u9996\u5148\uff0c\u53ef\u4ee5\u89c2\u5bdf\u5230\u57fa\u7ebf\u6a21\u578b\u7684\u524d\u4e94\u4e2a\u6ee4\u6ce2\u5668\u5927\u90e8\u5206\u90fd\u5728\u76f8\u540c\u7684\u4f4d\u7f6e\u6709\u54cd\u5e94\uff0c\u800c\u5f15\u5165\u4e86SPS\u4e4b\u540e\uff0c\u6ee4\u6ce2\u5668\u7684\u54cd\u5e94\u5206\u5e03\u4e8e\u4e0d\u540c\u7684\u533a\u57df\u3002\u8fd9\u8868\u660e\u4f5c\u8005\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u5730\u51cf\u5c11\u4e86\u67d0\u4e9b\u5f3a\u6a21\u5f0f\u7684\u4f18\u52bf\uff0c\u5e76\u4e14\u9f13\u52b1\u66f4\u591a\u7684\u6a21\u5f0f\u6765\u8868\u793a\u8f93\u5165\u3002\u540c\u65f6\u57fa\u7ebf\u6a21\u5f0f\u53ef\u80fd\u4f1a\u88ab\u67d0\u4e9b\u566a\u58f0\u6a21\u5f0f\u6240\u5f71\u54cd\uff0c\u5982\u4e0b\u56fe\u7b2c\u4e8c\u884c\uff0c\u57fa\u7ebf\u6a21\u578b\u68c0\u6d4b\u5230\u4e00\u79cd\u5c3e\u90e8\u6837\u5f0f\uff0c\u800c\u8be5\u6837\u5f0f\u662f\u7531\u53e6\u4e00\u67b6\u98de\u673a\u7684\u5c3e\u90e8\u610f\u5916\u7ec4\u5408\u800c\u5f62\u6210\u7684\u566a\u58f0\u6a21\u5f0f\u3002</p> <p> <p></p> <p></p> <p>\u6a21\u578b\u89e3\u91ca\uff1a</p> <p>\u2003\u2003\u4e0e\u5229\u7528\u5168\u5c40\u89c6\u89c9\u7ebf\u7d22\u53ef\u89c6\u5316\u6765\u63d0\u4f9b\u6a21\u578b\u89e3\u91ca\u7684\u5168\u5c40\u5e73\u5747\u6c60\u5316\u4e0d\u540c\uff0cSPS\u57fa\u4e8e\u5168\u5c40\u6700\u5927\u6c60\u5316\uff0c\u56e0\u6b64\u53ef\u4ee5\u63d0\u4f9b\u6a21\u578b\u9884\u6d4b\u66f4\u8be6\u7ec6\u7684\u89e3\u91ca(\u7ec6\u5fae\u90e8\u5206\u7684\u91cd\u8981\u6027)\u3002\u53e6\u5916\uff0cSPS\u8fd8\u53ef\u4ee5\u901a\u8fc7\u9f13\u52b1\u5bf9\u66f4\u591a\u90e8\u5206\u533a\u57df\u7684\u5173\u6ce8\u6765\u589e\u5f3a\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u4ece\u800c\u5f97\u5230\u66f4\u5b8c\u6574\u7684\u8868\u793a\u3002\u7ed9\u5b9a\u4e00\u5f20\u56fe\u7247\u4ee5\u53ca\u76f8\u5e94\u7279\u5f81\u56fe\u7684\u5b9a\u4f4d\u7d22\u5f15i\uff0c\u9996\u5148\u8ba1\u7b97\u533a\u57df\u8d21\u732eC(R_i)\uff0c\u4e4b\u540e\u751f\u6210\u5c40\u90e8\u7c7b\u522b\u54cd\u5e94\u56feLCAM(Local Class Activation Map)\u3002\u6700\u540e\uff0c\u5bf9\u533a\u57df\u8d21\u732e\u5206\u6570\u8fdb\u884c\u6392\u5e8f\uff0c\u5e76\u4e14\u663e\u793a\u524dk\u4e2a\u8d21\u732e\u5206\u6570\u548c\u5bf9\u5e94\u7684\u533a\u57df\uff0c\u6700\u540e\u7684\u7ed3\u679c\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u4e0b\u56fe\u663e\u793a\u4e86\u5bf9\u6a21\u578b\u9884\u6d4b\u6700\u91cd\u8981\u7684\u51e0\u4e2a\u533a\u57df\uff1a</p> <p> <p></p> <p></p>"},{"location":"fine-grained/paper/SPS1/#_8","title":"\u7cbe\u5ea6\u5bf9\u6bd4","text":"<p> <p></p> <p></p>"},{"location":"fine-grained/paper/SPS1/#_9","title":"\u603b\u7ed3","text":"<p>\u2003\u2003\u4f5c\u8005\u901a\u8fc7\u7edf\u8ba1\uff0c\u53d1\u73b0\u4e86\u4e2d\u7ea7\u6a21\u578b\u5b58\u5728\u4e00\u4e2a\u95ee\u9898\uff0c\u5373\u53ea\u6709\u5c11\u91cf\u7684\u56fe\u50cf\u533a\u57df\u6709\u52a9\u4e8e\u6700\u7ec8\u7684\u9884\u6d4b\uff0c\u56e0\u6b64\u63d0\u51fa\u4e86\u968f\u673a\u90e8\u5206\u4ea4\u6362\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002\u4e3b\u8981\u601d\u60f3\u5c31\u662f\u5c06\u4e00\u5f20\u771f\u5b9e\u7684\u7279\u5f81\u4f5c\u4e3a\u566a\u58f0\u6e90\u53bb\u5e72\u6270\u53e6\u4e00\u4e2a\u7279\u5f81\uff0c\u5e76\u4e14\u8bc1\u660e\u4e86\u8fd9\u79cd\u7b56\u7565\u6709\u6548\u5730\u4fc3\u8fdb\u4e86\u795e\u7ecf\u7f51\u7edc\u5728\u9884\u6d4b\u8fc7\u7a0b\u4e2d\u4f9d\u9760\u66f4\u591a\u7684\u533a\u57df\u505a\u5224\u65ad\uff0c\u4f5c\u8005\u8fd8\u5c55\u793a\u4e86\u5b83\u5728\u63d0\u9ad8\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u7684\u4f18\u52bf\u3002</p> <p>\u6ce8\uff1a\u4ee5\u4e0a\u5185\u5bb9\u4ec5\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u89c2\u70b9\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u5927\u5bb6\u6279\u8bc4\u6307\u6b63\u3002</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e7412\u670827\u65e5</p>"},{"location":"fine-grained/paper/WS-DAN1/","title":"\u7ec6\u7c92\u5ea6\uff1aWS-DAN","text":""},{"location":"fine-grained/paper/WS-DAN1/#_1","title":"\u7efc\u8ff0","text":"<p>\u8bba\u6587\u5730\u5740\uff1ahttps://arxiv.org/pdf/1901.09891v2.pdf</p> <p>\u6e90\u7801\u5730\u5740(PyTorch\u7248\u672c)\uff1ahttps://github.com/GuYuc/WS-DAN.PyTorch</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u7c7b(FGVC)</p> <p>\u5173\u952e\u8bcd\uff1a\u6570\u636e\u589e\u5e7f\u3001\u5f31\u76d1\u7763\u5b66\u4e60\u3001\u6ce8\u610f\u529b\u673a\u5236\u3001\u53cc\u7ebf\u6027\u6c60\u5316</p>"},{"location":"fine-grained/paper/WS-DAN1/#_2","title":"\u4e3b\u8981\u601d\u60f3","text":"<p>\u2003\u2003\u672c\u6587\u4e3b\u8981\u662f\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6ce8\u610f\u529b\u56fe\u7684\u6570\u636e\u589e\u5f3a\u7f51\u7edc\uff0c\u901a\u8fc7\u5c06\u7279\u5f81\u56fe\u4f20\u5165\u5377\u79ef\u6838\u5927\u5c0f\u4e3a1*1\u7684\u5377\u79ef\u5c42\uff0c\u5f97\u5230\u6ce8\u610f\u529b\u56fe\uff0c\u5e76\u4e14\u901a\u8fc7\u6ce8\u610f\u529b\u6b63\u5219\u5316\u63aa\u65bd\u6765\u76d1\u7763\u7ea6\u675f\u6ce8\u610f\u529b\u56fe\u7684\u5173\u6ce8\u533a\u57df\uff0c\u5229\u7528\u8be5\u6ce8\u610f\u529b\u56fe\u5bf9\u539f\u56fe\u50cf\u8fdb\u884c\u6ce8\u610f\u529b\u88c1\u526a\u4e0e\u6ce8\u610f\u529b\u4e0b\u964d\u4e24\u79cd\u6570\u636e\u6269\u5145\u65b9\u5f0f\uff0c\u518d\u5c06\u6269\u5145\u540e\u7684\u6570\u636e\u4f20\u5165\u7f51\u7edc\u8fdb\u884c\u8bad\u7ec3\uff0c\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4e86\u7f51\u7edc\u5bf9\u7ec6\u7c92\u5ea6\u7279\u5f81\u7684\u5b66\u4e60\u548c\u7f51\u7edc\u7684\u6cdb\u5316\u80fd\u529b\u3002\u4f5c\u8005\u53c2\u8003\u300aBilinear CNNs for Fine-grained Visual Recognition\u300b(\u8bba\u6587\u7b14\u8bb0)\uff0c\u63d0\u51fa\u53cc\u7ebf\u6027\u6ce8\u610f\u529b\u6c60\u5316\u7f51\u7edc\u7ed3\u6784\uff0c\u6709\u6548\u5730\u5c06\u7279\u5f81\u56fe\u4e0e\u6ce8\u610f\u529b\u56fe\u7684\u7279\u5f81\u76f8\u878d\u5408\uff0c\u8fdb\u4e00\u6b65\u4f20\u5165\u5168\u8fde\u63a5\u5c42\u8fdb\u884c\u5206\u7c7b\u9884\u6d4b\u3002</p> <p>\u2003\u2003\u5728\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\uff0c\u7f51\u7edc\u9996\u5148\u901a\u8fc7\u751f\u6210\u7684\u6ce8\u610f\u529b\u56fe\u5f97\u5230\u539f\u56fe\u50cf\u7684\u6ce8\u610f\u529b\u533a\u57df\uff0c\u4e4b\u540e\u5bf9\u8be5\u533a\u57df\u8fdb\u884c\u88c1\u526a\u653e\u5927\uff0c\u6709\u6548\u5730\u8fc7\u6ee4\u4e86\u65e0\u5173\u7684\u80cc\u666f\u4fe1\u606f\uff0c\u6700\u540e\u5c06\u88c1\u526a\u540e\u7684\u56fe\u7247\u653e\u5165\u7f51\u7edc\u8fdb\u884c\u9884\u6d4b\uff0c\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4e86\u7f51\u7edc\u7684\u8bc6\u522b\u7cbe\u5ea6\u3002</p> <p> <p></p> <p></p>"},{"location":"fine-grained/paper/WS-DAN1/#_3","title":"\u91cd\u8981\u6a21\u5757","text":""},{"location":"fine-grained/paper/WS-DAN1/#_4","title":"\u53cc\u7ebf\u6027\u6ce8\u610f\u529b\u6c60\u5316","text":"<p>\u2003\u2003\u4e3b\u5e72\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u4ee5resnet50\u4e3a\u4f8b\uff0c\u5c06layer4\u5c42\u7684\u8f93\u51fa\u4f5c\u4e3a\u7279\u5f81\u56fe(a:Feature Maps)\uff0c\u5c06\u5f97\u5230\u7684\u7279\u5f81\u56fe\u4f20\u5165\u5377\u79ef\u6838\u5927\u5c0f\u4e3a1*1\u7684\u5377\u79ef\u5c42\uff0c\u6700\u540e\u7ecf\u8fc7\u6807\u51c6\u5316\u4ee5\u53caReLU\u6fc0\u6d3b\u51fd\u6570\uff0c\u5f97\u5230\u6700\u540e\u7684\u6ce8\u610f\u529b\u56fe(b:Attention Maps) \u6ce8\u610f\uff1a\u5c06\u6ce8\u610f\u529b\u56fe\u9996\u5148\u7ecf\u8fc7\u6807\u51c6\u5316\uff0c\u518d\u7ecf\u8fc7ReLU\u51fd\u6570\uff0c\u53ef\u4ee5\u5c06\u54cd\u5e94\u503c(\u54cd\u5e94\u503c\u8d8a\u9ad8\uff0c\u4ee3\u8868\u56fe\u7247\u8be5\u533a\u57df\u6240\u542b\u7684\u4fe1\u606f\u8d8a\u4e30\u5bcc)\u4f4e\u7684\u90e8\u5206(\u5c0f\u4e8e\u96f6\u7684\u90e8\u5206)\u5f52\u4e3a\u96f6\uff0c\u6700\u540e\u7684\u6548\u679c\u53ef\u4ee5\u89c1\u4e0b\u56fe\u6a59\u8272\u6846\u90e8\u5206\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u5f97\u5230\u7279\u5f81\u56fe\u4e0e\u6ce8\u610f\u529b\u56fe\u4e4b\u540e\uff0c\u5c31\u662f\u8981\u8003\u8651\u5982\u4f55\u5c06\u4e24\u7ec4\u6570\u636e\u8fdb\u884c\u7279\u5f81\u878d\u5408\uff0c\u53d7\u8bba\u6587\u300aBilinear CNNs for Fine-grained Visual Recognition\u300b\u7684\u542f\u53d1\uff0c\u63d0\u51fa\u4e86\u53cc\u7ebf\u6027\u6c60\u5316\u7684\u64cd\u4f5c\u3002</p> <p>\u2003\u2003\u53cc\u7ebf\u6027\u6c60\u5316\u4e3b\u8981\u7528\u4e8e\u7279\u5f81\u878d\u5408\uff0c\u5bf9\u4e8e\u4ece\u540c\u4e00\u4e2a\u6837\u672c\u63d0\u53d6\u51fa\u6765\u7684\u7279\u5f81x\u548c\u7279\u5f81y(\u5728\u8fd9\u91cc\u76f8\u5f53\u4e8e\u662f\u4ece\u540c\u4e00\u5f20\u56fe\u7247\u63d0\u53d6\u51fa\u6765\u7684\u7279\u5f81\u56fe\u4e0e\u6ce8\u610f\u529b\u56fe)\uff0c\u5148\u8fdb\u884c\u7279\u5f81\u53cc\u7ebf\u6027\u878d\u5408\uff08\u76f8\u4e58\uff09\u540e\uff0c\u518d\u8fdb\u884c\u91c7\u6837\u64cd\u4f5c(\u5168\u5c40\u5e73\u5747\u91c7\u6837\u6216\u8005\u5168\u5c40\u6700\u5927\u91c7\u6837)\uff0c\u6700\u540e\u518d\u53d8\u6210\u4e00\u4e2a\u5411\u91cf\uff0c\u5f97\u5230\u878d\u5408\u540e\u7684\u7279\u5f81\uff0c\u7528\u4e8e\u7ec6\u7c92\u5ea6\u5206\u7c7b\u3002</p> <p>\u2003\u2003\u672c\u7bc7\u6587\u7ae0\u4e2d\uff0c\u5f97\u5230\u7684\u7279\u5f81\u56fe\u4f9d\u6b21\u4e0e\u6bcf\u5f20\u6ce8\u610f\u529b\u56fe\u505a\u70b9\u4e58\uff0c\u5c06\u6ce8\u610f\u529b\u56fe\u4e0e\u7279\u5f81\u56fe\u7684\u6570\u636e\u76f8\u878d\u5408\uff0c\u5f97\u5230M\u7ec4\u90e8\u5206\u7279\u5f81\u56fe\uff0c\u516c\u5f0f\u5982\u4e0b\uff1a $$ F_k=A_k\\cdot F \\quad(k=1,2,\u2026\u2026,M) $$  \u2003\u2003\u5f97\u5230\u7684\u7279\u5f81\u56fe\u518d\u7ecf\u8fc7\u7279\u5f81\u63d0\u53d6\u64cd\u4f5cg(\u00b7)\uff0c\u6bd4\u5982\uff1a\u5168\u5c40\u5e73\u5747\u6c60\u5316(GAP)\u3001\u5168\u5c40\u6700\u5927\u6c60\u5316(GMP)\uff0c\u5f97\u5230\u90e8\u5206\u6ce8\u610f\u529b\u7279\u5f81\uff0c\u5c06M\u4e2a\u90e8\u5206\u6ce8\u610f\u529b\u7279\u6027\u76f8\u53e0\u52a0\uff0c\u5c31\u5f97\u5230\u6700\u7ec8\u7684\u7279\u5f81\u77e9\u9635P\uff0c\u603b\u4f53\u6d41\u7a0b\u53ef\u4ee5\u89c1\u4e0a\u56fe\u3002\u516c\u5f0f\u5982\u4e0b\uff1a $$ P=\\mathrm{\\Gamma}(A,F)= \\left( \\begin{matrix} g(A_1\\cdot F) \\\\ g(A_2 \\cdot F) \\\\ \\cdots \\\\ g(A_M \\cdot F) \\end{matrix} \\right)=\\left( \\begin{matrix} f_1 \\\\ f_2 \\\\ \\cdots \\\\ f_M  \\end{matrix} \\right) $$  \u2003\u2003\u6362\u79cd\u65b9\u5f0f\u601d\u8003\uff0c\u672c\u6587\u7684\u53cc\u7ebf\u6027\u6c60\u5316\u5c31\u662f\u5229\u7528\u6ce8\u610f\u529b\u56fe\u4f5c\u4e3a\u6307\u5bfc\u56fe\uff0c\u5c06\u539f\u7279\u5f81\u56fe\u7684\u6570\u636e\u8fdb\u884c\u91cd\u65b0\u89c4\u5212\uff0c\u5bf9\u4e8e\u6bcf\u5f20\u6ce8\u610f\u529b\u56fe\u90fd\u5bf9\u6240\u6709\u7684\u7279\u5f81\u56fe\u505a\u4e00\u6b21\u70b9\u4e58\u8fd0\u7b97\uff0c\u4fdd\u7559\u54cd\u5e94\u503c\u9ad8\u7684\u90e8\u5206\uff0c\u5373\u6ce8\u610f\u529b\u56fe\u6240\u5173\u6ce8\u7684\u90e8\u5206\uff0c\u54cd\u5e94\u503c\u4f4e(\u4e0d\u88ab\u6ce8\u610f\u529b\u56fe\u5173\u6ce8\u7684\u90e8\u5206)\u5c06\u53d8\u4e3a0\uff0c\u5229\u7528\u8fd9\u4e2a\u601d\u60f3\uff0c\u540e\u9762\u7684\u6ce8\u610f\u529b\u6b63\u5219\u5316\u5c06\u4f1a\u975e\u5e38\u5bb9\u6613\u7406\u89e3\u3002</p>"},{"location":"fine-grained/paper/WS-DAN1/#_5","title":"\u6ce8\u610f\u529b\u6b63\u5219\u5316","text":"<p>\u2003\u2003\u5bf9\u4e8e\u6bcf\u4e2a\u79cd\u7c7b\uff0c\u6211\u4eec\u90fd\u5e0c\u671b\u6bcf\u5f20\u6ce8\u610f\u529b\u56fe\u5c3d\u53ef\u80fd\u5173\u6ce8\u76f8\u540c\u7684\u90e8\u5206\u3002\u6bd4\u5982\u8bf4\uff0c\u5728CUB-200-2011\u7684\u6570\u636e\u96c6\u4e2d\uff0c\u5047\u8bbe\u6211\u4eec\u5e0c\u671b\u7b2c\u4e00\u5f20\u6ce8\u610f\u529b\u56fe\u5173\u6ce8\u4e8e\u9e1f\u7684\u5934\u90e8\u3001\u7b2c\u4e8c\u5f20\u6ce8\u610f\u529b\u56fe\u5173\u6ce8\u4e8e\u9e1f\u7684\u5634\u90e8\u3001\u7b2c\u4e09\u5f20\u6ce8\u610f\u529b\u56fe\u5173\u6ce8\u4e8e\u9e1f\u7684\u7fc5\u8180\uff0c\u7b49\u7b49\u3002\u867d\u7136\u9e1f\u7684\u79cd\u7c7b\u4e0d\u540c\uff0c\u4f46\u662f\u6211\u4eec\u5e0c\u671b\u6ce8\u610f\u529b\u56fe\u5173\u6ce8\u7684\u90e8\u4f4d\u662f\u4e00\u6837\u7684\u3002</p> <p>\u2003\u2003\u5982\u679c\u9700\u8981\u7edf\u4e00\u6ce8\u610f\u529b\u56fe\u6240\u5173\u6ce8\u7684\u533a\u57df\uff0c\u5c31\u9700\u8981\u5f97\u5230\u4e00\u4e2a\u6807\u51c6\uff0c\u6bcf\u6b21\u8bad\u7ec3\u7684\u8fc7\u7a0b\u4e2d\uff0c\u6ce8\u610f\u529b\u5173\u6ce8\u70b9\u90fd\u9700\u8981\u4e0d\u65ad\u9760\u8fd1\u6b64\u6807\u51c6\u3002\u56e0\u6b64\uff0c\u672c\u7bc7\u6587\u7ae0\u4e2d\u8bbe\u7f6e\u5168\u5c40\u7279\u5f81\u4e2d\u5fc3ck\uff0c\u7528\u6765\u89c4\u8303\u6ce8\u610f\u529b\u7684\u5173\u6ce8\u533a\u57df\u3002</p> <p>\u2003\u2003\u5168\u5c40\u7279\u5f81\u4e2d\u5fc3\u7531\u7279\u5f81\u77e9\u9635\u6240\u786e\u5b9a\uff0c\u8bad\u7ec3\u5f00\u59cb\u521d\u59cb\u5316\u4e3a\u5168\u96f6\u77e9\u9635\uff0c\u6bcf\u8bad\u7ec3\u4e00\u6b21\uff0c\u7279\u5f81\u4e2d\u5fc3\u66f4\u65b0\u4e00\u6b21\uff0c\u66f4\u65b0\u516c\u5f0f\u5982\u4e0b\uff1a $$ c_k \\leftarrow c_k + \u03b2 (f_k-c_k) $$  \u5176\u4e2d\uff0c\u03b2\u662f\u7279\u5f81\u4e2d\u5fc3\u66f4\u65b0\u901f\u7387\uff0c\u51b3\u5b9a\u4e86\u7279\u5f81\u4e2d\u5fc3\u7684\u66f4\u65b0\u5feb\u6162(\u4e0e\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u5b66\u4e60\u7387\u7c7b\u4f3c)\u3002</p> <p>\u2003\u2003\u9996\u5148\u8ba9\u7279\u5f81\u77e9\u9635\u548c\u7279\u5f81\u4e2d\u5fc3\u505a\u5dee\uff0c\u5f97\u5230\u5dee\u5f02\u6027\uff0c\u7136\u540e\u4e0e\u539f\u6765\u7684\u7279\u5f81\u4e2d\u5fc3\u505a\u548c\uff0c\u505a\u4e00\u4e2a\u66f4\u65b0\u3002\u5982\u6b64\u91cd\u590d\u4e0b\u53bb\uff0c\u7279\u5f81\u4e2d\u5fc3\u4f1a\u9010\u6e10\u8d8b\u4e8e\u7a33\u5b9a\uff0c\u4ee3\u8868\u4e86\u6574\u4e2a\u6570\u636e\u96c6\u7684\u7279\u5f81(\u6bd4\u5982CUB-200-2011\u4e2d\uff0c\u7efc\u5408200\u7c7b\u9e1f\u7684\u6240\u6709\u7279\u5f81\u77e9\u9635)\u3002\u76f8\u5f53\u4e8e\uff0c\u5f62\u6210\u4e00\u79cd\u6807\u51c6\uff0c\u8be5\u6807\u51c6\u5c31\u662f\u6ce8\u610f\u529b\u56fe\u5173\u6ce8\u533a\u57df\u7684\u6807\u51c6\uff0c\u518d\u901a\u8fc7\u6784\u5efa\u635f\u5931\u51fd\u6570\uff1a $$ L_A=\\sum^M_{k=1}{||f_k-c_k||^2_2} $$ </p> <p>\u2003\u2003\u8ba9\u7279\u5f81\u4e2d\u5fc3\u8d77\u5230\u4f18\u5316\u7684\u4f5c\u7528\uff0c\u4f7f\u7f51\u7edc\u5f97\u5230\u7684\u7279\u5f81\u77e9\u9635\u4e0d\u65ad\u9760\u8fd1\u7279\u5f81\u4e2d\u5fc3\uff0c\u6700\u7ec8\u8fbe\u5230\u8ba9\u6ce8\u610f\u529b\u56fe\u9010\u6e10\u5173\u6ce8\u76f8\u540c\u533a\u57df\u7684\u76ee\u7684\u3002\u7279\u5f81\u4e2d\u5fc3\u8d77\u6e90\u4e8e\u7279\u5f81\u77e9\u9635\uff0c\u8fdb\u4e00\u6b65\u7528\u6765\u89c4\u8303\u7279\u5f81\u77e9\u9635\u3002</p> <p>\u2003\u2003\u6362\u4e00\u79cd\u65b9\u5f0f\u7406\u89e3\uff0c\u7279\u5f81\u56fe\u7ecf\u8fc7\u53cc\u7ebf\u6027\u6ce8\u610f\u529b\u6c60\u5316\u64cd\u4f5c\u751f\u6210\u7279\u5f81\u77e9\u9635\uff0c\u7279\u5f81\u77e9\u9635\u4e2d\u7684\u6bcf\u4e00\u884c\u6570\u636e\u53ea\u5305\u542b\u4e86\u6ce8\u610f\u529b\u56fe\u6240\u5173\u6ce8\u7684\u90e8\u5206(\u4e0d\u88ab\u5173\u6ce8\u7684\u90e8\u5206\u88ab\u8bbe\u7f6e\u4e3a0)\uff0c\u6362\u53e5\u8bdd\u8bf4\u5c31\u662f\u975e\u96f6\u533a\u57df\u4e00\u81f4\u3002\u5982\u679c\u7b2c\u4e00\u5f20\u6ce8\u610f\u529b\u56fe\u53ea\u5173\u6ce8\u9e1f\u7684\u5634\u90e8\uff0c\u5219\u7279\u5f81\u77e9\u9635\u4e2d\u7684\u7b2c\u4e00\u884c\u6570\u636e\u53ea\u6709\u8be5\u56fe\u50cf\u4e2d\u9e1f\u7684\u5634\u90e8\u6570\u636e\uff0c\u56fe\u50cf\u6570\u636e\u4e2d\u9664\u4e86\u9e1f\u7684\u5634\u90e8\u6570\u636e\u90fd\u88ab\u5f52\u4e3a\u96f6\uff0c\u5982\u679c\u7b2c\u4e8c\u5f20\u6ce8\u610f\u529b\u56fe\u53ea\u5173\u6ce8\u9e1f\u7684\u5934\u90e8\uff0c\u5219\u7279\u5f81\u77e9\u9635\u4e2d\u7684\u7b2c\u4e8c\u884c\u6570\u636e\u53ea\u6709\u8be5\u56fe\u50cf\u4e2d\u9e1f\u7684\u5934\u90e8\u6570\u636e\uff0c\u56fe\u50cf\u6570\u636e\u4e2d\u9664\u4e86\u9e1f\u7684\u5934\u90e8\u6570\u636e\u90fd\u88ab\u5f52\u4e3a\u96f6\uff0c\u4f9d\u6b21\u7c7b\u63a8\uff0c\u5728\u8fd9\u4e2a\u4f8b\u5b50\u4e2d\uff0c\u5168\u5c40\u7279\u5f81\u4e2d\u5fc3\u7684\u7b2c\u4e00\u884c\u6570\u636e\u5e94\u8be5\u5305\u542b\u4e86200\u7c7b\u9e1f\u7684\u5634\u90e8\u6570\u636e\uff0c\u6240\u4ee5\u5982\u679c\u6700\u540e\u5f97\u5230\u7684\u7279\u5f81\u77e9\u9635\u5173\u6ce8\u7684\u4e0d\u662f\u9e1f\u7684\u5634\u90e8\uff0c\u5373fk\u4e0eck\u5728\u7b2c\u4e00\u884c\u6570\u636e\u5143\u7d20\u4e2d\u76f8\u5dee\u6bd4\u8f83\u5927\uff0c\u4f1a\u901a\u8fc7\u635f\u5931\u51fd\u6570\u505a\u51fa\u76f8\u5e94\u8c03\u6574\uff0c\u8ba9fk\u9010\u6e10\u5411ck\u504f\u79fb\u3002\u8bbe\u7acbck\u76f8\u5f53\u4e8e\u5728\u672c\u6570\u636e\u96c6\u4e2d\u56fa\u5b9a\u4e86\u6ce8\u610f\u529b\u56fe\u7684\u5173\u6ce8\u533a\u57df\uff0c\u4e5f\u5c31\u662f\u56fa\u5b9a\u4e86\u96f6\u4ef6\u5173\u6ce8\u533a\u57df</p> <p>\u2003\u2003\u73b0\u5b9e\u60c5\u51b5\u4e2d\uff0c\u6ce8\u610f\u529b\u56fe\u5173\u6ce8\u7684\u533a\u57df\u53ef\u80fd\u6bd4\u8f83\u590d\u6742\uff0c\u4e0d\u4e00\u5b9a\u4e00\u5f20\u6ce8\u610f\u529b\u56fe\u5c31\u51c6\u786e\u65e0\u8bef\u5730\u53ea\u5173\u6ce8\u9e1f\u7684\u4e00\u4e2a\u90e8\u4f4d\uff0c\u53ea\u662f\u8fd9\u4e48\u8bf4\u66f4\u52a0\u65b9\u4fbf\u7406\u89e3\u3002</p>"},{"location":"fine-grained/paper/WS-DAN1/#_6","title":"\u57fa\u4e8e\u6ce8\u610f\u529b\u5f15\u5bfc\u7684\u6570\u636e\u589e\u5e7f","text":"<p>\u2003\u2003\u5728\u4f20\u7edf\u7684\u6570\u636e\u589e\u5e7f\u64cd\u4f5c\u4e2d\uff0c\u5e38\u7528\u5230\u968f\u673a\u968f\u673a\u88c1\u526a\u3001\u968f\u673a\u7ffb\u8f6c\u7b49\u4e00\u7cfb\u5217\u968f\u673a\u64cd\u4f5c\uff0c\u5f80\u5f80\u6548\u679c\u6bd4\u8f83\u4f4e\u6548\u3002\u5f53\u6709\u4e86\u6ce8\u610f\u529b\u56fe\u4e4b\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u6839\u636e\u6ce8\u610f\u529b\u56fe\u505a\u4e00\u4e9b\u6bd4\u8f83\u9ad8\u6548\u7684\u6570\u636e\u589e\u5e7f\u64cd\u4f5c\uff0c\u5bf9\u4e8e\u6bcf\u5f20\u56fe\u7684\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u6211\u4eec\u968f\u673a\u9009\u62e9\u4e24\u5f20\u6ce8\u610f\u529b\u56fe\u7528\u4e8e\u4e4b\u540e\u7684\u6570\u636e\u589e\u5e7f\u64cd\u4f5c\u3002\u5f53\u5f97\u5230\u6ce8\u610f\u529b\u56fe\u4e4b\u540e\uff0c\u9996\u5148\u8fdb\u884c\u5f52\u4e00\u5316\u64cd\u4f5c\uff0c\u516c\u5f0f\u5982\u4e0b\uff1a $$ A_k^*=\\frac{A_k-min(A_k)}{max(A_k)-min(A_k)}\uff0c\u5176\u4e2dA_k^* \\in R^{H\u00d7W} $$ </p>"},{"location":"fine-grained/paper/WS-DAN1/#_7","title":"\u6ce8\u610f\u529b\u88c1\u526a","text":"<p>\u2003\u2003\u4e3a\u4e86\u8fdb\u4e00\u6b65\u63d0\u9ad8\u795e\u7ecf\u7f51\u7edc\u7684\u7279\u5f81\u63d0\u53d6\u80fd\u529b\uff0c\u5229\u7528\u968f\u673a\u9009\u62e9\u7684\u6ce8\u610f\u529b\u56fe\uff0c\u6765\u786e\u5b9a\u7269\u4f53\u7684\u5173\u952e\u90e8\u4f4d\uff0c\u518d\u5c06\u5173\u952e\u90e8\u4f4d\u653e\u5165\u6a21\u578b\u4e2d\u8bad\u7ec3\uff0c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6a21\u578b\u7684\u8bc6\u522b\u7cbe\u5ea6\u3002</p> <p> <p></p> <p></p> <p>\u2003\u2003\u7b2c\u4e00\u884c\u662f\u968f\u673a\u88c1\u526a\uff0c\u7b2c\u4e8c\u884c\u662f\u57fa\u4e8e\u6ce8\u610f\u529b\u56fe\u7684\u88c1\u526a\uff0c\u660e\u663e\u7b2c\u4e8c\u79cd\u65b9\u6cd5\u66f4\u6709\u6548\uff0c\u901a\u8fc7\u653e\u5927\u5173\u952e\u90e8\u4f4d\uff0c\u518d\u653e\u5165\u7f51\u7edc\u8bad\u7ec3\uff0c\u6765\u6709\u76ee\u7684\u5730\u63d0\u9ad8\u7f51\u7edc\u7ec6\u7c92\u5ea6\u7279\u5f81\u63d0\u53d6\u7684\u80fd\u529b\uff0c\u63d0\u9ad8\u4e86\u7f51\u7edc\u7684\u8bc6\u522b\u7cbe\u5ea6\u3002</p> <p>\u2003\u2003\u9996\u5148\uff0c\u6211\u4eec\u5148\u786e\u5b9a\u4e00\u4e2a\u9608\u503c\u03b8\uff0c\u7136\u540e\u901a\u8fc7\u5bf9\u6bd4\u6ce8\u610f\u529b\u56fe\u4e0a\u7684\u5143\u7d20\u548c\u9608\u503c\u03b8\u7684\u5927\u5c0f\uff0c\u6765\u5f97\u5230\u88c1\u526a\u63a9\u7801\uff0c\u5177\u4f53\u516c\u5f0f\u5982\u4e0b\uff1a $$ C_k(i,j)=\\left \\{ \\begin{matrix} 1,\\quad if A_k^*(i,j)&gt;\u03b8_c \\\\ 0,\\quad \\quad\\quad otherwise \\end{matrix} \\right. $$  \u5176\u4e2dC_k\u8868\u793a\u88c1\u526a\u63a9\u7801\uff0c\u03b8_c\u8868\u793a\u9608\u503c\uff0c\u5e76\u4e14\u03b8_c \\in [0,1]\u3002</p> <p>\u2003\u2003\u5f97\u5230\u88c1\u526a\u63a9\u7801\u540e\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u786e\u5b9a\u4e00\u4e2a\u53ef\u4ee5\u8986\u76d6\u539f\u59cb\u56fe\u50cf\u79ef\u6781\u54cd\u5e94\u7684\u533a\u57df(\u5c31\u662f\u6ce8\u610f\u529b\u6240\u5173\u6ce8\u7684\u533a\u57df)\uff0c\u5e76\u4e14\u901a\u8fc7\u653e\u5927\u8be5\u533a\u57df\uff0c\u53ef\u4ee5\u5b9e\u73b0\u653e\u5927\u7ec6\u8282\u7684\u529f\u80fd\uff0c\u4ece\u800c\u66f4\u597d\u5730\u63d0\u53d6\u7ec6\u7c92\u5ea6\u7279\u5f81\u3002(\u5177\u4f53\u5b9e\u73b0\u65b9\u6cd5\u89c1\u6e90\u7801\u89e3\u8bfb)</p>"},{"location":"fine-grained/paper/WS-DAN1/#_8","title":"\u6ce8\u610f\u529b\u4e0b\u964d","text":"<p>\u2003\u2003\u6ce8\u610f\u529b\u6b63\u5219\u5316\u76d1\u7763\u4e86\u540c\u4e00\u5f20\u6ce8\u610f\u529b\u56fe\u5c3d\u91cf\u5173\u6ce8\u4e8e\u540c\u4e00\u4e2a\u90e8\u4f4d\uff0c\u4f46\u662f\u8fd8\u5b58\u5728\u4e00\u4e2a\u95ee\u9898\uff0c\u4e0d\u540c\u7684\u6ce8\u610f\u529b\u56fe\u53ef\u80fd\u96c6\u4e2d\u5173\u6ce8\u5728\u76f8\u4f3c\u7684\u90e8\u4f4d\uff0c\u4e3a\u4e86\u9f13\u52b1\u6ce8\u610f\u529b\u56fe\u80fd\u591f\u4ee3\u8868\u591a\u4e2a\u6709\u533a\u5206\u5ea6\u7684\u90e8\u4f4d(\u4e5f\u5c31\u662f\u5173\u6ce8\u533a\u57df\u5c3d\u91cf\u4e0d\u91cd\u590d)\uff0c\u672c\u7bc7\u6587\u7ae0\u91c7\u7528\u6ce8\u610f\u529b\u4e0b\u964d\u7684\u65b9\u5f0f\uff0c\u901a\u8fc7\u5220\u9664\u6ce8\u610f\u529b\u5173\u6ce8\u7684\u90e8\u4f4d\uff0c\u6765\u76d1\u7763\u7f51\u7edc\u5b66\u4e60\u66f4\u591a\u53ef\u7528\u4e8e\u6ce8\u610f\u529b\u5173\u6ce8\u7684\u533a\u57df\u3002</p> <p> <p></p> <p></p> <p>\u2003\u2003\u7b2c\u4e00\u884c\u662f\u968f\u673a\u5220\u9664\uff0c\u7b2c\u4e8c\u884c\u662f\u57fa\u4e8e\u6ce8\u610f\u529b\u56fe\u7684\u5220\u9664\uff0c\u660e\u663e\u7b2c\u4e8c\u79cd\u5220\u9664\u65b9\u6cd5\u66f4\u6709\u76ee\u7684\u6027\uff0c\u901a\u8fc7\u62b9\u53bb\u5173\u952e\u90e8\u4f4d\uff0c\u518d\u653e\u5165\u7f51\u7edc\u8bad\u7ec3\uff0c\u6765\u6709\u76ee\u7684\u5730\u63d0\u9ad8\u7f51\u7edc\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u63d0\u9ad8\u4e86\u7f51\u7edc\u7684\u9c81\u68d2\u6027\u3002</p> <p>\u2003\u2003\u5b9e\u73b0\u65b9\u6cd5\u548c\u6ce8\u610f\u529b\u88c1\u526a\u90e8\u5206\u7684\u5b9e\u73b0\u65b9\u6cd5\u7c7b\u4f3c\uff0c\u6211\u4eec\u9996\u5148\u786e\u5b9a\u4e00\u4e2a\u9608\u503c\u03b8\uff0c\u7136\u540e\u5229\u7528\u4e0b\u9762\u7684\u516c\u5f0f\u5f97\u5230\u6ce8\u610f\u529b\u4e0b\u964d\u63a9\u7801\u3002 $$ D_k(i,j)=\\left \\{ \\begin{matrix} 0,\\quad if A_k^*(i,j)&gt;\u03b8_d \\\\ 1,\\quad \\quad\\quad otherwise \\end{matrix} \\right. $$  \u5176\u4e2dD_k\u8868\u793a\u4e0b\u964d\u63a9\u7801\uff0c\u03b8_d\u8868\u793a\u9608\u503c\uff0c\u5e76\u4e14\u03b8_d \\in [0,1]\u3002</p> <p>\u2003\u2003\u901a\u8fc7\u5229\u7528\u8be5\u63a9\u7801\uff0c\u53ef\u4ee5\u5220\u53bb\u539f\u59cb\u56fe\u50cf\u7684\u54cd\u5e94\u533a\u57df\uff0c\u518d\u5c06\u5220\u9664\u540e\u7684\u56fe\u50cf\u653e\u5165\u7f51\u7edc\u8bad\u7ec3\uff0c\u53ef\u4ee5\u9f13\u52b1\u7f51\u7edc\u5173\u6ce8\u66f4\u591a\u7684\u533a\u57df\u3002(\u5177\u4f53\u5b9e\u73b0\u65b9\u6cd5\u89c1\u6e90\u7801\u89e3\u8bfb)</p>"},{"location":"fine-grained/paper/WS-DAN1/#_9","title":"\u7269\u4f53\u5b9a\u4f4d\u4ee5\u53ca\u7ec6\u5316","text":"<p>\u2003\u2003\u6ce8\u610f\u529b\u56fe\u4e0d\u4ec5\u53ef\u4ee5\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7528\u6765\u6269\u5145\u6570\u636e\uff0c\u6765\u589e\u5f3a\u7f51\u7edc\u7684\u7279\u5f81\u63d0\u53d6\u80fd\u529b\u4ee5\u53ca\u6cdb\u5316\u80fd\u529b\uff0c\u8fd8\u53ef\u4ee5\u5229\u7528\u6ce8\u610f\u529b\u56fe\u5728\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\u8f93\u51fa\u56fe\u7247\u7684\u5173\u6ce8\u533a\u57df\uff0c\u901a\u8fc7\u653e\u5927\u5176\u5173\u6ce8\u533a\u57df\uff0c\u53ef\u4ee5\u9884\u6d4b\u7269\u4f53\u5bf9\u8c61\u7684\u6574\u4e2a\u533a\u57df\uff0c\u51cf\u5c11\u80cc\u666f\u7684\u5e72\u6270\u56e0\u7d20\uff0c\u63d0\u9ad8\u6d4b\u8bd5\u8fc7\u7a0b\u7684\u8bc6\u522b\u51c6\u786e\u7387\uff0c\u6ce8\u610f\u529b\u7684\u5173\u6ce8\u533a\u57df\u751f\u6210\u516c\u5f0f\u5982\u4e0b\uff1a $$ A_m=\\frac{1}{M}\\sum^M_{k=1}A_{k} $$  \u2003\u2003\u5f97\u5230\u6ce8\u610f\u529b\u5173\u6ce8\u533a\u57df\u540e\uff0c\u540e\u9762\u7684\u64cd\u4f5c\u5c31\u7c7b\u4f3c\u6ce8\u610f\u529b\u88c1\u526a\u90e8\u5206\uff0c\u8fd9\u91cc\u4e0d\u5728\u63cf\u8ff0\u4e86\u3002</p>"},{"location":"fine-grained/paper/WS-DAN1/#_10","title":"\u8bad\u7ec3\u4e0e\u6d4b\u8bd5\u6d41\u7a0b","text":"<p>\u2003\u2003\u5177\u4f53\u7684\u8bad\u7ec3\u6d41\u7a0b\u53ef\u4ee5\u89c1\u4e0b\u56fe\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u9996\u5148\uff0c\u5c06\u539f\u56fe\u50cfx1\u7ecf\u8fc7\u7f51\u7edc\u4e3b\u5e72\u90e8\u5206(\u7279\u5f81\u63d0\u53d6\u4e0e\u53cc\u7ebf\u6027\u6ce8\u610f\u529b\u6c60\u5316)\uff0c\u5f97\u5230\u7279\u5f81\u77e9\u9635f1\u4e0e\u6ce8\u610f\u529b\u56fe\uff0c\u4e00\u65b9\u9762\uff0c\u7279\u5f81\u77e9\u9635f1\u4f20\u5165\u5168\u8fde\u63a5\u5c42\uff0c\u53ef\u4ee5\u5f97\u5230\u7b2c\u4e00\u4e2a\u9884\u6d4b\u7ed3\u679cy1\uff1b\u53e6\u4e00\u65b9\u9762\uff0c\u5bf9\u4e8e\u6bcf\u5f20\u8bad\u7ec3\u56fe\u7247\uff0c\u90fd\u76f8\u5e94\u9009\u62e9\u4e24\u5f20\u6ce8\u610f\u529b\u56fe\uff0c\u7528\u4e8e\u6ce8\u610f\u529b\u88c1\u526a\u548c\u6ce8\u610f\u529b\u4e0b\u964d\uff0c\u5f97\u5230\u4e24\u5f20\u6570\u636e\u589e\u5f3a\u540e\u7684\u56fe\u7247x2\u3001x3\uff0c\u518d\u5c06\u8fd9\u4e24\u5f20\u56fe\u7247\u5206\u522b\u4f20\u5165\u7f51\u7edc\uff0c\u4e0e\u7b2c\u4e00\u5f20\u56fe\u7247x1\u7c7b\u4f3c\uff0c\u5206\u522b\u5f97\u5230\u4e24\u4e2a\u9884\u6d4b\u503cy2\u3001y3\u3002\u4e09\u4e2a\u9884\u6d4b\u503c\u4e0e\u8f93\u51fa\u7684\u7279\u5f81\u77e9\u9635f1\u5171\u540c\u4f18\u5316\u7f51\u7edc\u53c2\u6570\uff0c\u5177\u4f53\u7684\u635f\u5931\u51fd\u6570\u8bf7\u89c1\u4e0b\u6587</p> <p>\u2003\u2003\u5177\u4f53\u7684\u6d4b\u8bd5\u6d41\u7a0b\u53ef\u4ee5\u89c1\u4e0b\u56fe\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u539f\u56fe\u50cfx1\u9996\u5148\u7ecf\u8fc7\u7f51\u7edc\u4e3b\u5e72\u90e8\u5206\uff0c\u751f\u6210\u7279\u5f81\u77e9\u9635f1\u4ee5\u53ca\u6ce8\u610f\u529b\u56fe\uff0c\u4e00\u65b9\u9762\uff0c\u901a\u8fc7\u5c06\u7279\u5f81\u77e9\u9635\u4f20\u5165\u5168\u8fde\u63a5\u5c42\uff0c\u53ef\u4ee5\u5f97\u5230\u4e00\u4e2a\u9884\u6d4b\u7ed3\u679cy1\uff1b\u53e6\u4e00\u65b9\u9762\uff0c\u6ce8\u610f\u529b\u56fe\u53ef\u4ee5\u5f97\u5230\u6ce8\u610f\u529b\u533a\u57df\uff0c\u518d\u5229\u7528\u6ce8\u610f\u529b\u533a\u57df\u88c1\u526a\u539f\u56fe\u50cf\uff0c\u5f97\u5230\u7269\u4f53\u6240\u5728\u56fe\u50cfx2\uff0c\u518d\u5c06x2\u4f20\u5165\u7f51\u7edc\uff0c\u4e0ex1\u7c7b\u4f3c\uff0c\u5f97\u5230\u7b2c\u4e8c\u4e2a\u9884\u6d4b\u7ed3\u679cy2\u3002\u6700\u540e\uff0c\u4e24\u79cd\u9884\u6d4b\u7ed3\u679c\u53d6\u5e73\u5747\u503c\u5f97\u5230\u6700\u540e\u7684\u9884\u6d4b\u7ed3\u679c\u3002</p>"},{"location":"fine-grained/paper/WS-DAN1/#_11","title":"\u635f\u5931\u51fd\u6570","text":"<p>\u2003\u2003\u6700\u7ec8\u7684\u635f\u5931\u7531\u56db\u90e8\u5206\u635f\u5931\u5171\u540c\u8ba1\u7b97\u5f97\u5230\uff0c\u8bbeL\u662f\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u8ba1\u7b97\u516c\u5f0f\u5982\u4e0b\uff1a $$ L_\u603b=\\frac{1}{3}L(y_{raw},y)+\\frac{1}{3}L(y_{crop},y)+\\frac{1}{3}L(y_{drop},y)+L_A(f_k,c_k) $$  \u5176\u4e2d\uff0cL_a\u662f\u4e4b\u524d\u5b9a\u4e49\u597d\u7684f_k\u4e0ec_k\u7684\u8ddd\u79bb\u635f\u5931\uff0cL_\u603b\u7528\u6765\u4f18\u5316\u5168\u5c40\u7684\u53c2\u6570\u3002</p> <p>\u5206\u7c7b\u635f\u5931\u4e0e\u7279\u5f81\u4e2d\u5fc3\u7684\u635f\u5931\u5171\u540c\u4f18\u5316\u7f51\u7edc\u53c2\u6570\u3002</p>"},{"location":"fine-grained/paper/WS-DAN1/#_12","title":"\u7cbe\u5ea6\u5bf9\u6bd4","text":"<p>CUB-200-2011</p> <p> <p></p> <p></p> <p>Stanford Cars</p> <p> <p></p> <p></p> <p>Aircraft</p> <p> <p></p> <p></p>"},{"location":"fine-grained/paper/WS-DAN1/#_13","title":"\u603b\u7ed3","text":"<p>\u2003\u2003\u672c\u6587\u901a\u8fc7\u5c06\u5f31\u76d1\u7763\u5b66\u4e60\u548c\u6570\u636e\u589e\u5f3a\u76f8\u7ed3\u5408\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5f31\u76d1\u7763\u6570\u636e\u6ce8\u610f\u529b\u7f51\u7edc\uff0c\u5f31\u76d1\u7763\u5b66\u4e60\u4e3a\u6570\u636e\u589e\u5f3a\u63d0\u4f9b\u7a7a\u95f4\u5206\u5e03(\u5373\u6ce8\u610f\u529b)\uff0c\u6570\u636e\u589e\u5f3a\u9f13\u52b1\u5b66\u4e60\u591a\u6837\u6027\u7684\u6ce8\u610f\u529b\uff0c\u4ed6\u4eec\u76f8\u4e92\u4fc3\u8fdb\uff0c\u5171\u540c\u4f18\u5316\u7f51\u7edc\uff0c\u4f7f\u5f97\u7f51\u7edc\u80fd\u591f\u5b66\u5230\u6765\u81ea\u591a\u4e2a\u5c40\u90e8\u533a\u57df\u7684\u5224\u522b\u56fe\u50cf\u7279\u5f81\u3002</p> <p>\u6ce8\uff1a\u4ee5\u4e0a\u5185\u5bb9\u4ec5\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u6307\u6b63\u3002</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65e5\u671f\uff1a2021\u5e749\u67086\u65e5</p>"},{"location":"img_enhance/DDPM/DDPM/","title":"\u6269\u6563\u6a21\u578b\u2014\u2014DDPM","text":""},{"location":"img_enhance/DDPM/DDPM/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aNIPS2020</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://arxiv.org/pdf/2006.11239v2.pdf</p>"},{"location":"img_enhance/DDPM/DDPM/#_2","title":"\u4ecb\u7ecd","text":"<p>\u2003\u2003\u6269\u6563\u6a21\u578b\u4e3b\u8981\u5305\u62ec\u524d\u5411\u8fc7\u7a0b\uff08\u4e0d\u65ad\u5f80\u8f93\u5165\u6570\u636e\u4e2d\u6dfb\u52a0\u566a\u58f0\uff09\u548c\u540e\u5411\u8fc7\u7a0b\uff08\u5bf9\u52a0\u566a\u56fe\u50cf\u6267\u884c\u53bb\u566a\u3001\u6062\u590d\u76ee\u7684\uff09\u3002</p> <p> <p></p> <p></p> <p>\u524d\u5411\u8fc7\u7a0b</p> <p>\u2003\u2003\u524d\u5411\u8fc7\u7a0b\u4e0d\u65ad\u6dfb\u52a0\u566a\u58f0\uff0c\u968f\u7740\u91c7\u6837\u6b65\u7684\u589e\u52a0\uff0c\u566a\u58f0\u5360\u6bd4\u4e0d\u65ad\u589e\u52a0\uff0c $$ \\alpha_t = 1-\\beta_t\\\\ x_t=\\sqrt{\\overline {a_t}}x_0+\\sqrt{1-\\overline{a_t}}z_t $$  \u5176\u4e2d\uff0c\\beta\u968f\u7740\u91c7\u6837\u6b65\u7684\u589e\u5927\u800c\u589e\u5927\uff0ca\u968f\u7740\u65f6\u95f4\u6b65\u7684\u589e\u5927\u800c\u51cf\u5c0f\uff0c\\overline{a_t}\u7b49\u4e8ea_ta_{t-1}a_{t-2}\\dots a_0\uff0c\\overline {a_t}\u8d8a\u5927\uff0c\u5219\u539f\u56fe\u6570\u636e\u5360\u6bd4\u8d8a\u5927\uff0c\u53cd\u4e4b\u566a\u58f0\u5360\u6bd4\u8d8a\u5927\uff0cz_t\u8868\u793a\u9ad8\u65af\u566a\u58f0\u3002</p> <p>\u53cd\u5411\u8fc7\u7a0b</p> <p>\u2003\u2003\u53cd\u5411\u8fc7\u7a0b\u4e3a\u6d88\u9664\u566a\u58f0\uff0c\u5177\u4f53\u6b65\u9aa4\u4e3a\uff1a</p> <ul> <li>\u6839\u636e\u6bcf\u4e2a\u91c7\u6837\u6b65t\u548c\u91c7\u6837\u56fe\u50cfx_t\uff0c\u9884\u6d4b\u9ad8\u65af\u566a\u58f0z_t\uff0c\u4e4b\u540e\u8ba1\u7b97\u56fe\u50cf\u5206\u5e03\u7684\u5747\u503c\\mu</li> </ul>  \\mu_t=\\frac{1}{\\sqrt{at}}(x_t-\\frac{1-\\alpha_t}{\\sqrt{1-\\overline \\alpha_t}}z_t)  <ul> <li>\u8ba1\u7b97\u56fe\u50cf\u5206\u5e03\u7684\u65b9\u5dee\\sigma\uff0c\u6807\u51c6\u7684\u6269\u6563\u6a21\u578b\u4e2d\uff0c\u65b9\u5dee\u662f\u56fa\u5b9a\u7684\u6570\u503c\uff1a</li> </ul>  \\frac{1}{\\sigma^2}=\\frac{\\alpha_t}{\\beta_t}+\\frac{1}{1-\\overline \\alpha_{t-1}}  <p>\u540e\u7eed\u7684\u6539\u8fdb\u7248\u672c\u4e2d\uff0c\u65b9\u5dee\u901a\u8fc7\u6a21\u578b\u7684\u9884\u6d4b\u5f97\u5230\u3002</p> <ul> <li>\u5f97\u5230q(x_{t-1}|x_t,x_0)\uff08\u9ad8\u65af\u5206\u5e03\u60c5\u51b5\uff09\uff0c\u6839\u636e\u91cd\u53c2\u6570\u6280\u5de7\u5f97\u5230x_{t-1}</li> </ul>  x_{t-1}=\\mu_t + \\sigma \\odot \\epsilon,\\epsilon \\in N(0,1)  <p>\u5176\u4e2d\\epsilon\u76f8\u5f53\u4e8e\u566a\u58f0\u3002</p> <p>\u6ce8\uff1a</p> <ul> <li>\u6240\u6dfb\u52a0\u7684\u566a\u58f0\u5360\u6bd4\u4e0e\u65f6\u95f4\u6b65t\u6709\u5173\uff0c\u56e0\u6b64\u795e\u7ecf\u7f51\u7edc\u4e3b\u8981\u6839\u636e\u8f93\u5165\u7684\u91c7\u6837\u56fex_t\u548c\u91c7\u6837\u6b65t\u6765\u9884\u6d4b\u566a\u58f0z_t\uff0c\u7f51\u7edc\u7684\u8f93\u5165\u901a\u5e38\u662f\u4e24\u7ec4\u6570\u636e\uff0c\u5148\u5c06\u65f6\u95f4\u6b65t\u505a\u7f16\u7801\u64cd\u4f5c\uff0c\u5c06\u79bb\u6563\u7684\u6570\u636e\u53d8\u4e3a\u8fde\u7eed\u7684\u5411\u91cf\uff0c\u4e4b\u540e\u518d\u4e0e\u56fe\u50cf\u7279\u5f81\u878d\u5408\uff0c\u7528\u4e8e\u9884\u6d4b\u566a\u58f0\u3002\u5176\u4e2d\uff0c\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u4e3b\u8981\u7531U-Net+Attention\u6784\u6210\uff0c\u7f51\u7edc\u7684\u8bad\u7ec3\u4e3b\u8981\u7531\u7f51\u7edc\u7684\u8f93\u51fa\u548c\u566a\u58f0\u6e90\u4e4b\u95f4\u7684MSE\u635f\u5931\u6784\u6210\uff1b</li> <li>\u63a8\u7406\u9636\u6bb5\uff0c\u5c06\u91c7\u6837\u56fex_t\u4e0e\u91c7\u6837\u6b65t\u8fed\u4ee3\u4f20\u5165\u7f51\u7edc\u4e2d\uff0c\u91cd\u590dT\u6b21\uff0c\u5176\u4e2dt\u4eceT-1\u964d\u4f4e\u4e3a0\uff0c\u6700\u7ec8\u751f\u6210\u4e00\u5f20\u56fe\u50cf\u3002</li> </ul> <p>\u672a\u5b8c\u5f85\u7eed\uff0c\u8fd8\u6709\u4e00\u90e8\u5206\u539f\u7406\u7ec6\u8282\u9700\u8981\u518d\u7406\u89e3\u4e00\u4e0b\u3002\u3002</p> <p>\u53c2\u8003\u94fe\u63a5\uff1ahttps://zhuanlan.zhihu.com/p/572770333</p>"},{"location":"img_enhance/DDPM/DDPM/#_3","title":"\u6e90\u7801\u7b14\u8bb0","text":"<p>\u2003\u2003\u4ee3\u7801\u53c2\u8003\u94fe\u63a5\uff1ahttps://colab.research.google.com/drive/1sjy9odlSSy0RBVgMTgP7s99NXsqglsUL?usp=sharing#scrollTo=Ed12NNXPtDon</p>"},{"location":"img_enhance/DDPM/DDPM/#_4","title":"\u603b\u4f53\u6d41\u7a0b","text":"<pre><code># \u603b\u7684\u91c7\u6837\u6b21\u6570\uff0c\u4e5f\u5c31\u662f\u6700\u540e\u5b9e\u73b0\u7684\u8fc7\u7a0b\u4e2d\uff0c\u566a\u58f0\u7ecf\u8fc7T\u6b21\u6062\u590d\u4f1a\u751f\u6210\u56fe\u7247\nT = 300\nbetas = linear_beta_schedule(timesteps=T)\n# \u5b9a\u4e49\u03b1\u548c\u03b2\uff0c\u5176\u4e2d\u03b1\u7528\u4e8e\u63a7\u5236\u566a\u58f0\u548c\u56fe\u50cf\u7684\u5360\u6bd4\uff0c\u03b1\u8d8a\u5927\u5219\u539f\u56fe\u5360\u6bd4\u8d8a\u5927\uff0c\u03b1\u8d8a\u5c0f\u5219\u566a\u58f0\u5360\u6bd4\u8d8a\u5927\n# \u968f\u7740\u91c7\u6837\u6b65t\u589e\u5927\uff0cbeta\u8d8a\u6765\u8d8a\u5927\uff0calpha\u8d8a\u6765\u8d8a\u5c0f\nalphas = 1. - betas\n# \u95f4\u65ad\u751f\u6210\u566a\u58f0\u8d85\u53c2\u6570\uff0ctorch.cumprod\u7528\u4e8e\u5143\u7d20\u7d2f\u4e58\uff0c\u751f\u6210\u7684\u6570\u636e\u4e3a[a1,a1*a2,a1*a2*a3,\u2026\u2026]\nalphas_cumprod = torch.cumprod(alphas, axis=0)\nalphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n# \u6839\u4e0bai\u5206\u4e4b1\uff0c\u7528\u4e8e\u8ba1\u7b97\u91c7\u6837\u8fc7\u7a0b\u4e2d\u7684xt-1\uff0c\u5177\u4f53\u89c1\u8bba\u6587\nsqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n# sqrt(\u7d2f\u4e58at)\nsqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n# sqrt(1-\u7d2f\u4e58at)\uff0cminus\u51cf\uff0c\nsqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)\n# \u7528\u4e8e\u540e\u7eed\u518d\u7ed3\u5408\u5747\u503c\u6765\u8ba1\u7b97xt\nposterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n\nmodel = SimpleUnet()\nBATCH_SIZE = 2\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel.to(device)\nepochs = 100  # Try more!\n\nt = torch.randint(0, T, (BATCH_SIZE,), device=device).long()\nimg = torch.randn((2, 3, 224, 224))\n# \u8ba1\u7b97\u635f\u5931\uff0c\u6839\u636e\u635f\u5931\u6765\u53cd\u5411\u4f20\u64ad\nloss = get_loss(model, img, t)\n# \u6d4b\u8bd5\u9636\u6bb5\uff0c\u751f\u6210\u56fe\u50cf\nsample_plot_image(img_size=224)\n</code></pre>"},{"location":"img_enhance/DDPM/DDPM/#_5","title":"\u8bad\u7ec3\u8fc7\u7a0b","text":"<pre><code>def linear_beta_schedule(timesteps, start=0.0001, end=0.02):\n    return torch.linspace(start, end, timesteps)\n\n\ndef forward_diffusion_sample(x_0, t, device=\"cpu\"):\n    \"\"\"\n    Takes an image and a timestep as input and\n    returns the noisy version of it\n    \"\"\"\n    noise = torch.randn_like(x_0)\n    sqrt_alphas_cumprod_t = get_index_from_list(sqrt_alphas_cumprod, t, x_0.shape)\n    sqrt_one_minus_alphas_cumprod_t = get_index_from_list(\n        sqrt_one_minus_alphas_cumprod, t, x_0.shape\n    )\n    # mean + variance\n    # \u6839\u636e\u516c\u5f0f\u6765\u6dfb\u52a0\u566a\u58f0\n    return sqrt_alphas_cumprod_t.to(device) * x_0.to(device) \\\n           + sqrt_one_minus_alphas_cumprod_t.to(device) * noise.to(device), noise.to(device)\n\n\ndef get_index_from_list(vals, t, x_shape):\n    \"\"\"\n    Returns a specific index t of a passed list of values vals\n    while considering the batch dimension.\n    \"\"\"\n    batch_size = t.shape[0]\n    out = vals.gather(-1, t.cpu())\n    return out.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)\n\n\ndef get_loss(model, x_0, t):\n    # \u5bf9\u56fe\u50cf\u6309\u6b65\u6dfb\u52a0\u566a\u58f0\uff0c\u6b65\u6570t\u8d8a\u5927\uff0c\u5219\u566a\u58f0z\u5360\u6bd4\u8d8a\u5927\uff0c\u5e76\u4e14\u8fd4\u56de\u566a\u58f0z\n    x_noisy, noise = forward_diffusion_sample(x_0, t, device)\n    # \u6838\u5fc3\u76ee\u7684\uff0c\u6839\u636e\u65f6\u95f4\u6b65t\uff0c\u548c\u6dfb\u52a0\u566a\u58f0\u540e\u7684\u56fe\u50cf\uff0c\u9884\u6d4b\u51fa\u566a\u58f0\u6e90z\n    # \u8fd9\u91cc\u5e76\u4e0d\u662f\u76f4\u63a5\u9884\u6d4b\u6dfb\u52a0\u4e86\u591a\u5c11\u566a\u58f0\uff0c\u56e0\u4e3a\u6240\u6dfb\u52a0\u7684\u566a\u58f0\u4e0e\u566a\u58f0\u6e90z\u548c\u65f6\u95f4\u6b65t\u6709\u5173\n    noise_pred = model(x_noisy, t)\n    return F.l1_loss(noise, noise_pred)\n</code></pre>"},{"location":"img_enhance/DDPM/DDPM/#_6","title":"\u6d4b\u8bd5\u8fc7\u7a0b","text":"<pre><code>@torch.no_grad()\ndef sample_timestep(x, t):\n    \"\"\"\n    Calls the model to predict the noise in the image and returns\n    the denoised image.\n    Applies noise to this image, if we are not in the last step yet.\n    \"\"\"\n    betas_t = get_index_from_list(betas, t, x.shape)\n    sqrt_one_minus_alphas_cumprod_t = get_index_from_list(\n        sqrt_one_minus_alphas_cumprod, t, x.shape\n    )\n    sqrt_recip_alphas_t = get_index_from_list(sqrt_recip_alphas, t, x.shape)\n\n    # Call model (current image - noise prediction)\n    # \u5229\u7528\u516c\u5f0f\u8ba1\u7b97\u5747\u503c\n    model_mean = sqrt_recip_alphas_t * (\n            x - betas_t * model(x, t) / sqrt_one_minus_alphas_cumprod_t\n    )\n    posterior_variance_t = get_index_from_list(posterior_variance, t, x.shape)\n\n    if t == 0:\n        # As pointed out by Luis Pereira (see YouTube comment)\n        # The t's are offset from the t's in the paper\n        return model_mean\n    else:\n        noise = torch.randn_like(x)\n        # \u91cd\u91c7\u6837\u6280\u5de7\uff0c\u76f8\u5f53\u4e8e\u56fe\u50cf\u8fd8\u539f\u7684\u8fc7\u7a0b\uff0c\u5747\u503c+sqrt(\u65b9\u5dee)*\u566a\u58f0\n        return model_mean + torch.sqrt(posterior_variance_t) * noise\n\n\n@torch.no_grad()\ndef sample_plot_image(img_size=224):\n    # \u4eceT\u5f00\u59cb\u5f80\u524d\u8fed\u4ee3\uff0c\u4e5f\u5373\u4ece\u7eaf\u566a\u58f0\u5f00\u59cb\u751f\u6210\n    img = torch.randn((1, 3, img_size, img_size), device=device)\n    for i in range(0, T)[::-1]:\n        t = torch.full((1,), i, device=device, dtype=torch.long)\n        img = sample_timestep(img, t)\n        # Edit: This is to maintain the natural range of the distribution\n        img = torch.clamp(img, -1.0, 1.0)\n</code></pre>"},{"location":"img_enhance/DDPM/DDPM/#_7","title":"\u7f51\u7edc\u7ed3\u6784","text":"<p>\u2003\u2003\u8fd9\u53ea\u662f\u4e00\u4e2a\u7b80\u5355\u7684\u6848\u4f8b\uff0c\u540e\u671f\u53ef\u4ee5\u6839\u636e\u4efb\u52a1\u5177\u4f53\u5f62\u5f0f\u6765\u8bbe\u7f6e\u7f51\u7edc\u5f62\u5f0f\u3002\u4f46\u662f\u6709\u4e00\u4e2a\u6838\u5fc3\u70b9\uff0c\u5728\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b\u4e2d\uff0c\u7f51\u7edc\u540c\u65f6\u63a5\u6536\u56fe\u50cf\u548c\u91c7\u6837\u6b65t\uff0c\u5148\u8981\u5bf9\u91c7\u6837\u6b65t\u505a\u7f16\u7801\uff0c\u5c06\u79bb\u6563\u7684\u6570\u636e\u53d8\u4e3a\u8fde\u7eed\u7684\u5411\u91cf\u6570\u636e\uff0c\u4e4b\u540e\u5c06\u56fe\u50cf\u7279\u5f81\u4e0e\u91c7\u6837\u6b65\u7279\u5f81\u505a\u878d\u5408\uff0c\u5728\u6bcf\u6b21\u4e0b\u91c7\u6837\u4ee5\u53ca\u4e0a\u91c7\u6837\u8fc7\u7a0b\u4e2d\uff0c\u91c7\u6837\u6b65\u7279\u5f81\u90fd\u8981\u548c\u7f16\u7801\u3001\u89e3\u7801\u7279\u5f81\u505a\u878d\u5408\u64cd\u4f5c\u3002</p> <pre><code>from torch import nn\nimport math\nimport torch\n\n\nclass Block(nn.Module):\n    def __init__(self, in_ch, out_ch, time_emb_dim, up=False):\n        super().__init__()\n        self.time_mlp = nn.Linear(time_emb_dim, out_ch)\n        if up:\n            self.conv1 = nn.Conv2d(2 * in_ch, out_ch, 3, padding=1)\n            self.transform = nn.ConvTranspose2d(out_ch, out_ch, 4, 2, 1)\n        else:\n            self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n            self.transform = nn.Conv2d(out_ch, out_ch, 4, 2, 1)\n        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n        self.bnorm1 = nn.BatchNorm2d(out_ch)\n        self.bnorm2 = nn.BatchNorm2d(out_ch)\n        self.relu = nn.ReLU()\n\n    def forward(self, x, t, ):\n        # First Conv\n        h = self.bnorm1(self.relu(self.conv1(x)))\n        # Time embedding\n        time_emb = self.relu(self.time_mlp(t))\n        # Extend last 2 dimensions\n        time_emb = time_emb[(...,) + (None,) * 2]\n        # Add time channel\n        # \u56fe\u50cf\u7279\u5f81\u4e0e\u91c7\u6837\u6b65\u7f16\u7801\u5411\u91cf\u505a\u52a0\u6cd5\n        h = h + time_emb\n        # Second Conv\n        h = self.bnorm2(self.relu(self.conv2(h)))\n        # Down or Upsample\n        return self.transform(h)\n\n\nclass SinusoidalPositionEmbeddings(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        self.dim = dim\n\n    def forward(self, time):\n        device = time.device\n        half_dim = self.dim // 2\n        embeddings = math.log(10000) / (half_dim - 1)\n        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n        embeddings = time[:, None] * embeddings[None, :]\n        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n        # TODO: Double check the ordering here\n        return embeddings\n\n\nclass SimpleUnet(nn.Module):\n    \"\"\"\n    A simplified variant of the Unet architecture.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__()\n        image_channels = 3\n        down_channels = (64, 128, 256, 512, 1024)\n        up_channels = (1024, 512, 256, 128, 64)\n        out_dim = 3\n        time_emb_dim = 32\n\n        # Time embedding\n        self.time_mlp = nn.Sequential(\n            SinusoidalPositionEmbeddings(time_emb_dim),\n            nn.Linear(time_emb_dim, time_emb_dim),\n            nn.ReLU()\n        )\n\n        # Initial projection\n        self.conv0 = nn.Conv2d(image_channels, down_channels[0], 3, padding=1)\n\n        # Downsample\n        self.downs = nn.ModuleList([Block(down_channels[i], down_channels[i + 1], \\\n                                          time_emb_dim) \\\n                                    for i in range(len(down_channels) - 1)])\n        # Upsample\n        self.ups = nn.ModuleList([Block(up_channels[i], up_channels[i + 1], \\\n                                        time_emb_dim, up=True) \\\n                                  for i in range(len(up_channels) - 1)])\n\n        # Edit: Corrected a bug found by Jakub C (see YouTube comment)\n        self.output = nn.Conv2d(up_channels[-1], out_dim, 1)\n\n    def forward(self, x, timestep):\n        # Embedd time\n        # \u5bf9\u91c7\u6837\u6b65\u7f16\u7801\uff0c\u5c06\u79bb\u6563\u7684\u6570\u636e\u7f16\u7801\u4e3a\u8fde\u7eed\u7684\u5411\u91cf\n        t = self.time_mlp(timestep)\n        # Initial conv\n        x = self.conv0(x)\n        # Unet\n        residual_inputs = []\n        for down in self.downs:\n            # \u56fe\u50cf\u7279\u5f81\u4e0e\u91c7\u6837\u6b65\u7f16\u7801\u5411\u91cf\u540c\u65f6\u4f20\u5165\u4e0b\u91c7\u6837\u6a21\u5757\n            # \u4e2d\u95f4\u6709\u4e00\u6b65\u52a0\u6cd5\uff0c\u76f8\u5f53\u4e8e\u505a\u4e86\u878d\u5408\u64cd\u4f5c\uff08\u5229\u7528\u5e7f\u64ad\u673a\u5236\uff09\n            x = down(x, t)\n            residual_inputs.append(x)\n        for up in self.ups:\n            residual_x = residual_inputs.pop()\n            # Add residual x as additional channels\n            x = torch.cat((x, residual_x), dim=1)\n            x = up(x, t)\n        return self.output(x)\n</code></pre> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u6307\u6b63\u3002</p>"},{"location":"img_enhance/DDPM/GDP/","title":"GDP\u2014\u2014\u7528\u4e8e\u56fe\u50cf\u6062\u590d\u7684\u6269\u6563\u6a21\u578b","text":""},{"location":"img_enhance/DDPM/GDP/#_1","title":"\u7efc\u8ff0","text":"<p>\u8bba\u6587\u5730\u5740\uff1ahttps://arxiv.org/pdf/2304.01247.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/Fayeben/GenerativeDiffusionPrior</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u56fe\u50cf\u589e\u5f3a</p>"},{"location":"img_enhance/DDPM/GDP/#_2","title":"\u4e3b\u8981\u601d\u60f3","text":"<p>\u2003\u2003\u56fe\u50cf\u6062\u590d\u548c\u589e\u5f3a\u4efb\u52a1\u7684\u76ee\u7684\u662f\u9006\u8f6c\u9000\u5316\u95ee\u9898\uff0c\u63d0\u9ad8\u56fe\u50cf\u8d28\u91cf\uff0c\u901a\u5e38\u6765\u8bf4\uff0c\u6062\u590d\u548c\u589e\u5f3a\u4efb\u52a1\u53ef\u4ee5\u5206\u4e3a\u4e24\u5927\u7c7b\uff1a</p> <ul> <li>\u7ebf\u6027\u9006\u95ee\u9898\uff1a\u4f8b\u5982\u8d85\u5206\u8fa8\u7387\u91cd\u6784\uff08super-resolution\uff09\u3001\u56fe\u50cf\u53bb\u6a21\u7cca\uff08deblurring\uff09\u3001\u56fe\u50cf\u7ed8\u5236\uff08inpainting\uff09\u3001\u56fe\u50cf\u4e0a\u8272\uff08colorization\uff09\uff0c\u5176\u4e2d\u7684\u9000\u5316\u6a21\u578b\u901a\u5e38\u662f\u7ebf\u6027\u4e14\u5df2\u77e5\u7684\uff1b</li> <li>\u975e\u7ebf\u6027\u6216\u76f2\u95ee\u9898\uff1a\u4f8b\u5982\u4f4e\u5149\u589e\u5f3a\uff08low-light enhancement\uff09\u3001HDR\u56fe\u50cf\u6062\u590d\uff08HDR image recovery\uff09\uff0c\u5176\u4e2d\u9000\u5316\u6a21\u578b\u662f\u975e\u7ebf\u6027\u4e14\u672a\u77e5\u7684\u3002</li> </ul> <p>\u2003\u2003\u5bf9\u4e8e\u7279\u5b9a\u7684\u7ebf\u6027\u9000\u5316\u6a21\u578b\uff0c\u56fe\u50cf\u6062\u590d\u53ef\u4ee5\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u7684\u7aef\u5230\u7aef\u8bad\u7ec3\u6765\u89e3\u51b3\u3002\u7136\u800c\u73b0\u5b9e\u4e16\u754c\u4e2d\uff0c\u56fe\u50cf\u4f1a\u9762\u4e34\u591a\u91cd\u3001\u590d\u6742\u7684\u9000\u5316\uff0c\u4f1a\u5f71\u54cd\u56fe\u50cf\u7684\u751f\u6210\u8fc7\u7a0b\u3002</p> <p>\u2003\u2003\u901a\u8fc7\u751f\u6210\u6a21\u578b\u6765\u5bfb\u6c42\u66f4\u4e00\u822c\u7684\u56fe\u50cf\u5148\u9a8c\uff0c\u5e76\u4e14\u5728\u65e0\u76d1\u7763\u7684\u7b56\u7565\u4e0b\u5904\u7406\u56fe\u50cf\u6062\u590d\uff0c\u5176\u4e2d\u4e0d\u540c\u9000\u5316\u6a21\u578b\u7684\u591a\u4e2a\u6062\u590d\u4efb\u52a1\u53ef\u4ee5\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u89e3\u51b3\uff08\u4ec5\u7528\u4e00\u4e2a\u6a21\u578b\u89e3\u51b3\u591a\u4e2a\u9000\u5316\u4efb\u52a1\uff09\u3002\u4f8b\u5982\uff0c\u5229\u7528GAN\u5728\u5927\u91cf\u5e72\u51c0\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\uff0c\u5b66\u4e60\u4e86\u4e30\u5bcc\u7684\u73b0\u5b9e\u4e16\u754c\u573a\u666f\u77e5\u8bc6\uff0c\u901a\u8fc7GAN\u53cd\u6f14\u6210\u529f\u5730\u89e3\u51b3\u4e86\u5404\u79cd\u7ebf\u6027\u9006\u95ee\u9898\uff08\u8bba\u6587\u94fe\u63a5\uff09\uff1b\u4e0e\u6b64\u540c\u65f6\uff0c\u6269\u6563\u6a21\u578b\u5728GAN\u7684\u57fa\u7840\u4e0a\u5c55\u793a\u4e86\u6548\u679c\u975e\u5e38\u597d\u5e76\u4e14\u591a\u6837\u6027\u8f83\u9ad8\u7684\u751f\u6210\u80fd\u529b\u4ee5\u53ca\u7ec6\u8282\u6062\u590d\u80fd\u529b\u3002</p> <p>\u2003\u2003\u5728\u672c\u6587\u4e2d\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u7528\u4e8e\u56fe\u50cf\u6062\u590d\u548c\u589e\u5f3a\u7684GDP\u7b97\u6cd5\uff0c\u5229\u7528\u8bad\u7ec3\u597d\u7684\u6269\u6563\u6a21\u578b\uff08DDPM\uff09\u4f5c\u4e3a\u901a\u7528\u56fe\u50cf\u6062\u590d\u548c\u589e\u5f3a\u7684\u6709\u6548\u5148\u9a8c\uff0c\u4f7f\u7528\u9000\u5316\u7684\u56fe\u50cf\u4f5c\u4e3a\u6307\u5bfc\u3002\u4f5c\u4e3a\u4e00\u4e2a\u7edf\u4e00\u7684\u56fe\u50cf\u6062\u590d\u6846\u67b6\uff0cGDP\u4e0d\u4ec5\u9002\u7528\u4e8e\u5404\u79cd\u7ebf\u6027\u9006\u95ee\u9898\uff0c\u800c\u4e14\u7b2c\u4e00\u6b21\u63a8\u5e7f\u5230\u975e\u7ebf\u6027\u3001\u76f2\u76ee\u7684\u56fe\u50cf\u6062\u590d\u548c\u589e\u5f3a\u4efb\u52a1\u3002\u7136\u800c\uff0c\u89e3\u51b3\u76f2\u76ee\u7684\u9006\u95ee\u9898\u5e76\u4e0d\u5bb9\u6613\uff0c\u56e0\u4e3a\u9700\u8981\u540c\u65f6\u4f30\u8ba1\u9000\u5316\u6a21\u578b\u5e76\u4e14\u4ee5\u9ad8\u771f\u5ea6\u6062\u590d\u5e72\u51c0\u56fe\u50cf\u3002\u7531\u4e8e\u9884\u8bad\u7ec3\u7684\u6269\u6563\u6a21\u578b\u5177\u6709\u751f\u6210\u5148\u9a8c\uff0cDDPM\u6d41\u5f62\u5185\u7684\u53bb\u566a\u81ea\u7136\u5730\u6b63\u5219\u5316\u4e86\u6062\u590d\u56fe\u50cf\u7684\u771f\u5b9e\u611f\u548c\u4fdd\u771f\u5ea6\uff0c\u56e0\u6b64\uff0c\u4f5c\u8005\u91c7\u7528\u4e86\u4e00\u79cd\u76f2\u9000\u5316\u4f30\u8ba1\u7b56\u7565\uff0c\u5728\u53bb\u566a\u8fc7\u7a0b\u4e2d\u968f\u673a\u521d\u59cb\u5316\u548c\u4f18\u5316GDP\u9000\u5316\u6a21\u578b\u7684\u53c2\u6570\u3002\u6b64\u5916\uff0c\u4e3a\u4e86\u8fdb\u4e00\u6b65\u63d0\u9ad8\u56fe\u50cf\u7684\u771f\u5b9e\u611f\u548c\u8d28\u91cf\uff0c\u4f5c\u8005\u7cfb\u7edf\u5730\u7814\u7a76\u4e86\u4e00\u79cd\u6709\u6548\u7684\u7b56\u7565\u6765\u6307\u5bfc\u6269\u6563\u6a21\u578b\uff0c\u5728\u91c7\u6837\u8fc7\u7a0b\u4e2d\uff0c\u9884\u8bad\u7ec3\u7684DDPM\u9996\u5148\u901a\u8fc7\u4f30\u8ba1\u566a\u58f0x_t\uff0c\u4ece\u566a\u58f0x_t\u4e2d\u9884\u6d4b\u51fa\u4e00\u4e2a\u5e72\u51c0\u7684\u56fe\u50cf\\tilde{x}_0\uff0c\u5728\u8fd9\u4e2a\u4e2d\u95f4\u53d8\u91cf\\tilde x_0\u4e0a\u6dfb\u52a0\u5f15\u5bfc\u6765\u63a7\u5236DDPM\u7684\u751f\u6210\u8fc7\u7a0b\u3002\u6b64\u5916\uff0c\u672c\u6587\u8fd8\u63d0\u51fa\u4e86\u5206\u5c42\u5f15\u5bfc\u548c\u57fa\u4e8e\u8865\u4e01\u7684\u751f\u6210\u7b56\u7565\uff0c\u5728\u8fd9\u4e24\u4e2a\u65b9\u6cd5\u7684\u5e2e\u52a9\u4e0b\uff0cGDP\u53ef\u4ee5\u6062\u590d\u4efb\u610f\u5206\u8fa8\u7387\u7684\u56fe\u50cf\uff0c\u5176\u4e2d\u9996\u5148\u9884\u6d4b\u4f4e\u5206\u8fa8\u7387\u7684\u56fe\u50cf\u548c\u9000\u5316\u6a21\u578b\uff0c\u7528\u4e8e\u6307\u5bfc\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u7684\u751f\u6210\u3002</p> <p>\u6ce8\uff1a\u4f30\u8ba1\u9000\u5316\u6a21\u578b\uff0c\u4e5f\u5c31\u662f\u4e86\u89e3\u56fe\u50cf\u662f\u5982\u4f55\u88ab\u7834\u574f\u7684\uff0c\u4f8b\u5982\u53bb\u96fe\u9000\u5316\u6a21\u578b\u5c31\u662f\u5728\u539f\u56fe\u4e0a\u52a0\u96fe\u3002</p> <p>\u2003\u2003\u672c\u6587\u7684\u8d21\u732e\uff1a</p> <ul> <li>GDP\u662f\u7b2c\u4e00\u4e2a\u7edf\u4e00\u7684\u56fe\u50cf\u6062\u590d\u7b97\u6cd5\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u4f7f\u7528\u5728ImageNet\u4e0a\u9884\u8bad\u7ec3\u7684\u5355\u4e2a\u65e0\u6761\u4ef6DDPM\uff0c\u4ee5\u65e0\u76d1\u7763\u7684\u65b9\u5f0f\u4e3a\u7edf\u4e00\u7684\u56fe\u50cf\u6062\u590d\u548c\u589e\u5f3a\u4ea7\u751f\u591a\u6837\u5316\u548c\u9ad8\u4fdd\u771f\u7684\u8f93\u51fa\uff1b</li> <li>GDP\u80fd\u591f\u4f18\u5316\u968f\u673a\u521d\u59cb\u5316\u7684\u9000\u5316\u6a21\u578b\uff0c\u4ece\u800c\u5f62\u6210\u4e00\u4e2a\u5f3a\u5927\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u4efb\u4f55\u76f2\u76ee\u7684\u56fe\u50cf\u6062\u590d\u95ee\u9898\uff1b</li> <li>\u4e3a\u4e86\u5b9e\u73b0\u4efb\u610f\u5927\u5c0f\u7684\u56fe\u50cf\u751f\u6210\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u5206\u5c42\u5f15\u5bfc\u548c\u57fa\u4e8epatch\u7684\u65b9\u6cd5\uff0c\u6781\u5927\u5730\u4fc3\u8fdb\u4e86GDP\u5728\u81ea\u7136\u56fe\u50cf\u751f\u6210\u65b9\u9762\u7684\u589e\u5f3a</li> <li>\u4e0d\u540c\u4e8e\u4f20\u7edf\u7684\u5f15\u5bfc\u65b9\u5f0f\uff0cGDP\u76f4\u63a5\u9884\u6d4b\u6bcf\u4e00\u6b65\u7ed9\u5b9a\u7684\u566a\u58f0\u56fe\u50cf\u7684\u4e34\u65f6\u8f93\u51fa\uff0c\u5e76\u5229\u7528GDP\u76f4\u63a5\u6307\u5bfc\u4e0b\u4e00\u6b65\u7684\u56fe\u50cf\u751f\u6210\u3002</li> </ul>"},{"location":"img_enhance/DDPM/GDP/#_3","title":"\u65b9\u6cd5","text":""},{"location":"img_enhance/DDPM/GDP/#_4","title":"\u6269\u6563\u6a21\u578b","text":"<p>\u2003\u2003\u6269\u6563\u6a21\u578b\u4e3b\u8981\u5c06\u590d\u6742\u7684\u6570\u636e\u5206\u5e03x_0\\sim p_{data}\u9010\u6e10\u6dfb\u52a0\u566a\u58f0\uff0c\u8f6c\u4e3a\u7b80\u5355\u7684\u566a\u58f0\u5206\u5e03x_T\\sim p_{latent}=N(0,I)\uff0c\u5e76\u4e14\u4ece\u566a\u58f0\u4e2d\u6062\u590d\u6570\u636e\uff0c\u5176\u4e2dN\u4e3a\u9ad8\u65af\u5206\u5e03\uff0cDDPM\u4e3b\u8981\u5305\u62ec\u6269\u6563\u8fc7\u7a0b\u548c\u6062\u590d\u8fc7\u7a0b\u3002</p> <p> \u6269\u6563\u8fc7\u7a0b\u662f\u4e00\u4e2a\u9a6c\u5c14\u79d1\u592b\u94fe\uff0c\u9010\u6b65\u7834\u574f\u539f\u59cb\u56fe\u50cf\u6570\u636ex_0\uff0c\u76f4\u5230\u4ed6\u5728T\u4e2a\u6269\u6563\u65f6\u95f4\u6b65\u957f\u53d8\u4e3a\u9ad8\u65af\u566a\u58f0\uff0c\u5bf9\u5e94\u4f1a\u91c7\u6837\u5f97\u5230T\u4e2a\u7834\u574f\u7a0b\u5ea6\u4e0d\u540c\u7684\u6570\u636ex_1,\\dots,x_T\uff0c\u6269\u6563\u8fc7\u7a0b\u7684\u5b9a\u4e49\u4e3a\u9ad8\u65af\u8fc1\u79fb\uff1a $$ q(x_1,\\dots,x_T|x_0)=\\Pi^T_{t=1}q(x_t|x_{t-1}) $$  \u5176\u4e2dt\u8868\u793a\u6269\u6563\u6b65\u6570\uff0cq(x_t|x_{t-1})=N(x_t;\\sqrt{1-\\beta_t}x_{t-1},\\beta_tI)\uff0c\\beta_t\u4e3a\u56fa\u5b9a\u7684\u6216\u53ef\u5b66\u4e60\u7684\u65b9\u5dee\u8868\uff0c\u4efb\u4f55\u6b65\u957fx_t\u90fd\u53ef\u4ee5\u901a\u8fc7\u4e0b\u9762\u7684\u516c\u5f0f\u76f4\u63a5\u4ecex_0\u91c7\u6837\u5f97\u5230\uff1a $$ x_t=\\sqrt{\\overline \\alpha_t}x_0+\\sqrt{1-\\overline{\\alpha}_t}\\epsilon $$  \u5176\u4e2d\\epsilon\\sim N(0,1)\uff0c\\alpha_t=1-\\beta_t\uff0c\\overline\\alpha_t=\\Pi^t_{i=1}\\alpha_i\u3002\u6269\u6563\u6a21\u578b\u8bba\u6587\u4e2d\u4e5f\u66fe\u6307\u51fa\uff0cq(x_t|x_0)=N(x_t;\\sqrt{\\overline \\alpha_t}x_0,(1-\\overline \\alpha_t)I)\uff0c\u968f\u7740t\u7684\u589e\u5927\uff08\u6162\u6162\u53d8\u6210T\uff09\uff0c\\overline\\alpha_t\u9010\u6e10\u53d8\u4e3a0\uff0c\u540c\u65f6q(x_t|x_0)\u9010\u6e10\u8d8b\u5411\u4e8e\u9ad8\u65af\u5206\u5e03\uff0c\u5373\u9010\u6e10\u53d8\u4e3a\u5b8c\u5168\u7684\u566a\u58f0\u3002</p> <p> \u53cd\u5411\u8fc7\u7a0b\u540c\u6837\u4e5f\u662f\u4e00\u4e2a\u9a6c\u5c14\u79d1\u592b\u94fe\uff0c\u8fed\u4ee3\u5730\u5bf9\u4e00\u4e2a\u9ad8\u65af\u566a\u58f0\u53bb\u566a\uff0c\u5f97\u5230\u4e00\u5e45\u6e05\u6670\u7684\u56fe\u50cf\u3002\u4ece\u566a\u58f0x_T\\sim N(0,I)\u5230\u6e05\u6670\u56fe\u50cfx_0\u7684\u8fc7\u7a0b\u53ef\u4ee5\u5b9a\u4e49\u4e3a\uff1a $$ p_\\theta(x_0,\\dots,x_{T-1}|x_t)=\\Pi^T_{t=1}p_\\theta(x_{t-1}|x_t)\\\\ p_\\theta(x_{t-1}|x_t)=N(x_{t-1};\\mu_\\theta(x_t,t),\\sum_\\theta I) $$  \u5176\u4e2d\\mu_\\theta(x_t,t)\u662f\u6211\u4eec\u60f3\u8981\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\\theta\u53bb\u4f30\u8ba1\u7684\u76ee\u6807\uff0c\u65b9\u5dee\\sum_\\theta\u53ef\u4ee5\u662f\u4e00\u4e2a\u968f\u7740\u65f6\u95f4t\uff08\u91c7\u6837\u6b65\uff09\u53d8\u5316\u7684\u5e38\u6570\uff0c\u4e5f\u53ef\u4ee5\u662f\u4e00\u4e2a\u53ef\u5b66\u4e60\u7684\u53c2\u6570\uff0c\\mu_\\theta\u53ef\u4ee5\u901a\u8fc7\u5982\u4e0b\u516c\u5f0f\u5f97\u5230\uff1a $$ \\mu_\\theta(x_t,t)=\\frac{1}{\\sqrt{\\alpha_t}}(x_t,-\\frac{\\beta_t}{\\sqrt{1-\\overline\\alpha_t}}\\epsilon_\\theta(x_t,t)) $$  \u2003\u2003\u5728\u5b9e\u8df5\u4e2d\uff0c\u901a\u5e38\u4ecex_t\u4e2d\u9884\u6d4b\\tilde x_0\uff0c\u4e4b\u540e\u4f7f\u7528\\tilde x_0\u548cx_t\u5bf9x_{t-1}\u8fdb\u884c\u91c7\u6837\uff1a $$ \\tilde x_0=\\frac{x_t}{\\sqrt{\\overline \\alpha_t}}-\\frac{\\sqrt{1-\\overline \\alpha_t}\\epsilon_\\theta(x_t,t)}{\\sqrt{\\overline \\alpha_t}} $$ $$ q(x_{t-1}|x_t,\\tilde x_0)=N(x_{t-1};\\tilde\\mu_t(x_t,\\tilde x_0),\\beta_t I) $$ </p> <p>\u2003\u2003\u5176\u4e2d\\tilde \\mu_t(x_t,\\tilde x_0)=\\frac{\\sqrt{\\overline \\alpha_{t-1}}\\beta_t}{1-\\overline {\\alpha_t}}+\\frac{\\sqrt{\\alpha_t}(1-\\overline{\\alpha_{t-1}})}{1-\\overline \\alpha_t}x_t\uff0c\\tilde \\beta_t=\\frac{1-\\overline \\alpha_{t-1}}{1-\\overline \\alpha_t}\\beta_t</p>"},{"location":"img_enhance/DDPM/GDP/#gdp_1","title":"\u751f\u6210\u6269\u6563\u5148\u9a8c\u6a21\u578b\uff08GDP\uff09","text":"<p>\u2003\u2003\u5728\u672c\u6587\u4e2d\uff0c\u4f5c\u8005\u7684\u76ee\u6807\u5c31\u662f\u5229\u7528\u8bad\u7ec3\u597d\u7684\u6269\u6563\u6a21\u578b\u4f5c\u4e3a\u7edf\u4e00\u56fe\u50cf\u6062\u590d\u548c\u589e\u5f3a\u7684\u6709\u6548\u5148\u9a8c\uff0c\u7279\u522b\u662f\u5904\u7406\u79cd\u7c7b\u7e41\u591a\u7684\u56fe\u50cf\u9000\u5316\u95ee\u9898\u3002\u5047\u8bbe\u9000\u5316\u56fe\u50cfy\u901a\u8fc7\u9000\u5316\u6a21\u578bD\u5f97\u5230\uff1ay=D(x)\uff0c\u5176\u4e2dx\u8868\u793a\u539f\u59cb\u56fe\u50cf\u3002\u4f5c\u8005\u4f7f\u7528\u5b58\u50a8\u5728\u67d0\u4e2a\u5148\u9a8c\u4e2d\u7684x\u7edf\u8ba1\u91cf\uff0c\u5728x\u7684\u7a7a\u95f4\u4e2d\u641c\u7d22\u6700\u5339\u914dy\u7684x\uff08\u4e5f\u5c31\u662f\u627e\u51fay\u5bf9\u5e94\u7684\u6e05\u6670\u56fe\u50cfx\uff09\uff0c\u5728\u672c\u6587\u4e2d\uff0c\u4f5c\u8005\u5c06\u91cd\u70b9\u7814\u7a76\u653e\u5728\u66f4\u901a\u7528\u7684\u56fe\u50cf\u5148\u9a8c\uff0c\u5373\u5728\u5927\u89c4\u6a21\u81ea\u7136\u56fe\u50cf\u4e0a\u8bad\u7ec3\u7684\u6269\u6563\u6a21\u578b\u7528\u4e8e\u56fe\u50cf\u5408\u6210\uff0c\u6269\u6563\u6a21\u578b\u7684\u53cd\u5411\u53bb\u566a\u8fc7\u7a0b\u53ef\u4ee5\u9000\u5316\u4e3a\u4ee5y\u4e3a\u6761\u4ef6\u7684\u56fe\u50cf\u751f\u6210\u8fc7\u7a0b\uff0c\u5177\u4f53\u6765\u8bf4\uff0c\u53cd\u5411\u53bb\u566a\u5206\u5e03p_\\theta(x_{t-1}|x_t)\uff0c\u53ef\u4ee5\u7528\u4e8e\u6784\u6210\u6761\u4ef6\u5206\u5e03p_\\theta(x_{t-1}|x_t,y)\uff1a $$ \\log{p_\\theta(x_{t-1}|x_t,y)}=\\log{(p_\\theta(x_{t-1}|x_t)p(y|x_t))}+K_1\\approx \\log{p(r)} + K_2 $$  \u5176\u4e2d\uff0cr\\sim N(r;\\mu_\\theta(x_t,t)+\\sum_g,\\sum)\uff0cg=\\nabla x_t\\log{p(y|x_t)}\uff0c\\sum=\\sum_\\theta(x_t)\uff0cK_1\u548cK_2\u53ef\u4ee5\u89c6\u4e3a\u5e38\u6570\uff0cp_\\theta(y|x_t)\u53ef\u4ee5\u770b\u4f5c\u662fx_t\u88ab\u964d\u566a\u540e\u5f97\u5230\u8d28\u91cf\u4e0ey\u4e00\u81f4\u7684\u56fe\u50cf\u7684\u6982\u7387\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u542f\u53d1\u5f0f\u8fd1\u4f3c\uff1a $$ p(y|x_t)=\\frac1Z\\exp{(-[sL(D(x_t),y)+\\lambda Q(x_t)])} $$  \u5176\u4e2dL\u8868\u793a\u56fe\u50cf\u8ddd\u79bb\u5ea6\u91cf\uff0cZ\u4e3a\u5f52\u4e00\u5316\u56e0\u5b50\uff0cs\u4e3a\u4e00\u4e2a\u63a7\u5236\u6307\u5bfc\u5e45\u5ea6\u7684\u6bd4\u4f8b\u56e0\u5b50\u3002\u76f4\u89c2\u5730\u6765\u8bf4\uff0c\u8fd9\u4e00\u5b9a\u4e49\u9f13\u52b1x_t\u4e0e\u635f\u574f\u7684\u56fe\u50cfy\u4e00\u81f4\uff0c\u4ece\u800c\u8ba9p(y|x_t)\u83b7\u5f97\u8f83\u9ad8\u7684\u6982\u7387\uff0cQ\u4e3a\u53ef\u9009\u7684\u8d28\u91cf\u589e\u5f3a\u635f\u5931\uff0c\u7528\u4e8e\u589e\u5f3aGDP\u7684\u7075\u6d3b\u6027\uff0c\u53ef\u4ee5\u7528\u6765\u63a7\u5236\u67d0\u4e9b\u5c5e\u6027\uff08\u5982\u4eae\u5ea6\uff09\u6216\u589e\u5f3a\u53bb\u566a\u56fe\u50cf\u7684\u8d28\u91cf\uff0c\\lambda\u662f\u8c03\u8282\u56fe\u50cf\u8d28\u91cf\u7684\u6bd4\u4f8b\u56e0\u5b50\uff0c\u4e24\u8fb9\u7684\u68af\u5ea6\u8ba1\u7b97\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ \\log{p(y|x_t)}=-\\log Z-sL(D(x_t),y)-\\lambda Q(x_t)\\\\ \\nabla_{x_t}\\log{p(y|x_t)}=-s\\nabla_{x_t}L(D(x_t),y)-\\lambda\\nabla_{x_t}Q(x_t) $$  \u5176\u4e2d\u8ddd\u79bb\u5ea6\u91cfL\u548c\u53ef\u9009\u7684\u8d28\u91cf\u635f\u5931Q\u53ef\u4ee5\u5728\u540e\u7eed\u6587\u7ae0\u4e2d\u627e\u5230\u3002</p> <p> <p></p> <p></p> <p>\u6ce8\uff1a\u6269\u6563\u6a21\u578b\u7684\u63a8\u7406\u8fc7\u7a0b\u5c31\u662f\u9010\u6b65\u53bb\u566a\u7684\u8fc7\u7a0b\uff0c\u9010\u6b65\u5c06\u5b8c\u5168\u7684\u9ad8\u65af\u566a\u58f0\u53d8\u4e3a\u6e05\u6670\u56fe\u50cf\uff0c\u5728\u8fd9\u91cc\uff0c\u4f5c\u8005\u8ba9\u9000\u5316\u56fe\u50cfy\u4f5c\u4e3a\u6307\u5bfc\uff0c\u8ba9\u9ad8\u65af\u566a\u58f0\u5728\u53bb\u566a\u7684\u8fc7\u7a0b\u4e2d\u9010\u6b65\u5f80y\u56fe\u50cf\u6240\u6307\u5bfc\u7684\u5206\u5e03\u4e0a\u53bb\u9760\u62e2\uff0c\u7531\u4e8e\u9884\u8bad\u7ec3\u7684\u6269\u6563\u6a21\u578b\u5177\u6709\u6e05\u6670\u56fe\u50cf\u7684\u5148\u9a8c\u77e5\u8bc6\uff0c\u56e0\u6b64\u53ef\u4ee5\u5929\u7136\u5730\u751f\u6210y\u5bf9\u5e94\u7684\u6e05\u6670\u56fe\u50cf\u3002\u81f3\u4e8e\u600e\u4e48\u6307\u5bfc\u6269\u6563\u6a21\u578b\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u5c31\u662f\u540e\u9762\u9700\u8981\u8ba8\u8bba\u7684\u5185\u5bb9\u4e86\u3002</p> <p>\u2003\u2003\u901a\u8fc7\u5229\u7528-(s\\sum\\nabla_{x_t}L(D(x_t),y)+\\lambda\\sum\\nabla_{x_t}Q(x_t))\uff0c\u5bf9\u65e0\u6761\u4ef6\u5206\u5e03\u5e73\u5747\u503c\u8fdb\u884c\u5e73\u79fb\uff0c\u53ef\u4ee5\u8fd1\u4f3c\u5730\u5f97\u5230\u6761\u4ef6\u8fc1\u79fbp_{\\theta}(x_{t-1}|x_t,y)\u548c\u6761\u4ef6\u8fc1\u79fbp_\\theta(x_{t-1}|x_t)\u3002</p> <p>\u6ce8\uff1a</p> <ul> <li>\u8fd9\u91cc\u4f7f\u7528\u635f\u5931\u6240\u4ea7\u751f\u7684\u68af\u5ea6\u6765\u5bf9\u56fe\u50cf\u5206\u5e03\u505a\u8fc1\u79fb\uff0c\u4e5f\u5c31\u662f\u5c06\u968f\u673a\u751f\u6210\u7684\u56fe\u50cf\u5206\u5e03\u4e00\u6b65\u6b65\u8fc1\u79fb\u5230y\u5bf9\u5e94\u6e05\u6670\u56fe\u50cf\u7684\u5206\u5e03\uff1b</li> <li>\u4f5c\u8005\u53d1\u73b0\u6dfb\u52a0\u6307\u5bfc\u7684\u65b9\u5f0f\u548c\u65b9\u5dee\\sum\u7684\u7ec4\u5408\u4f1a\u5bf9\u91cd\u6784\u56fe\u50cf\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\uff0c\u56e0\u6b64\u540e\u9762\u5220\u53bb\u4e86\u65b9\u5dee\u7684\u4f5c\u7528\u3002</li> </ul>"},{"location":"img_enhance/DDPM/GDP/#_5","title":"\u5355\u4e00\u56fe\u50cf\u6307\u5bfc","text":"<p>\u2003\u2003\u8d85\u5206\u91cd\u6784\u3001\u7ed8\u56fe\u3001\u4e0a\u8272\u3001\u53bb\u6a21\u7cca\u4ee5\u53ca\u5149\u7167\u4efb\u52a1\u90fd\u4f7f\u7528\u5355\u56fe\u50cf\u5f15\u5bfc\u3002</p> <p> \u65b9\u5dee\\sum\u5bf9\u6307\u5bfc\u7684\u5f71\u54cd\uff1a\u5728\u4ee5\u5f80\u7684\u6761\u4ef6\u6269\u6563\u6a21\u578b\u4e2d\uff0c\u5bf9\u91c7\u6837\u8fc7\u7a0b\u4e2d\u7684\u5747\u503c\u4f4d\u79fb\u91c7\u7528\u65b9\u5dee\\sum\uff0c\u4f46\u662f\u5728\u4f5c\u8005\u7684\u5de5\u4f5c\u4e2d\uff0c\u4f5c\u8005\u53d1\u73b0\u65b9\u5dee\\sum\u53ef\u80fd\u4f1a\u5bf9\u5b9e\u9a8c\u4e2d\u751f\u6210\u7684\u56fe\u50cf\u8d28\u91cf\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\u3002\u56e0\u6b64\uff0c\u672c\u6587\u5728\u5f15\u5bfc\u53bb\u566a\u7684\u8fc7\u7a0b\u4e2d\u9664\u53bb\u65b9\u5dee\uff0c\u6765\u63d0\u9ad8\u6027\u80fd\uff0c\u5f15\u5bfc\u53bb\u566a\u7684\u8fc7\u7a0b\u53ef\u4ee5\u901a\u8fc7\u53ef\u53d8\u5c3a\u5ea6\\hat s\u6765\u5b9e\u73b0\u3002</p> <p> \u5173\u4e8ex_t\u7684\u6307\u5bfc\uff1a\u9996\u5148\uff0c\u6700\u7b80\u5355\u7684\u65b9\u6cd5\u5c31\u662f\u76f4\u63a5\u5728x_t\u4e0a\u5e94\u7528\u6307\u5bfc\uff0c\u4e5f\u5c31\u662f\u8bbe\u8ba1\u635f\u5931\uff0c\u8ba9\u9000\u5316\u540e\u7684x_t\u8d8b\u5411\u4e8ey\uff08\u76f4\u63a5\u62c9\u8fdbD(x_t)\u4e0ey\uff09\uff0c\u6d41\u7a0b\u56fe\u5982\u4e0a\u56feb\u6240\u793a\uff0c\u8fc7\u7a0b\u5982\u4e0b\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u4f46\u662f\u8fd9\u6837\u505a\u5f80\u5f80\u6548\u679c\u5e76\u4e0d\u662f\u5f88\u597d\uff0cx_t\u662f\u4e00\u4e2a\u5177\u6709\u7279\u5b9a\u566a\u58f0\u5927\u5c0f\u7684\u566a\u58f0\u56fe\u50cf\uff0c\u4f46y\u901a\u5e38\u662f\u7531\u6ca1\u6709\u566a\u58f0\u7684\u6e05\u6670\u56fe\u50cf\u9000\u5316\u800c\u6765\uff0c\u5bf9\u5e26\u566a\u56fe\u50cfx_t\u76f4\u63a5\u6267\u884c\u9000\u5316\u7684\u8bdd\uff0c\u7b97\u6cd5\u96be\u4ee5\u77e5\u9053\u6240\u751f\u6210\u7684\u9000\u5316\u56fe\u50cf\u662f\u7531\u9000\u5316\u6a21\u578bD\u9020\u6210\u7684\u8fd8\u662f\u539f\u59cb\u56fe\u50cf\u672c\u8eab\u5e26\u7684\uff0c\u56e0\u6b64\u96be\u4ee5\u8861\u91cfD(x_t)\u4e0ey\u4e4b\u95f4\u7684\u8ddd\u79bb\uff0c\u76f4\u63a5\u7528MSE\u635f\u5931\u6216\u8005\u611f\u77e5\u635f\u5931\u5f3a\u884c\u62c9\u8fd1\u7684\u8bdd\uff0c\u5c06\u4f7fx_t\u504f\u79bb\u539f\u6765\u7684\u566a\u58f0\u8f68\u8ff9\uff0c\u4f1a\u5bfc\u81f4\u6240\u751f\u6210\u7684\u56fe\u50cf\u8d28\u91cf\u4f4e\u4e0b\u3002</p> <p>\u6ce8\uff1a\u56e0\u4e3a\u8981\u8bc4\u4f30\u9000\u5316\u6a21\u578bD\uff0c\u6240\u4ee5\u8981\u5728\u539f\u6765\u7684\u6269\u6563\u6d41\u7a0b\u4e0a\u5f15\u5165\u4e00\u4e2a\u65b0\u7684\u5206\u652f\uff0c\u7528\u4e8e\u8bc4\u4f30\u9000\u5316\u6a21\u578b\u3002\uff08\u9000\u5316\u6a21\u578b\u9700\u8981\u91cd\u65b0\u8bad\u7ec3\u5417\uff1f\uff09</p> <p> \u5173\u4e8e\\tilde x_0\u7684\u6307\u5bfc\uff1a\u4e3a\u4e86\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898\uff0c\u4f5c\u8005\u7cfb\u7edf\u5730\u7814\u7a76\u4e86\u5e94\u7528\u4e8e\\tilde x_0\u7684\u6761\u4ef6\u4fe1\u53f7\u3002\u5728\u91c7\u6837\u8fc7\u7a0b\u4e2d\uff0c\u9884\u8bad\u7ec3\u7684DDPM\u6a21\u578b\u901a\u5e38\u5148\u4f30\u8ba1x_t\u4e2d\u7684\u566a\u58f0\uff08\u5229\u7528x_t\u548c\u65f6\u95f4\u6b65t\u9884\u6d4b\u566a\u58f0\u6e90\uff09\uff0c\u4ece\u566a\u58f0\u56fe\u50cfx_t\u4e2d\u9884\u6d4b\u4e00\u5f20\u5e72\u51c0\u56fe\u50cf\\tilde x_0\uff08\u76f8\u5f53\u4e8e\u4e00\u4e2a\u4e2d\u95f4\u6001\uff09\u3002\u4e4b\u540e\u5229\u7528\u9884\u6d4b\u7684\\tilde x_0\u4e0ey\u8ba1\u7b97\u635f\u5931\uff0c\u5229\u7528\u635f\u5931\u4f18\u5316\u9000\u5316\u6a21\u578bD\uff0c\u5e76\u4e14\u518d\u5229\u7528\u635f\u5931\u4ea7\u751f\u7684\u68af\u5ea6\u751f\u6210\u56fe\u50cf\u201c\u5f15\u5bfc\u201d\uff08guidance\uff09\uff0c\u6700\u540e\u8ba9\u56fe\u50cf\u201c\u5f15\u5bfc\u201d\u4e0ex_t\u4e00\u8d77\u5bf9\u4e0b\u4e00\u6b65\u6f5c\u5728\u7684x_{t-1}\u8fdb\u884c\u91c7\u6837\uff0c\u5177\u4f53\u8fc7\u7a0b\u5982\u4e0b\u8868\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u6838\u5fc3\u601d\u60f3\u5c31\u662f\u5728\u4e2d\u95f4\u53d8\u91cf\\tilde x_0\u4e0a\u6dfb\u52a0\u5f15\u5bfc\u6765\u63a7\u5236DDPM\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u901a\u5e38\u662f\u5229\u7528\u68af\u5ea6\u6765\u9010\u6b65\u505a\u5f15\u5bfc\uff0c\u5f88\u7c7b\u4f3c\u68af\u5ea6\u4e0b\u964d\u6cd5\u4e2d\u7684\u64cd\u4f5c\uff0c\u6d41\u7a0b\u56fe\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p> \u5df2\u77e5\u7684\u9000\u5316\uff1a\u8fd9\u7c7b\u4efb\u52a1\u901a\u5e38\u662f\u9000\u5316\u51fd\u6570\u5df2\u77e5\u7684\u4efb\u52a1\uff0c\u4f8b\u5982\uff1a\u53bb\u566a\u548c\u8d85\u5206\u8fa8\u7387\u91cd\u6784\u53ef\u4ee5\u8868\u793a\u4e3ay=(x\\otimes k)\\downarrow_s\uff0c\u5047\u8bbe\u4f4e\u5206\u8fa8\u7387\u56fe\u50cfLR\u901a\u8fc7\u5982\u4e0b\u8fc7\u7a0b\u83b7\u5f97\uff1a\u9996\u5148\u5c06\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u4e0e\u9ad8\u65af\u6838\uff08\u6216\u70b9\u6269\u6563\u51fd\u6570\uff09k\u505a\u5377\u79ef\u5f97\u5230\u6a21\u7cca\u56fe\u50cfx\\otimes k\uff1b\u4e4b\u540e\u5bf9\u6a21\u7cca\u56fe\u50cf\u6267\u884c\u6bd4\u4f8b\u56e0\u5b50\u4e3as\u7684\u4e0b\u91c7\u6837\u64cd\u4f5c\\downarrow_s\u3002\u56fe\u50cf\u4fee\u590d\uff08inpainting\uff09\u7684\u76ee\u7684\u662f\u6062\u590d\u56fe\u50cf\u7684\u7f3a\u5931\u50cf\u7d20\uff0c\u76f8\u5e94\u7684\u9000\u5316\u53d8\u5316\u662f\u5c06\u539f\u59cb\u56fe\u50cf\u4e0e\u4e8c\u503c\u63a9\u6a21m\u76f8\u4e58\uff1a\\varphi(x)=x\\odot m\uff0c\u5176\u4e2d\\odot\u8868\u793a\u54c8\u8fbe\u739b\u79ef\u3002\u56fe\u50cf\u4e0a\u8272\u4efb\u52a1\u76ee\u7684\u662f\u5c06\u7070\u5ea6\u56fe\u50cfy\\in R^{H\\times W}\u8fd8\u539f\u4e3a\u5177\u6709RGB\u4e09\u8272\u901a\u9053\u7684\u5f69\u8272\u56fe\u50cfx\\in R^{3\\times H\\times W}\uff0c\u4e3a\u4e86\u4ece\u5f69\u8272\u56fe\u50cfx\u5f97\u5230y\uff0c\u9000\u5316\u53d8\u5316\\varphi\u53ea\u662f\u4fdd\u7559x\u4eae\u5ea6\u7684\u7070\u5ea6\u53d8\u6362\u3002</p> <p> \u672a\u77e5\u7684\u9000\u5316\uff1a\u5728\u771f\u5b9e\u4e16\u754c\u4e2d\uff0c\u5f88\u591a\u56fe\u50cf\u90fd\u7ecf\u5386\u975e\u5e38\u590d\u6742\u7684\u56fe\u50cf\u9000\u5316\u8fc7\u7a0b\uff0c\u5176\u4e2d\u9000\u5316\u6a21\u578b\u6216\u8005\u9000\u5316\u6a21\u578b\u7684\u53c2\u6570\u662f\u672a\u77e5\u7684\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u9700\u8981\u540c\u65f6\u4f30\u8ba1\u539f\u59cb\u56fe\u50cf\u548c\u9000\u5316\u6a21\u578b\u53c2\u6570\uff0c\u4f8b\u5982\u5f31\u5149\u589e\u5f3a\u4efb\u52a1\u548cHDR\u56fe\u50cf\u6062\u590d\u4efb\u52a1\u53ef\u4ee5\u89c6\u4e3a\u5177\u6709\u672a\u77e5\u9000\u5316\u6a21\u578b\u7684\u4efb\u52a1\u3002\u5728\u8fd9\u91cc\uff0c\u4f5c\u8005\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7b80\u5355\uff0c\u5e76\u4e14\u6709\u6548\u7684\u964d\u89e3\u6a21\u578b\u6765\u6a21\u62df\u590d\u6742\u7684\u964d\u89e3\uff1a $$ y=fx+M $$  \u5176\u4e2d\u5149\u56e0\u5b50f\u4e3a\u6807\u91cf\uff0c\u5149\u63a9\u7801\u4e3a\u4e0ex\u76f8\u540c\u7ef4\u6570\u7684\u5411\u91cf\uff0cf\u4e3a\u9000\u5316\u6a21\u578b\u7684\u672a\u77e5\u53c2\u6570\uff0c\u6211\u4eec\u4e4b\u6240\u4ee5\u53ef\u4ee5\u4f7f\u7528\u5355\u4e00\u7684\u9000\u5316\u6a21\u578b\u5c31\u662f\u56e0\u4e3a\u53ea\u8981f\u548cM\u5927\u5c0f\u76f8\u540c\uff0c\u4efb\u610f\u4e00\u5bf9\u635f\u574f\u56fe\u50cf\u548c\u5bf9\u5e94\u7684\u9ad8\u8d28\u91cf\u56fe\u50cf\u4e4b\u95f4\u7684\u53d8\u6362\u90fd\u53ef\u4ee5\u88abf\u548cM\u6355\u83b7\u3002\u5982\u679c\u4ed6\u6ca1\u6709\u76f8\u540c\u7684\u5927\u5c0f\uff0c\u5219\u53ef\u4ee5\u5148\u5c06x\u7684\u5927\u5c0f\u8c03\u6574\u4e3a\u4e0ey\u76f8\u540c\u7684\u5927\u5c0f\uff0c\u4e4b\u540e\u518d\u5e94\u7528\u8fd9\u4e2a\u53d8\u6362\u3002\u6ce8\u610f\uff1a\u8fd9\u79cd\u9000\u5316\u6a21\u578b\u901a\u5e38\u662f\u975e\u7ebf\u6027\u7684\uff0c\u56e0\u4e3af\u548cM\u7684\u6784\u5efa\u4f9d\u8d56\u4e8ex\u548cy\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u6211\u4eec\u9700\u8981\u5bf9\u6bcf\u4e2a\u5355\u72ec\u7684\u635f\u574f\u56fe\u50cf\u4f30\u8ba1f\u548cM\uff0c\u9996\u5148\u968f\u673a\u521d\u59cb\u5316\u5b83\uff0c\u4e4b\u540e\u5728DDPM\u7684\u63a8\u7406\u8fc7\u7a0b\u4e2d\u540c\u6b65\u4f18\u5316\u5b83\u4eec\uff08\u4e5f\u5c31\u662f\u4f18\u5316\u9884\u8bbe\u7684\u9000\u5316\u6a21\u578bD\uff09\uff0c\u8fdb\u4e00\u6b65\u4f30\u8ba1\u51faf\u548cM\u3002\uff08\u5982\u4e0a\u9762\u7684\u7b97\u6cd52\u6240\u793a\uff09</p>"},{"location":"img_enhance/DDPM/GDP/#_6","title":"\u6269\u5c55\u7248\u672c","text":"<p> \u591a\u56fe\u6307\u5bfc\uff1a\u90e8\u5206\u4efb\u52a1\u9700\u8981\u6839\u636e\u591a\u4e2a\u8f93\u5165\u6765\u91cd\u5efa\u6062\u590d\u56fe\u50cf\uff0c\u4f8b\u5982HDR\u4efb\u52a1\u4e2d\uff0c\u6839\u636e\u66dd\u5149\u5ea6\u4e3a\u9ad8\u3001\u4e2d\u3001\u4f4e\u7684\u4e09\u7ec4\u56fe\u50cf\u6765\u91cd\u5efa\u4e00\u5f20HDR\u56fe\u50cf\u3002\u5bf9\u6b64\uff0c\u4f5c\u8005\u989d\u5916\u6269\u5c55\u4e86\u4e4b\u524d\u7684\u5355\u56fe\u6307\u5bfc\u7b97\u6cd5\uff0c\u5728\u9006\u5411\u8fc7\u7a0b\u4e2d\uff0c\u6709\u4e09\u5f20\u635f\u574f\u7684\u56fe\u50cf\u6765\u5f15\u5bfc\u751f\u6210\uff0c\u4ece\u800c\u968f\u673a\u521d\u59cb\u5316\u548c\u4f18\u53163\u5f20LDR\u56fe\u50cf\u7684\u4e09\u5bf9\u76f2\u53c2\u6570\u3002</p> <p> <p></p> <p></p> <p> \u6062\u590d\u4efb\u610f\u5c3a\u5bf8\u56fe\u50cf\uff1a\u9884\u8bad\u7ec3\u7684\u6269\u6563\u6a21\u578b\u53ea\u80fd\u8f93\u51fa\u56fa\u5b9a\u5927\u5c0f\u7684\u56fe\u50cf\uff0c\u800c\u5404\u79cd\u56fe\u50cf\u6062\u590d\u4efb\u52a1\u7684\u56fe\u50cf\u5927\u5c0f\u662f\u4e0d\u540c\u7684\uff0c\u672c\u6587\u91c7\u7528\u57fa\u4e8epatch\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u5c06\u539f\u59cb\u56fe\u50cf\u5212\u5206\u6210\u540c\u6837\u5927\u5c0f\u7684patch\uff0c\u4e4b\u540e\u5206\u522b\u505a\u6062\u590d\u3002\u901a\u8fc7\u8fd9\u79cd\u57fa\u4e8e\u8865\u4e01\u7b56\u7565\u7684\u4f18\u70b9\u53ef\u4ee5\u5c06GDP\u7b97\u6cd5\u6269\u5c55\u5230\u6062\u590d\u4efb\u610f\u5206\u8fa8\u7387\u7684\u56fe\u50cf\uff0c\u4ece\u800c\u4fc3\u8fdbGDP\u7684\u901a\u7528\u6027\u3002</p> <p> <p></p> <p></p> <p>\u6ce8\uff1a\u4e00\u5f20\u56fe\u88c1\u526a\u6210\u4e0d\u540c\u7684patch\uff0c\u5206\u522b\u505a\u6062\u590d\uff0c\u8fd9\u4e5f\u662f\u5bfc\u81f4\u7b97\u6cd5\u63a8\u7406\u8fc7\u7a0b\u5f88\u6162\u7684\u4e00\u4e2a\u91cd\u8981\u539f\u56e0\u3002</p>"},{"location":"img_enhance/DDPM/GDP/#_7","title":"\u635f\u5931\u51fd\u6570","text":"<p>\u2003\u2003\u5728GDP\u4e2d\uff0c\u635f\u5931\u51fd\u6570\u4e3b\u8981\u7528\u4e8e\u4f18\u5316\u9000\u5316\u6a21\u578bD\uff0c\u540c\u65f6\u635f\u5931\u4ea7\u751f\u7684\u68af\u5ea6\u7528\u4e8e\u5bf9\u6269\u6563\u6a21\u578b\u7684\u63a8\u7406\u8fc7\u7a0b\u8fdb\u884c\u6307\u5bfc\uff08guidance\uff09\uff0c\u4e00\u65e6\u635f\u5931\u5f88\u5927\uff0c\u8bf4\u660e\u6269\u6563\u6a21\u578b\u63a8\u7406\u5f97\u5230\u7684\u56fe\u50cf\u5206\u5e03\u4e0ey\u5dee\u5f02\u6bd4\u8f83\u5927\uff0c\u9700\u8981\u8f83\u5927\u7684\u5f15\u5bfc\u6821\u6b63\u8fc7\u6765\uff0c\u56e0\u6b64\u53ef\u4ee5\u7528\u68af\u5ea6\u6765\u6307\u5bfc\u751f\u6210\u56fe\u50cf\u7684\u8fc1\u8dc3\u8fc7\u7a0b\u3002\u63a8\u7406\u5230\u6700\u540e\uff0c\u9000\u5316\u6a21\u578b\u53ef\u4ee5\u5f88\u597d\u5730\u6a21\u62df\u5f53\u524d\u8f93\u5165\u56fe\u50cf\u7684\u9000\u5316\u73b0\u8c61\uff0c\u540c\u65f6\u6269\u6563\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u53ef\u4ee5\u9010\u6b65\u751f\u6210y\u5bf9\u5e94\u7684\u6e05\u6670\u56fe\u50cf\u3002</p> <p>\u2003\u2003\u635f\u5931\u53ef\u4ee5\u4e3b\u8981\u5206\u4e3a\u91cd\u6784\u635f\u5931\u548c\u8d28\u91cf\u589e\u5f3a\u635f\u5931\u4e24\u5927\u90e8\u5206\uff0c\u6062\u590d\u635f\u5931\u7528\u4e8e\u6062\u590d\u6761\u4ef6\u4fe1\u53f7\u4e2d\u5305\u542b\u7684\u4fe1\u606f\uff0c\u8d28\u91cf\u589e\u5f3a\u635f\u5931\u7528\u4e8e\u63d0\u9ad8\u6700\u7ec8\u8f93\u51fa\u7684\u8d28\u91cf\u3002</p> <p> \u6062\u590d\u635f\u5931\uff1a\u6062\u590d\u635f\u5931\u53ef\u4ee5\u662fMSE\u3001SSIM\u635f\u5931\u3001\u611f\u77e5\u635f\u5931\u6216\u8005\u5176\u4ed6\u7528\u4e8e\u56fe\u50cf\u6062\u590d\u7684\u635f\u5931\uff0c\u5728\u8fd9\u91cc\uff0c\u4f5c\u8005\u53ea\u91c7\u7528MSE\u635f\u5931\u4f5c\u4e3a\u6062\u590d\u635f\u5931\u3002</p> <p> \u8d28\u91cf\u589e\u5f3a\u635f\u5931\uff1a1\uff09\u66dd\u5149\u63a7\u5236\u635f\u5931\uff0c\u7528\u4e8e\u63a7\u5236\u5fae\u5149\u56fe\u50cf\u589e\u5f3a\u7684\u66dd\u5149\u6c34\u5e73\uff0c\u63d0\u9ad8GDP\u7684\u901a\u7528\u6027\uff1a $$ L_{exp}=\\frac1U\\sum^U_{k=1}|R_k-E| $$  \u5176\u4e2dU\u8868\u793a\u5927\u5c0f\u4e3a8\\times8\u7684\u4e0d\u91cd\u53e0\u533a\u57df\u7684\u4e2a\u6570\uff0cR\u4e3a\u91cd\u6784\u56fe\u50cf\u4e2d\u5c40\u90e8\u533a\u57df\u7684\u5e73\u5747\u5f3a\u5ea6\u6570\u503c\uff08\u4e5f\u5c31\u662f\u5c40\u90e8\u7684\u5747\u503c\uff0c\u7528\u5e73\u5747\u6c60\u5316\u5b9e\u73b0\uff09\uff0cE\u8bbe\u7f6e\u4e3aRGB\u8272\u5f69\u7a7a\u95f4\u4e2d\u7684\u7070\u5ea6\u7ea7\uff0c\u5b9e\u9a8c\u4e2d\u53ef\u4ee5\u901a\u8fc7\u8c03\u8282E\u6765\u63a7\u5236\u4eae\u5ea6\u3002</p> <p>\u2003\u20032\uff09\u989c\u8272\u6052\u5b9a\u635f\u5931\uff1a\u5229\u7528\u989c\u8272\u6052\u5b9a\u6027\u635f\u5931\u6765\u6821\u6b63\u6062\u590d\u56fe\u50cf\u4e2d\u6f5c\u5728\u7684\u989c\u8272\u504f\u5dee\uff0c\u5e76\u4e14\u5728\u7740\u8272\u4efb\u52a1\u4e2d\u8fde\u63a5\u4e09\u4e2a\u8c03\u6574\u901a\u9053\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u8868\u793a\u4e3a\uff1a $$ L_{col}=\\sum_{\\forall(m,n)\\in\\epsilon}(Y^m-Y^n)^2,\\epsilon=\\{(R,G),(R,B),(G,B)\\} $$  \u5176\u4e2dY^m\u8868\u793a\u6062\u590d\u56fe\u50cf\u4e2dm\u4e2a\u901a\u9053\u7684\u5e73\u5747\u5f3a\u5ea6\u503c\uff0c(m,n)\u4e3a\u4e00\u5bf9\u901a\u9053\u3002</p> <p>\u2003\u20033\uff09\u7167\u660e\u5e73\u6ed1\u635f\u5931\uff1a\u4e3a\u4e86\u4fdd\u6301\u6240\u4f18\u5316\u7684\u5149\u7167\u63a9\u6a21M\u4e2d\u76f8\u90bb\u50cf\u7d20\u4e4b\u95f4\u7684\u5355\u8c03\u5173\u7cfb\uff0c\u5bf9\u6bcf\u4e2a\u5149\u7167\u65b9\u5deeM\u4f7f\u7528\u4e00\u4e2a\u7167\u660e\u5e73\u6ed1\u635f\u5931\uff1a $$ L_{tv_M}=\\frac1N\\sum^N_{n=1}\\sum_{c\\in\\zeta}(|\\nabla_hM^c_n|^2+|\\nabla_vM^c_n|^2),\\zeta=\\{R,G,B\\} $$  \u5176\u4e2dN\u4e3a\u8fed\u4ee3\u6b21\u6570\uff0c\\nabla_h\u548c\\nabla_v\u5206\u522b\u8868\u793a\u6c34\u5e73\u548c\u5782\u76f4\u68af\u5ea6\u64cd\u4f5c\u3002</p> <p>\u2003\u2003\u635f\u5931\u5e76\u4e0d\u4e00\u5b9a\u662f\u901a\u7528\u7684\uff0c\u9700\u8981\u6839\u636e\u5177\u4f53\u4efb\u52a1\u505a\u7b5b\u9009\uff0c\u5177\u4f53\u800c\u8a00\uff0c\u56fe\u50cf\u7740\u8272\u4efb\u52a1\u5229\u7528\u989c\u8272\u6052\u5b9a\u635f\u5931\u6765\u83b7\u5f97\u66f4\u81ea\u7136\u7684\u989c\u8272\uff0c\u540c\u65f6\uff0c\u5f31\u5149\u589e\u5f3a\u9700\u8981\u5931\u53bb\u8272\u6052\u6027\uff08\u4e5f\u5c31\u662f\u589e\u5f3a\u524d\u540e\u7684\u989c\u8272\u4e0d\u4e00\u81f4\uff09\uff1b\u6b64\u5916\uff0c\u5f31\u5149\u589e\u5f3a\u4efb\u52a1\u5229\u7528\u7167\u660e\u5e73\u6ed1\u5ea6\u635f\u5931\u4f7f\u4f30\u8ba1\u7684\u5149\u63a9\u6a21\u66f4\u5e73\u6ed1\uff0c\u66dd\u5149\u63a7\u5236\u635f\u5931\u4f7f\u6211\u4eec\u80fd\u591f\u624b\u52a8\u63a7\u5236\u6062\u590d\u56fe\u50cf\u7684\u4eae\u5ea6\u3002</p> <p>\u521d\u6b65\u5b8c\u7a3f\u4e8e\uff1a2023\u5e747\u670816\u65e5</p> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u6307\u6b63\u3002</p>"},{"location":"img_enhance/HDR/HDR-Transformer/","title":"HDR-Transformer","text":""},{"location":"img_enhance/HDR/HDR-Transformer/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aEuropean Conference on Computer Vision 2022(ECCV, 2022)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://arxiv.org/pdf/2208.05114v1.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/liuzhen03/HDR-Transformer-PyTorch</p> <p>\u9488\u5bf9\u9886\u57df\uff1aHDR\u6210\u50cf</p>"},{"location":"img_enhance/HDR/HDR-Transformer/#_2","title":"\u4e3b\u8981\u601d\u60f3","text":"<p>\u2003\u2003\u591a\u5e27\u9ad8\u52a8\u6001\u8303\u56f4\u6210\u50cf\uff08High Dynamic Range Imaging, HDRI/HDR\uff09\u65e8\u5728\u901a\u8fc7\u5408\u5e76\u591a\u5e45\u4e0d\u540c\u66dd\u5149\u7a0b\u5ea6\u4e0b\u7684\u4f4e\u52a8\u6001\u8303\u56f4\u56fe\u50cf\uff0c\u751f\u6210\u5177\u6709\u66f4\u5bbd\u52a8\u6001\u8303\u56f4\u548c\u66f4\u903c\u771f\u7ec6\u8282\u7684\u56fe\u50cf\u3002\u5982\u679c\u8fd9\u4e9b\u4f4e\u52a8\u6001\u8303\u56f4\u56fe\u50cf\u5b8c\u5168\u5bf9\u9f50\uff0c\u5219\u53ef\u4ee5\u5f88\u597d\u5730\u878d\u5408\u4e3aHDR\u56fe\u50cf\uff0c\u4f46\u662f\uff0c\u5b9e\u9645\u62cd\u6444\u5230\u7684\u56fe\u50cf\u5bb9\u6613\u53d7\u5230\u76f8\u673a\u3001\u7269\u4f53\u8fd0\u52a8\u7684\u5e72\u6270\uff0c\u4e09\u5f20\u4f4e\u52a8\u6001\u8303\u56f4\u56fe\u50cf\u5f80\u5f80\u4e0d\u80fd\u5f88\u597d\u5730\u5f97\u5230\u5bf9\u9f50\uff0c\u76f4\u63a5\u5bf9\u4e09\u56fe\u50cf\u505a\u878d\u5408\u7684\u8bdd\uff0c\u6240\u751f\u6210\u7684\u56fe\u50cf\u5bb9\u6613\u4ea7\u751f\u4f2a\u5f71\u3001\u91cd\u5f71\uff0c\u4f8b\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u73b0\u8c61\uff0c\u4f20\u7edf\u7684\u7b97\u6cd5\u901a\u5e38\u5206\u4e3a\u4e24\u7c7b\uff1a\u5728\u56fe\u50cf\u878d\u5408\u524d\u5bf9\u9f50\uff08align\uff09\u56fe\u50cf\u6216\u8005\u62d2\u7edd\uff08reject\uff09\u4e0d\u5bf9\u9f50\u7684\u50cf\u7d20\u6765\u53bb\u9664\u91cd\u5f71\uff0c\u4f46\u7cbe\u786e\u5730\u5bf9\u9f50\u56fe\u50cf\u6216\u8005\u7cbe\u786e\u5730\u5b9a\u4f4d\u4e0d\u5bf9\u9f50\u7684\u50cf\u7d20\u5f80\u5f80\u96be\u4ee5\u5b9e\u73b0\uff0c\u6240\u751f\u6210\u7684HDR\u56fe\u50cf\u6548\u679c\u5e76\u4e0d\u597d\uff0c\u56e0\u6b64\u73b0\u5728\u5e38\u5e38\u4ee5\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u6765\u8bad\u7ec3CNN\uff0c\u5229\u7528CNN\u6765\u5b9e\u73b0\u56fe\u50cf\u7684\u878d\u5408\u3002</p> <p>\u2003\u2003\u57fa\u4e8eCNN\u7684\u53bb\u91cd\u5f71\u65b9\u6cd5\u4e3b\u8981\u5206\u4e3a\u4e24\u7c7b\uff1a\u2460\u5229\u7528\u5355\u5e94\u6027\u6216\u5149\u6d41\u6cd5\u5bf9LDR\u56fe\u50cf\u8fdb\u884c\u9884\u5bf9\u9f50\uff1b\u2461\u8bbe\u8ba1\u7aef\u5230\u7aef\u7684\u9690\u5f0f\u5bf9\u9f50\u6a21\u5757\u6216\u8005\u65b0\u9896\u7684\u5b66\u4e60\u7b56\u7565\u6765\u5904\u7406\u91cd\u5f71\u3002\u4f46\u662f\u7531\u4e8e\u5377\u79ef\u5c40\u90e8\u6027\u7684\u9650\u5236\uff0c\u6a21\u578b\u96be\u4ee5\u5efa\u7acb\u8fdc\u7a0b\u4f9d\u8d56\uff08\u9700\u8981\u5806\u53e0\u8f83\u6df1\u7684\u5377\u79ef\u5c42\u6765\u5b9e\u73b0\u63d0\u9ad8\u611f\u53d7\u91ce\u7684\u76ee\u7684\uff09\uff0c\u5982\u679c\u56fe\u4e2d\u7269\u4f53\u7684\u8fd0\u52a8\u8303\u56f4\u8fc7\u5927\uff0c\u5219\u5148\u524d\u57fa\u4e8eCNN\u7684\u65b9\u6cd5\u4ecd\u5bb9\u6613\u4ea7\u751f\u91cd\u5f71\uff1b\u540c\u65f6\u7531\u4e8e\u5728\u6574\u5e45\u56fe\u50cf\u4e2d\u5171\u4eab\u5377\u79ef\u6838\uff0c\u56e0\u6b64\u5377\u79ef\u662f\u5185\u5bb9\u65e0\u5173\u7684\u8fd0\u7b97\uff08content-independment\uff09\uff0c\u8fd9\u4e00\u7279\u6027\u5bfc\u81f4\u5377\u79ef\u8fd0\u7b97\u5ffd\u7565\u4e86\u4e0d\u540c\u56fe\u50cf\u533a\u57df\u7684\u957f\u8ddd\u79bb\u5f3a\u5ea6\u53d8\u5316\uff0c\u4e5f\u5c31\u662f\u5377\u79ef\u8fd0\u7b97\u4f1a\u5e73\u7b49\u5730\u5bf9\u5f85\u56fe\u50cf\u4e2d\u7684\u6240\u6709\u6570\u636e\u3002\uff08\u5f15\u5165\u6ce8\u610f\u529b\u673a\u5236\u53ef\u4ee5\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff09</p> <p>\u2003\u2003\u5bf9\u4e8e\u6a21\u578b\u7684\u957f\u8ddd\u79bb\u5efa\u6a21\u80fd\u529b\uff0c\u4e00\u4e2a\u5f88\u597d\u5730\u7b56\u7565\u5c31\u662f\u5229\u7528transformer\u7ed3\u6784\uff0c\u4f8b\u5982ViT\u7b97\u6cd5\u3002\u7136\u800c\uff0c\u672c\u6587\u4f5c\u8005\u53d1\u73b0transformer\u7ed3\u6784\u5e76\u4e0d\u80fd\u76f4\u63a5\u5e94\u7528\u4e8eHDR\u4efb\u52a1\u4e2d\uff0c\u4e3b\u8981\u6709\u4e24\u4e2a\u539f\u56e0\uff1a\u2460transformer\u7f3a\u4e4fCNN\u4e2d\u5f52\u7eb3\u504f\u5dee\u7684\u80fd\u529b\uff08inductive biases\uff09\uff0c\u56e0\u6b64\u5728\u6570\u636e\u91cf\u4e0d\u8db3\u7684\u60c5\u51b5\u4e0b\u8bad\u7ec3\u65f6\u6cdb\u5316\u80fd\u529b\u8f83\u5dee\uff0c\u6a21\u578b\u6027\u80fd\u4e0d\u9ad8\uff1b\u2461\u5e27\u5185\u548c\u5e27\u95f4\u76f8\u90bb\u50cf\u7d20\u4e4b\u95f4\u7684\u5173\u7cfb\u4e5f\u5bf9\u6062\u590d\u56fe\u50cf\u7684\u5c40\u90e8\u7ec6\u8282\u81f3\u5173\u91cd\u8981\uff0c\u800c\u7eaftransformer\u7ed3\u6784\u96be\u4ee5\u63d0\u53d6\u5c40\u90e8\u4e0a\u4e0b\u6587\u4e4b\u524d\u7684\u5173\u7cfb\u3002</p> <p>\u6ce8\uff1a\u5728HDR\u4efb\u52a1\u4e2d\u6536\u96c6\u5927\u91cf\u771f\u5b9e\u6807\u8bb0\u7684\u6837\u672c\u6210\u672c\u8fc7\u9ad8\uff0c\u56e0\u6b64\u6570\u636e\u96c6\u5f80\u5f80\u6709\u9650\u3002</p> <p>\u2003\u2003\u5bf9\u6b64\uff0c\u672c\u6587\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u4e0a\u4e0b\u6587\u611f\u77e5\u7684ViT\uff08Context-Aware Vision Transformer, CA-ViT\uff09\uff0c\u901a\u8fc7\u53cc\u5206\u652f\u67b6\u6784\u6765\u540c\u65f6\u6355\u83b7\u5168\u5c40\u548c\u5c40\u90e8\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u4e5f\u5c31\u662f\u540c\u65f6\u5b9e\u73b0\u5168\u5c40\u548c\u5c40\u90e8\u7684\u5efa\u6a21\u3002\u5bf9\u4e8e\u5168\u5c40\u5206\u652f\uff0c\u4f5c\u8005\u4f7f\u7528\u57fa\u4e8e\u7a97\u53e3\u7684\u591a\u5934transformer\u7f16\u7801\u5668\u6765\u6355\u8fdc\u7a0b\u4e0a\u4e0b\u6587\u5173\u7cfb\uff08\u5373Swin transformer\uff09\uff1b\u5bf9\u4e8e\u5c40\u90e8\u5206\u652f\uff0c\u4f5c\u8005\u8bbe\u8ba1\u4e86\u5c40\u90e8\u4e0a\u4e0b\u6587\u63d0\u53d6\u5668\uff08local context extractor, LCE\uff09\uff0c\u901a\u8fc7\u5377\u79ef\u5757\u6765\u63d0\u53d6\u5c40\u90e8\u7279\u5f81\u6620\u5c04\uff0c\u5e76\u4e14\u901a\u8fc7\u901a\u9053\u6ce8\u610f\u529b\u673a\u5236\u5728\u591a\u4e2a\u5e27\u7279\u5f81\u4e4b\u95f4\u9009\u62e9\u6709\u7528\u7684\u7279\u5f81\uff0c\u6291\u5236\u65e0\u7528\u7684\u7279\u5f81\uff0c\u56e0\u6b64\uff0cCA-ViT\u7ed3\u6784\u53ef\u4ee5\u4f7f\u5168\u5c40\u548c\u5c40\u90e8\u4ee5\u4e92\u8865\u7684\u65b9\u5f0f\u53d1\u6325\u4f5c\u7528\u3002\u57fa\u4e8eCA-ViT\u7ed3\u6784\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u7528\u4e8eHDR\u6210\u50cf\u7684transformer\u7ed3\u6784\uff08HDR-Transformer\uff09\u3002</p> <p>\u2003\u2003\u5bf9\u4e8eHDR-Transformer\uff0c\u4e3b\u8981\u5305\u62ec\u4e24\u4e2a\u6a21\u5757\uff1a\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u548cHDR\u6062\u590d\u7f51\u7edc\uff0c\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u5229\u7528\u5377\u79ef\u8fd0\u7b97\u548c\u7a7a\u95f4\u6ce8\u610f\u529b\u6a21\u5757\u6765\u63d0\u53d6\u6d45\u5c42\u7279\u5f81\uff0c\u5e76\u4e14\u8fdb\u884c\u7c97\u878d\u5408\uff0c\u6709\u52a9\u4e8e\u7a33\u5b9atransformer\u7684\u8bad\u7ec3\u548c\u6291\u5236\u56fe\u50cf\u4e2d\u4e0d\u5bf9\u9f50\u7684\u50cf\u7d20\u3002HDR\u91cd\u5efa\u6a21\u5757\u4ee5CA-ViT\u4e3a\u57fa\u672c\u7ec4\u4ef6\uff0c\u4ece\u5168\u5c40\u548c\u5c40\u90e8\u4e24\u4e2a\u89d2\u5ea6\u5bf9\u56fe\u50cf\u5efa\u6a21\uff0c\u6709\u52a9\u4e8e\u91cd\u5efa\u9ad8\u8d28\u91cf\u7684HDR\u56fe\u50cf\uff0c\u540c\u65f6\u65e0\u9700\u5806\u53e0\u975e\u5e38\u6df1\u7684\u5377\u79ef\u5757\u3002</p>"},{"location":"img_enhance/HDR/HDR-Transformer/#_3","title":"\u65b9\u6cd5","text":""},{"location":"img_enhance/HDR/HDR-Transformer/#ca-vit","title":"CA-ViT","text":"<p>\u2003\u2003\u5177\u4f53\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u4e3b\u8981\u5305\u62ec\u4e00\u4e2a\u5168\u5c40Swin transformer\u7f16\u7801\u5668\u5206\u652f\u548c\u4e00\u4e2a\u5c40\u90e8LCE\u5206\u652f\uff1a</p> <p> <p></p> <p></p> <p>\u5176\u4e2dLCE\u5206\u652f\u5c31\u662f\u4e00\u5c42\u6807\u51c6\u5316\u5c42\u52a0\u4e0a\u901a\u9053\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5bf9\u4e8e\u4e24\u4e2a\u5206\u652f\u8f93\u51fa\u7684\u7279\u5f81\uff0c\u4f5c\u8005\u91c7\u7528\u5143\u7d20\u52a0\u6cd5\u6765\u5408\u5e76\u4e0a\u4e0b\u6587\uff0c\u51cf\u5c11\u9644\u52a0\u53c2\u6570\u7684\u5f71\u54cd\u3002</p>"},{"location":"img_enhance/HDR/HDR-Transformer/#_4","title":"\u7f51\u7edc\u7ed3\u6784","text":"<p>\u2003\u2003\u7f51\u7edc\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u603b\u4f53\u5305\u62ec\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\uff08a\uff09\u548cHDR\u6062\u590d\u7f51\u7edc\uff08b\uff09\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u4e3a\u4e86\u66f4\u597d\u5730\u5229\u7528\u8f93\u5165\u6570\u636e\uff0c\u9996\u5148\u4f9d\u6b21\u5229\u7528\u4f3d\u9a6c\u6821\u6b63\uff0c\u5c06\u4e09\u5f20LDR\u56fe\u50cfI_i\u6620\u5c04\u5230HDR\u57df\uff0c\u751f\u6210\u4f3d\u9a6c\u6821\u6b63\u56fe\u50cf\\hat I_i\uff1a $$ \\hat I_i=\\frac{(I_i)^\\gamma}{t_i},i=1,2,3 $$  \u4e4b\u540e\u5c06I_i\u4e0e\\hat I_i\u5408\u5e76\uff0c\u540c\u65f6\u8f93\u5165\u5230\u7f51\u7edc\u4e2d\u3002</p> <p>\u7279\u5f81\u63d0\u53d6\u7f51\u7edc</p> <p>\u2003\u2003\u5c06\u66dd\u5149\u5ea6\u4e3a\u201c\u4e2d\u201d\u7684\u56fe\u50cf\u89c6\u4e3a\u201c\u53c2\u8003\u56fe\u50cf\u201d\uff08reference feature\uff09\uff0c\u9996\u5148\u5c06\u4e09\u7ec4\u56fe\u50cf\u6570\u636e\u4f9d\u6b21\u7ecf\u8fc7\u5377\u79ef\u5c42\uff0c\u5f97\u5230\u6d45\u5c42\u7279\u5f81f_i\uff0c\u4e4b\u540e\u5c06\u53c2\u8003\u56fe\u50cf\u7684\u7279\u5f81f_2\u4f9d\u6b21\u4e0e\u5176\u4ed6\u975e\u53c2\u8003\u56fe\u50cf\u7279\u5f81f_1\u4e0ef_3\u5408\u5e76\uff0c\u7528\u4e8e\u8ba1\u7b97\u7a7a\u95f4\u6ce8\u610f\u529b\u56fem_i\uff1a $$ m_i=A(f_i,f_2),i=1,3 $$  \u4e4b\u540e\u518d\u5c06\u6ce8\u610f\u529b\u56fe\u53cd\u4e58\u56de\u975e\u53c2\u8003\u7279\u5f81\uff0c\u5f97\u5230\u6ce8\u610f\u529b\u7279\u5f81\\hat f_i\uff1a $$ f'_i=f_i\\odot m_i,i=1,3 $$  \u5176\u4e2d\uff0c\\odot\u8868\u793a\u9010\u5143\u7d20\u76f8\u4e58\uff0c\u7a7a\u95f4\u6ce8\u610f\u529b\u53ef\u4ee5\u6709\u6548\u5730\u51cf\u5c11\u7531\u524d\u666f\u7269\u4f53\u8fd0\u52a8\u5f15\u8d77\u7684\u4e0d\u5e0c\u671b\u5173\u6ce8\u7684\u5185\u5bb9\uff0c\u6291\u5236\u65e0\u5173\u5185\u5bb9\u7684\u91cd\u8981\u6027\u3002\u6ce8\u610f\u529b\u6a21\u5757\u4e2d\u7684\u5377\u79ef\u5c42\u4e5f\u53ef\u4ee5\u589e\u52a0\u540e\u7eedtransformer\u5c42\u7684\u5f52\u7eb3\u504f\u7f6e\u3002</p> <p>HDR\u6062\u590d\u7f51\u7edc</p> <p>\u2003\u2003\u8be5\u7f51\u7edc\u4e3b\u8981\u7531\u591a\u4e2a\u4e0a\u4e0b\u6587\u611f\u77e5Transformer\u6a21\u5757\u6784\u6210\uff08Context-Aware Transformer Blocks, CTB\uff09\uff0c\u6bcf\u4e2a\u6a21\u5757\u7531\u591a\u4e2aCA-ViT\u3001\u7a7a\u6d1e\u5377\u79ef\u5c42\uff08dilated convolution layer\uff09\u4ee5\u53ca\u4e00\u4e2a\u6b8b\u5dee\u8fde\u63a5\u7ec4\u6210\uff0c\u5176\u4e2d\u7a7a\u6d1e\u5377\u79ef\u7528\u4e8e\u63d0\u9ad8\u4e0a\u4e0b\u6587\u8303\u56f4\u7684\u611f\u53d7\u91ce\uff0c\u6b8b\u5dee\u8fde\u63a5\u7528\u4e8e\u7a33\u5b9a\u6a21\u578b\u7684\u4f18\u5316\u8fc7\u7a0b\u3002</p> <p>\u6ce8\uff1a</p> <ul> <li> <p>\u8f93\u5165\u7279\u5f81\u7531f_1',f_2,f_3'\u5408\u5e76\u6784\u6210\uff0c\u7ecf\u8fc7\u4e00\u5c42\u5377\u79ef\u5c42\u538b\u7f29\u901a\u9053\u6570\u3002</p> </li> <li> <p>\u65e9\u671f\u7684\u5377\u79ef\u5c42\u6709\u52a9\u4e8e\u7a33\u5b9aViT\u7684\u8bad\u7ec3\u8fc7\u7a0b\uff08\u5373\u5728ViT\u7ed3\u6784\u524d\u9762\u5f15\u5165\u5377\u79ef\u5c42\uff09\uff1aThe early convolution layers help to stabilize the training process of Vision Transformers\uff08Xiao, T., Singh, M., Mintun, E., Darrell, T., Doll\u00b4ar, P., Girshick, R.: Early convolutions help transformers see better. arXiv preprint arXiv:2106.14881 (2021)\uff09</p> </li> </ul>"},{"location":"img_enhance/HDR/HDR-Transformer/#_5","title":"\u635f\u5931\u51fd\u6570","text":"<p>\u2003\u2003\u7531\u4e8eHDR\u56fe\u50cf\u901a\u5e38\u662f\u5728\u8272\u8c03\u6620\u5c04\u540e\u67e5\u770b\u7684\uff0c\u56e0\u6b64\u5728\u8fd9\u91cc\u4f7f\u7528\\mu-law\u51fd\u6570\u8ba1\u7b97\u8272\u8c03\u6620\u5c04\u57df\u4e2d\u7684\u635f\u5931\uff1a $$ \\mathcal T(x)=\\frac{\\log(1+\\mu x)}{\\log(1+\\mu)} $$  \u5176\u4e2d\\mu\u8bbe\u7f6e\u4e3a5000\uff0c\\mathcal T(x)\u662f\u8272\u8c03\u6620\u5c04\u7684HDR\u56fe\u50cf\uff0c\u5728\u8fd9\u91cc\uff0c\u672c\u6587\u540c\u65f6\u4f7f\u7528L1\u635f\u5931L_r\u548c\u611f\u77e5\u635f\u5931L_p\u6765\u4f18\u5316\u7f51\u7edc\u53c2\u6570\uff1a $$ L=L_r+\\lambda_p L_p $$  \u5176\u4e2d\\lambda_p\u8bbe\u4e3a0.01\uff0c\u611f\u77e5\u635f\u5931\u91c7\u7528VGG16\u8f93\u51fa\u7684\u7279\u5f81\uff0c\u63d0\u53d6Conv12\uff0cConv22\uff0cConv33\uff0cConv43\uff08Conv12\u8868\u793a\u7b2c\u4e00\u9636\u6bb5\u7684\u7b2c\u4e8c\u5c42\u5377\u79ef\u751f\u6210\u7684\u6fc0\u6d3b\u7279\u5f81\uff0c\u9636\u6bb5\u4ece1\u5f00\u59cb\uff0c\u6bcf\u7ecf\u8fc7\u4e00\u6b21\u6700\u5927\u6c60\u5316\u9636\u6bb5\u6570\u52a01\uff09\u3002</p>"},{"location":"img_enhance/HDR/HDR-Transformer/#_6","title":"\u5b9e\u9a8c","text":"<p>\u6570\u636e\u96c6\uff1aKalantari</p> <p>\u8bad\u7ec3\u9636\u6bb5\uff1a\u968f\u673a\u88c1\u526a128*128\u7684\u56fe\u7247\u6765\u505a\u8bad\u7ec3\uff1b</p> <p>\u6d4b\u8bd5\u9636\u6bb5\uff1a\u5bf9\u4e8e\u6bcf\u5f20\u56fe\u7247\uff0c\u5148\u4ee5\u7f51\u683c\u7684\u5f62\u5f0f\u62c6\u5206\u6210256*256\u7684patch\uff0c\u7136\u540e\u904d\u5386\u6240\u6709\u7684patch\u6765\u505a\u6d4b\u8bd5\uff0c\u5bf9\u4e8e\u4e00\u5f20\u56fe\u7684\u6240\u6709patch\u53d6\u5747\u503c\uff0c\u5f97\u5230\u6bcf\u5f20\u56fe\u7684\u6307\u6807\u6570\u636e\uff1b</p>"},{"location":"img_enhance/HDR/HDR-Transformer/#_7","title":"\u7cbe\u5ea6\u5bf9\u6bd4","text":"<p> <p></p> <p></p>"},{"location":"img_enhance/HDR/HDR-Transformer/#_8","title":"\u603b\u7ed3","text":"<p>\u2003\u2003\u5728\u672c\u6587\u4e2d\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u5206\u652f\u4e0a\u4e0b\u6587\u611f\u77e5Transformer\uff0c\u901a\u8fc7\u52a0\u5165\u5c40\u90e8\u7279\u5f81\u63d0\u53d6\u5668\uff08\u5373\u5f15\u5165\u5377\u79ef\u64cd\u4f5c\uff09\u6765\u514b\u670d\u4f20\u7edfViT\u5728\u5c40\u90e8\u5efa\u6a21\u4e0a\u7684\u4e0d\u8db3\uff0c\u6269\u5c55\u4e86\u6807\u51c6\u7684ViT\u6a21\u5757\uff0c\u53ef\u4ee5\u5b9e\u73b0\u5168\u5c40\u548c\u5c40\u90e8\u4e0a\u4e0b\u6587\u7684\u540c\u65f6\u5efa\u6a21\u3002\u6b64\u5916\uff0c\u57fa\u4e8e\u6240\u8bbe\u8ba1\u7684CA-ViT\u6a21\u5757\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u7528\u4e8eHDR\u6210\u50cf\u7684HDR-Transformer\u7f51\u7edc\uff0c\u901a\u8fc7\u7ed3\u5408Transformer\u548cCNN\u7684\u4f18\u70b9\uff0c\u6765\u6709\u6548\u5730\u7f13\u89e3HDR\u6210\u50cf\u8fc7\u7a0b\u4e2d\u5bb9\u6613\u4ea7\u751f\u91cd\u5f71\u7684\u95ee\u9898\u3002</p>"},{"location":"img_enhance/HDR/HDR-Transformer/#_9","title":"\u9644\uff1a\u6e90\u7801","text":"<p>CA-ViT</p> <pre><code>import torch\nfrom torch import nn\nfrom timm.models.layers import DropPath, to_2tuple, trunc_normal_\n\n\nclass Mlp(nn.Module):\n    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n        super().__init__()\n        out_features = out_features or in_features\n        hidden_features = hidden_features or in_features\n        self.fc1 = nn.Linear(in_features, hidden_features)\n        self.act = act_layer()\n        self.fc2 = nn.Linear(hidden_features, out_features)\n        self.drop = nn.Dropout(drop)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.act(x)\n        x = self.drop(x)\n        x = self.fc2(x)\n        x = self.drop(x)\n        return x\n\n\ndef window_partition(x, window_size):\n    B, H, W, C = x.shape\n    x = x.view(B, H // window_size, window_size, W // window_size, window_size, C)\n    windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, window_size, window_size, C)\n    return windows\n\n\ndef window_reverse(windows, window_size, H, W):\n    B = int(windows.shape[0] / (H * W / window_size / window_size))\n    x = windows.view(B, H // window_size, W // window_size, window_size, window_size, -1)\n    x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(B, H, W, -1)\n    return x\n\n\nclass WindowAttention(nn.Module):\n\n    def __init__(self, dim, window_size, num_heads, qkv_bias=True, qk_scale=None, attn_drop=0., proj_drop=0.):\n\n        super().__init__()\n        self.dim = dim\n        self.window_size = window_size  # Wh, Ww\n        self.num_heads = num_heads\n        head_dim = dim // num_heads\n        self.scale = qk_scale or head_dim ** -0.5\n\n        # define a parameter table of relative position bias\n        self.relative_position_bias_table = nn.Parameter(\n            torch.zeros((2 * window_size[0] - 1) * (2 * window_size[1] - 1), num_heads))  # 2*Wh-1 * 2*Ww-1, nH\n\n        # get pair-wise relative position index for each token inside the window\n        coords_h = torch.arange(self.window_size[0])\n        coords_w = torch.arange(self.window_size[1])\n        coords = torch.stack(torch.meshgrid([coords_h, coords_w]))  # 2, Wh, Ww\n        coords_flatten = torch.flatten(coords, 1)  # 2, Wh*Ww\n        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]  # 2, Wh*Ww, Wh*Ww\n        relative_coords = relative_coords.permute(1, 2, 0).contiguous()  # Wh*Ww, Wh*Ww, 2\n        relative_coords[:, :, 0] += self.window_size[0] - 1  # shift to start from 0\n        relative_coords[:, :, 1] += self.window_size[1] - 1\n        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n        relative_position_index = relative_coords.sum(-1)  # Wh*Ww, Wh*Ww\n        self.register_buffer(\"relative_position_index\", relative_position_index)\n\n        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n        self.attn_drop = nn.Dropout(attn_drop)\n        self.proj = nn.Linear(dim, dim)\n\n        self.proj_drop = nn.Dropout(proj_drop)\n\n        trunc_normal_(self.relative_position_bias_table, std=.02)\n        self.softmax = nn.Softmax(dim=-1)\n\n    def forward(self, x, mask=None):\n\n        B_, N, C = x.shape\n        qkv = self.qkv(x).reshape(B_, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n        q, k, v = qkv[0], qkv[1], qkv[2]\n\n        q = q * self.scale\n        attn = (q @ k.transpose(-2, -1))\n\n        relative_position_bias = self.relative_position_bias_table[self.relative_position_index.view(-1)].view(\n            self.window_size[0] * self.window_size[1], self.window_size[0] * self.window_size[1], -1)  # Wh*Ww,Wh*Ww,nH\n        relative_position_bias = relative_position_bias.permute(2, 0, 1).contiguous()  # nH, Wh*Ww, Wh*Ww\n        attn = attn + relative_position_bias.unsqueeze(0)\n\n        if mask is not None:\n            nW = mask.shape[0]\n            attn = attn.view(B_ // nW, nW, self.num_heads, N, N) + mask.unsqueeze(1).unsqueeze(0)\n            attn = attn.view(-1, self.num_heads, N, N)\n            attn = self.softmax(attn)\n        else:\n            attn = self.softmax(attn)\n\n        attn = self.attn_drop(attn)\n\n        x = (attn @ v).transpose(1, 2).reshape(B_, N, C)\n        x = self.proj(x)\n        x = self.proj_drop(x)\n        return x\n\n    def extra_repr(self) -&gt; str:\n        return f'dim={self.dim}, window_size={self.window_size}, num_heads={self.num_heads}'\n\n    def flops(self, N):\n        # calculate flops for 1 window with token length of N\n        flops = 0\n        # qkv = self.qkv(x)\n        flops += N * self.dim * 3 * self.dim\n        # attn = (q @ k.transpose(-2, -1))\n        flops += self.num_heads * N * (self.dim // self.num_heads) * N\n        #  x = (attn @ v)\n        flops += self.num_heads * N * N * (self.dim // self.num_heads)\n        # x = self.proj(x)\n        flops += N * self.dim * self.dim\n        return flops\n\n\nclass LocalContextExtractor(nn.Module):\n\n    def __init__(self, dim, reduction=8):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(dim, dim // reduction, kernel_size=1, padding=0, bias=True),\n            nn.Conv2d(dim // reduction, dim // reduction, kernel_size=3, padding=1, bias=True),\n            nn.Conv2d(dim // reduction, dim, kernel_size=1, padding=0, bias=True),\n            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n        )\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Sequential(\n            nn.Linear(dim, dim // reduction, bias=False),\n            nn.ReLU(),\n            nn.Linear(dim // reduction, dim, bias=False),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        x = self.conv(x)\n        B, C, _, _ = x.size()\n        y = self.avg_pool(x).view(B, C)\n        y = self.fc(y).view(B, C, 1, 1)\n        return x * y.expand_as(x)\n\n\nclass ContextAwareTransformer(nn.Module):\n\n    def __init__(self, dim, input_resolution, num_heads, window_size=8, shift_size=0,\n                 mlp_ratio=4., qkv_bias=True, qk_scale=None, drop=0., attn_drop=0., drop_path=0.,\n                 act_layer=nn.GELU, norm_layer=nn.LayerNorm):\n        super().__init__()\n        self.dim = dim\n        self.input_resolution = input_resolution\n        self.num_heads = num_heads\n        self.window_size = window_size\n        self.shift_size = shift_size\n        self.mlp_ratio = mlp_ratio\n        if min(self.input_resolution) &lt;= self.window_size:\n            # if window size is larger than input resolution, we don't partition windows\n            self.shift_size = 0\n            self.window_size = min(self.input_resolution)\n        assert 0 &lt;= self.shift_size &lt; self.window_size, \"shift_size must in 0-window_size\"\n\n        self.norm1 = norm_layer(dim)\n        self.attn = WindowAttention(\n            dim, window_size=to_2tuple(self.window_size), num_heads=num_heads,\n            qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)\n\n        self.drop_path = DropPath(drop_path) if drop_path &gt; 0. else nn.Identity()\n        self.norm2 = norm_layer(dim)\n        mlp_hidden_dim = int(dim * mlp_ratio)\n        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n\n        if self.shift_size &gt; 0:\n            attn_mask = self.calculate_mask(self.input_resolution)\n        else:\n            attn_mask = None\n\n        self.register_buffer(\"attn_mask\", attn_mask)\n\n        self.lce = LocalContextExtractor(self.dim)\n\n    def calculate_mask(self, x_size):\n        # calculate attention mask for SW-MSA\n        H, W = x_size\n        img_mask = torch.zeros((1, H, W, 1))  # 1 H W 1\n        h_slices = (slice(0, -self.window_size),\n                    slice(-self.window_size, -self.shift_size),\n                    slice(-self.shift_size, None))\n        w_slices = (slice(0, -self.window_size),\n                    slice(-self.window_size, -self.shift_size),\n                    slice(-self.shift_size, None))\n        cnt = 0\n        for h in h_slices:\n            for w in w_slices:\n                img_mask[:, h, w, :] = cnt\n                cnt += 1\n\n        mask_windows = window_partition(img_mask, self.window_size)  # nW, window_size, window_size, 1\n        mask_windows = mask_windows.view(-1, self.window_size * self.window_size)\n        attn_mask = mask_windows.unsqueeze(1) - mask_windows.unsqueeze(2)\n        attn_mask = attn_mask.masked_fill(attn_mask != 0, float(-100.0)).masked_fill(attn_mask == 0, float(0.0))\n\n        return attn_mask\n\n    def forward(self, x, x_size):\n        H, W = x_size\n        B, L, C = x.shape\n        # assert L == H * W, \"input feature has wrong size\"\n\n        shortcut = x\n        x = self.norm1(x)\n        x = x.view(B, H, W, C)\n        # local context features\n        lcf = x.permute(0, 3, 1, 2)\n\n        # cyclic shift\n        if self.shift_size &gt; 0:\n            shifted_x = torch.roll(x, shifts=(-self.shift_size, -self.shift_size), dims=(1, 2))\n        else:\n            shifted_x = x\n\n        # partition windows\n        x_windows = window_partition(shifted_x, self.window_size)  # nW*B, window_size, window_size, C\n        x_windows = x_windows.view(-1, self.window_size * self.window_size, C)  # nW*B, window_size*window_size, C\n\n        # W-MSA/SW-MSA (to be compatible for testing on images whose shapes are the multiple of window size\n        if self.input_resolution == x_size:\n            attn_windows = self.attn(x_windows, mask=self.attn_mask)  # nW*B, window_size*window_size, C\n        else:\n            attn_windows = self.attn(x_windows, mask=self.calculate_mask(x_size).to(x.device))\n\n        # merge windows\n        attn_windows = attn_windows.view(-1, self.window_size, self.window_size, C)\n        shifted_x = window_reverse(attn_windows, self.window_size, H, W)  # B H' W' C\n\n        # reverse cyclic shift\n        if self.shift_size &gt; 0:\n            x = torch.roll(shifted_x, shifts=(self.shift_size, self.shift_size), dims=(1, 2))\n        else:\n            x = shifted_x\n        x = x.view(B, H * W, C)\n\n        # FFN\n        x = shortcut + self.drop_path(x)\n        x = x + self.drop_path(self.mlp(self.norm2(x)))\n        # local context\n        lc = self.lce(lcf)\n        lc = lc.view(B, C, H * W).permute(0, 2, 1)\n        x = lc + x\n\n        return x\n\n    def extra_repr(self) -&gt; str:\n        return f\"dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, \" \\\n               f\"window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}\"\n\n    def flops(self):\n        flops = 0\n        H, W = self.input_resolution\n        # norm1\n        flops += self.dim * H * W\n        # W-MSA/SW-MSA\n        nW = H * W / self.window_size / self.window_size\n        flops += nW * self.attn.flops(self.window_size * self.window_size)\n        # mlp\n        flops += 2 * H * W * self.dim * self.dim * self.mlp_ratio\n        # norm2\n        flops += self.dim * H * W\n        return flops\n</code></pre> <p>\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u6307\u6b63</p> <p>\u6ce8\uff1a\u521d\u6b65\u5b8c\u7a3f\u4e8e2023\u5e747\u67083\u65e5</p>"},{"location":"img_enhance/dataset/HDR_dataset/","title":"HDR\u5e38\u7528\u6570\u636e\u96c6","text":"<p>\u767e\u5ea6\u7f51\u76d8\u5730\u5740\uff1ahttps://pan.baidu.com/s/1WgLXsVUp1zXropB6UjBs9Q?pwd=ukej</p>"},{"location":"img_enhance/dataset/HDR_dataset/#kalantari","title":"Kalantari","text":"<p>\u5b98\u65b9\u4e0b\u8f7d\u5730\u5740\uff1ahttps://cseweb.ucsd.edu/~viscomp/projects/SIG17HDR</p> <p>\u8f93\u5165\u56fe\u50cf\uff1a.tif\u683c\u5f0f\uff0c48\u4f4d\u6df1\u5ea6\uff0848\u8868\u793a16*3\uff09\uff0c\u4e09\u4e2a\u901a\u9053\u6570\u636e\u8303\u56f4\u4e3a0 \\sim 2^{16}-1\uff0c\u53730 ~ 65535\uff1b</p> <p>\u6807\u7b7e\u56fe\u50cf\uff1a.hdr\u683c\u5f0f\uff0c\u8bfb\u53d6\u7684\u56fe\u50cf\u6570\u636e\u8303\u56f4\u4e3a0.0\\sim 1.0\uff0c\u6d6e\u70b9\u6570\u636e\u7c7b\u578b\uff0c\u8d8a\u63a5\u8fd1\u4e8e1\uff0c\u8868\u793a\u4eae\u5ea6\u8d8a\u5927\u3002</p> <p>\u8bad\u7ec3\u8fc7\u7a0b\uff1a\u4f1a\u5c06\u8f93\u5165\u7684\u4f4e\u52a8\u6001\u8303\u56f4\u56fe\u5f52\u4e00\u5316\uff0c\u4e4b\u540e\u8f6c\u4e3a\u9ad8\u52a8\u6001\u8303\u56f4\u56fe\uff0c\u8f6c\u6362\u516c\u5f0f\uff1a(imgs ** gamma) / (expo + 1e-8)\uff0cgamma\u8d85\u53c2\u6570\u5728\u8bba\u6587\u300aHDR-Transformer\u300b\u4e2d\u8bbe\u7f6e\u4e3a2.2\uff0cexpo\u8868\u793a\u66dd\u5149\u65f6\u95f4\uff08\u6216\u66dd\u5149\u503c\uff09\uff08\u53ef\u4ee5\u8865\u507f\u66dd\u5149\u5e26\u6765\u7684\u4eae\u5ea6\u53d8\u5316\uff0c\u4f7f\u5f97\u56fe\u50cf\u4e2d\u7684\u4eae\u5ea6\u66f4\u52a0\u51c6\u786e\u3002\uff09\uff0c\u8be5\u6570\u636e\u50a8\u5b58\u5728exposure.txt\u3002</p> <pre><code># LDR\u8f6c\u4e3aHDR\uff0c\u6570\u636e\u8303\u56f4\u4e3a0-1\ndef ldr_to_hdr(imgs, expo, gamma=2.2):\n    return (imgs ** gamma) / (expo + 1e-8)\n</code></pre> <p>\u6ce8\uff1a\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u901a\u5e38\u5c06\u4e00\u5f20\u56fe\u7684ldr\u56fe\u4e0e\u5bf9\u5e94\u7684hdr\u56fe\u6570\u636e\u5408\u5e76\uff0c\u540c\u65f6\u5f53\u505a\u7f51\u7edc\u7684\u4e00\u4e2a\u8f93\u5165\u3002\u7f51\u7edc\u6700\u540e\u4e00\u5c42\u4e3asigmoid\uff0c\u5c06\u8f93\u51fa\u7684\u56fe\u7247\u505a\u5f52\u4e00\u5316\uff0c\u4e4b\u540e\u5c06\u8bfb\u5230hdr\u56fe\u50cf\u505aL1\u635f\u5931\u3002\uff08\u6240\u8bfb\u53d6\u7684\u56fe\u50cf\u8303\u56f4\u5c31\u662f0-1\uff0c\u4e0d\u9700\u8981\u989d\u5916\u505a\u5f52\u4e00\u5316\u5904\u7406\uff09</p> <p>\u6d4b\u8bd5\u8fc7\u7a0b\uff1a\u76f4\u63a5\u5c06\u7f51\u7edc\u7684\u8f93\u51fa\u89c6\u4e3ahdr\u56fe\u50cf\uff0c\u4ee5.hdr\u56fe\u50cf\u7684\u683c\u5f0f\u4fdd\u5b58\u5373\u53ef\uff0c\u8bc4\u4f30\u6307\u6807\u7684\u65f6\u5019\u4e5f\u662f\u76f4\u63a5\u5229\u7528\u6a21\u578b\u7684\u8f93\u5165\u8f93\u51fa\u505a\u8bc4\u4f30\u3002</p> <pre><code>save_hdr(os.path.join(args.save_dir, '{}_pred.hdr'.format(idx)), pred_hdr)\n\n# \u5c06\u56fe\u50cf\u6570\u636e\u8f6c\u5b58\u4e3a.hdr\u683c\u5f0f\u7684\u6587\u4ef6\ndef radiance_writer(out_path, image):\n    with open(out_path, \"wb\") as f:\n        # \u5411\u6587\u4ef6\u4e2d\u5199\u5165\u4e00\u4e9b\u5934\u90e8\u4fe1\u606f\uff0c\u4ee5\u6ce8\u91ca\u7684\u5f62\u5f0f\u6807\u8bc6RADIANCE\u683c\u5f0f\n        # \u5e76\u6307\u5b9a\u56fe\u50cf\u7684\u683c\u5f0f\u4e3a32-bit RLE (Run Length Encoded) RGBE\u3002\n        f.write(b\"#?RADIANCE\\n# Made with Python &amp; Numpy\\nFORMAT=32-bit_rle_rgbe\\n\\n\")\n        # \u5199\u5165\u56fe\u50cf\u7684\u5927\u5c0f\u4fe1\u606f\uff0c\u6307\u5b9a\u56fe\u50cf\u7684\u9ad8\u5ea6\uff08Y\u8f74\u65b9\u5411\uff09\u548c\u5bbd\u5ea6\uff08X\u8f74\u65b9\u5411\uff09\u3002\n        f.write(b\"-Y %d +X %d\\n\" % (image.shape[0], image.shape[1]))\n        # \u8ba1\u7b97\u56fe\u50cf\u4e2d\u6700\u4eae\u7684\u50cf\u7d20\u503c\uff0c\u5e76\u4f7f\u7528np.frexp\u51fd\u6570\u5c06\u6700\u4eae\u50cf\u7d20\u503c\u62c6\u5206\u4e3a\u5c3e\u6570\u548c\u6307\u6570\u7684\u5f62\u5f0f\u3002\n        # \u7136\u540e\u901a\u8fc7\u7f29\u653e\u5c3e\u6570\u5c06\u5176\u6620\u5c04\u52300\u5230255\u7684\u8303\u56f4\u5185\u3002\n        brightest = np.maximum(np.maximum(image[..., 0], image[..., 1]), image[..., 2])\n        mantissa = np.zeros_like(brightest)\n        exponent = np.zeros_like(brightest)\n        np.frexp(brightest, mantissa, exponent)\n        scaled_mantissa = mantissa * 255.0 / brightest\n        # \u521b\u5efa\u4e00\u4e2a\u65b0\u7684\u6570\u7ec4rgbe\uff0c\u7528\u4e8e\u5b58\u50a8\u8c03\u6574\u540e\u7684\u56fe\u50cf\u6570\u636e\u3002\n        # \u5c06\u56fe\u50cf\u7684RGB\u901a\u9053\u4e58\u4ee5\u5c3e\u6570\u5e76\u56db\u820d\u4e94\u5165\u4e3a\u6574\u6570\uff0c\u7136\u540e\u5c06\u6307\u6570\u52a0\u4e0a128\u3002\n        rgbe = np.zeros((image.shape[0], image.shape[1], 4), dtype=np.uint8)\n        rgbe[..., 0:3] = np.around(image[..., 0:3] * scaled_mantissa[..., None])\n        rgbe[..., 3] = np.around(exponent + 128)\n        # \u5c06rgbe\u6570\u7ec4\u5c55\u5e73\u5e76\u4ee5\u4e8c\u8fdb\u5236\u5f62\u5f0f\u5199\u5165\u5230\u6253\u5f00\u7684\u6587\u4ef6\u4e2d\u3002\n        rgbe.flatten().tofile(f)\n</code></pre> <p>\u4ee3\u7801\u5f15\u81ea\uff1ahttps://github.com/liuzhen03/HDR-Transformer-PyTorch</p> <p>\u5f15\u7528</p> <pre><code>@article{LearningHDR,\n    author  = {Nima Khademi Kalantari and Ravi Ramamoorthi},\n    title   = {Deep High Dynamic Range Imaging of Dynamic Scenes},\n    journal = {ACM Transactions on Graphics (Proceedings of SIGGRAPH 2017)},\n    volume  = {36},\n    number  = {4},\n    year    = {2017},\n}\n</code></pre>"},{"location":"img_enhance/dataset/HDR_dataset/#ntire_20212022","title":"NTIRE 2021/2022","text":"<p>\u4e0b\u8f7d\u5730\u5740\uff1ahttps://codalab.lisn.upsaclay.fr/competitions/1515</p> <p>\u8f93\u5165\u56fe\u50cf\uff1a.png\u683c\u5f0f\uff0c24\u4f4d\u6df1\u5ea6\uff088*3\uff09\uff0c\u4e09\u4e2a\u901a\u9053\u6570\u636e\u8303\u56f4\u4e3a0 \\sim 2^8-1\uff0c\u53730 \\sim 255\uff1b</p> <p>\u6807\u7b7e\u56fe\u50cf\uff1a.png\u683c\u5f0f\uff0c48\u4f4d\u6df1\u5ea6\uff0816*3\uff09\uff0c\u4e09\u4e2a\u901a\u9053\u6570\u636e\u8303\u56f4\u4e3a0 \\sim 2^{16}-1\uff0c\u53730 \\sim 65535\uff0c\u5728\u8bfb\u53d6\u7684\u65f6\u5019\uff0c\u9700\u8981\u505a\u989d\u5916\u7684\u5904\u7406\uff0c\u6062\u590dHDR\u56fe\u50cf\u7684\u539f\u59cb\u8303\u56f4\uff08\u6bd4\u8d5b\u5b98\u7f51\u6570\u636e\u4ecb\u7ecd\u4e2d\u5199\u5230\u7684\uff09</p> <p>\u8bad\u7ec3\u8fc7\u7a0b\uff1a</p> <p>\u200b       \u8f93\u5165\u56fe\u50cf\u8bfb\u53d6\u540e\u76f4\u63a5\u505a\u5f52\u4e00\u5316\u64cd\u4f5c\uff0c\u8f6c\u4e3a\u6d6e\u70b9\u6570\u636e\u7c7b\u578b\u3002\u6807\u7b7e\u56fe\u50cf\u8bfb\u53d6\u540e\u5229\u7528\u6bd4\u8d5b\u5b98\u65b9\u63d0\u4f9b\u7684\u4ee3\u7801\uff0c\u5c06\u56fe\u50cf\u6062\u590d\u6210HDR\u56fe\u50cf\u7684\u8303\u56f4\uff08\u8fd9\u91cc\u7684\u56fe\u50cf\u6570\u636e\u5e76\u4e0d\u662f0-1\u4e4b\u95f4\uff0c\u66dd\u5149\u5ea6\u9ad8\u7684\u5730\u65b9\u6570\u636e\u503c\u4f1a\u5927\u4e8e1\uff0c\u6709\u70b9\u5947\u602a\uff0c\u548c\u4e0a\u9762Kalantari\u6570\u636e\u4e2d\u7684.hdr\u56fe\u50cf\u6570\u636e\u683c\u5f0f\u4e0d\u592a\u4e00\u6837\uff09</p> <pre><code># NTIRE\u5b98\u65b9\u7ed9\u7684\u8bfb\u53d6HDR\u56fe\u50cf\u7684\u4ee3\u7801\uff08\u8bfb\u53d6\u6807\u7b7e\u56fe\u50cf\uff09\ndef imread_uint16_png(image_path, alignratio_path):\n    \"\"\" This function loads a uint16 png image from the specified path and restore its original image range with\n    the ratio stored in the specified alignratio.npy respective path.\n\n\n    Args:\n        image_path (str): Path to the uint16 png image\n        alignratio_path (str): Path to the alignratio.npy file corresponding to the image\n\n    Returns:\n        np.ndarray (np.float32, (h,w,3)): Returns the RGB HDR image specified in image_path.\n\n    \"\"\"\n    # Load the align_ratio variable and ensure is in np.float32 precision\n    align_ratio = np.load(alignratio_path).astype(np.float32)\n    # Load image without changing bit depth and normalize by align ratio\n    return cv2.cvtColor(cv2.imread(image_path, cv2.IMREAD_UNCHANGED), cv2.COLOR_BGR2RGB) / align_ratio\n</code></pre> <p>\u6d4b\u8bd5\u8fc7\u7a0b\uff1a</p>"},{"location":"img_enhance/dataset/HDR_dataset/#sice","title":"SICE","text":"<p>\u5b98\u65b9\u4e0b\u8f7d\u5730\u5740\uff1ahttps://github.com/csjcai/SICE</p> <p>\u8f93\u5165\u56fe\u50cf\u548c\u6807\u7b7e\u56fe\u50cf\u7684\u6570\u636e\u90fd\u662f24\u4f4d\u6df1\u5ea6\uff0c\u4e09\u4e2a\u901a\u9053\u6570\u8303\u56f4\u90fd\u662f0\\sim255\u3002 </p> <p>\u5f15\u7528</p> <pre><code>@article{Cai2018deep,\ntitle={Learning a Deep Single Image Contrast Enhancer from Multi-Exposure Images}, \nauthor={Cai, Jianrui and Gu, Shuhang and Zhang, Lei},\njournal={IEEE Transactions on Image Processing},\nvolume={27}, \nnumber={4}, \npages={2049-2062}, \nyear={2018}, \npublisher={IEEE}\n}\n</code></pre> <p>\u6ce8\uff1a\u300aUltra-High-Definition Image HDR Reconstruction via Collaborative Bilateral Learning\u300b\u8bba\u6587\u66fe\u7528\u5230\u8fd9\u4e2a\u6570\u636e</p>"},{"location":"img_enhance/dataset/HDR_dataset/#hu","title":"Hu","text":"<p>\u5f15\u7528</p> <pre><code>@inproceedings{hu2020sensor,\n  title={Sensor-realistic synthetic data engine for multi-frame high dynamic range photography},\n  author={Hu, Jinhan and Choe, Gyeongmin and Nadir, Zeeshan and Nabil, Osama and Lee, Seok-Jun and Sheikh, Hamid and Yoo, Youngjun and Polley, Michael},\n  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},\n  pages={516--517},\n  year={2020}\n}\n</code></pre> <p>\u6ce8\uff1a\u300aSMAE: Few-shot Learning for HDR Deghosting with Saturation-Aware Masked Autoencoders\u300b\u66fe\u7528\u5230\u8fd9\u4e2a\u6570\u636e</p>"},{"location":"img_enhance/dataset/deraining/","title":"\u6570\u636e\u96c6","text":"<p>\u767e\u5ea6\u7f51\u76d8\u94fe\u63a5\uff1a\u94fe\u63a5\uff1ahttps://pan.baidu.com/s/1vAlRqNmvAwtZ0nSvz6ncpQ \uff08\u5bc6\u7801\uff1auo1x \uff09</p>"},{"location":"img_enhance/dataset/deraining/#_2","title":"\u5408\u6210\u6570\u636e","text":"<ul> <li>Rain100L\uff1a200 \u4e2a\u8bad\u7ec3\u5bf9\u548c 100 \u4e2a\u6d4b\u8bd5\u5bf9</li> <li>Rain100H\uff1a1800 \u4e2a\u8bad\u7ec3\u5bf9\u548c 100 \u4e2a\u6d4b\u8bd5\u5bf9</li> <li>Rain200L\uff1a1800 \u4e2a\u8bad\u7ec3\u5bf9\u548c 200 \u4e2a\u6d4b\u8bd5\u5bf9</li> <li>Rain200H\uff1a1800 \u4e2a\u8bad\u7ec3\u5bf9\uff08\u4e0e Rain100H \u76f8\u540c\uff09\u548c 200 \u4e2a\u6d4b\u8bd5\u5bf9</li> </ul> <p>Rain100\u3001Rain200\u7cfb\u5217\u5b98\u65b9\u4e0b\u8f7d\u5730\u5740\uff1ahttps://www.icst.pku.edu.cn/struct/Projects/joint_rain_removal.html</p> <ul> <li>Rain800\uff1a700 \u4e2a\u8bad\u7ec3\u5bf9\u548c 100 \u4e2a\u6d4b\u8bd5\u5bf9\uff08\u6709\u4e24\u5bf9\u56fe\u7247\u7279\u522b\u5927\uff0c\u53ef\u4ee5\u5220\u6389\uff09</li> </ul> <p>github\uff1ahttps://github.com/hezhangsprinter/ID-CGAN</p> <p>\u8c37\u6b4c\u4e91\u76d8\uff1ahttps://drive.google.com/file/d/1_pP8fR-gpHUB0q1kpvZxKALvjLZ-JVM8/view</p> <ul> <li>Rain1200\uff1a12000\u4e2a\u8bad\u7ec3\u5bf9\u548c1200\u4e2a\u6d4b\u8bd5\u5bf9</li> </ul> <p>github\uff1ahttps://github.com/hezhangsprinter/DID-MDN</p> <p>\u8c37\u6b4c\u4e91\u76d8\uff1ahttps://drive.google.com/file/d/1cMXWICiblTsRl1zjN8FizF5hXOpVOJz4/view</p> <ul> <li> <p>Rain1400\uff1a12600\u4e2a\u8bad\u7ec3\u5bf9\u548c1400\u4e2a\u6d4b\u8bd5\u5bf9</p> </li> <li> <p>Rain13k\uff1a13712\u4e2a\u8bad\u7ec3\u5bf9\u548c\u4e94\u7ec4\u6d4b\u8bd5\u6570\u636e\u96c6</p> </li> </ul> <p>github\uff1ahttps://github.com/megvii-model/HINet</p> <p>\u8c37\u6b4c\u4e91\u76d8\uff1ahttps://drive.google.com/drive/folders/1Hnnlc5kI0v9_BtfMytC2LR5VpLAFZtVe</p>"},{"location":"img_enhance/dataset/deraining/#_3","title":"\u771f\u5b9e\u6570\u636e","text":"<ul> <li>SPA-Data\uff1a638492 \u4e2a\u8bad\u7ec3\u5bf9\uff0c1000 \u4e2a\u6d4b\u8bd5\u5bf9</li> </ul> <p>github\uff1ahttps://stevewongv.github.io</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65f6\u95f4\uff1a2022\u5e747\u670814\u65e5</p>"},{"location":"img_enhance/matrix/PSNR/","title":"\u56fe\u50cf\u8d28\u91cf\u8bc4\u4f30\u6307\u6807\u2014\u2014PSNR","text":"<p>\u2003\u2003PSNR\u5168\u79f0\u4e3aPeak Signal to Noise Ratio\uff0c\u5373\u5cf0\u503c\u4fe1\u566a\u6bd4\uff0c\u662f\u4e00\u79cd\u8bc4\u4ef7\u56fe\u50cf\u7684\u5ba2\u89c2\u6807\u51c6\uff0c\u7ecf\u5e38\u7528\u4e8e\u8ba1\u7b97\u4e24\u5e45\u56fe\u50cf\u7684\u53ef\u89c6\u5316\u8bef\u5dee\uff0c\u5982\u8861\u91cf\u539f\u56fe\u4e0e\u7ecf\u8fc7\u538b\u7f29\u540e\u56fe\u50cf\u4e4b\u95f4\u7684\u53ef\u89c6\u5316\u5dee\u5f02\u3001\u751f\u6210\u7f51\u7edc\u751f\u6210\u7684\u56fe\u50cf\u4e0e\u771f\u5b9e\u56fe\u50cf\u4e4b\u95f4\u7684\u5dee\u5f02\u7b49\u7b49\u3002</p> <p>\u8ba1\u7b97\u65b9\u6cd5</p> <p>\u2003\u2003\u5047\u8bbe\u5904\u7406\u540e\u56fe\u50cf\u4e3aI\u3001\u771f\u5b9e\u56fe\u50cf\u4e3aK\uff0c\u5219\u5cf0\u503c\u566a\u58f0\u6bd4\u5b9a\u4e49\u4e3a\uff1a $$ PSNR=10\u00b7\\log_{10}(\\frac{MAX^2}{MSE})=20\u00b7\\log_{10}(\\frac{MAX}{\\sqrt{MSE}}) $$  \u5176\u4e2d\uff0cMAX\u8868\u793a\u56fe\u50cf\u4e0a\u50cf\u7d20\u70b9\u7684\u6700\u5927\u6570\u503c\uff0c\u5e38\u5b9a\u4e49\u4e3a1\u6216\u8005255\uff0cMSE\u5b9a\u4e49\u4e3a\uff1a $$ MSE=\\frac{1}{mn}\\sum^{m-1}_{i=0}\\sum^{n-1}_{j=0}||I(i,j)-K(i,j)||^2 $$ </p>"},{"location":"img_enhance/matrix/PSNR/#_1","title":"\u4ee3\u7801\u5b9e\u73b0","text":"<ul> <li>\u53c2\u8003\u8bba\u6587\u300aSpatial Attentive Single-Image Deraining with a High Quality Real Rain Dataset\u300b\u7684\u6e90\u7801\uff1ahttps://github.com/stevewongv/SPANet</li> </ul> <pre><code># \u8fd9\u91cc\u4ee5\u751f\u6210\u7f51\u7edc\u4e2d\u6d4b\u8bd5\u6a21\u578b\u6027\u80fd\u4e3a\u4f8b\uff0c\u6240\u4ee5pred\u4e0egt\u5747\u662ftensor\u683c\u5f0f\n# \u5e76\u4e14\u5728\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u56fe\u50cf\u6570\u636e\u5747\u88ab\u5f52\u4e00\u5316\u81f30\u52301\u4e4b\u95f4\uff0c\u56e0\u6b64max\u9ed8\u8ba41.0\ndef psnr(pred, gt, max=1.0):\n    # \u9700\u8981\u5148\u5207\u65ad\u68af\u5ea6\uff0c\u5c06\u6570\u636e\u8f6c\u4e3anumpy\u683c\u5f0f\u8fdb\u884c\u8ba1\u7b97\n    pred = pred.clamp(0, max).cpu().detach().numpy()\n    gt = gt.clamp(0, max).cpu().detach().numpy()\n    # \u4e24\u4e2a\u56fe\u50cf\u6570\u503c\u505a\u5dee\uff0c\u4e4b\u540e\u6c42\u6839\u4e0bMSE\n    imdff = pred - gt\n    rmse = math.sqrt(np.mean(imdff ** 2))\n    # \u5982\u679c\u50cf\u7d20\u5b8c\u5168\u76f8\u540c\uff0c\u5373rmse\u4e3a0\uff0c\u5219PSNR\u76f4\u63a5\u8fd4\u56de100\uff0c\u9632\u6b62\u540e\u7eed\u8ba1\u7b97log\u65f6\u62a5\u9519\n    if rmse == 0:\n        return 100\n    # \u6309\u516c\u5f0f\u8ba1\u7b97\n    return 20 * math.log10(max / rmse)\n</code></pre> <p>\u76f4\u63a5\u8c03\u7528skimage\u5e93\u4e2d\u7684\u51fd\u6570</p> <pre><code>from skimage.metrics import peak_signal_noise_ratio\n\n\n# \u8fd9\u91ccdata_range\u8868\u793a\u56fe\u50cf\u50cf\u7d20\u7684\u6700\u5927\u503c\uff0c\u5373\u516c\u5f0f\u4e2d\u7684MAX\n# \u5982\u679c\u4e0d\u4f20\u5165data_range\uff0c\u5219\u7a0b\u5e8f\u9ed8\u8ba4\u9009\u62e9image_true\u4e2d\u6700\u5927\u7684\u50cf\u7d20\u503c\n# \u6216\u8005\u6700\u5927\u503c\u51cf\u6700\u5c0f\u503c(\u5982\u679c\u50cf\u7d20\u70b9\u5b58\u5728\u8d1f\u6570\u60c5\u51b5)\uff0c\u5177\u4f53\u53ef\u89c1\u6e90\u7801\npsnr = peak_signal_noise_ratio(image_true, image_test, data_range=None)\n</code></pre> <p>skimage\u4e2d\u8ba1\u7b97PSNR\u7684\u6e90\u7801</p> <pre><code>def peak_signal_noise_ratio(image_true, image_test, *, data_range=None):\n    \"\"\"\n    Compute the peak signal to noise ratio (PSNR) for an image.\n\n    Parameters\n    ----------\n    image_true : ndarray\n        Ground-truth image, same shape as im_test.\n    image_test : ndarray\n        Test image.\n    data_range : int, optional\n        The data range of the input image (distance between minimum and\n        maximum possible values).  By default, this is estimated from the image\n        data-type.\n\n    Returns\n    -------\n    psnr : float\n        The PSNR metric.\n\n    Notes\n    -----\n    .. versionchanged:: 0.16\n        This function was renamed from ``skimage.measure.compare_psnr`` to\n        ``skimage.metrics.peak_signal_noise_ratio``.\n\n    References\n    ----------\n    .. [1] https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio\n\n    \"\"\"\n    check_shape_equality(image_true, image_test)\n    # \u5982\u679c\u4e0d\u6307\u5b9adata_range\u7684\u8bdd\uff0c\u5219\u9ed8\u8ba4\u53d6image_true\u4e2d\u7684\u6700\u5927\u503c\uff0c\u6216\u8005\u6700\u5927\u503c\u51cf\u6700\u5c0f\u503c\n    if data_range is None:\n        if image_true.dtype != image_test.dtype:\n            warn(\"Inputs have mismatched dtype.  Setting data_range based on \"\n                 \"image_true.\")\n        dmin, dmax = dtype_range[image_true.dtype.type]\n        true_min, true_max = np.min(image_true), np.max(image_true)\n        if true_max &gt; dmax or true_min &lt; dmin:\n            raise ValueError(\n                \"image_true has intensity values outside the range expected \"\n                \"for its data type. Please manually specify the data_range.\")\n        if true_min &gt;= 0:\n            # most common case (255 for uint8, 1 for float)\n            data_range = dmax\n        else:\n            data_range = dmax - dmin\n    # \u5c06\u6570\u636e\u8f6c\u53d8\u4e3afloat\u7c7b\u578b\n    image_true, image_test = _as_floats(image_true, image_test)\n    # \u8ba1\u7b97MSE\n    err = mean_squared_error(image_true, image_test)\n    # \u8fdb\u4e00\u6b65\u8ba1\u7b97PSNR\n    return 10 * np.log10((data_range ** 2) / err)\n</code></pre> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u4e8e\uff1a2022\u5e744\u67088\u65e5</p>"},{"location":"img_enhance/matrix/SSIM/","title":"\u56fe\u50cf\u8d28\u91cf\u8bc4\u4f30\u6307\u6807\u2014\u2014SSIM","text":"<p>\u2003\u2003SSIM\u5168\u79f0\u4e3aStructural Similarity\uff0c\u5373\u7ed3\u6784\u76f8\u4f3c\u6027\uff0c\u7528\u4e8e\u8bc4\u4f30\u4e24\u5e45\u56fe\u50cf\u76f8\u4f3c\u5ea6\u7684\u6307\u6807\uff0c\u5e38\u7528\u4e8e\u8861\u91cf\u56fe\u50cf\u5931\u771f\u524d\u4e0e\u5931\u771f\u540e\u7684\u76f8\u4f3c\u6027\uff0c\u4e5f\u7528\u4e8e\u8861\u91cf\u6a21\u578b\u751f\u6210\u56fe\u50cf\u7684\u771f\u5b9e\u6027\uff0c\u5982\u56fe\u50cf\u53bb\u96e8\u3001\u56fe\u50cf\u53bb\u96fe\u3001\u56fe\u50cf\u548c\u8c10\u5316\u7b49\u7b49\u3002</p> <p>\u8ba1\u7b97\u65b9\u6cd5</p> <p>\u2003\u2003SSIM\u7684\u8ba1\u7b97\u57fa\u4e8e\u6ed1\u52a8\u7a97\u53e3\u5b9e\u73b0\uff0c\u5373\u6bcf\u6b21\u8ba1\u7b97\u5747\u4ece\u56fe\u7247\u4e0a\u53d6\u4e00\u4e2a\u5c3a\u5bf8\u4e3aN\\times N\u7684\u7a97\u53e3\uff0c\u57fa\u4e8e\u7a97\u53e3\u8ba1\u7b97SSIM\u6307\u6807\uff0c\u904d\u5386\u6574\u5f20\u56fe\u50cf\u540e\u518d\u5c06\u6240\u6709\u7a97\u53e3\u7684\u6570\u503c\u53d6\u5e73\u5747\u503c\uff0c\u4f5c\u4e3a\u6574\u5f20\u56fe\u50cf\u7684SSIM\u6307\u6807\u3002</p> <p>\u2003\u2003\u5047\u8bbex\u8868\u793a\u7b2c\u4e00\u5f20\u56fe\u50cf\u7a97\u53e3\u4e2d\u7684\u6570\u636e\uff0cy\u8868\u793a\u7b2c\u4e8c\u5f20\u56fe\u50cf\u7a97\u53e3\u4e2d\u7684\u6570\u636e\u3002\u5176\u4e2d\u56fe\u50cf\u7684\u76f8\u4f3c\u6027\u7531\u4e09\u90e8\u5206\u6784\u6210\uff1aluminance(\u4eae\u5ea6)\u3001contrast(\u5bf9\u6bd4\u5ea6)\u548cstructure(\u7ed3\u6784)\u3002luminance\u8ba1\u7b97\u516c\u5f0f\u4e3a\uff1a $$ l(x,y)=\\frac{2\\mu_x\\mu_y+c_1}{\\mu_x^2+\\mu_y^2+c_1} $$  contrast\u8ba1\u7b97\u516c\u5f0f\u4e3a\uff1a $$ c(x,y)=\\frac{2\\sigma_x\\sigma_y+c_2}{\\sigma_x^2+\\sigma_y^2+c_2} $$  structure\u8ba1\u7b97\u516c\u5f0f\u4e3a\uff1a $$ s(x,y)=\\frac{\\sigma_{xy}+c_3}{\\sigma_x\\sigma_y+c_3} $$  \u5176\u4e2d\\mu_x\u548c\\mu_y\u4f9d\u6b21\u8868\u793ax\u548cy\u7684\u5747\u503c\uff0c\\sigma_x\u548c\\sigma_y\u4f9d\u6b21\u8868\u793ax\u548cy\u7684\u65b9\u5dee\uff0c\\sigma_{xy}\u8868\u793ax\u548cy\u4e4b\u95f4\u7684\u534f\u65b9\u5dee\uff0cc_1=(k_1L)^2\u3001c_2=(k_2L)^2\u4ee5\u53cac_3=c_2/2\uff0c\u8868\u793a\u4e09\u4e2a\u5e38\u6570\uff0c\u907f\u514d\u5206\u6bcd\u4e3a0\uff0ck_1\u4e0ek_2\u4f9d\u6b21\u9ed8\u8ba4\u4e3a0.01\u548c0.03\uff0cL\u8868\u793a\u56fe\u50cf\u50cf\u7d20\u503c\u7684\u8303\u56f4\uff0c\u53732^B-1\u3002</p> <p>\u2003\u2003\u6700\u540eSSIM\u7684\u8ba1\u7b97\u516c\u5f0f\u4e3a\uff1a $$ SSIM(x,y)=[l(x,y)^{\\alpha}\u00b7c(x,y)^{\\beta}\u00b7s(x,y)^{\\gamma}] $$  \u5982\u679c\u4ee4\\alpha, \\beta, \\gamma\u5747\u4e3a1\uff0c\u5219\u5f97\u5230\u5e38\u7528\u7684SSIM\u8ba1\u7b97\u516c\u5f0f\uff1a $$ SSIM(x,y)=\\frac{(2\\mu_x\\mu_y+c_1)(2\\sigma_{xy}+c_2)}{(\\mu_x^2+\\mu_y^2+c_2)(\\sigma_x^2+\\sigma_y^2+c_2)} $$ </p>"},{"location":"img_enhance/matrix/SSIM/#_1","title":"\u4ee3\u7801\u5b9e\u73b0","text":"<ul> <li>\u53c2\u8003\u8bba\u6587\u300aSpatial Attentive Single-Image Deraining with a High Quality Real Rain Dataset\u300b\u7684\u6e90\u7801\uff1ahttps://github.com/stevewongv/SPANet</li> </ul> <pre><code>def gaussian(window_size, sigma):\n    # \u8ba1\u7b97\u516c\u5f0f:e^(-x^2)/(2*sigma^2)\uff0c\u5176\u4e2dx\u8868\u793a\u8ddd\u79bb\u4e2d\u5fc3\u70b9\u7684\u8ddd\u79bb\uff0csigma\u9ed8\u8ba41.5\n    gauss = torch.Tensor([exp(-(x - window_size // 2) ** 2 / float(2 * sigma ** 2)) for x in range(window_size)])\n    # \u6570\u636e\u5f52\u4e00\u5316\n    return gauss / gauss.sum()\n\n\n# \u8ba1\u7b97\u6ed1\u52a8\u7a97\u53e3\u6743\u91cd\ndef create_window(window_size, channel):\n    # \u5229\u7528\u6ed1\u52a8\u7a97\u53e3\u5c3a\u5bf8\u5148\u8ba1\u7b97\u4e00\u4e2a\u4e00\u7ef4\uff0c\u5e76\u4e14\u670d\u4ece\u6b63\u6001\u5206\u5e03\u7684\u6570\u636e\n    # \u6ce8\u610f\u8fd9\u91cc\u5229\u7528unsqueeze\u51fd\u6570\u6269\u4e86\u4e00\u4e0b\u7ef4\u5ea6\uff0c\u4ece\u884c\u5411\u91cf\u53d8\u4e3a\u4e86\u5217\u5411\u91cf\n    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n    # \u5217\u5411\u91cf\u4e58\u4ee5\u884c\u5411\u91cf\uff0c\u53d8\u4e3an*n\u7684\u77e9\u9635\uff0c\u6b63\u597d\u5bf9\u5e94\u7a97\u53e3\u6743\u91cd\n    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n    # \u6cbf\u901a\u9053\u7ef4\u5ea6\u590d\u5236channel\u904d\uff0c\u6bcf\u4e2a\u901a\u9053\u5bf9\u5e94\u4e00\u4e2a\u6743\u91cd(\u8fd9\u91cc\u6240\u6709\u901a\u9053\u6743\u91cd\u76f8\u540c\uff0c\u5747\u670d\u4ece\u6b63\u6001\u5206\u5e03)\uff0c\u5e76\u4e14\u53d8\u4e3a\u8fde\u7eed\u5b58\u50a8\u7684\u6570\u636e\n    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n    # \u8fd4\u56de\u7a97\u53e3\u6743\u91cd\u6570\u636e\n    return window\n\n\ndef _ssim(img1, img2, window, window_size, channel, size_average=True):\n    # \u8ba1\u7b97\u6bcf\u4e2a\u6ed1\u52a8\u7a97\u53e3\u7684\u5747\u503c\n    # \u5377\u79ef\u8fd0\u7b97\u6b63\u597d\u662f\u7a97\u53e3\u6570\u636e\u6309\u6743\u91cd\u6c42\u548c\u518d\u53d6\u5747\u503c\uff0c\u56e0\u6b64\u53ef\u4ee5\u5229\u7528\u4e8c\u7ef4\u5377\u79ef\u8fd0\u7b97\u6765\u8ba1\u7b97\u7a97\u53e3\u4e2d\u6570\u636e\u7684\u5747\u503c\n    mu1 = F.conv2d(img1, window, padding=window_size // 2, groups=channel)\n    mu2 = F.conv2d(img2, window, padding=window_size // 2, groups=channel)\n    # \u5747\u503c\u53d6\u5e73\u65b9\uff0c\u5373E^2(X)\n    mu1_sq = mu1.pow(2)\n    mu2_sq = mu2.pow(2)\n    # \u8ba1\u7b97E(X)E(Y)\uff0c\u7528\u4e8e\u540e\u7eed\u8ba1\u7b97\u534f\u65b9\u5dee\n    mu1_mu2 = mu1 * mu2\n    # \u4f9d\u6b21\u8ba1\u7b97img1\u4e0eimg2\u7684\u65b9\u5dee\n    # \u8fd9\u91cc\u8ba1\u7b97\u65b9\u5dee\u5229\u7528\u516c\u5f0fD(X)=E(X^2)-E^2(X)\uff0c\u5176\u4e2dE^2(X)\u8868\u793a\u5747\u503c\u7684\u5e73\u65b9\uff0c\u5373\u4e0a\u8ff0\u516c\u5f0f\u4e2d\u7684mu1_sq\u3001mu2_sq\u3001mu1_mu2\n    sigma1_sq = F.conv2d(img1 * img1, window, padding=window_size // 2, groups=channel) - mu1_sq\n    sigma2_sq = F.conv2d(img2 * img2, window, padding=window_size // 2, groups=channel) - mu2_sq\n    # \u8ba1\u7b97img1\u3001img2\u4e4b\u95f4\u7684\u534f\u65b9\u5dee\n    # \u5229\u7528\u516c\u5f0fConv(X,Y)=E(XY)-E(X)E(Y)\n    sigma12 = F.conv2d(img1 * img2, window, padding=window_size // 2, groups=channel) - mu1_mu2\n    C1 = 0.01 ** 2\n    C2 = 0.03 ** 2\n    # \u5229\u7528\u4e0a\u8ff0\u5f97\u5230\u7684\u6307\u6807\uff0c\u4f20\u5165\u516c\u5f0f\u8ba1\u7b97ssim\u503c\uff0c\u6b64\u65f6\u4f1a\u5f97\u5230\u4e00\u5f20\u56fe\uff0c\u6700\u540e\u518d\u6c42\u5747\u503c\u5373\u53ef\n    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n\n    if size_average:\n        return ssim_map.mean()\n    else:\n        return ssim_map.mean(1).mean(1).mean(1)\n\n\ndef ssim(img1, img2, window_size=11, size_average=True):\n    # \u5c06\u8f93\u5165\u7684\u56fe\u50cf\u6570\u636e\u9650\u5236\u4e3a0-1\u4e4b\u95f4(\u4e00\u822c\u6570\u636e\u5c31\u662f\u4f4d\u4e8e0-1\u4e4b\u95f4\uff0c\u9632\u6b62\u51fa\u73b0\u5f02\u5e38\u503c)\n    img1 = torch.clamp(img1, min=0, max=1)\n    img2 = torch.clamp(img2, min=0, max=1)\n    # \u5f97\u5230\u56fe\u7247\u901a\u9053\u6570\n    (_, channel, _, _) = img1.size()\n    # \u5f97\u5230\u7a97\u53e3\u7684\u6743\u91cd\u6570\u636e\uff0c\u79bb\u7a97\u53e3\u4e2d\u5fc3\u8d8a\u8fdc\uff0c\u6743\u91cd\u8d8a\u5c0f\u3002\u6743\u91cd\u670d\u4ece\u9ad8\u65af\u5206\u5e03(\u6b63\u6001\u5206\u5e03)\n    window = create_window(window_size, channel)\n    # \u5982\u679c\u56fe\u7247\u6570\u636e\u50a8\u5b58\u5728cuda\u4e0a(\u5373\u5229\u7528\u663e\u5361\u8bad\u7ec3)\uff0c\u5219\u5c06\u7a97\u53e3\u6743\u91cd\u6570\u636e\u4e5f\u4f20\u5165cuda\u4e2d\n    if img1.is_cuda:\n        window = window.cuda(img1.get_device())\n    # \u7edf\u4e00\u6570\u636e\u7c7b\u578b\n    window = window.type_as(img1)\n    # \u8c03\u7528_ssim\uff0c\u8ba1\u7b97ssim\u503c\n    return _ssim(img1, img2, window, window_size, channel, size_average)\n</code></pre> <p>\u76f4\u63a5\u8c03\u7528skimage\u5e93\u4e2d\u7684\u51fd\u6570</p> <pre><code>from skimage.metrics import structural_similarity\n\n\n# im1, im2\u5206\u522b\u8868\u793a\u53c2\u4e0e\u8ba1\u7b97\u7684\u56fe\u50cf\u6570\u636e\n# data_range\u8868\u793a\u56fe\u50cf\u6570\u636e\u7684\u8303\u56f4\uff0c\u4e00\u822c\u8bbe\u7f6e\u4e3a255\u6216\u80051(\u5982\u679c\u5bf9\u56fe\u50cf\u6570\u636e\u505a\u4e86\u5f52\u4e00\u5316\u64cd\u4f5c\uff0c\u5219\u4e3a1)\n# channel_axis\u8868\u793a\u989c\u8272\u901a\u9053\u4f4d\u4e8e\u56fe\u50cf\u7684\u7b2c\u51e0\u7ef4\u5ea6\uff0c\u5982\u679c\u4e0d\u6307\u5b9a\u7684\u8bdd\uff0c\u5219\u9ed8\u8ba4\u8f93\u5165\u7070\u5ea6\u56fe\u50cf\nssim = structural_similarity(im1, im2, win_size=None, gradient=False, data_range=None, \n        channel_axis=None, multichannel=False, gaussian_weights=False, full=False)\n</code></pre> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u4e8e\uff1a2022\u5e744\u670819\u65e5</p>"},{"location":"other/email/","title":"\u90ae\u4ef6\u6a21\u677f","text":""},{"location":"other/email/#_2","title":"\u5411\u4f5c\u8005\u54a8\u8be2\u95ee\u9898","text":""},{"location":"other/email/#_3","title":"\u6a21\u677f","text":"<p>\u9996\u6b21\u8be2\u95ee</p> <p>\u9898\u76ee\uff1aA question(Some questions) of paper \u201cXXX\u201d</p> <p>Dear Dr. XX,</p> <p>I am a student at XXX (Qilu University of Technology).</p> <p>I have carefully studied your paper which name is \u201cXXX\u201d. After reading your paper, I think it is of great research significance to XXX. Thank you for your contribution to XXX (Domain Adaptive Object Detection).</p> <p>However, after reading your paper, I encountered some problems. I would be very grateful if you could give me some suggestions:</p> <p>\u2460</p> <p>\u2461</p> <p>I sincerely hope that my problems will not cause you any trouble. Looking forward to your reply. Thank you.</p> <p>Sincerely yours,</p> <p>XXX</p> <p>\u518d\u6b21\u8be2\u95ee</p> <p>\u9898\u76ee\uff1aA question(Some questions) of paper \u201cXXX\u201d</p> <p>Dear Dr. XX</p> <p>I\u2019m sorry to bother you again.</p> <p>Thank you for your patient help, but  I have one more question for this paper. </p> <p>\u2460</p> <p>I would be very grateful if you could help me. Thank you.</p> <p>Sincerely yours,</p> <p>XXX</p>"},{"location":"other/email/#_4","title":"\u53e5\u5b50","text":"<p>\u2460\u6211\u60f3\u77e5\u9053XXX\uff1a I was wondering if</p> <p>\u4f8b\uff1aI was wondering if it is necessary to add a loss function here.</p> <p>\u6211\u60f3\u77e5\u9053\u6709\u5fc5\u8981\u5728\u8fd9\u91cc\u6dfb\u52a0\u4e00\u4e2a\u635f\u5931\u51fd\u6570\u5417\uff1f</p> <p>\u2461XXX\u6709\u53ef\u80fd\u5417\uff1aWould it be possible</p> <p>\u4f8b\uff1aWould it be possible to establish the connection between modules A and B?</p> <p>\u5728\u6a21\u5757A\u548c\u6a21\u5757B\u4e4b\u95f4\u6709\u53ef\u80fd\u5efa\u7acb\u8d77\u8054\u7cfb\u5417\uff1f</p> <p>\u2462\u6211\u771f\u5fc3\u5e0c\u671b\u6211\u7684\u95ee\u9898\u4e0d\u4f1a\u6253\u6270\u5230\u60a8</p> <p>I sincerely hope that my question will not bother you.</p> <p>\u2463\u5982\u679c\u7740\u6025\u7684\u8bdd\u53ef\u4ee5\u52a0\u4e0a\u8fd9\u53e5\u8bdd</p> <p>These questions are very important to me, and looking forward to your help. Thank you.</p> <p>\u8fd9\u4e9b\u95ee\u9898\u5bf9\u6211\u6765\u8bf4\u975e\u5e38\u91cd\u8981\uff0c\u671f\u5f85\u60a8\u7684\u5e2e\u52a9\uff0c\u8c22\u8c22\u3002</p>"},{"location":"other/email/#_5","title":"\u8be2\u95ee\u4ee3\u7801","text":""},{"location":"other/email/#_6","title":"\u6a21\u677f","text":"<p>\u9898\u76ee\uff1aA request for code of paper \u201cXXX\u201d</p> <p>Dear Dr. XXX,</p> <p>Hello Professor, I am sorry to disturb you in your busy schedule. I\u2019m a student of XXX from China.</p> <p>Recently, I\u2019m research on XXX (Domain Adaptive Object Detection). Your paper named \u201cXXX\u201d gives me great inspiration. However, I encountered some problems when I implemented the idea in the paper. I was wondering if you can send me the source code. I promise they will only be used for research purposes.</p> <p>No matter whether you agree to share the source code with me or not, best wishes to you.</p> <p>Looking forward to your reply. Thank you.</p> <p>Sincerely yours,</p> <p>XXX</p>"},{"location":"other/email/#_7","title":"\u56de\u590d\u611f\u8c22\u4fe1","text":""},{"location":"other/email/#_8","title":"\u6a21\u677f","text":"<p>Dear Dr.XX,</p> <p>Thank you for your kind support and clear explanation. That helps me understand your paper more deeply, which means a lot to my study.</p> <p>Sincerely yours,</p> <p>XXX</p>"},{"location":"other/email/#_9","title":"\u53e5\u5b50","text":"<p>\u5bf9\u4e8e\u60a8\u7684\u5e2e\u52a9\uff0c\u8a00\u8bed\u65e0\u6cd5\u8868\u8fbe\u6211\u7684\u611f\u6fc0\u4e4b\u60c5\u3002</p> <p>My appreciation to you for your assistance is beyond words.</p> <p>\u8fd9\u5bf9\u6211\u5e2e\u52a9\u5f88\u5927\uff0c\u975e\u5e38\u611f\u8c22\u60a8\u7684\u5e2e\u52a9</p> <p>It is very helpful to me. Thank you very much for your help.</p> <p>\u8fd9\u8ba9\u6211\u5bf9\u8fd9\u4e2a\u6a21\u5757\u6709\u4e86\u8fdb\u4e00\u6b65\u7684\u7406\u89e3</p> <p>This gives me a further understanding of this module.</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\uff1a2022\u5e745\u67084\u65e5\uff0c\u672a\u5b8c\u5f85\u7eed</p> <p>\u4ee5\u4e0a\u4ec5\u662f\u4e2a\u4eba\u5e73\u65f6\u7684\u603b\u7ed3\uff0c\u82e5\u6709\u8bed\u6cd5\u9519\u8bef\u6216\u8005\u8868\u8ff0\u4e0d\u5f53\u7684\u5730\u65b9\uff0c\u6b22\u8fce\u6307\u6b63</p>"},{"location":"other/program/","title":"\u5e38\u7528\u7a0b\u5e8f","text":""},{"location":"other/program/#_2","title":"\u6df1\u5ea6\u5b66\u4e60\u76f8\u5173","text":"<p>\u63a7\u5236\u968f\u673a\u79cd\u5b50</p> <pre><code>torch.manual_seed(opt.seed)\ntorch.cuda.manual_seed(opt.seed)\ntorch.cuda.manual_seed_all(opt.seed)\nnp.random.seed(opt.seed)  # Numpy module.\nrandom.seed(opt.seed)  # Python random module.\ntorch.manual_seed(opt.seed)\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.deterministic = True\nprint('seed: ', opt.seed)\n</code></pre> <p>\u6a21\u578bmodel\u4e0e\u53c2\u6570state_dict\u6709\u90e8\u5206\u6a21\u5757\u53c2\u6570\u91cd\u5408\uff0c\u52a0\u8f7d\u91cd\u5408\u6a21\u5757\u7684\u53c2\u6570</p> <pre><code>checkpoint = torch.load(args.pretrained)\nstate_dict = checkpoint['state_dict']\nmodel_dict_old = model.state_dict()\nmodel_dict_new = {}\nfor k, v in state_dict.items():\n    if k in model_dict_old:\n        model_dict_new[k] = v\nmodel_dict_old.update(model_dict_new)\nmodel.load_state_dict(model_dict_old)\n</code></pre>"},{"location":"other/program/#_3","title":"\u76ee\u6807\u68c0\u6d4b\u6807\u7b7e\u8f6c\u6362","text":"<p>json2txt</p> <p>\u2003\u2003json\u5305\u62ec\u6570\u636e\u96c6\u4e2d\u6240\u6709\u7684\u56fe\u50cf\u6807\u6ce8\uff08\u6574\u4e2a\u6570\u636e\u96c6\u5bf9\u5e94\u4e00\u4e2ajson\u6587\u4ef6\uff09\uff0ctxt\u4ee5\u56fe\u50cf\u4e3a\u5355\u4f4d\u5b58\u50a8\u6807\u6ce8\uff08\u4e00\u4e2a\u56fe\u50cf\u5bf9\u5e94\u4e00\u4e2atxt\u6587\u4ef6\uff09</p> <pre><code># \u4f20\u5165json\u6587\u4ef6\u8def\u5f84\u548ctxt\u4fdd\u5b58\u7684\u8def\u5f84\ndef json2txt(json_path, out_path):\n    with open(json_path, 'r') as f:\n        data = json.load(f)\n\n    # Create a directory to store txt files\n    output_folder = out_path\n\n    # Group annotations by image ID\n    image_annotations = {}\n    for annotation in data['annotations']:\n        image_id = annotation['image_id']\n        if image_id not in image_annotations:\n            image_annotations[image_id] = []\n        image_annotations[image_id].append(annotation)\n\n    # Write annotations to txt files\n    for image in data['images']:\n        image_id = image['id']\n        image_file_name = image['file_name']\n        annotations = image_annotations.get(image_id, [])\n        txt_file_name = os.path.join(output_folder, f\"{image_file_name.split('/')[-1][:-4]}.txt\")\n        with open(txt_file_name, 'w') as txt_file:\n            for annotation in annotations:\n                category_id = annotation['category_id']\n                bbox = annotation['bbox']\n                # \u8f93\u51fa\u5206\u522b\u4e3a\u7c7b\u522b\u3001bbox\u5750\u6807\n                txt_file.write(f\"{category_id} {bbox[0]} {bbox[1]} {bbox[2]} {bbox[3]}\\n\")\n</code></pre>"},{"location":"other/program/#_4","title":"\u6a21\u578b\u8bc4\u4ef7\u90e8\u5206","text":"<p>\u7ed8\u5236\u6df7\u6dc6\u77e9\u9635\u56fe</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\ndef plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n    \"\"\"\n    \u7ed8\u5236\u6df7\u6dc6\u77e9\u9635\u56fe\n\n    \u53c2\u6570\uff1a\n    cm : array-like, shape = [n_classes, n_classes]\n        \u6df7\u6dc6\u77e9\u9635\n    classes : list\n        \u7c7b\u522b\u540d\u79f0\u5217\u8868\n    normalize : bool, optional\n        \u662f\u5426\u8fdb\u884c\u5f52\u4e00\u5316\n    title : str, optional\n        \u56fe\u8868\u6807\u9898\n    cmap : colormap, optional\n        \u989c\u8272\u6620\u5c04\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"\u5f52\u4e00\u5316\u6df7\u6dc6\u77e9\u9635:\")\n    else:\n        print('\u6df7\u6dc6\u77e9\u9635, \u4e0d\u8fdb\u884c\u5f52\u4e00\u5316')\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] &gt; thresh else \"black\")\n\n    plt.ylabel('\u771f\u5b9e\u6807\u7b7e')\n    plt.xlabel('\u9884\u6d4b\u6807\u7b7e')\n    plt.tight_layout()\n\n# \u793a\u4f8b\u7684\u771f\u5b9e\u6807\u7b7e\u548c\u9884\u6d4b\u6807\u7b7e\ny_true = np.array([0, 1, 2, 2, 1, 0, 2])\ny_pred = np.array([0, 1, 1, 2, 1, 0, 2])\n\n# \u8ba1\u7b97\u6df7\u6dc6\u77e9\u9635\ncm = confusion_matrix(y_true, y_pred)\n\n# \u5b9a\u4e49\u7c7b\u522b\u540d\u79f0\nclasses = ['\u7c7b\u522b1', '\u7c7b\u522b2', '\u7c7b\u522b3']\n\n# \u7ed8\u5236\u6df7\u6dc6\u77e9\u9635\u56fe\nplt.figure()\nplot_confusion_matrix(cm, classes, title='\u6df7\u6dc6\u77e9\u9635', normalize=False)\nplt.show()\n</code></pre>"},{"location":"other/program/#_5","title":"\u5904\u7406\u6587\u4ef6","text":"<p>\u904d\u5386\u6307\u5b9a\u7684\u76ee\u5f55\u53ca\u5b50\u76ee\u5f55</p> <pre><code>import os\n\ndef list_files_in_directory(directory):\n    \"\"\"\n    \u5217\u51fa\u6307\u5b9a\u76ee\u5f55\u53ca\u5176\u5b50\u76ee\u5f55\u4e2d\u7684\u6240\u6709\u6587\u4ef6\n    \"\"\"\n    for dirpath, dirnames, filenames in os.walk(directory):\n        print(f'\u5f53\u524d\u76ee\u5f55: {dirpath}')\n        print(f'\u5305\u542b\u7684\u5b50\u76ee\u5f55: {dirnames}')\n        print(f'\u5305\u542b\u7684\u6587\u4ef6: {filenames}')\n        print('-----')\n\nif __name__ == \"__main__\":\n    directory_path = input(\"\u8bf7\u8f93\u5165\u8981\u5217\u51fa\u6587\u4ef6\u7684\u76ee\u5f55\u8def\u5f84: \")\n    list_files_in_directory(directory_path)\n</code></pre>"},{"location":"other/program/#_6","title":"\u8ba1\u7b97\u4e00\u4e2a\u6587\u4ef6\u5939\u5185\u6240\u6709\u6307\u5b9a\u540e\u7f00\u6587\u4ef6\u7684\u6570\u91cf","text":"<pre><code>import os\n\n# \u5b9a\u4e49\u5141\u8bb8\u7684\u56fe\u7247\u6269\u5c55\u540d\nIMAGE_EXTENSIONS = {'.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff'}\n\ndef is_image_file(filename):\n    \"\"\"\n    \u5224\u65ad\u6587\u4ef6\u662f\u5426\u4e3a\u56fe\u7247\u6587\u4ef6\n    \"\"\"\n    extension = os.path.splitext(filename)[1].lower()\n    return extension in IMAGE_EXTENSIONS\n\ndef count_images_in_directory(directory):\n    \"\"\"\n    \u8ba1\u7b97\u6307\u5b9a\u76ee\u5f55\u53ca\u5176\u5b50\u76ee\u5f55\u4e2d\u7684\u56fe\u7247\u6570\u91cf\n    \"\"\"\n    image_count = 0\n    for root, _, files in os.walk(directory):\n        for file in files:\n            if is_image_file(file):\n                image_count += 1\n    return image_count\n\nif __name__ == \"__main__\":\n    directory_path = input(\"\u8bf7\u8f93\u5165\u8981\u8ba1\u7b97\u56fe\u7247\u6570\u91cf\u7684\u6587\u4ef6\u5939\u8def\u5f84: \")\n    total_images = count_images_in_directory(directory_path)\n    print(f\"\u6587\u4ef6\u5939 '{directory_path}' \u5185\u5171\u6709 {total_images} \u5f20\u56fe\u7247\u3002\")\n</code></pre>"},{"location":"other/program/#pdf","title":"PDF\u76f8\u5173","text":"<p>\u5408\u5e76PDF</p> <p>\u7528\u5230\u7684\u5e93<code>PyPDF2</code></p> <pre><code>def merge_pdfs(input_pdf_paths, output_pdf_path):\n    # \u521b\u5efa\u4e00\u4e2aPdfWriter\u5bf9\u8c61\u6765\u4fdd\u5b58\u5408\u5e76\u540e\u7684PDF\n    pdf_writer = PyPDF2.PdfWriter()\n\n    # \u904d\u5386\u6240\u6709\u8f93\u5165PDF\u6587\u4ef6\uff0c\u5e76\u5c06\u5b83\u4eec\u6dfb\u52a0\u5230PdfWriter\u4e2d\n    for pdf_path in input_pdf_paths:\n        with open(pdf_path, 'rb') as pdf_file:\n            pdf_reader = PyPDF2.PdfReader(pdf_file)\n            # \u904d\u5386\u6bcf\u4e00\u9875\uff0c\u5c06\u5176\u6dfb\u52a0\u5230PdfWriter\n            for page_num in range(len(pdf_reader.pages)):\n                page = pdf_reader.pages[page_num]\n                pdf_writer.add_page(page)\n\n    # \u5c06\u5408\u5e76\u540e\u7684PDF\u4fdd\u5b58\u5230\u8f93\u51fa\u6587\u4ef6\u4e2d\n    with open(output_pdf_path, 'wb') as output_pdf:\n        pdf_writer.write(output_pdf)\n\n# \u5f85\u5408\u5e76\u7684PDF\u6587\u4ef6\u8def\u5f84\ninput_pdf_paths = ['XXX.pdf', 'XXX.pdf']\n# \u8f93\u51fa\u7684PDF\u540d\u5b57\noutput_pdf_path = 'XXX.pdf'\n# \u8c03\u7528\u51fd\u6570\u8fdb\u884c\u5408\u5e76\nmerge_pdfs(input_pdf_paths, output_pdf_path)\n</code></pre> <p>\u5c06\u591a\u4e2a\u56fe\u7247\u5408\u5e76\u4e3aPDF</p> <p>\u7528\u5230\u7684\u5e93<code>PIL</code></p> <pre><code>from PIL import Image\n\ndef convert_jpgs_to_pdf(jpg_file_paths, pdf_file_path):\n    img = Image.open(jpg_file_paths[0])\n    # \u83b7\u53d6\u7b2c\u4e00\u4e2a\u56fe\u50cf\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6\n    width, height = img.size\n    # \u521b\u5efaPDF\u5bf9\u8c61\n    pdf = Image.new('RGB', (width, height * len(jpg_file_paths)), 'white')\n    for i, jpg_file_path in enumerate(jpg_file_paths):\n        img = Image.open(jpg_file_path)\n        # \u5c06JPEG\u56fe\u50cf\u7c98\u8d34\u5230PDF\u4e2d\n        pdf.paste(img, (0, i * height))\n    # \u4fdd\u5b58PDF\u6587\u4ef6\n    pdf.save(pdf_file_path, 'PDF', resolution=100.0)\n\n# \u66ff\u6362\u4e3a\u4f60\u7684JPEG\u6587\u4ef6\u8def\u5f84\u5217\u8868\u548cPDF\u6587\u4ef6\u8def\u5f84\njpg_file_paths = ['image1.jpg', 'image2.jpg']\npdf_file_path = 'output.pdf'\n</code></pre> <p>\u5c06docx\u6587\u4ef6\u8f6c\u4e3apdf</p> <p>\u7528\u5230\u7684\u5e93<code>docx2pdf</code></p> <pre><code>from docx2pdf import convert\n\n# \u66ff\u6362\u4e3a\u4f60\u7684Word\u6587\u4ef6\u8def\u5f84\u548cPDF\u6587\u4ef6\u8def\u5f84\nword_file_path = 'document.docx'\npdf_file_path = 'document.pdf'\n\n# \u5c06Word\u6587\u6863\u8f6c\u6362\u4e3aPDF\nconvert(word_file_path, pdf_file_path)\n</code></pre>"},{"location":"other/website/","title":"\u7f51\u7ad9\u6c47\u603b","text":""},{"location":"other/website/#_2","title":"\u8bba\u6587","text":""},{"location":"other/website/#_3","title":"\u627e\u8bba\u6587","text":"<ul> <li>\u8c37\u6b4c\u5b66\u672f\uff1ahttps://scholar.google.com</li> <li>Paper With Code\uff1ahttps://paperswithcode.com/sota</li> <li>AMiner\uff1ahttps://www.aminer.cn</li> <li>dblp\uff1ahttps://dblp.org\uff0c\u4f8b\uff1aCVPR\uff1ahttps://dblp.uni-trier.de/db/conf/cvpr/index.html\uff08\u76f4\u63a5\u6539\u4f1a\u8bae\u7b80\u79f0\uff09</li> <li>ICLR\uff1ahttps://iclr.cc/\uff08\u4f8b\u5982ICLR2023\uff1ahttps://iclr.cc/virtual/2023/papers.html?filter=titles\uff0c\u76f4\u63a5\u6539\u65f6\u95f4\u5373\u53ef\uff09</li> <li>ICML\uff1ahttps://icml.cc/\uff08\u4f8b\u5982ICML2023\uff1ahttps://icml.cc/virtual/2023/papers.html?filter=titles\uff0c\u76f4\u63a5\u6539\u65f6\u95f4\u5373\u53ef\uff09</li> <li>NIPS\uff1ahttps://proceedings.neurips.cc</li> <li>CVF\uff1ahttps://openaccess.thecvf.com</li> <li>OpenReview\uff1ahttps://openreview.net</li> <li>ECCV\uff1ahttps://www.ecva.net/papers.php</li> <li>ACM\uff1ahttps://dl.acm.org/conference/mm/proceedings\uff08\u5b98\u7f51\u5730\u5740\uff1ahttps://www.acmmmasia.org/\uff09</li> <li>SCI\uff1ahttps://www.sciencedirect.com</li> <li>IEEE Xplore\uff1ahttps://ieeexplore.ieee.org</li> <li>Arxiv\uff1ahttps://arxiv.org</li> </ul> <p>\u5199\u8bba\u6587</p> <ul> <li>Overleaf\uff1ahttps://cn.overleaf.com</li> <li>IEEE\u5b98\u65b9\u8bba\u6587\u6a21\u677f\uff1ahttps://template-selector.ieee.org/secure/templateSelector/publicationType</li> <li>SCI\u8bba\u6587\u914d\u8272\uff1ahttp://lcpmgh.com/colors/</li> </ul> <p>\u627e\u6e90\u7801</p> <ul> <li>CatalyzeX\uff1ahttps://www.catalyzex.com/</li> <li>Paper With Code\uff1ahttps://paperswithcode.com/sota</li> </ul>"},{"location":"other/website/#_4","title":"\u671f\u520a\u5b98\u7f51","text":"<p>\u6295\u7a3f/\u5ba1\u7a3f</p> <ul> <li>Neurocomputing\uff1ahttps://www2.cloud.editorialmanager.com/neucom/default2.aspx</li> <li>Pattern Recognition Letters (PRL)\uff1ahttps://www2.cloud.editorialmanager.com/prletters/default2.aspx</li> </ul>"},{"location":"other/website/#_5","title":"\u4f1a\u8bae","text":"<ul> <li>VALSE\u89c6\u89c9\u4e0e\u5b66\u4e60\u9752\u5e74\u5b66\u8005\u7814\u8ba8\u4f1a\uff1ahttp://valser.org</li> </ul>"},{"location":"other/website/#_6","title":"\u4fe1\u606f\u67e5\u8be2","text":"<p>\u57fa\u91d1\u67e5\u8be2</p> <ul> <li>\u56fd\u81ea\u7136\u5b98\u7f51-\u9879\u76ee\u67e5\u8be2\uff1ahttps://kd.nsfc.cn/fundingProjectInit</li> </ul> <p>\u5b66\u672f\u4fe1\u606f</p> <ul> <li>Web Of Science\uff1ahttps://www.webofscience.com</li> <li>ORCID\uff1ahttps://orcid.org</li> </ul> <p>SCI\u671f\u520a\u4fe1\u606f\u67e5\u8be2</p> <ul> <li>LetPub\uff1ahttps://www.letpub.com.cn/index.php?page=journalapp</li> </ul> <p>CCF\u4f1a\u8bae\u63a8\u8350\u7b49\u7ea7</p> <ul> <li>CCF\u5b98\u7f51\uff1ahttps://www.ccf.org.cn/Academic_Evaluation/By_category/</li> </ul> <p>\u4e13\u5229\u67e5\u8be2</p> <ul> <li>\u4e13\u5229\u68c0\u7d22\u53ca\u5206\u6790\uff1ahttps://pss-system.cponline.cnipa.gov.cn/conventionalSearch</li> <li>\u4e2d\u56fd\u4e13\u5229\u516c\u5e03\u516c\u544a\uff1ahttp://epub.cnipa.gov.cn</li> <li>\u4e2d\u56fd\u4e13\u5229\u4e0b\u8f7d\u7f51\uff1ahttps://www.drugfuture.com/cnpat/cn_patent.asp</li> </ul> <p>\u8f6f\u4ef6\u8457\u4f5c\u6743\u67e5\u8be2</p> <ul> <li>\u4e2d\u56fd\u7248\u6743\u767b\u8bb0\u67e5\u8be2\u670d\u52a1\u5e73\u53f0\uff1ahttps://register.ccopyright.com.cn/query.html</li> </ul>"},{"location":"other/website/#_7","title":"\u670d\u52a1\u5668\u8d44\u6e90","text":"<ul> <li>Colab\uff1ahttps://colab.google/</li> </ul>"},{"location":"other/website/#python","title":"Python\u5e93","text":"<p>API\u6587\u6863</p> <ul> <li>mmcv\uff1ahttps://mmcv.readthedocs.io/zh_CN/latest/index.html</li> <li>PyTorch\uff1ahttps://pytorch.org/docs/stable/index.html</li> <li>Scikit-learn\uff1ahttps://scikit-learn.org/stable/modules/classes.html</li> <li> <p>OpenCV\uff1ahttps://docs.opencv.org\uff0c\u8865\u5145\uff0cPython\u7248\u672c\uff1ahttps://docs.opencv.org/4.7.0/d6/d00/tutorial_py_root.html\u3001\u4e2d\u6587\u6587\u6863\uff1ahttp://www.woshicver.com</p> </li> <li> <p>Matplotlib\uff1ahttps://matplotlib.org/stable/api/index.html</p> </li> <li>Pandas\uff1ahttps://pandas.pydata.org/docs/reference/index.html</li> <li>Numpy\uff1ahttps://numpy.org/doc/stable/reference/index.html</li> </ul> <p>\u67e5\u8be2\u4ee5\u53ca\u4e0b\u8f7dPython\u5e93</p> <ul> <li> <p>Python Package Index (PyPI)\uff1ahttps://pypi.org</p> </li> <li> <p>LFD\uff1ahttps://www.lfd.uci.edu/~gohlke/pythonlibs</p> </li> </ul> <p>\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u5b98\u7f51</p> <ul> <li>PyTorch\uff1ahttps://pytorch.org</li> <li>TensorFlow\uff1ahttps://www.tensorflow.org/?hl=zh-cn</li> <li>PaddlePaddle\uff1ahttps://www.paddlepaddle.org.cn</li> </ul>"},{"location":"other/website/#gpt","title":"GPT","text":"<ul> <li>GPT3.5\uff1ahttps://chatbot.theb.ai/#/chat/1002</li> <li>OpenAI\uff1ahttps://chat.openai.com</li> </ul> <p>\u63d0\u793a\u8bcd\u76f8\u5173</p> <ul> <li>prompts\uff1ahttps://prompts.chat/\uff08\u82f1\u6587\uff09</li> <li>ChatGPT SC\uff1ahttps://www.aishort.top/</li> <li>\u6559\u7a0b\u5408\u96c6\uff1ahttps://gpt.candobear.com/</li> <li>\u5176\u4ed6\uff1ahttp://www.atoolbox.net/Tool.php?Id=1100</li> </ul>"},{"location":"other/website/#_8","title":"\u90ae\u7bb1","text":"<ul> <li>Gmail\uff1ahttps://mail.google.com/</li> </ul>"},{"location":"other/website/#_9","title":"\u955c\u50cf\u6e90","text":"<ul> <li>\u6e05\u534e\u5927\u5b66\uff1ahttps://mirrors.tuna.tsinghua.edu.cn</li> <li>\u963f\u91cc\u4e91\uff1ahttps://developer.aliyun.com/mirror</li> <li>\u817e\u8baf\uff1ahttps://mirrors.cloud.tencent.com</li> </ul>"},{"location":"other/website/#_10","title":"\u8d44\u6e90\u641c\u7d22","text":"<ul> <li> <p>Medium\uff1ahttps://medium.com</p> </li> <li> <p>\u866b\u90e8\u843d\u5feb\u641c\uff1ahttps://search.chongbuluo.com</p> </li> <li> <p>\u5c0f\u6728\u866b\uff1ahttp://muchong.com/bbs</p> </li> <li> <p>\u9e20\u6469\u641c\u7d22\uff1ahttps://www.jiumodiary.com/\uff08\u641c\u7535\u5b50\u4e66\uff09</p> </li> </ul>"},{"location":"other/website/#_11","title":"\u5728\u7ebf\u5de5\u5177","text":"<ul> <li>\u8bb0\u7075\uff1ahttps://remeins.com/\uff08CAJ\u8f6cPDF\uff09</li> <li>\u5728\u7ebfPDF\u7f16\u8f91\uff1ahttps://www.ilovepdf.com/</li> </ul>"},{"location":"other/website/#_12","title":"\u7f16\u7a0b\u5237\u9898","text":"<ul> <li> <p>\u6d1b\u8c37\uff1ahttps://www.luogu.com.cn</p> </li> <li> <p>\u529b\u6263\uff1ahttps://leetcode.cn</p> </li> </ul>"},{"location":"other/website/#_13","title":"\u7ade\u8d5b/\u793e\u533a","text":"<ul> <li>kaggle\uff1ahttps://www.kaggle.com</li> <li>\u5929\u6c60\uff1ahttps://tianchi.aliyun.com/competition/activeList</li> <li> <p>FlyAI\uff1ahttps://www.flyai.com</p> </li> <li> <p>DataFountain\uff1ahttps://www.datafountain.cn</p> </li> <li> <p>\u548c\u9cb8\u793e\u533a\uff1ahttps://www.heywhale.com/home</p> </li> <li> <p>\u6781\u5e02\uff1ahttps://www.cvmart.net</p> </li> </ul>"},{"location":"other/website/#_14","title":"\u516c\u5f00\u6570\u636e\u96c6\u4e0b\u8f7d","text":"<ul> <li>roboflow\uff1ahttps://universe.roboflow.com/</li> <li>\u98de\u6d46\uff1ahttps://aistudio.baidu.com/datasetoverview</li> <li>\u5929\u6c60\uff1ahttps://tianchi.aliyun.com/dataset</li> </ul>"},{"location":"other/website/#_15","title":"\u5e38\u7528\u8f6f\u4ef6","text":"<ul> <li>\u77e5\u4e91\u6587\u732e\uff1ahttps://www.zhiyunwenxian.cn</li> <li>Ghelper\uff08\u8c37\u6b4c\u8bbf\u95ee\u52a9\u624b\uff09\uff1ahttps://ghelper.net</li> <li>SimpleTex\uff08\u8bc6\u522b\u516c\u5f0f\u56fe\u7247\uff09\uff1ahttps://simpletex.cn/</li> </ul>"},{"location":"other/website/#_16","title":"\u5728\u7ebf\u8f6f\u4ef6","text":"<ul> <li>SPSS\uff1ahttps://spssau.com/index.html</li> </ul>"},{"location":"other/website/#_17","title":"\u5176\u4ed6","text":"<ul> <li>CUDA\u5de5\u5177\u5305\uff1ahttps://developer.nvidia.com/CUDA-TOOLKIT-ARCHIVE</li> </ul>"},{"location":"other_paper/Cycle_GAN/","title":"Cycle GAN","text":""},{"location":"other_paper/Cycle_GAN/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aIEEE International Conference on Computer Vision 2017 (ICCV 2017)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content_ICCV_2017/papers/Zhu_Unpaired_Image-To-Image_Translation_ICCV_2017_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/junyanz/pytorch-CycleGAN-and-pix2pix</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u5bf9\u6297\u751f\u6210\u7f51\u7edc\u3001\u56fe\u50cf\u8f6c\u6362</p>"},{"location":"other_paper/Cycle_GAN/#_2","title":"\u7f51\u7edc\u7ed3\u6784","text":"<p> <p></p> <p></p> <p>\u635f\u5931\u51fd\u6570</p> <p>\u8bba\u6587\u4e2d\u4e3b\u8981\u63d0\u5230\u4e09\u79cd\u635f\u5931\uff1a</p> <ul> <li>\u4e00\u81f4\u6027\u635f\u5931\uff1aA\u57df\u56fe\u50cfX\u4eceA\u8f6c\u6362\u5230B\uff0c\u518d\u4eceB\u8f6c\u56deA\uff0c\u5f97\u5230\u56fe\u50cfY\uff0c\u5c06\u6700\u7ec8\u8f93\u51fa\u7684\u56fe\u50cfY\u548c\u539f\u59cb\u8f93\u5165\u56fe\u50cfX\u505al_1\u635f\u5931\uff0c\u5bf9\u4e8eB\u57df\u7684\u56fe\u50cf\u4e5f\u6709\u7c7b\u4f3c\u7684\u635f\u5931\uff1b</li> <li>\u9274\u522b\u5668A\u548c\u9274\u522b\u5668B\u7684\u5206\u7c7b\u635f\u5931\u3002</li> </ul> <p>\u6e90\u7801\u4e2d\u8fd8\u63d0\u5230\u4e00\u79cd\u635f\u5931\uff1a</p> <ul> <li>identity\u635f\u5931\uff1aA\u57df\u56fe\u50cfX\u4f20\u5165B\u5230A\u7684\u751f\u6210\u5668\u4e2d\uff0c\u5f97\u5230\u56fe\u50cfY\uff0c\u5c06Y\u548cX\u505al_1\u635f\u5931\uff0c\u8bad\u7ec3\u7f51\u7edc\u7684\u8bc6\u522b\u80fd\u529b\uff0c\u8f85\u52a9\u7f51\u7edc\u771f\u6b63\u7406\u89e3A\u57df\u4fe1\u606f\uff0c\u5bf9\u4e8eA\u5230B\u7684\u751f\u6210\u5668\u6709\u7c7b\u4f3c\u7684\u635f\u5931\u3002</li> </ul>"},{"location":"other_paper/Cycle_GAN/#_3","title":"\u751f\u6210\u5668","text":"<p>\u4ee5ResNet\u4e3a\u57fa\u7840</p> <pre><code>class ResnetGenerator(nn.Module):\n    \"\"\"Resnet-based generator that consists of Resnet blocks between a few downsampling/upsampling operations.\n\n    We adapt Torch code and idea from Justin Johnson's neural style transfer project(https://github.com/jcjohnson/fast-neural-style)\n    \"\"\"\n\n    def __init__(self, input_nc, output_nc, ngf=64, norm_layer=nn.BatchNorm2d, use_dropout=False, n_blocks=6, padding_type='reflect'):\n        \"\"\"Construct a Resnet-based generator\n\n        Parameters:\n            input_nc (int)      -- \u8f93\u5165\u56fe\u7247\u7684\u901a\u9053\u6570(the number of channels in input images)\n            output_nc (int)     -- \u671f\u671b\u8f93\u51fa\u56fe\u7247\u7684\u901a\u9053\u6570(the number of channels in output images)\n            ngf (int)           -- \u91c7\u6837\u5f00\u59cb\u65f6\u7684\u901a\u9053\u6570\uff0c\u9ed8\u8ba464(the number of filters in the last conv layer)\n            norm_layer          -- \u6807\u51c6\u5316\u5c42(normalization layer)\n            use_dropout (bool)  -- ResNet\u5377\u79ef\u6a21\u5757\u662f\u5426\u4f7f\u7528dropout\u5c42(if use dropout layers)\n            n_blocks (int)      -- ResNet\u5377\u79ef\u6a21\u5757\u7684\u6570\u91cf(the number of ResNet blocks)\n            padding_type (str)  -- \u586b\u5145\u64cd\u4f5c\u65b9\u6cd5(the name of padding layer in conv layers: reflect | replicate | zero)\n        \"\"\"\n        assert(n_blocks &gt;= 0)\n        super(ResnetGenerator, self).__init__()\n        if type(norm_layer) == functools.partial:\n            use_bias = norm_layer.func == nn.InstanceNorm2d\n        else:\n            use_bias = norm_layer == nn.InstanceNorm2d\n        # nn.ReflectionPad2d\u8868\u793a\u955c\u50cf\u586b\u5145\n        # \u5b9a\u4e49\u7b2c\u4e00\u4e2a\u5377\u79ef\u6a21\u5757\uff0c\u5c06\u56fe\u7247\u901a\u9053\u6570\u8c03\u6574\u4e3a64\n        model = [nn.ReflectionPad2d(3),\n                 nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0, bias=use_bias),\n                 norm_layer(ngf),\n                 nn.ReLU(True)]\n\n        n_downsampling = 2\n        # \u6dfb\u52a0\u4e0b\u91c7\u6837\u5c42\n        for i in range(n_downsampling):  # add downsampling layers\n            # i\u8868\u793a\u4e0b\u91c7\u6837\u7684\u6b21\u6570\uff0cmult\u8868\u793a\u901a\u9053\u653e\u5927\u7684\u500d\u6570\uff0c\u901a\u9053\u53d8\u5316\u60c5\u51b564-&gt;128-&gt;256\u3002\n            # \u5e76\u4e14\u6bcf\u4e0b\u91c7\u6837\u4e00\u6b21\uff0c\u56fe\u7247\u957f\u5bbd\u5c3a\u5bf8\u53d8\u4e3a\u539f\u6765\u7684\u4e8c\u5206\u4e4b\u4e00\n            mult = 2 ** i\n            model += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1, bias=use_bias),\n                      norm_layer(ngf * mult * 2),\n                      nn.ReLU(True)]\n\n        mult = 2 ** n_downsampling\n        # \u6dfb\u52a0ResNet\u6a21\u5757\uff0c\u5373\u4e3b\u8981\u7684\u7279\u5f81\u63d0\u53d6\uff0c\u6570\u636e\u8f6c\u6362\u6a21\u5757\n        for i in range(n_blocks):\n            # padding_type\u8868\u793a\u586b\u5145\u7c7b\u578b\uff0cnorm_layer\u8868\u793a\u5f52\u4e00\u5316\u5c42\uff0cuse_dropout\u8868\u793a\u662f\u5426\u4f7f\u7528dropout\uff0cuse_bias\u8868\u793a\u5377\u79ef\u5c42\u662f\u5426\u4f7f\u7528\u504f\u7f6e\u53c2\u6570\n            model += [ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout, use_bias=use_bias)]\n        # \u6dfb\u52a0\u4e0a\u91c7\u6837\u5c42\uff0c\u8fd9\u91cc\u4e0e\u4e0b\u91c7\u6837\u5c42\u7c7b\u4f3c\n        for i in range(n_downsampling):  # add upsampling layers\n            mult = 2 ** (n_downsampling - i)\n            # \u552f\u4e00\u4e0d\u540c\u7684\u662f\u8fd9\u91cc\u4f7f\u7528\u9006\u5377\u79ef\u64cd\u4f5c\uff0c\u6765\u6269\u5927\u56fe\u50cf\u5c3a\u5bf8\n            model += [nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2),\n                                         kernel_size=3, stride=2,\n                                         padding=1, output_padding=1,\n                                         bias=use_bias),\n                      norm_layer(int(ngf * mult / 2)),\n                      nn.ReLU(True)]\n        # \u6dfb\u52a0\u6700\u540e\u4e00\u5c42\u5377\u79ef\u6a21\u5757\uff0c\u5c06\u56fe\u50cf\u901a\u9053\u6570\u4ece64\u8f6c\u6362\u4e3a\u6307\u5b9a\u7684\u901a\u9053\u6570\uff0c\u5982\u679c\u662f\u4e09\u8272\u56fe\uff0c\u5219\u5c06\u8f93\u51fa\u901a\u9053\u6570\u8f6c\u4e3a3\n        model += [nn.ReflectionPad2d(3)]\n        model += [nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0)]\n        model += [nn.Tanh()]\n        # \u5c06\u6a21\u578b\u64cd\u4f5c\u5408\u5e76\n        self.model = nn.Sequential(*model)\n\n    def forward(self, input):\n        \"\"\"Standard forward\"\"\"\n        return self.model(input)\n</code></pre>"},{"location":"other_paper/Cycle_GAN/#_4","title":"\u4e3b\u8981\u7684\u5377\u79ef\u6a21\u5757","text":"<pre><code>class ResnetBlock(nn.Module):\n    \"\"\"Define a Resnet block\"\"\"\n\n    def __init__(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n        \"\"\"Initialize the Resnet block\n\n        A resnet block is a conv block with skip connections\n        We construct a conv block with build_conv_block function,\n        and implement skip connections in &lt;forward&gt; function.\n        Original Resnet paper: https://arxiv.org/pdf/1512.03385.pdf\n        \"\"\"\n        super(ResnetBlock, self).__init__()\n        # \u5b9a\u4e49\u4e3b\u8981\u7684\u5377\u79ef\u6a21\u5757\uff0c\u5305\u62ec\u5377\u79ef\u5c42\u548cdropout\u5c42\n        self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, use_dropout, use_bias)\n\n    def build_conv_block(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n        \"\"\"Construct a convolutional block.\n\n        Parameters:\n            dim (int)           -- the number of channels in the conv layer.\n            padding_type (str)  -- the name of padding layer: reflect | replicate | zero\n            norm_layer          -- normalization layer\n            use_dropout (bool)  -- if use dropout layers.\n            use_bias (bool)     -- if the conv layer uses bias or not\n\n        Returns a conv block (with a conv layer, a normalization layer, and a non-linearity layer (ReLU))\n        \"\"\"\n        conv_block = []\n        p = 0\n        # \u586b\u5145\u7b56\u7565\uff0c\u8fd9\u91cc\u4e5f\u53ef\u4ee5\u901a\u8fc7\u6307\u5b9aConv2d\u91cc\u7684\u53c2\u6570\u6765\u5b9e\u73b0\u9009\u62e9\u586b\u5145\u7684\u7b56\u7565\n        # reflect\u8868\u793a\u955c\u50cf\u586b\u5145\uff0c\u4ee5\u77e9\u9635\u8fb9\u7f18\u4e3a\u5bf9\u79f0\u8f74\uff0c\u5c06\u53cd\u65b9\u5411\u7684\u5bf9\u79f0\u5143\u7d20\u586b\u5145\u5230\u6700\u5916\u56f4\n        if padding_type == 'reflect':\n            conv_block += [nn.ReflectionPad2d(1)]\n        # replicate\u8868\u793a\u590d\u5236\u586b\u5145\uff0c\u4f7f\u7528\u8f93\u5165\u8fb9\u754c\u7684\u590d\u5236\u503c\u586b\u5145\u5f20\u91cf\n        elif padding_type == 'replicate':\n            conv_block += [nn.ReplicationPad2d(1)]\n        # zero\u8868\u793a\u96f6\u586b\u5145\n        elif padding_type == 'zero':\n            p = 1\n        else:\n            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n        # \u6dfb\u52a0\u4e00\u5c42\u5377\u79ef\u5c42\n        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim), nn.ReLU(True)]\n        # \u5982\u679c\u6307\u5b9ause_dropout\u4e3atrue\u7684\u8bdd\uff0c\u5219\u6dfb\u52a0\u4e00\u5c42dropout\u5c42\n        if use_dropout:\n            conv_block += [nn.Dropout(0.5)]\n\n        # \u4e0b\u9762\u518d\u5b9a\u4e49\u4e00\u5c42\u5377\u79ef\uff0c\u548c\u4e0a\u9762\u4e00\u6837\uff0c\u5148\u9009\u62e9\u586b\u5145\u7b56\u7565\uff0c\u518d\u6dfb\u52a0\u5377\u79ef\u5c42\n        p = 0\n        if padding_type == 'reflect':\n            conv_block += [nn.ReflectionPad2d(1)]\n        elif padding_type == 'replicate':\n            conv_block += [nn.ReplicationPad2d(1)]\n        elif padding_type == 'zero':\n            p = 1\n        else:\n            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim)]\n        # \u5c06\u6240\u6709\u7684\u6a21\u5757(\u586b\u5145\u5c42(\u5982\u679c\u6709\u7684\u8bdd)\u3001\u5377\u79ef\u5c42\u3001dropout\u5c42)\u5408\u5e76\u4e3a\u4e00\u4e2a\u6a21\u5757\n        return nn.Sequential(*conv_block)\n\n    def forward(self, x):\n        \"\"\"Forward function (with skip connections)\"\"\"\n        # \u6dfb\u52a0\u8df3\u8dc3\u8fde\u63a5\uff0c\u5373\u6b8b\u5dee\u6620\u5c04\n        # \u7279\u5f81\u56fe\u5148\u7ecf\u8fc7\u5b9a\u4e49\u597d\u7684\u5377\u79ef\u6a21\u5757\uff0c\u518d\u4e0e\u8f93\u5165\u7279\u5f81\u56fe\u76f8\u52a0\n        out = x + self.conv_block(x)  # add skip connections\n        return out\n</code></pre>"},{"location":"other_paper/Cycle_GAN/#_5","title":"\u5224\u522b\u5668","text":"<pre><code>class NLayerDiscriminator(nn.Module):\n    \"\"\"Defines a PatchGAN discriminator\"\"\"\n\n    def __init__(self, input_nc, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d):\n        \"\"\"Construct a PatchGAN discriminator\n\n        Parameters:\n            input_nc (int)  -- the number of channels in input images\n            ndf (int)       -- the number of filters in the last conv layer\n            n_layers (int)  -- the number of conv layers in the discriminator\n            norm_layer      -- normalization layer\n        \"\"\"\n        super(NLayerDiscriminator, self).__init__()\n        if type(norm_layer) == functools.partial:  # no need to use bias as BatchNorm2d has affine parameters\n            use_bias = norm_layer.func == nn.InstanceNorm2d\n        else:\n            use_bias = norm_layer == nn.InstanceNorm2d\n        # \u7b2c\u4e00\u5c42\u5377\u79ef\u7684\u5377\u79ef\u6838\u5c3a\u5bf8\u548cpadding\u5927\u5c0f\uff0c\u8fd9\u91cc\u7684\u5377\u79ef\u6838\u5c3a\u5bf8\u9ed8\u8ba4\u4e3a4\n        kw = 4\n        padw = 1\n        # \u6dfb\u52a0\u7b2c\u4e00\u5c42\u5377\u79ef\uff0c\u4e3b\u8981\u7528\u4e8e\u4e0b\u91c7\u6837\u4ee5\u53ca\u6539\u53d8\u901a\u9053\u6570\uff0c\u5c06\u7279\u5f81\u56fe\u901a\u9053\u6570\u4ece3\u6539\u621064\n        sequence = [nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw), nn.LeakyReLU(0.2, True)]\n        nf_mult = 1\n        nf_mult_prev = 1\n        # \u9010\u4e00\u6dfb\u52a0\u6838\u5fc3\u5377\u79ef\u5c42\u7684\u4e2a\u6570\uff0c\u4e00\u5171\u6dfb\u52a0n_layers\u4e2a\u5377\u79ef\u6a21\u5757(\u8fd9\u91cc\u662f\u4e0d\u662f\u8981\u8bbe\u6210n_layers+1?)\n        # \u6bcf\u4e2a\u5377\u79ef\u6a21\u5757\u5747\u7531\u5377\u79ef\u5c42\u3001\u6807\u51c6\u5316\u5c42\u3001LeakyReLU\u6fc0\u6d3b\u5c42\u6784\u6210\n        for n in range(1, n_layers):  # gradually increase the number of filters\n            # nf_mult_prev\u8868\u793a\u8be5\u6a21\u5757\u8f93\u5165\u7279\u5f81\u56fe\u7684\u901a\u9053\u653e\u5927\u500d\u6570(\u500d\u6570\u76f8\u5bf9\u4e8e64)\n            # \u8fd9\u91cc\u505a\u4e00\u4e2a\u66f4\u65b0\u8d4b\u503c\uff0c\u5373\u4e0a\u4e00\u6a21\u5757\u7684\u8f93\u51fa\u500d\u6570\u4f5c\u4e3a\u8fd9\u4e00\u6a21\u5757\u7684\u8f93\u5165\u500d\u6570\n            nf_mult_prev = nf_mult\n            # nf_mult\u8868\u793a\u8be5\u6a21\u5757\u8f93\u51fa\u7279\u5f81\u56fe\u7684\u901a\u9053\u6570\u653e\u5927\u500d\u6570\uff0c\u6700\u9ad8\u653e\u59278\u500d\uff0c\u5373\u901a\u9053\u6570\u6700\u591a\u4e3a512\n            nf_mult = min(2 ** n, 8)\n            # \u589e\u52a0\u5377\u79ef\u6a21\u5757\n            sequence += [\n                nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=2, padding=padw, bias=use_bias),\n                norm_layer(ndf * nf_mult),\n                nn.LeakyReLU(0.2, True)\n            ]\n        # \u548cfor\u5faa\u73af\u4e2d\u7c7b\u4f3c\uff0c\u6dfb\u52a0\u4e00\u4e2a\u5377\u79ef\u6a21\u5757\n        nf_mult_prev = nf_mult\n        nf_mult = min(2 ** n_layers, 8)\n        sequence += [\n            nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=1, padding=padw, bias=use_bias),\n            norm_layer(ndf * nf_mult),\n            nn.LeakyReLU(0.2, True)\n        ]\n        # \u6dfb\u52a0\u6700\u540e\u4e00\u5c42\u5377\u79ef\uff0c\u8f93\u5165\u901a\u9053\u6570\u8bbe\u5b9a\u4e3a1\uff0c\u5373\u8f93\u51fa\u4e00\u5f20\u9884\u6d4b\u56fe\n        # \u56e0\u4e3a\u662f\u4e8c\u5206\u7c7b\uff0cTrue or False\uff0c\u56e0\u6b64\u53ea\u9700\u8981\u8f93\u51fa\u4e00\u4e2a\u6570\u5373\u53ef\uff0c\u8d8a\u63a5\u8fd1\u4e8e1\u8868\u793a\u8d8a\u503e\u5411\u4e8eTrue\uff0c\u8d8a\u63a5\u8fd10\u8868\u793a\u8d8a\u503e\u5411\u4e8eFasle\n        sequence += [nn.Conv2d(ndf * nf_mult, 1, kernel_size=kw, stride=1, padding=padw)]  # output 1 channel prediction map\n        self.model = nn.Sequential(*sequence)\n\n    def forward(self, input):\n        \"\"\"Standard forward.\"\"\"\n        return self.model(input)\n</code></pre>"},{"location":"other_paper/Cycle_GAN/#_6","title":"\u521d\u59cb\u5316\u53c2\u6570","text":"<pre><code>def weights_init_normal(m):\n    if isinstance(m, nn.Conv2d):\n        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n        if hasattr(m, \"bias\") and m.bias is not None:\n            torch.nn.init.constant_(m.bias.data, 0.0)\n        elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n            torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n            torch.nn.init.constant_(m.bias.data, 0.0)\n</code></pre>"},{"location":"other_paper/Cycle_GAN/#_7","title":"\u8bad\u7ec3\u6d41\u7a0b","text":"<p>\u6570\u636e\u7684\u8f93\u5165\u548c\u53c2\u6570\u7684\u66f4\u65b0\u5728train.py\u6587\u4ef6\u4e2d\u4e3b\u8981\u4f53\u73b0\u5728\u4e24\u884c\u4ee3\u7801\u4e2d</p> <pre><code># \u5c06\u6570\u636e\u4f20\u5165\u6a21\u578b\nmodel.set_input(data)         # unpack data from dataset and apply preprocessing\n# \u66f4\u65b0\u6a21\u578b\u7684\u53c2\u6570\nmodel.optimize_parameters()   # calculate loss functions, get gradients, update network weights\n</code></pre> <p>\u6574\u4e2a\u8bad\u7ec3\u9636\u6bb5\uff08\u524d\u5411\u4f20\u64ad\u3001\u8ba1\u7b97\u635f\u5931\u3001\u53cd\u5411\u4f20\u64ad\u4ee5\u53ca\u66f4\u65b0\u53c2\u6570\uff09\u88ab\u5d4c\u5165\u5230\u4e00\u4e2a\u5927\u7c7b\u4e2d</p> <pre><code>class CycleGANModel(BaseModel):\n    \"\"\"\n    This class implements the CycleGAN model, for learning image-to-image translation without paired data.\n\n    The model training requires '--dataset_mode unaligned' dataset.\n    By default, it uses a '--netG resnet_9blocks' ResNet generator,\n    a '--netD basic' discriminator (PatchGAN introduced by pix2pix),\n    and a least-square GANs objective ('--gan_mode lsgan').\n\n    CycleGAN paper: https://arxiv.org/pdf/1703.10593.pdf\n    \"\"\"\n\n    @staticmethod\n    def modify_commandline_options(parser, is_train=True):\n        \"\"\"Add new dataset-specific options, and rewrite default values for existing options.\n\n        Parameters:\n            parser          -- original option parser\n            is_train (bool) -- whether training phase or test phase. You can use this flag to add training-specific or test-specific options.\n\n        Returns:\n            the modified parser.\n\n        For CycleGAN, in addition to GAN losses, we introduce lambda_A, lambda_B, and lambda_identity for the following losses.\n        A (source domain), B (target domain).\n        Generators: G_A: A -&gt; B; G_B: B -&gt; A.\n        Discriminators: D_A: G_A(A) vs. B; D_B: G_B(B) vs. A.\n        Forward cycle loss:  lambda_A * ||G_B(G_A(A)) - A|| (Eqn. (2) in the paper)\n        Backward cycle loss: lambda_B * ||G_A(G_B(B)) - B|| (Eqn. (2) in the paper)\n        Identity loss (optional): lambda_identity * (||G_A(B) - B|| * lambda_B + ||G_B(A) - A|| * lambda_A) (Sec 5.2 \"Photo generation from paintings\" in the paper)\n        Dropout is not used in the original CycleGAN paper.\n        \"\"\"\n        parser.set_defaults(no_dropout=True)  # default CycleGAN did not use dropout\n        if is_train:\n            parser.add_argument('--lambda_A', type=float, default=10.0, help='weight for cycle loss (A -&gt; B -&gt; A)')\n            parser.add_argument('--lambda_B', type=float, default=10.0, help='weight for cycle loss (B -&gt; A -&gt; B)')\n            parser.add_argument('--lambda_identity', type=float, default=0.5,\n                                help='use identity mapping. Setting lambda_identity other than 0 has an effect of scaling the weight of the identity mapping loss. For example, if the weight of the identity loss should be 10 times smaller than the weight of the reconstruction loss, please set lambda_identity = 0.1')\n\n        return parser\n\n    def __init__(self, opt):\n        \"\"\"Initialize the CycleGAN class.\n\n        Parameters:\n            opt (Option class)-- stores all the experiment flags; needs to be a subclass of BaseOptions\n        \"\"\"\n        BaseModel.__init__(self, opt)\n        # specify the training losses you want to print out. The training/test scripts will call\n        # &lt;BaseModel.get_current_losses&gt;\n        self.loss_names = ['D_A', 'G_A', 'cycle_A', 'idt_A', 'D_B', 'G_B', 'cycle_B', 'idt_B']\n        # specify the images you want to save/display. The training/test scripts will call &lt;BaseModel.get_current_visuals&gt;\n        visual_names_A = ['real_A', 'fake_B', 'rec_A']\n        visual_names_B = ['real_B', 'fake_A', 'rec_B']\n        if self.isTrain and self.opt.lambda_identity &gt; 0.0:  # if identity loss is used, we also visualize idt_B=G_A(B) ad idt_A=G_A(B)\n            visual_names_A.append('idt_B')\n            visual_names_B.append('idt_A')\n\n        self.visual_names = visual_names_A + visual_names_B  # combine visualizations for A and B\n        # specify the models you want to save to the disk. The training/test scripts will call\n        # &lt;BaseModel.save_networks&gt; and &lt;BaseModel.load_networks&gt;.\n        if self.isTrain:\n            self.model_names = ['G_A', 'G_B', 'D_A', 'D_B']\n        else:  # during test time, only load Gs\n            self.model_names = ['G_A', 'G_B']\n\n        # define networks (both Generators and discriminators)\n        # The naming is different from those used in the paper.\n        # Code (vs. paper): G_A (G), G_B (F), D_A (D_Y), D_B (D_X)\n        # \u5b9a\u4e49\u751f\u6210\u5668\uff0c\u540e\u7f00\u4e3aA\u7684\u53d8\u91cf\u8868\u793a\u4ee5A\u4e3a\u8f93\u5165\u7684\u751f\u6210\u5668\uff0c\u7b80\u79f0\u751f\u6210\u5668A\n        self.netG_A = networks.define_G(opt.input_nc, opt.output_nc, opt.ngf, opt.netG, opt.norm,\n                                        not opt.no_dropout, opt.init_type, opt.init_gain, self.gpu_ids)\n        # \u540c\u7406\uff0c\u540e\u7f00\u4e3aB\u7684\u53d8\u91cf\u8868\u793a\u4ee5B\u4e3a\u8f93\u5165\u7684\u751f\u6210\u5668\uff0c\u7b80\u79f0\u751f\u6210\u5668B\n        self.netG_B = networks.define_G(opt.output_nc, opt.input_nc, opt.ngf, opt.netG, opt.norm,\n                                        not opt.no_dropout, opt.init_type, opt.init_gain, self.gpu_ids)\n\n        if self.isTrain:  # define discriminators\n            # \u5982\u679c\u662f\u8bad\u7ec3\u9636\u6bb5\u7684\u8bdd\u5219\u9700\u8981\u5b9a\u4e49\u5224\u522b\u5668\n            # \u8fd9\u91cc\u540e\u7f00A\u3001B\u5206\u522b\u8868\u793a\u7528\u4e8e\u4f18\u5316\u751f\u6210\u5668A\u3001B\u7684\u5224\u522b\u5668\uff0c\u5982:netD_A\u8868\u793a\u7528\u4e8e\u4f18\u5316netG_A\u7684\u5224\u522b\u5668\uff0c\u7b80\u79f0\u5224\u522b\u5668A\n            self.netD_A = networks.define_D(opt.output_nc, opt.ndf, opt.netD,\n                                            opt.n_layers_D, opt.norm, opt.init_type, opt.init_gain, self.gpu_ids)\n            self.netD_B = networks.define_D(opt.input_nc, opt.ndf, opt.netD,\n                                            opt.n_layers_D, opt.norm, opt.init_type, opt.init_gain, self.gpu_ids)\n\n        if self.isTrain:\n            # \u8bad\u7ec3\u9636\u6bb5\u7684\u8bdd\uff0c\u9700\u8981\u5b9a\u4e49\u635f\u5931\u51fd\u6570\u548c\u4f18\u5316\u5668\n            if opt.lambda_identity &gt; 0.0:  # only works when input and output images have the same number of channels\n                assert (opt.input_nc == opt.output_nc)\n            # \u521b\u5efa\u56fe\u50cf\u7f13\u51b2\u533a\n            self.fake_A_pool = ImagePool(opt.pool_size)  # create image buffer to store previously generated images\n            self.fake_B_pool = ImagePool(opt.pool_size)  # create image buffer to store previously generated images\n            # define loss functions\n            # criterionGAN\u8868\u793a\u7528\u4e8e\u8ba1\u7b97\u5224\u522b\u5668\u635f\u5931\u7684\u635f\u5931\u51fd\u6570\uff0c\u5e38\u7528\u4ea4\u53c9\u71b5\u635f\u5931\u6216MSE\u635f\u5931\n            self.criterionGAN = networks.GANLoss(opt.gan_mode).to(self.device)  # define GAN loss.\n            # criterionCycle\u8868\u793a\u8ba1\u7b97\u5faa\u73af\u635f\u5931\u7684\u635f\u5931\u51fd\u6570\n            self.criterionCycle = torch.nn.L1Loss()\n            # criterionIdt\u8868\u793a\u8861\u91cf\u56fe\u50cf\u8d28\u91cf\u7684\u635f\u5931\u51fd\u6570\uff0c\u5bf9\u5404\u4e2a\u901a\u9053\u5143\u7d20\u8ba1\u7b97L1\u635f\u5931\n            self.criterionIdt = torch.nn.L1Loss()\n            # initialize optimizers; schedulers will be automatically created by function &lt;BaseModel.setup&gt;.\n            # \u5206\u522b\u5b9a\u4e49\u751f\u6210\u5668\u7684\u4f18\u5316\u5668\u548c\u5224\u522b\u5668\u7684\u4f18\u5316\u5668\n            self.optimizer_G = torch.optim.Adam(itertools.chain(self.netG_A.parameters(), self.netG_B.parameters()),\n                                                lr=opt.lr, betas=(opt.beta1, 0.999))\n            self.optimizer_D = torch.optim.Adam(itertools.chain(self.netD_A.parameters(), self.netD_B.parameters()),\n                                                lr=opt.lr, betas=(opt.beta1, 0.999))\n            self.optimizers.append(self.optimizer_G)\n            self.optimizers.append(self.optimizer_D)\n\n    # \u8f93\u5165\u548c\u6807\u7b7e\u65f6\uff0c\u8c03\u7528\u8fd9\u4e2a\u51fd\u6570\n    def set_input(self, input):\n        \"\"\"Unpack input data from the dataloader and perform necessary pre-processing steps.\n\n        Parameters:\n            input (dict): include the data itself and its metadata information.\n\n        The option 'direction' can be used to swap domain A and domain B.\n        \"\"\"\n        # direction\u7528\u4e8e\u4ea4\u6362A\u3001B\u4e24\u4e2a\u9886\u57df\u7684\u8f93\u5165\u6570\u636e\n        AtoB = self.opt.direction == 'AtoB'\n        # self.real_A\u8868\u793aA\u9886\u57df\u7684\u771f\u5b9e\u56fe\u50cf\n        self.real_A = input['A' if AtoB else 'B'].to(self.device)\n        # self.real_B\u8868\u793aB\u9886\u57df\u7684\u771f\u5b9e\u56fe\u50cf\n        self.real_B = input['B' if AtoB else 'A'].to(self.device)\n        self.image_paths = input['A_paths' if AtoB else 'B_paths']\n\n    def forward(self):\n        \"\"\"Run forward pass; called by both functions &lt;optimize_parameters&gt; and &lt;test&gt;.\"\"\"\n        # \u524d\u5411\u4f20\u64ad\u9636\u6bb5\n        # \u5c06A\u9886\u57df\u7684\u771f\u5b9e\u56fe\u50cf\u4f20\u5165\u751f\u6210\u5668A\u4e2d\uff0c\u5f97\u5230\u751f\u6210\u7684B\u56fe\u50cf\n        self.fake_B = self.netG_A(self.real_A)  # G_A(A)\n        # \u5c06\u751f\u6210\u7684B\u56fe\u50cf\u4f20\u5165\u751f\u6210\u5668B\u4e2d\uff0c\u5f97\u5230\u4e8c\u6b21\u751f\u6210\u7684A\u9886\u57df\u56fe\u50cf\n        self.rec_A = self.netG_B(self.fake_B)  # G_B(G_A(A))\n        # \u4e0b\u8ff0\u540c\u7406\uff0c\u5c06\u771f\u5b9eB\u56fe\u50cf\u8fde\u7eed\u4f20\u5165\u751f\u6210\u5668B\u548c\u751f\u6210\u5668A\uff0c\u5f97\u5230\u751f\u6210\u7684A\u548c\u4e8c\u6b21\u751f\u6210\u7684B\n        self.fake_A = self.netG_B(self.real_B)  # G_B(B)\n        self.rec_B = self.netG_A(self.fake_A)  # G_A(G_B(B))\n\n    # \u5224\u522b\u5668\u7684\u53cd\u5411\u4f20\u64ad\uff0c\u8ba1\u7b97\u635f\u5931\u8fc7\u7a0b\uff0c\u8fd9\u91cc\u5b9a\u4e49\u4e86\u4e24\u4e2a\u5224\u522b\u5668\u76f8\u540c\u7684\u8fc7\u7a0b(\u5373\u57fa\u7840\u8fc7\u7a0b)\n    def backward_D_basic(self, netD, real, fake):\n        \"\"\"Calculate GAN loss for the discriminator\n\n        Parameters:\n            netD (network)      -- the discriminator D\n            real (tensor array) -- real images \u771f\u5b9e\u56fe\n            fake (tensor array) -- images generated by a generator \u751f\u6210\u56fe\n\n        Return the discriminator loss.\n        We also call loss_D.backward() to calculate the gradients.\n        \"\"\"\n        # Real\n        # \u5c06\u771f\u5b9e\u56fe\u50cf\u4f20\u5165\u5224\u522b\u5668\u4e2d\uff0c\u751f\u6210\u771f\u5b9e\u56fe\u7684\u9884\u6d4b\u503c\uff0c\u5e76\u4e14\u4e0eTrue\u505a\u635f\u5931\n        pred_real = netD(real)\n        loss_D_real = self.criterionGAN(pred_real, True)\n        # Fake\n        # \u5c06\u751f\u6210\u7684\u56fe\u50cf(\u5047\u56fe\u50cf)\u4f20\u5165\u5224\u522b\u5668\u4e2d\uff0c\u751f\u6210\u5047\u56fe\u7684\u9884\u6d4b\u503c\uff0c\u5e76\u4e0eFasle\u505a\u635f\u5931\n        # \u4e4b\u6240\u4ee5\u4e0eFalse\u505a\u635f\u5931\u5c31\u662f\u4e3a\u4e86\u63d0\u9ad8\u81ea\u5df1\u7684\u9274\u522b\u80fd\u529b\n        # \u5728\u9274\u522b\u65b9\u5411\u6b63\u786e\u7684\u524d\u63d0\u4e0b(\u5373\u5c06\u771f\u5b9e\u56fe\u50cf\u5224\u65ad\u4e3aTrue\u7684\u524d\u63d0\u4e0b)\uff0c\u52aa\u529b\u5c06\u751f\u6210\u5668\u751f\u6210\u7684\u56fe\u50cf\u5224\u65ad\u4e3a\u5047(\u5373Fasle)\n        pred_fake = netD(fake.detach())\n        loss_D_fake = self.criterionGAN(pred_fake, False)\n        # Combined loss and calculate gradients\n        # \u4e24\u79cd\u635f\u5931\u53d6\u5747\u503c\n        loss_D = (loss_D_real + loss_D_fake) * 0.5\n        # \u53cd\u5411\u4f20\u64ad\uff0c\u8ba1\u7b97\u68af\u5ea6\n        loss_D.backward()\n        return loss_D\n\n    def backward_D_A(self):\n        \"\"\"Calculate GAN loss for discriminator D_A\"\"\"\n        # \u8ba1\u7b97\u5224\u522b\u5668A\u7684\u635f\u5931\n        fake_B = self.fake_B_pool.query(self.fake_B)\n        self.loss_D_A = self.backward_D_basic(self.netD_A, self.real_B, fake_B)\n\n    def backward_D_B(self):\n        \"\"\"Calculate GAN loss for discriminator D_B\"\"\"\n        # \u8ba1\u7b97\u5224\u522b\u5668B\u7684\u635f\u5931\n        fake_A = self.fake_A_pool.query(self.fake_A)\n        self.loss_D_B = self.backward_D_basic(self.netD_B, self.real_A, fake_A)\n\n    def backward_G(self):\n        # \u751f\u6210\u5668\u7684\u53cd\u5411\u4f20\u64ad\u8fc7\u7a0b\n        \"\"\"Calculate the loss for generators G_A and G_B\"\"\"\n        # \u4e09\u79cd\u635f\u5931\u7684\u6743\u91cd\n        lambda_idt = self.opt.lambda_identity\n        lambda_A = self.opt.lambda_A\n        lambda_B = self.opt.lambda_B\n        # Identity loss\n        if lambda_idt &gt; 0:\n            # G_A should be identity if real_B is fed: ||G_A(B) - B||\n            # \u5982\u679c\u5c06B\u4f20\u5165\u751f\u6210\u5668A\u4e2d\uff0c\u9886\u57df\u7279\u5f81\u4e0d\u5e94\u8be5\u53d1\u751f\u53d8\u5316\uff0c\u5373\u56fe\u50cf\u50cf\u7d20\u70b9\u6570\u636e\u4e0d\u53d8\n            # \u6362\u53e5\u8bdd\u8bf4\u5c31\u662f\u751f\u6210\u5668A\u53ea\u80fd\u751f\u6210B\u9886\u57df\u7684\u6570\u636e\uff0c\u5982\u679c\u4f20\u5165\u7684\u6570\u636e\u672c\u8eab\u5c5e\u4e8eB\u9886\u57df\uff0c\u5219\u6570\u636e\u4e0d\u53d8\uff0c\u5373\u56fe\u50cf\u7279\u5f81\u4e0d\u53d1\u751f\u53d8\u5316\n            self.idt_A = self.netG_A(self.real_B)\n            self.loss_idt_A = self.criterionIdt(self.idt_A, self.real_B) * lambda_B * lambda_idt\n            # G_B should be identity if real_A is fed: ||G_B(A) - A||\n            # \u5bf9\u4e8e\u751f\u6210\u5668B\u540c\u7406\n            self.idt_B = self.netG_B(self.real_A)\n            self.loss_idt_B = self.criterionIdt(self.idt_B, self.real_A) * lambda_A * lambda_idt\n        else:\n            self.loss_idt_A = 0\n            self.loss_idt_B = 0\n\n        # GAN loss D_A(G_A(A))\n        # \u5224\u522b\u5668\u635f\u5931\u5bf9\u4e8e\u751f\u6210\u5668\u7684\u4f18\u5316\uff0c\u8fd9\u91cc\u5c06\u751f\u6210\u56fe\u7684\u5224\u522b\u7ed3\u679c\u4e0eTrue\u505a\u635f\u5931\n        # \u5373\u671f\u671b\u8ba9\u751f\u6210\u5668\u751f\u6210\u7684\u6570\u636e\u5f97\u5230\u5224\u522b\u5668\u7684\u8ba4\u53ef\n        # \u8fd9\u91cc\u7684True\u4e0e\u5224\u522b\u5668\u4e2d\u7684False\u6b63\u597d\u6784\u6210\u5bf9\u6297\u5173\u7cfb\uff0c\u5373\u5728\u5224\u522b\u5668\u63d0\u9ad8\u81ea\u5df1\u5224\u522b\u80fd\u529b\u7684\u540c\u65f6\uff0c\u751f\u6210\u5668\u4e5f\u5728\u63d0\u9ad8\u81ea\u5df1\u7684\u751f\u6210\u80fd\u529b\n        self.loss_G_A = self.criterionGAN(self.netD_A(self.fake_B), True)\n        # GAN loss D_B(G_B(B))\n        self.loss_G_B = self.criterionGAN(self.netD_B(self.fake_A), True)\n        # Forward cycle loss || G_B(G_A(A)) - A||\n        # \u4e8c\u6b21\u751f\u6210\u7684\u56fe\u50cf\u4e0e\u771f\u5b9e\u56fe\u50cf\u505aL1\u635f\u5931\n        self.loss_cycle_A = self.criterionCycle(self.rec_A, self.real_A) * lambda_A\n        # Backward cycle loss || G_A(G_B(B)) - B||\n        self.loss_cycle_B = self.criterionCycle(self.rec_B, self.real_B) * lambda_B\n        # combined loss and calculate gradients\n        # \u5c06\u6240\u6709\u635f\u5931\u76f8\u52a0\uff0c\u5f97\u5230\u751f\u6210\u5668\u7684\u635f\u5931\n        self.loss_G = self.loss_G_A + self.loss_G_B + self.loss_cycle_A + self.loss_cycle_B + self.loss_idt_A + self.loss_idt_B\n        # \u6700\u540e\u53cd\u5411\u4f20\u64ad\uff0c\u8ba1\u7b97\u68af\u5ea6\n        self.loss_G.backward()\n\n    # \u901a\u8fc7\u8c03\u7528optimize_parameters\u65b9\u6cd5\u5b9e\u73b0\u53c2\u6570\u7684\u66f4\u65b0\n    def optimize_parameters(self):\n        \"\"\"Calculate losses, gradients, and update network weights; called in every training iteration\"\"\"\n        # forward\n        # \u524d\u5411\u4f20\u64ad\uff0c\u5c06\u4e24\u79cd\u6570\u636e\u4f9d\u6b21\u4f20\u5165\u4e24\u4e2a\u751f\u6210\u5668\n        self.forward()  # compute fake images and reconstruction images.\n        # G_A and G_B\n        # \u8fd9\u91cc\u5c06\u5224\u522b\u5668\u7684\u53c2\u6570\u51bb\u4f4f\uff0c\u53ea\u66f4\u65b0\u751f\u6210\u5668\u53c2\u6570\n        self.set_requires_grad([self.netD_A, self.netD_B], False)  # Ds require no gradients when optimizing Gs\n        # \u751f\u6210\u5668\u7684\u4f18\u5316\u5668\u68af\u5ea6\u6e05\u96f6\n        self.optimizer_G.zero_grad()  # set G_A and G_B's gradients to zero\n        # \u751f\u6210\u5668\u53cd\u5411\u4f20\u64ad\uff0c\u8ba1\u7b97\u68af\u5ea6\n        self.backward_G()  # calculate gradients for G_A and G_B\n        # \u66f4\u65b0\u751f\u6210\u5668\u53c2\u6570\n        self.optimizer_G.step()  # update G_A and G_B's weights\n        # D_A and D_B\n        # \u5c06\u5224\u522b\u5668\u53c2\u6570\u89e3\u51bb\n        self.set_requires_grad([self.netD_A, self.netD_B], True)\n        # \u5224\u522b\u5668\u7684\u4f18\u5316\u5668\u68af\u5ea6\u6e05\u96f6\n        self.optimizer_D.zero_grad()  # set D_A and D_B's gradients to zero\n        # \u5224\u522b\u5668A\u505a\u53cd\u5411\u4f20\u64ad\uff0c\u8ba1\u7b97\u68af\u5ea6\n        self.backward_D_A()  # calculate gradients for D_A\n        # \u5224\u522b\u5668B\u505a\u53cd\u5411\u4f20\u64ad\uff0c\u8ba1\u7b97\u68af\u5ea6\n        self.backward_D_B()  # calculate graidents for D_B\n        # \u4f18\u5316\u5224\u522b\u5668\u7684\u53c2\u6570\n        self.optimizer_D.step()  # update D_A and D_B's weights\n</code></pre> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u4e8e\uff1a2022\u5e744\u670820\u65e5</p>"},{"location":"other_paper/GradCAM/","title":"\u7269\u4f53\u5b9a\u4f4d\uff1aGrad-CAM","text":""},{"location":"other_paper/GradCAM/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aIEEE International Conference on Computer Vision 2017 (ICCV,  2017)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttp://openaccess.thecvf.com/content_ICCV_2017/papers/Selvaraju_Grad-CAM_Visual_Explanations_ICCV_2017_paper.pdf</p> <p>\u5173\u952e\u5b57\uff1a\u65e0\u76d1\u7763\u5b9a\u4f4d</p>"},{"location":"other_paper/GradCAM/#_2","title":"\u4ecb\u7ecd","text":"<p>\u2003\u2003Grad-CAM\u7684\u5168\u79f0\u4e3a\u68af\u5ea6\u52a0\u6743\u7684\u7c7b\u522b\u54cd\u5e94\u56fe\uff08Gradient-weighted Class Activation Mapping\uff09\uff0c\u5e38\u7528\u4e8e\u7269\u4f53\u5b9a\u4f4d\uff0c\u9002\u7528\u4e8e\u56fe\u50cf\u5206\u7c7b\u6a21\u578b\u3001\u56fe\u50cf\u63cf\u8ff0\u6a21\u578b\uff08image captioning\uff09\u4ee5\u53ca\u53ef\u89c6\u5316\u95ee\u7b54\u7cfb\u7edf\uff08visual question answering\uff09\u7b49\u7b49\u3002</p> <p>\u2003\u2003\u751f\u6210\u54cd\u5e94\u56fe\u7684\u6838\u5fc3\u5c31\u662f\u83b7\u5f97\u57fa\u4e8e\u6307\u5b9a\u7c7b\u522b\u7684\u68af\u5ea6\uff0c\u4e4b\u540e\u5229\u7528\u68af\u5ea6\u8ba1\u7b97\u795e\u7ecf\u5143\u7684\u91cd\u8981\u6027\uff1a $$ \\alpha_k^c=\\frac1Z\\sum_i\\sum_j\\frac{\\partial y^c}{\\partial A^k_{i,j}} $$  \u5176\u4e2d\\alpha^c_k\u662f\u7b2ck\u5f20\u7279\u5f81\u56feA^k\u5bf9\u4e8e\u9884\u6d4b\u7c7b\u522bc\u7684\u76f8\u5bf9\u91cd\u8981\u6027\uff0cy^c\u8868\u793a\u7c7b\u522bc\u7684\u9884\u6d4b\u503c\uff08\u7f51\u7edc\u7684\u8f93\u51fa\uff0c\u672a\u7ecf\u8fc7softmax\uff09\uff0c\u4e4b\u540e\u5c06\\alpha\u4e0e\u7279\u5f81\u56feA\u76f8\u4e58\uff0c\u518d\u6cbf\u901a\u9053\u65b9\u5411\u6c42\u548c\u5f97\u5230\u4e00\u5f20\u56fe\uff0c\u6700\u540e\u518d\u4f20\u5165ReLU\u6fc0\u6d3b\u51fd\u6570\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u54cd\u5e94\u56fe\uff1a $$ L^c_{Grad-CAM}=ReLU(\\sum_k \\alpha^c_k A^k) $$  \u540e\u7eed\u53ef\u4ee5\u5229\u7528\u54cd\u5e94\u56fe\u6765\u6267\u884c\u5b9a\u4f4d\u4efb\u52a1\uff0c\u54cd\u5e94\u56fe\u4e0a\u6570\u636e\u8d8a\u5927\uff0c\u8868\u793a\u539f\u56fe\u54cd\u5e94\u4f4d\u7f6e\u4e0a\u662f\u7269\u4f53\u6240\u5728\u533a\u57df\u3002</p> <p>\u6ce8\uff1a</p> <ul> <li>Grad-CAM\u7b97\u6cd5\u6838\u5fc3\u5c31\u5728\u4e8e\u63d0\u53d6\u6307\u5b9a\u7c7b\u522b\u7684\u68af\u5ea6\uff0c\u5728PyTorch\u4e2d\u53ef\u7528hook\u6a21\u5757\u63d0\u53d6\u6307\u5b9a\u4e2d\u95f4\u53d8\u91cf\u7684\u68af\u5ea6\uff1b</li> <li>\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u53ef\u7528\u4f7f\u7528\u7c7b\u522b\u6807\u7b7e\u6765\u5b9a\u4f4d\uff0c\u5728\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\u65e0\u6807\u7b7e\uff0c\u53ef\u4ee5\u4f7f\u7528\u9884\u6d4b\u503c\u6700\u5927\u7684\u5e8f\u53f7\u4f5c\u4e3a\u7269\u4f53\u7c7b\u522b\u6765\u5b9a\u4f4d\uff1b</li> <li>\u54cd\u5e94\u56fe\u4e0d\u80fd\u76f4\u63a5\u7528\u4e8e\u53ef\u89c6\u5316\uff0c\u53ef\u4ee5\u5148\u7ecf\u8fc7\u4e00\u6b21\u5f52\u4e00\u5316\u8fd0\u7b97\uff0c\u4e4b\u540e\u4f7f\u7528<code>cv2.applyColorMap</code>\u5c06\u539f\u5355\u901a\u9053\u56fe\u50cf\u6570\u636e\u8f6c\u4e3a3\u8272\u56fe\u50cf\u6570\u636e\uff1b</li> <li>\u5982\u679c\u7f51\u7edc\u6709BN\u5c42\u6216DropOut\u5c42\uff0c\u5728\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\u6267\u884c\u5b9a\u4f4d\u65f6\uff0c\u9700\u8981\u5c06\u6a21\u578b\u8bbe\u4e3a<code>eval()</code>\u6a21\u5f0f\uff0c\u8c03\u6574\u7f51\u7edc\u8fd0\u7b97\u65b9\u5f0f\u3002</li> </ul>"},{"location":"other_paper/GradCAM/#_3","title":"\u4ee3\u7801\u5b9e\u73b0","text":"<p>\u2003\u2003\u4ee3\u7801\u4e3a\u4e2a\u4eba\u5b9e\u73b0\uff0c\u4ec5\u4f9b\u53c2\u8003\uff0c\u53ef\u89c6\u5316\u6548\u679c\u5982\u4e0b\uff1a</p> <p> <p></p> <p></p> <pre><code>import cv2\nimport torch\nimport numpy as np\nimport torch.nn.functional as F\nfrom torchvision import models, transforms\n\n\n# \u5b9a\u4e49\u53cd\u5411\u4f20\u64ad\u548c\u524d\u5411\u4f20\u64adhook\uff0c\u5206\u522b\u7528\u4e8e\u63d0\u53d6\u68af\u5ea6\u548c\u7279\u5f81\n# \u8fd9\u91cc\u53ea\u63d0\u53d6\u7f51\u7edc\u6a21\u5757\u8f93\u51fa\u5143\u7d20\u7684\u68af\u5ea6\u548c\u5bf9\u5e94\u7684\u7279\u5f81\u6570\u636e\ndef backward_hook(module, inputs, outputs):\n    grad_outputs.append(outputs[0].detach())\n\n\ndef forward_hook(module, inputs, outputs):\n    feature_outputs.append(outputs)\n\n\n# \u6570\u636e\u5f52\u4e00\u5316\u6a21\u5757\ndef _normalize(cams):\n    min = cams.min()\n    max = cams.max()\n    return (cams - min) / (max - min)\n\n\ntorch.manual_seed(0)\nimg_path = 'dog.jpg'\ngrad_outputs = []\nfeature_outputs = []\ninput_size = (224, 224)\n# \u5b9a\u4e49\u7f51\u7edc\u6a21\u578b\uff0c\u6ce8\u610f\u6d4b\u8bd5\u9636\u6bb5\u8981\u5c06\u6a21\u578b\u8bbe\u7f6e\u4e3aeval()\nnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1).eval()\n# \u5c06\u5b9a\u4e49\u597d\u7684hook\u52a0\u5230\u7f51\u7edc\u6a21\u5757\u4e0a\u9762\uff0c\u6ce8\u610f\u6a21\u5757\u540d\u79f0\nnet.layer4.register_full_backward_hook(backward_hook)\nnet.layer4.register_forward_hook(forward_hook)\ntran = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nimg = cv2.imread(img_path)\nimg_re = cv2.resize(img, input_size)\nimg_re = cv2.cvtColor(img_re, cv2.COLOR_BGR2RGB)\n\ndata = tran(img_re).unsqueeze(0)\n# \u5c06\u56fe\u7247\u6570\u636e\u4f20\u5165\u7f51\u7edc\u4e2d\uff0c\u505a\u524d\u5411\u4f20\u64ad\uff0c\u6b64\u65f6feature_outputs\u4e2d\u5df2\u7ecf\u6709\u4e86\u7279\u5f81\u6570\u636e\nout = net(data)\ncls_idx = torch.argmax(out).item()\n# \u63d0\u53d6\u5230\u7f51\u7edc\u9884\u6d4b\u6700\u5927\u7684\u6982\u7387\u5e8f\u53f7\uff0c\u5f53\u6210\u9884\u6d4b\u7c7b\u522b\uff0c\u8bbe\u4e3ac\nscore = out[:, cls_idx]\nnet.zero_grad()\n# \u53cd\u5411\u4f20\u64ad\uff0c\u5f97\u5230\u5173\u4e8e\u7c7b\u522bc\u7684\u68af\u5ea6\uff0c\u6b64\u65f6\u50a8\u5b58\u5728grad_outputs\u4e2d\nscore.backward(retain_graph=True)\n# \u68af\u5ea6\u6c42\u5747\u503c-&gt;\u548c\u7279\u5f81\u6570\u636e\u76f8\u4e58-&gt;\u76f8\u4e58\u7ed3\u679c\u6cbf\u901a\u9053\u65b9\u5411\u6c42\u548c-&gt;\u7ecf\u8fc7relu-&gt;\u5f52\u4e00\u5316\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u5b9a\u4f4d\u54cd\u5e94\u56fe\nweight = grad_outputs[-1].squeeze(0).mean(dim=(0)).unsqueeze(0)\ngrad_cam = (weight * feature_outputs[-1].squeeze(0)).sum(0)\ngrad_cam = _normalize(F.relu(grad_cam, inplace=True)).cpu().detach().numpy()\n# \u5c06\u54cd\u5e94\u56fe\u653e\u5927\u5230\u548c\u539f\u56fe\u4e00\u6837\u7684\u5927\u5c0f\uff0c\u4e4b\u540e\u8f6c\u4e3a\u4e09\u8272\u56fe\uff0c\u53d8\u6210\u70ed\u56fe\ngrad_cam = cv2.resize(grad_cam, (img.shape[1], img.shape[0]))\nheatmap = cv2.applyColorMap(np.uint8(255 * grad_cam), cv2.COLORMAP_JET)\n# \u70ed\u56fe\u548c\u539f\u56fe\u52a0\u6743\u76f8\u52a0\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u53ef\u89c6\u5316\u56fe\nheatmap = cv2.addWeighted(img, 0.5, heatmap, 0.5, 0)\ncv2.imwrite('hotmap.jpg', heatmap)\n</code></pre> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u6307\u6b63</p> <p>2023\u5e742\u67084\u65e5</p>"},{"location":"other_paper/PartialConv/","title":"\u5c40\u90e8\u5377\u79ef\u2014\u2014Partial Convolutions","text":""},{"location":"other_paper/PartialConv/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aEuropean Conference on Computer Vision 2018 (ECCV 18)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content_ECCV_2018/papers/Guilin_Liu_Image_Inpainting_for_ECCV_2018_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/NVIDIA/partialconv</p> <p>\u9488\u5bf9\u9886\u57df\uff1a\u56fe\u50cf\u4fee\u8865</p>"},{"location":"other_paper/PartialConv/#_2","title":"\u65b9\u6cd5","text":"<p> \u7279\u5f81\u66f4\u65b0\u89c4\u5219\uff1a\u5728\u4e0d\u89c4\u5219\u56fe\u5f62\u7684\u5377\u79ef\uff08\u56fe\u50cf\u975e\u77e9\u5f62\uff09\u8fc7\u7a0b\u4e2d\uff0c\u5047\u8bbeW\u8868\u793a\u5377\u79ef\u6838\u6743\u91cd\u53c2\u6570\uff0cb\u8868\u793a\u76f8\u5e94\u7684\u504f\u7f6e\u53c2\u6570\uff0cX\u8868\u793a\u5f53\u524d\u5377\u79ef\u6838\u5bf9\u5e94\u6ed1\u52a8\u7a97\u53e3\u4e2d\u7684\u50cf\u7d20\u70b9\u7279\u5f81\uff0cM\u8868\u793a\u50cf\u7d20\u70b9\u5bf9\u5e94\u7684\u4e8c\u5143\u63a9\u6a21\uff08\u5229\u7528M\u786e\u5b9a\u4e0d\u89c4\u5219\u56fe\u5f62\uff09\uff0c\u7ecf\u8fc7\u5c40\u90e8\u5377\u79ef\u64cd\u4f5c\u540e\u7684\u7279\u5f81\u6570\u636e\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ \\begin{aligned} x'= \\left\\{\\begin{matrix} &amp;W^T(X\\odot M)\\frac{sum(1)}{sum(M)}+b\\quad &amp;if\\quad sum(M)&gt;0\\\\ &amp;0\\quad&amp;\\text{otherwise} \\end{matrix}\\right. \\end{aligned} $$  \u5176\u4e2d\\odot\u8868\u793a\u70b9\u4e58\u64cd\u4f5c\uff0csum(1)\u8868\u793a\u6ed1\u52a8\u7a97\u53e3\u5bf9\u5e94\u7684\u50cf\u7d20\u70b9\u6570\u91cf\uff0c\u5373\u5377\u79ef\u6838\u5927\u5c0f\u3002\u5982\u516c\u5f0f\u6240\u793a\uff0c\u7ecf\u8fc7\u5c40\u90e8\u5377\u79ef\u5f97\u5230\u7684\u7279\u5f81\u6570\u636e\u53ea\u4e0e\u672a\u5c4f\u853d\u7684\u8f93\u5165\u6570\u636e\u6709\u5173\uff0c\u5373\u53ea\u4e0e\u63a9\u6a21\u56feM\u4e0a\u6570\u636e\u4e3a1\u5bf9\u5e94\u4f4d\u7f6e\u7684\u50cf\u7d20\u70b9\u6709\u5173\u3002\u5176\u4e2d\\frac{sum(1)}{sum(M)}\u8868\u793a\u7f29\u653e\u56e0\u5b50\uff0c\u5229\u7528\u9002\u5f53\u7684\u7f29\u653e\u6765\u8c03\u6574\u6709\u6548\u8f93\u5165\u7684\u53d8\u5316\u91cf\uff0c\u5f53\u4e00\u4e2a\u50cf\u7d20\u70b9\u4e3a\u6709\u6548\u50cf\u7d20\u70b9\uff08\u5373M\u5bf9\u5e94\u4f4d\u7f6e\u4e0a\u4e3a1\uff09\uff0c\u4f46\u5468\u56f4\u7684\u6709\u6548\u50cf\u7d20\u70b9\u6bd4\u8f83\u5c11\u65f6\uff08M\u5bf9\u5e94\u4f4d\u7f6e\u4e0a\u4e3a0\uff09\uff0c\u7ecf\u8fc7\u5377\u79ef\u540e\u8be5\u4f4d\u7f6e\u4e0a\u7684\u6570\u4f1a\u6bd4\u8f83\u5c0f\uff08\u5377\u79ef\u662f\u5c40\u90e8\u50cf\u7d20\u70b9\u4e0e\u6743\u91cd\u4e58\u79ef\u518d\u76f8\u52a0\uff0c\u5982\u679c\u5468\u56f4\u6709\u6548\u50cf\u7d20\u70b9\u6bd4\u8f83\u5c11\uff0c\u53730\u6bd4\u8f83\u591a\uff0c\u5219\u8be5\u50cf\u7d20\u70b9\u5377\u79ef\u540e\u7684\u6570\u6bd4\u8f83\u5c0f\uff09\uff0c\u6b64\u65f6\u8be5\u56e0\u5b50\u4f1a\u6bd4\u8f83\u5927\uff0c\u901a\u8fc7\u653e\u5927\u5377\u79ef\u540e\u7684\u6570\u636e\u6765\u5e73\u8861\u7279\u5f81\u5927\u5c0f\u3002</p> <p> \u63a9\u6a21\u66f4\u65b0\u89c4\u5219\uff1a\u5982\u679c\u5f53\u524d\u50cf\u7d20\u70b9\u5bf9\u5e94\u7684\u6ed1\u52a8\u7a97\u53e3\u4e2d\u81f3\u5c11\u5305\u542b\u4e00\u4e2a\u6709\u6548\u50cf\u7d20\u70b9\uff0c\u5219\u5c06\u8be5\u4f4d\u7f6e\u6807\u8bb0\u4e3a\u6709\u6548\uff0c\u5373\u8be5\u50cf\u7d20\u70b9\u5904\u7684M\u8bbe\u7f6e\u4e3a1\uff0c\u8fd9\u6709\u70b9\u7c7b\u4f3c\u4e8e\u56fe\u50cf\u5904\u7406\u4e2d\u7684\u81a8\u80c0\u8fd0\u7b97\uff1a $$ \\begin{aligned} m'= \\left\\{\\begin{matrix} 1,\\quad &amp;if\\quad sum(M)&gt;0\\\\ 0,\\quad&amp;\\text{otherwise} \\end{matrix}\\right. \\end{aligned} $$  \u8be5\u8fd0\u7b97\u53ef\u4ee5\u5d4c\u5165\u5230\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b\u4e2d\uff0c\u53ea\u8981\u8f93\u5165\u7684\u56fe\u50cf\u5305\u542b\u6709\u6548\u50cf\u7d20\u70b9\uff0c\u5219\u7ecf\u8fc7\u8db3\u591f\u591a\u7684\u90e8\u5206\u5377\u79ef\u8fd0\u7b97\uff0c\u63a9\u6a21\u56feM\u4e0a\u7684\u6570\u636e\u6700\u7ec8\u4f1a\u5168\u90e8\u66f4\u65b0\u4e3a1\u3002</p>"},{"location":"other_paper/PartialConv/#_3","title":"\u4ee3\u7801\u5b9e\u73b0","text":"<p>\u4ee5\u4e8c\u7ef4\u5377\u79ef\u4e3a\u4f8b</p> <pre><code>class PartialConv2d(nn.Conv2d):\n    def __init__(self, *args, **kwargs):\n        # whether the mask is multi-channel or not\n        if 'multi_channel' in kwargs:\n            self.multi_channel = kwargs['multi_channel']\n            kwargs.pop('multi_channel')\n        else:\n            self.multi_channel = False\n        # \u8bbe\u7f6e\u4e3aTrue\u8868\u793a\u540c\u65f6\u8fd4\u56de\u5377\u79ef\u540e\u7684\u7279\u5f81\u548c\u66f4\u65b0\u540e\u7684\u63a9\u6a21M\n        self.return_mask = True\n        # \u8fd9\u91cc\u7684\u7ee7\u627f\u5305\u62ec\u7ee7\u627f\u7236\u7c7bnn.Conv2d\u4e2d\uff0c__init__\u51fd\u6570\u91cc\u5b9a\u4e49\u7684\u6240\u6709\u5c5e\u6027\uff0c\u5305\u62ec\u524d\u5411\u4f20\u64ad\u7528\u5230\u7684\u504f\u7f6e\u9879\n        super(PartialConv2d, self).__init__(*args, **kwargs)\n        if self.multi_channel:\n            self.weight_maskUpdater = torch.ones(self.out_channels, self.in_channels, self.kernel_size[0],\n                                                 self.kernel_size[1])\n        else:\n            self.weight_maskUpdater = torch.ones(1, 1, self.kernel_size[0], self.kernel_size[1])\n        # \u6ed1\u52a8\u7a97\u53e3\u7684\u5c3a\u5bf8\uff0c\u5373\u957f\u4e58\u5bbd\uff0c\u5bf9\u5e94\u8bba\u6587\u4e2d\u7684sum(1)\n        self.slide_winsize = self.weight_maskUpdater.shape[1] * self.weight_maskUpdater.shape[2] * \\\n                             self.weight_maskUpdater.shape[3]\n\n        self.last_size = (None, None, None, None)\n        self.update_mask = None\n        self.mask_ratio = None\n\n    def forward(self, input, mask_in=None):\n        assert len(input.shape) == 4\n        if mask_in is not None or self.last_size != tuple(input.shape):\n            self.last_size = tuple(input.shape)\n            # \u4ee5\u4e0b\u64cd\u4f5c\u4e0d\u4ea7\u751f\u68af\u5ea6\n            with torch.no_grad():\n                # \u4fdd\u8bc1mask\u5377\u79ef\u53c2\u6570\u4e0e\u8f93\u5165\u56fe\u50cf\u7684\u6570\u636e\u7c7b\u578b\u4e00\u81f4\n                if self.weight_maskUpdater.type() != input.type():\n                    self.weight_maskUpdater = self.weight_maskUpdater.to(input)\n                # \u5982\u679c\u4e0d\u5b58\u5728\u63a9\u6a21\uff0c\u5219\u521b\u5efa\u4e00\u4e2a\u5168\u4e00\u6570\u7ec4\u5f53\u505a\u63a9\u6a21\u56fe\n                if mask_in is None:\n                    # if mask is not provided, create a mask\n                    if self.multi_channel:\n                        mask = torch.ones(input.data.shape[0], input.data.shape[1], input.data.shape[2],\n                                          input.data.shape[3]).to(input)\n                    else:\n                        mask = torch.ones(1, 1, input.data.shape[2], input.data.shape[3]).to(input)\n                else:\n                    mask = mask_in\n                # \u5148\u5bf9\u63a9\u6a21\u505a\u5377\u79ef\uff0c\u5f97\u5230\u8bba\u6587\u4e2d\u7684sum(M)\n                self.update_mask = F.conv2d(mask, self.weight_maskUpdater, bias=None, stride=self.stride,\n                                            padding=self.padding, dilation=self.dilation, groups=1)\n                # \u8fd9\u91cc\u5f97\u5230\u63a9\u6a21\u6bd4\u7387\uff0c\u7528\u4e8e\u8c03\u6574\u6709\u6548\u8f93\u5165\u7684\u7279\u5f81\u5927\u5c0f\uff0c\u76f8\u5f53\u4e8e\u8bba\u6587\u4e2d\u7684sum(1)/sum(M)\n                self.mask_ratio = self.slide_winsize / (self.update_mask + 1e-8)\n                # \u901a\u8fc7\u9650\u5236\u6700\u5927\u4e3a1\uff0c\u6700\u5c0f\u4e3a0\uff0c\u4ece\u800c\u5f97\u5230\u8bba\u6587\u4e2d\u7684m'\n                self.update_mask = torch.clamp(self.update_mask, 0, 1)\n                # \u66f4\u65b0\u540e\u7684\u63a9\u6a21\u56fe\u4e0e\u4e4b\u524d\u5f97\u5230\u7684\u6bd4\u7387\u76f8\u4e58\uff0c\u4f7fsum(M)&lt;0\u65f6\u7684\u6bd4\u7387\u53d8\u4e3a0\uff0c\u7528\u4e8e\u540e\u7eed\u548c\u5377\u79ef\u540e\u7684\u56fe\u50cf\u505a\u70b9\u4e58\uff0c\u5f97\u5230x'\n                # \u5373\u5bf9\u5e94\u516c\u5f0f(1)\u4e2d\uff0csum(M)&lt;0\u7684\u50cf\u7d20\u70b9\u7ecf\u8fc7\u5c40\u90e8\u5377\u79ef\u540e\u50cf\u7d20\u70b9\u4f9d\u7136\u662f0\n                self.mask_ratio = torch.mul(self.mask_ratio, self.update_mask)\n        # \u8fd9\u91cc\u6267\u884cPartialConv2d\u7236\u7c7b\u7684\u524d\u5411\u4f20\u64ad\u64cd\u4f5c\uff0c\u800c\u7236\u7c7b\u4e3ann.Conv2d\uff0c\u56e0\u6b64\u76f8\u5f53\u4e8e\u76f4\u63a5\u505a\u4e00\u4e2a\u5377\u79ef\u8fd0\u7b97\n        # \u5982\u679c\u5b58\u5728\u63a9\u6a21M\uff0c\u5219\u5148\u8ba9\u8f93\u5165\u56fe\u50cf\u4e0e\u63a9\u6a21M\u505a\u70b9\u4e58\uff0c\u4e4b\u540e\u505a\u5377\u79ef\u8fd0\u7b97\uff0c\u5426\u5219\u76f4\u63a5\u8ba9\u8f93\u5165\u56fe\u50cf\u505a\u5377\u79ef\u8fd0\u7b97\n        raw_out = super(PartialConv2d, self).forward(torch.mul(input, mask) if mask_in is not None else input)\n        # \u56e0\u4e3a\u8fd9\u4e2a\u7c7b\u7ee7\u627fnn.Conv2d\uff0c\u56e0\u6b64\u8fd9\u91cc\u7684self.bias\u662fnn.Conv2d\u4e2d\u81ea\u5e26\u7684\u504f\u7f6e\u9879\n        if self.bias is not None:\n            # \u5982\u679c\u8be5\u5377\u79ef\u64cd\u4f5c\u5b58\u5728\u504f\u7f6e\u9879\u7684\u8bdd\uff0c\u5219\u5148\u8ba9\u5377\u79ef\u64cd\u4f5c\u51cf\u53bb\u504f\u7f6e\u9879\uff0c\u4e4b\u540e\u518d\u4e0e\u63a9\u6a21\u6bd4\u7387\u76f8\u4e58\uff0c\u6700\u540e\u518d\u52a0\u4e0a\u504f\u7f6e\u9879\n            # \u5bf9\u5e94\u8bba\u6587\u4e2d\u516c\u5f0f1\uff0c\u5148\u8ba9\u6743\u91cd\u4e58\u4ee5\u8f93\u5165\u6570\u636e\uff0c\u4e4b\u540e\u4e58\u4ee5\u63a9\u6a21\u6bd4\u7387\uff0c\u6700\u540e\u52a0\u4e0a\u504f\u7f6e\u9879\n            bias_view = self.bias.view(1, self.out_channels, 1, 1)\n            output = torch.mul(raw_out - bias_view, self.mask_ratio) + bias_view\n            # \u518d\u8ba9\u8f93\u51fa\u7684\u6570\u636e\u4e0e\u66f4\u65b0\u540e\u7684\u63a9\u6a21\u56fe\u76f8\u4e58(\u76f8\u5f53\u4e8e\u518d\u51cf\u53bbsum(M)&lt;0\u5904\u7684\u504f\u7f6e\u6570\u636e)\n            output = torch.mul(output, self.update_mask)\n        else:\n            # \u5982\u679c\u6ca1\u6709\u504f\u7f6e\u9879\u7684\u8bdd\uff0c\u5219\u76f4\u63a5\u505a\u70b9\u4e58\u5373\u53ef\n            output = torch.mul(raw_out, self.mask_ratio)\n        # \u8fd4\u56de\u8f93\u51fa\u6570\u636e\u548c\u66f4\u65b0\u540e\u7684\u63a9\u6a21\u56fe\n        if self.return_mask:\n            return output, self.update_mask\n        else:\n            return output\n</code></pre> <p>\u6ce8\uff1a\u4ee5\u4e0a\u5185\u5bb9\u4ec5\u662f\u7b14\u8005\u7684\u4e2a\u4eba\u89c2\u70b9\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u6279\u8bc4\u6307\u6b63\u3002</p> <p>\u521d\u6b65\u5b8c\u7a3f\uff1a2022\u5e743\u670831\u65e5</p>"},{"location":"other_paper/attention/","title":"\u5e38\u89c1\u7684\u6ce8\u610f\u529b\u673a\u5236","text":"<p>\u53c2\u8003\u94fe\u63a5\uff1a</p> <ul> <li>https://github.com/xmu-xiaoma666/External-Attention-pytorch</li> </ul>"},{"location":"other_paper/attention/#self_attention","title":"Self Attention","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aNIPS2017</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf</p> <p>\u6d41\u7a0b\u56fe</p> <p> <p></p> <p></p> <p>\u7a0b\u5e8f</p> <pre><code>class ScaledDotProductAttention(nn.Module):\n    '''\n    Scaled dot-product attention\n    '''\n\n    def __init__(self, d_model, d_k, d_v, h,dropout=.1):\n        '''\n        :param d_model: Output dimensionality of the model\n        :param d_k: Dimensionality of queries and keys\n        :param d_v: Dimensionality of values\n        :param h: Number of heads\n        '''\n        super(ScaledDotProductAttention, self).__init__()\n        self.fc_q = nn.Linear(d_model, h * d_k)\n        self.fc_k = nn.Linear(d_model, h * d_k)\n        self.fc_v = nn.Linear(d_model, h * d_v)\n        self.fc_o = nn.Linear(h * d_v, d_model)\n        self.dropout=nn.Dropout(dropout)\n\n        self.d_model = d_model\n        self.d_k = d_k\n        self.d_v = d_v\n        self.h = h\n\n        self.init_weights()\n\n\n    def init_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                init.kaiming_normal_(m.weight, mode='fan_out')\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                init.constant_(m.weight, 1)\n                init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                init.normal_(m.weight, std=0.001)\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n\n    def forward(self, queries, keys, values, attention_mask=None, attention_weights=None):\n        '''\n        Computes\n        :param queries: Queries (b_s, nq, d_model)\n        :param keys: Keys (b_s, nk, d_model)\n        :param values: Values (b_s, nk, d_model)\n        :param attention_mask: Mask over attention values (b_s, h, nq, nk). True indicates masking.\n        :param attention_weights: Multiplicative weights for attention values (b_s, h, nq, nk).\n        :return:\n        '''\n        b_s, nq = queries.shape[:2]\n        nk = keys.shape[1]\n\n        q = self.fc_q(queries).view(b_s, nq, self.h, self.d_k).permute(0, 2, 1, 3)  # (b_s, h, nq, d_k)\n        k = self.fc_k(keys).view(b_s, nk, self.h, self.d_k).permute(0, 2, 3, 1)  # (b_s, h, d_k, nk)\n        v = self.fc_v(values).view(b_s, nk, self.h, self.d_v).permute(0, 2, 1, 3)  # (b_s, h, nk, d_v)\n\n        att = torch.matmul(q, k) / np.sqrt(self.d_k)  # (b_s, h, nq, nk)\n        if attention_weights is not None:\n            att = att * attention_weights\n        if attention_mask is not None:\n            att = att.masked_fill(attention_mask, -np.inf)\n        att = torch.softmax(att, -1)\n        att=self.dropout(att)\n\n        out = torch.matmul(att, v).permute(0, 2, 1, 3).contiguous().view(b_s, nq, self.h * self.d_v)  # (b_s, nq, h*d_v)\n        out = self.fc_o(out)  # (b_s, nq, d_model)\n        return out\n</code></pre> <p>\u4f7f\u7528</p> <pre><code>input=torch.randn(50,49,512)\nsa = ScaledDotProductAttention(d_model=512, d_k=512, d_v=512, h=8)\noutput=sa(input,input,input)\nprint(output.shape)\n</code></pre>"},{"location":"other_paper/attention/#senet","title":"SENet","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aCVPR2018</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content_cvpr_2018/papers/Hu_Squeeze-and-Excitation_Networks_CVPR_2018_paper.pdf</p> <p>\u6d41\u7a0b\u56fe</p> <p> <p></p> <p></p> <p>\u7a0b\u5e8f</p> <pre><code>class SEAttention(nn.Module):\n\n    def __init__(self, channel=512,reduction=16):\n        super().__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Sequential(\n            nn.Linear(channel, channel // reduction, bias=False),\n            nn.ReLU(inplace=True),\n            nn.Linear(channel // reduction, channel, bias=False),\n            nn.Sigmoid()\n        )\n\n\n    def init_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                init.kaiming_normal_(m.weight, mode='fan_out')\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                init.constant_(m.weight, 1)\n                init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                init.normal_(m.weight, std=0.001)\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n\n    def forward(self, x):\n        b, c, _, _ = x.size()\n        y = self.avg_pool(x).view(b, c)\n        y = self.fc(y).view(b, c, 1, 1)\n        return x * y.expand_as(x)\n</code></pre>"},{"location":"other_paper/attention/#cbam","title":"CBAM","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aECCV2018</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openaccess.thecvf.com/content_ECCV_2018/papers/Sanghyun_Woo_Convolutional_Block_Attention_ECCV_2018_paper.pdf</p> <p>\u6d41\u7a0b\u56fe</p> <p> <p></p> <p></p> <p>\u7a0b\u5e8f</p> <pre><code># \u901a\u9053\u6ce8\u610f\u529b\nclass ChannelAttention(nn.Module):\n    def __init__(self, channel, reduction=16):\n        super().__init__()\n        self.maxpool = nn.AdaptiveMaxPool2d(1)\n        self.avgpool = nn.AdaptiveAvgPool2d(1)\n        self.se = nn.Sequential(\n            nn.Conv2d(channel, channel // reduction, 1, bias=False),\n            nn.ReLU(),\n            nn.Conv2d(channel // reduction, channel, 1, bias=False)\n        )\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        max_result = self.maxpool(x)\n        avg_result = self.avgpool(x)\n        max_out = self.se(max_result)\n        avg_out = self.se(avg_result)\n        output = self.sigmoid(max_out + avg_out)\n        return output\n\n# \u7a7a\u95f4\u6ce8\u610f\u529b\nclass SpatialAttention(nn.Module):\n    def __init__(self, kernel_size=7):\n        super().__init__()\n        self.conv = nn.Conv2d(2, 1, kernel_size=kernel_size, padding=kernel_size // 2)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        max_result, _ = torch.max(x, dim=1, keepdim=True)\n        avg_result = torch.mean(x, dim=1, keepdim=True)\n        result = torch.cat([max_result, avg_result], 1)\n        output = self.conv(result)\n        output = self.sigmoid(output)\n        return output\n\n# CBAM\u6a21\u5757\nclass CBAMBlock(nn.Module):\n\n    def __init__(self, channel=512, reduction=16, kernel_size=49):\n        super().__init__()\n        self.ca = ChannelAttention(channel=channel, reduction=reduction)\n        self.sa = SpatialAttention(kernel_size=kernel_size)\n\n    def init_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                init.kaiming_normal_(m.weight, mode='fan_out')\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                init.constant_(m.weight, 1)\n                init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                init.normal_(m.weight, std=0.001)\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n\n    def forward(self, x):\n        b, c, _, _ = x.size()\n        residual = x\n        out = x * self.ca(x)\n        out = out * self.sa(out)\n        # \u6700\u540e\u8fd9\u91cc\u8fd8\u989d\u5916\u52a0\u4e86\u8f93\u5165\u6570\u636e\n        return out + residual\n</code></pre>"},{"location":"other_paper/attention/#bam","title":"BAM","text":"<p>\u8bba\u6587\u5730\u5740\uff1ahttps://arxiv.org/pdf/1807.06514.pdf</p> <p>\u6d41\u7a0b\u56fe</p> <p> <p></p> <p></p> <p>\u7a0b\u5e8f</p> <pre><code>class Flatten(nn.Module):\n    def forward(self, x):\n        return x.view(x.shape[0], -1)\n\n\nclass ChannelAttention(nn.Module):\n    def __init__(self, channel, reduction=16, num_layers=3):\n        super().__init__()\n        self.avgpool = nn.AdaptiveAvgPool2d(1)\n        gate_channels = [channel]\n        gate_channels += [channel // reduction] * num_layers\n        gate_channels += [channel]\n\n        self.ca = nn.Sequential()\n        self.ca.add_module('flatten', Flatten())\n        for i in range(len(gate_channels) - 2):\n            self.ca.add_module('fc%d' % i, nn.Linear(gate_channels[i], gate_channels[i + 1]))\n            self.ca.add_module('bn%d' % i, nn.BatchNorm1d(gate_channels[i + 1]))\n            self.ca.add_module('relu%d' % i, nn.ReLU())\n        self.ca.add_module('last_fc', nn.Linear(gate_channels[-2], gate_channels[-1]))\n\n    def forward(self, x):\n        res = self.avgpool(x)\n        res = self.ca(res)\n        res = res.unsqueeze(-1).unsqueeze(-1).expand_as(x)\n        return res\n\n\nclass SpatialAttention(nn.Module):\n    def __init__(self, channel, reduction=16, num_layers=3, dia_val=2):\n        super().__init__()\n        self.sa = nn.Sequential()\n        self.sa.add_module('conv_reduce1',\n                           nn.Conv2d(kernel_size=1, in_channels=channel, out_channels=channel // reduction))\n        self.sa.add_module('bn_reduce1', nn.BatchNorm2d(channel // reduction))\n        self.sa.add_module('relu_reduce1', nn.ReLU())\n        for i in range(num_layers):\n            self.sa.add_module('conv_%d' % i, nn.Conv2d(kernel_size=3, in_channels=channel // reduction,\n                                                        out_channels=channel // reduction, padding=1, dilation=dia_val))\n            self.sa.add_module('bn_%d' % i, nn.BatchNorm2d(channel // reduction))\n            self.sa.add_module('relu_%d' % i, nn.ReLU())\n        self.sa.add_module('last_conv', nn.Conv2d(channel // reduction, 1, kernel_size=1))\n\n    def forward(self, x):\n        res = self.sa(x)\n        res = res.expand_as(x)\n        return res\n\n\nclass BAMBlock(nn.Module):\n\n    def __init__(self, channel=512, reduction=16, dia_val=2):\n        super().__init__()\n        self.ca = ChannelAttention(channel=channel, reduction=reduction)\n        self.sa = SpatialAttention(channel=channel, reduction=reduction, dia_val=dia_val)\n        self.sigmoid = nn.Sigmoid()\n\n    def init_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                init.kaiming_normal_(m.weight, mode='fan_out')\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                init.constant_(m.weight, 1)\n                init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                init.normal_(m.weight, std=0.001)\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n\n    def forward(self, x):\n        b, c, _, _ = x.size()\n        sa_out = self.sa(x)\n        ca_out = self.ca(x)\n        weight = self.sigmoid(sa_out + ca_out)\n        out = (1 + weight) * x\n        return out\n</code></pre>"},{"location":"other_paper/attention/#eca-net","title":"ECA-Net","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aCVPR2020</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttp://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_ECA-Net_Efficient_Channel_Attention_for_Deep_Convolutional_Neural_Networks_CVPR_2020_paper.pdf</p> <p>\u6d41\u7a0b\u56fe</p> <p> <p></p> <p></p> <p>\u7a0b\u5e8f</p> <pre><code>class ECAAttention(nn.Module):\n\n    def __init__(self, kernel_size=3):\n        super().__init__()\n        self.gap = nn.AdaptiveAvgPool2d(1)\n        self.conv = nn.Conv1d(1, 1, kernel_size=kernel_size, padding=(kernel_size - 1) // 2)\n        self.sigmoid = nn.Sigmoid()\n\n    def init_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                init.kaiming_normal_(m.weight, mode='fan_out')\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                init.constant_(m.weight, 1)\n                init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                init.normal_(m.weight, std=0.001)\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n\n    def forward(self, x):\n        y = self.gap(x)  # bs,c,1,1\n        y = y.squeeze(-1).permute(0, 2, 1)  # bs,1,c\n        y = self.conv(y)  # bs,1,c\n        y = self.sigmoid(y)  # bs,1,c\n        y = y.permute(0, 2, 1).unsqueeze(-1)  # bs,c,1,1\n        return x * y.expand_as(x)\n</code></pre>"},{"location":"other_paper/attention/#danet","title":"DANet","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aCVPR2019</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttp://openaccess.thecvf.com/content_CVPR_2019/papers/Fu_Dual_Attention_Network_for_Scene_Segmentation_CVPR_2019_paper.pdf</p> <p>\u6d41\u7a0b\u56fe</p> <p> <p></p> <p></p> <p>\u7a0b\u5e8f</p> <pre><code>import numpy as np\nimport torch\nfrom torch import nn\nfrom torch.nn import init\n\n\nclass SimplifiedScaledDotProductAttention(nn.Module):\n    '''\n    Scaled dot-product attention\n    '''\n\n    def __init__(self, d_model, h, dropout=.1):\n        '''\n        :param d_model: Output dimensionality of the model\n        :param d_k: Dimensionality of queries and keys\n        :param d_v: Dimensionality of values\n        :param h: Number of heads\n        '''\n        super(SimplifiedScaledDotProductAttention, self).__init__()\n\n        self.d_model = d_model\n        self.d_k = d_model // h\n        self.d_v = d_model // h\n        self.h = h\n\n        self.fc_o = nn.Linear(h * self.d_v, d_model)\n        self.dropout = nn.Dropout(dropout)\n\n        self.init_weights()\n\n    def init_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                init.kaiming_normal_(m.weight, mode='fan_out')\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                init.constant_(m.weight, 1)\n                init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                init.normal_(m.weight, std=0.001)\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n\n    def forward(self, queries, keys, values, attention_mask=None, attention_weights=None):\n        '''\n        Computes\n        :param queries: Queries (b_s, nq, d_model)\n        :param keys: Keys (b_s, nk, d_model)\n        :param values: Values (b_s, nk, d_model)\n        :param attention_mask: Mask over attention values (b_s, h, nq, nk). True indicates masking.\n        :param attention_weights: Multiplicative weights for attention values (b_s, h, nq, nk).\n        :return:\n        '''\n        b_s, nq = queries.shape[:2]\n        nk = keys.shape[1]\n\n        q = queries.view(b_s, nq, self.h, self.d_k).permute(0, 2, 1, 3)  # (b_s, h, nq, d_k)\n        k = keys.view(b_s, nk, self.h, self.d_k).permute(0, 2, 3, 1)  # (b_s, h, d_k, nk)\n        v = values.view(b_s, nk, self.h, self.d_v).permute(0, 2, 1, 3)  # (b_s, h, nk, d_v)\n\n        att = torch.matmul(q, k) / np.sqrt(self.d_k)  # (b_s, h, nq, nk)\n        if attention_weights is not None:\n            att = att * attention_weights\n        if attention_mask is not None:\n            att = att.masked_fill(attention_mask, -np.inf)\n        att = torch.softmax(att, -1)\n        att = self.dropout(att)\n\n        out = torch.matmul(att, v).permute(0, 2, 1, 3).contiguous().view(b_s, nq, self.h * self.d_v)  # (b_s, nq, h*d_v)\n        out = self.fc_o(out)  # (b_s, nq, d_model)\n        return out\n\n\nclass ScaledDotProductAttention(nn.Module):\n    '''\n    Scaled dot-product attention\n    '''\n\n    def __init__(self, d_model, d_k, d_v, h,dropout=.1):\n        '''\n        :param d_model: Output dimensionality of the model\n        :param d_k: Dimensionality of queries and keys\n        :param d_v: Dimensionality of values\n        :param h: Number of heads\n        '''\n        super(ScaledDotProductAttention, self).__init__()\n        self.fc_q = nn.Linear(d_model, h * d_k)\n        self.fc_k = nn.Linear(d_model, h * d_k)\n        self.fc_v = nn.Linear(d_model, h * d_v)\n        self.fc_o = nn.Linear(h * d_v, d_model)\n        self.dropout=nn.Dropout(dropout)\n\n        self.d_model = d_model\n        self.d_k = d_k\n        self.d_v = d_v\n        self.h = h\n\n        self.init_weights()\n\n\n    def init_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                init.kaiming_normal_(m.weight, mode='fan_out')\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                init.constant_(m.weight, 1)\n                init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                init.normal_(m.weight, std=0.001)\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n\n    def forward(self, queries, keys, values, attention_mask=None, attention_weights=None):\n        '''\n        Computes\n        :param queries: Queries (b_s, nq, d_model)\n        :param keys: Keys (b_s, nk, d_model)\n        :param values: Values (b_s, nk, d_model)\n        :param attention_mask: Mask over attention values (b_s, h, nq, nk). True indicates masking.\n        :param attention_weights: Multiplicative weights for attention values (b_s, h, nq, nk).\n        :return:\n        '''\n        b_s, nq = queries.shape[:2]\n        nk = keys.shape[1]\n\n        q = self.fc_q(queries).view(b_s, nq, self.h, self.d_k).permute(0, 2, 1, 3)  # (b_s, h, nq, d_k)\n        k = self.fc_k(keys).view(b_s, nk, self.h, self.d_k).permute(0, 2, 3, 1)  # (b_s, h, d_k, nk)\n        v = self.fc_v(values).view(b_s, nk, self.h, self.d_v).permute(0, 2, 1, 3)  # (b_s, h, nk, d_v)\n\n        att = torch.matmul(q, k) / np.sqrt(self.d_k)  # (b_s, h, nq, nk)\n        if attention_weights is not None:\n            att = att * attention_weights\n        if attention_mask is not None:\n            att = att.masked_fill(attention_mask, -np.inf)\n        att = torch.softmax(att, -1)\n        att=self.dropout(att)\n\n        out = torch.matmul(att, v).permute(0, 2, 1, 3).contiguous().view(b_s, nq, self.h * self.d_v)  # (b_s, nq, h*d_v)\n        out = self.fc_o(out)  # (b_s, nq, d_model)\n        return out\n\n\nclass PositionAttentionModule(nn.Module):\n\n    def __init__(self, d_model=512, kernel_size=3, H=7, W=7):\n        super().__init__()\n        self.cnn = nn.Conv2d(d_model, d_model, kernel_size=kernel_size, padding=(kernel_size - 1) // 2)\n        self.pa = ScaledDotProductAttention(d_model, d_k=d_model, d_v=d_model, h=1)\n\n    def forward(self, x):\n        bs, c, h, w = x.shape\n        y = self.cnn(x)\n        y = y.view(bs, c, -1).permute(0, 2, 1)  # bs,h*w,c\n        y = self.pa(y, y, y)  # bs,h*w,c\n        return y\n\n\nclass ChannelAttentionModule(nn.Module):\n\n    def __init__(self, d_model=512, kernel_size=3, H=7, W=7):\n        super().__init__()\n        self.cnn = nn.Conv2d(d_model, d_model, kernel_size=kernel_size, padding=(kernel_size - 1) // 2)\n        self.pa = SimplifiedScaledDotProductAttention(H * W, h=1)\n\n    def forward(self, x):\n        bs, c, h, w = x.shape\n        y = self.cnn(x)\n        y = y.view(bs, c, -1)  # bs,c,h*w\n        y = self.pa(y, y, y)  # bs,c,h*w\n        return y\n\n\nclass DAModule(nn.Module):\n\n    def __init__(self, d_model=512, kernel_size=3, H=7, W=7):\n        super().__init__()\n        self.position_attention_module = PositionAttentionModule(d_model=512, kernel_size=3, H=7, W=7)\n        self.channel_attention_module = ChannelAttentionModule(d_model=512, kernel_size=3, H=7, W=7)\n\n    def forward(self, input):\n        bs, c, h, w = input.shape\n        p_out = self.position_attention_module(input)\n        c_out = self.channel_attention_module(input)\n        p_out = p_out.permute(0, 2, 1).view(bs, c, h, w)\n        c_out = c_out.view(bs, c, h, w)\n        return p_out + c_out\n</code></pre> <p>\u4f7f\u7528</p> <pre><code>from model.attention.DANet import DAModule\nimport torch\n\ninput=torch.randn(50,512,7,7)\ndanet=DAModule(d_model=512,kernel_size=3,H=7,W=7)\nprint(danet(input).shape)\n</code></pre>"},{"location":"other_paper/saliency_sampling/","title":"\u663e\u8457\u6027\u91c7\u6837","text":""},{"location":"other_paper/saliency_sampling/#_2","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aEuropean Conference on Computer Vision 2018 (ECCV, 2018)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttp://openaccess.thecvf.com/content_ECCV_2018/papers/Adria_Recasens_Learning_to_Zoom_ECCV_2018_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/recasens/Saliency-Sampler</p>"},{"location":"other_paper/saliency_sampling/#_3","title":"\u4ecb\u7ecd","text":"<p>\u2003\u2003\u5982\u679c\u628a\u4e00\u822c\u7684\u666e\u901a\u91c7\u6837\u770b\u6210\u5747\u8861\u7684\u91c7\u6837\u8fc7\u7a0b\uff0c\u90a3\u4e48\u663e\u8457\u6027\u91c7\u6837\u5c31\u53ef\u4ee5\u770b\u6210\u4e0d\u5747\u8861\u7684\u91c7\u6837\u8fc7\u7a0b\u3002\u5c06\u539f\u56feX\u770b\u6210\u4e00\u4e2a\u7f51\u683c\uff0c\u5c06\u7f51\u683c\u9876\u70b9\u8bbe\u7f6e\u4e3aV\uff0c\u666e\u901a\u7684\u91c7\u6837\u76f8\u5f53\u4e8e\u5728\u7f51\u683c\u4e0a\u5747\u5300\u53d6\u70b9\uff0c\u5982\u6bcf\u9694\u4e00\u4e2a\u70b9\u53d6\u4e00\u4e2a\u6570\u636e\uff0c\u6700\u540e\u7ecf\u8fc7\u4e0b\u91c7\u6837\u5f97\u5230\u7684\u56fe\u50cf\u957f\u5bbd\u5747\u662f\u539f\u6765\u7684\u4e00\u534a\uff0c\u5e76\u4e14\u56fe\u50cf\u6240\u8574\u542b\u7684\u4fe1\u606f\u5206\u5e03\u5927\u4f53\u4e0d\u53d8\uff1b\u663e\u8457\u6027\u91c7\u6837\u4e5f\u662f\u5728\u7f51\u683c\u4e0a\u53d6\u70b9\uff0c\u4f46\u662f\u53d6\u70b9\u8fc7\u7a0b\u53d7\u91c7\u6837\u56fe\u7684\u5f71\u54cd\uff0c\u91c7\u6837\u56fe\u4e0a\u7684\u6570\u636e\u8d8a\u5927\uff0c\u5219\u5728\u8be5\u533a\u57df\u5468\u56f4\u53d6\u7684\u70b9\u5c31\u8d8a\u591a\uff0c\u6700\u540e\u7684\u91c7\u6837\u56fe\u4e2d\uff0c\u8be5\u533a\u57df\u4e0a\u7684\u4fe1\u606f\u5c31\u8d8a\u4e30\u5bcc\uff0c\u4e0e\u5229\u7528\u653e\u5927\u955c\u653e\u5927\u8be5\u533a\u57df\u7684\u6548\u679c\u7c7b\u4f3c\u3002</p> <p>\u2003\u2003\u663e\u8457\u6027\u91c7\u6837\u7684\u8fc7\u7a0b\u76f8\u5f53\u4e8e\u63a2\u7d22\u65b0\u7684\u51e0\u4f55\u5f62\u72b6V\u2018\uff0c\u4f7f\u539f\u6765\u5747\u5300\u7684\u7f51\u683c\u70b9\u53d7\u91c7\u6837\u56fe\u7684\u5f71\u54cd\uff0c\u505a\u7279\u6b8a\u7684\u6536\u7f29\u4e0e\u6269\u5f20\u3002\u91c7\u6837\u56fe\u4e0a\u6570\u636e\u5927\u7684\u533a\u57df\uff0c\u76f8\u5f53\u4e8e\u5728\u539f\u59cb\u7684\u7f51\u683c\u70b9\u4e2d\u505a\u4e86\u4e00\u4e2a\u6269\u5f20\u64cd\u4f5c\uff1b\u6570\u636e\u5c0f\u7684\u533a\u57df\uff0c\u76f8\u5f53\u4e8e\u5728\u539f\u59cb\u7f51\u683c\u70b9\u4e2d\u505a\u4e86\u4e00\u4e2a\u6536\u7f29\u64cd\u4f5c\u3002\u6362\u53e5\u8bdd\u8bf4\uff0c\u91c7\u6837\u56fe\u4e2d\u6570\u636e\u6bd4\u8f83\u5927\u7684\u533a\u57df\u4f1a\u5438\u5f15\u5468\u56f4\u6570\u636e\u6bd4\u8f83\u5c0f\u7684\u533a\u57df\uff0c\u5177\u4f53\u5982\u4e0b\u56fe\uff1a</p> <p> <p></p> <p></p> <p>\u56fe\u4f8b\u4e2d\u91c7\u6837\u56feS\u4e0a\u7684\u70b9\u8d8a\u4eae\uff0c\u4ee3\u8868\u91c7\u6837\u56fe\u8be5\u4f4d\u7f6e\u4e0a\u7684\u6570\u636e\u8d8a\u5927\uff0c\u901a\u8fc7\u5438\u5f15\u5468\u56f4\u6570\u503c\u6bd4\u8f83\u5c0f\u7684\u533a\u57df\uff0c\u8fbe\u5230\u626d\u66f2\u539f\u56fe\u5750\u6807\u7cfb\u7684\u6548\u679c\uff0c\u6700\u7ec8\u53ef\u4ee5\u5b9e\u73b0\u653e\u5927\u8be5\u533a\u57df\u7ec6\u8282\u7684\u76ee\u7684\u3002</p> <p>\u2003\u2003\u5229\u7528\u91c7\u6837\u56fe\u8fdb\u884c\u663e\u8457\u6027\u91c7\u6837\u7684\u8fc7\u7a0b\u53ef\u4ee5\u8f6c\u5316\u4e3a\u6c42\u89e3\u91cd\u91c7\u6837\u56fe\u548c\u8f93\u5165\u56fe\u50cf\u4e4b\u95f4\u6620\u5c04\u7684\u95ee\u9898\u3002\u5047\u8bbe\u539f\u56fe\u5750\u6807\u4e3a(x,y)\uff0c\u6620\u5c04\u5230\u91cd\u91c7\u6837\u56fe\u7684\u50cf\u7d20\u70b9\u5750\u6807\u4e3a(x\u2019,y\u2019)\uff0c(x\u2019,y\u2019)\u7684\u751f\u6210\uff0c\u53ef\u4ee5\u770b\u6210(x,y)\u88ab\u5468\u56f4\u5750\u6807\u70b9\u62c9\u626f\u7684\u7ed3\u679c\uff0c\u62c9\u626f\u529b\u5ea6\u4e0e\u91c7\u6837\u56fe\u4e0a\u5468\u56f4\u70b9\u7684\u6570\u636e\u5927\u5c0f\u4ee5\u53ca(x,y)\u4e0e\u5176\u4ed6\u5750\u6807\u70b9\u7684\u8ddd\u79bb\u6709\u5173\u3002\u5982\u4e0a\u56fe\u4e2d\uff0c\u7531\u4e8e\u767d\u8272\u533a\u57df\u91c7\u6837\u56fe\u4e0a\u7684\u6570\u636e\u6bd4\u8f83\u5927\uff0c\u56e0\u6b64\u767d\u8272\u533a\u57df\u5bf9\u5468\u56f4\u7684\u62c9\u626f\u529b\u5ea6\u5927\uff0c\u4f1a\u5bf9\u5468\u56f4\u7684\u50cf\u7d20\u505a\u4e00\u4e2a\u5438\u5f15\uff0c\u4e5f\u5c31\u662f\u5c06\u5468\u56f4\u7684\u50cf\u7d20\u7edf\u4e00\u62c9\u5411\u81ea\u5df1\uff1b\u800c\u4e0a\u56fe\u4e2d\u9ed1\u8272\u533a\u57df\uff0c\u7531\u4e8e\u91c7\u6837\u56fe\u4e0a\u7684\u6570\u636e\u6bd4\u8f83\u5c0f\uff0c\u62c9\u626f\u529b\u5ea6\u6bd4\u8f83\u5c0f\uff0c\u56e0\u6b64\u53ea\u80fd\u88ab\u62c9\u5411\u767d\u8272\u533a\u57df\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u9ad8\u65af\u8ddd\u79bb\u6838\u51fd\u6570k(v\u2019,v)\uff0c\u70b9v\u4e0e\u5176\u4ed6\u50cf\u7d20\u70b9v\u2019\u7684\u8ddd\u79bb\u8d8a\u5927\uff0c\u8be5\u503c\u8d8a\u5c0f\uff0c\u8ddd\u79bb\u8d8a\u5c0f\uff0c\u8be5\u503c\u8d8a\u5927\u3002\u5047\u8bbe\u6620\u5c04\u53ef\u4ee5\u5199\u6210\u4e24\u4e2a\u51fd\u6570f(v)\u548cg(v)\uff0c\u5219\u8be5\u51fd\u6570\u53ef\u4ee5\u8868\u793a\u6210\u5982\u4e0b\u5f62\u5f0f\uff0c\u5176\u4e2dQ\u8868\u793a\u8ba1\u7b97\u5f97\u5230\u7684\u91c7\u6837\u56fe\uff1a $$ f(v)=\\frac{\\sum_{v'}Q(v')k(v',v)v_x}{\\sum_{v'}Q(v')k(v',v)},\\\\ g(v)=\\frac{\\sum_{v'}Q(v')k(v',v)v_y}{\\sum_{v'}Q(v')k(v',v)}. $$ </p> <p>\u2003\u2003\u5229\u7528\u4e0a\u8ff0\u516c\u5f0f\u8fdb\u884c\u91cd\u91c7\u6837\u64cd\u4f5c\uff0c\u663e\u8457\u6027\u8f83\u9ad8\u7684\u533a\u57df\u4f1a\u5438\u5f15\u5176\u4ed6\u50cf\u7d20\uff0c\u56e0\u6b64\u91c7\u6837\u66f4\u5bc6\u96c6\uff0c\u5e76\u4e14\u5f15\u5165\u4e86\u8ddd\u79bb\u56e0\u7d20k\uff0c\u53ef\u4ee5\u5145\u5f53\u6b63\u5219\u5316\u5668\uff0c\u907f\u514d\u6240\u6709\u50cf\u7d20\u70b9\u6536\u655b\u5230\u76f8\u540c\u7684\u5750\u6807\u70b9\u3002</p> <p>\u6ce8\uff1a</p> <ul> <li>\u91c7\u6837\u8fc7\u7a0b\u4e0d\u4e00\u5b9a\u5fc5\u987b\u7cbe\u51c6\u5230\u539f\u56fe\u4e0a\u7684\u50cf\u7d20\u70b9\uff0c\u4ecb\u4e8e\u4e24\u4e2a\u50cf\u7d20\u70b9\u4e4b\u95f4\u7684\u91c7\u6837\u70b9\uff0c\u5229\u7528\u63d2\u503c\u8fd0\u7b97\u5b9e\u73b0\u91c7\u6837\u3002</li> </ul>"},{"location":"other_paper/saliency_sampling/#_4","title":"\u6e90\u7801\u5b9e\u73b0","text":""},{"location":"other_paper/saliency_sampling/#_5","title":"\u65b9\u6cd5\u51fd\u6570","text":"<p>\u8fd9\u91cc\u5bf9\u6e90\u7801\u505a\u4e86\u4e00\u4e0b\u4fee\u6539\uff0c\u53ea\u5b9e\u73b0\u91c7\u6837\u8fc7\u7a0b</p> <p>\u5b9a\u4e49\u7c7b\u65f6\uff1a\u4f20\u5165\u56fe\u7247\u5c3a\u5bf8</p> <p>\u524d\u5411\u4f20\u64ad\u65f6\uff1a</p> <ul> <li>\u8f93\u5165\uff1a\u5f85\u91c7\u6837\u7684\u56fe\u7247\uff08\u7279\u5f81\uff09\u3001\u5c3a\u5bf8\u4e3a31\u7684\u91c7\u6837\u56fe</li> <li>\u8f93\u51fa\uff1a\u663e\u8457\u6027\u91c7\u6837\u540e\u7684\u56fe\u7247\uff08\u7279\u5f81\uff09</li> </ul> <pre><code>class Saliency_Sampler(nn.Module):\n    def __init__(self, input_size=448):\n        super(Saliency_Sampler, self).__init__()\n\n        # \u91c7\u7528\u56fe\u7684\u5c3a\u5bf8\n        self.grid_size = 31\n        # \u7528\u4e8e\u5bf9\u91c7\u6837\u56fe\u7684\u586b\u5145\n        self.padding_size = 30\n        # \u91c7\u6837\u56fe\u7ecf\u8fc7\u6269\u5145\u540e\u7684\u957f\u5bbd\u5c3a\u5bf8\n        self.global_size = self.grid_size + 2 * self.padding_size\n        # \u56fe\u7247\u8f93\u5165\u7684\u5c3a\u5bf8\n        self.input_size_net = input_size\n        self.conv_last = nn.Conv2d(256, 1, kernel_size=1, padding=0, stride=1)\n        # \u9ad8\u65af\u6838\uff0c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f(3)\u4e2d\u7684k\n        gaussian_weights = torch.FloatTensor(makeGaussian(2 * self.padding_size + 1, fwhm=13))\n\n        # \u8f93\u5165\u8f93\u51fa\u5747\u4e3a1\u7684\u5377\u79ef\u8fd0\u7b97\uff0ckernel_size\u4e3a61*61\uff0c\u7528\u4e8e\u516c\u5f0f(2,3)\u7684\u8ba1\u7b97\n        # \u56e0\u4e3af,g\u4e2d\u6bcf\u4e2a\u503c\u90fd\u7531\u539f\u663e\u8457\u56fe\u6bcf\u4e2a\u70b9\u8ba1\u7b97\uff0c\u5e76\u4e14\u6c42\u548c\u5f97\u5230\n        self.filter = nn.Conv2d(1, 1, kernel_size=(2 * self.padding_size + 1, 2 * self.padding_size + 1), bias=False)\n        # \u5c06\u5377\u79ef\u53c2\u6570\u5b9a\u4e49\u4e3a\u9ad8\u65af\u6838\u53c2\u6570\uff0c\u5373\u516c\u5f0f\u4e2d\u7684k\n        # \u9ad8\u65af\u6838\uff0c\u5bf9\u5e94\u8bba\u6587\u4e2d\u7684\u8ddd\u79bb\u6838k\uff0c\u8be5\u5377\u79ef\u64cd\u4f5c\u5bf9\u5e94\u8bba\u6587\u516c\u5f0f(7)\uff0c\u4e58\u79ef+\u6c42\u548c\n        self.filter.weight[0].data[:, :, :] = gaussian_weights\n\n        # \u521d\u59cb\u5316\u68af\u5ea6\u77e9\u9635\uff0c\u4e24\u5f20\u68af\u5ea6\u56fe\uff0c\u5206\u522b\u4ee3\u8868x\u7684\u68af\u5ea6\u548cy\u7684\u68af\u5ea6\n        # \u6570\u503c\u4ece-1\u52302\u5747\u5300\u53d8\u5316\n        self.P_basis = torch.zeros(2, self.grid_size + 2 * self.padding_size, self.grid_size + 2 * self.padding_size)\n        for k in range(2):\n            for i in range(self.global_size):\n                for j in range(self.global_size):\n                    self.P_basis[k, i, j] = k * (i - self.padding_size) / (self.grid_size - 1.0) + (1.0 - k) * (\n                            j - self.padding_size) / (self.grid_size - 1.0)\n\n    def create_grid(self, x):\n        # \u8f93\u5165\uff1ax \u6269\u5145\u540e\u7684\u91c7\u6837\u56fe\n        # \u9884\u5148\u5b9a\u4e49\u4e00\u4e2a\u548c\u91c7\u6837\u56fe\u5c3a\u5bf8\u76f8\u540c\u7684\u5168\u96f6\u77e9\u9635\n        P = torch.autograd.Variable(\n            torch.zeros(1, 2, self.grid_size + 2 * self.padding_size, self.grid_size + 2 * self.padding_size).cuda(),\n            requires_grad=False)\n        # \u521d\u59cb\u5316\u4e3a\u5747\u5300\u7684\u7f51\u683c\u56fe\n        P[0, :, :, :] = self.P_basis\n        # \u5c06P\u6269\u5c55\u7ef4\u5ea6\uff0c\u7b2c\u4e00\u7ef4\u5ea6\u5927\u5c0f\u4ece1\u6269\u5c55\u5230batch_size\uff0c\u5373\u5c06\u6240\u6709batch\u7684\u68af\u5ea6\u56fe\u90fd\u505a\u4e00\u4e2a\u521d\u59cb\u5316\n        P = P.expand(x.size(0), 2, self.grid_size + 2 * self.padding_size, self.grid_size + 2 * self.padding_size)\n        # \u5c06\u8f93\u5165\u8fdb\u884c\u5806\u53e0\uff0c\u53d8\u6210\u4e24\u5f20\u56fe\uff0c\u6b64\u65f6x_cat\u7684\u5c3a\u5bf8\u4e3abatch*2*91*91\n        x_cat = torch.cat((x, x), 1)\n        # \u5377\u79ef\u540e\u5f97\u5230\u7684\u5c3a\u5bf8\u4e3abatch*1*31*31\uff0c\u5377\u79ef\u6838\u5c3a\u5bf8\u4e3a61*61\uff0c\u8fd9\u91cc\u5377\u79ef\u6838\u53c2\u6570\u88ab\u8bbe\u7f6e\u4e3a\u9ad8\u65af\u6838\uff0c\u5373\u516c\u5f0f(7,8)\u4e2d\u7684\u8ddd\u79bb\u6838k\n        # \u8fd9\u91cc\u7684\u5377\u79ef\u76f8\u5f53\u4e8e\u8bba\u6587\u4e2d\u7684\u516c\u5f0f(7,8)\u4e2d\u7684\u5206\u6bcd\uff0c\u91c7\u6837\u56fe\u4e0e\u8ddd\u79bb\u6838\u4e58\u79ef\u518d\u6c42\u548c\n        p_filter = self.filter(x)\n        # \u8fd9\u91cc\u5f97\u5230(2*batch)*1*91*91\u7684\u77e9\u9635\uff0c\u521d\u59cb\u5316\u7684\u5747\u5300\u7f51\u683c\u56fe\u4e0e\u91c7\u6837\u56fe\u505a\u70b9\u4e58\uff0c\u76f8\u5f53\u4e8e\u516c\u5f0f(7,8)\u4e2d\u5206\u5b50\u7684\u4e00\u90e8\u5206\n        x_mul = torch.mul(P, x_cat).view(-1, 1, self.global_size, self.global_size)\n        # \u8fd9\u91cc\u5f97\u5230batch*2*31*31\u7684\u77e9\u9635\uff0c\u518d\u6b21\u5229\u7528\u5377\u79ef\u64cd\u4f5c\u5b9e\u73b0\u6c42\u548c\u518d\u76f8\u52a0\uff0c\u6700\u7ec8\u5f97\u5230\u516c\u5f0f(7,8)\u4e2d\u7684\u5206\u5b50\n        all_filter = self.filter(x_mul).view(-1, 2, self.grid_size, self.grid_size)\n        # \u5c06all_filter\u5206\u79bb\uff0c\u5206\u51fax\u65b9\u5411\u548cy\u65b9\u5411\n        x_filter = all_filter[:, 0, :, :].contiguous().view(-1, 1, self.grid_size, self.grid_size)\n        y_filter = all_filter[:, 1, :, :].contiguous().view(-1, 1, self.grid_size, self.grid_size)\n        # \u5c06\u7ed3\u679c\u76f8\u9664\uff0c\u5206\u522b\u5f97\u5230f\u4e0ev\n        x_filter = x_filter / p_filter\n        y_filter = y_filter / p_filter\n\n        xgrids = x_filter * 2 - 1\n        ygrids = y_filter * 2 - 1\n        # \u8303\u56f4\u63a7\u5236\u5230-1\u52301\u4e4b\u95f4\n        xgrids = torch.clamp(xgrids, min=-1, max=1)\n        ygrids = torch.clamp(ygrids, min=-1, max=1)\n\n        xgrids = xgrids.view(-1, 1, self.grid_size, self.grid_size)\n        ygrids = ygrids.view(-1, 1, self.grid_size, self.grid_size)\n        # \u6b64\u65f6grid\u4e3abatch*2*31*31\uff0c\u4e3a\u91c7\u6837\u7f51\u683c\n        grid = torch.cat((xgrids, ygrids), 1)\n        # \u4e0a\u91c7\u6837\uff0c\u5c06\u68af\u5ea6\u56fe\u653e\u5927\n        grid = F.interpolate(grid, size=(self.input_size_net, self.input_size_net), mode='bilinear', align_corners=True)\n        # \u6700\u7ec8\u53d8\u6210batch*448*448*2\n        grid = torch.transpose(grid, 1, 2)\n        grid = torch.transpose(grid, 2, 3)\n\n        return grid\n\n    def forward(self, x, p):\n        # x\u8868\u793a\u5f85\u91c7\u6837\u7684\u56fe\u50cf\n        # p\u8868\u793a\u91c7\u6837\u56fe\uff0c\u901a\u9053\u6570\u4e3a1\uff0c\u5bbd\u9ad8\u5c3a\u5bf8\u5747\u4e3aself.grid_size(\u4e4b\u524d\u8bbe\u7f6e\u597d\u7684)\n        # p:(batch, 1, self.grid_size, self.grid_size)\n\n        # \u5c06\u91c7\u6837\u56fe\u505a\u4e00\u4e2a\u586b\u5145\uff0c\u4fbf\u4e8e\u4e0b\u9762\u5bf9u,v\u7684\u8ba1\u7b97\n        p = nn.ReplicationPad2d(self.padding_size)(p)\n        # \u901a\u8fc7\u91c7\u6837\u56fe\uff0c\u5f97\u5230\u91c7\u6837\u7f51\u683c\u56fe\n        grid = self.create_grid(p)\n        # \u5229\u7528\u5f97\u5230\u7684\u7f51\u683c\u56fe\u5bf9\u8f93\u5165\u56fe\u50cf\u505a\u4e00\u4e2a\u7f51\u683c\u91c7\u6837\uff0c\u5373\u663e\u8457\u91c7\u6837\u8fc7\u7a0b\n        x_sampled = F.grid_sample(x, grid)\n\n        # \u8fd4\u56de\u91c7\u6837\u6570\u636e\n        return x_sampled\n</code></pre>"},{"location":"other_paper/saliency_sampling/#_6","title":"\u9ad8\u65af\u6838\u7684\u751f\u6210","text":"<pre><code>def makeGaussian(size, fwhm = 3, center=None):\n    # x\u4e3a0\u523060\uff0c\u4e00\u517161\u4e2a\u6570\n    x = np.arange(0, size, 1, float)\n    # np.newaxis\u8868\u793a\u589e\u52a0\u4e00\u4e2a\u7ef4\u5ea6\n    # \u6b64\u65f6y\u7684\u7ef4\u5ea6\u4e3a(61,1)\n    y = x[:,np.newaxis]\n    # \u662f\u5426\u8f93\u5165\u4e2d\u5fc3\n    if center is None:\n        x0 = y0 = size // 2\n    else:\n        x0 = center[0]\n        y0 = center[1]\n    # \u8ba1\u7b97\u9ad8\u65af\u6838\n    return np.exp(-4*np.log(2) * ((x-x0)**2 + (y-y0)**2) / fwhm**2)\n</code></pre> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u9519\u8bef\uff0c\u6b22\u8fce\u6307\u6b63</p> <p>\u521d\u6b65\u5b8c\u7a3f\u4e8e\uff1a2023\u5e742\u67083\u65e5</p>"},{"location":"python/rearrange/","title":"rearrange\u4ecb\u7ecd","text":"<pre><code>rearrange(tensor: Union[Tensor, List[Tensor]], pattern: str, **axes_lengths)\n</code></pre> <p>\u529f\u80fd\uff1a\u91cd\u65b0\u5212\u5206\u5f20\u91cf\u7ef4\u5ea6\uff0c\u53ef\u4ee5\u5b9e\u73b0\u6570\u7ec4\u7684\u8f6c\u7f6e\u3001\u62c6\u5206\u3001\u5408\u5e76\u7b49\u64cd\u4f5c\u3002</p> <p>\u8f93\u5165\uff1a</p> <ul> <li><code>tensor</code>\uff1a\u9700\u8981\u8c03\u6574\u7ef4\u5ea6\u7684\u5f20\u91cf\u6570\u636e\uff1b</li> <li><code>pattern</code>\uff1a\u8c03\u6574\u89c4\u5219\uff1b</li> <li><code>axes_lengths</code>\uff1a\u9644\u52a0\u7684\u5c3a\u5bf8\u89c4\u683c\uff1b</li> </ul> <p>\u6ce8\u610f\uff1a</p> <ul> <li>\u5982\u679c\u9700\u8981\u5c06\u67d0\u4e00\u7ef4\u5ea6\u62c6\u5206\u6210\u591a\u4e2a\u7ef4\u5ea6\uff0c\u9700\u8981\u989d\u5916\u6307\u5b9a\u4e00\u4e9b\u9644\u52a0\u7684\u5c3a\u5bf8\u89c4\u683c\u53d8\u91cf\uff0c\u540c\u65f6\u62c6\u5206\u6216\u8005\u5408\u5e76\u7ef4\u5ea6\u65f6\uff0c\u6ce8\u610f\u53d8\u91cf\u987a\u5e8f\uff1b</li> </ul>"},{"location":"python/rearrange/#_1","title":"\u4ee3\u7801\u6848\u4f8b","text":""},{"location":"python/rearrange/#_2","title":"\u62c6\u5206","text":"<pre><code>import torch\nfrom einops import rearrange\n\ndata = torch.range(1, 10)\ndata1 = rearrange(data, '(a b) -&gt; a b', a=2, b=5)\ndata2 = rearrange(data, '(b a) -&gt; a b', a=2, b=5)\nprint(data1)\nprint(data2)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code># (a b) -&gt; a b\ntensor([[ 1.,  2.,  3.,  4.,  5.],\n        [ 6.,  7.,  8.,  9., 10.]])\n# (b a) -&gt; a b\ntensor([[ 1.,  3.,  5.,  7.,  9.],\n        [ 2.,  4.,  6.,  8., 10.]])\n</code></pre> <p>\u6ce8\u610f\uff1a(a b) -&gt; a b\u65f6\uff0c\u76f8\u5f53\u4e8e\u76f4\u63a5\u6309\u987a\u5e8f\u62c6\u5206\uff0c\u6bcfb\u4e2a\u4e3a1\u7ec4\uff0c\u4e00\u5171\u5206\u51faa\u7ec4\u6765\uff0cb\u770b\u6210\u6bcf\u7ec4\u7684\u7279\u5f81\u957f\u5ea6\uff0ca\u770b\u6210\u7ec4\u6570\uff1b(b a) -&gt; a b\u65f6\uff0c\u76f8\u5f53\u4e8e\u5148\u628a\u6570\u636e\u5212\u5206\u6210(b, a)\u7684\uff0c\u4e4b\u540e\u518d\u505a\u4e00\u6b21\u8f6c\u7f6e\uff0c\u5373\uff1a</p> <pre><code>print(data.reshape(5, 2).transpose(-1, -2))\n\n# \u8f93\u51fa\ntensor([[ 1.,  3.,  5.,  7.,  9.],\n        [ 2.,  4.,  6.,  8., 10.]])\n</code></pre>"},{"location":"python/rearrange/#_3","title":"\u5408\u5e76","text":"<pre><code>import torch\nfrom einops import rearrange\n\ndata = torch.range(1, 10).reshape(2, 5)\ndata1 = rearrange(data, 'a b -&gt; (a b)')\ndata2 = rearrange(data, 'a b -&gt; (b a)')\nprint(data)\nprint(data1)\nprint(data2)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code>tensor([[ 1.,  2.,  3.,  4.,  5.],\n        [ 6.,  7.,  8.,  9., 10.]])\n# a b -&gt; (a b)\ntensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])\n# a b -&gt; (b a)\ntensor([ 1.,  6.,  2.,  7.,  3.,  8.,  4.,  9.,  5., 10.])\n</code></pre> <p>\u6ce8\u610f\uff1a(a b) -&gt; a b\u65f6\uff0c\u76f8\u5f53\u4e8e\u76f4\u63a5\u6309\u987a\u5e8f\u5408\u5e76\uff0ca\u4e2a\u7ec4\u7684\u7279\u5f81\uff0c\u6309\u987a\u5e8f\u4e32\u8054\u5408\u5e76\uff1ba b -&gt; (b a)\u65f6\uff0c\u76f8\u5f53\u4e8e\u5148\u628a\u6570\u7ec4\u505a\u8f6c\u7f6e\uff0c\u4e4b\u540e\u518d\u5408\u5e76\uff0c\u5373\uff1a</p> <pre><code>print(data.transpose(-1, -2).reshape(-1))\n\ntensor([ 1.,  6.,  2.,  7.,  3.,  8.,  4.,  9.,  5., 10.])\n</code></pre> <p>\u5b98\u7f51\u6587\u6863\uff1ahttps://einops.rocks/api/rearrange/</p> <p>\u6700\u540e\u4e00\u6b21\u4fee\u6539\u4e8e\uff1a2023\u5e7411\u670822\u65e5</p>"},{"location":"python/tqdm/","title":"Python\u5e38\u7528\u5e93\uff1aTqdm\u2014\u2014\u663e\u793a\u8fdb\u5ea6\u6761","text":""},{"location":"python/tqdm/#_1","title":"\u4ecb\u7ecd","text":"<p>\u529f\u80fd\uff1a\u6784\u5efa\u8fdb\u5ea6\u6761\uff0c\u5171\u6709\u4e24\u79cd\u6784\u5efa\u7b56\u7565\uff0c\u4e00\u4e2a\u662f\u57fa\u4e8e\u53ef\u8fed\u4ee3\u7684\u5bf9\u8c61\u6784\u5efa\u8fdb\u5ea6\u6761\uff0c\u505afor\u5faa\u73af\u8fed\u4ee3\u65f6\u4f1a\u81ea\u52a8\u66f4\u65b0\u8fdb\u5ea6\u6761\uff1b\u53e6\u4e00\u4e2a\u662f\u6784\u5efa\u624b\u52a8\u66f4\u65b0\u7684\u8fdb\u5ea6\u6761\uff0c\u8fd9\u79cd\u65b9\u5f0f\u7075\u6d3b\u6027\u66f4\u5f3a</p> <pre><code>class tqdm(Comparable):\n\n    def __init__(self, iterable=None, desc=None, total=None, leave=True, file=None,\n                     ncols=None, mininterval=0.1, maxinterval=10.0, miniters=None,\n                     ascii=None, disable=False, unit='it', unit_scale=False,\n                     dynamic_ncols=False, smoothing=0.3, bar_format=None, initial=0,\n                     position=None, postfix=None, unit_divisor=1000, write_bytes=False,\n                     lock_args=None, nrows=None, colour=None, delay=0.0, gui=False,\n                     **kwargs):\n</code></pre> <p>\u5e38\u7528\u53c2\u6570\u4ecb\u7ecd\uff1a</p> <ul> <li><code>iterable</code>\uff1a\u53ef\u8fed\u4ee3\u7684\u5bf9\u8c61\uff0c\u5982\u679c\u60f3\u8bbe\u7f6e\u624b\u52a8\u66f4\u65b0\u7684\u8fdb\u5ea6\u6761\uff0c\u5c31\u4e0d\u9700\u8981\u4f20\u5165\u8fd9\u4e00\u53c2\u6570\uff1b</li> <li><code>desc</code>\uff1a\u7528\u4e8e\u653e\u5728\u8fdb\u5ea6\u6761\u5de6\u8fb9\u7684\u63cf\u8ff0\u6587\u5b57\uff0c\u5b57\u7b26\u4e32\u683c\u5f0f\uff1b</li> <li><code>total</code>\uff1a\u8fdb\u5ea6\u6761\u603b\u957f\u5ea6\uff0c\u6574\u6570\u5f62\u5f0f\uff1b</li> <li><code>leave</code>\uff1a\u8fed\u4ee3\u5b8c\u4e4b\u540e\u662f\u5426\u4fdd\u7559\u8fdb\u5ea6\u6761\uff0c\u5e03\u5c14\u683c\u5f0f\uff1b</li> </ul> <p>\u5e38\u7528\u65b9\u6cd5</p> <ul> <li><code>tqdm.set_description(desc)</code>\uff1a\u8bbe\u7f6e\u8fdb\u5ea6\u6761\u7684\u63cf\u8ff0\u4fe1\u606f\uff0c\u4f20\u5165\u5b57\u7b26\u4e32\u6570\u636e\uff0c\u8fd9\u91cc\u4f1a\u548c\u5b9a\u4e49<code>tqdm</code>\u65f6\u4f20\u5165\u7684<code>desc</code>\u53c2\u6570\u76f8\u51b2\u7a81\uff0c\u4e8c\u8005\u529f\u80fd\u7c7b\u4f3c\uff1b</li> <li><code>tqdm.set_postfix(**kwargs)</code>\uff1a\u8bbe\u7f6e\u8fdb\u5ea6\u6761\u540e\u7f00\uff0c\u53ef\u4ee5\u7528\u6765\u663e\u793a\u989d\u5916\u7684\u4fe1\u606f\uff0c\u4f20\u5165\u5b57\u5178\u683c\u5f0f\u7684\u6570\u636e\uff1b</li> </ul>"},{"location":"python/tqdm/#_2","title":"\u57fa\u4e8e\u53ef\u8fed\u4ee3\u5bf9\u8c61\u6784\u5efa","text":"<p>\u4ee3\u7801\u6848\u4f8b</p> <p>\u200b   \u5728\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u65f6\uff0c\u5e38\u5e38\u628a\u6784\u5efa\u7684\u6570\u636e\u52a0\u8f7d\u5668\u4f20\u5165tqdm\u4e2d\uff0c\u6784\u5efa\u8fdb\u5ea6\u6761\uff0c\u505afor\u5faa\u73af\u904d\u5386\u6570\u636e\u505a\u8bad\u7ec3\u7684\u65f6\u5019\uff0c\u4f1a\u53ef\u89c6\u5316\u51fa\u8bad\u7ec3\u8fc7\u7a0b\u3002</p> <pre><code>from tqdm import tqdm\nimport time\n\n\ndataloader = range(10)\ntqds = tqdm(dataloader, desc=\"train\")\nfor i in tqds:\n    tqds.set_postfix({'Iteration': i})\n    time.sleep(0.1)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code>train: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:01&lt;00:00,  9.45it/s, Iteration=9]\n</code></pre>"},{"location":"python/tqdm/#_3","title":"\u624b\u52a8\u6784\u5efa","text":"<p>\u4ee3\u7801\u6848\u4f8b</p> <pre><code>from tqdm import tqdm\nimport time\n\n\n# total\u8868\u793a\u8fdb\u5ea6\u6761\u603b\u957f\u5ea6\nwith tqdm(total=10) as pbar:\n    for i in range(10):\n        pbar.set_description('iter {}'. format(i))\n        time.sleep(0.1)\n        # \u8fdb\u884c\u8fdb\u5ea6\u6761\u66f4\u65b0\uff0c\u8fd9\u91cc\u4f20\u51651\u8868\u793a\u5f80\u524d\u8fdb1\u683c\n        pbar.update(1)\n</code></pre> <p>\u8f93\u51fa</p> <pre><code>iter 9: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:01&lt;00:00,  9.49it/s]\n</code></pre>"},{"location":"python/tqdm/#_4","title":"\u5b98\u65b9\u6587\u6863","text":"<p>tqdm.tqdm\uff1ahttps://tqdm.github.io/docs/tqdm/</p>"},{"location":"transformer/CLIP/","title":"CLIP\u2014\u2014\u4ece\u81ea\u7136\u8bed\u8a00\u4e2d\u5b66\u4e60\u89c6\u89c9\u6a21\u578b","text":""},{"location":"transformer/CLIP/#clip_1","title":"CLIP\u7b80\u4ecb","text":"<p>\u2003\u2003\u4f20\u7edf\u7684\u89c6\u89c9\u4efb\u52a1\u5728\u8bad\u7ec3\u6a21\u578b\u65f6\u6240\u7528\u7684\u6570\u636e\u96c6\u901a\u5e38\u662f\u4e00\u5f20\u56fe\u7247\u5bf9\u5e94\u4e00\u7ec4\u6807\u7b7e\u7684\u683c\u5f0f\uff0c\u8bad\u7ec3\u8fc7\u7a0b\u5177\u6709\u5355\u4e00\u6027\uff0c\u5e76\u4e14\u8bad\u7ec3\u51fa\u6765\u7684\u6a21\u578b\u5177\u6709\u9886\u57df\u552f\u4e00\u6027\uff0c\u5373\u6a21\u578b\u7684\u9002\u7528\u8303\u56f4\u4ec5\u9650\u4e8e\u8bad\u7ec3\u6570\u636e\u6240\u5305\u62ec\u7684\u8303\u56f4\uff0c\u4f8b\u5982\u5728ImageNet\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\uff0c\u6a21\u578b\u6700\u591a\u53ea\u80fd\u9274\u522b\u6570\u636e\u96c6\u6240\u5305\u542b\u76841000\u4e2a\u7c7b\u522b\uff0c\u65e0\u6cd5\u9274\u522b\u5176\u4ed6\u7c7b\u522b\uff0c\u5982\u679c\u60f3\u8981\u7528\u5230\u65b0\u7684\u9886\u57df\uff0c\u6700\u5e38\u7528\u7684\u7b56\u7565\u5c31\u662f\u5148\u4fee\u6539\u5206\u7c7b\u5c42\u7684\u8f93\u51fa\uff0c\u4e4b\u540e\u62ff\u4e00\u4e9b\u65b0\u9886\u57df\u7684\u56fe\u7247\u6765\u5fae\u8c03\uff08fine-tuning\uff09\u6a21\u578b\u7684\u53c2\u6570\u3002</p> <p>\u2003\u2003\u672c\u6587\u4e2d\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u6587\u672c\u7279\u5f81\u4f5c\u4e3a\u76d1\u7763\u4fe1\u53f7\u7684\u8bad\u7ec3\u7b56\u7565\uff0c\u4e0d\u9700\u8981\u989d\u5916\u7684\u6807\u7b7e\u6765\u76d1\u7763\uff0c\u6452\u5f03\u4f20\u7edf\u4e00\u5bf9\u4e00\u7684\u8bad\u7ec3\u6a21\u5f0f\uff0c\u5229\u7528\u8bed\u8a00\u4fe1\u606f\u6765\u63cf\u8ff0\u56fe\u50cf\uff0c\u5e76\u4e14\u52a0\u4ee5\u8bad\u7ec3\uff0c\u8ba9\u6a21\u578b\u771f\u6b63\u7ad9\u5728\u8bed\u4e49\u7684\u89d2\u5ea6\u4e0a\u7406\u89e3\u56fe\u50cf\uff0c\u53ef\u4ee5\u8ba9\u6a21\u578b\u5b66\u5230\u66f4\u5168\u9762\u7684\u56fe\u50cf\u4fe1\u606f\uff0c\u66f4\u52a0\u8d34\u5408\u4eba\u7c7b\u7684\u8ba4\u77e5\u65b9\u5f0f\u3002</p> <p>\u2003\u2003\u7f51\u7edc\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003CLIP\u6838\u5fc3\u601d\u60f3\uff1a\u5229\u7528\u5bf9\u6bd4\u5b66\u4e60\u7b56\u7565\uff0c\u901a\u8fc7\u56fe\u6587\u5339\u914d\u6765\u8bad\u7ec3\u6a21\u578b\u5bf9\u56fe\u7247\u7684\u8bed\u4e49\u7406\u89e3\u80fd\u529b\uff0c\u4ece\u800c\u5b9e\u73b0zero-shot\u7684\u529f\u80fd\u3002\uff08\u540e\u7eed\u5bf9CLIP\u505a\u6539\u8fdb\u4e5f\u662f\u4e3a\u4e86\u8ba9\u6a21\u578b\u63d0\u5347\u6cdb\u5316\u80fd\u529b\uff0c\u5b9e\u73b0zero-shot\u529f\u80fd\uff09</p> <p>\u8bad\u7ec3\u8fc7\u7a0b\uff1a</p> <ul> <li>\u5229\u7528\u56fe\u50cf\u7f16\u7801\u5668\u5bf9\u8f93\u5165\u56fe\u50cf\u505a\u7f16\u7801\uff0c\u5f97\u5230\u56fe\u50cf\u7279\u5f81\uff1b</li> <li>\u5229\u7528\u6587\u672c\u7f16\u7801\u5668\u5bf9\u8f93\u5165\u7684\u6587\u672c\u505a\u7f16\u7801\uff0c\u5f97\u5230\u6587\u672c\u7279\u5f81\uff1b</li> <li>\u5229\u7528\u5bf9\u6bd4\u5b66\u4e60\u8bad\u7ec3\u6a21\u578b\uff0c\u4f9d\u6b21\u8ba1\u7b97\u6bcf\u4e2a\u56fe\u50cf\u7279\u5f81\u4e0e\u6587\u672c\u7279\u5f81\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6\uff0c\u8ba9\u914d\u5bf9\u7684\u56fe\u6587\u7279\u5f81\u66f4\u52a0\u76f8\u4f3c\uff0c\u4e0d\u914d\u5bf9\u7684\u56fe\u6587\u7279\u5f81\u66f4\u52a0\u4e0d\u540c\uff1b</li> </ul> <p>\u6d4b\u8bd5\u8fc7\u7a0b\uff1a</p> <ul> <li>\u9884\u8bbe\u4e00\u7ec4\u7c7b\u522b\u6587\u672c\uff0c\u6784\u5efa\u63d0\u793a\u8bcd\uff08prompt\uff09\uff0c\u201dA photo of a XXX\u201d\uff0c\u8f93\u5165\u5230\u6587\u672c\u7f16\u7801\u5668\u4e2d\u83b7\u5f97\u6587\u672c\u7f16\u7801\uff1b</li> <li>\u5c06\u56fe\u7247\u4f20\u5165\u56fe\u50cf\u7f16\u7801\u5668\uff0c\u83b7\u5f97\u56fe\u50cf\u7f16\u7801\uff1b</li> <li>\u5c06\u56fe\u50cf\u7279\u5f81\u4e0e\u6240\u6709\u7684\u6587\u672c\u7279\u5f81\u505a\u5339\u914d\uff0c\u627e\u51fa\u6700\u76f8\u4f3c\u7684\u6587\u672c\u6765\uff0c\u6700\u7ec8\u5f97\u5230\u56fe\u50cf\u7684\u9884\u6d4b\u7c7b\u522b\u3002</li> </ul>"},{"location":"transformer/CLIP/#_1","title":"\u7b80\u6613\u4ee3\u7801","text":"<pre><code># image_encoder - ResNet or Vision Transformer\n# text_encoder - CBOW or Text Transformer\n# I[n, h, w, c] - minibatch of aligned images\n# T[n, l] - minibatch of aligned texts\n# W_i[d_i, d_e] - learned proj of image to embed\n# W_t[d_t, d_e] - learned proj of text to embed\n# t - learned temperature parameter\n\n# extract feature representations of each modality\nI_f = image_encoder(I) #[n, d_i]\nT_f = text_encoder(T) #[n, d_t]\n\n# joint multimodal embedding [n, d_e]\n# \u5408\u5e76\u591a\u6a21\u6001\u7279\u5f81\nI_e = l2_normalize(np.dot(I_f, W_i), axis=1)\nT_e = l2_normalize(np.dot(T_f, W_t), axis=1)\n\n# scaled pairwise cosine similarities [n, n]\n# \u8ba1\u7b97\u76f8\u4f3c\u5ea6\nlogits = np.dot(I_e, T_e.T) * np.exp(t)\n\n# symmetric loss function\n# \u5bf9\u89d2\u7ebf\u4e0a\u5339\u914d\nlabels = np.arange(n)\n# \u5bf9\u79f0\u7684\u635f\u5931\uff0c\u540c\u65f6\u4f18\u5316\u56fe\u50cf\u548c\u6587\u672c\u7f16\u7801\u5668\nloss_i = cross_entropy_loss(logits, labels, axis=0)\nloss_t = cross_entropy_loss(logits, labels, axis=1)\nloss = (loss_i + loss_t)/2\n</code></pre>"},{"location":"transformer/CLIP/#_2","title":"\u8bed\u4e49\u5206\u5272\u65b9\u5411\u6539\u8fdb","text":""},{"location":"transformer/CLIP/#ldse","title":"LDSE","text":"<p>\u6d4b\u8bd5\u6548\u679c</p> <p> <p></p> <p></p> <ul> <li>\u53ea\u9700\u8981\u7ed9\u51fa\u60f3\u8981\u5206\u5272\u7684\u7c7b\u522b\uff0c\u6a21\u578b\u5c31\u53ef\u4ee5\u5206\u5272\u51fa\u5bf9\u8c61\u8303\u56f4\uff1b</li> <li>\u5177\u6709\u8f83\u5f3a\u7684\u5bb9\u9519\u7387\uff0c\u5982\u7b2c\u4e00\u884c\u7b2c\u4e09\u4e2a\uff0c\u5982\u679c\u56fe\u7247\u4e2d\u6ca1\u6709\u8f66\uff0c\u5373\u4f7f\u8ba9\u5206\u5272\u8f66\u7684\u8bdd\uff0c\u6a21\u578b\u4e5f\u4e0d\u4f1a\u4ea7\u751f\u9519\u8bef\u7684\u9884\u6d4b\uff1b</li> <li>\u53ef\u4ee5\u540c\u65f6\u9274\u522b\u5b50\u7c7b\u522b\u548c\u7236\u7c7b\u522b\uff1b</li> <li>other\u8868\u793a\u80cc\u666f\u533a\u57df\uff0c\u53ef\u4ee5\u6362\u6210\u5176\u4ed6\u5355\u8bcd\uff0c\u5982a\u3001and\u3001the\u7b49\u7b49\uff0c\u53ea\u8981\u4e0d\u4e0e\u7269\u4f53\u540d\u5b57\u7279\u522b\u50cf\u5c31\u884c\u3002</li> </ul> <p>\u7f51\u7edc\u7ed3\u6784\uff1a</p> <p> <p></p> <p></p> <ul> <li>\u6574\u4f53\u7ed3\u6784\u548cCLIP\u5f88\u50cf\uff0c\u8fd9\u91cc\u5c06CLIP\u4e2d\u6574\u5f20\u56fe\u7684\u5206\u7c7b\u6539\u4e3a\u4e86\u9010\u50cf\u7d20\u70b9\u505a\u5206\u7c7b\uff1b</li> <li>Text Encoder\u76f4\u63a5\u4f7f\u7528CLIP\u4e2d\u7684\u6587\u672c\u7f16\u7801\u5668\uff0c\u7f51\u7edc\u7ed3\u6784\u548c\u6743\u91cd\u90fd\u4e0d\u6539\u53d8\uff0c\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5c06\u53c2\u6570\u51bb\u4f4f\uff1b</li> <li>Image Encoder\u91c7\u7528DPT\u7684\u7ed3\u6784\uff08ViT+decoder\uff09\uff1b</li> <li>\u5c3a\u5bf8\u4e3a(N,C)\u7684\u6587\u672c\u7279\u5f81\u548c\u5c3a\u5bf8\u4e3a(H,W,C)\u7684\u56fe\u50cf\u7279\u5f81\u6cbf\u901a\u9053\u65b9\u5411\u76f8\u4e58\uff0c\u8ba1\u7b97\u76f8\u4f3c\u5ea6\uff0c\u5f97\u5230\u5c3a\u5bf8\u4e3a(H,W,N)\u7684\u6570\u636e\uff1b</li> <li>Spatial Regularization Blocks\u662f\u672c\u6587\u63d0\u51fa\u7684\u4e00\u4e2a\u65b0\u6a21\u5757\uff0c\u8ba1\u7b97\u5b8c\u56fe\u6587\u76f8\u4f3c\u5ea6\u4e4b\u540e\u518d\u5f15\u5165\u4e00\u4e9b\u53ef\u5b66\u4e60\u7684\u53c2\u6570\uff0c\u7528\u4e8e\u8fdb\u4e00\u6b65\u5b66\u4e60\u878d\u5408\u540e\u7684\u7279\u5f81\u3002</li> </ul> <p>\u6ce8\uff1a</p> <ul> <li>CLIP\u4f7f\u7528\u5bf9\u6bd4\u5b66\u4e60\uff0c\u5229\u7528\u63cf\u8ff0\u56fe\u50cf\u7684\u6587\u672c\u6765\u505a\u76d1\u7763\uff08\u4e0d\u7528\u6307\u660e\u56fe\u50cf\u7684\u7c7b\u522b\uff09\uff0c\u76f8\u5f53\u4e8e\u65e0\u76d1\u7763\u5b66\u4e60\uff1b</li> <li>LDSE\u9700\u8981mask\u6807\u7b7e\u548c\u5bf9\u5e94\u7684\u7c7b\u522b\u8bed\u4e49\u4fe1\u606f\uff08\u9700\u8981\u7279\u5b9a\u6307\u51fa\u6765\u50cf\u7d20\u70b9\u7684\u7c7b\u522b\u540d\u79f0\uff09\uff0c\u56e0\u6b64\u662f\u6709\u76d1\u7763\u5b66\u4e60\uff0c\u9700\u8981\u624b\u52a8\u505a\u6807\u6ce8\uff1b</li> <li>\u8bed\u4e49\u4fe1\u606f\u7684\u5f15\u5165\uff0c\u4f7f\u5f97\u6a21\u578b\u53ef\u4ee5\u5b9e\u73b0zero-shot\u529f\u80fd</li> </ul>"},{"location":"transformer/CLIP/#groupvit","title":"GroupViT","text":"<p> \u65e0\u76d1\u7763\u8bad\u7ec3\u8bed\u4e49\u5206\u5272\u5e38\u7528Group\u7b56\u7565\uff0c\u7531\u4e00\u4e2a\u70b9\u5411\u5916\u53d1\u6563\uff0c\u627e\u76f8\u4f3c\u7279\u5f81\uff0c\u8fdb\u4e00\u6b65\u751f\u6210\u4e00\u7ec4mask\u3002\u672c\u6587\u4f5c\u8005\u91cd\u62feGrouping\u7b97\u6cd5\uff0c\u5728ViT\u6a21\u578b\u4e2d\u52a0\u5165Grouping Block\uff0c\u540c\u65f6\u52a0\u5165\u4e86\u53ef\u5b66\u4e60\u7684Group tokens\uff0c\u6162\u6162\u5c06\u56fe\u50cf\u7684\u7279\u5f81\u805a\u7c7b\uff0c\u53d8\u6210\u4e00\u4e2a\u4e2amask\uff0c\u7f51\u7edc\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u56fe\u50cf\u7f16\u7801\u8fc7\u7a0b\uff1a</p> <ul> <li>\u7b2c\u4e00\u9636\u6bb5\u5148\u9884\u8bbe64\u4e2agrouping tokens\uff0c\u56fe\u50cf\u7279\u5f81\u548ctokens\u7ecf\u8fc76\u7ec4transformer layers\uff0c\u518d\u4f20\u5165grouping block\u6a21\u5757\uff0c\u505a\u805a\u7c7b\u64cd\u4f5c\uff0c\u5c06\u7279\u5f81\u5e8f\u5217\u5206\u914d\u7ed9tokens\uff0c\u7531\u4e8e\u76f4\u63a5\u5206\u914d\u7684\u8bdd\u4e0d\u53ef\u5bfc\uff0c\u56e0\u6b64\u8fd9\u91cc\u91c7\u7528\u6ce8\u610f\u529b\u64cd\u4f5c\uff0c\u6765\u505a\u52a0\u6743\u6c42\u548c\uff0c\u5c06\u5206\u914d\u8fc7\u7a0b\u53d8\u4e3a\u53ef\u5bfc\u7684\uff1b</li> <li>\u548c\u7b2c\u4e00\u9636\u6bb5\u7c7b\u4f3c\uff0c\u7b2c\u4e8c\u9636\u6bb5\u518d\u9884\u8bbe8\u4e2atokens\uff0c\u8ba9\u8f93\u51fa\u768464\u7279\u5f81\u4e0e8\u4e2atokens\u4e00\u8d77\u7ecf\u8fc73\u7ec4transformer layers\uff0c\u518d\u7ecf\u8fc7grouping block\u5f97\u52308\u4e2a\u63a9\u6a21\u7279\u5f81\u3002</li> </ul> <p>\u8bad\u7ec3\u8fc7\u7a0b\uff1a</p> <ul> <li>8\u4e2a\u7279\u5f81\u7ecf\u8fc7\u5168\u5c40\u5e73\u5747\u6c60\u5316\u3001MLP\u7b49\u7ed3\u6784\u5f97\u5230\u6700\u7ec8\u7684\u56fe\u50cf\u7279\u5f81\uff0c\u6700\u540e\u518d\u5229\u7528\u56fe\u50cf\u7279\u5f81\u548c\u6587\u672c\u7279\u5f81\u8ba1\u7b97\u5bf9\u6bd4\u635f\u5931\u3002</li> </ul> <p>\u63a8\u7406\u8fc7\u7a0b\uff1a</p> <ul> <li>\u7f51\u7edc\u8f93\u51fa\u76848\u4e2atokens\u4e0e\u6587\u672c\u7279\u5f81\u8ba1\u7b97\u76f8\u4f3c\u5ea6\uff0c\u76f8\u4f3c\u5ea6\u5927\u4e8e\u9608\u503c\u7684\u88ab\u89c6\u4e3a\u524d\u666f\uff0c\u5426\u5219\u770b\u6210\u80cc\u666f\u3002</li> </ul> <p>\u6ce8\uff1a</p> <ul> <li>\u8fd9\u91cc\u7684grouping tokens\u548cViT\u4e2d\u7684cls tokens\u3001DETR\u4e2d\u7684\u67e5\u8be2\u5411\u91cf\u529f\u80fd\u7c7b\u4f3c\uff0c\u90fd\u662f\u9884\u8bbe\u7684\u7f51\u7edc\u8f93\u51fa\uff0c\u7ecf\u8fc7TF\u6a21\u5757\u4e4b\u540e\uff0c\u9884\u8bbe\u7684\u5411\u91cf\u4f1a\u7efc\u5408\u8003\u8651\u5176\u4f59\u7684\u7279\u5f81\u5411\u91cf\uff0c\u6765\u5f97\u5230\u6700\u7ec8\u7684\u56fe\u50cf\u7279\u5f81\uff1b</li> </ul> <p>\u5c40\u9650\u6027\uff1a</p> <ul> <li>\u7531\u4e8e\u7f51\u7edc\u53ea\u8f93\u51fa8\u4e2atokens\u7279\u5f81\uff0c\u56e0\u6b64\u6700\u591a\u5206\u5272\u51fa\u516b\u4e2a\u7c7b\u522b\uff1b</li> <li>\u80cc\u666f\u5e72\u6270\u95ee\u9898\u96be\u4ee5\u89e3\u51b3\uff0cmask\u5bb9\u6613\u751f\u6210\uff0c\u4f46\u662fmask\u7684\u5206\u7c7b\u4e0d\u597d\u505a\u3002\uff08\u65e0\u76d1\u7763\u8bed\u4e49\u5206\u5272\u7684\u901a\u75c5\u2014\u2014\u96be\u4ee5\u786e\u5b9a\u7c7b\u522b\u4fe1\u606f\uff09</li> </ul>"},{"location":"transformer/CLIP/#_3","title":"\u76ee\u6807\u68c0\u6d4b\u65b9\u5411\u7684\u6539\u8fdb","text":"<p>\u672a\u5b8c\u5f85\u7eed\u3002\u3002</p> <p>\u53c2\u8003\uff1ahttps://www.bilibili.com/video/BV1FV4y1p7Lm</p>"},{"location":"transformer/DETR/","title":"DETR\u2014\u2014\u57fa\u4e8eTransformers\u7684\u7aef\u5230\u7aef\u76ee\u6807\u68c0\u6d4b\u5668","text":""},{"location":"transformer/DETR/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aEuropean Conference on Computer Vision 2020 (ECCV, 2020)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123460205.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/facebookresearch/detr\uff08Facebook\uff09</p>"},{"location":"transformer/DETR/#_2","title":"\u4ecb\u7ecd","text":"<p>\u2003\u2003\u4f20\u7edf\u7684\u76ee\u6807\u68c0\u6d4b\u90fd\u4e0d\u662f\u7aef\u5230\u7aef\u7684\u68c0\u6d4b\u65b9\u6cd5\uff08\u4f8b\u5982Faster R-CNN\uff0cYOLOv3\u7b49\u7b49\uff09\uff0c\u7f51\u7edc\u7684\u8f93\u51fa\u8f83\u591a\uff0c\u9700\u8981\u518d\u5229\u7528NMS\u8fd0\u7b97\u8fc7\u6ee4\u91cd\u53e0\u7387\u8f83\u9ad8\u7684\u8fb9\u754c\u6846\uff0c\u89e3\u51b3\u5197\u4f59\u95ee\u9898\uff0c\u5e76\u4e14\u57fa\u4e8e\u951a\u70b9\u7684\u7b97\u6cd5\u8fd8\u9700\u8981\u6839\u636e\u5177\u4f53\u4efb\u52a1\u6765\u9884\u8bbe\u951a\u70b9\uff0c\u5b9e\u65bd\u8d77\u6765\u6bd4\u8f83\u9ebb\u70e6\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u76ee\u6807\u68c0\u6d4b\u7f51\u7edc\u67b6\u6784\uff0c\u53ef\u4ee5\u5b9e\u73b0\u7aef\u5230\u7aef\u8fd0\u7b97\uff0c\u7f51\u7edc\u8f93\u51fa\u7684\u7ed3\u679c\u5c31\u662f\u6700\u7ec8\u7684\u9884\u6d4b\u7ed3\u679c\uff0c\u4e0d\u9700\u8981\u989d\u5916\u7684\u8fd0\u7b97\uff0c\u5177\u4f53\u7f51\u7edc\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u6838\u5fc3\u601d\u60f3\u5c31\u662f\u9884\u8bbe\u4e00\u7ec4\u76ee\u6807\u67e5\u8be2\u5411\u91cf\uff08\u7c7b\u4f3c\u4e8e\u96c6\u5408\u7684\u601d\u60f3\uff0c\u6587\u4e2d\u9884\u8bbe100\u4e2a\uff09\uff0c\u6bcf\u4e2a\u5411\u91cf\u6700\u540e\u90fd\u4f1a\u9884\u6d4b\u51fa\u4e00\u4e2a\u7269\u4f53\uff0c\u5982\u679c\u5411\u91cf\u88ab\u9884\u6d4b\u4e3a\u4e86\u80cc\u666f\uff0c\u5219\u4e22\u5f03\u8be5\u9884\u6d4b\uff0c\u5982\u679c\u88ab\u9884\u6d4b\u4e3a\u524d\u666f\uff0c\u5219\u8f93\u51fa\u9884\u6d4b\u7ed3\u679c\u3002</p>"},{"location":"transformer/DETR/#_3","title":"\u7f51\u7edc\u7ed3\u6784","text":"<p>\u2003\u2003\u7f51\u7edc\u4e3b\u8981\u7531\u4e09\u90e8\u5206\u7ec4\u6210\uff0cCNN\u4e3b\u5e72\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u3001Transformer\u7f16\u7801-\u89e3\u7801\u5668\u3001\u9884\u6d4b\u5934\uff08FFN\uff09\uff0c\u5176\u4e2d\u4e3b\u5e72\u7f51\u7edc\u4f7f\u7528\u7ecf\u5178\u7684CNN\u7ed3\u6784\uff08\u5982ResNet\uff09\uff0c\u9884\u6d4b\u5934\u7531\u591a\u5c42\u611f\u77e5\u673a\uff08MLP\uff09\u7ec4\u6210\u3002</p> <p>Transformer\u7f16\u7801\u5668</p> <p>\u2003\u2003\u7f16\u7801\u5668\u4e3b\u8981\u7531\u516d\u4e2aTransformer\u7f16\u7801\u5668\u6a21\u5757\u7ec4\u6210\uff0c\u9996\u5148\u4f7f\u75281\\times1\u7684\u5377\u79ef\u5c06CNN\u5f97\u5230\u7684\u7279\u5f81\u56fe\u6cbf\u901a\u9053\u65b9\u5411\u538b\u7f29\u7ef4\u5ea6\uff0c\u5e76\u4e14\u62c9\u76f4\u5bbd\u9ad8\u7ef4\u5ea6\uff0c\u6bcf\u4e2a\u901a\u9053\u53d8\u6210\u4e00\u4e2a\u5411\u91cf\uff0c\u5f97\u5230\u7f16\u7801\u7279\u5f81\uff0c\u5c3a\u5bf8\u7531(2048,\\frac H{32},\\frac W{32})\u53d8\u4e3a(256,\\frac {H}{32} * \\frac W{32})\uff0c\u4e4b\u540e\u5c06\u4f4d\u7f6e\u7f16\u7801\u548c\u7f16\u7801\u7279\u5f81\u4f9d\u6b21\u4f20\u5165\u6bcf\u4e2aTransformer\u6a21\u5757\u4e2d\u505a\u7f16\u7801\u64cd\u4f5c\uff0c\u66f4\u65b0\u7f16\u7801\u7279\u5f81\u3002</p> <p>\u2003\u2003\u5728\u591a\u5934\u6ce8\u610f\u529b\u4e2d\uff0cq\u3001k\u5143\u7d20\u4f20\u5165\u4f4d\u7f6e\u7f16\u7801\u4e0e\u7f16\u7801\u7279\u5f81\u76f8\u52a0\u540e\u7684\u6570\u636e\uff0cv\u4f20\u5165\u7279\u5f81\u56fe\u3002\u6ce8\uff1akqv\u7684\u5173\u7cfb\u7528\u4e00\u53e5\u8bdd\u6765\u8bf4\u5c31\u662f\u6839\u636ekv\u7684\u952e\u503c\u5339\u914d\u5173\u7cfb\uff0c\u9884\u6d4bq\u5bf9\u5e94\u7684\u6570\u503c\uff0c\u6839\u636ekq\u7684\u76f8\u4f3c\u5ea6\u5bf9v\u505a\u52a0\u6743\u6c42\u548c\u3002</p> <p>\u2003\u2003Transformer\u7f16\u7801\u5668\u6a21\u5757\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>Transformer\u89e3\u7801\u5668</p> <p>\u2003\u2003\u89e3\u7801\u5668\u7531\u516d\u4e2a\u89e3\u7801\u6a21\u5757\u6784\u6210\uff08\u4e0eTransformer\u4e2d\u7684\u89e3\u7801\u6a21\u5757\u76f8\u540c\uff09\uff0c\u6bcf\u4e2a\u6a21\u5757\u5747\u4ee5\u7f16\u7801\u7279\u5f81\u3001\u4f4d\u7f6e\u7f16\u7801\u3001\u76ee\u6807\u67e5\u8be2\u5411\u91cf\uff08\u9884\u8bbe\u7684\u76ee\u6807\u5411\u91cf\uff09\u3001\u89e3\u7801\u7279\u5f81\u4f5c\u4e3a\u8f93\u5165\uff0c\u89e3\u7801\u7279\u5f81\u521d\u59cb\u5316\u4e3a0 \u3002</p> <p>\u2003\u2003\u9996\u5148\u76ee\u6807\u67e5\u8be2\u5411\u91cf\u505a\u81ea\u6ce8\u610f\u529b\u64cd\u4f5c\uff0c\u5c06\u67e5\u8be2\u5411\u91cf\u4e0e\u89e3\u7801\u7279\u5f81\u4f20\u5165\u591a\u5934\u6ce8\u610f\u529b\uff0c\u5176\u4e2dq\u3001k\u5143\u7d20\u4f20\u5165\u76ee\u6807\u67e5\u8be2\u5411\u91cf\u4e0e\u89e3\u7801\u7279\u5f81\u76f8\u52a0\u540e\u7684\u6570\u636e\uff0cv\u4f20\u5165\u89e3\u7801\u7279\u5f81\u3002\u4e4b\u540e\u518d\u5c06\u6240\u5f97\u6570\u636e\u4f20\u5165\u591a\u5934\u6ce8\u610f\u529b\u4e2d\uff0cq\u4f20\u5165\u89e3\u7801\u7279\u5f81\u4e0e\u7269\u4f53\u67e5\u8be2\u5411\u91cf\u76f8\u52a0\uff0ck\u4f20\u5165\u7f16\u7801\u7279\u5f81\u4e0e\u4f4d\u7f6e\u7f16\u7801\u76f8\u52a0\uff0cv\u4f20\u5165\u7f16\u7801\u7279\u5f81\u3002</p> <p>\u2003\u2003\u7279\u5f81\u7ecf\u8fc7\u516d\u7ec4\u89e3\u7801\u6a21\u5757\u4e4b\u540e\uff0c\u4f1a\u5f97\u5230\u5c3a\u5bf8\u4e3a(N,256)\u7684\u89e3\u7801\u7279\u5f81\uff0c\u518d\u5c06\u6b64\u7279\u5f81\u4f20\u5165\u9884\u6d4b\u5934\uff0c\u53ef\u4ee5\u5f97\u5230\u7269\u4f53\u7c7b\u522b\u4ee5\u53ca\u8fb9\u754c\u6846\u5750\u6807\u6570\u636e\u3002</p> <p>\u6ce8\uff1a</p> <ul> <li>\u7279\u5f81\u4f20\u5165TF\u7f16\u7801\u5668\u5c31\u662f\u4e3a\u4e86\u8ba9\u7f51\u7edc\u53ef\u4ee5\u5b66\u4e60\u5168\u5c40\u7279\u5f81\uff0c\u66f4\u597d\u5730\u4ece\u5168\u5c40\u7684\u89d2\u5ea6\u53bb\u89e3\u51b3\u95ee\u9898\uff08\u7c7b\u4f3cNL\u6a21\u5757\uff09\uff1b</li> <li>N\u5728\u9884\u8bbe\u65f6\u8981\u5927\u4e8e\u6bcf\u5f20\u56fe\u7684\u7269\u4f53\u6570\u91cf\uff0c\u4e00\u822c\u9ed8\u8ba4\u8bbe\u6210100\uff1b</li> <li>\u7c7b\u522b\u5305\u542b\u80cc\u666f\u7c7b\uff0c\u9884\u8bbe\u7684\u76ee\u6807\u88ab\u9884\u6d4b\u4e3a\u80cc\u666f\u65f6\uff0c\u5219\u4e22\u5f03\u8be5\u9884\u6d4b\u6570\u636e\uff1b</li> <li>\u5728\u89e3\u7801\u4e2d\uff0c\u7269\u4f53\u67e5\u8be2\u5411\u91cf\u8981\u5148\u505a\u81ea\u6ce8\u610f\u529b\u64cd\u4f5c\uff0c\u4f7f\u5f97\u5404\u4e2a\u67e5\u8be2\u5411\u91cf\u53ef\u4ee5\u76f8\u4e92\u901a\u4fe1\uff0c\u8ba9\u4e0d\u540c\u7684\u5411\u91cf\u53ef\u4ee5\u5173\u6ce8\u4e0d\u540c\u7684\u7269\u4f53\uff0c\u9632\u6b62\u4e0d\u540c\u5411\u91cf\u53bb\u9884\u6d4b\u540c\u4e00\u4e2a\u76ee\u6807\u3002\u6362\u4e2a\u89d2\u5ea6\u601d\u8003\uff0c\u6b63\u662f\u7531\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\u5e7f\u6cdb\u7684\u5e94\u7528\uff0c\u624d\u4f7f\u5f97\u7aef\u5230\u7aef\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u7684\u5b9e\u73b0\u6210\u4e3a\u53ef\u80fd\uff0c\u8ba9\u4e0d\u540c\u8fb9\u754c\u6846\u4e4b\u95f4\u53ef\u4ee5\u76f8\u4e92\u5173\u6ce8\uff0c\u89e3\u51b3\u4e86\u8fb9\u754c\u6846\u5197\u4f59\u95ee\u9898\u3002</li> </ul>"},{"location":"transformer/DETR/#_4","title":"\u6807\u7b7e\u5339\u914d","text":"<p>\u2003\u2003\u9664\u4e86\u5229\u7528Transformer\u7ed3\u6784\u89e3\u51b3\u8fb9\u754c\u6846\u4e4b\u95f4\u7684\u5197\u4f59\uff0c\u8fd8\u6709\u4e00\u4e2a\u95ee\u9898\u5c31\u662f\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5982\u4f55\u5c06\u67e5\u8be2\u5411\u91cf\u7684\u9884\u6d4b\u7ed3\u679c\u4e0e\u6807\u7b7e\u76f8\u5339\u914d\uff0c\u4e5f\u5c31\u662f\u5982\u4f55\u5224\u65ad\u6bcf\u4e2a\u67e5\u8be2\u5411\u91cf\u662f\u8be5\u9884\u6d4b\u524d\u666f\u8fd8\u662f\u8be5\u9884\u6d4b\u80cc\u666f\u3002\u5bf9\u4e8e\u6bcf\u4e2a\u7269\u4f53\u6807\u7b7e\uff0c\u6211\u4eec\u6240\u671f\u671b\u7684\u5c31\u662f\u5339\u914d\u4e00\u4e2a\u548c\u4ed6\u6700\u63a5\u8fd1\u7684\u9884\u6d4b\u5411\u91cf\uff0c\u800c\u6bcf\u4e2a\u9884\u6d4b\u7ed3\u679c\u53ea\u80fd\u53bb\u5339\u914d\u4e00\u4e2a\u6807\u7b7e\uff0c\u4e0d\u80fd\u51fa\u73b0\u201c\u91cd\u590d\u9884\u6d4b\u201d\u7684\u73b0\u8c61\uff0c\u56e0\u6b64\u8be5\u4efb\u52a1\u53ef\u4ee5\u89c6\u4e3a\u4e00\u4e2a\u4e8c\u5206\u56fe\u5339\u914d\u95ee\u9898\uff0c\u672c\u6587\u4f7f\u7528\u5308\u7259\u5229\u7b97\u6cd5\u53bb\u5339\u914d\u3002\u201c\u662f\u5426\u63a5\u8fd1\u201c\u8fd9\u4e00\u6982\u5ff5\u53ef\u4ee5\u5229\u7528\u635f\u5931\u8861\u91cf\uff0c\u635f\u5931\u8d8a\u5c0f\uff0c\u8bf4\u660e\u8d8a\u63a5\u8fd1\uff0c\u8d8a\u5e94\u8be5\u5339\u914d\u8fd9\u7ec4\u5173\u7cfb\uff0c\u56e0\u6b64\u5308\u7259\u5229\u7b97\u6cd5\u4e2d\u8282\u70b9\u4e4b\u95f4\u7684\u6743\u91cd\u53ef\u4ee5\u4f7f\u7528\u635f\u5931\u53bb\u66ff\u4ee3\u3002\u67e5\u8be2\u5411\u91cf\u7684\u9884\u6d4b\u7ed3\u679c\\hat{y}_{\\sigma(i)}\u4e0e\u7269\u4f53\u6807\u7b7ey_i\u4e4b\u95f4\u7684\u635f\u5931\u6743\u91cd\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ L_{match}(y_i,\\hat{y}_{\\sigma(i)})=-\\hat{p}_{\\sigma(i)}(c_i)+L_{box}(b_i,\\hat{b}_{\\sigma(i)}) $$  \u5176\u4e2d\uff0ci\u8868\u793a\u6807\u7b7e\u7684\u7c7b\u522b\uff0c\u8fd9\u91cc\u5229\u75281-p\u53bb\u8fd1\u4f3c\u4ee3\u66ff\u8d1f\u5bf9\u6570\u4f3c\u7136\u635f\u5931(NLL\uff0c1\u53ef\u4ee5\u7701\u6389)\uff0c\u7528\u4e8e\u8861\u91cf\u7c7b\u522b\u76f8\u4f3c\u5ea6\u3002</p> <p>\u2003\u2003\u9996\u5148\u8ba1\u7b97\u6bcf\u4e2a\u67e5\u8be2\u5411\u91cf\u7684\u9884\u6d4b\u7ed3\u679c\u4e0e\u6bcf\u4e2a\u6807\u7b7e\u4e4b\u95f4\u7684\u635f\u5931\uff0c\u4e4b\u540e\u7b5b\u9009\u51fa\u4e3a\u6bcf\u4e2a\u6807\u7b7e\u5339\u914d\u51fa\u76f8\u4f3c\u5ea6\u6700\u9ad8\u7684\u9884\u6d4b\u7ed3\u679c\u3002\u5339\u914d\u5230\u6807\u7b7e\u7684\u9884\u6d4b\u7ed3\u679c\u5229\u7528\u6807\u7b7e\u53bb\u8ba1\u7b97\u68c0\u6d4b\u635f\u5931\uff0c\u5305\u62ec\u7528\u4e8e\u4f18\u5316\u5206\u7c7b\u6027\u80fd\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u548c\u4f18\u5316\u8fb9\u754c\u6846\u9884\u6d4b\u6027\u80fd\u7684L1\u3001GIoU\u635f\u5931\uff1b\u672a\u5339\u914d\u5230\u6807\u7b7e\u7684\u9884\u6d4b\u7ed3\u679c\u7edf\u4e00\u5339\u914d\u6210\u80cc\u666f\u7c7b\u522b\uff0c\u53ea\u53c2\u4e0e\u6a21\u578b\u5206\u7c7b\u6027\u80fd\u7684\u4f18\u5316\uff0c\u4e0d\u53c2\u4e0e\u8fb9\u754c\u6846\u9884\u6d4b\u7684\u4f18\u5316\u3002</p> <p>\u6ce8\uff1a</p> <ul> <li>DETR\u6807\u7b7e\u5339\u914d\u7684\u6838\u5fc3\u5339\u914d\u601d\u8def\u5c31\u662f\u6700\u5c0f\u5316\u635f\u5931\u603b\u6570\u503c\uff0c\u4e5f\u5c31\u662f\u5982\u4f55\u5339\u914d\u6807\u7b7e\u4e0e\u67e5\u8be2\u5411\u91cf\u4e4b\u95f4\u7684\u5173\u7cfb\u53ef\u4ee5\u6700\u5c0f\u5316\u603b\u635f\u5931\u5927\u5c0f\uff1b</li> <li>\u4e0d\u80fd\u5355\u7eaf\u5229\u7528IoU\u53bb\u8861\u91cf\u9884\u6d4b\u662f\u5426\u63a5\u8fd1\uff0c\u56e0\u4e3aIoU\u53ea\u5173\u6ce8\u8fb9\u754c\u6846\u4f4d\u7f6e\u662f\u5426\u91cd\u5408\uff0c\u76ee\u6807\u68c0\u6d4b\u7ed3\u679c\u8fd8\u5305\u542b\u7c7b\u522b\u8fd9\u4e00\u6982\u5ff5\uff0c\u56e0\u6b64\u9700\u8981\u7efc\u5408\u7c7b\u522b\u4e0e\u8fb9\u754c\u6846\u53bb\u5224\u65ad\u662f\u5426\u63a5\u8fd1\u3002</li> </ul>"},{"location":"transformer/DETR/#_5","title":"\u6e90\u7801","text":""},{"location":"transformer/DETR/#_6","title":"\u7f51\u7edc\u7ed3\u6784","text":"<p>\u2003\u2003\u524d\u5411\u4f20\u64ad\u6d41\u7a0b\uff1a\u8f93\u5165\u56fe\u50cf\u2192backbone\u2192encoder\u2192decoder\u2192prediction head</p> <pre><code>class DETR(nn.Module):\n    \"\"\" This is the DETR module that performs object detection \"\"\"\n    def __init__(self, backbone, transformer, num_classes, num_queries, aux_loss=False):\n        \"\"\" Initializes the model.\n        Parameters:\n            backbone: torch module of the backbone to be used. See backbone.py\n            transformer: torch module of the transformer architecture. See transformer.py\n            num_classes: number of object classes\n            num_queries: number of object queries, ie detection slot. This is the maximal number of objects\n                         DETR can detect in a single image. For COCO, we recommend 100 queries.\n            aux_loss: True if auxiliary decoding losses (loss at each decoder layer) are to be used.\n        \"\"\"\n        super().__init__()\n        self.num_queries = num_queries\n        self.transformer = transformer\n        hidden_dim = transformer.d_model\n        self.class_embed = nn.Linear(hidden_dim, num_classes + 1)\n        self.bbox_embed = MLP(hidden_dim, hidden_dim, 4, 3)\n        self.query_embed = nn.Embedding(num_queries, hidden_dim)\n        self.input_proj = nn.Conv2d(backbone.num_channels, hidden_dim, kernel_size=1)\n        self.backbone = backbone\n        self.aux_loss = aux_loss\n\n    def forward(self, samples: NestedTensor):\n        \"\"\" The forward expects a NestedTensor, which consists of:\n               - samples.tensor: batched images, of shape [batch_size x 3 x H x W]\n               - samples.mask: a binary mask of shape [batch_size x H x W], containing 1 on padded pixels\n\n            It returns a dict with the following elements:\n               - \"pred_logits\": the classification logits (including no-object) for all queries.\n                                Shape= [batch_size x num_queries x (num_classes + 1)]\n               - \"pred_boxes\": The normalized boxes coordinates for all queries, represented as\n                               (center_x, center_y, height, width). These values are normalized in [0, 1],\n                               relative to the size of each individual image (disregarding possible padding).\n                               See PostProcess for information on how to retrieve the unnormalized bounding box.\n               - \"aux_outputs\": Optional, only returned when auxilary losses are activated. It is a list of\n                                dictionnaries containing the two above keys for each decoder layer.\n        \"\"\"\n        if isinstance(samples, (list, torch.Tensor)):\n            samples = nested_tensor_from_tensor_list(samples)\n        # sample \u6709\u4e24\u7ec4\u53d8\u91cf\uff0c'tensor'\u548c'mask\u2019\uff0c\u524d\u8005\u662f\u56fe\u7247\u6570\u636e\n        # \u540e\u8005\u8868\u793a\u4e3a\u4e86\u62fc\u63a5\u591a\u4e2a\u56fe\u7247\u6240\u586b\u5145\u7684\u533a\u57df\uff0c\u7528True\u8868\u793a\uff0c\u586b\u5145\u7684\u533a\u57df\u5728\u540e\u7eed\u7684TF\u8fd0\u7b97\u4e2d\u8981\u5ffd\u7565\n        # \u5c06\u8f93\u5165\u4f20\u5165\u4e3b\u5e72\u7f51\u7edc\u4e2d\uff0c\u9ed8\u8ba4Reset50\uff0c\u5f97\u5230\u6700\u540e\u4e00\u5c42\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u548c\u4f4d\u7f6e\u7f16\u7801\uff0c\u7279\u5f81\u56fe\u901a\u9053\u6570\u4e3a2048\uff0c\u4f4d\u7f6e\u7f16\u7801\u901a\u9053\u6570\u4e3a256\n        features, pos = self.backbone(samples)\n        src, mask = features[-1].decompose()\n        assert mask is not None\n        # self.input_proj(src)\u7528\u4e8e\u538b\u7f29\u7279\u5f81\u56fe\u901a\u9053\u7ef4\u6570\uff0c2048-&gt;256\n        # self.query_embed\u7269\u4f53\u67e5\u8be2\u7f16\u7801\uff0c\u9ed8\u8ba4100*256\uff0c\u6700\u591a\u67e5\u8be2100\u4e2a\u7269\u4f53\n        # \u8fd4\u56de\u7684hs\u5c3a\u5bf8\u4e3a[6, batch, 100, 256]\uff0c6\u8868\u793a\u89e3\u7801\u5668\u4e2d\u516d\u4e2aTF\u6a21\u5757\u8f93\u51fa\u7684\u7279\u5f81\n        hs = self.transformer(self.input_proj(src), mask, self.query_embed.weight, pos[-1])[0]\n        # \u7ecf\u8fc7\u7ebf\u5f62\u6620\u5c04\u5c42\uff0c\u5f97\u5230\u5206\u7c7b\u5206\u6570\u548c\u7269\u4f53\u8fb9\u754c\u6846\u6570\u636e\n        outputs_class = self.class_embed(hs)\n        outputs_coord = self.bbox_embed(hs).sigmoid()\n        # \u63d0\u53d6\u6700\u540e\u4e00\u7ec4\u6570\u636e\uff0c\u5373\u6700\u540e\u4e00\u4e2a\u6a21\u5757\u7684\u8f93\u51fa\uff0c\u5f53\u4f5c\u7f51\u7edc\u7684\u6700\u7ec8\u9884\u6d4b\n        out = {'pred_logits': outputs_class[-1], 'pred_boxes': outputs_coord[-1]}\n        if self.aux_loss:\n            out['aux_outputs'] = self._set_aux_loss(outputs_class, outputs_coord)\n        return out\n</code></pre>"},{"location":"transformer/DETR/#tf-","title":"TF\u7f16\u7801-\u89e3\u7801\u7ed3\u6784","text":"<pre><code>class Transformer(nn.Module):\n\n    def __init__(self, d_model=512, nhead=8, num_encoder_layers=6,\n                 num_decoder_layers=6, dim_feedforward=2048, dropout=0.1,\n                 activation=\"relu\", normalize_before=False,\n                 return_intermediate_dec=False):\n        super().__init__()\n        # \u5b9a\u4e49\u7f16\u7801\u7ed3\u6784(\u75316\u4e2aTF\u6a21\u5757\u7ec4\u6210)\n        encoder_layer = TransformerEncoderLayer(d_model, nhead, dim_feedforward,\n                                                dropout, activation, normalize_before)\n        encoder_norm = nn.LayerNorm(d_model) if normalize_before else None\n        self.encoder = TransformerEncoder(encoder_layer, num_encoder_layers, encoder_norm)\n        # \u5b9a\u4e49\u89e3\u7801\u7ed3\u6784(\u75316\u4e2aTF\u6a21\u5757\u7ec4\u6210)\n        decoder_layer = TransformerDecoderLayer(d_model, nhead, dim_feedforward,\n                                                dropout, activation, normalize_before)\n        decoder_norm = nn.LayerNorm(d_model)\n        self.decoder = TransformerDecoder(decoder_layer, num_decoder_layers, decoder_norm,\n                                          return_intermediate=return_intermediate_dec)\n\n        self._reset_parameters()\n\n        self.d_model = d_model\n        self.nhead = nhead\n\n    def _reset_parameters(self):\n        for p in self.parameters():\n            if p.dim() &gt; 1:\n                nn.init.xavier_uniform_(p)\n\n    def forward(self, src, mask, query_embed, pos_embed):\n        # flatten NxCxHxW to HWxNxC\n        bs, c, h, w = src.shape\n        src = src.flatten(2).permute(2, 0, 1)\n        pos_embed = pos_embed.flatten(2).permute(2, 0, 1)\n        query_embed = query_embed.unsqueeze(1).repeat(1, bs, 1)\n        mask = mask.flatten(1)\n\n        tgt = torch.zeros_like(query_embed)\n        # \u5148\u5c06\u7279\u5f81\u56fe\u4e0e\u4f4d\u7f6e\u7f16\u7801\u4f20\u5165TF\u7f16\u7801\u5668(\u75316\u4e2aTF\u6a21\u5757\u7ec4\u6210\uff09\uff0cmask\u7528\u4e8e\u8868\u793a\u54ea\u4e9b\u4f4d\u7f6e\u4e0a\u7684\u5143\u7d20\u9700\u8981\u88ab\u5ffd\u7565(\u5ffd\u7565\u586b\u5145\u76840)\n        memory = self.encoder(src, src_key_padding_mask=mask, pos=pos_embed)\n        # tgt\u7528\u4e8e\u5b58\u50a8\u89e3\u7801\u5668\u8f93\u51fa\u7684\u7279\u5f81\uff0cmemory\u4e3a\u7f16\u7801\u5668\u8f93\u51fa\u7684\u7f16\u7801\u7279\u5f81\uff0cpos_embed\u4e3a\u4f4d\u7f6e\u7f16\u7801\n        # query_embed\u8868\u793a\u7269\u4f53\u67e5\u8be2\u7279\u5f81\u5411\u91cf\n        hs = self.decoder(tgt, memory, memory_key_padding_mask=mask,\n                          pos=pos_embed, query_pos=query_embed)\n        return hs.transpose(1, 2), memory.permute(1, 2, 0).view(bs, c, h, w)\n</code></pre>"},{"location":"transformer/DETR/#_7","title":"\u7f16\u7801","text":"<pre><code>class TransformerEncoderLayer(nn.Module):\n\n    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1,\n                 activation=\"relu\", normalize_before=False):\n        super().__init__()\n        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n        # Implementation of Feedforward model\n        self.linear1 = nn.Linear(d_model, dim_feedforward)\n        self.dropout = nn.Dropout(dropout)\n        self.linear2 = nn.Linear(dim_feedforward, d_model)\n\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.dropout1 = nn.Dropout(dropout)\n        self.dropout2 = nn.Dropout(dropout)\n\n        self.activation = _get_activation_fn(activation)\n        self.normalize_before = normalize_before\n\n    def with_pos_embed(self, tensor, pos: Optional[Tensor]):\n        return tensor if pos is None else tensor + pos\n\n    def forward_post(self,\n                     src,\n                     src_mask: Optional[Tensor] = None,\n                     src_key_padding_mask: Optional[Tensor] = None,\n                     pos: Optional[Tensor] = None):\n        q = k = self.with_pos_embed(src, pos)\n        # q\u3001k\u5143\u7d20\u4f20\u5165\u4f4d\u7f6e\u7f16\u7801\u4e0e\u7f16\u7801\u7279\u5f81\u76f8\u52a0\u540e\u7684\u6570\u636e\uff1bv\u4f20\u5165\u7279\u5f81\u56fe\u3002\u4e0b\u9762\u662f\u4e00\u4e2a\u5b8c\u6574\u7684TF\u6a21\u5757\n        src2 = self.self_attn(q, k, value=src, attn_mask=src_mask,\n                              key_padding_mask=src_key_padding_mask)[0]\n        src = src + self.dropout1(src2)\n        src = self.norm1(src)\n        src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))\n        src = src + self.dropout2(src2)\n        src = self.norm2(src)\n        return src\n\n    def forward_pre(self, src,\n                    src_mask: Optional[Tensor] = None,\n                    src_key_padding_mask: Optional[Tensor] = None,\n                    pos: Optional[Tensor] = None):\n        # \u5148\u505a\u5f52\u4e00\u5316\u8fd0\u7b97\uff0c\u518d\u505a\u6ce8\u610f\u529b\u8fd0\u7b97\n        src2 = self.norm1(src)\n        q = k = self.with_pos_embed(src2, pos)\n        src2 = self.self_attn(q, k, value=src2, attn_mask=src_mask,\n                              key_padding_mask=src_key_padding_mask)[0]\n        src = src + self.dropout1(src2)\n        src2 = self.norm2(src)\n        src2 = self.linear2(self.dropout(self.activation(self.linear1(src2))))\n        src = src + self.dropout2(src2)\n        return src\n\n    def forward(self, src,\n                src_mask: Optional[Tensor] = None,\n                src_key_padding_mask: Optional[Tensor] = None,\n                pos: Optional[Tensor] = None):\n        if self.normalize_before:\n            return self.forward_pre(src, src_mask, src_key_padding_mask, pos)\n        return self.forward_post(src, src_mask, src_key_padding_mask, pos)\n</code></pre>"},{"location":"transformer/DETR/#_8","title":"\u89e3\u7801","text":"<pre><code>class TransformerDecoderLayer(nn.Module):\n\n    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1,\n                 activation=\"relu\", normalize_before=False):\n        super().__init__()\n        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n        self.multihead_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n        # Implementation of Feedforward model\n        self.linear1 = nn.Linear(d_model, dim_feedforward)\n        self.dropout = nn.Dropout(dropout)\n        self.linear2 = nn.Linear(dim_feedforward, d_model)\n\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.norm3 = nn.LayerNorm(d_model)\n        self.dropout1 = nn.Dropout(dropout)\n        self.dropout2 = nn.Dropout(dropout)\n        self.dropout3 = nn.Dropout(dropout)\n\n        self.activation = _get_activation_fn(activation)\n        self.normalize_before = normalize_before\n\n    def with_pos_embed(self, tensor, pos: Optional[Tensor]):\n        return tensor if pos is None else tensor + pos\n\n    def forward_post(self, tgt, memory,\n                     tgt_mask: Optional[Tensor] = None,\n                     memory_mask: Optional[Tensor] = None,\n                     tgt_key_padding_mask: Optional[Tensor] = None,\n                     memory_key_padding_mask: Optional[Tensor] = None,\n                     pos: Optional[Tensor] = None,\n                     query_pos: Optional[Tensor] = None):\n        q = k = self.with_pos_embed(tgt, query_pos)\n        # \u7269\u4f53\u67e5\u8be2\u5411\u91cf\u5148\u505a\u4e00\u6b21\u81ea\u6ce8\u610f\u529b\u8fd0\u7b97\uff0c\u4f7f\u5f97\u5404\u4e2a\u8fb9\u754c\u6846\u53ef\u4ee5\u76f8\u4e92\u901a\u4fe1\uff0c\u8ba9\u4e0d\u540c\u8fb9\u754c\u6846\u53ef\u4ee5\u5173\u6ce8\u4e0d\u540c\u7684\u7269\u4f53\n        tgt2 = self.self_attn(q, k, value=tgt, attn_mask=tgt_mask,\n                              key_padding_mask=tgt_key_padding_mask)[0]\n        tgt = tgt + self.dropout1(tgt2)\n        tgt = self.norm1(tgt)\n        # q\uff1a\u89e3\u7801\u7279\u5f81\u4e0e\u7269\u4f53\u67e5\u8be2\u5411\u91cf\u76f8\u52a0\uff0ck\uff1a\u7f16\u7801\u7279\u5f81\u4e0e\u4f4d\u7f6e\u7f16\u7801\u76f8\u52a0\uff0cv\uff1a\u7f16\u7801\u7279\u5f81\n        # \u4e0b\u9762\u662f\u4e00\u4e2a\u5b8c\u6574\u7684TF\u6a21\u5757\n        tgt2 = self.multihead_attn(query=self.with_pos_embed(tgt, query_pos),\n                                   key=self.with_pos_embed(memory, pos),\n                                   value=memory, attn_mask=memory_mask,\n                                   key_padding_mask=memory_key_padding_mask)[0]\n        tgt = tgt + self.dropout2(tgt2)\n        tgt = self.norm2(tgt)\n        tgt2 = self.linear2(self.dropout(self.activation(self.linear1(tgt))))\n        tgt = tgt + self.dropout3(tgt2)\n        tgt = self.norm3(tgt)\n        return tgt\n\n    def forward_pre(self, tgt, memory,\n                    tgt_mask: Optional[Tensor] = None,\n                    memory_mask: Optional[Tensor] = None,\n                    tgt_key_padding_mask: Optional[Tensor] = None,\n                    memory_key_padding_mask: Optional[Tensor] = None,\n                    pos: Optional[Tensor] = None,\n                    query_pos: Optional[Tensor] = None):\n        tgt2 = self.norm1(tgt)\n        q = k = self.with_pos_embed(tgt2, query_pos)\n        tgt2 = self.self_attn(q, k, value=tgt2, attn_mask=tgt_mask,\n                              key_padding_mask=tgt_key_padding_mask)[0]\n        tgt = tgt + self.dropout1(tgt2)\n        tgt2 = self.norm2(tgt)\n        tgt2 = self.multihead_attn(query=self.with_pos_embed(tgt2, query_pos),\n                                   key=self.with_pos_embed(memory, pos),\n                                   value=memory, attn_mask=memory_mask,\n                                   key_padding_mask=memory_key_padding_mask)[0]\n        tgt = tgt + self.dropout2(tgt2)\n        tgt2 = self.norm3(tgt)\n        tgt2 = self.linear2(self.dropout(self.activation(self.linear1(tgt2))))\n        tgt = tgt + self.dropout3(tgt2)\n        return tgt\n\n    def forward(self, tgt, memory,\n                tgt_mask: Optional[Tensor] = None,\n                memory_mask: Optional[Tensor] = None,\n                tgt_key_padding_mask: Optional[Tensor] = None,\n                memory_key_padding_mask: Optional[Tensor] = None,\n                pos: Optional[Tensor] = None,\n                query_pos: Optional[Tensor] = None):\n        if self.normalize_before:\n            return self.forward_pre(tgt, memory, tgt_mask, memory_mask,\n                                    tgt_key_padding_mask, memory_key_padding_mask, pos, query_pos)\n        return self.forward_post(tgt, memory, tgt_mask, memory_mask,\n                                 tgt_key_padding_mask, memory_key_padding_mask, pos, query_pos)\n</code></pre>"},{"location":"transformer/DETR/#_9","title":"\u635f\u5931\u8ba1\u7b97","text":"<p>\u2003\u2003\u5c06\u8f93\u51fa\u7684100\u4e2a\u9884\u6d4b\u7ed3\u679c\u9010\u4e00\u548c\u6807\u7b7e\u505a\u5339\u914d\uff0c\u5f97\u5230\u635f\u5931\u6700\u5c0f\u7684\u5339\u914d\u7ed3\u679c\uff0c\u4e4b\u540e\u5229\u7528\u5339\u914d\u7ed3\u679c\u8ba1\u7b97\u635f\u5931\uff0c\u505a\u4f18\u5316\uff0c\u672a\u5339\u914d\u5230\u6807\u7b7e\u7684\u7edf\u4e00\u89c6\u4e3a\u80cc\u666f\u7c7b\u522b\uff0c\u53ea\u4f18\u5316\u5206\u7c7b\u7684\u9884\u6d4b\uff0c\u4e0d\u4f18\u5316\u8fb9\u754c\u6846\u9884\u6d4b\u3002</p> <pre><code>class SetCriterion(nn.Module):\n    \"\"\" This class computes the loss for DETR.\n    The process happens in two steps:\n        1) we compute hungarian assignment between ground truth boxes and the outputs of the model\n        2) we supervise each pair of matched ground-truth / prediction (supervise class and box)\n    \"\"\"\n    def __init__(self, num_classes, matcher, weight_dict, eos_coef, losses):\n        \"\"\" Create the criterion.\n        Parameters:\n            num_classes: number of object categories, omitting the special no-object category\n            matcher: module able to compute a matching between targets and proposals\n            weight_dict: dict containing as key the names of the losses and as values their relative weight.\n            eos_coef: relative classification weight applied to the no-object category\n            losses: list of all the losses to be applied. See get_loss for list of available losses.\n        \"\"\"\n        super().__init__()\n        self.num_classes = num_classes\n        self.matcher = matcher\n        self.weight_dict = weight_dict\n        self.eos_coef = eos_coef\n        self.losses = losses\n        empty_weight = torch.ones(self.num_classes + 1)\n        empty_weight[-1] = self.eos_coef\n        self.register_buffer('empty_weight', empty_weight)\n\n    def forward(self, outputs, targets):\n        \"\"\" This performs the loss computation.\n        Parameters:\n             outputs: dict of tensors, see the output specification of the model for the format\n             targets: list of dicts, such that len(targets) == batch_size.\n                      The expected keys in each dict depends on the losses applied, see each loss' doc\n        \"\"\"\n        outputs_without_aux = {k: v for k, v in outputs.items() if k != 'aux_outputs'}\n\n        # \u68c0\u7d22\u6700\u540e\u4e00\u5c42\u8f93\u51fa\u548c\u76ee\u6807\u4e4b\u95f4\u7684\u5339\u914d\uff0c\u8fd4\u56de\u5217\u8868\u6570\u636e\n        # \u6bcf\u4e2a\u6570\u636e\u5305\u542b\u4e24\u4e2a\u6570\u7ec4\uff0c\u5206\u522b\u8868\u793a\u88ab\u5339\u914d\u6846\u7684\u5e8f\u53f7\u548c\u524d\u666f\u7269\u4f53\u5e8f\u53f7\n        indices = self.matcher(outputs_without_aux, targets)\n\n        # Compute the average number of target boxes accross all nodes, for normalization purposes\n        num_boxes = sum(len(t[\"labels\"]) for t in targets)\n        num_boxes = torch.as_tensor([num_boxes], dtype=torch.float, device=next(iter(outputs.values())).device)\n        if is_dist_avail_and_initialized():\n            torch.distributed.all_reduce(num_boxes)\n        num_boxes = torch.clamp(num_boxes / get_world_size(), min=1).item()\n\n        # \u8ba1\u7b97\u6240\u6709\u7684\u635f\u5931\uff0c\u8ba1\u7b97\u635f\u5931\u65f6\uff0c\u672a\u5339\u914d\u5230\u6807\u7b7e\u7684\u9884\u6d4b\u8fb9\u754c\u6846\u4e4b\u53c2\u4e0e\u7c7b\u522b\u635f\u5931\u7684\u8ba1\u7b97\uff0c\u5212\u5206\u4e3a\u80cc\u666f\u7c7b\u522b\n        # \u4e0d\u53c2\u4e0e\u8fb9\u754c\u6846\u635f\u5931\u7684\u8ba1\u7b97(L1\u4e0eIoU)\n        losses = {}\n        for loss in self.losses:\n            losses.update(self.get_loss(loss, outputs, targets, indices, num_boxes))\n\n        # \u5728\u8f85\u52a9\u635f\u5931\u7684\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u5bf9\u6bcf\u4e2a\u4e2d\u95f4\u5c42\u7684\u8f93\u51fa\u91cd\u590d\u8fd9\u4e2a\u8fc7\u7a0b\n        # In case of auxiliary losses, we repeat this process with the output of each intermediate layer.\n        if 'aux_outputs' in outputs:\n            for i, aux_outputs in enumerate(outputs['aux_outputs']):\n                indices = self.matcher(aux_outputs, targets)\n                for loss in self.losses:\n                    if loss == 'masks':\n                        # Intermediate masks losses are too costly to compute, we ignore them.\n                        continue\n                    kwargs = {}\n                    if loss == 'labels':\n                        # Logging is enabled only for the last layer\n                        kwargs = {'log': False}\n                    l_dict = self.get_loss(loss, aux_outputs, targets, indices, num_boxes, **kwargs)\n                    l_dict = {k + f'_{i}': v for k, v in l_dict.items()}\n                    losses.update(l_dict)\n\n        return losses\n</code></pre>"},{"location":"transformer/DETR/#_10","title":"\u5308\u7259\u5229\u7b97\u6cd5\u5339\u914d\u6807\u7b7e","text":"<p>\u2003\u2003\u6838\u5fc3\u601d\u60f3\uff0c\u6700\u5c0f\u5316\u635f\u5931</p> <pre><code>class HungarianMatcher(nn.Module):\n    \"\"\"This class computes an assignment between the targets and the predictions of the network\n\n    For efficiency reasons, the targets don't include the no_object. Because of this, in general,\n    there are more predictions than targets. In this case, we do a 1-to-1 matching of the best predictions,\n    while the others are un-matched (and thus treated as non-objects).\n    \"\"\"\n\n    def __init__(self, cost_class: float = 1, cost_bbox: float = 1, cost_giou: float = 1):\n        \"\"\"Creates the matcher\n\n        Params:\n            cost_class: This is the relative weight of the classification error in the matching cost\n            cost_bbox: This is the relative weight of the L1 error of the bounding box coordinates in the matching cost\n            cost_giou: This is the relative weight of the giou loss of the bounding box in the matching cost\n        \"\"\"\n        super().__init__()\n        self.cost_class = cost_class\n        self.cost_bbox = cost_bbox\n        self.cost_giou = cost_giou\n        assert cost_class != 0 or cost_bbox != 0 or cost_giou != 0, \"all costs cant be 0\"\n\n    @torch.no_grad()\n    def forward(self, outputs, targets):\n        \"\"\" Performs the matching\n\n        Params:\n            outputs: This is a dict that contains at least these entries:\n                 \"pred_logits\": Tensor of dim [batch_size, num_queries, num_classes] with the classification logits\n                 \"pred_boxes\": Tensor of dim [batch_size, num_queries, 4] with the predicted box coordinates\n\n            targets: This is a list of targets (len(targets) = batch_size), where each target is a dict containing:\n                 \"labels\": Tensor of dim [num_target_boxes] (where num_target_boxes is the number of ground-truth\n                           objects in the target) containing the class labels\n                 \"boxes\": Tensor of dim [num_target_boxes, 4] containing the target box coordinates\n\n        Returns:\n            A list of size batch_size, containing tuples of (index_i, index_j) where:\n                - index_i is the indices of the selected predictions (in order)\n                - index_j is the indices of the corresponding selected targets (in order)\n            For each batch element, it holds:\n                len(index_i) = len(index_j) = min(num_queries, num_target_boxes)\n        \"\"\"\n        bs, num_queries = outputs[\"pred_logits\"].shape[:2]\n\n        # We flatten to compute the cost matrices in a batch\n        out_prob = outputs[\"pred_logits\"].flatten(0, 1).softmax(-1)  # [batch_size * num_queries, num_classes]\n        out_bbox = outputs[\"pred_boxes\"].flatten(0, 1)  # [batch_size * num_queries, 4]\n\n        # Also concat the target labels and boxes\n        tgt_ids = torch.cat([v[\"labels\"] for v in targets])\n        tgt_bbox = torch.cat([v[\"boxes\"] for v in targets])\n\n        # \u4f7f\u75281 - proba[target class]\u8fd1\u4f3c\u66ff\u4ee3NLL\u635f\u5931\uff0c1\u53ef\u4ee5\u5ffd\u7565\uff0c\u53ea\u8ba1\u7b97- proba[target class]\u5373\u53ef\n        cost_class = -out_prob[:, tgt_ids]\n\n        # torch.cdist\u7528\u4e8e\u8ba1\u7b97\u4e24\u4e2a\u96c6\u5408\u6240\u6709\u5411\u91cf\u4e4b\u95f4\u7684\u8ddd\u79bb\n        # Compute the L1 cost between boxes\uff0c\u8ba1\u7b97\u6240\u6709\u9884\u6d4b\u8fb9\u754c\u6846\u4e0e\u6240\u6709\u6807\u7b7e\u4e4b\u95f4\u7684L1\u8ddd\u79bb\uff0ccost_bbox\u5c3a\u5bf8\u4e3a[b*100, \u8fb9\u754c\u6846\u603b\u6570\uff08\u5ef6b\u76f8\u52a0)]\n        cost_bbox = torch.cdist(out_bbox, tgt_bbox, p=1)\n\n        # \u8ba1\u7b97\u9884\u6d4b\u6846\u4e0e\u6807\u7b7e\u6846\u4e4b\u95f4\u7684GIOU\u635f\u5931\n        cost_giou = -generalized_box_iou(box_cxcywh_to_xyxy(out_bbox), box_cxcywh_to_xyxy(tgt_bbox))\n\n        # Final cost matrix\uff0c\u5c06\u635f\u5931\u76f8\u52a0\uff0c\u5f97\u5230 \u5339\u914d\u5f97\u5206\u77e9\u9635\n        # \u6839\u636e\u5f97\u5206\u77e9\u9635\u6765\u5339\u914d\u9884\u6d4b\u6846\u4e0e\u6807\u7b7e\u6846\uff0c\u5339\u914d\u7684\u6838\u5fc3\u76ee\u7684\u5c31\u662f\u4e3a\u4e86\u6700\u5c0f\u5316\u635f\u5931\n        C = self.cost_bbox * cost_bbox + self.cost_class * cost_class + self.cost_giou * cost_giou\n        C = C.view(bs, num_queries, -1).cpu()\n\n        sizes = [len(v[\"boxes\"]) for v in targets]\n        # linear_sum_assignment\uff0c\u8c03\u7528\u5308\u7259\u5229\u7b97\u6cd5\u6765\u5339\u914d\n        indices = [linear_sum_assignment(c[i]) for i, c in enumerate(C.split(sizes, -1))]\n        return [(torch.as_tensor(i, dtype=torch.int64), torch.as_tensor(j, dtype=torch.int64)) for i, j in indices]\n</code></pre>"},{"location":"transformer/DETR/#_11","title":"\u8ba1\u7b97\u8fc7\u7a0b","text":"<pre><code>def loss_labels(self, outputs, targets, indices, num_boxes, log=True):\n    \"\"\"Classification loss (NLL) \u8ba1\u7b97\u5206\u7c7b\u635f\u5931\uff0c\u5206\u7c7b\u635f\u5931\u4f7f\u7528NLL\u8ba1\u7b97\uff0c\u548c\u524d\u9762\u5339\u914d\u8fb9\u754c\u6846\u65f6\u8ba1\u7b97\u5f97\u5206\u77e9\u9635\u7684\u8fc7\u7a0b\u76f8\u533a\u5206\n    targets dicts must contain the key \"labels\" containing a tensor of dim [nb_target_boxes]\n    \"\"\"\n    assert 'pred_logits' in outputs\n    src_logits = outputs['pred_logits']\n    # idx\uff0ctarget_classes_o\u5206\u522b\u5b9a\u4f4d\u884c(batch)\u4e0e\u5217(\u9884\u6d4b\u6846\u5e8f\u53f7)\uff0c\u5b9a\u4f4d\u88ab\u5339\u914d\u5230\u7684\u9884\u6d4b\u6846\n    idx = self._get_src_permutation_idx(indices)\n    target_classes_o = torch.cat([t[\"labels\"][J] for t, (_, J) in zip(targets, indices)])\n    # \u672a\u5339\u914d\u5230\u7269\u4f53\u7684\u5168\u90e8\u8bbe\u4e3a\u80cc\u666f\u7c7b\u522b(\u6700\u540e\u4e00\u4e2a\u5e8f\u53f7\uff09\uff0c\u5339\u914d\u5230\u7269\u4f53\u7684\u5229\u7528\u7269\u4f53\u7c7b\u522b\u4f5c\u4f18\u5316(\u4ece0\u5f00\u59cb)\n    target_classes = torch.full(src_logits.shape[:2], self.num_classes,\n                                dtype=torch.int64, device=src_logits.device)\n    target_classes[idx] = target_classes_o\n\n    # \u8ba1\u7b97\u4ea4\u53c9\u71b5\u635f\u5931\n    loss_ce = F.cross_entropy(src_logits.transpose(1, 2), target_classes, self.empty_weight)\n    losses = {'loss_ce': loss_ce}\n    if log:\n        # TODO this should probably be a separate loss, not hacked in this one here\n        losses['class_error'] = 100 - accuracy(src_logits[idx], target_classes_o)[0]\n    return losses\n\n@torch.no_grad()\ndef loss_cardinality(self, outputs, targets, indices, num_boxes):\n    \"\"\" Compute the cardinality error, ie the absolute error in the number of predicted non-empty boxes\n    This is not really a loss, it is intended for logging purposes only. It doesn't propagate gradients\n    \"\"\"\n    pred_logits = outputs['pred_logits']\n    device = pred_logits.device\n    tgt_lengths = torch.as_tensor([len(v[\"labels\"]) for v in targets], device=device)\n    # Count the number of predictions that are NOT \"no-object\" (which is the last class)\n    card_pred = (pred_logits.argmax(-1) != pred_logits.shape[-1] - 1).sum(1)\n    card_err = F.l1_loss(card_pred.float(), tgt_lengths.float())\n    losses = {'cardinality_error': card_err}\n    return losses\n\ndef loss_boxes(self, outputs, targets, indices, num_boxes):\n    \"\"\"Compute the losses related to the bounding boxes, the L1 regression loss and the GIoU loss\n       targets dicts must contain the key \"boxes\" containing a tensor of dim [nb_target_boxes, 4]\n       The target boxes are expected in format (center_x, center_y, w, h), normalized by the image size.\n    \"\"\"\n    # \u8ba1\u7b97\u8fb9\u754c\u6846\u635f\u5931\uff0c\u5305\u62ecL1\u635f\u5931\u4e0eGIoU\u635f\u5931\uff0c\u53ea\u8ba1\u7b97\u5339\u914d\u5230\u7684\u9884\u6d4b\u8fb9\u754c\u6846\n    assert 'pred_boxes' in outputs\n    idx = self._get_src_permutation_idx(indices)\n    src_boxes = outputs['pred_boxes'][idx]\n    target_boxes = torch.cat([t['boxes'][i] for t, (_, i) in zip(targets, indices)], dim=0)\n    # \u8ba1\u7b97L1\u635f\u5931\u4e0eGIoU\u635f\u5931\n    loss_bbox = F.l1_loss(src_boxes, target_boxes, reduction='none')\n\n    losses = {}\n    losses['loss_bbox'] = loss_bbox.sum() / num_boxes\n\n    loss_giou = 1 - torch.diag(box_ops.generalized_box_iou(\n        box_ops.box_cxcywh_to_xyxy(src_boxes),\n        box_ops.box_cxcywh_to_xyxy(target_boxes)))\n    losses['loss_giou'] = loss_giou.sum() / num_boxes\n    return losses\n\ndef loss_masks(self, outputs, targets, indices, num_boxes):\n    \"\"\"Compute the losses related to the masks: the focal loss and the dice loss.\n       targets dicts must contain the key \"masks\" containing a tensor of dim [nb_target_boxes, h, w]\n    \"\"\"\n    assert \"pred_masks\" in outputs\n\n    src_idx = self._get_src_permutation_idx(indices)\n    tgt_idx = self._get_tgt_permutation_idx(indices)\n    src_masks = outputs[\"pred_masks\"]\n    src_masks = src_masks[src_idx]\n    masks = [t[\"masks\"] for t in targets]\n    # TODO use valid to mask invalid areas due to padding in loss\n    target_masks, valid = nested_tensor_from_tensor_list(masks).decompose()\n    target_masks = target_masks.to(src_masks)\n    target_masks = target_masks[tgt_idx]\n\n    # upsample predictions to the target size\n    src_masks = interpolate(src_masks[:, None], size=target_masks.shape[-2:],\n                            mode=\"bilinear\", align_corners=False)\n    src_masks = src_masks[:, 0].flatten(1)\n\n    target_masks = target_masks.flatten(1)\n    target_masks = target_masks.view(src_masks.shape)\n    losses = {\n        \"loss_mask\": sigmoid_focal_loss(src_masks, target_masks, num_boxes),\n        \"loss_dice\": dice_loss(src_masks, target_masks, num_boxes),\n    }\n    return losses\n\ndef _get_src_permutation_idx(self, indices):\n    # permute predictions following indices\n    batch_idx = torch.cat([torch.full_like(src, i) for i, (src, _) in enumerate(indices)])\n    src_idx = torch.cat([src for (src, _) in indices])\n    return batch_idx, src_idx\n\ndef _get_tgt_permutation_idx(self, indices):\n    # permute targets following indices\n    batch_idx = torch.cat([torch.full_like(tgt, i) for i, (_, tgt) in enumerate(indices)])\n    tgt_idx = torch.cat([tgt for (_, tgt) in indices])\n    return batch_idx, tgt_idx\n\ndef get_loss(self, loss, outputs, targets, indices, num_boxes, **kwargs):\n    loss_map = {\n        'labels': self.loss_labels,\n        'cardinality': self.loss_cardinality,\n        'boxes': self.loss_boxes,\n        'masks': self.loss_masks\n    }\n    assert loss in loss_map, f'do you really want to compute {loss} loss?'\n    return loss_map[loss](outputs, targets, indices, num_boxes, **kwargs)\n</code></pre> <p>\u521d\u6b65\u5b8c\u7a3f\u4e8e\uff1a2023\u5e744\u670821\u65e5</p> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u6307\u6b63</p>"},{"location":"transformer/DINO/","title":"DINO\u8bba\u6587\u7b14\u8bb0","text":""},{"location":"transformer/DINO/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aICCV 2021</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttp://openaccess.thecvf.com//content/ICCV2021/papers/Caron_Emerging_Properties_in_Self-Supervised_Vision_Transformers_ICCV_2021_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/facebookresearch/dino</p>"},{"location":"transformer/DINO/#_2","title":"\u4e3b\u8981\u601d\u60f3","text":"<p>\u2003\u2003Transformer\u7531\u4e8e\u5176\u8fdc\u8ddd\u79bb\u5efa\u6a21\u7684\u4f18\u52bf\uff0c\u6700\u8fd1\u7ecf\u5e38\u7528\u4e8e\u89e3\u51b3\u89c6\u89c9\u7684\u5404\u5927\u4efb\u52a1\uff0c\u5e38\u89c1\u7684\u7b56\u7565\u5c31\u662f\u5728\u5927\u91cf\u6570\u636e\u4e0a\u8fdb\u884c\u6709\u76d1\u7763\u9884\u8bad\u7ec3\uff0c\u83b7\u5f97\u8f83\u5f3a\u7684\u8bed\u4e49\u8868\u5f81\u80fd\u529b\uff0c\u4e4b\u540e\u5728\u76ee\u6807\u6570\u636e\u4e0a\u8fdb\u884c\u5fae\u8c03\uff0c\u7528\u4e8e\u4e0b\u6e38\u4efb\u52a1\u7684\u5e94\u7528\u3002\u4f46\u8fd9\u79cd\u65b9\u6cd5\u5e76\u6ca1\u6709\u660e\u663e\u7684\u597d\u5904\uff0c\u5728\u589e\u52a0\u8ba1\u7b97\u91cf\u7684\u540c\u65f6\uff0c\u6240\u63d0\u53d6\u7684\u7279\u5f81\u5e76\u6ca1\u6709\u8868\u73b0\u51fa\u72ec\u7279\u7684\u5c5e\u6027\uff08unique properties\uff09\uff0c\u8fd9\u5c31\u4e0d\u514d\u4ea7\u751f\u7591\u95ee\uff0c\u5229\u7528\u6709\u76d1\u7763\u5f0f\u7684\u8bad\u7ec3\u7b56\u7565\uff0c\u662f\u5426\u5145\u5206\u6316\u6398\u4e86\u6a21\u578b\u7684\u7279\u5f81\u8868\u793a\u6f5c\u529b\uff1f</p> <p>\u2003\u2003\u5728\u672c\u6587\u4e2d\uff0c\u4f5c\u8005\u5229\u7528\u5f31\u76d1\u7763\u5b66\u4e60\u7b56\u7565\uff0c\u6765\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86transformer\u5728\u89c6\u89c9\u5e94\u7528\u4e2d\u7684\u80fd\u529b\u3002\u8003\u8651\u5230transformer\u5728NLP\u9886\u57df\u4e2d\u53d6\u5f97\u6210\u529f\u7684\u4e3b\u8981\u56e0\u7d20\u4e4b\u4e00\u662f\u4f7f\u7528\u4e86\u81ea\u76d1\u7763\u8bad\u7ec3\uff0c\u4f8b\u5982BERT\u4f7f\u7528MLM\uff08Masked Language Model\uff09\u7684\u81ea\u76d1\u7763\u8bad\u7ec3\u7b56\u7565\uff0c\u968f\u673a\u62b9\u6389\u90e8\u5206\u5355\u8bcd\uff0c\u4e4b\u540e\u6839\u636e\u4e0a\u4e0b\u6587\u6765\u9884\u6d4b\u8fd9\u4e2a\u5355\u8bcd\uff1bGPT\u91c7\u7528ALM\uff08Autoregressive Language Modeling\uff09\u7684\u81ea\u76d1\u7763\u8bad\u7ec3\u7b56\u7565\uff0c\u8ba9\u6a21\u578b\u6839\u636e\u524d\u6587\u6765\u9884\u6d4b\u4e0b\u4e00\u4e2a\u53ef\u80fd\u51fa\u73b0\u7684\u5355\u8bcd\u3002\u8fd9\u4e9b\u7b97\u6cd5\u5747\u4f7f\u7528\u53e5\u5b50\u4e2d\u7684\u5355\u8bcd\u6765\u521b\u5efa\u5047\u8bbe\u4efb\u52a1\uff08pretext task\uff09\uff0c\u8fd9\u79cd\u64cd\u4f5c\u53ef\u4ee5\u63d0\u4f9b\u66f4\u4e30\u5bcc\u7684\u5b66\u4e60\u4fe1\u53f7\uff0c\u53ef\u4ee5\u8ba9\u6a21\u578b\u5728\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u5b66\u5230\u66f4\u591a\u7684\u8bed\u4e49\u4fe1\u606f\uff0c\u76f8\u6bd4\u4e8e\u76d1\u7763\u5b66\u4e60\u4e2d\uff0c\u7b80\u5355\u5730\u9884\u6d4b\u6bcf\u4e2a\u53e5\u5b50\u56fa\u5b9a\u5355\u4e00\u7684\u6807\u7b7e\u96be\u4ee5\u8ba9\u7f51\u7edc\u5b66\u5230\u8fd9\u79cd\u4e30\u5bcc\u7684\u8bed\u4e49\u4fe1\u606f\uff0c\u6a21\u578b\u7684\u7406\u89e3\u80fd\u529b\u5f80\u5f80\u4f1a\u88ab\u53e5\u5b50\u7684\u6807\u7b7e\u6240\u7ea6\u675f\u3002\u540c\u6837\uff0c\u5728\u56fe\u50cf\u4efb\u52a1\u4e2d\uff0c\u56fe\u50cf\u7ea7\u522b\u7684\u76d1\u7763\u5e38\u5e38\u4f1a\u964d\u4f4e\u89c6\u89c9\u7684\u4fe1\u606f\u91cf\uff0c\u6574\u5e45\u56fe\u50cf\u4e30\u5bcc\u7684\u8bed\u4e49\u4fe1\u606f\u4f1a\u88ab\u7b80\u5316\u4e3a\u4ece\u51e0\u5343\u4e2a\u5bf9\u8c61\u7c7b\u522b\u7684\u9884\u5b9a\u4e49\u96c6\u5408\u4e2d\u9009\u62e9\u7684\u5355\u4e2a\u6982\u5ff5\uff0c\u6240\u5b66\u5230\u7684\u89c6\u89c9\u4fe1\u606f\u91cf\u4f1a\u5927\u5927\u964d\u4f4e\uff0c\u8fd9\u4e5f\u662f\u8981\u7528\u81ea\u76d1\u7763\u5b66\u4e60\u7b56\u7565\u6765\u53d6\u4ee3\u76d1\u7763\u5b66\u4e60\u7b56\u7565\u7684\u4e00\u4e2a\u6838\u5fc3\u51fa\u53d1\u70b9\u3002</p> <p>\u2003\u2003\u4f5c\u8005\u7684\u81ea\u6211\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u53ef\u4ee5\u8868\u793a\u4e3a\u4e00\u79cd\u65e0\u6807\u7b7e\u7684\u77e5\u8bc6\u84b8\u998f\u64cd\u4f5c\uff08distillation with no labels, DINO\uff09\uff0c\u901a\u8fc7\u4f7f\u7528\u6807\u51c6\u7684\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u8ba9\u5b66\u751f\u7f51\u7edc\u53bb\u5b66\u4e60\u6559\u5e08\u7f51\u7edc\u7684\u8f93\u51fa\uff0c\u540c\u65f6\u6559\u5e08\u7f51\u7edc\u7531\u52a8\u91cf\u7f16\u7801\u5668\uff08momentum encoder\uff09\u6784\u6210\uff0c\u5373\u6559\u5e08\u7f51\u7edc\u7684\u53c2\u6570\u901a\u8fc7\u5b66\u751f\u7f51\u7edc\u7684\u53c2\u6570\u6765\u52a8\u91cf\u5f0f\u5730\u66f4\u65b0\uff0c\u6700\u540e\u4f5c\u8005\u4f7f\u7528\u4e2d\u5fc3\u5316\u64cd\u4f5c\u548c\u9510\u5316\u64cd\u4f5c\uff08centering and sharpening\uff09\u6765\u907f\u514d\u6559\u5e08\u7f51\u7edc\u7684\u5d29\u6e83\u95ee\u9898\uff08collapse\uff09\u3002\u6b64\u67b6\u6784\u662f\u6bd4\u8f83\u7075\u6d3b\u7684\uff0c\u53ef\u4ee5\u5728CNN\u6216\u8005ViT\u4e0a\u8fdb\u884c\u5de5\u4f5c\uff0c\u4e0d\u9700\u8981\u4fee\u6539\u539f\u59cb\u7684\u7f51\u7edc\u67b6\u6784\uff0c\u4e5f\u4e0d\u9700\u8981\u9002\u5e94\u5185\u90e8\u6807\u51c6\u5316\u64cd\u4f5c\uff08internal normalizations \uff09\u3002</p> <p>\u2003\u2003\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u5229\u7528\u81ea\u76d1\u7763\u5b66\u4e60\u7684ViT\u7279\u5f81\u660e\u786e\u5305\u542b\u4e86\u573a\u666f\u5e03\u5c40\uff0c\u7279\u522b\u662f\u5bf9\u8c61\u8fb9\u754c\uff0c\u8fd9\u4e9b\u5173\u6ce8\u533a\u57df\u53ef\u4ee5\u5728\u6700\u540e\u4e00\u4e2a\u81ea\u6ce8\u610f\u529b\u5173\u6ce8\u6a21\u5757\u4e2d\u76f4\u63a5\u63d0\u53d6\uff0c\u540c\u65f6\uff0c\u81ea\u76d1\u7763ViT\u7f51\u7edc\u6240\u63d0\u53d6\u7684\u7279\u5f81\u5728\u57fa\u672c\u8fd1\u90bb\u5206\u7c7b\u5668k-NN\u4e0b\u8868\u73b0\u7279\u522b\u597d\uff0c\u65e0\u9700\u4efb\u4f55\u5fae\u8c03\u5c31\u53ef\u4ee5\u5728ImageNet\u4e0a\u8fbe\u523078.3%\u7684\u51c6\u786e\u7387\u3002</p> <p> <p></p> <p></p>"},{"location":"transformer/DINO/#_3","title":"\u65b9\u6cd5","text":"<p>\u77e5\u8bc6\u84b8\u998f</p> <p>\u2003\u2003\u77e5\u8bc6\u84b8\u998f\u662f\u4e00\u79cd\u5b66\u4e60\u8303\u5f0f\uff0c\u8ba9\u5b66\u751f\u7f51\u7edcg_{\\theta_s}\u53bb\u5339\u914d\u6559\u5e08\u7f51\u7edcg_{\\theta_t}\u7684\u8f93\u51fa\uff0c\u7ed9\u5b9a\u8f93\u5165\u56fe\u50cfx\uff0c\u4e24\u4e2a\u7f51\u7edc\u8f93\u51faK\u7ef4\u4e0a\u7684\u6982\u7387\u5206\u5e03\uff0c\u5206\u522b\u8868\u793a\u4e3aP_s\u548cP_t\uff08\u7531\u7f51\u7edcg\u7684\u8f93\u51fa\u8fdb\u884csoftmax\u5f52\u4e00\u5316\u5f97\u5230\uff09\uff1a $$ P_s(x)^{(i)}=\\frac{\\exp(g_{\\theta_s}(x)^{(i)}/\\tau_s)}{\\sum^K_{k=1}\\exp(g_{\\theta_s}(x)^{(k)}/\\tau_s)} $$  \u5176\u4e2d\\tau_s&gt;0\u8868\u793a\u7528\u4e8e\u63a7\u5236\u5b66\u751f\u7f51\u7edc\u8f93\u51fa\u5206\u5e03\u5c16\u9510\u7a0b\u5ea6\u7684\u6e29\u5ea6\u53c2\u6570\uff0c\u5bf9\u4e8e\u6559\u5e08\u7f51\u7edc\u7684\u6982\u7387\u5206\u5e03\uff0c\u4e5f\u6709\u540c\u6837\u7684\u516c\u5f0f\u4ee5\u53ca\u6e29\u5ea6\u8d85\u53c2\u6570\\tau_t\u3002\u7ed9\u5b9a\u4e00\u4e2a\u56fa\u5b9a\u7684\u6559\u5e08\u7f51\u7edcg_{\\theta_t}\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u4ea4\u53c9\u71b5\u635f\u5931\u6765\u5339\u914d\u5b66\u751f\u7f51\u7edc\u548c\u6559\u5e08\u7f51\u7edc\u7684\u8f93\u51fa\uff0c\u4ece\u800c\u66f4\u65b0\u5b66\u751f\u7f51\u7edc\u7684\u53c2\u6570\\theta_s\uff1a $$ \\min_{\\theta_s}H(P_t(x),P_s(x)) $$  \u5176\u4e2dH(a,b)=-a\\log b\u200b\uff0c\u8fd9\u4e00\u6b65\u7528\u4e8e\u8ba9\u5b66\u751f\u7f51\u7edc\u7684\u8f93\u51fa\u5411\u6559\u5e08\u7f51\u7edc\u9760\u62e2\uff0c\u6b64\u8fc7\u7a0b\u5e76\u4e0d\u66f4\u65b0\u6559\u5e08\u7f51\u7edc\u7684\u53c2\u6570\u3002</p> <p>\u81ea\u76d1\u7763\u5b66\u4e60</p> <p>\u2003\u2003\u77e5\u8bc6\u84b8\u998f\u8303\u5f0f\u5728\u8bbe\u8ba1\u7684\u521d\u8877\uff0c\u5c31\u662f\u4e3a\u4e86\u9488\u5bf9\u4e24\u4e2a\u4e0d\u540c\u7684\u6a21\u578b\uff0c\u7528\u590d\u6742\u5ea6\u8f83\u9ad8\u3001\u6027\u80fd\u8f83\u597d\u7684\u6a21\u578b\u53bb\u63d0\u5347\u590d\u6742\u5ea6\u8f83\u4f4e\u3001\u6027\u80fd\u8f83\u5f31\u7684\u6a21\u578b\uff0c\u5c06\u5f3a\u6a21\u578b\u7684\u80fd\u529b\u901a\u8fc7\u84b8\u998f\u7684\u65b9\u5f0f\u84b8\u7ed9\u5f31\u6a21\u578b\uff0c\u56e0\u6b64\u9700\u8981\u8ba9\u5f31\u6a21\u578b\u7684\u8f93\u51fa\u5f80\u5f3a\u6a21\u578b\u7684\u8f93\u51fa\u4e0a\u9760\u62e2\u3002\u8fd9\u91cc\u6559\u5e08\u7f51\u7edc\u8f93\u51fa\u7684\u7ed3\u679c\u76f8\u5f53\u4e8e\u4f2a\u6807\u7b7e\uff0c\u8ba9\u5b66\u751f\u7f51\u7edc\u53bb\u5b66\u4e60\uff0c\u56e0\u6b64\u5982\u679c\u6709\u4e00\u4e2a\u8bad\u7ec3\u597d\u7684\u6559\u5e08\u7f51\u7edc\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u5728\u6ca1\u6709\u771f\u5b9e\u6807\u7b7e\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u6765\u8bad\u7ec3\u5b66\u751f\u7f51\u7edc\uff0c\u8ba9\u5b66\u751f\u7f51\u7edc\u53bb\u6559\u5e08\u7f51\u7edc\u7684\u80fd\u529b\u3002\u800c\u5728\u8fd9\u7bc7\u6587\u7ae0\u4e2d\uff0c\u4f5c\u8005\u505a\u4e86\u8fdb\u4e00\u6b65\u7684\u6539\u8fdb\uff0c\u5047\u8bbe\u6559\u5e08\u7f51\u7edc\u548c\u5b66\u751f\u7f51\u7edc\u90fd\u662f\u968f\u673a\u521d\u59cb\u5316\u7684\uff0c\u4e5f\u5c31\u662f\u90fd\u9700\u8981\u8fdb\u884c\u53c2\u6570\u66f4\u65b0\uff0c\u7528\u6559\u5e08\u7f51\u7edc\u751f\u6210\u7684\u4f2a\u6807\u7b7e\u53bb\u8bad\u7ec3\u5b66\u751f\u7f51\u7edc\uff0c\u4ece\u800c\u5b9e\u73b0\u5b8c\u5168\u610f\u4e49\u4e0a\u7684\u81ea\u76d1\u7763\u8bad\u7ec3\uff0c\u73b0\u5728\u95ee\u9898\u7684\u6838\u5fc3\u5c31\u5728\u4e8e\u5982\u4f55\u52a8\u6001\u66f4\u65b0\u6559\u5e08\u7f51\u7edc\u7684\u53c2\u6570\u3002\u5728\u8fd9\u91cc\uff0c\u4f5c\u8005\u53c2\u8003\u52a8\u91cf\u66f4\u65b0\u7684\u601d\u60f3\uff0c\u5229\u7528EMA\u7b56\u7565\uff0c\u8ba9\u5b66\u751f\u7f51\u7edc\u7684\u53c2\u6570\u53bb\u66f4\u65b0\u6559\u5e08\u7f51\u7edc\u7684\u53c2\u6570\uff0c\u8fd9\u6837\u5b66\u751f\u7f51\u7edc\u5411\u6559\u5e08\u7f51\u7edc\u9760\u62e2\u7684\u540c\u65f6\u4e5f\u4f1a\u6539\u53d8\u6559\u5e08\u7f51\u7edc\uff0c\u6700\u7ec8\u4e24\u4e2a\u7f51\u7edc\u4f1a\u671d\u7740\u540c\u4e00\u4e2a\u8f93\u51fa\u7ed3\u679c\u8d8b\u52bf\u4e0a\u4f18\u5316\uff0c\u7f51\u7edc\u4e3b\u8981\u6d41\u7a0b\u56fe\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u4f46\u5176\u5b9e\u8fd8\u6709\u4e2a\u95ee\u9898\uff0c\u5982\u679c\u6559\u5e08\u7f51\u7edc\u548c\u5b66\u751f\u7f51\u7edc\u4f7f\u7528\u7684\u662f\u540c\u4e00\u4e2a\u8f93\u5165\uff0c\u90a3\u4e48\u4ed6\u4eec\u53ef\u4ee5\u8f7b\u800c\u6613\u4e3e\u5730\u5f97\u5230\u76f8\u540c\u7684\u8f93\u51fa\uff0c\u4ece\u800c\u65e0\u9700\u5b66\u4f1a\u63d0\u53d6\u56fe\u4e2d\u7684\u8bed\u4e49\u4fe1\u606f\u4e5f\u53ef\u4ee5\u5b9e\u73b0\u8fd9\u4e00\u70b9\uff0c\u8fd9\u4e0e\u6211\u4eec\u5229\u7528\u81ea\u76d1\u7763\u5b66\u4e60\u53bb\u505a\u6a21\u578b\u9884\u8bad\u7ec3\u7684\u521d\u8877\u662f\u80cc\u9053\u76f8\u9a70\u7684\uff0c\u56e0\u6b64\u8fd9\u91cc\u5bf9\u4e24\u4e2a\u6a21\u578b\u7684\u8f93\u5165\u9700\u8981\u505a\u4e0d\u540c\u7684\u5904\u7406\u3002</p> <p>\u2003\u2003\u9996\u5148\uff0c\u4f7f\u7528\u591a\u5c3a\u5ea6\u88c1\u526a\u7b56\u7565\u6784\u5efa\u540c\u4e00\u56fe\u7247\u4e0b\u7684\u4e0d\u540c\u89c6\u56fe\u3002\u7ed9\u5b9a\u4e00\u5f20\u56fe\u50cf\uff0c\u751f\u6210\u4e0d\u540c\u89c6\u89d2\u56fe\u7684\u96c6\u5408V\uff0c\u8fd9\u4e2a\u96c6\u5408\u5305\u542b\u4e24\u4e2a\u5c3a\u5bf8\u8f83\u5927\u7684\u5168\u5c40\u89c6\u56fex^g_1,x^g_2\u548c\u4e00\u4e9b\u5c3a\u5bf8\u8f83\u5c0f\u7684\u5c40\u90e8\u89c6\u56fe\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6240\u6709\u89c6\u56fe\u90fd\u4f1a\u4f20\u5165\u5b66\u751f\u7f51\u7edc\u5f97\u5230\u8f93\u51fa\uff0c\u540c\u65f6\u53ea\u5c06\u5168\u5c40\u89c6\u56fe\u4f20\u5165\u6559\u5e08\u7f51\u7edc\u5f97\u5230\u8f93\u51fa\uff0c\u635f\u5931\u51fd\u6570\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ L_s=\\min_{\\theta_s}{\\sum_{x\\in\\{x^g_1,x^g_2\\}}\\sum_{x'\\in V,x'\\neq x}H(P_t(x),P_s(x'))} $$  \u5bf9\u4e8eDINO\u7684\u57fa\u672c\u53c2\u6570\u8bbe\u7f6e\uff0c\u4f5c\u8005\u4f7f\u7528\u4e24\u4e2a\u5206\u8fa8\u7387\u4e3a224^2\u7684\u5168\u5c40\u89c6\u56fe\uff0c\u53ef\u4ee5\u8986\u76d6\u539f\u59cb\u56fe\u50cf\u7684\u5927\u90e8\u5206\u533a\u57df\uff08\u5927\u4e8e\u539f\u56fe\u768450%\uff09\uff0c\u4f7f\u7528\u591a\u4e2a\u5206\u8fa8\u7387\u4e3a96^2\u7684\u5c40\u90e8\u89c6\u56fe\uff0c\u7528\u4e8e\u8986\u76d6\u539f\u59cb\u56fe\u50cf\u7684\u4e00\u5c0f\u90e8\u5206\u533a\u57df\uff08\u5c0f\u4e8e\u539f\u56fe\u768450%\uff09\u3002\u4e24\u4e2a\u795e\u7ecf\u7f51\u7edc\u4f7f\u7528\u76f8\u540c\u7684\u7ed3\u6784g\uff0c\u540c\u65f6\u4f7f\u7528\u4e0d\u540c\u7684\u53c2\u6570\\theta_s\u548c\\theta_t\uff0c\u4f7f\u7528\u635f\u5931\u51fd\u6570L_s\u6765\u66f4\u65b0\u5b66\u751f\u7f51\u7edc\u7684\u53c2\u6570\\theta_s\u200b\u200b\u3002</p> <p>\u2003\u2003\u8fd9\u4e00\u64cd\u4f5c\u6d41\u7a0b\u4e0b\u6765\uff0c\u7f51\u7edc\u4f1a\u5b9e\u73b0\u4e00\u4e2a\u4ece\u5c40\u90e8\u8bed\u4e49\u5230\u5168\u5c40\u8bed\u4e49\u7684\u7edf\u4e00\u8fc7\u7a0b\uff0c\u4ece\u800c\u8feb\u4f7f\u7f51\u7edc\u53ef\u4ee5\u63d0\u53d6\u56fe\u50cf\u4e2d\u771f\u6b63\u6709\u610f\u4e49\u7684\u8bed\u4e49\u4fe1\u606f\uff0c\u53ea\u6709\u8fd9\u6837\uff0c\u6559\u5e08\u7f51\u7edc\u548c\u5b66\u751f\u7f51\u7edc\u624d\u53ef\u80fd\u8f93\u51fa\u76f8\u540c\u7684\u7279\u5f81\u5206\u5e03\uff0c\u8fd9\u6837\u4e5f\u5b9e\u73b0\u4e86\u5728\u65e0\u6807\u7b7e\u7684\u60c5\u51b5\u4e0b\uff0c\u63d0\u5347\u6a21\u578b\u7279\u5f81\u63d0\u53d6\u80fd\u529b\u7684\u76ee\u7684\uff0c\u7b97\u6cd5\u6574\u4e2a\u524d\u5411\u4f20\u64ad\u6d41\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u6559\u5e08\u7f51\u7edc</p> <p>\u2003\u2003\u4e0e\u5355\u7eaf\u7684\u77e5\u8bc6\u84b8\u998f\u4efb\u52a1\u4e0d\u540c\uff0c\u8fd9\u91cc\u6ca1\u6709\u5148\u9a8c\u7684\u6559\u5e08\u53c2\u6570\\theta_t\uff0c\u56e0\u6b64\u6211\u4eec\u53ea\u80fd\u901a\u8fc7\u5b66\u751f\u7f51\u7edc\u7684\u53c2\u6570\u6765\u5f97\u5230\u6559\u5e08\u7f51\u7edc\u7684\u53c2\u6570\u3002\u5728\u4f5c\u8005\u5c1d\u8bd5\u4e86\u5927\u91cf\u7684\u65b9\u6cd5\u4e4b\u540e\uff0c\u53d1\u73b0\u4f7f\u7528\u6307\u6570\u79fb\u52a8\u5e73\u5747\u7b56\u7565\uff08exponential moving average, EMA\uff09\uff0c\u5373\u52a8\u91cf\u7f16\u7801\u5668\u6548\u679c\u6700\u597d\uff0c\u66f4\u65b0\u89c4\u5219\u4e3a\uff1a $$ \\theta_t\\leftarrow \\lambda\\theta_t+(1-\\lambda)\\theta_s $$ \\lambda\u7528\u4e8e\u63a7\u5236\u52a8\u91cf\u66f4\u65b0\u7684\u5feb\u6162\uff0c\u53d8\u5316\u6ce2\u52a8\u9075\u5faa\u4ece0.996\u52301\u7684\u4f59\u5f26\u8c03\u5ea6\u5668\uff08cosine schedule\uff09\u3002 \u6574\u4e2a\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u4f5c\u8005\u53d1\u73b0\u6559\u5e08\u7f51\u7edc\u7684\u6027\u80fd\u8981\u4f18\u4e8e\u5b66\u751f\u7f51\u7edc\uff0c\u56e0\u6b64\u53ef\u4ee5\u63d0\u4f9b\u8d28\u91cf\u66f4\u9ad8\u7684\u76ee\u6807\u7279\u5f81\u6765\u6307\u5bfc\u5b66\u751f\u7f51\u7edc\u7684\u5b66\u4e60\u3002</p> <p>\u907f\u514d\u5d29\u6e83</p> <p>\u2003\u2003\u4f5c\u8005\u5728\u8fd9\u91cc\u4f7f\u7528\u4e2d\u5fc3\u64cd\u4f5c\u548c\u9510\u5316\u64cd\u4f5c\uff08centering and sharpening\uff09\u6765\u907f\u514d\u6559\u5e08\u7f51\u7edc\u7684\u5d29\u6e83\u95ee\u9898\uff0c\u4e2d\u5fc3\u64cd\u4f5c\u7528\u4e8e\u9632\u6b62\u5355\u4e2a\u7ef4\u5ea6\u7684\u7279\u5f81\u5360\u4e3b\u5bfc\u5730\u4f4d\uff0c\u4f1a\u9f13\u52b1\u6559\u5e08\u7f51\u7edc\u8f93\u51fa\u5747\u5300\u7684\u6570\u636e\u5206\u5e03\uff0c\u800c\u9510\u5316\u64cd\u4f5c\u5219\u6709\u76f8\u53cd\u7684\u4f5c\u7528\uff0c\u8fd0\u7528\u8fd9\u4e24\u79cd\u64cd\u4f5c\u53ef\u4ee5\u5e73\u8861\u4ed6\u4eec\u7684\u6548\u679c\uff0c\u8db3\u4ee5\u907f\u514d\u6559\u5e08\u7f51\u7edc\u5728\u52a8\u91cf\u66f4\u65b0\u65f6\u7684\u5d29\u6e83\u3002\u4e2d\u5fc3\u64cd\u4f5c\u76f8\u5f53\u4e8e\u5bf9\u6559\u5e08\u7f51\u7edc\u7684\u8f93\u51fa\u589e\u52a0\u4e00\u4e2a\u504f\u7f6ec\uff0c\u5373g_t(x)\\leftarrow g_t(x)+c\uff0c\u5176\u4e2dc\u7684\u66f4\u65b0\u4e5f\u5229\u7528\u52a8\u91cf\u66f4\u65b0\u7b56\u7565\uff1a</p> <p> $$ c\\leftarrow mc+(1-m)\\frac1B\\sum^B_{i=1}g_{\\theta_t}(x_i) $$  \u5176\u4e2dm&gt;0\u4e3a\u901f\u7387\u53c2\u6570\uff0cB\u4e3a\u6279\u6b21\u5927\u5c0f\uff0c\u8f93\u51fa\u9510\u5316\u662f\u901a\u8fc7\u5728\u6559\u5e08\u7f51\u7edc\u7684softmax\u5f52\u4e00\u5316\u4e2d\u4f7f\u7528\u8f83\u4f4e\u6e29\u5ea6\u53c2\u6570\\tau_t\u200b\u6765\u5b9e\u73b0\u7684\uff0c\u53cd\u5411\u4f20\u64ad\u66f4\u65b0\u53c2\u6570\u7684\u6d41\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u7b97\u6cd5\u4f2a\u4ee3\u7801\u6d41\u7a0b\u5982\u4e0b\uff1a</p> <p> <p></p> <p></p> <p>\u7f51\u7edc\u7ed3\u6784</p> <p>\u2003\u2003\u795e\u7ecf\u7f51\u7edcg\u7531\u4e3b\u5e72\u7279\u5f81\u63d0\u53d6\u7f51\u7edcf\uff08ViT\u6216ResNet\uff09\u548c\u6295\u5f71\u5934h\u7ec4\u6210\uff1ag=h\\circ f\uff0c\u4e0b\u6e38\u4efb\u52a1\u4e2d\u4f7f\u7528\u7684\u7279\u5f81\u662f\u7531f\u8f93\u51fa\u7684\u7279\u5f81\u6570\u636e\uff0c\u6295\u5f71\u5934h\u662f\u7531\u9690\u85cf\u5c42\u7ef4\u5ea6\u4e3a2048\u7684\u4e09\u5c42\u591a\u5c42\u611f\u77e5\u673a\u4ee5\u53ca\u4e00\u4e2aK\u7ef4\u6743\u503c\u5f52\u4e00\u5316\u5168\u8fde\u63a5\u5c42\u7ec4\u6210\uff0c\u5b66\u751f\u7f51\u7edc\u548c\u6559\u5e08\u7f51\u7edc\u67b6\u6784\u5b8c\u5168\u76f8\u540c\uff0cViT\u67b6\u6784\u53c2\u6570\u5982\u4e0b\u8868\u6240\u793a\uff1a</p> <p> <p></p> <p></p>"},{"location":"transformer/DINO/#_4","title":"\u603b\u7ed3","text":"<p>\u2003\u2003\u4f5c\u8005\u5229\u7528\u77e5\u8bc6\u84b8\u998f\u548c\u52a8\u91cf\u66f4\u65b0\u7b56\u7565\u5b9e\u73b0\u4e86ViT\u6a21\u578b\u5728\u89c6\u89c9\u4efb\u52a1\u4e0a\u7684\u81ea\u76d1\u7763\u8bad\u7ec3\uff0c\u901a\u8fc7\u6446\u8131\u6807\u7b7e\u7684\u7ea6\u675f\uff0c\u5145\u5206\u6316\u6398\u4e86ViT\u7b97\u6cd5\u7684\u7279\u5f81\u8868\u793a\u6f5c\u529b\uff0c\u540c\u65f6\u8be5\u7b97\u6cd5\u5b58\u5728\u4e24\u4e2a\u5728\u672a\u6765\u7684\u7814\u7a76\u4e2d\u53ef\u4ee5\u5229\u7528\u7684\u5e94\u7528\uff1a\u2460\u6240\u63d0\u53d6\u7684\u9ad8\u8d28\u91cf\u7279\u5f81\u4f20\u5165k-NN\u7b97\u6cd5\u53ef\u4ee5\u5b9e\u73b0\u8f83\u51c6\u7684\u5206\u7c7b\uff0c\u56e0\u6b64\u8be5\u7279\u5f81\u6709\u5229\u4e8e\u7528\u6765\u505a\u56fe\u50cf\u68c0\u7d22\u4efb\u52a1\uff1b\u2461\u6240\u5f97\u5230\u7684\u7279\u5f81\u6570\u636e\u5305\u542b\u4e86\u573a\u666f\u5e03\u5c40\uff0c\u6709\u5229\u4e8e\u5f31\u76d1\u7763\u56fe\u50cf\u5206\u5272\u4efb\u52a1\u3002</p>"},{"location":"transformer/DINO/#_5","title":"\u90e8\u5206\u6e90\u7801","text":"<p>\u8bad\u7ec3\u9636\u6bb5</p> <p>\u6838\u5fc3\u4ee3\u7801</p> <pre><code>for it, (images, _) in enumerate(metric_logger.log_every(data_loader, 10, header)):\n    # update weight decay and learning rate according to their schedule\n    it = len(data_loader) * epoch + it  # global training iteration\n    for i, param_group in enumerate(optimizer.param_groups):\n        param_group[\"lr\"] = lr_schedule[it]\n        if i == 0:  # only the first group is regularized\n            param_group[\"weight_decay\"] = wd_schedule[it]\n\n    # move images to gpu\n    images = [im.cuda(non_blocking=True) for im in images]\n    # teacher and student forward passes + compute dino loss\n    with torch.cuda.amp.autocast(fp16_scaler is not None):\n        teacher_output = teacher(images[:2])  # only the 2 global views pass through the teacher\n        student_output = student(images)\n        loss = dino_loss(student_output, teacher_output, epoch)\n\n    if not math.isfinite(loss.item()):\n        print(\"Loss is {}, stopping training\".format(loss.item()), force=True)\n        sys.exit(1)\n\n    # student update\n    optimizer.zero_grad()\n    param_norms = None\n    if fp16_scaler is None:\n        loss.backward()\n        if args.clip_grad:\n            param_norms = utils.clip_gradients(student, args.clip_grad)\n        utils.cancel_gradients_last_layer(epoch, student,\n                                          args.freeze_last_layer)\n        optimizer.step()\n    else:\n        fp16_scaler.scale(loss).backward()\n        if args.clip_grad:\n            fp16_scaler.unscale_(optimizer)  # unscale the gradients of optimizer's assigned params in-place\n            param_norms = utils.clip_gradients(student, args.clip_grad)\n        utils.cancel_gradients_last_layer(epoch, student,\n                                          args.freeze_last_layer)\n        fp16_scaler.step(optimizer)\n        fp16_scaler.update()\n\n    # EMA update for the teacher\n    # \u6bcf\u6b21\u8bfb\u53d6\u4e00\u6b21\u6570\u636e\uff0c\u90fd\u4f1a\u7528\u5b66\u751f\u7f51\u7edc\u7684\u53c2\u6570\u52a8\u91cf\u66f4\u65b0\u4e00\u6b21\u6559\u5e08\u7f51\u7edc\n    with torch.no_grad():\n        m = momentum_schedule[it]  # momentum parameter\n        for param_q, param_k in zip(student.module.parameters(), teacher_without_ddp.parameters()):\n            param_k.data.mul_(m).add_((1 - m) * param_q.detach().data)\n\n    # logging\n    torch.cuda.synchronize()\n    metric_logger.update(loss=loss.item())\n    metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n    metric_logger.update(wd=optimizer.param_groups[0][\"weight_decay\"])\n</code></pre> <p>DINO\u635f\u5931</p> <pre><code>class DINOLoss(nn.Module):\n    def __init__(self, out_dim, ncrops, warmup_teacher_temp, teacher_temp,\n                 warmup_teacher_temp_epochs, nepochs, student_temp=0.1,\n                 center_momentum=0.9):\n        super().__init__()\n        # \u5b66\u751f\u7f51\u7edc\u7684\u8f6f\u5316\u6e29\u5ea6\n        self.student_temp = student_temp\n        # \u4e2d\u5fc3C\u7684\u52a8\u91cf\u66f4\u65b0\u53c2\u6570\n        self.center_momentum = center_momentum\n        # \u5c0fpatch\u7684\u6570\u91cf\uff0c\u9ed8\u8ba4\u662f10\n        self.ncrops = ncrops\n        # \u521d\u59cb\u5316\u4e2d\u5fc3\u53c2\u6570center\n        self.register_buffer(\"center\", torch.zeros(1, out_dim))\n        # we apply a warm up for the teacher temperature because\n        # a too high temperature makes the training instable at the beginning\n        # \u6559\u5e08\u7f51\u7edc\u7684\u8f6f\u5316\u6e29\u5ea6\uff0c\u5bf9\u6559\u5e08\u7f51\u7edc\u7684\u8f93\u51fa\u505a\u8f6f\u5316\uff0c\u53ef\u4ee5\u63d0\u5347\u8bad\u7ec3\u521d\u671f\u7684\u7a33\u5b9a\u6027\n        self.teacher_temp_schedule = np.concatenate((\n            np.linspace(warmup_teacher_temp,\n                        teacher_temp, warmup_teacher_temp_epochs),\n            np.ones(nepochs - warmup_teacher_temp_epochs) * teacher_temp\n        ))\n\n    def forward(self, student_output, teacher_output, epoch):\n        \"\"\"\n        Cross-entropy between softmax outputs of the teacher and student networks.\n        \"\"\"\n        # \u5148\u5bf9\u5b66\u751f\u7f51\u7edc\u7684\u8f93\u51fa\u505a\u8f6f\u5316\n        student_out = student_output / self.student_temp\n        student_out = student_out.chunk(self.ncrops)\n\n        # teacher centering and sharpening\n        # \u5bf9\u6559\u5e08\u7f51\u7edc\u7684\u8f93\u51fa\u505a\u8f6f\u5316\uff0c\u540c\u65f6\u5229\u7528center\u505a\u5e73\u6ed1\u64cd\u4f5c\n        temp = self.teacher_temp_schedule[epoch]\n        teacher_out = F.softmax((teacher_output - self.center) / temp, dim=-1)\n        # \u5207\u65adteacher\u8f93\u51fa\u7684\u68af\u5ea6\uff0c\u4ea4\u53c9\u71b5\u635f\u5931\u53ea\u7528\u4e8e\u4f18\u5316\u5b66\u751f\u7f51\u7edc\n        teacher_out = teacher_out.detach().chunk(2)\n\n        total_loss = 0\n        n_loss_terms = 0\n        for iq, q in enumerate(teacher_out):\n            for v in range(len(student_out)):\n                if v == iq:\n                    # we skip cases where student and teacher operate on the same view\n                    continue\n                loss = torch.sum(-q * F.log_softmax(student_out[v], dim=-1), dim=-1)\n                total_loss += loss.mean()\n                n_loss_terms += 1\n        total_loss /= n_loss_terms\n        # \u5229\u7528\u6559\u5e08\u7f51\u7edc\u7684\u8f93\u51fa\u6765\u66f4\u65b0center\u53c2\u6570\n        self.update_center(teacher_output)\n        return total_loss\n\n    @torch.no_grad()\n    def update_center(self, teacher_output):\n        \"\"\"\n        Update center used for teacher output.\n        \"\"\"\n        # \u9996\u5148\u5bf9\u8f93\u51fa\u6cbfbatch\u6c42\u5747\u503c\n        batch_center = torch.sum(teacher_output, dim=0, keepdim=True)\n        dist.all_reduce(batch_center)\n        batch_center = batch_center / (len(teacher_output) * dist.get_world_size())\n\n        # ema update\n        # \u4e4b\u540e\u52a8\u91cf\u66f4\u65b0center\u53c2\u6570\n        self.center = self.center * self.center_momentum + batch_center * (1 - self.center_momentum)\n</code></pre> <p>\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u6307\u6b63</p>"},{"location":"transformer/DeDETR/","title":"Deformable DETR\u2014\u2014\u7b14\u8bb0","text":""},{"location":"transformer/DeDETR/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aICLR 2021</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openreview.net/pdf?id=gZ9hCDWe6ke</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/fundamentalvision/Deformable-DETR</p>"},{"location":"transformer/DeDETR/#_2","title":"\u4e3b\u8981\u601d\u60f3","text":"<p>\u2003\u2003DETR\u662f\u7b2c\u4e00\u4e2a\u5229\u7528Transformer\u5b9e\u73b0\u7684\u7aef\u5230\u7aef\u7684\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\uff0c\u5927\u5927\u7b80\u5316\u4e86\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u7684\u5b9e\u73b0\u8fc7\u7a0b\uff0c\u4f46\u662f\u4ed6\u4ecd\u5b58\u5728\u4e24\u4e2a\u95ee\u9898\uff1a\u2460\u4e0e\u73b0\u6709\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u76f8\u6bd4\uff0c\u5b83\u9700\u8981\u975e\u5e38\u957f\u7684\u8bad\u7ec3\u65f6\u95f4\u6765\u6536\u655b\uff0c\u6536\u655b\u901f\u5ea6\u7279\u522b\u6162\uff08\u5728COCO\u6570\u636e\u96c6\u4e0a\uff0c\u9700\u8981500\u4e2aepoch\u624d\u80fd\u6536\u655b\uff09\uff1b\u2461DETR\u96be\u4ee5\u68c0\u6d4b\u5c0f\u76ee\u6807\u3002\u5982\u4eca\u7684\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u901a\u5e38\u4f7f\u7528\u591a\u5c3a\u5ea6\u7279\u5f81\u6765\u68c0\u6d4b\u4e0d\u540c\u5c3a\u5ea6\u4e0b\u7684\u7269\u4f53\uff0c\u5728\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u4e2d\u68c0\u6d4b\u5c0f\u7269\u4f53\uff0c\u4f46\u662fDETR\u4e2d\u7684\u591a\u5934\u6ce8\u610f\u529b\u8fd0\u7b97\u6a21\u5757\u5bf9\u7279\u5f81\u5c3a\u5bf8\u975e\u5e38\u654f\u611f\uff0c\u5bf9\u4e8e\u4e00\u5f20\u9ad8\u5206\u8fa8\u7387\u7684\u7279\u5f81\u56fe\u4f1a\u4ea7\u751f\u96be\u4ee5\u4f30\u8ba1\u7684\u8ba1\u7b97\u91cf\uff08\u590d\u6742\u5ea6\u5448\u5e73\u65b9\u589e\u957f\uff09\u3002</p> <p>\u2003\u2003\u591a\u5934\u6ce8\u610f\u529b\u6a21\u5757\u521d\u59cb\u5316\u540e\uff0c\u5728\u8ba1\u7b97\u7279\u5f81\u6620\u5c04\u65f6\uff0c\u6bcf\u4e2a\u50cf\u7d20\u70b9\u90fd\u4f1a\u4e0e\u7279\u5f81\u56fe\u4e2d\u6240\u6709\u50cf\u7d20\u70b9\u4ea7\u751f\u4e00\u6b21\u6ce8\u610f\u529b\u8fd0\u7b97\uff0c\u5e76\u4e14\u6240\u6709\u7684\u6ce8\u610f\u529b\u4f1a\u65bd\u52a0\u51e0\u4e4e\u4e00\u6837\u7684\u6ce8\u610f\u529b\u6743\u91cd\uff0c\u800c\u6ce8\u610f\u529b\u8fd0\u7b97\u7684\u76ee\u7684\u80af\u5b9a\u662f\u60f3\u8981\u8ba9\u6ce8\u610f\u529b\u6743\u91cd\u96c6\u4e2d\u5728\u67d0\u51e0\u4e2a\u533a\u57df\uff0c\u8fd9\u4e5f\u662f\u6ce8\u610f\u529b\u6a21\u5757\u7684\u4f18\u5316\u8d8b\u52bf\uff0c\u5bf9\u4e8e\u6bcf\u4e2a\u50cf\u7d20\u70b9\u6765\u8bf4\uff0c\u4ece\u5927\u91cf\u7684\u533a\u57df\u4e2d\u6311\u9009\u51fa\u51e0\u4e2a\u6709\u610f\u4e49\u7684\u533a\u57df\u662f\u975e\u5e38\u96be\u7684\uff0c\u8fd9\u4e5f\u662f\u4e3a\u4ec0\u4e48DETR\u8bad\u7ec3\u5468\u671f\u5f88\u957f\u7684\u4e00\u4e2a\u91cd\u8981\u539f\u56e0\uff0c\u800c\u4e14\u8bad\u7ec3\u7684\u65f6\u957f\u4e5f\u4f1a\u548c\u7279\u5f81\u56fe\u5c3a\u5bf8\u5bc6\u5207\u76f8\u5173\uff1b\u540c\u65f6\uff0cTF\u7f16\u7801\u5668\u4e2d\u7684\u6ce8\u610f\u529b\u8fd0\u7b97\u4e0e\u50cf\u7d20\u6570\u503c\u5448\u5e73\u65b9\u53d8\u5316\u5173\u7cfb\uff0c\u56e0\u6b64\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u5728\u8ba1\u7b97\u6ce8\u610f\u529b\u65f6\u4f1a\u4ea7\u751f\u975e\u5e38\u9ad8\u7684\u8ba1\u7b97\u6d88\u8017\u3002</p> <p>\u2003\u2003\u6ce8\u610f\u95ee\u9898\u7684\u903b\u8f91\u5173\u7cfb\uff1a\u7a20\u5bc6\u7684\u6ce8\u610f\u529b\u8fd0\u7b97\u8981\u6c42\u5927\u91cf\u7684\u6ce8\u610f\u529b\u6743\u91cd\uff0c\u4f18\u5316\u8fd9\u4e9b\u6743\u91cd\u9700\u8981\u5f88\u957f\u7684\u8bad\u7ec3\u65f6\u95f4\uff0c\u56e0\u6b64\u5bfc\u81f4DETR\u6536\u655b\u6162\uff08\u95ee\u98981\uff09\uff0c\u8fd9\u4e00\u95ee\u9898\u540c\u6837\u662fTransformer\u6a21\u5757\u5904\u7406\u56fe\u50cf\u6570\u636e\u65f6\u7684\u901a\u75c5\uff0c\u4e0d\u540c\u4e8e\u81ea\u7136\u8bed\u8a00\uff0c\u56fe\u50cf\u6570\u636e\u672c\u8eab\u5177\u6709\u4fe1\u606f\u7a00\u758f\u7684\u7279\u70b9\uff0c\u7279\u5f81\u6570\u636e\u5c3a\u5bf8\u975e\u5e38\u5927\uff0c\u5229\u7528\u7a20\u5bc6\u7684\u6ce8\u610f\u529b\u4f1a\u4ea7\u751f\u5f88\u591a\u5197\u4f59\u7684\u8ba1\u7b97\u91cf\uff08\u6ce8\u610f\u529b\u662f\u89e3\u51b3\u4fe1\u606f\u7a00\u758f\u7684\u4e00\u4e2a\u6709\u6548\u7b56\u7565\uff0c\u4f1a\u63d0\u5347\u7b97\u6cd5\u6027\u80fd\u4e0a\u9650\uff0c\u4f46\u662f\u7a20\u5bc6\u7684\u6ce8\u610f\u529b\u673a\u5236\u4f1a\u5927\u5927\u589e\u52a0\u8ba1\u7b97\u91cf\uff0c\u4f1a\u62ac\u9ad8\u7b97\u6cd5\u6210\u672c\uff0c\u6ce8\u610f\u5e95\u5c42\u903b\u8f91\u5173\u7cfb\uff0c\u5f15\u5165\u4e00\u4e2a\u6a21\u5757\u5728\u89e3\u51b3\u67d0\u4e2a\u95ee\u9898\u7684\u540c\u65f6\u4e5f\u4f1a\u5f15\u5165\u65b0\u7684\u95ee\u9898\uff09\uff1b\u540c\u65f6\u4f20\u7edf\u7684Transformer\u8ba1\u7b97\u91cf\u4e0e\u7279\u5f81\u5c3a\u5bf8\u5bc6\u5207\u76f8\u5173\uff0c\u5206\u8fa8\u7387\u9ad8\u7684\u7279\u5f81\u4f1a\u5927\u5927\u589e\u52a0\u6ce8\u610f\u529b\u7684\u8ba1\u7b97\u91cf\uff0c\u56e0\u6b64\u76f4\u63a5\u5bfc\u81f4\u7b97\u6cd5\u4e0d\u80fd\u5229\u7528\u6d45\u5c42\u7279\u5f81\u505a\u68c0\u6d4b\uff0c\u5373\u4e0d\u80fd\u5229\u7528\u591a\u5c3a\u5ea6\u7279\u5f81\u505a\u9884\u6d4b\uff0c\u4ece\u800c\u5bfc\u81f4\u7b97\u6cd5\u5728\u68c0\u6d4b\u5c0f\u76ee\u6807\u7269\u4f53\u4e0a\u6027\u80fd\u4e0d\u597d\u3002</p> <p>\u2003\u2003\u5bf9\u4e8e\u8fd9\u4e00\u95ee\u9898\uff0c\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6cd5\u5c31\u662f\u5c06\u7a20\u5bc6\u7684\u6ce8\u610f\u529b\u8fd0\u7b97\u8f6c\u4e3a\u7a00\u758f\u7684\u6ce8\u610f\u529b\u8fd0\u7b97\uff0c\u5728\u56fe\u50cf\u9886\u57df\u4e2d\uff0c\u53ef\u53d8\u5f62\u5377\u79ef\u662f\u4e00\u79cd\u5904\u7406\u7a00\u758f\u7a7a\u95f4\u4f4d\u7f6e\u5f3a\u5927\u800c\u6709\u6548\u7684\u673a\u5236\uff0c\u5176\u4e2d\u7684\u7a00\u758f\u91c7\u6837\u601d\u60f3\u53ef\u4ee5\u5e94\u7528\u5230Transformer\u6ce8\u610f\u529b\u673a\u5236\u4e2d\uff0c\u8fdb\u4e00\u6b65\u6539\u8fdb\u6ce8\u610f\u529b\u7684\u8ba1\u7b97\u7b56\u7565\u3002</p> <p>\u2003\u2003\u672c\u6587\u4e2d\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u53ef\u53d8\u5f62\u7684DETR\u7b97\u6cd5\uff08Deformable DETR\uff09\uff0c\u7f13\u89e3\u4e86\u539f\u59cbDETR\u4e2d\u6536\u655b\u901f\u5ea6\u6162\u4ee5\u53ca\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u7684\u95ee\u9898\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u5b83\u540c\u65f6\u7ed3\u5408\u4e86\u53ef\u53d8\u5f62\u5377\u79ef\u4e2d\u7a00\u758f\u7a7a\u95f4\u91c7\u6837\u7684\u4f18\u70b9\u548cTransformer\u4e2d\u4f4d\u7f6e\u5173\u7cfb\u5efa\u6a21\u7684\u80fd\u529b\uff0c\u8ba9\u6bcf\u4e2a\u5143\u7d20\u5173\u6ce8\u4e00\u5c0f\u7ec4\u91c7\u6837\u4f4d\u7f6e\uff0c\u4f5c\u4e3a\u7279\u5f81\u56fe\u6240\u6709\u50cf\u7d20\u4e2d\u7a81\u51fa\u7684k\u6570\u636e\u5143\u7d20\u7684\u9884\u6ee4\u6ce2\u5668\u3002\u8be5\u6a21\u5757\u53ef\u4ee5\u81ea\u7136\u5730\u6269\u5c55\u5230\u805a\u5408\u591a\u5c3a\u5ea6\u7279\u5f81\uff0c\u800c\u65e0\u9700FPN\u7684\u5e2e\u52a9\uff0c\u5728Deformable DETR\u4e2d\uff0c\u4f5c\u8005\u4f7f\u7528\uff08\u591a\u5c3a\u5ea6\uff09\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u6a21\u5757\u6765\u4ee3\u66ff\u4f20\u7edf\u7684Transformer\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u5177\u4f53\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u6ce8\uff1a\u5229\u7528\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u8fd0\u7b97\u4ee3\u66ff\u4f20\u7edf\u7684\u6ce8\u610f\u529b\u8fd0\u7b97\uff0c\u5728\u63d0\u5347\u7b97\u6cd5\u8ba1\u7b97\u901f\u5ea6\u7684\u540c\u65f6\uff0c\u80af\u5b9a\u4e5f\u4f1a\u964d\u4f4e\u6a21\u578b\u68c0\u6d4b\u7cbe\u5ea6\u7684\u4e0a\u9650\uff08\u4f1a\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u524a\u5f31\u6a21\u578b\u7684\u7279\u5f81\u8868\u793a\u80fd\u529b\uff09\uff0c\u6ce8\u610f\u8fd9\u79cd\u5e73\u8861\u53d6\u820d\u7684\u5173\u7cfb\u3002\u6362\u53e5\u8bdd\u8bf4\uff0c\u5982\u679c\u6709\u5927\u91cf\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u5e76\u4e14\u5bf9\u68c0\u6d4b\u901f\u5ea6\u6ca1\u6709\u8981\u6c42\uff0c\u5219\u5229\u7528\u4f20\u7edf\u7684Transformer\u505a\u6ce8\u610f\u529b\u8fd0\u7b97\u6548\u679c\u66f4\u597d\u3002</p>"},{"location":"transformer/DeDETR/#_3","title":"\u65b9\u6cd5","text":"<p>DETR\u7f51\u7edc\u7ed3\u6784\uff1a</p> <p> <p></p> <p></p>"},{"location":"transformer/DeDETR/#_4","title":"\u53ef\u53d8\u6ce8\u610f\u529b\u6a21\u5757","text":"<p>\u2003\u2003\u5c06Transformer\u5e94\u7528\u4e8e\u56fe\u50cf\u7279\u5f81\u63d0\u53d6\u7684\u8fc7\u7a0b\u4e2d\u65f6\uff0c\u5b58\u5728\u4e00\u4e2a\u6838\u5fc3\u7684\u95ee\u9898\uff1aTransformer\u6a21\u5757\u4f1a\u8003\u8651\u6240\u6709\u7a7a\u95f4\u4f4d\u7f6e\u7684\u6743\u91cd\uff0c\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u53ef\u53d8\u6ce8\u610f\u529b\u6a21\u5757\u3002\u53d7\u5230\u53ef\u53d8\u5377\u79ef\u6a21\u5757\u7684\u542f\u53d1\uff0c\u53ef\u53d8\u6ce8\u610f\u529b\u6a21\u5757\u53ea\u5173\u6ce8\u53c2\u8003\u70b9\u5468\u56f4\u7684\u4e00\u5c0f\u90e8\u5206\u5173\u952e\u91c7\u6837\u70b9\uff0c\u4e0d\u8003\u8651\u7279\u5f81\u56fe\u7684\u5c3a\u5bf8\u5927\u5c0f\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u901a\u8fc7\u4e3a\u6bcf\u4e2a\u67e5\u8be2query\u5206\u914d\u5c11\u91cf\u3001\u56fa\u5b9a\u6570\u91cf\u7684\u952ekeys\uff08\u8fd9\u91cc\u7684\u952e\u4e5f\u5c31\u662f\u53c2\u8003\u70b9\uff0c\u5373\u540e\u9762\u7684\u91c7\u6837\u70b9\uff09\uff0cq\u4e2d\u6bcf\u4e2a\u5143\u7d20\u548c\u56fa\u5b9a\u6570\u91cf\u7684\u952ek\u505a\u76f8\u4f3c\u5ea6\u8ba1\u7b97\uff0c\u5927\u5927\u51cf\u5c11\u4e86\u8ba1\u7b97\u91cf\uff08\u539f\u6765\u7684k\u662f\u6574\u4e2a\u7279\u5f81\u56fe\uff0c\u73b0\u5728\u53ea\u9009\u53d6\u5176\u4e2d\u5c11\u91cf\u7684\u7279\u5f81\u6570\u636e\uff09\uff0c\u53ef\u4ee5\u51cf\u8f7b\u6536\u655b\u6162\u548c\u7279\u5f81\u7a7a\u95f4\u5206\u8fa8\u7387\u5927\u6240\u5e26\u6765\u7684\u95ee\u9898\u3002</p> <p>\u6ce8\uff1a\u6ce8\u610f\u529b\u8ba1\u7b97\u7684\u672c\u8d28\uff0c\u5c31\u662f\u5bf9\u4e8eq\u4e2d\u6bcf\u4e2a\u5143\u7d20\uff0c\u8ba1\u7b97\u4e0ek\u7684\u76f8\u4f3c\u5ea6\uff0c\u8fdb\u4e00\u6b65\u5bf9 k\u5bf9\u5e94\u7684v \u505a\u52a0\u6743\u64cd\u4f5c\uff0c\u6c42\u51faq\u5bf9\u5e94\u7684\u2019v\u2019\u3002</p> <p> <p></p> <p></p> <p>\u7ed9\u5b9a\u4e00\u4e2a\u8f93\u5165\u7279\u5f81\u56fex\\in R^{C\\times H\\times W}\uff0c\u5047\u8bbeq\u8868\u793a\u4e00\u4e2a\u5e26\u6709\u5185\u5bb9\u7279\u5f81z_q\u548c\u4e8c\u7ef4\u53c2\u8003\u70b9p_q\u7684\u67e5\u8be2\u5411\u91cf\uff0c\u53ef\u53d8\u6ce8\u610f\u529b\u7279\u5f81\u7684\u8ba1\u7b97\u516c\u5f0f\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ DeAtt(z_q,p_q,x)=\\sum^M_{m=1}W_m[\\sum^K_{k=1}A_{mqk}\\cdot W_m'x(p_q+\\Delta p_{mqk})] $$  \u5176\u4e2d\uff0cm\u8868\u793a\u6ce8\u610f\u529b\u7684\u5934\u6570\uff0ck\u8868\u793a\u6240\u91c7\u6837\u7684\u952e\u7684\u5e8f\u53f7\uff0cK\u8868\u793a\u603b\u91c7\u6837\u7684\u952e\u6570\uff0c\u91c7\u6837\u6570\u8981\u8fdc\u5c0f\u4e8e\u56fe\u50cf\u7279\u5f81\u5c3a\u5bf8(K\\ll HW)\uff0c\\Delta p_{mqk}\u548cA_{mqk}\u5206\u522b\u8868\u793a\u7b2cm\u4e2a\u6ce8\u610f\u529b\u5934\u3001\u7b2ck\u4e2a\u91c7\u6837\u70b9\u7684\u91c7\u6837\u504f\u79fb\u91cf\u548c\u6ce8\u610f\u529b\u6743\u91cd\u3002\u6ce8\u610f\u529b\u6743\u91cdA_{mqk}\u7684\u8303\u56f4\u5728[0,1]\u5185\uff0c\u901a\u8fc7\\sum^K_{k=1}A_{mqk}=1\u5f15\u5165\u7684\u7ea6\u675f\u8fdb\u884c\u5f52\u4e00\u5316\u64cd\u4f5c\uff08softmax\u8fd0\u7b97\uff09\uff0c\\Delta p_{mqk}\\in R^2\u4e3a\u65e0\u7ea6\u675f\u8303\u56f4\u7684\u4e8c\u7ef4\u5b9e\u6570\u3002\u7531\u4e8ep_q+\\Delta p_{mqk}\u4e0d\u662f\u6574\u6570\uff0c\u65e0\u6cd5\u76f4\u63a5\u7528\u4e8e\u5e73\u79fb\u64cd\u4f5c\uff0c\u5bf9\u6b64\u4f5c\u8005\u91c7\u7528\u53cc\u7ebf\u6027\u63d2\u503c\u64cd\u4f5c\uff08bilinear interpolation\uff09\u6765\u5b9e\u73b0\u91c7\u6837\u8fc7\u7a0b\uff0c\u5373x(p_q+\\Delta p_{mqk})\uff0c\\Delta p_{mqk}\u548cA_{mqk}\u901a\u8fc7\u67e5\u8be2\u7279\u5f81z_q\u4e0a\u7684\u7ebf\u6027\u6295\u5f71\u5f97\u5230\u3002\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u5c06\u67e5\u8be2\u7279\u5f81z_q\u4f20\u5165\u7ebf\u6027\u56de\u5f52\u5c42\uff0c\u5f97\u5230\u901a\u9053\u6570\u4e3a2MK\u7684\u91c7\u6837\u504f\u79fb\u91cf\u7f16\u7801\\Delta p_{mqk}\u548c\u901a\u9053\u6570\u4e3aMK\u7684\u6ce8\u610f\u529b\u6743\u91cdA_{mqk}\uff08\u6743\u91cd\u4f1a\u7ecf\u8fc7\u4e00\u6b21softmax\u8fd0\u7b97\uff09\u3002</p> <p>\u2003\u2003\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u6a21\u5757\u7528\u4e8e\u5904\u7406\u5173\u952e\u5143\u7d20\u7684\u5377\u79ef\u7279\u5f81\uff0c\u8bbeN_q\u4e3a\u67e5\u8be2\u5143\u7d20\u7684\u6570\u91cf\uff0c\u5f53MK\u8f83\u5c0f\u65f6\uff0c\u53ef\u53d8\u5377\u79ef\u6a21\u5757\u7684\u590d\u6742\u5ea6\u4e3aO(2N_qC^2+\\min(HWC^2,N_qKC^2))\uff0c\u5c06\u5176\u5e94\u7528\u4e8eDETR\u7684\u7f16\u7801\u5668\u65f6\uff0c\u6709N_q=HW\uff0c\u590d\u6742\u5ea6\u53d8\u4e3aO(HWC^2)\uff0c\u590d\u6742\u5ea6\u4e0e\u7a7a\u95f4\u5927\u5c0f\u5448\u7ebf\u6027\u5173\u7cfb\uff0c\u5f53\u5176\u5e94\u7528\u4e8eDETR\u7684\u89e3\u7801\u5668\u65f6\uff0c\u6709N_q=N\uff08N\u4e3a\u7269\u4f53\u67e5\u8be2\u5411\u91cf\u7684\u6570\u91cf(object queries)\uff09\uff0c\u590d\u6742\u5ea6\u53d8\u4e3aO(NKC^2)\uff0c\u4e0e\u7a7a\u95f4\u5c3a\u5bf8HW\u65e0\u5173\u3002</p> <p>\u6ce8\uff1a\u5bf9\u4e8e\u7279\u5f81\u56fe\u4e0a\u7684\u6bcf\u4e2a\u50cf\u7d20\u70b9\uff0c\u4f20\u7edf\u7684\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\uff0c\u4f1a\u5bf9\u7279\u5f81\u56fe\u4e0a\u6240\u6709\u7684\u70b9\u90fd\u6c42\u4e00\u6b21\u6743\u91cd\uff0c\u5373\u7279\u5f81\u56fe\u4e0a\u6240\u6709\u7684\u70b9\u90fd\u4f1a\u5bf9\u8be5\u70b9\u4ea7\u751f\u5f71\u54cd\uff0c\u8ba1\u7b97\u91cf\u6bd4\u8f83\u5927\uff0c\u800c\u4e14\u6bd4\u8f83\u5197\u4f59\uff0c\u5728\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u6a21\u5757\u4e2d\uff0c\u53ea\u4f1a\u9009\u53d6\u56fe\u91cc\u7684K\u4e2a\u70b9\u6c42\u4e00\u6b21\u6743\u91cd\uff0c\u5373\u53ea\u9009\u53d6\u5bf9\u5f53\u524d\u70b9\u5f71\u54cd\u6bd4\u8f83\u5927\u7684K\u4e2a\u70b9\uff0c\u6765\u5bf9\u5f53\u524d\u70b9\u4ea7\u751f\u5f71\u54cd\uff0c\u5927\u5e45\u5ea6\u51cf\u5c0f\u4e86\u8fd0\u7b97\u91cf\u3002</p>"},{"location":"transformer/DeDETR/#_5","title":"\u591a\u5c3a\u5ea6\u53ef\u53d8\u6ce8\u610f\u529b\u6a21\u5757","text":"<p>\u2003\u2003\u7531\u4e8e\u591a\u5c3a\u5ea6\u7279\u5f81\u53ef\u4ee5\u7075\u6d3b\u8868\u793a\u5927\u7269\u4f53\u548c\u5c0f\u7269\u4f53\uff0c\u5f53\u524d\u5927\u90e8\u5206\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u90fd\u7528\u5230\u4e86\u591a\u5c3a\u5ea6\u7279\u5f81\uff0c\u672c\u7b97\u6cd5\u7684\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u6a21\u5757\u53ef\u4ee5\u81ea\u7136\u5730\u6269\u5c55\u5230\u591a\u5c3a\u5ea6\u7279\u5f81\u56fe\u4e0a\u3002</p> <p>\u2003\u2003\u5047\u8bbe\\{x^l\\}^L_{l=1}\u4e3a\u591a\u5c3a\u5ea6\u7279\u5f81\u56fe\uff0c\u5176\u4e2dx^l\\in R^{C\\times H_l\\times W_l}\uff0c\u5047\u8bbe\\hat p\\in[0,1]^2\u4e3a\u6bcf\u4e2a\u67e5\u8be2\u5411\u91cfq\u53c2\u8003\u70b9\u7684\u5f52\u4e00\u5316\u5750\u6807\uff0c\u591a\u5c3a\u5ea6\u53ef\u53d8\u6ce8\u610f\u529b\u6a21\u5757\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ MSDeAtt(z_q,\\hat p_q,\\{x^l\\}^L_{l=1})=\\sum^M_{m=1}W_m[\\sum^L_{l=1}\\sum^K_{k=1}A_{mlqk}\\cdot W_m'x^l(\\phi_l(\\hat p_q)+\\Delta p_{mlqk})] $$  \u5176\u4e2dm\u8868\u793a\u6ce8\u610f\u529b\u5934\u7684\u7d22\u5f15\u5e8f\u53f7\uff0cl\u8868\u793a\u8f93\u5165\u7279\u5f81\u7684\u5c42\u7ea7\u7d22\u5f15\uff0ck\u8868\u793a\u91c7\u6837\u70b9\u7684\u7d22\u5f15\uff0c\\Delta p_{mlqk}\u548cA_{mlqk}\u5206\u522b\u8868\u793a\u7b2cl\u5c42\u7279\u5f81\u3001\u7b2cm\u4e2a\u6ce8\u610f\u529b\u5934\u7684\uff0c\u91c7\u6837\u70b9\u7684\u504f\u79fb\u91cf\u548c\u7b2ck\u4e2a\u91c7\u6837\u70b9\u7684\u6ce8\u610f\u529b\u6743\u91cd\uff0c\u6ce8\u610f\u529b\u6743\u91cdA_{mlqk}\u4f1a\u7531\u516c\u5f0f\\sum^L_{l=1}\\sum^K_{k=1}A_{mlqk}=1\u8fdb\u884c\u5f52\u4e00\u5316\u3002\u4e3a\u4e86\u6e05\u6670\u5730\u8868\u8ff0\u56fe\u50cf\u7684\u5c3a\u5ea6\uff0c\u4f5c\u8005\u4f7f\u7528\u5f52\u4e00\u5316\u540e\u7684\u5750\u6807\\hat p_q\\in[0,1]^2\u6765\u8868\u793a\u6bcf\u4e2a\u53c2\u8003\u91c7\u6837\u70b9\uff0c\u5176\u4e2d(0,0)\u548c(1,1)\u5206\u522b\u8868\u793a\u56fe\u50cf\u7684\u5de6\u4e0a\u89d2\u548c\u53f3\u4e0b\u89d2\u3002\u5f0f\u4e2d\u7684\u51fd\u6570\\phi_l(\\hat p_q)\u5c06\u5f52\u4e00\u5316\u5750\u6807\\hat p_q\u91cd\u65b0\u7f29\u653e\u4e3a\u7b2cl\u5c42\u7684\u8f93\u5165\u7279\u5f81\u56fe\uff0c\u591a\u5c3a\u5ea6\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u6a21\u5757\u4e0e\u4e4b\u524d\u7684\u5355\u5c3a\u5ea6\u7248\u672c\u975e\u5e38\u76f8\u4f3c\uff0c\u533a\u522b\u5728\u4e8e\u5b83\u4ece\u591a\u4e2a\u5c3a\u5ea6\u7279\u5f81\u56fe\u4e2d\u91c7\u6837KL\u4e2a\u70b9\uff0c\u800c\u4e0d\u662f\u4ece\u5355\u5c3a\u5ea6\u7279\u5f81\u56fe\u4e2d\u91c7\u6837K\u4e2a\u70b9\u3002\u7b80\u5355\u6765\u8bf4\uff0c\u5c31\u662f\u5c06\u6240\u6709\u5c42\u7ea7\u7684\u5e8f\u5217\u7279\u5f81\u6cbf\u5c42\u7ea7\u65b9\u5411\u5408\u5e76\uff08\u5408\u5e76\u4e4b\u524d\u4f1a\u5728\u6bcf\u4e2a\u5c42\u7ea7\u7279\u5f81\u4e0a\u5206\u522b\u6dfb\u52a0\u4e00\u4e2a\u5c42\u7ea7\u7f16\u7801\u7279\u5f81\uff09\uff0c\u4e4b\u540e\u5728\u4e0d\u540c\u5c42\u7ea7\u4e0a\u9884\u8bbe\u53c2\u8003\u70b9\uff08\u5c42\u7ea7\u8d8a\u6d45\uff0c\u5219\u53c2\u8003\u70b9\u6b65\u5e45\u8d8a\u5c0f\uff09\uff0c\u8fdb\u4e00\u6b65\u4f20\u5165\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u6a21\u5757\u3002</p> <p>\u2003\u2003\u5f53K=L=1\uff0c\u5e76\u4e14W_m'\\in R^{C_v\\times C}\u56fa\u5b9a\u4e3a\u5355\u4f4d\u77e9\u9635\u65f6\uff0c\u6240\u63d0\u51fa\u7684\u6ce8\u610f\u529b\u6a21\u5757\u5c06\u9000\u5316\u4e3a\u53ef\u53d8\u5f62\u5377\u79ef\uff0c\u53ef\u53d8\u5f62\u5377\u79ef\u662f\u4e3a\u5355\u5c3a\u5ea6\u8f93\u5165\u8bbe\u8ba1\u7684\uff0c\u6bcf\u4e2a\u6ce8\u610f\u529b\u5934\u53ea\u96c6\u4e2d\u5728\u4e00\u4e2a\u91c7\u6837\u70b9\u4e0a\u3002\u7136\u800c\uff0c\u6211\u4eec\u7684\u591a\u5c3a\u5ea6\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u4f1a\u67e5\u770b\u6765\u81ea\u591a\u5c3a\u5ea6\u8f93\u5165\u7684\u591a\u4e2a\u91c7\u6837\u70b9\uff0c\u6240\u63d0\u51fa\u7684\uff08\u591a\u5c3a\u5ea6\uff09\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u6a21\u5757\u4e5f\u53ef\u4ee5\u89c6\u4e3aTransformer\u6ce8\u610f\u529b\u673a\u5236\u7684\u6709\u6548\u53d8\u4f53\uff0c\u5176\u4e2d\u53ef\u53d8\u5f62\u91c7\u6837\u5b9a\u4f4d\u5f15\u5165\u4e86\u9884\u6ee4\u6ce2\u5668\u673a\u5236\uff08pre-filtering\uff09\uff0c\u4e5f\u5c31\u662f\u53ea\u5728\u91c7\u6837\u70b9\u4e0a\u505a\u6ee4\u6ce2\u64cd\u4f5c\uff08\u5373\u52a0\u6743\u6c42\u548c\u64cd\u4f5c\uff09\uff0c\u5f53\u91c7\u6837\u70b9\u904d\u5386\u6240\u6709\u53ef\u80fd\u7684\u4f4d\u7f6e\u65f6\uff0c\u6240\u63d0\u51fa\u7684\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u7b49\u540c\u4e8eTransformer\u6ce8\u610f\u529b\u3002</p> <p>\u8fd9\u91cc\u53ef\u53d8\u5f62\u5377\u79ef\u662f\u4e3a\u5355\u5c3a\u5ea6\u8f93\u5165\u8bbe\u8ba1\u7684\u662f\u5565\u610f\u601d\uff1f\u518d\u770b\u770b\u53ef\u53d8\u5f62\u5377\u79ef\u90a3\u5757\uff1b</p>"},{"location":"transformer/DeDETR/#tf","title":"\u53ef\u53d8\u5f62\u7684TF\u7f16\u7801\u5668","text":"<p>\u2003\u2003\u4f5c\u8005\u5229\u7528\u591a\u5c3a\u5ea6\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u6a21\u5757\u66ff\u6362\u4e86DETR\u4e2d\u7684TF\u7f16\u7801\u5668\uff0c\u7f16\u7801\u5668\u7684\u8f93\u5165\u548c\u8f93\u5165\u5177\u6709\u76f8\u540c\u5206\u8fa8\u7387\u7684\u591a\u5c3a\u5ea6\u7279\u5f81\uff0c\u5728\u7f16\u7801\u5668\u4e2d\uff0c\u6211\u4eec\u4eceResNet\u4e2dC3\u5230C5\u9636\u6bb5\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u63d0\u53d6\u591a\u5c3a\u5ea6\u7279\u5f81\u56fe\\{x^l\\}^{L-1}_{l=1}(L=4)\uff08\u5176\u4e2dResNet\u8f93\u51fa\u7684\u7279\u5f81\u4f1a\u9996\u5148\u7ecf\u8fc7\u4e00\u5c421\\times1\u7684\u5377\u79ef\u5c42\uff0c\u7528\u4e8e\u7edf\u4e00\u7279\u5f81\u56fe\u7684\u901a\u9053\u6570\uff0c\u7edf\u4e00\u6210256\uff09\uff0c\u5176\u4e2dC_l\u7684\u5206\u8fa8\u7387\u662f\u8f93\u5165\u56fe\u50cf\u7684\\frac{1}{2^l}\u500d\uff0c\u6ce8\u610f\uff0c\u5206\u8fa8\u7387\u6700\u5c0f\u7684\u7279\u5f81\u56fex^L\u662f\u7531C5\u7684\u8f93\u51fa\u7ecf\u8fc7\u4e00\u5c42\u5377\u79ef\u6838\u4e3a3\\times3\uff0c\u5e76\u4e14\u6b65\u957f\u4e3a2\u7684\u5377\u79ef\u5c42\u5f97\u5230\uff0c\u5b9a\u4e49\u4e3aC6\uff0c\u6240\u6709\u7684\u7279\u5f81\u56fe\u901a\u9053\u6570\u5747\u4e3a256\u3002\u6ce8\u610f\uff0c\u4f5c\u8005\u5e76\u6ca1\u6709\u7528\u5230FPN\u4e2d\u81ea\u9876\u5411\u4e0b\u7684\u7ed3\u6784\uff0c\u56e0\u4e3a\u6240\u63d0\u51fa\u7684\u591a\u5c3a\u5ea6\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u6a21\u5757\u672c\u8eab\u5c31\u53ef\u4ee5\u5728\u591a\u5c3a\u5ea6\u7279\u5f81\u6620\u5c04\u4e4b\u95f4\u8fdb\u884c\u4fe1\u606f\u4ea4\u6362\uff0cTF\u5e8f\u5217\u95f4\u7684\u5efa\u6a21\u80fd\u529b\u5b9e\u73b0\u4e86\u8fd9\u4e00\u70b9\u3002\uff08\u8bba\u6587\u7684\u9644\u5f55\u4e2d\u9a8c\u8bc1\u4e86\uff0c\u5f15\u5165FPN\u7ed3\u6784\u4e0d\u4f1a\u63d0\u9ad8\u6a21\u578b\u6700\u7ec8\u7684\u6027\u80fd\uff09</p> <p>\u2003\u2003\u5728\u7f16\u7801\u5668\u4e2d\u5e94\u7528\u591a\u5c3a\u5ea6\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u8f93\u51fa\u662f\u4e0e\u8f93\u5165\u5206\u8fa8\u7387\u76f8\u540c\u7684\u591a\u5c3a\u5ea6\u7279\u5f81\u56fe\uff0c\u952e\u548c\u67e5\u8be2\u5143\u7d20\u90fd\u662f\u6765\u81ea\u591a\u5c3a\u5ea6\u7279\u5f81\u56fe\u7684\u50cf\u7d20\uff0c\u5bf9\u4e8e\u6bcf\u4e2a\u67e5\u8be2\u5411\u91cf\u7684\u50cf\u7d20\uff0c\u53c2\u8003\u70b9\u662f\u5176\u672c\u8eab\uff0c\u4e3a\u4e86\u8bc6\u522b\u6bcf\u4e2a\u67e5\u8be2\u50cf\u7d20\u6240\u5904\u7684\u7279\u5f81\u7ea7\u522b\uff0c\u9664\u4e86\u5d4c\u5165\u4f4d\u7f6e\u7f16\u7801\u4ee5\u5916\uff0c\u4f5c\u8005\u8fd8\u5728\u7279\u5f81\u8868\u793a\u4e2d\u6dfb\u52a0\u4e86\u4e00\u4e2a\u5c3a\u5ea6\u7f16\u7801\uff0c\u8868\u793a\u4e3a\\{e_l\\}^L_{l=1}\uff0c\u4e0e\u4f4d\u7f6e\u7f16\u7801\u4e0d\u540c\uff08\u4f4d\u7f6e\u7f16\u7801\u662f\u56fa\u5b9a\u7684\uff09\uff0c\u5c3a\u5ea6\u7f16\u7801\u662f\u968f\u673a\u521d\u59cb\u5316\u7684\uff0c\u5e76\u4e14\u4e0e\u7f51\u7edc\u5171\u540c\u8bad\u7ec3\u3002</p> <p>\u53ef\u53d8\u5f62\u7684TF\u89e3\u7801\u5668</p> <p>\u2003\u2003\u89e3\u7801\u5668\u4e2d\u6709\u4ea4\u53c9\u6ce8\u610f\u529b\u6a21\u5757\u548c\u81ea\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u8fd9\u4e24\u79cd\u6ce8\u610f\u529b\u6a21\u5757\u7684\u67e5\u8be2\u5143\u7d20\uff08\u5373q\u503c\uff09\u90fd\u662f\u7269\u4f53\u67e5\u8be2\u5411\u91cfQ\uff0c\u5728\u4ea4\u53c9\u6ce8\u610f\u529b\u4e2d\uff0c\u7269\u4f53\u67e5\u8be2\u5411\u91cf\u4ece\u7279\u5f81\u56fe\u4e2d\u63d0\u53d6\u7279\u5f81\uff0c\u952e\uff08k\uff09\u4e3a\u4ece\u7f16\u7801\u5668\u8f93\u51fa\u7684\u7279\u5f81\u56fe\uff1b\u5728\u81ea\u6ce8\u610f\u529b\u6a21\u5757\u4e2d\uff0c\u7269\u4f53\u67e5\u8be2\u76f8\u4e92\u4ea4\u4e92\uff0c\u952e\uff08k\uff09\u4e3a\u7269\u4f53\u7684\u67e5\u8be2\u5411\u91cf\u3002\u7531\u4e8e\u63d0\u51fa\u7684\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u6a21\u5757\u662f\u4e3a\u4e86\u5904\u7406\u5377\u79ef\u7279\u5f81\u6620\u5c04\u4f5c\u4e3a\u952e\uff08k\uff09\u503c\u5143\u7d20\uff0c\u56e0\u6b64\u4f5c\u8005\u53ea\u5c06\u6bcf\u4e2a\u4ea4\u53c9\u6ce8\u610f\u529b\u6a21\u5757\u66ff\u6362\u4e3a\u591a\u5c3a\u5ea6\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u4fdd\u6301\u81ea\u6ce8\u610f\u529b\u6a21\u5757\u7ed3\u6784\u4e0d\u53d8\u3002\u5bf9\u4e8e\u6bcf\u4e2a\u7269\u4f53\u67e5\u8be2\u5411\u91cf\uff0c2D\u53c2\u8003\u70b9\\hat p_q\u5f52\u4e00\u5316\u540e\u7684\u5750\u6807\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u7ebf\u6027\u6295\u5f71\u548c\u4e00\u4e2asigmoid\u51fd\u6570\u4ece\u5176\u5bf9\u8c61\u67e5\u8be2\u5d4c\u5165\u4e2d\u9884\u6d4b\u3002</p> <p>\u2003\u2003\u7531\u4e8e\u591a\u5c3a\u5ea6\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u6a21\u5757\u63d0\u53d6\u53c2\u8003\u70b9\u5468\u56f4\u7684\u56fe\u50cf\u7279\u5f81\uff0c\u56e0\u6b64\u6211\u4eec\u8ba9\u68c0\u6d4b\u5934\u9884\u6d4b\u7684\u8fb9\u754c\u6846\u4f5c\u4e3a\u76f8\u5bf9\u4e8e\u53c2\u8003\u70b9\u7684\u76f8\u5bf9\u504f\u79fb\u91cf\uff0c\u4ece\u800c\u8fdb\u4e00\u6b65\u964d\u4f4e\u4f18\u5316\u96be\u5ea6\uff0c\u53c2\u8003\u70b9\u4ee5\u6846\u4e2d\u5fc3\u4f5c\u4e3a\u521d\u59cb\u5316\u6570\u636e\u3002\u8fd9\u6837\uff0c\u5b66\u4e60\u5230\u7684\u89e3\u7801\u5668\u6ce8\u610f\u529b\u4e0e\u9884\u6d4b\u7684\u8fb9\u754c\u6846\u5177\u6709\u5f88\u5f3a\u7684\u76f8\u5173\u6027\uff0c\u8fdb\u4e00\u6b65\u52a0\u5feb\u4e86\u7f51\u7edc\u7684\u6536\u655b\u3002</p> <p>Deformable DETR\u7684\u63d0\u5347</p> <p>\u8fed\u4ee3\u8fb9\u754c\u6846\u7684\u7ec6\u5316\uff1a\u53d7\u5230\u5149\u6d41\u4f30\u8ba1\u4e2d\u5f00\u53d1\u8fed\u4ee3\u7ec6\u5316\u7684\u542f\u53d1\uff0c\u4e3a\u4e86\u63d0\u9ad8\u76ee\u6807\u68c0\u6027\u80fd\uff0c\u4f5c\u8005\u5efa\u7acb\u4e86\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u8fed\u4ee3\u8fb9\u754c\u6846\u7ec6\u5316\u673a\u5236\uff0c\u5728\u8fd9\u91cc\uff0c\u6bcf\u4e2a\u89e3\u7801\u5668\u5c42\u57fa\u4e8e\u524d\u4e00\u5c42\u7684\u9884\u6d4b\u6765\u7ec6\u5316\u8fb9\u754c\u6846\u3002</p> <p>\u4e8c\u9636\u6bb5Deformable DETR\uff1a\u5728\u539f\u59cb\u7684DETR\u4e2d\uff0c\u89e3\u7801\u5668\u4e2d\u7684\u7269\u4f53\u67e5\u8be2\u5411\u91cfQ\u4e0e\u5f53\u524d\u56fe\u50cf\u65e0\u5173\uff0c\u53d7\u4e8c\u9636\u6bb5\u76ee\u6807\u68c0\u6d4b\u5668\u7684\u542f\u53d1\uff0c\u4f5c\u8005\u63a2\u7d22\u4e86\u4e00\u79cdDeformable DETR\u7684\u53d8\u4f53\uff0c\u5373\u4e8c\u9636\u6bb5Deformable DETR\u76ee\u6807\u68c0\u6d4b\u5668\uff0c\u7b2c\u4e00\u9636\u6bb5\u68c0\u6d4b\u5230\u7684\u8fb9\u754c\u6846\u5f53\u505a\u533a\u57df\u5efa\u8bae\uff08proposals\uff09\uff0c\u4e4b\u540e\u8fdb\u4e00\u6b65\u4f20\u5165\u7b2c\u4e8c\u9636\u6bb5\u4e2d\uff0c\u5145\u5f53\u7269\u4f53\u67e5\u8be2\u5411\u91cf\uff0c\u7528\u4e8e\u7ec6\u5316\u6240\u9884\u6d4b\u7684\u8fb9\u754c\u6846\u4f4d\u7f6e\u3002</p> <p>\u6ce8\uff1a\u5728\u7b2c\u4e00\u9636\u6bb5\uff0c\u4e3a\u4e86\u5b9e\u73b0\u9ad8\u53ec\u56de\u7387\u7684\u63d0\u8bae\uff0c\u8fd9\u91cc\u7684\u67e5\u8be2\u5411\u91cfQ\u662f\u4ee5\u56fe\u50cf\u7279\u5f81\u7684\u5f62\u5f0f\u8f93\u5165\u5230\u89e3\u7801\u5668\u4e2d\uff0c\u548c\u4e00\u9636\u6bb5\u7684\u4e0d\u4e00\u6837\uff0c\u4e00\u9636\u6bb5\u7684Q\u662f\u4e00\u7ec4\u9884\u8bbe\u597d\u5f62\u72b6\u3001\u53ef\u5b66\u4e60\u7684\u53c2\u6570\u3002\u8fd9\u91cc\u591a\u5c3a\u5ea6\u7279\u5f81\u4e2d\u7684\u6bcf\u4e2a\u7279\u5f81\u50cf\u7d20\u90fd\u5c06\u4f5c\u4e3a\u7269\u4f53\u67e5\u8be2\u5411\u91cf\uff0c\u7136\u800c\uff0c\u8fd9\u4e48\u505a\u4f1a\u5e26\u6765\u975e\u5e38\u5927\u7684\u8ba1\u7b97\u91cf\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u968f\u7740\u67e5\u8be2\u6570\u91cf\uff08\u5373\u56fe\u50cf\u5c3a\u5bf8\uff09\u7684\u589e\u52a0\u800c\u5448\u4e8c\u6b21\u589e\u957f\u3002\u4e3a\u4e86\u907f\u514d\u8fd9\u4e2a\u95ee\u9898\uff0c\u4f5c\u8005\u5728\u7b2c\u4e00\u9636\u6bb5\u4e2d\u53bb\u6389\u4e86\u89e3\u7801\u5668\uff0c\u5f62\u6210\u4e86\u4e00\u4e2a\u53ea\u6709\u7f16\u7801\u5668\u7684Deformable DETR\u6765\u751f\u6210\u533a\u57df\u5efa\u8bae\uff0c\u5176\u4e2d\u6bcf\u4e2a\u50cf\u7d20\u70b9\u76f4\u63a5\u7528\u6765\u9884\u6d4b\u4e00\u4e2a\u8fb9\u754c\u6846\uff0c\u9009\u53d6\u5f97\u5206\u6700\u9ad8\u7684\u8fb9\u754c\u6846\u4f5c\u4e3a\u533a\u57df\u5efa\u8bae\uff0c\u5728\u50cf\u7b2c\u4e8c\u9636\u6bb5\u63d0\u4f9b\u533a\u57df\u5efa\u8bae\u4e4b\u524d\uff0c\u4e0d\u5e94\u7528NMS\u3002</p>"},{"location":"transformer/DeDETR/#_6","title":"\u6e90\u7801\u5b9e\u73b0","text":""},{"location":"transformer/DeDETR/#_7","title":"\u6d41\u7a0b","text":"<p>backbone\u6a21\u5757</p> <ul> <li>\u56fe\u50cf\u5148\u7ecf\u8fc7backbone\uff08\u4e00\u822c\u7531CNN\u7ec4\u6210\uff09\uff0c\u5f97\u5230\u591a\u4e2a\u5c42\u7ea7\u7684\u7279\u5f81\u56fe\uff0c\u6839\u636e\u7279\u5f81\u56fe\u5c3a\u5bf8\u9884\u8bbe\u4f4d\u7f6e\u7f16\u7801\uff08\u8fd9\u91cc\u7684\u4f4d\u7f6e\u7f16\u7801\u662f\u56fa\u5b9a\u7684\u6570\u636e\uff0cx\u3001y\u5206\u522b\u4e0esin\u3001cos\u8fd0\u7b97\u6709\u5173\uff09\uff1b</li> <li>\u4e0d\u540c\u5c42\u7ea7\u7279\u5f81\u56fe\u901a\u9053\u6570\u4e0d\u4e00\u6837\uff0c\u4e0d\u80fd\u76f4\u63a5\u4f20\u5165TF\u7f16\u7801\u5668\uff0c\u56e0\u6b64\u50cfFPN\u4e00\u6837\uff0c\u5148\u7edf\u4e00\u901a\u9053\u6570\uff0c\u901a\u9053\u6570\u7edf\u4e00\u6210256\uff1b</li> </ul> <p>TF\u6a21\u5757</p> <ul> <li>\u6839\u636e\u4e0d\u540c\u5c42\u7ea7\uff0c\u9884\u8bbe\u591a\u7ec4\u7279\u5f81\u5c42\u7f16\u7801\uff08\u8fd9\u91cc\u7279\u5f81\u5c42\u7f16\u7801\u4e3a\u53ef\u5b66\u4e60\u7684\u53c2\u6570\uff0c\u5c3a\u5bf8\u4e3a[\u5c42\u6570\uff0c256]\uff09\uff0c\u5148\u5c06\u56fe\u50cf\u7279\u5f81\u62c9\u76f4\uff0c\u53d8\u4e3a\u5e8f\u5217\u7279\u5f81\uff0c\u5e76\u4e14\u5c06\u4e0d\u540c\u5c42\u7ea7\u7684\u5e8f\u5217\u7279\u5f81\u5408\u5e76\uff0c\u5408\u5e76\u4e3a\u4e00\u4e2a\u603b\u7684\u5e8f\u5217\u7279\u5f81\uff1b</li> <li>\u5e76\u4e14\u5c06\u56fe\u50cf\u7684\u4f4d\u7f6e\u7f16\u7801\u4e0e\u7279\u5f81\u5c42\u7f16\u7801\u76f8\u52a0\uff0c\u7528\u4e8e\u8868\u793a\u56fe\u50cf\u6bcf\u4e2a\u56fe\u50cf\u7279\u5f81\u7684\u5c42\u7ea7\u548c\u4f4d\u7f6e\u4fe1\u606f\uff0c\u7b80\u79f0\u56fe\u50cf\u7684\u4fe1\u606f\u7f16\u7801\uff1b</li> </ul> <p>\u7f16\u7801\u6a21\u5757</p> <ul> <li>\u751f\u6210\u53c2\u8003\u70b9\u5750\u6807\u6570\u636e\uff1a\u5bf9\u4e8e\u6bcf\u4e2a\u5c42\u7ea7\u7279\u5f81\uff0c\u5c06\u5176\u89c6\u4e3a\u4e00\u4e2a\u7f51\u683c\uff0c\u7f51\u683c\u4e0a\u7684\u70b9\u5c31\u662f\u53c2\u8003\u70b9\uff08\u6bcf\u4e2a\u5750\u6807\u70b9\u5bf9\u5e94\u4e00\u4e2a\u7279\u5f81\u70b9\uff09\uff0c\u5750\u6807\u6570\u636e\u4ece\u5de6\u4e0a\u5230\u53f3\u4e0b\u4f9d\u6b21\u589e\u5927\uff0c\u5e76\u4e14\u7279\u5f81\u5c42\u8d8a\u6df1\uff0c\u7279\u5f81\u56fe\u8d8a\u5c0f\uff0c\u76f8\u90bb\u53c2\u8003\u70b9\u7684\u6570\u503c\u8de8\u5ea6\u5c31\u8d8a\u5927\uff0c\u9ed8\u8ba4\u6bcf\u4e2a\u7279\u5f81\u70b9\u751f\u6210\u56db\u4e2a\u53c2\u8003\u70b9\uff1b</li> <li>q\u4e3a\u56fe\u50cf\u7f16\u7801\u7279\u5f81\u4e0e\u4fe1\u606f\u7f16\u7801\u76f8\u52a0\u540e\u7684\u6570\u636e\u3001v\u4e3a\u5355\u7eaf\u7684\u56fe\u50cf\u7f16\u7801\u7279\u5f81\u3002\u5c06v\u4f20\u5165\u7ebf\u6027\u6620\u5c04\uff0c\u5f97\u5230\u8ba1\u7b97\u6ce8\u610f\u529b\u524d\u6240\u7528\u7684v\uff1b\u6a21\u578b\u5229\u7528q\u9884\u6d4b\u53c2\u8003\u70b9\u5728x\u3001y\u4e0a\u7684\u504f\u79fb\u91cf\u3001\u4ee5\u53ca\u5404\u4e2a\u53c2\u8003\u70b9\u7684\u6743\u91cd\uff08\u89e3\u91ca\uff1a\u6bcf\u4e2a\u6ce8\u610f\u529b\u70b9\u5230\u5e95\u5728\u54ea\uff0c\u5e76\u4e14\u6ce8\u610f\u529b\u7684\u4fa7\u91cd\u529b\u5ea6\u6709\u591a\u5927\uff0c\u53ea\u8ddf\u67e5\u8be2q\u6709\u5173\uff0c\u56e0\u4e3a\u6ce8\u610f\u529b\u548c\u6838\u5fc3\u76ee\u7684\u5c31\u662f\u8981\u5f97\u5230\u67e5\u8be2q\u5bf9\u5e94\u7684\u2019v\u2019\u503c\uff09\uff1b</li> <li>\u53c2\u8003\u5750\u6807\u70b9\u4e0e\u9884\u6d4b\u7684\u504f\u79fb\u91cf\u76f8\u52a0\uff0c\u5f97\u5230\u91c7\u6837\u70b9\u5750\u6807\uff1b</li> <li>\u5c06v\u3001\u91c7\u6837\u5750\u6807\u70b9\u3001\u6ce8\u610f\u529b\u6743\u91cd\u4f20\u5165\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u8ba1\u7b97\u6a21\u5757\uff0c\u8ba1\u7b97\u6ce8\u610f\u529b\u6570\u636e\uff1b</li> <li>\u4e4b\u540e\u8ba1\u7b97TF\u6a21\u5757\u4e2d\u5269\u4f59\u7684\u90e8\u5206\uff08\u6b8b\u5dee\u6620\u5c04\u3001LN\u3001FFN\u7b49\u7b49\uff09\uff1b</li> </ul> <p>\u6ce8\uff1a\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u6a21\u5757\u964d\u4f4e\u8ba1\u7b97\u91cf\u7684\u672c\u8d28\uff0c\u5c31\u662f\u51cf\u5c11q\u5728\u8ba1\u7b97\u6ce8\u610f\u529b\u65f6\u6240\u53c2\u8003\u7684\u70b9\uff0c\u4f20\u7edf\u7684\u591a\u5934\u6ce8\u610f\u529b\uff0c\u5bf9\u4e8eq\u4e2d\u6bcf\u4e2a\u5143\u7d20\uff0c\u90fd\u8981\u9010\u4e00\u4e0ek\u505a\u4e00\u6b21\u6ce8\u610f\u529b\u8fd0\u7b97\uff0c\u5f97\u5230\u6743\u91cd\uff0c\u518d\u4e0e\u6240\u6709\u7684v\u503c\u52a0\u6743\u6c42\u548c\uff0c\u800c\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u6a21\u5757\u5c31\u9650\u5b9a\u4e86\u53c2\u8003\u70b9\u7684\u4e2a\u6570\uff0c\u8fd9\u91cc\u9ed8\u8ba4\u9650\u5b9a\u4e3a4\u4e2a\uff0c\u5373q\u4e2d\u6bcf\u4e2a\u5143\u7d20\uff0c\u53ea\u4e0ek\u4e2d4\u4e2a\u5143\u7d20\u4f5c\u6ce8\u610f\u529b\u8fd0\u7b97\uff0c\u5f97\u5230\u7684\u6743\u91cd\uff0c\u5728\u4e0ev\u4e2d\u5bf9\u5e94\u76844\u4e2a\u5143\u7d20\u4f5c\u52a0\u6743\u6c42\u548c\uff0c\u5176\u4e2d\u91c7\u6837\u70b9\u5750\u6807\u5c31\u662f\u4e3a\u4e86\u5b9a\u4f4d4\u4e2a\u53c2\u8003\u5143\u7d20\u3002</p> <p>\u89e3\u7801\u6a21\u5757</p> <ul> <li>\u9884\u8bbe\u4e00\u7ec4\u7269\u4f53\u67e5\u8be2\u5411\u91cfQ\u3001\u521d\u59cb\u7684\u89e3\u7801\u7279\u5f81tgt\uff08\u4e8c\u8005\u7c7b\u4f3c\uff0c\u6570\u636e\u5747\u4e3a\u53ef\u5b66\u4e60\u7684\u53c2\u6570\uff0c\u5c3a\u5bf8\u5747\u4e3a[\u67e5\u8be2\u4e2a\u6570\u3001\u7279\u5f81\u7ef4\u5ea6]\uff09\uff0c\u5c06\u67e5\u8be2\u5411\u91cf\u4f20\u5165\u7ebf\u6027\u6620\u5c04\u5c42\uff0c\u6620\u5c04\u4e3a2\u4e2a\u6570\uff0c\u8868\u793a\u8fb9\u754c\u6846\u53c2\u8003\u70b9\u5750\u6807\uff0c\u53c2\u8003\u70b9\u5c3a\u5bf8\u4e3a[\u67e5\u8be2\u4e2a\u6570,2]\uff08\u540e\u7eed\u518d\u590d\u52364\u500d\uff0c\u6bcf\u4e2a\u7269\u4f53\u67e5\u8be2\u91c7\u68374\u4e2a\u70b9\uff09\uff0c\u8fd9\u91cc\u8ba1\u7b97\u53c2\u8003\u70b9\u4e5f\u662f\u4e3a\u4e86\u540e\u7eed\u5728\u89e3\u7801\u8fc7\u7a0b\u4e2d\uff0c\u5f15\u5165\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u8fd0\u7b97\uff1b</li> <li>\u5148\u5bf9\u67e5\u8be2\u5411\u91cf\u3001\u89e3\u7801\u7279\u5f81\u7b97\u4e00\u6b21\u81ea\u6ce8\u610f\u529b\uff08self-attention\uff09\uff0c\u5176\u4e2dq\u3001k\u4e3a\u89e3\u7801\u7279\u5f81tgt\u4e0e\u67e5\u8be2\u5411\u91cfQ\u76f8\u52a0\uff0cv\u4e3a\u89e3\u7801\u7279\u5f81tgt\uff0c\u540e\u9762\u518d\u7ecf\u8fc7\u6b8b\u5dee\u6620\u5c04\u3001LN\u8fd0\u7b97\uff1b</li> <li>\u8ba1\u7b97\u4ea4\u53c9\u6ce8\u610f\u529b\uff08\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u8fd0\u7b97\uff09\uff0c\u5176\u4e2dq\u4e3a\u89e3\u7801\u7279\u5f81tgt\u4e0e\u67e5\u8be2\u5411\u91cfQ\u76f8\u52a0\uff0c\u5c3a\u5bf8\u4e3a[\u67e5\u8be2\u4e2a\u6570,\u7279\u5f81\u7ef4\u5ea6]\uff0ck\u4e3a\u8fb9\u754c\u6846\u53c2\u8003\u70b9\u5750\u6807\uff0c\u5c3a\u5bf8\u4e3a[\u67e5\u8be2\u4e2a\u6570,4,2]\uff0cv\u4e3a\u7f16\u7801\u7279\u5f81src\uff0c\u5c3a\u5bf8\u4e3a[\u7279\u5f81\u5e8f\u5217\u6570,\u7279\u5f81\u7ef4\u6570]\u3002q\u5148\u7ecf\u8fc7\u4e24\u6b21\u7ebf\u6027\u6620\u5c04\uff0c\u5f97\u5230\u53c2\u8003\u70b9\u7684\u504f\u79fb\u91cf\u548c\u6ce8\u610f\u529b\u6743\u91cd\uff0c\u504f\u79fb\u91cf\u4e0e\u53c2\u8003\u70b9\u5750\u6807\u76f8\u52a0\uff0c\u5f97\u5230\u91c7\u6837\u70b9\uff0c\u4e4b\u540e\u5c06v\u3001\u91c7\u6837\u70b9\u3001\u6ce8\u610f\u529b\u6743\u91cd\u4f20\u5165\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u8ba1\u7b97\u6ce8\u610f\u529b\uff0c\u6700\u540e\u518d\u7ecf\u8fc7\u6b8b\u5dee\u6620\u5c04\u3001LN\u3001FFN\uff1b</li> </ul> <p>\u6ce8\uff1a</p> <ul> <li>\u89e3\u7801\u7279\u5f81\u662f\u968f\u7740\u89e3\u7801\u7684\u8fc7\u7a0b\u4e0d\u65ad\u53d8\u5316\u7684\uff0c\u800c\u67e5\u8be2\u5411\u91cfQ\u5728\u89e3\u7801\u8fc7\u7a0b\u4e2d\u662f\u4e0d\u53d8\u7684\uff0c\u56e0\u6b64\u5728\u6bcf\u4e2a\u89e3\u7801\u6a21\u5757\u4e2d\uff0cq\u662f\u4e0d\u4e00\u6837\u7684\uff0c\u7c7b\u4f3c\u8fed\u4ee3\u4f18\u5316\u8868\u793a\uff1b</li> <li>\u8bba\u6587\u4e2d\u7684\u4e24\u5927\u6539\u8fdb\u70b9\u201c\u8fed\u4ee3\u8fb9\u754c\u6846\u7684\u7ec6\u5316\u201d\u548c\u201c\u4e8c\u9636\u6bb5Deformable DETR\u201d\uff0c\u90fd\u662f\u5bf9\u7269\u4f53\u7684\u53c2\u8003\u70b9\u5750\u6807\u505a\u64cd\u4f5c\uff0c\u8fed\u4ee3\u8fb9\u754c\u6846\u7684\u7ec6\u5316\u662f\u5728\u6bcf\u6b21\u89e3\u7801\u6a21\u5757\u8fc7\u7a0b\u4e2d\uff0c\u90fd\u6539\u8fdb\u4e00\u6b21\u7269\u4f53\u53c2\u8003\u70b9\u5750\u6807\uff0c\u7c7b\u4f3c\u8fed\u4ee3\u4f18\u5316\u8868\u793a\uff08\u539f\u59cb\u65b9\u6cd5\uff0c\u6bcf\u4e2a\u89e3\u7801\u6a21\u5757\u7528\u7684\u53c2\u8003\u70b9\u5750\u6807\u90fd\u4e00\u6837\uff09\uff1b\u4e8c\u9636\u6bb5\u7684DeDETR\uff0c\u4f1a\u5728\u7f16\u7801\u4e4b\u540e\uff0c\u5148\u5c06\u7f16\u7801\u7279\u5f81\u4f20\u5165\u4e00\u6b21\u89e3\u7801\u5668\uff08\u989d\u5916\u8bbe\u7f6e\u7684\uff09\uff0c\u89e3\u7801\u5f97\u5230\u7684\u7279\u5f81\u7528\u4e8e\u521d\u59cb\u5316\u7269\u4f53\u53c2\u8003\u70b9\u5750\u6807\uff08\u539f\u59cb\u65b9\u6cd5\uff0c\u53c2\u8003\u70b9\u5750\u6807\u7684\u521d\u59cb\u5316\u7531\u67e5\u8be2\u5411\u91cf\u505a\u4e00\u6b21\u7ebf\u6027\u6620\u5c04\u5f97\u5230\uff09\u3002</li> </ul> <p>\u9884\u6d4b\u6a21\u5757</p> <ul> <li>\u6839\u636e\u5f97\u5230\u7684\u89e3\u7801\u7279\u5f81\uff0c\u9884\u6d4b\u8fb9\u754c\u6846\u548c\u7c7b\u522b\uff0c\u4ee5\u7c7b\u522b\u4e3a\u4f8b\uff0c\u8f93\u51fa\u7684\u6570\u636e\u5c3a\u5bf8\u4e3a[\u67e5\u8be2\u4e2a\u6570\u3001\u7c7b\u522b\u6570]\uff1b</li> </ul>"},{"location":"transformer/DeDETR/#transformer","title":"Transformer\u6a21\u5757","text":"<pre><code>class DeformableTransformer(nn.Module):\n    def __init__(self, d_model=256, nhead=8,\n                 num_encoder_layers=6, num_decoder_layers=6, dim_feedforward=1024, dropout=0.1,\n                 activation=\"relu\", return_intermediate_dec=False,\n                 num_feature_levels=4, dec_n_points=4,  enc_n_points=4,\n                 two_stage=False, two_stage_num_proposals=300):\n        super().__init__()\n\n        self.d_model = d_model\n        self.nhead = nhead\n        self.two_stage = two_stage\n        self.two_stage_num_proposals = two_stage_num_proposals\n\n        encoder_layer = DeformableTransformerEncoderLayer(d_model, dim_feedforward,\n                                                          dropout, activation,\n                                                          num_feature_levels, nhead, enc_n_points)\n        self.encoder = DeformableTransformerEncoder(encoder_layer, num_encoder_layers)\n\n        decoder_layer = DeformableTransformerDecoderLayer(d_model, dim_feedforward,\n                                                          dropout, activation,\n                                                          num_feature_levels, nhead, dec_n_points)\n        self.decoder = DeformableTransformerDecoder(decoder_layer, num_decoder_layers, return_intermediate_dec)\n\n        self.level_embed = nn.Parameter(torch.Tensor(num_feature_levels, d_model))\n\n        if two_stage:\n            self.enc_output = nn.Linear(d_model, d_model)\n            self.enc_output_norm = nn.LayerNorm(d_model)\n            self.pos_trans = nn.Linear(d_model * 2, d_model * 2)\n            self.pos_trans_norm = nn.LayerNorm(d_model * 2)\n        else:\n            self.reference_points = nn.Linear(d_model, 2)\n\n        self._reset_parameters()\n\n    def _reset_parameters(self):\n        for p in self.parameters():\n            if p.dim() &gt; 1:\n                nn.init.xavier_uniform_(p)\n        for m in self.modules():\n            if isinstance(m, MSDeformAttn):\n                m._reset_parameters()\n        if not self.two_stage:\n            xavier_uniform_(self.reference_points.weight.data, gain=1.0)\n            constant_(self.reference_points.bias.data, 0.)\n        normal_(self.level_embed)\n\n    def get_proposal_pos_embed(self, proposals):\n        num_pos_feats = 128\n        temperature = 10000\n        scale = 2 * math.pi\n\n        dim_t = torch.arange(num_pos_feats, dtype=torch.float32, device=proposals.device)\n        dim_t = temperature ** (2 * (dim_t // 2) / num_pos_feats)\n        # N, L, 4\n        proposals = proposals.sigmoid() * scale\n        # N, L, 4, 128\n        pos = proposals[:, :, :, None] / dim_t\n        # N, L, 4, 64, 2\n        pos = torch.stack((pos[:, :, :, 0::2].sin(), pos[:, :, :, 1::2].cos()), dim=4).flatten(2)\n        return pos\n\n    def gen_encoder_output_proposals(self, memory, memory_padding_mask, spatial_shapes):\n        N_, S_, C_ = memory.shape\n        base_scale = 4.0\n        proposals = []\n        _cur = 0\n        for lvl, (H_, W_) in enumerate(spatial_shapes):\n            mask_flatten_ = memory_padding_mask[:, _cur:(_cur + H_ * W_)].view(N_, H_, W_, 1)\n            valid_H = torch.sum(~mask_flatten_[:, :, 0, 0], 1)\n            valid_W = torch.sum(~mask_flatten_[:, 0, :, 0], 1)\n\n            grid_y, grid_x = torch.meshgrid(torch.linspace(0, H_ - 1, H_, dtype=torch.float32, device=memory.device),\n                                            torch.linspace(0, W_ - 1, W_, dtype=torch.float32, device=memory.device))\n            grid = torch.cat([grid_x.unsqueeze(-1), grid_y.unsqueeze(-1)], -1)\n\n            scale = torch.cat([valid_W.unsqueeze(-1), valid_H.unsqueeze(-1)], 1).view(N_, 1, 1, 2)\n            grid = (grid.unsqueeze(0).expand(N_, -1, -1, -1) + 0.5) / scale\n            wh = torch.ones_like(grid) * 0.05 * (2.0 ** lvl)\n            proposal = torch.cat((grid, wh), -1).view(N_, -1, 4)\n            proposals.append(proposal)\n            _cur += (H_ * W_)\n        output_proposals = torch.cat(proposals, 1)\n        output_proposals_valid = ((output_proposals &gt; 0.01) &amp; (output_proposals &lt; 0.99)).all(-1, keepdim=True)\n        output_proposals = torch.log(output_proposals / (1 - output_proposals))\n        output_proposals = output_proposals.masked_fill(memory_padding_mask.unsqueeze(-1), float('inf'))\n        output_proposals = output_proposals.masked_fill(~output_proposals_valid, float('inf'))\n\n        output_memory = memory\n        output_memory = output_memory.masked_fill(memory_padding_mask.unsqueeze(-1), float(0))\n        output_memory = output_memory.masked_fill(~output_proposals_valid, float(0))\n        output_memory = self.enc_output_norm(self.enc_output(output_memory))\n        return output_memory, output_proposals\n\n    def get_valid_ratio(self, mask):\n        _, H, W = mask.shape\n        valid_H = torch.sum(~mask[:, :, 0], 1)\n        valid_W = torch.sum(~mask[:, 0, :], 1)\n        valid_ratio_h = valid_H.float() / H\n        valid_ratio_w = valid_W.float() / W\n        valid_ratio = torch.stack([valid_ratio_w, valid_ratio_h], -1)\n        return valid_ratio\n\n    def forward(self, srcs, masks, pos_embeds, query_embed=None):\n        assert self.two_stage or query_embed is not None\n\n        # prepare input for encoder\n        src_flatten = []\n        mask_flatten = []\n        lvl_pos_embed_flatten = []\n        spatial_shapes = []\n        # \u5c06\u56fe\u50cf\u7279\u5f81\u62c9\u76f4\uff0c\u53d8\u4e3a\u5e8f\u5217\u7279\u5f81\uff0c\u5e76\u4e14\u5c06\u56fe\u50cf\u7684\u4f4d\u7f6e\u7f16\u7801\u4e0e\u7279\u5f81\u5c42\u7f16\u7801\u76f8\u52a0\uff0c\u8d4b\u4e88\u7279\u5f81\u5c42\u4fe1\u606f\uff0c\u7528\u4e8e\u533a\u5206\u4e0d\u540c\u7279\u5f81\u5c42\u7684\u56fe\u50cf\u7279\u5f81\n        for lvl, (src, mask, pos_embed) in enumerate(zip(srcs, masks, pos_embeds)):\n            bs, c, h, w = src.shape\n            spatial_shape = (h, w)\n            spatial_shapes.append(spatial_shape)\n            src = src.flatten(2).transpose(1, 2)\n            mask = mask.flatten(1)\n            pos_embed = pos_embed.flatten(2).transpose(1, 2)\n            # \u4f4d\u7f6e\u7f16\u7801 + \u7279\u5f81\u5c42\u7f16\u7801\uff0c\u5f97\u5230\u56fe\u50cf\u7684\u4fe1\u606f\u7f16\u7801\uff0c\u7528\u4e8e\u533a\u5206\u4e0d\u540c\u533a\u57df\u7684\u7279\u5f81\n            lvl_pos_embed = pos_embed + self.level_embed[lvl].view(1, 1, -1)\n            lvl_pos_embed_flatten.append(lvl_pos_embed)\n            src_flatten.append(src)\n            mask_flatten.append(mask)\n        # \u4e0d\u540c\u7279\u5f81\u5c42\u7684\u7279\u5f81\u6cbf\u5c42\u65b9\u5411\u5408\u5e76\uff0c\u5408\u5e76\u4e3a\u4e00\u4e2a\u5927\u7684\u7279\u5f81\u5e8f\u5217\n        src_flatten = torch.cat(src_flatten, 1)\n        mask_flatten = torch.cat(mask_flatten, 1)\n        lvl_pos_embed_flatten = torch.cat(lvl_pos_embed_flatten, 1)\n        spatial_shapes = torch.as_tensor(spatial_shapes, dtype=torch.long, device=src_flatten.device)\n        level_start_index = torch.cat((spatial_shapes.new_zeros((1, )), spatial_shapes.prod(1).cumsum(0)[:-1]))\n        valid_ratios = torch.stack([self.get_valid_ratio(m) for m in masks], 1)\n\n        # encoder \u5229\u7528\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u6a21\u5757\u505a\u7f16\u7801\n        # src_flatten\u8868\u793a\u56fe\u50cf\u7f16\u7801\u7279\u5f81\u3001spatial_shapes\u8868\u793a\u6bcf\u4e2a\u7279\u5f81\u5c42\u7ea7\u7684\u5c3a\u5bf8\u3001level_start_index\u8868\u793a\u7279\u5f81\u5e8f\u5217\u7684\u5c42\u7ea7\u7d22\u5f15\n        # valid_ratios\u8868\u793a\u9884\u8bbe\u53c2\u8003\u70b9\u5750\u6807\u65f6x\u3001y\u7684\u6bd4\u7387\uff0c\u9ed8\u8ba4(1,1)\uff0c\u5373\u4e0d\u505a\u53d8\u5316\n        memory = self.encoder(src_flatten, spatial_shapes, level_start_index, valid_ratios, lvl_pos_embed_flatten, mask_flatten)\n\n        # prepare input for decoder\n        bs, _, c = memory.shape\n        if self.two_stage:\n            output_memory, output_proposals = self.gen_encoder_output_proposals(memory, mask_flatten, spatial_shapes)\n\n            # hack implementation for two-stage Deformable DETR\n            enc_outputs_class = self.decoder.class_embed[self.decoder.num_layers](output_memory)\n            enc_outputs_coord_unact = self.decoder.bbox_embed[self.decoder.num_layers](output_memory) + output_proposals\n\n            topk = self.two_stage_num_proposals\n            topk_proposals = torch.topk(enc_outputs_class[..., 0], topk, dim=1)[1]\n            topk_coords_unact = torch.gather(enc_outputs_coord_unact, 1, topk_proposals.unsqueeze(-1).repeat(1, 1, 4))\n            topk_coords_unact = topk_coords_unact.detach()\n            reference_points = topk_coords_unact.sigmoid()\n            init_reference_out = reference_points\n            pos_trans_out = self.pos_trans_norm(self.pos_trans(self.get_proposal_pos_embed(topk_coords_unact)))\n            query_embed, tgt = torch.split(pos_trans_out, c, dim=2)\n        else:\n            query_embed, tgt = torch.split(query_embed, c, dim=1)\n            query_embed = query_embed.unsqueeze(0).expand(bs, -1, -1)\n            tgt = tgt.unsqueeze(0).expand(bs, -1, -1)\n            reference_points = self.reference_points(query_embed).sigmoid()\n            init_reference_out = reference_points\n\n        # decoder\n        # \u5f97\u5230\u89e3\u7801\u7279\u5f81\uff0c\u8fd8\u6709\u6bcf\u5c42\u7684inter_references\uff0c\u7528\u4e8eiterative bounding box refinement\uff0c\u5373\u8fed\u4ee3\u8fb9\u754c\u6846\u7684\u7ec6\u5316\uff0c\u5c5e\u4e8eDeDETR\u7684\u63d0\u5347\u4efb\u52a1\n        hs, inter_references = self.decoder(tgt, reference_points, memory,\n                                            spatial_shapes, level_start_index, valid_ratios, query_embed, mask_flatten)\n\n        inter_references_out = inter_references\n        if self.two_stage:\n            return hs, init_reference_out, inter_references_out, enc_outputs_class, enc_outputs_coord_unact\n        return hs, init_reference_out, inter_references_out, None, None\n</code></pre>"},{"location":"transformer/DeDETR/#_8","title":"\u7f16\u7801\u5668","text":"<pre><code>class DeformableTransformerEncoderLayer(nn.Module):\n    def __init__(self,\n                 d_model=256, d_ffn=1024,\n                 dropout=0.1, activation=\"relu\",\n                 n_levels=4, n_heads=8, n_points=4):\n        super().__init__()\n\n        # self attention\n        self.self_attn = MSDeformAttn(d_model, n_levels, n_heads, n_points)\n        self.dropout1 = nn.Dropout(dropout)\n        self.norm1 = nn.LayerNorm(d_model)\n\n        # ffn\n        self.linear1 = nn.Linear(d_model, d_ffn)\n        self.activation = _get_activation_fn(activation)\n        self.dropout2 = nn.Dropout(dropout)\n        self.linear2 = nn.Linear(d_ffn, d_model)\n        self.dropout3 = nn.Dropout(dropout)\n        self.norm2 = nn.LayerNorm(d_model)\n\n    @staticmethod\n    def with_pos_embed(tensor, pos):\n        return tensor if pos is None else tensor + pos\n\n    def forward_ffn(self, src):\n        src2 = self.linear2(self.dropout2(self.activation(self.linear1(src))))\n        src = src + self.dropout3(src2)\n        src = self.norm2(src)\n        return src\n\n    def forward(self, src, pos, reference_points, spatial_shapes, level_start_index, padding_mask=None):\n        # self attention\n        # \u56fe\u50cf\u7f16\u7801\u7279\u5f81\u4e0e\u4fe1\u606f\u7f16\u7801\u76f8\u52a0\u540e\u7684\u6570\u636e\uff0c\u5145\u5f53\u67e5\u8be2q\u3002\u5355\u7eaf\u7684\u56fe\u50cf\u7f16\u7801\u7279\u5f81src\u5145\u5f53\u503cv\n        # reference_points\u8868\u793a\u53c2\u8003\u70b9\uff0c\u7528\u4e8e\u8ba1\u7b97\u91c7\u6837\u70b9\n        # spatial_shapes\u4e3a\u6bcf\u5c42\u7279\u5f81\u56fe\u7684\u5c3a\u5bf8\uff0clevel_start_index\u4e3a\u7279\u5f81\u5e8f\u5217\u5c42\u7ea7\u7684\u7d22\u5f15\uff08level_start_index[0]\u5230level_start_index[1]\u8868\u793a\u7b2c\u4e00\u7ea7\u7684\u7d22\u5f15\uff0c\u6d45\u5c42\u7279\u5f81\uff09\n        src2 = self.self_attn(self.with_pos_embed(src, pos), reference_points, src, spatial_shapes, level_start_index, padding_mask)\n        src = src + self.dropout1(src2)\n        src = self.norm1(src)\n\n        # ffn\n        src = self.forward_ffn(src)\n\n        return src\nclass DeformableTransformerEncoder(nn.Module):\n    def __init__(self, encoder_layer, num_layers):\n        super().__init__()\n        self.layers = _get_clones(encoder_layer, num_layers)\n        self.num_layers = num_layers\n\n    @staticmethod\n    def get_reference_points(spatial_shapes, valid_ratios, device):\n        reference_points_list = []\n        for lvl, (H_, W_) in enumerate(spatial_shapes):\n\n            ref_y, ref_x = torch.meshgrid(torch.linspace(0.5, H_ - 0.5, H_, dtype=torch.float32, device=device),\n                                          torch.linspace(0.5, W_ - 0.5, W_, dtype=torch.float32, device=device))\n            ref_y = ref_y.reshape(-1)[None] / (valid_ratios[:, None, lvl, 1] * H_)\n            ref_x = ref_x.reshape(-1)[None] / (valid_ratios[:, None, lvl, 0] * W_)\n            ref = torch.stack((ref_x, ref_y), -1)\n            reference_points_list.append(ref)\n        reference_points = torch.cat(reference_points_list, 1)\n        reference_points = reference_points[:, :, None] * valid_ratios[:, None]\n        return reference_points\n\n    def forward(self, src, spatial_shapes, level_start_index, valid_ratios, pos=None, padding_mask=None):\n        output = src\n        # \u5728\u6bcf\u4e2a\u50cf\u7d20\u70b9\u4e0a\u9884\u751f\u6210\u591a\u4e2a\u53c2\u8003\u70b9\uff0c\u5e76\u4e14\u5bf9\u4e8e\u6bcf\u4e2a\u5c42\u7ea7\u7279\u5f81\uff0c\u5c06\u5176\u89c6\u4e3a\u4e00\u4e2a\u7f51\u683c\uff0c\u7f51\u683c\u4e0a\u7684\u70b9\u5c31\u662f\u53c2\u8003\u70b9\uff0c\u5750\u6807\u4ece\u5de6\u4e0a\u5230\u53f3\u4e0b\u4f9d\u6b21\u589e\u5927\uff08\u4ece0\u589e\u4e3a1\uff09\n        # \u56e0\u6b64\u7279\u5f81\u5c42\u8d8a\u6df1\uff0c\u7279\u5f81\u56fe\u8d8a\u5c0f\uff0c\u76f8\u90bb\u53c2\u8003\u70b9\u6570\u503c\u7684\u8de8\u5ea6\u5c31\u8d8a\u5927\uff08\u6b65\u5e45\u5927\uff09\n        # valid_ratios\u4e3a\u4e0d\u540c\u53c2\u8003\u70b9\u7684\u6bd4\u4f8b\uff0c\u9ed8\u8ba4\u90fd\u662f1,1\uff0c\u751f\u62104\u4e2a\u53c2\u8003\u70b9\uff0c\u5bf9\u4e8e\u6bcf\u4e2a\u70b9\uff0c\u751f\u62104\u4e2a\u4e00\u6837\u7684\u53c2\u8003\u70b9\n        reference_points = self.get_reference_points(spatial_shapes, valid_ratios, device=src.device)\n        for _, layer in enumerate(self.layers):\n            output = layer(output, pos, reference_points, spatial_shapes, level_start_index, padding_mask)\n\n        return output\n</code></pre>"},{"location":"transformer/DeDETR/#_9","title":"\u53ef\u53d8\u6ce8\u610f\u529b\u6a21\u5757","text":"<pre><code>class MSDeformAttn(nn.Module):\n    def __init__(self, d_model=256, n_levels=4, n_heads=8, n_points=4):\n        \"\"\"\n        Multi-Scale Deformable Attention Module\n        :param d_model      hidden dimension\n        :param n_levels     number of feature levels\n        :param n_heads      number of attention heads\n        :param n_points     number of sampling points per attention head per feature level\n        \"\"\"\n        super().__init__()\n        if d_model % n_heads != 0:\n            raise ValueError('d_model must be divisible by n_heads, but got {} and {}'.format(d_model, n_heads))\n        _d_per_head = d_model // n_heads\n        # you'd better set _d_per_head to a power of 2 which is more efficient in our CUDA implementation\n        if not _is_power_of_2(_d_per_head):\n            warnings.warn(\"You'd better set d_model in MSDeformAttn to make the dimension of each attention head a power of 2 \"\n                          \"which is more efficient in our CUDA implementation.\")\n\n        self.im2col_step = 64\n\n        self.d_model = d_model\n        self.n_levels = n_levels\n        self.n_heads = n_heads\n        self.n_points = n_points\n\n        self.sampling_offsets = nn.Linear(d_model, n_heads * n_levels * n_points * 2)\n        self.attention_weights = nn.Linear(d_model, n_heads * n_levels * n_points)\n        self.value_proj = nn.Linear(d_model, d_model)\n        self.output_proj = nn.Linear(d_model, d_model)\n\n        self._reset_parameters()\n\n    def _reset_parameters(self):\n        constant_(self.sampling_offsets.weight.data, 0.)\n        thetas = torch.arange(self.n_heads, dtype=torch.float32) * (2.0 * math.pi / self.n_heads)\n        grid_init = torch.stack([thetas.cos(), thetas.sin()], -1)\n        grid_init = (grid_init / grid_init.abs().max(-1, keepdim=True)[0]).view(self.n_heads, 1, 1, 2).repeat(1, self.n_levels, self.n_points, 1)\n        for i in range(self.n_points):\n            grid_init[:, :, i, :] *= i + 1\n        with torch.no_grad():\n            self.sampling_offsets.bias = nn.Parameter(grid_init.view(-1))\n        constant_(self.attention_weights.weight.data, 0.)\n        constant_(self.attention_weights.bias.data, 0.)\n        xavier_uniform_(self.value_proj.weight.data)\n        constant_(self.value_proj.bias.data, 0.)\n        xavier_uniform_(self.output_proj.weight.data)\n        constant_(self.output_proj.bias.data, 0.)\n\n    def forward(self, query, reference_points, input_flatten, input_spatial_shapes, input_level_start_index, input_padding_mask=None):\n        \"\"\"\n        :param query                       (N, Length_{query}, C)\uff0c\u7f16\u7801\u7279\u5f81\u4e0e\u4fe1\u606f\u7f16\u7801\u76f8\u52a0\u540e\u7684\u6570\u636e\uff0c\u5145\u5f53\u67e5\u8be2q\n        :param reference_points            (N, Length_{query}, n_levels, 2), range in [0, 1], top-left (0,0), bottom-right (1, 1), including padding area\n                                        or (N, Length_{query}, n_levels, 4), add additional (w, h) to form reference boxes\n        :param input_flatten               (N, \\sum_{l=0}^{L-1} H_l \\cdot W_l, C)\uff0c\u7f16\u7801\u7279\u5f81\uff0c\u5145\u5f53\u503cv\n        :param input_spatial_shapes        (n_levels, 2), [(H_0, W_0), (H_1, W_1), ..., (H_{L-1}, W_{L-1})]\n        :param input_level_start_index     (n_levels, ), [0, H_0*W_0, H_0*W_0+H_1*W_1, H_0*W_0+H_1*W_1+H_2*W_2, ..., H_0*W_0+H_1*W_1+...+H_{L-1}*W_{L-1}]\n        :param input_padding_mask          (N, \\sum_{l=0}^{L-1} H_l \\cdot W_l), True for padding elements, False for non-padding elements\n\n        :return output                     (N, Length_{query}, C)\n        \"\"\"\n        N, Len_q, _ = query.shape\n        N, Len_in, _ = input_flatten.shape\n        assert (input_spatial_shapes[:, 0] * input_spatial_shapes[:, 1]).sum() == Len_in\n        # v\u7ecf\u8fc7\u4e00\u6b21\u7ebf\u6027\u6620\u5c04\uff0c\u5f97\u5230\u7528\u4e8e\u8ba1\u7b97\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u7684v\n        value = self.value_proj(input_flatten)\n        if input_padding_mask is not None:\n            value = value.masked_fill(input_padding_mask[..., None], float(0))\n        # \u5206\u6210\u4e0d\u540c\u7684\u5934\uff0c\u5f15\u5165\u591a\u5934\u6ce8\u610f\u7684\u6982\u5ff5\n        value = value.view(N, Len_in, self.n_heads, self.d_model // self.n_heads)\n        # \u5229\u7528\u67e5\u8be2\u5411\u91cf\u9884\u6d4b\u504f\u79fb\u91cf\uff08\u5230\u5e95\u5f80\u54ea\u504f\uff0c\u4e0e\u54ea\u4e2a\u5143\u7d20\u5efa\u7acb\u8054\u7cfb\uff0c\u9700\u8981\u56e0\u67e5\u8be2\u5411\u91cfq\u800c\u5f02\uff0c\u56e0\u4e3a\u6ce8\u610f\u529b\u672c\u8eab\u5c31\u662f\u8981\u8ba1\u7b97q\u5bf9\u5e94\u7684'v'\u503c\uff09\n        # \u6ce8\u610f\uff0c\u8fd9\u91cc\u628a\u6240\u6709\u5c42\u7684\u7279\u5f81\u5e8f\u5217\u90fd\u6df7\u5230\u4e00\u5757\u4e86\uff0c\u6240\u4ee5\u6bcf\u4e2a\u7279\u5f81\u5e8f\u5217\u90fd\u4f1a\u9884\u6d4b\u56db\u7ec4\u504f\u79fb\u91cf\uff0c\u5206\u522b\u8868\u793a\u5bf9\u5e94\u7684\u5c42\u7ea7\n        # \u540e\u9762\u4f1a\u6839\u636e\u5c42\u7ea7\u7279\u5f81\u5e8f\u5217\u7684\u7d22\u5f15input_level_start_index\uff0c\u6765\u8fdb\u884c\u7b5b\u9009\n        sampling_offsets = self.sampling_offsets(query).view(N, Len_q, self.n_heads, self.n_levels, self.n_points, 2)\n        # \u6839\u636e\u67e5\u8be2\u6765\u8ba1\u7b97\u6ce8\u610f\u529b\u6743\u91cd\uff0c\u540c\u6837\u6743\u91cd\u53ea\u8ddf\u67e5\u8be2q\u6709\u5173\u3002\u6ce8\u610f\uff1a\u504f\u79fb\u91cf\u4e0ex\u3001y\u4e24\u4e2a\u6570\u6709\u5173\uff0c\u56e0\u6b64\u504f\u79fb\u6570\u636e\u91cf\u662f\u6ce8\u610f\u529b\u6743\u91cd\u6570\u636e\u91cf\u7684\u4e24\u500d\n        attention_weights = self.attention_weights(query).view(N, Len_q, self.n_heads, self.n_levels * self.n_points)\n        # \u6743\u91cd\u7ecf\u8fc7\u4e00\u6b21softmax\uff0c\u505a\u5f52\u4e00\u5316\u64cd\u4f5c\n        attention_weights = F.softmax(attention_weights, -1).view(N, Len_q, self.n_heads, self.n_levels, self.n_points)\n        # N, Len_q, n_heads, n_levels, n_points, 2\n        # \u53c2\u8003\u70b9\u4e0e\u504f\u79fb\u91cf\u505a\u52a0\u6cd5\uff0c\u5f97\u5230\u91c7\u6837\u70b9\u3002\u8ddf\u4e0a\u9762\u5206\u6790\u7684\u4e00\u6837\uff0c\u65e0\u8bba\u54ea\u4e2a\u5c42\u7ea7\uff0c\u6bcf\u4e2a\u5e8f\u5217\u7279\u5f81\u90fd\u4f1a\u4e0e\u4e0d\u540c\u5c42\u4e0a\u7684\u504f\u79fb\u91cf\u505a\u76f8\u52a0\uff0c\u540e\u9762\u4f1a\u518d\u6839\u636einput_level_start_index\u7b5b\u9009\u51fa\u6765\n        if reference_points.shape[-1] == 2:\n            offset_normalizer = torch.stack([input_spatial_shapes[..., 1], input_spatial_shapes[..., 0]], -1)\n            sampling_locations = reference_points[:, :, None, :, None, :] \\\n                                 + sampling_offsets / offset_normalizer[None, None, None, :, None, :]\n        elif reference_points.shape[-1] == 4:\n            sampling_locations = reference_points[:, :, None, :, None, :2] \\\n                                 + sampling_offsets / self.n_points * reference_points[:, :, None, :, None, 2:] * 0.5\n        else:\n            raise ValueError(\n                'Last dim of reference_points must be 2 or 4, but get {} instead.'.format(reference_points.shape[-1]))\n        # \u76f4\u63a5\u8bf6\u8c03\u7528\u5e93\uff0c\u8ba1\u7b97\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u673a\u5236\n        output = MSDeformAttnFunction.apply(\n            value, input_spatial_shapes, input_level_start_index, sampling_locations, attention_weights, self.im2col_step)\n        output = self.output_proj(output)\n        return output\n</code></pre>"},{"location":"transformer/DeDETR/#_10","title":"\u89e3\u7801\u5668","text":"<pre><code>class DeformableTransformerDecoderLayer(nn.Module):\n    def __init__(self, d_model=256, d_ffn=1024,\n                 dropout=0.1, activation=\"relu\",\n                 n_levels=4, n_heads=8, n_points=4):\n        super().__init__()\n\n        # cross attention\n        self.cross_attn = MSDeformAttn(d_model, n_levels, n_heads, n_points)\n        self.dropout1 = nn.Dropout(dropout)\n        self.norm1 = nn.LayerNorm(d_model)\n\n        # self attention\n        self.self_attn = nn.MultiheadAttention(d_model, n_heads, dropout=dropout)\n        self.dropout2 = nn.Dropout(dropout)\n        self.norm2 = nn.LayerNorm(d_model)\n\n        # ffn\n        self.linear1 = nn.Linear(d_model, d_ffn)\n        self.activation = _get_activation_fn(activation)\n        self.dropout3 = nn.Dropout(dropout)\n        self.linear2 = nn.Linear(d_ffn, d_model)\n        self.dropout4 = nn.Dropout(dropout)\n        self.norm3 = nn.LayerNorm(d_model)\n\n    @staticmethod\n    def with_pos_embed(tensor, pos):\n        return tensor if pos is None else tensor + pos\n\n    def forward_ffn(self, tgt):\n        tgt2 = self.linear2(self.dropout3(self.activation(self.linear1(tgt))))\n        tgt = tgt + self.dropout4(tgt2)\n        tgt = self.norm3(tgt)\n        return tgt\n\n    def forward(self, tgt, query_pos, reference_points, src, src_spatial_shapes, level_start_index, src_padding_mask=None):\n        # self attention # \u89e3\u7801\u7279\u5f81\u548c\u67e5\u8be2\u5411\u91cfq\u505a\u81ea\u6ce8\u610f\u529b\u8fd0\u7b97\uff0c\u81ea\u6ce8\u610f\u529b\u8fd0\u7b97\u76f4\u63a5\u7528\u591a\u5934\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u4e0d\u505a\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u64cd\u4f5c\n        q = k = self.with_pos_embed(tgt, query_pos)\n        tgt2 = self.self_attn(q.transpose(0, 1), k.transpose(0, 1), tgt.transpose(0, 1))[0].transpose(0, 1)\n        tgt = tgt + self.dropout2(tgt2)\n        tgt = self.norm2(tgt)\n\n        # cross attention # \u4ea4\u53c9\u6ce8\u610f\u529b\n        tgt2 = self.cross_attn(self.with_pos_embed(tgt, query_pos),\n                               reference_points,\n                               src, src_spatial_shapes, level_start_index, src_padding_mask)\n        tgt = tgt + self.dropout1(tgt2)\n        tgt = self.norm1(tgt)\n\n        # ffn\n        tgt = self.forward_ffn(tgt)\n\n        return tgt\n\n\nclass DeformableTransformerDecoder(nn.Module):\n    def __init__(self, decoder_layer, num_layers, return_intermediate=False):\n        super().__init__()\n        self.layers = _get_clones(decoder_layer, num_layers)\n        self.num_layers = num_layers\n        self.return_intermediate = return_intermediate\n        # hack implementation for iterative bounding box refinement and two-stage Deformable DETR\n        self.bbox_embed = None\n        self.class_embed = None\n    # tgt\u8868\u793a\u56fe\u50cf\u89e3\u7801\u7279\u5f81\uff0c\u662f\u968f\u7740for\u5faa\u73af\uff08\u89e3\u7801\u8fd0\u7b97\uff09\u7684\u8fdb\u884c\u4e0d\u65ad\u53d8\u5316\u7684\uff0c\u5c3a\u5bf8\u4e0e\u9884\u8bbe\u7684\u67e5\u8be2\u5411\u91cfq\u4e00\u6837\uff0c\u90fd\u662f(300,256)\n    # src\u8868\u793a\u56fe\u50cf\u7f16\u7801\u7279\u5f81\uff0c\u5728\u89e3\u7801\u8fc7\u7a0b\u4e2d\u59cb\u7ec8\u4e0d\u53d8\n    def forward(self, tgt, reference_points, src, src_spatial_shapes, src_level_start_index, src_valid_ratios,\n                query_pos=None, src_padding_mask=None):\n        output = tgt\n\n        intermediate = []\n        intermediate_reference_points = []\n        for lid, layer in enumerate(self.layers):\n            if reference_points.shape[-1] == 4:\n                reference_points_input = reference_points[:, :, None] \\\n                                         * torch.cat([src_valid_ratios, src_valid_ratios], -1)[:, None]\n            else:\n                assert reference_points.shape[-1] == 2\n                reference_points_input = reference_points[:, :, None] * src_valid_ratios[:, None]\n            output = layer(output, query_pos, reference_points_input, src, src_spatial_shapes, src_level_start_index, src_padding_mask)\n\n            # hack implementation for iterative bounding box refinement\n            if self.bbox_embed is not None:\n            # if True:\n            #     \u6bcf\u6b21\u5f97\u5230\u7684\u56fe\u50cf\u89e3\u7801\u7279\u5f81\u90fd\u7528\u4e8e\u7ec6\u5316\u53c2\u8003\u70b9\uff0c\u4e4b\u540e\u7ec6\u5316\u8fb9\u754c\u6846\n                tmp = self.bbox_embed[lid](output)\n                if reference_points.shape[-1] == 4:\n                    new_reference_points = tmp + inverse_sigmoid(reference_points)\n                    new_reference_points = new_reference_points.sigmoid()\n                else:\n                    assert reference_points.shape[-1] == 2\n                    new_reference_points = tmp\n                    new_reference_points[..., :2] = tmp[..., :2] + inverse_sigmoid(reference_points)\n                    new_reference_points = new_reference_points.sigmoid()\n                reference_points = new_reference_points.detach()\n\n            if self.return_intermediate:\n                intermediate.append(output)\n                intermediate_reference_points.append(reference_points)\n\n        if self.return_intermediate:\n            return torch.stack(intermediate), torch.stack(intermediate_reference_points)\n\n        return output, reference_points\n</code></pre> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u6307\u6b63\u3002</p> <p>\u521d\u6b65\u5b8c\u7a3f\u4e8e\uff1a2023\u5e748\u6708</p>"},{"location":"transformer/Maskformer/","title":"Maskformer","text":""},{"location":"transformer/Maskformer/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aAdvances in Neural Information Processing Systems, 2021 (NIPS, 2021)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttp://proceedings.neurips.cc/paper/2021/file/950a4152c2b4aa3ad78bdd6b366cc179-Paper.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/facebookresearch/MaskFormer</p>"},{"location":"transformer/Maskformer/#_2","title":"\u4ecb\u7ecd","text":"<p>\u2003\u2003\u4f20\u7edf\u7684\u8bed\u4e49\u5206\u5272\u7b97\u6cd5\u5927\u90e8\u5206\u90fd\u662f\u57fa\u4e8e\u50cf\u7d20\u70b9\u505a\u5206\u7c7b\u7684\u7b97\u6cd5\uff0c\u5982\u4e0b\u56fe\u5de6\u4fa7\u6240\u793a\uff0c\u5229\u7528\u5206\u7c7b\u635f\u5931\u5bf9\u6bcf\u4e2a\u50cf\u7d20\u70b9\u505a\u4f18\u5316\uff0c\u5c06\u8bed\u4e49\u5206\u5272\u4efb\u52a1\u7b80\u5316\u4e3a\u5206\u7c7b\u4efb\u52a1\u3002\u672c\u6587\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u4e3a\u63a9\u6a21\u5206\u7c7b\uff08mask classification\uff09\u65b9\u6cd5\uff0c\u5982\u4e0b\u56fe\u53f3\u4fa7\u6240\u793a\uff0c\u7f51\u7edc\u9996\u5148\u9884\u6d4b\u51fa\u4e00\u7ec4\u4e8c\u503c\u63a9\u7801\uff0c\u6bcf\u4e2a\u63a9\u7801\u90fd\u4ee3\u8868\u4e00\u4e2a\u5b9e\u4f8b\u533a\u57df\uff0c\u4e4b\u540e\u518d\u9488\u5bf9\u6bcf\u4e2a\u63a9\u7801\u505a\u5206\u7c7b\u64cd\u4f5c\uff0c\u5224\u65ad\u8be5\u5b9e\u4f8b\u5c5e\u4e8e\u54ea\u4e2a\u7c7b\u522b\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u7edf\u4e00\u89e3\u51b3\u8bed\u4e49\u7ea7\u5206\u5272(semantic-level segmentation)\u548c\u5b9e\u4f8b\u7ea7\u5206\u5272(instance-level segmentation)\u4efb\u52a1\u3002</p> <p> <p></p> <p></p> <p>\u2003\u2003\u5b9e\u73b0\u65b9\u6cd5\u4e0eDETR\u7c7b\u4f3c\uff0c\u6838\u5fc3\u601d\u60f3\u4e3a\u9884\u8bbeN\u4e2a\u67e5\u8be2\u5411\u91cf\uff0c\u4e4b\u540e\u5229\u7528\u9884\u8bbe\u7684\u5411\u91cf\u505a\u89e3\u7801\uff0c\u5f97\u5230N\u7ec4\u63a9\u7801\u548c\u7c7b\u522b\u3002\u7f51\u7edc\u4e3b\u8981\u7531\u4e09\u90e8\u5206\u7ec4\u6210\uff1a\u2460\u50cf\u7d20\u6a21\u5757\uff08pixel-level module\uff09\uff1b\u2461TF\u6a21\u5757\uff08transformer module\uff09\uff1b\u2462\u5206\u5272\u6a21\u5757\uff08segmentation module\uff09\uff0c\u7b97\u6cd5\u7ed3\u6784\u56fe\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u50cf\u7d20\u6a21\u5757\uff08pixel-level module\uff09</p> <p>\u2003\u2003\u4e3b\u8981\u7531\u4e24\u4e2a\u6a21\u5757\u6784\u6210\uff1a</p> <ul> <li>backbone\uff1a\u53ef\u4ee5\u662f\u6807\u51c6\u7684ResNet\u7f51\u7edc\uff0c\u4e5f\u53ef\u4ee5\u662fSwin-Transformer\u7f51\u7edc\uff0c\u4e3b\u8981\u7528\u4e8e\u5bf9\u56fe\u50cf\u505a\u7f16\u7801\uff0c\u63d0\u53d6\u7279\u5f81\uff1b</li> <li>pixel decoder\uff1a\u53ef\u4ee5\u4f7f\u7528\u5e38\u89c1\u7684\u4e0a\u91c7\u6837\u7b97\u6cd5\u6267\u884c\u89e3\u7801\uff0c\u540c\u65f6\u4e5f\u53ef\u4ee5\u6dfb\u52a0ASPP\u3001PSP\u6a21\u5757\u6765\u63d0\u9ad8\u611f\u53d7\u91ce\uff0c\u6355\u83b7\u8de8\u4f4d\u7f6e\u7684\u4fe1\u606f\uff0c\u4f46\u662fTF\u6a21\u5757\u672c\u6765\u5c31\u6709\u6355\u83b7\u5168\u5c40\u4fe1\u606f\u7684\u80fd\u529b\uff0c\u56e0\u6b64\u4e0d\u7528\u6dfb\u52a0\u989d\u5916\u7684\u6a21\u5757\u3002\u672c\u6587\u4f5c\u8005\u53c2\u8003FPN\u6a21\u5757\uff0c\u6dfb\u52a0\u4e86\u6a2a\u5411\u8fde\u63a5\u64cd\u4f5c\u6765\u5b9e\u73b0\u4e0a\u91c7\u6837\uff0c\u5bf9\u4e8e\u6bcf\u6b21\u89e3\u7801\uff0c\u9996\u5148\u5229\u75281*1\u7684\u5377\u79ef\u5c06\u7279\u5f81\u56fe\u901a\u9053\u6570\u538b\u7f29\u4e3a256\uff0c\u4e4b\u540e\u5229\u7528\u4e0a\u91c7\u6837\u64cd\u4f5c\u5c06\u6df1\u5c42\u7684\u7279\u5f81\u56fe\u653e\u5927\u4e24\u500d\uff0c\u518d\u4e0e\u6d45\u5c42\u7279\u5f81\u76f8\u52a0\uff0c\u6700\u540e\u7ecf\u8fc7\u4e00\u6b213*3\u7684\u5377\u79ef\u505a\u7279\u5f81\u878d\u5408\uff08\u6bcf\u6b21\u5377\u79ef\u90fd\u4f1a\u7ecf\u8fc7\u4e00\u6b21GN\u548cReLU\uff09\u3002pixel decoder\u4f1a\u5c06\u6b65\u5e45\u4e3a32\u7684\u7279\u5f81\u56fe\u89e3\u7801\u4e3a\u6b65\u5e45\u4e3a4\u7684\u7279\u5f81\u56fe\uff0c\u89e3\u7801\u6700\u540e\u4f1a\u7ecf\u8fc7\u4e00\u6b211*1\u7684\u5377\u79ef\u5f97\u5230\u50cf\u7d20\u7f16\u7801\uff08per-pixel embeddings\uff09\uff0c\u901a\u9053\u6570\u4e3a256\uff08\u8fd9\u91cc\u8981\u548c\u4e0b\u9762\u5206\u5272\u6a21\u5757\u8f93\u51fa\u7684\u63a9\u6a21\u7f16\u7801\u7279\u5f81\u7ef4\u5ea6\u5bf9\u5e94\u8d77\u6765\uff0c\u540e\u9762\u8f93\u51fa\u7684\u63a9\u6a21\u7f16\u7801\u7279\u5f81\u7ef4\u5ea6\u51fa\u73b0\u53d8\u5316\uff0c\u8fd9\u91cc\u5c31\u8981\u6539\u53d8\uff09\u3002</li> </ul> <p>\u6ce8\uff1a\u7531\u4e8e\u89e3\u7801\u7279\u5f81\u6b65\u5e45\u4e3a4\uff0c\u5c3a\u5bf8\u4e3a\u539f\u56fe\u5c3a\u5bf8\u7684\u56db\u5206\u4e4b\u4e00\uff0c\u56e0\u6b64\u8f93\u51fa\u7684\u63a9\u6a21\u4e5f\u662f\u539f\u56fe\u7684\u56db\u5206\u4e4b\u4e00\uff0c\u9700\u8981\u5229\u7528\u53cc\u7ebf\u6027\u63d2\u503c\u64cd\u4f5c\u5c06\u8f93\u51fa\u7684\u63a9\u6a21\u56fe\u653e\u59274\u500d\uff0c\u518d\u8ba1\u7b97\u635f\u5931\u3002</p> <p>TF\u6a21\u5757\uff08transformer module\uff09</p> <p>\u2003\u2003\u8fd9\u91cc\u4f7f\u7528\u7684\u89e3\u7801\u6a21\u5757\u548cDETR\u4e2d\u7684\u89e3\u7801\u6a21\u5757\u7ed3\u6784\u4e00\u6837\uff08\u5305\u62ec\u591a\u5934\u6ce8\u610f\u529b\u4e2dQKV\u7684\u4f20\u5165\u65b9\u5f0f\uff09\uff0c\u5176\u4e2d\u7f16\u7801\u7279\u5f81\u4f7f\u7528\u6765\u81eabackbone\u6700\u540e\u4e00\u4e2a\u9636\u6bb5\u7684\u7279\u5f81\u56fe\uff0c\u5e76\u4e14\u9884\u8bbe100\u4e2a\u67e5\u8be2\u5411\u91cf\uff0c\u4f7f\u75286\u4e2aTF\u89e3\u7801\u6a21\u5757\u3002</p> <p>\u8865\uff1a\u9996\u5148\u8ba9\u9884\u8bbe\u7684\u67e5\u8be2\u5411\u91cf\u505a\u81ea\u6ce8\u610f\u529b\u64cd\u4f5c\uff0c\u5c06\u67e5\u8be2\u5411\u91cf\u4e0e\u89e3\u7801\u7279\u5f81\u4f20\u5165\u591a\u5934\u6ce8\u610f\u529b\uff0c\u5176\u4e2dq\u3001k\u5143\u7d20\u4f20\u5165\u67e5\u8be2\u5411\u91cf\u4e0e\u89e3\u7801\u7279\u5f81\u76f8\u52a0\u540e\u7684\u6570\u636e\uff0cv\u4f20\u5165\u89e3\u7801\u7279\u5f81\u3002\u4e4b\u540e\u518d\u5c06\u6240\u5f97\u6570\u636e\u4f20\u5165\u591a\u5934\u6ce8\u610f\u529b\u4e2d\uff0cq\u4f20\u5165\u89e3\u7801\u7279\u5f81\u4e0e\u7269\u4f53\u67e5\u8be2\u5411\u91cf\u76f8\u52a0\uff0ck\u4f20\u5165\u7f16\u7801\u7279\u5f81\u4e0e\u4f4d\u7f6e\u7f16\u7801\u76f8\u52a0\uff0cv\u4f20\u5165\u7f16\u7801\u7279\u5f81\u3002\u7279\u5f81\u7ecf\u8fc7\u516d\u7ec4\u89e3\u7801\u6a21\u5757\u4e4b\u540e\uff0c\u4f1a\u5f97\u5230\u5c3a\u5bf8\u4e3a(N,256)\u7684\u89e3\u7801\u7279\u5f81\uff0c\u518d\u5c06\u6b64\u7279\u5f81\u4f20\u5165\u9884\u6d4b\u5934\uff0c\u53ef\u4ee5\u5f97\u5230\u7269\u4f53\u7c7b\u522b\u4ee5\u53ca\u8fb9\u754c\u6846\u5750\u6807\u6570\u636e\u3002</p> <p>\u5206\u5272\u6a21\u5757\uff08segmentation module\uff09</p> <p>\u2003\u2003\u4e3b\u8981\u7531\u591a\u5c42\u611f\u77e5\u673a\u6784\u6210\u3002\u5bf9\u4e8e\u63a9\u6a21\u7c7b\u522b\u9884\u6d4b\uff0c\u5c06TF\u89e3\u7801\u7279\u5f81\u4f20\u5165\u542b\u6709\u4e00\u4e2a\u9690\u85cf\u5c42\u7684MLP\u505a\u5206\u7c7b\uff0c\u5e76\u4e14\u5c06\u7ed3\u679c\u4f20\u5165Softmax\u5c42\u505a\u5f52\u4e00\u5316\uff0c\u8f93\u51faK+1\u4e2a\u9884\u6d4b\u5206\u6570\uff08K\u4e2a\u7c7b\u522b\uff0c1\u4e2a\u8868\u793a\\phi\uff0c\u5373\u65e0\u76ee\u6807\uff0c\u820d\u53bb\u8be5\u63a9\u7801\uff09\uff1b\u5bf9\u4e8e\u4e8c\u503c\u63a9\u6a21\u9884\u6d4b\uff0c\u5c06TF\u89e3\u7801\u7279\u5f81\u4f20\u5165\u542b\u6709\u4e24\u4e2a\u9690\u85cf\u5c42\u7684MLP\u505a\u9884\u6d4b\uff0c\u8f93\u51fa\u4e00\u7ec4\u63a9\u6a21\u7f16\u7801\u7279\u5f81\uff08mask embedding\uff09\uff0c\u7279\u5f81\u7ef4\u5ea6\u8981\u548cpixel decoder\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u901a\u9053\u6570\u76f8\u540c\uff0c\u4e4b\u540e\u518d\u5c06\u6240\u5f97\u7684\u63a9\u6a21\u7f16\u7801\u7279\u5f81\u4e0e\u89e3\u7801\u7279\u5f81\u56fe\u505a\u77e9\u9635\u4e58\u6cd5\u8fd0\u7b97\uff0c\u5f97\u5230N\u7ec4\u9884\u6d4b\u63a9\u6a21\uff0c\u4e4b\u540e\u518d\u7ecf\u8fc7\u4e00\u6b21sigmoid\u8fd0\u7b97\u505a\u5f52\u4e00\u5316\u3002</p> <p>\u635f\u5931\u51fd\u6570</p> <p>\u2003\u2003\u5bf9\u4e8e\u4e8c\u503c\u63a9\u6a21\u56fe\u9884\u6d4b\u7684\u4f18\u5316\uff0c\u4f7f\u7528focal loss\u548cdice loss\uff08focal loss\u6743\u91cd\u8bbe\u4e3a20.0\uff0cdice loss\u6743\u91cd\u8bbe\u4e3a1.0\uff09\uff0c\u5bf9\u4e8e\u63a9\u6a21\u56fe\u7c7b\u522b\u9884\u6d4b\u7684\u4f18\u5316\uff0c\u4f7f\u7528\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\u3002\u5bf9\u4e8e\u67e5\u8be2\u5411\u91cf\u7684\u6807\u7b7e\u5339\u914d\uff0c\u4f7f\u7528\u548cDETR\u4e2d\u76f8\u540c\u7684\u5339\u914d\u89c4\u5219\uff0c\u5148\u8ba1\u7b97\u635f\u5931\u77e9\u9635\uff0c\u4e4b\u540e\u5229\u7528\u5308\u7259\u5229\u7b97\u6cd5\u505a\u5339\u914d\u3002</p> <p>\u63a8\u7406\u8fc7\u7a0b</p> <ul> <li>\u5bf9\u4e8e\u8bed\u4e49\u63a8\u7406\uff1a\u9996\u5148\u5220\u6389\u2205\u5bf9\u5e94\u7c7b\u522b\u7684\u9884\u6d4b\u5206\u6570\uff0c\u4e4b\u540e\u8ba9\u5c3a\u5bf8\u4e3a[N,K]\u7684\u63a9\u6a21\u7c7b\u522b\u9884\u6d4b\u5206\u6570\u4e0e\u5c3a\u5bf8\u4e3a[N,H,W]\u7684\u4e8c\u503c\u63a9\u6a21\u9884\u6d4b\u505a\u77e9\u9635\u4e58\u6cd5\uff08\u7c7b\u522b\u5206\u6570\u5148\u8f6c\u7f6e\uff09\uff0c\u5f97\u5230\u5c3a\u5bf8\u4e3a[K,H,W]\u7684\u9884\u6d4b\u56fe\uff0c\u4e4b\u540e\u6cbf\u901a\u9053\u65b9\u5411\u9009\u53d6\u6570\u503c\u6700\u5927\u7684\u7d22\u5f15\u5e8f\u53f7\uff0c\u5f53\u505a\u8be5\u70b9\u7684\u7c7b\u522b\uff1b</li> <li>\u5bf9\u4e8e\u5168\u666f\u63a8\u7406\uff08\u65e2\u8981\u9884\u6d4b\u8bed\u4e49\u3001\u4e5f\u8981\u7ed9\u51fa\u5b9e\u4f8b\uff09\uff1a\u5148\u5220\u6389\u9884\u6d4b\u4e3a\u2205\u7684\u63a9\u6a21\uff0c\u4ee5\u53ca\u6700\u5927\u9884\u6d4b\u5206\u6570\u4ecd\u8fc7\u5c0f\u7684\u63a9\u6a21\uff08\u6709\u4e2a\u9608\u503c\uff09\uff0c\u4e4b\u540e\u8ba9\u6bcf\u4e2a\u63a9\u6a21\u7684\u7c7b\u522b\u9884\u6d4b\u5206\u6570\u4e0e\u4e8c\u503c\u63a9\u6a21\u7684\u524d\u666f\u5206\u6570\u505a\u70b9\u4e58\uff0c\u5f97\u5230\u7efc\u5408\u5206\u6570\uff0c\u6bcf\u4e2a\u70b9\u4e0a\uff0c\u6700\u5927\u7684\u7efc\u5408\u5206\u6570\u6240\u5bf9\u5e94\u7684\u7c7b\u522b\u5373\u4e3a\u8be5\u70b9\u7684\u9884\u6d4b\u7c7b\u522b\uff0c\u5373\u6bcf\u4e2a\u70b9\u7684\u7c7b\u522b\u53ef\u89c6\u4e3a\uff1aarg\\max_{i:c_i\\ne \\phi}p_i(c_i)\u3002\u901a\u4fd7\u5730\u6765\u8bb2\u5c31\u662f\u53ea\u6709\u5f53\u7c7b\u522b\u9884\u6d4b\u5206\u6570\u4e0e\u4e8c\u503c\u63a9\u6a21\u4e0a\u7684\u524d\u666f\u9884\u6d4b\u5206\u6570\u90fd\u5f88\u5927\u65f6\uff0c\u8be5\u70b9\u624d\u53ef\u4ee5\u89c6\u4e3a\u4e00\u4e2a\u5b9e\u4f8b\u70b9\u3002</li> </ul> <p>\u6ce8\uff1a\u63a8\u7406\u8fc7\u7a0bbatch\u8981\u8bbe\u4e3a1</p> <p>\u53c2\u8003\u94fe\u63a5\uff1a</p> <ul> <li>https://zhuanlan.zhihu.com/p/389457610</li> </ul>"},{"location":"transformer/Maskformer/#_3","title":"\u4ee3\u7801\u5b9e\u73b0","text":"<p>\u2003\u2003\u95ee\u9898\u8bb0\u5f55\uff1a\u5168\u666f\u5206\u5272\uff0c\u600e\u4e48\u5224\u65ad\u4e00\u4e2a\u7269\u4f53\u662f\u5426\u5c5e\u4e8e\u53ef\u6570\u7269\u4f53\u8fd8\u662f\u4e0d\u53ef\u6570\u7269\u4f53\u3002\u5728\u524d\u9762\u5df2\u7ecf\u5220\u53bb\u4e86\u2205\u7c7b\u522b\uff0c\u5269\u4e0b\u7684\u63a9\u6a21\u7684\u7c7b\u522b\u5f52\u5c5e\u5e94\u8be5\u90fd\u662f\u9884\u8bbe\u597d\u7684\u7c7b\u522b\u5427\uff0c\u90a3\u5982\u679c\u53ea\u5224\u65ad\u5f53\u524d\u7c7b\u522b\u662f\u5426\u5c5e\u4e8e\u9884\u8bbe\u597d\u7684\uff0c\u90a3\u4e48\u6240\u6709\u7684\u63a9\u6a21\u6240\u4ee3\u8868\u7684\u7269\u4f53\u5c82\u4e0d\u90fd\u662f\u53ef\u6570\u7c7b\u522b\u7684\u7269\u4f53\u4e86\uff1f</p> <p>\u53c2\u8003\u4ee3\u7801\uff1a</p> <ul> <li>https://github.com/tinnunculus/MaskFormer</li> <li>https://github.com/facebookresearch/MaskFormer</li> </ul>"},{"location":"transformer/Maskformer/#_4","title":"\u6574\u4f53\u7ed3\u6784","text":"<pre><code>class MaskFormer(nn.Module):\n    def __init__(self, model_config):\n        super(MaskFormer, self).__init__()\n        # \u521d\u59cb\u5316\u6a21\u5757\n        self.backbone = Swin_transformer(\n            patch_size=model_config[\"backbone_patch_size\"],\n            window_size=model_config[\"backbone_window_size\"],\n            merge_size=model_config[\"backbone_merge_size\"],\n            model_dim=model_config[\"backbone_model_dim\"],\n            num_layers_in_stage=model_config[\"backbone_num_layers_in_stage\"]\n        )\n\n        in_channels = list(model_config[\"backbone_model_dim\"] * 2 ** i for i in\n                           range(len(model_config[\"backbone_num_layers_in_stage\"])))[::-1]\n        self.pixel_decoder = Pixel_decoder(\n            in_channels=in_channels,\n            channels=model_config[\"pixel_decoder_channels\"],\n            n_groups=model_config[\"pixel_decoder_n_groups\"]\n        )\n\n        in_channels = model_config[\"backbone_model_dim\"] * 2 ** (len(model_config[\"backbone_num_layers_in_stage\"]) - 1)\n        self.transformer_decoder = Transformer_decoder(\n            nhead=model_config[\"transformer_decoder_num_head\"],\n            dropout=model_config[\"transformer_decoder_dropout\"],\n            num_decoder_layers=model_config[\"transformer_decoder_num_layer\"]\n        )\n\n        self.segmentation_module = Segmentation_module(\n            n_class=model_config[\"segmentation_module_num_class\"],\n            in_channels=model_config[\"segmentation_module_in_channels\"],\n            out_channels=model_config[\"segmentation_module_out_channels\"]\n        )\n        n_query = model_config[\"transformer_decoder_num_query\"]\n        d_model = model_config[\"transformer_decoder_dimension\"]\n        feature_size = model_config[\"transformer_decoder_positional_size\"]\n        self.query_embed = nn.Parameter(torch.rand(n_query, d_model))\n        self.pos_embed = nn.Parameter(torch.randn(1, feature_size[0] * feature_size[1], d_model))\n        # \u9884\u8bbe\u4e00\u4e2a1*1\u7684\u5377\u79ef\uff0c\u5c06\u7f16\u7801\u7279\u5f81\u901a\u9053\u6570\u538b\u7f29\u4e3ad_model\uff0c\u4e4b\u540e\u4fbf\u4e8e\u4f20\u5165TF\u89e3\u7801\u6a21\u5757\n        self.conv_pre = nn.Conv2d(in_channels, d_model, kernel_size=1)\n        self.object_mask_threshold = 0.5\n        self.overlap_threshold = 0.0\n\n    def forward(self, x):\n        # \u8fd4\u56de\u4e00\u7ec4\u7279\u5f81\uff0c\u4ee5res50\u4e3a\u4f8b\uff0c\u8fd4\u56de[\"res2\", \"res3\", \"res4\", \"res5\"]\n        # \u4fbf\u4e8e\u540e\u7eed\u5229\u7528\u591a\u7ec4\u7279\u5f81\u505aFPN\u7279\u5f81\u878d\u5408\n        features = self.backbone(x)\n        # \u7279\u5f81\u56fe\u505a\u89e3\u7801\uff0c\u901a\u9053\u6570\u53d8\u4e3a256\uff0c\u5c3a\u5bf8\u653e\u59273\u6b21(\u53d8\u4e3a\u539f\u6765\u76848\u500d)\n        # \u7ed3\u6784\u53c2\u8003FPN\u7ed3\u6784\uff0c\u6bcf\u505a\u4e00\u6b21\u4e0a\u91c7\u6837\u90fd\u548c\u524d\u9762\u7684\u89e3\u7801\u7279\u5f81\u505a\u4e00\u6b21\u878d\u5408\uff08\u76f8\u52a0\uff09\n        pixel_feature = self.pixel_decoder(features)\n        b, C, H, W = pixel_feature.shape\n        # \u5c06\u6700\u540e\u4e00\u5c42\u7684\u7f16\u7801\u7279\u5f81\u4f20\u5165TF\u89e3\u7801\u5668\u4e2d\uff0c\u7ed3\u5408\u9884\u8bbe\u7684N\u4e2a\u67e5\u8be2\u5b9e\u4f8b\u5411\u91cf\u505a\u89e3\u7801\uff0c\u5f97\u5230\u89e3\u7801\u7279\u5f81\n        mask_embedded_vecs = self.transformer_decoder(self.conv_pre(features['stage4']),\n                                                     query_embed=self.query_embed, pos_embed=self.pos_embed)[0]\n        # \u5229\u7528\u6700\u540e\u4e00\u5c42\u7684\u89e3\u7801\u7279\u5f81\u505a\u9884\u6d4b\n        mask_embedded_vec = mask_embedded_vecs[-1]\n        # \u89e3\u7801\u7279\u5f81\u4f9d\u6b21\u4f20\u5165\u4e24\u7ec4MLP\uff0c\u5f97\u5230\u63a9\u6a21\u5411\u91cf\u548c\u5206\u7c7b\u7ed3\u679c\n        segmentation_mask_vecs, classification_vecs = self.segmentation_module(mask_embedded_vec)\n        # \u63a9\u6a21\u5411\u91cf\u548c\u89e3\u7801\u7279\u5f81\u505a\u77e9\u9635\u4e58\u6cd5\uff0c\u5f97\u5230\u9884\u6d4b\u7684\u4e8c\u503c\u63a9\u6a21\n        segmentation_mask = torch.matmul(segmentation_mask_vecs, pixel_feature.view(b, C, -1)).view(b, -1, H, W)\n        segmentation_mask = F.sigmoid(segmentation_mask)\n\n        result = {}\n        result[\"pred_masks\"] = segmentation_mask\n        result[\"pred_logits\"] = classification_vecs\n        return result\n</code></pre>"},{"location":"transformer/Maskformer/#_5","title":"\u7279\u5f81\u89e3\u7801","text":"<pre><code>class Pixel_decoder(nn.Module):\n    def __init__(\n            self,\n            in_channels: list = [96 * 8, 96 * 4, 96 * 2, 96],\n            channels: int = 256,\n            mask_dim: int = 256,\n            n_groups: int = 16\n    ):\n        super(Pixel_decoder, self).__init__()\n        self.num_stage = len(in_channels)\n        self.from_encoder_projection_list = nn.ModuleList([])\n        self.from_feature_projection_list = nn.ModuleList([])\n\n        # \u7b2c\u4e00\u4e2alayer\u4e0d\u9700\u8981\u5bf9\u6765\u81eaencoder\u7684feature\u8fdb\u884cprojection.\n        for i, in_channel in enumerate(in_channels):\n            if i == 0:\n                from_feature_projection = nn.Sequential(\n                    nn.Conv2d(in_channel, channels, kernel_size=3, stride=1, padding=1),\n                    nn.GroupNorm(n_groups, channels),\n                    nn.ReLU()\n                )\n\n                self.from_encoder_projection_list.append(None)\n                self.from_feature_projection_list.append(from_feature_projection)\n            else:\n                from_feature_projection = nn.Sequential(\n                    nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1),\n                    nn.GroupNorm(n_groups, channels),\n                    nn.ReLU()\n                )\n                from_encoder_projection = nn.Sequential(\n                    nn.Conv2d(in_channel, channels, kernel_size=1, stride=1),\n                    nn.GroupNorm(n_groups, channels)\n                )\n\n                self.from_encoder_projection_list.append(from_encoder_projection)\n                self.from_feature_projection_list.append(from_feature_projection)\n\n        self.final_projection = nn.Conv2d(channels, mask_dim, kernel_size=1, stride=1)\n\n    def forward(self, features):\n        '''\n            features : dict keys : stage1, stage2, stage3, stage4\n        '''\n        # \u89e3\u7801\u64cd\u4f5c\uff0c\u5c0616*16\u7279\u5f81\u56fe\u89e3\u78013\u6b21\uff0c\u53d8\u4e3a128*128\u7684\u7279\u5f81\u56fe\n        # \u7ed3\u6784\u53c2\u8003FPN\u7ed3\u6784\uff0c\u6bcf\u505a\u4e00\u6b21\u4e0a\u91c7\u6837\u90fd\u548c\u524d\u9762\u7684\u89e3\u7801\u7279\u5f81\u505a\u4e00\u6b21\u878d\u5408\uff08\u76f8\u52a0\uff09\n        feature = self.from_feature_projection_list[0](features['stage4'])\n\n        for i, (encoder_projection, feature_projection) in enumerate(\n                zip(self.from_encoder_projection_list[1:], self.from_feature_projection_list[1:])):\n            # \u5148\u5c06\u524d\u4e00\u4e2a\u7279\u5f81\u56fe\u901a\u9053\u6570\u538b\u7f29\uff0c\u4e4b\u540e\u5c06\u540e\u4e00\u4e2a\u7279\u5f81\u56fe\u5c3a\u5bf8\u53d8\u4e3a\u4e24\u500d\uff0c\u76f8\u52a0\n            feature = encoder_projection(features['stage' + str(3 - i)]) + F.interpolate(feature, scale_factor=2,\n                                                                                         mode=\"nearest\")\n            # \u7ecf\u8fc7\u4e00\u7ec4\u5377\u79ef\u6a21\u5757\n            feature = feature_projection(feature)\n        # \u6700\u540e\u7ecf\u8fc7\u4e00\u6b211*1\u7684\u5377\u79ef\uff0c\u5c06\u901a\u9053\u6570\u53d8\u4e3a\u89e3\u7801\u7279\u5f81\u7684\u901a\u9053\u6570\n        return self.final_projection(feature)\n</code></pre>"},{"location":"transformer/Maskformer/#tf","title":"TF\u89e3\u7801","text":"<p> \u89e3\u7801\u8fc7\u7a0b\u4e2d\uff0c\u81ea\u6ce8\u610f\u529b\u548c\u591a\u5934\u6ce8\u610f\u529bQKV\u7684\u4f20\u5165\u89c4\u5219\u548cDETR\u4e00\u6837\uff1a\u9996\u5148\u67e5\u8be2\u5411\u91cf\u505a\u81ea\u6ce8\u610f\u529b\u64cd\u4f5c\uff0c\u5c06\u67e5\u8be2\u5411\u91cf\u4e0e\u89e3\u7801\u7279\u5f81\u4f20\u5165\u591a\u5934\u6ce8\u610f\u529b\uff0c\u5176\u4e2dq\u3001k\u5143\u7d20\u4f20\u5165\u76ee\u6807\u67e5\u8be2\u5411\u91cf\u4e0e\u89e3\u7801\u7279\u5f81\u76f8\u52a0\u540e\u7684\u6570\u636e\uff0cv\u4f20\u5165\u89e3\u7801\u7279\u5f81\u3002\u4e4b\u540e\u518d\u5c06\u6240\u5f97\u6570\u636e\u4f20\u5165Transformer\u6a21\u5757\u4e2d\uff0c\u6d41\u7a0b\u4e0eTransformer\u89e3\u7801\u6a21\u5757\u7c7b\u4f3c\uff0c\u591a\u5934\u6ce8\u610f\u529b\u4e2d\uff0cq\u4f20\u5165\u89e3\u7801\u7279\u5f81\u4e0e\u7269\u4f53\u67e5\u8be2\u5411\u91cf\u76f8\u52a0\uff0ck\u4f20\u5165\u7f16\u7801\u7279\u5f81\u4e0e\u4f4d\u7f6e\u7f16\u7801\u76f8\u52a0\uff0cv\u4f20\u5165\u7f16\u7801\u7279\u5f81\u3002</p> <p>\u2003\u2003\u4ee3\u7801\u5b9e\u73b0\u548cDETR\u4e2d\u7684TF\u89e3\u7801\u6a21\u5757\u4e00\u81f4\uff1a</p> <pre><code>class Transformer_decoder(nn.Module):\n    def __init__(self, nhead=8, d_model=256, d_ff=512,\n                 dropout=0.1, num_decoder_layers=6, activation='relu',\n                 normalize_before=False):\n        super().__init__()\n\n        decoder_layer = TransformerDecoderLayer(\n            d_model, nhead, d_ff, dropout, activation, normalize_before\n        )\n        decoder_norm = nn.LayerNorm(d_model)\n        self.decoder = TransformerDecoder(\n            decoder_layer,\n            num_decoder_layers,\n            decoder_norm,\n            return_intermediate=True\n        )\n\n    def forward(self, memory, query_embed, pos_embed, mask=None):\n        # flatten NxCxHxW to HWxNxC\n        bs, c, h, w = memory.shape\n        memory = memory.flatten(2).permute(2, 0, 1)\n        pos_embed = pos_embed.flatten(2).permute(2, 0, 1)\n        query_embed = query_embed.unsqueeze(1).repeat(1, bs, 1)\n        if mask is not None:\n            mask = mask.flatten(1)\n\n        tgt = torch.zeros_like(query_embed)\n        hs = self.decoder(\n            tgt, memory, memory_key_padding_mask=mask, pos=pos_embed, query_pos=query_embed\n        )\n        return hs.transpose(1, 2), memory.permute(1, 2, 0).view(bs, c, h, w)\n\n\nclass TransformerDecoderLayer(nn.Module):\n    def __init__(\n            self,\n            d_model,\n            nhead,\n            dim_feedforward=2048,\n            dropout=0.1,\n            activation=\"relu\",\n            normalize_before=False,\n    ):\n        super().__init__()\n        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n        self.multihead_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n        # Implementation of Feedforward model\n        self.linear1 = nn.Linear(d_model, dim_feedforward)\n        self.dropout = nn.Dropout(dropout)\n        self.linear2 = nn.Linear(dim_feedforward, d_model)\n\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.norm3 = nn.LayerNorm(d_model)\n        self.dropout1 = nn.Dropout(dropout)\n        self.dropout2 = nn.Dropout(dropout)\n        self.dropout3 = nn.Dropout(dropout)\n\n        self.activation = _get_activation_fn(activation)\n        self.normalize_before = normalize_before\n\n    def with_pos_embed(self, tensor, pos: Optional[Tensor]):\n        return tensor if pos is None else tensor + pos\n\n    def forward(\n            self,\n            tgt,\n            memory,\n            tgt_mask: Optional[Tensor] = None,\n            memory_mask: Optional[Tensor] = None,\n            tgt_key_padding_mask: Optional[Tensor] = None,\n            memory_key_padding_mask: Optional[Tensor] = None,\n            pos: Optional[Tensor] = None,\n            query_pos: Optional[Tensor] = None,\n    ):\n        q = k = self.with_pos_embed(tgt, query_pos)\n        tgt2 = self.self_attn(\n            q, k, value=tgt, attn_mask=tgt_mask, key_padding_mask=tgt_key_padding_mask\n        )[0]\n        tgt = tgt + self.dropout1(tgt2)\n        tgt = self.norm1(tgt)\n        tgt2 = self.multihead_attn(\n            query=self.with_pos_embed(tgt, query_pos),\n            key=self.with_pos_embed(memory, pos),\n            value=memory,\n            attn_mask=memory_mask,\n            key_padding_mask=memory_key_padding_mask,\n        )[0]\n        tgt = tgt + self.dropout2(tgt2)\n        tgt = self.norm2(tgt)\n        tgt2 = self.linear2(self.dropout(self.activation(self.linear1(tgt))))\n        tgt = tgt + self.dropout3(tgt2)\n        tgt = self.norm3(tgt)\n        return tgt\n\n\ndef _get_activation_fn(activation):\n    \"\"\"Return an activation function given a string\"\"\"\n    if activation == \"relu\":\n        return F.relu\n    if activation == \"gelu\":\n        return F.gelu\n    if activation == \"glu\":\n        return F.glu\n    raise RuntimeError(f\"activation should be relu/gelu, not {activation}.\")\n\n\ndef _get_clones(module, N):\n    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n\n\nclass TransformerDecoder(nn.Module):\n    def __init__(self, decoder_layer, num_layers, norm=None, return_intermediate=False):\n        super().__init__()\n        self.layers = _get_clones(decoder_layer, num_layers)\n        self.num_layers = num_layers\n        self.norm = norm\n        self.return_intermediate = return_intermediate\n\n    def forward(\n            self,\n            tgt,\n            memory,\n            tgt_mask: Optional[Tensor] = None,\n            memory_mask: Optional[Tensor] = None,\n            tgt_key_padding_mask: Optional[Tensor] = None,\n            memory_key_padding_mask: Optional[Tensor] = None,\n            pos: Optional[Tensor] = None,\n            query_pos: Optional[Tensor] = None,\n    ):\n        output = tgt\n\n        intermediate = []\n\n        for layer in self.layers:\n            output = layer(\n                output,\n                memory,\n                tgt_mask=tgt_mask,\n                memory_mask=memory_mask,\n                tgt_key_padding_mask=tgt_key_padding_mask,\n                memory_key_padding_mask=memory_key_padding_mask,\n                pos=pos,\n                query_pos=query_pos,\n            )\n            if self.return_intermediate:\n                intermediate.append(self.norm(output))\n\n        if self.norm is not None:\n            output = self.norm(output)\n            if self.return_intermediate:\n                intermediate.pop()\n                intermediate.append(output)\n\n        if self.return_intermediate:\n            return torch.stack(intermediate)\n\n        return output.unsqueeze(0)\n</code></pre>"},{"location":"transformer/Maskformer/#_6","title":"\u6807\u7b7e\u5339\u914d","text":"<pre><code>class HungarianMatcher(nn.Module):\n    def __init__(self, w_class: float = 1, w_focal: float = 1, w_dice: float = 1):\n        super().__init__()\n        # \u8ba1\u7b97\u603b\u635f\u5931\u77e9\u9635\u65f6\uff0c\u6240\u7528\u7684\u6743\u91cd\n        self.w_class = w_class\n        self.w_focal = w_focal\n        self.w_dice = w_dice\n\n    @torch.no_grad()\n    def dice_cost(self, predict, target):\n        # predict : b * n_queries, h * w\n        # target : b * n_obj, h * w\n        numerator = 2 * (predict[:, None, :] * target[None, :, :]).sum(-1)\n        denominator = predict.sum(-1)[:, None] + target.sum(-1)[None, :]\n        cost_dice = 1 - (numerator + 1) / (denominator + 1)\n        return cost_dice\n\n    @torch.no_grad()\n    def focal_cost(self, predict, target, gamma=2., alpha=0.25):\n        # predict : b * n_queries, h * w\n        # target : b * n_obj, h * w\n        predict = predict[:, None, :].expand((predict.shape[0], target.shape[0], predict.shape[1]))\n        target = target[None, :, :].expand((predict.shape[0], target.shape[0], target.shape[1]))\n        ce = F.binary_cross_entropy_with_logits(predict, target, reduction='none')\n\n        p_t = predict * target + (1 - predict) * (1 - target)\n        focal_cost = ce * ((1 - p_t) ** gamma)\n\n        alpha_t = alpha * target + (1 - alpha) * (1 - target)\n        focal_cost = alpha_t * focal_cost\n        return focal_cost.mean(-1)\n\n    @torch.no_grad()\n    def forward(self, out, targets):\n        # \u5148\u63d0\u53d6\u9884\u6d4b\u503c\u548c\u6807\u7b7e\u6570\u636e\n        pred_logits = out[\"pred_logits\"]  # b, n, class + 1\n        pred_masks = out[\"pred_masks\"]  # b, n, h, w\n        target_logits = targets[\"labels\"]  # [ m_i for i in b]\n        target_masks = targets[\"masks\"]  # [ m_i, h, w for i in b]\n        bs, num_queries = pred_logits.shape[:2]\n        device = pred_logits.device\n        # \u5c06\u9884\u6d4b\u6570\u636e\u62c9\u76f4\uff0cout_prob:[batch_size * num_queries, num_classes + 1]\n        # out_mask:[batch_size * num_queries, h * w]\n        out_prob = pred_logits.flatten(0, 1).softmax(-1)\n        out_mask = pred_masks.flatten(0, 1).flatten(1, 2)\n        # \u5c06\u6807\u7b7e\u6570\u636e\u62c9\u76f4\uff0ctgt_ids:[batch_size * num_obj]\n        # tgt_mask:[batch_size * num_obj, h * w]\n        tgt_ids = torch.cat([v for v in target_logits])\n        tgt_mask = torch.cat([v for v in target_masks]).flatten(1, 2)\n\n        # \u8ba1\u7b97\u5355\u72ec\u7684\u635f\u5931\u77e9\u9635\uff0c\u5305\u62ec\u5206\u7c7b\u635f\u5931\u3001dice\u635f\u5931\u3001focal\u635f\u5931\n        cost_class = -out_prob[:, tgt_ids]  # [batch_size * num_queries, batch_size * num_obj]\n        cost_dice = self.dice_cost(out_mask, tgt_mask)  # [batch_size * num_queries, batch_size * num_obj]\n        cost_focal = self.focal_cost(out_mask, tgt_mask)  # [batch_size * num_queries, batch_size * num_obj]\n\n        # \u5408\u5e76\uff0c\u5f97\u5230\u603b\u635f\u5931\u77e9\u9635\n        C = self.w_dice * cost_dice + self.w_class * cost_class + self.w_focal * cost_focal\n        C = C.view(bs, num_queries, -1).cpu()  # [batch_size, num_queries, batch_size * num_obj]\n        # linear_sum_assignment\u8c03\u7528\u5308\u7259\u5229\u7b97\u6cd5\uff0c\u5f97\u5230\u603b\u635f\u5931\u6700\u5c0f\u7684\u5339\u914d\u7ed3\u679c\uff0c\u4e3a\u6bcf\u4e2a\u67e5\u8be2\u5411\u91cf\u52a0\u6807\u7b7e\n        sizes = [len(v) for v in target_masks]\n        indices = [linear_sum_assignment(c[i]) for i, c in enumerate(C.split(sizes, -1))]\n        result = []\n        for i, j in indices:\n            i = torch.as_tensor(i, dtype=torch.int64, device=device)\n            j = torch.as_tensor(j, dtype=torch.int64, device=device)\n            result.append(i[j])\n        return result\n</code></pre>"},{"location":"transformer/Maskformer/#_7","title":"\u635f\u5931\u8ba1\u7b97","text":"<pre><code>class Maskformer_loss(nn.Module):\n    def __init__(self, w_focal: float = 1., w_dice: float = 1., w_class: float = 1., w_noobj: float = 1.):\n        super(Maskformer_loss, self).__init__()\n        # \u635f\u5931\u6743\u91cd\n        self.w_class = w_class\n        self.w_focal = w_focal\n        self.w_dice = w_dice\n        # \u2205\u7c7b\u522b\u8ba1\u7b97\u4ea4\u53c9\u71b5\u65f6\uff0c\u5bf9\u5e94\u7684\u6743\u91cd\n        self.w_noobj = w_noobj\n\n    def class_loss(self, pred_logits, target_logits, match_indexs):\n        device = pred_logits.device\n        target_labels = torch.zeros(pred_logits.shape[:2], dtype=torch.int64, device=device)\n        cost_no_obj = torch.ones(pred_logits.shape[2], device=device)\n        cost_no_obj[0] *= self.w_noobj\n        # \u88ab\u5339\u914d\u5230\u7684\u5411\u91cf\u5f52\u4e3a\u524d\u666f\uff0c\u5e76\u4e14\u8d4b\u503c\u524d\u666f\u7c7b\u522b\n        for i, match_index in enumerate(match_indexs):\n            target_labels[i, match_index] = target_logits[i]\n\n        class_loss = F.cross_entropy(pred_logits.flatten(0, 1), target_labels.flatten(0, 1), cost_no_obj)\n        return class_loss\n\n    def focal_loss(self, predict, target, gamma=2.0, alpha=0.25):\n        # predict : b * n_queries, h * w\n        # target : b * n_obj, h * w\n        ce = F.binary_cross_entropy_with_logits(predict, target, reduction='none')\n\n        p_t = predict * target + (1 - predict) * (1 - target)\n        focal_cost = ce * ((1 - p_t) ** gamma)\n\n        alpha_t = alpha * target + (1 - alpha) * (1 - target)\n        focal_loss = alpha_t * focal_cost\n        return focal_loss.mean()\n\n    def dice_loss(self, predict, target):\n        numerator = 2 * (predict * target).sum(-1)\n        denominator = predict.sum(-1) + target.sum(-1)\n        loss_dice = 1 - (numerator + 1) / (denominator + 1)\n        return loss_dice.mean()\n\n    def forward(self, out, targets, match_indexs):\n        pred_logits = out[\"pred_logits\"]  # b, n, class + 1\n        pred_boxes = out[\"pred_masks\"]  # b, n, h, w\n        target_logits = targets[\"labels\"]  # [ m_i for i in b]\n        target_boxes = targets[\"masks\"]  # [ m_i, h, w for i in b]\n\n        tgt_mask = torch.cat([v for v in target_boxes]).flatten(1, 2)  # [batch_size * num_obj, h * w]\n        out_mask = pred_boxes.flatten(2)  # [batch_size, num_queries, h * w]\n        # \u7b5b\u9009\u88ab\u5339\u914d\u5230\u7684\u9884\u6d4b\u6570\u636e\n        out_mask = torch.cat([out_mask[i, match_index, :] for i, match_index in\n                              enumerate(match_indexs)])  # [batch_size * num_obj, h * w]\n        # \u8ba1\u7b97\u5206\u7c7b\u635f\u5931\uff0c\u672a\u88ab\u5339\u914d\u5230\u7684\u6570\u636e\u7edf\u4e00\u5212\u5206\u4e3a\u2205\u7c7b\u522b\n        class_loss = self.class_loss(pred_logits, target_logits, match_indexs) * self.w_class\n        focal_loss = self.focal_loss(out_mask, tgt_mask) * self.w_focal\n        dice_loss = self.dice_loss(out_mask, tgt_mask) * self.w_dice\n\n        return class_loss + focal_loss + dice_loss\n</code></pre>"},{"location":"transformer/Maskformer/#_8","title":"\u63a8\u7406\u8fc7\u7a0b","text":"<pre><code>def semantic_inference(self, mask_cls, mask_pred):\n    # mask_cls = F.softmax(mask_cls, dim=-1)[..., :-1]\n    # \u5220\u6389\u7b2c\u4e00\u4e2a\u7c7b\u522b\uff0c\u548c\u5b98\u65b9\u7ed9\u7684\u6e90\u7801\u4e0d\u592a\u4e00\u6837\uff0c\u4f46\u662f\u90fd\u8868\u793a\u5220\u9664\u2205\u7c7b\u522b\n    mask_cls = F.softmax(mask_cls, dim=-1)[..., 1:]\n    mask_pred = mask_pred.sigmoid()\n    # semseg\u5c3a\u5bf8\u4e3a[num_classes, h, w]\n    semseg = torch.einsum(\"bqc,bqhw-&gt;bchw\", mask_cls, mask_pred)\n    # \u540e\u7eed\u518d\u6cbf\u901a\u9053\u65b9\u5411\u9009\u53d6\u6570\u503c\u6700\u5927\u7684\u7d22\u5f15\uff0c\u5f53\u505a\u7c7b\u522b\u5e8f\u53f7\n    return semseg\n\ndef panoptic_inference(self, mask_cls, mask_pred):\n    mask_cls = torch.randn_like(mask_cls)\n    scores, labels = F.softmax(mask_cls, dim=-1).max(-1)\n    mask_pred = mask_pred.sigmoid()\n    # # \u628a\u6700\u540e\u4e00\u4e2a\u7c7b\u522b\u5e8f\u53f7\u5f53\u505a\u7a7a\u7c7b\u522b\n    # keep = labels.ne(self.num_classes) &amp; (scores &gt; self.object_mask_threshold)\n    # \u7b2c\u4e00\u4e2a\u5e8f\u53f7\u5f53\u505a\u7a7a\u7c7b\u522b\uff0c\u5220\u6389\u7a7a\u7c7b\u522b\u3002\u5e76\u4e14\u5220\u53bb\u7c7b\u522b\u5206\u6570\u6700\u5927\u503c\u8fd8\u5c0f\u4e8eobject_mask_threshold\u7684\u63a9\u6a21\n    keep = labels.ne(0) &amp; (scores &gt; self.object_mask_threshold)\n    cur_scores = scores[keep]\n    cur_classes = labels[keep]\n    cur_masks = mask_pred[keep]\n    # \u7c7b\u522b\u5206\u6570\u4e0e\u4e8c\u503c\u63a9\u6a21\u5206\u6570\u76f8\u4e58\uff0c\u5f97\u5230\u7efc\u5408\u5206\u6570\n    cur_prob_masks = cur_scores.view(-1, 1, 1) * cur_masks\n\n    h, w = cur_masks.shape[-2:]\n    panoptic_seg = torch.zeros((h, w), dtype=torch.int32, device=cur_masks.device)\n    segments_info = []\n\n    current_segment_id = 0\n\n    if cur_masks.shape[0] == 0:\n        # We didn't detect any mask :(\n        return panoptic_seg, segments_info\n    else:\n        # \u6cbf\u901a\u9053\u65b9\u5411\uff08\u5373\u7c7b\u522b\u65b9\u5411\uff09\uff0c\u5f97\u5230\u6bcf\u4e2a\u4f4d\u7f6e\u4e0a\u7efc\u5408\u5206\u6570\u6700\u5927\u7684\u67e5\u8be2\u7d22\u5f15\n        # \u7528\u4e8e\u5224\u65ad\u8be5\u70b9\u4e0a\u7684100\u4e2a\u8f93\u51fa\u4e2d\uff0c\u54ea\u4e2a\u8f93\u51fa\u5c5e\u4e8e\u8be5\u70b9\n        cur_mask_ids = cur_prob_masks.argmax(0)\n        stuff_memory_list = {}\n        # \u6309\u7c7b\u522b\u975e\u7a7a\u7684\u63a9\u6a21\u56fe\u904d\u5386\uff0c\n        for k in range(cur_classes.shape[0]):\n            pred_class = cur_classes[k].item()\n            # isthing\u7528\u4e8e\u5224\u65ad\u7269\u4f53\u662f\u5426\u662f\u53ef\u6570\u76ee\u6807\uff0c\u82e5\u4e3aTrue\uff0c\u5219\u8bf4\u660e\u7269\u4f53\u53ef\u6570\u3002\u5982\u4f55\u5224\u65ad\uff1f\n            # isthing = pred_class in self.metadata.thing_dataset_id_to_contiguous_id.values()\n            isthing = pred_class in [i for i in range(self.num_classes)]\n            # \u5224\u65ad\u5f53\u524d\u63a9\u6a21\u56fe\u7684\u5e8f\u53f7\u662f\u5426\u7b49\u4e8e\u7efc\u5408\u5206\u6570\u6700\u5927\u503c\u65f6\u7684\u5bf9\u5e94\u7684\u8f93\u51fa\u5e8f\u53f7\n            mask = cur_mask_ids == k\n            # \u5e76\u4e14\u63d0\u53d6\u533a\u57df\u9762\u79ef\n            mask_area = mask.sum().item()\n            original_area = (cur_masks[k] &gt;= 0.5).sum().item()\n            # \u9762\u79ef\u5927\u4e8e\u96f6\uff0c\u8bf4\u660e\u5f53\u524d\u63a9\u6a21\u56fe\u5b58\u5728\u4e00\u4e9b\u70b9\u662f\u524d\u666f\n            if mask_area &gt; 0 and original_area &gt; 0:\n                # self.overlap_threshold\u7528\u4e8e\u9650\u5236\u4e00\u4e2a\u5b9e\u4f8b\u6700\u5c0f\u5360\u6bd4\u591a\u5c11\n                if mask_area / original_area &lt; self.overlap_threshold:\n                    continue\n\n                # \u4e0d\u53ef\u6570\u7684\u5206\u652f\uff0c\u5373\u80cc\u666f\u533a\u57df\uff08\u5982\u5929\u7a7a\u3001\u5730\u9762\uff09\n                if not isthing:\n                    if int(pred_class) in stuff_memory_list.keys():\n                        panoptic_seg[mask] = stuff_memory_list[int(pred_class)]\n                        continue\n                    else:\n                        stuff_memory_list[int(pred_class)] = current_segment_id + 1\n                # \u5982\u679c\u53ef\u6570\uff0c\u5219\u89c6\u4e3a\u524d\u666f\u533a\u57df\uff0c\u5b9e\u4f8b\u6570\u52a0\u4e00\n                current_segment_id += 1\n                panoptic_seg[mask] = current_segment_id\n\n                segments_info.append(\n                    {\n                        \"id\": current_segment_id,\n                        \"isthing\": bool(isthing),\n                        \"category_id\": int(pred_class),\n                    }\n                )\n\n        return panoptic_seg, segments_info\n</code></pre> <p>\u6ce8\uff1a\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u7b80\u4ecb\uff0c\u82e5\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u6307\u6b63</p> <p>\u521d\u6b65\u5b8c\u7a3f\u4e8e\uff1a2023\u5e745\u67081\u65e5</p>"},{"location":"transformer/Swin/","title":"Swin Transformer","text":""},{"location":"transformer/Swin/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aIEEE International Conference on Computer Vision, 2021 (ICCV, 2021)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttp://openaccess.thecvf.com//content/ICCV2021/papers/Liu_Swin_Transformer_Hierarchical_Vision_Transformer_Using_Shifted_Windows_ICCV_2021_paper.pdf</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/microsoft/Swin-Transformer</p>"},{"location":"transformer/Swin/#_2","title":"\u4ecb\u7ecd","text":"<p>\u2003\u2003ViT\u7b97\u6cd5\u6210\u529f\u5c06Transformer\u5e94\u7528\u5230\u4e86\u89c6\u89c9\u9886\u57df\uff0c\u4f46\u662f\u8fd8\u5b58\u5728\u4e24\u4e2a\u95ee\u9898\uff1a</p> <ul> <li>\u89c6\u89c9\u4e2d\u5e38\u5e38\u6d89\u53ca\u591a\u5c3a\u5ea6\u95ee\u9898\uff0c\u9700\u8981\u6a21\u578b\u53ef\u4ee5\u6355\u6349\u56fe\u50cf\u4e0a\u591a\u4e2a\u5c3a\u5ea6\u7684\u4fe1\u606f\uff08\u5982\u76ee\u6807\u68c0\u6d4b\u4e2d\u7684\u5927\u7269\u4f53\u548c\u5c0f\u7269\u4f53\uff09\uff0c\u800cViT\u7b97\u6cd5\u5c3a\u5ea6\u5355\u4e00\uff0c\u4e0e\u6700\u521dPatch\u7684\u5212\u5206\u65b9\u6cd5\u6709\u5173\uff0c\u56e0\u6b64ViT\u7b97\u6cd5\u6b20\u7f3a\u83b7\u53d6\u591a\u5c3a\u5ea6\u4fe1\u606f\u7684\u80fd\u529b\uff1b</li> <li>ViT\u7b97\u6cd5\u5728\u8ba1\u7b97\u6ce8\u610f\u529b\u65f6\uff0c\u662f\u5728\u5168\u5c40\u7684\u56fe\u50cf\u4f4d\u7f6e\u4e0a\u8ba1\u7b97\u6ce8\u610f\u529b\uff0c\u56e0\u6b64\u8ba1\u7b97\u590d\u6742\u5ea6\u8f83\u9ad8\uff0c\u8ba1\u7b97\u91cf\u968f\u56fe\u50cf\u5c3a\u5bf8\u7684\u589e\u52a0\u5448\u5e73\u65b9\u901f\u5ea6\u589e\u52a0\u3002</li> </ul> <p>\u2003\u2003\u5bf9\u6b64\uff0c\u672c\u6587\u4f5c\u8005\u501f\u9274\u4e86\u5377\u79ef\u7684\u601d\u60f3\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u5c42\u7ea7\u5f0f\u7684\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\uff0c\u53ef\u4ee5\u5728\u51cf\u5c0f\u8ba1\u7b97\u91cf\u7684\u540c\u65f6\u5b9e\u73b0\u63d0\u53d6\u591a\u5c3a\u5ea6\u7279\u5f81\u6570\u636e\u7684\u80fd\u529b\uff0c\u5177\u4f53\u5982\u4e0b\u56fe\u5de6\u4fa7\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u9996\u5148\uff0c\u5bf9\u4e8e\u51cf\u5c0f\u8ba1\u7b97\u91cf\uff0c\u4f5c\u8005\u5220\u53bb\u4e86ViT\u4e2d\u8ba1\u7b97\u5168\u5c40\u6ce8\u610f\u529b\u7684\u64cd\u4f5c\uff0c\u628a\u539f\u56fe\u5212\u5206\u4e3a\u4e0d\u540c\u7684patch\u7a97\u53e3\uff0c\u5728\u6bcf\u4e2a\u7a97\u53e3\u5185\u5355\u72ec\u8ba1\u7b97\u6ce8\u610f\u529b\uff0c\u8fd9\u6837\u4e5f\u968f\u4e4b\u5f15\u6765\u4e86\u4e00\u4e2a\u95ee\u9898\uff0c\u5728\u7a97\u53e3\u5185\u8ba1\u7b97\u6ce8\u610f\u529b\u7684\u8bdd\uff0c\u6bcf\u4e2a\u7279\u5f81\u6570\u636e\u7684\u5173\u6ce8\u533a\u57df\u5c31\u88ab\u9650\u5236\u5728\u4e00\u4e2a\u7a97\u53e3\u5185\u4e86\uff0c\u8fd9\u6837\u5c31\u5931\u53bb\u4e86Transformer\u53ef\u4ee5\u5bf9\u5168\u5c40\u5b9e\u73b0\u5efa\u6a21\u7684\u4f18\u52bf\uff0c\u5bf9\u6b64\u672c\u6587\u4f5c\u8005\u53c8\u8bbe\u8ba1\u4e86\u79fb\u52a8\u7a97\u53e3\u64cd\u4f5c\uff0c\u5177\u4f53\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u5bf9\u4e8e\u5f53\u524d\u5c42\uff0c\u6b63\u5e38\u5212\u5206\u7a97\u53e3\uff0c\u8ba1\u7b97\u6ce8\u610f\u529b\uff0c\u5bf9\u4e8e\u4e0b\u4e00\u5c42\uff08\u5373Layer l+1\uff09\uff0c\u5c06\u7528\u4e8e\u8ba1\u7b97\u6ce8\u610f\u529b\u7684\u7a97\u53e3\u5411\u5de6\u4e0a\u89d2\u5e73\u79fb\u4e00\u6bb5\u8ddd\u79bb\uff0c\u5b9e\u73b0\u9519\u4f4d\uff0c\u4e4b\u540e\u518d\u8ba1\u7b97\u6bcf\u4e2a\u7a97\u53e3\u5185\u7684\u6ce8\u610f\u529b\u3002\u8fd9\u79cd\u9519\u4f4d\u8ba1\u7b97\u6ce8\u610f\u529b\u7684\u64cd\u4f5c\u4e3a\u4e24\u5c42\u4e4b\u95f4\u7684\u7279\u5f81\u642d\u5efa\u4e86\u4e00\u4e2a\u6865\u6881\uff0c\u53ef\u4ee5\u5b9e\u73b0\u7a97\u53e3\u4e4b\u95f4\u7684\u8fde\u63a5\u3001\u7279\u5f81\u6570\u636e\u4e4b\u95f4\u7684\u901a\u4fe1\uff0c\u8fdb\u4e00\u6b65\u5b9e\u73b0\u5168\u5c40\u5efa\u6a21\u7684\u76ee\u7684\u3002</p>"},{"location":"transformer/Swin/#_3","title":"\u7f51\u7edc\u7ed3\u6784","text":"<p>\u2003\u2003\u7f51\u7edc\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u56fe\u50cf\u4f20\u5165Swin\u6a21\u5757\u4e4b\u524d\u5148\u7ecf\u8fc7\u5207\u5206\u64cd\u4f5c\uff0c\u5212\u5206\u62104\\times4\u7684patch\uff0c\u518d\u5c06\u6bcf\u4e2apatch\u4f20\u5165linear\u7f16\u7801\u5c42\uff0c\u5f97\u5230\u5c3a\u5bf8\u4e3aC\u7684\u7279\u5f81\uff0c\u6bcf\u4e2apatch\u89c6\u4e3a\u4e00\u4e2a\u7279\u5f81\u70b9\uff0c\u6700\u540e\u4f9d\u6b21\u4f20\u5165Swin Transformer\u6a21\u5757\u63d0\u53d6\u7279\u5f81\u3001patch\u5408\u5e76\u6a21\u5757\u5408\u5e76\u7279\u5f81\uff0c\u5b9e\u73b0\u4e0b\u91c7\u6837\u76ee\u7684\uff0c\u7279\u5f81\u6570\u636e\u6bcf\u7ecf\u8fc7\u4e00\u6b21\u5408\u5e76\uff0c\u5bbd\u9ad8\u53d8\u4e3a\u539f\u6765\u7684\u4e00\u534a\uff0c\u901a\u9053\u6570\u53d8\u4e3a\u539f\u6765\u7684\u4e24\u500d\u3002</p>"},{"location":"transformer/Swin/#swin_transformer_1","title":"Swin Transformer\u6a21\u5757","text":"<p>\u2003\u2003\u6a21\u5757\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003Swin Transformer\u6a21\u5757\u4ea4\u9519\u7ec4\u6210\uff0c\u4e3b\u8981\u533a\u522b\u4e3a\u591a\u5934\u6ce8\u610f\u529b\u7684\u8ba1\u7b97\u65b9\u5f0f\u4e0d\u540c\uff0c\u5148\u7ecf\u8fc7\u6b63\u5e38\u7684\u7a97\u53e3\u6ce8\u610f\u529b\u8ba1\u7b97\uff08W-MSA\uff09\uff0c\u4e4b\u540e\u518d\u7ecf\u8fc7\u57fa\u4e8e\u79fb\u52a8\u7a97\u53e3\u7684\u6ce8\u610f\u529b\u8ba1\u7b97\uff08SW-MSA\uff09\u3002</p> <p>\u2003\u2003\u7a97\u53e3\u5185\u505a\u6ce8\u610f\u529b\u548c\u5168\u5c40\u505a\u6ce8\u610f\u529b\u7684\u533a\u522b\uff0c\u8981\u505a\u597d\u533a\u5206\uff1a</p> <ul> <li> <p>\u7a97\u53e3\u5185\u505a\u81ea\u6ce8\u610f\u529b\uff1a\u5e8f\u5217\u957f\u5ea6\u662f\u56fa\u5b9a\u7684\uff0c\u4e3a\u7a97\u53e3\u7684\u9762\u79efM\\times M\uff0c\u56fe\u50cf\u88ab\u5206\u5272\u6210\u4e86\u4e0d\u540c\u7684\u7a97\u53e3\uff0c\u6bcf\u4e2a\u7a97\u53e3\u4f9d\u6b21\u505a\u81ea\u6ce8\u610f\u529b\u8fd0\u7b97\uff0c\u56e0\u6b64\u7a97\u53e3\u88ab\u5f52\u5230\u4e86batch\u7ef4\u5ea6\uff0c\u7a97\u53e3\u5185\u6bcf\u4e2a\u50cf\u7d20\u70b9\u88ab\u89c6\u4e3a\u5e8f\u5217\uff1b</p> </li> <li> <p>\u5168\u5c40\u505a\u6ce8\u610f\u529b\uff08\u7b97\u6cd5\uff09\uff1a\u4e5f\u662f\u5148\u5212\u5206\u7a97\u53e3\uff0c\u4e0d\u8fc7\u8fd9\u91cc\u7684\u7a97\u53e3\u88ab\u89c6\u4e3a\u5e8f\u5217\uff0c\u5e8f\u5217\u957f\u5ea6\u4e0e\u56fe\u50cf\u5927\u5c0f\u4ee5\u53ca\u7a97\u53e3\u5927\u5c0f\u6709\u5173\uff0c\u5728\u8ba1\u7b97\u6ce8\u610f\u529b\u65f6\u6240\u6709\u7684\u5e8f\u5217\u4f1a\u540c\u65f6\u4f20\u5165\u4e00\u4e2aTF\u6a21\u5757\uff0c\u7a97\u53e3\u88ab\u5f52\u5230\u4e86\u5e8f\u5217\u7ef4\u5ea6\u3002</p> </li> </ul> <p>\u200b       \u65f6\u95f4\u590d\u6742\u5ea6\uff1a $$ \\Omega(MSA)=4hwC^2+2(hw)^2C\\\\ \\Omega(W-MSA)=(4M^2C^2+2M^4C)\\times\\frac hM\\times\\frac wM \\\\ =4hwC^2+2M^2hwC $$  \u5176\u4e2d\uff0ch\u3001w\u3001C\u3001M\u4f9d\u6b21\u4ee3\u8868\u7279\u5f81\u56fe\u7684\u9ad8\u3001\u5bbd\u3001\u901a\u9053\u6570\uff08\u5373\u7279\u5f81\u7ef4\u5ea6\uff09\u4ee5\u53ca\u6bcf\u4e2a\u7a97\u53e3\u7684\u5927\u5c0f\u3002</p> <p>\u57fa\u4e8e\u79fb\u52a8\u7a97\u53e3\u7684\u6ce8\u610f\u529b\u8ba1\u7b97\uff08SW-MSA\uff09</p> <p>\u2003\u2003\u4e3a\u4e86\u8ba9\u7a97\u53e3\u4e4b\u95f4\u53ef\u4ee5\u4ea7\u751f\u4fe1\u606f\u4f20\u9012\uff0c\u8fdb\u4e00\u6b65\u5b9e\u73b0\u7279\u5f81\u7684\u5168\u5c40\u5efa\u6a21\uff0c\u4f5c\u8005\u5728\u6bcf\u6b21\u6267\u884c\u7a97\u53e3\u6ce8\u610f\u529b\u8fd0\u7b97\u4e4b\u540e\uff0c\u90fd\u4f1a\u5411\u5de6\u4fa7\u548c\u4e0a\u4fa7\u504f\u79fb\\lfloor \\frac hM \\rfloor\u4e2a\u50cf\u7d20\u70b9\u7684\u8ddd\u79bb\uff0c\u8fd9\u6837\u6709\u7684\u7279\u5f81\u5c31\u4f1a\u6539\u53d8\u81ea\u5df1\u7684\u7a97\u53e3\u5f52\u5c5e\uff0c\u518d\u505a\u6ce8\u610f\u529b\u8fd0\u7b97\u65f6\u5c31\u53ef\u4ee5\u548c\u65b0\u7a97\u53e3\u5185\u5176\u4ed6\u7684\u7279\u5f81\u50cf\u7d20\u5efa\u7acb\u8054\u7cfb\uff0c\u8fd9\u6837\u7ecf\u8fc7\u591a\u6b21\u4ea4\u9519\u8054\u7cfb\u4e4b\u540e\uff0c\u6a21\u578b\u5c31\u53ef\u4ee5\u5bf9\u5168\u5c40\u5efa\u6a21\uff0c\u6bcf\u4e2a\u50cf\u7d20\u70b9\u90fd\u53ef\u4ee5\u5173\u6ce8\u5168\u5c40\u4e0a\u7684\u4fe1\u606f\u3002</p> <p> <p></p> <p></p> <p>\u2003\u2003\u7b80\u5355\u7684\u5e73\u79fb\u64cd\u4f5c\u4f1a\u5e26\u6765\u5f88\u591a\u95ee\u9898\uff0c\u4ee5\u4e0a\u56fe\u4e3a\u4f8b\uff0c\u79fb\u52a8\u7a97\u53e3\u4e4b\u540e\uff0c\u521d\u59cb\u7684\u56db\u4e2a\u7a97\u53e3\u4f1a\u53d8\u4e3a\u4e5d\u4e2a\u7a97\u53e3\uff0c\u5982\u679c\u76f4\u63a5\u5728\u4e5d\u4e2a\u7a97\u53e3\u4e0a\u4f9d\u6b21\u505a\u6ce8\u610f\u529b\u8fd0\u7b97\u7684\u8bdd\uff0c\u8ba1\u7b97\u91cf\u4f1a\u5f88\u5927\uff0c\u56e0\u6b64\u4f5c\u8005\u91c7\u7528\u5faa\u73af\u79fb\u52a8\u7684\u64cd\u4f5c\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u5c06\u79fb\u9664\u5de6\u4e0a\u89d2\u7684\u533a\u57df\u8f6c\u5165\u53f3\u4e0b\u89d2\uff0c\u8fdb\u4e00\u6b65\u5408\u5e76\u6210\u56db\u4e2a\u7a97\u53e3\u533a\u57df\u3002</p> <p> <p></p> <p></p> <p>\u2003\u2003\u4f46\u968f\u4e4b\u53c8\u4f1a\u4ea7\u751f\u4e00\u4e2a\u95ee\u9898\uff0c\u5e73\u79fb\u4e4b\u540e\u4e0d\u76f8\u90bb\u7684\u533a\u57df\u4f1a\u88ab\u62fc\u63a5\u5230\u4e00\u4e2a\u7a97\u53e3\u5185\u90e8\uff0c\u6b64\u65f6\u5728\u7a97\u53e3\u5185\u505a\u6ce8\u610f\u529b\u8fd0\u7b97\u7684\u8bdd\u4f1a\u8ba9\u4e0d\u76f8\u90bb\u7684\u533a\u57df\u5efa\u7acb\u4e0d\u5fc5\u8981\u7684\u8054\u7cfb\uff0c\u6574\u4e2a\u6a21\u578b\u5bb9\u6613\u4ea7\u751f\u6f5c\u5728\u7684\u95ee\u9898\uff0c\u56e0\u6b64\u4f5c\u8005\u53c8\u52a0\u4e86\u4e00\u4e2a\u63a9\u6a21\u64cd\u4f5c\uff0c\u6291\u5236\u4e0d\u76f8\u90bb\u533a\u57df\u7684\u6ce8\u610f\u529b\u6743\u91cd\u3002</p> <p>\u2003\u2003\u6838\u5fc3\u601d\u60f3\u5c31\u662f\u627e\u51fa\u4e0d\u76f8\u90bb\u4f4d\u7f6e\u6240\u4ea7\u751f\u7684\u6ce8\u610f\u529b\u6743\u91cd\uff0c\u4e4b\u540e\u5728Softmax\u8fd0\u7b97\u4e4b\u524d\u52a0\u4e0a\u8db3\u591f\u5927\u7684\u8d1f\u6570\uff08\u5982\u4e0b\u56fe\u53f3\u4fa7\u6240\u793a\uff0c\u6e90\u7801\u4e2d\u4f7f\u7528-100\uff09\uff0c\u7ecf\u8fc7Softmax\u8fd0\u7b97\u4e4b\u540e\u6ce8\u610f\u529b\u6743\u91cd\u4f1a\u88ab\u8fd1\u4f3c\u5f52\u4e3a0\u3002</p> <p> <p></p> <p></p> <p>\u56fe\u7247\u5f15\u81ea\uff1ahttps://github.com/microsoft/Swin-Transformer/issues/38</p> <p>\u6ce8\uff1a\u63a9\u6a21\u751f\u6210\u7b56\u7565\u53ef\u53c2\u8003https://www.bilibili.com/video/BV13L4y1475U\uff0c42:53\u3002</p>"},{"location":"transformer/Swin/#patch","title":"patch\u5408\u5e76\u6a21\u5757","text":"<p>\u2003\u2003\u5927\u4f53\u6d41\u7a0b\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u9996\u5148\u5c06\u7279\u5f81\u56fe\u62c6\u5206\u6210\u56db\u7ec4\uff0c\u4e4b\u540e\u6cbf\u901a\u9053\u65b9\u5411\u5408\u5e76\uff0c\u518d\u4f9d\u6b21\u7ecf\u8fc7\u5f52\u4e00\u5316\u5c42\u30011\\times1\u7684\u5377\u79ef\u5c42\u505a\u7279\u5f81\u878d\u5408\uff0c\u5c06\u901a\u9053\u6570\u538b\u7f29\u4e3a\u539f\u6765\u7684\u4e00\u534a\u3002</p>"},{"location":"transformer/Swin/#_4","title":"\u6a21\u578b\u89c4\u683c","text":"<ul> <li>Swin-T\uff1aC=96\uff0clayer\\quad numbers=\\{2,2,6,2\\}</li> <li>Swin-S\uff1aC=96\uff0clayer\\quad numbers=\\{2,2,18,2\\}</li> <li>Swin-B\uff1aC=128\uff0clayer\\quad numbers=\\{2,2,18,2\\}</li> <li>Swin-L\uff1aC=192\uff0clayer\\quad numbers=\\{2,2,18,2\\}</li> </ul> <p>\u5176\u4e2d\uff0c\u6a21\u578b\u5927\u5c0f\u6bd4\u4f8bT:S:B:L=0.25:0.5:1:2\uff0cSwin-T\u548cSwin-S\u7684\u590d\u6742\u5ea6\u7c7b\u4f3c\u4e8eResNet50\u548cResNet101\uff0c\u7a97\u53e3\u5927\u5c0fM\u9ed8\u8ba4\u4e3a7\uff0c\u6bcf\u4e2a\u5934\u67e5\u8be2\u5411\u91cf\u7684\u7ef4\u5ea6d\u9ed8\u8ba4\u4e3a32\uff08\u7ecf\u8fc7linear\u6620\u5c04\u540e\uff0ckqv\u7684\u7ef4\u6570\u5747\u4e3a32\uff09\uff0c\u6bcf\u4e2aMLP\u7684\\alpha\u9ed8\u8ba4\u4e3a4\uff08\u7279\u5f81\u7ef4\u6570m\\rightarrow\\alpha m\\rightarrow m\uff09\u3002</p> <p>\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u6307\u6b63\u3002</p>"},{"location":"transformer/Swin/#_5","title":"\u4ee3\u7801\u5b9e\u73b0","text":"<p>\u53c2\u8003\u94fe\u63a5\uff1a</p> <ul> <li>https://github.com/WZMIAOMIAO/deep-learning-for-image-processing</li> </ul>"},{"location":"transformer/Swin/#_6","title":"\u7f51\u7edc\u7ed3\u6784","text":"<pre><code>class SwinTransformer(nn.Module):\n    r\"\"\" Swin Transformer\n        A PyTorch impl of : `Swin Transformer: Hierarchical Vision Transformer using Shifted Windows`  -\n          https://arxiv.org/pdf/2103.14030\n\n    Args:\n        patch_size (int | tuple(int)): Patch size. Default: 4\n        in_chans (int): Number of input image channels. Default: 3\n        num_classes (int): Number of classes for classification head. Default: 1000\n        embed_dim (int): Patch embedding dimension. Default: 96\n        depths (tuple(int)): Depth of each Swin Transformer layer.\n        num_heads (tuple(int)): Number of attention heads in different layers.\n        window_size (int): Window size. Default: 7\n        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim. Default: 4\n        qkv_bias (bool): If True, add a learnable bias to query, key, value. Default: True\n        drop_rate (float): Dropout rate. Default: 0\n        attn_drop_rate (float): Attention dropout rate. Default: 0\n        drop_path_rate (float): Stochastic depth rate. Default: 0.1\n        norm_layer (nn.Module): Normalization layer. Default: nn.LayerNorm.\n        patch_norm (bool): If True, add normalization after patch embedding. Default: True\n        use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False\n    \"\"\"\n\n    def __init__(self, patch_size=4, in_chans=3, num_classes=1000,\n                 embed_dim=96, depths=(2, 2, 6, 2), num_heads=(3, 6, 12, 24),\n                 window_size=7, mlp_ratio=4., qkv_bias=True,\n                 drop_rate=0., attn_drop_rate=0., drop_path_rate=0.1,\n                 norm_layer=nn.LayerNorm, patch_norm=True,\n                 use_checkpoint=False, **kwargs):\n        super().__init__()\n\n        self.num_classes = num_classes\n        self.num_layers = len(depths)\n        self.embed_dim = embed_dim\n        self.patch_norm = patch_norm\n        # stage4\u8f93\u51fa\u7279\u5f81\u77e9\u9635\u7684channels\n        self.num_features = int(embed_dim * 2 ** (self.num_layers - 1))\n        self.mlp_ratio = mlp_ratio\n\n        # split image into non-overlapping patches\n        self.patch_embed = PatchEmbed(\n            patch_size=patch_size, in_c=in_chans, embed_dim=embed_dim,\n            norm_layer=norm_layer if self.patch_norm else None)\n        self.pos_drop = nn.Dropout(p=drop_rate)\n\n        # stochastic depth\n        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]  # stochastic depth decay rule\n\n        # build layers\n        self.layers = nn.ModuleList()\n        for i_layer in range(self.num_layers):\n            # \u6ce8\u610f\u8fd9\u91cc\u6784\u5efa\u7684stage\u548c\u8bba\u6587\u56fe\u4e2d\u6709\u4e9b\u5dee\u5f02\n            # \u8fd9\u91cc\u7684stage\u4e0d\u5305\u542b\u8be5stage\u7684patch_merging\u5c42\uff0c\u5305\u542b\u7684\u662f\u4e0b\u4e2astage\u7684\n            layers = BasicLayer(dim=int(embed_dim * 2 ** i_layer),\n                                depth=depths[i_layer],\n                                num_heads=num_heads[i_layer],\n                                window_size=window_size,\n                                mlp_ratio=self.mlp_ratio,\n                                qkv_bias=qkv_bias,\n                                drop=drop_rate,\n                                attn_drop=attn_drop_rate,\n                                drop_path=dpr[sum(depths[:i_layer]):sum(depths[:i_layer + 1])],\n                                norm_layer=norm_layer,\n                                downsample=PatchMerging if (i_layer &lt; self.num_layers - 1) else None,\n                                use_checkpoint=use_checkpoint)\n            self.layers.append(layers)\n\n        self.norm = norm_layer(self.num_features)\n        self.avgpool = nn.AdaptiveAvgPool1d(1)\n        self.head = nn.Linear(self.num_features, num_classes) if num_classes &gt; 0 else nn.Identity()\n\n        self.apply(self._init_weights)\n\n    def _init_weights(self, m):\n        if isinstance(m, nn.Linear):\n            nn.init.trunc_normal_(m.weight, std=.02)\n            if isinstance(m, nn.Linear) and m.bias is not None:\n                nn.init.constant_(m.bias, 0)\n        elif isinstance(m, nn.LayerNorm):\n            nn.init.constant_(m.bias, 0)\n            nn.init.constant_(m.weight, 1.0)\n\n    def forward(self, x):\n        # x: [B, L, C]\n        # patch_embed\u540c\u65f6\u5305\u542b\u4e86\u5207\u7247\u548c\u7ebf\u6027\u56de\u5f52\u64cd\u4f5c\n        x, H, W = self.patch_embed(x)\n        x = self.pos_drop(x)\n        # \u9010\u6b21\u7ecf\u8fc7\u56db\u4e2a\u9636\u6bb5\uff0c\u5bf9\u5e94\u8bba\u6587\u4e2d\u7684stage1-4\uff0c\u6bcf\u7ecf\u8fc7\u4e00\u4e2a\u9636\u6bb5\u7279\u5f81\u5c3a\u5bf8\u51cf\u534a\uff0c\u901a\u9053\u53d8\u4e3a\u4e24\u500d\n        for layer in self.layers:\n            # \u8f93\u51fa\u7684x\u5373\u4e3a\u63d0\u53d6\u7684\u7279\u5f81\n            x, H, W = layer(x, H, W)\n        # \u4e0b\u9762\u518d\u505a\u6c60\u5316\u3001linear\u7ebf\u6027\u56de\u5f52\uff0c\u5f97\u5230\u7c7b\u522b\u5206\u6570\n        x = self.norm(x)  # [B, L, C]\n        x = self.avgpool(x.transpose(1, 2))  # [B, C, 1]\n        x = torch.flatten(x, 1)\n        x = self.head(x)\n        return x\n</code></pre>"},{"location":"transformer/Swin/#_7","title":"\u8f93\u5165\u5c42","text":"<p>\u2003\u2003\u5148\u5207\u7247\uff0c\u518d\u4f20\u5165\u7ebf\u6027\u56de\u5f52\uff0c\u53ef\u7531\u4e00\u5c42\u5377\u79ef\u5b8c\u6210</p> <pre><code>class PatchEmbed(nn.Module):\n    \"\"\"\n    2D Image to Patch Embedding\n    \u5b9a\u4e49\u7f51\u7edc\u521d\u59cb\u7684patch partition\uff0c\u7528\u4e8e\u4e0b\u91c7\u6837\n    \"\"\"\n    def __init__(self, patch_size=4, in_c=3, embed_dim=96, norm_layer=None):\n        super().__init__()\n        patch_size = (patch_size, patch_size)\n        self.patch_size = patch_size\n        self.in_chans = in_c\n        self.embed_dim = embed_dim\n        # \u9ed8\u8ba4\u4e0b\u91c7\u68374\u500d\uff0c\u5373patch_size\u9ed8\u8ba44\n        self.proj = nn.Conv2d(in_c, embed_dim, kernel_size=patch_size, stride=patch_size)\n        self.norm = norm_layer(embed_dim) if norm_layer else nn.Identity()\n\n    def forward(self, x):\n        _, _, H, W = x.shape\n\n        # padding\n        # \u5982\u679c\u8f93\u5165\u56fe\u7247\u7684H\uff0cW\u4e0d\u662fpatch_size\u7684\u6574\u6570\u500d\uff0c\u9700\u8981\u8fdb\u884cpadding\n        pad_input = (H % self.patch_size[0] != 0) or (W % self.patch_size[1] != 0)\n        if pad_input:\n            # to pad the last 3 dimensions,\n            # (W_left, W_right, H_top,H_bottom, C_front, C_back)\n            x = F.pad(x, (0, self.patch_size[1] - W % self.patch_size[1],\n                          0, self.patch_size[0] - H % self.patch_size[0],\n                          0, 0))\n\n        # \u4e0b\u91c7\u6837patch_size\u500d\n        x = self.proj(x)\n        _, _, H, W = x.shape\n        # flatten: [B, C, H, W] -&gt; [B, C, HW]\n        # transpose: [B, C, HW] -&gt; [B, HW, C]\n        x = x.flatten(2).transpose(1, 2)\n        x = self.norm(x)\n        return x, H, W\n</code></pre>"},{"location":"transformer/Swin/#swin","title":"Swin\u6a21\u5757","text":"<pre><code>class SwinTransformerBlock(nn.Module):\n    r\"\"\" Swin Transformer Block.\n\n    Args:\n        dim (int): Number of input channels.\n        num_heads (int): Number of attention heads.\n        window_size (int): Window size.\n        shift_size (int): Shift size for SW-MSA.\n        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.\n        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True\n        drop (float, optional): Dropout rate. Default: 0.0\n        attn_drop (float, optional): Attention dropout rate. Default: 0.0\n        drop_path (float, optional): Stochastic depth rate. Default: 0.0\n        act_layer (nn.Module, optional): Activation layer. Default: nn.GELU\n        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm\n    \"\"\"\n\n    def __init__(self, dim, num_heads, window_size=7, shift_size=0,\n                 mlp_ratio=4., qkv_bias=True, drop=0., attn_drop=0., drop_path=0.,\n                 act_layer=nn.GELU, norm_layer=nn.LayerNorm):\n        super().__init__()\n        self.dim = dim\n        self.num_heads = num_heads\n        self.window_size = window_size\n        self.shift_size = shift_size\n        self.mlp_ratio = mlp_ratio\n        assert 0 &lt;= self.shift_size &lt; self.window_size, \"shift_size must in 0-window_size\"\n\n        self.norm1 = norm_layer(dim)\n        self.attn = WindowAttention(\n            dim, window_size=(self.window_size, self.window_size), num_heads=num_heads, qkv_bias=qkv_bias,\n            attn_drop=attn_drop, proj_drop=drop)\n\n        self.drop_path = DropPath(drop_path) if drop_path &gt; 0. else nn.Identity()\n        self.norm2 = norm_layer(dim)\n        mlp_hidden_dim = int(dim * mlp_ratio)\n        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n\n    def forward(self, x, attn_mask):\n        H, W = self.H, self.W\n        B, L, C = x.shape\n        assert L == H * W, \"input feature has wrong size\"\n\n        shortcut = x\n        x = self.norm1(x)\n        x = x.view(B, H, W, C)\n\n        # pad feature maps to multiples of window size\n        # \u628afeature map\u7ed9pad\u5230window size\u7684\u6574\u6570\u500d\n        pad_l = pad_t = 0\n        pad_r = (self.window_size - W % self.window_size) % self.window_size\n        pad_b = (self.window_size - H % self.window_size) % self.window_size\n        x = F.pad(x, (0, 0, pad_l, pad_r, pad_t, pad_b))\n        _, Hp, Wp, _ = x.shape\n\n        # cyclic shift\n        # self.shift_size\u8868\u793a\u9700\u8981\u5e73\u79fb\u591a\u5c11\uff0c\u5947\u6570\u7684block\u9700\u8981\u5e73\u79fb\n        if self.shift_size &gt; 0:\n            shifted_x = torch.roll(x, shifts=(-self.shift_size, -self.shift_size), dims=(1, 2))\n        else:\n            # \u5982\u679c\u4e0d\u9700\u8981\u5e73\u79fb\uff0c\u5219\u8ba1\u7b97\u6ce8\u610f\u529b\u65f6\u4e5f\u5c31\u4e0d\u9700\u8981\u63a9\u6a21\u64cd\u4f5c\u4e86\n            shifted_x = x\n            attn_mask = None\n\n        # partition windows\uff0c\u628a\u7279\u5f81\u56fe\u5207\u5206\u6210\u7247\uff0c\u5c3a\u5bf8\u53d8\u4e3a[nW*B, Mh, Mw, C]\n        x_windows = window_partition(shifted_x, self.window_size)\n        # x_windows\u5c3a\u5bf8\u4e3a[nW*B, Mh*Mw, C]\n        x_windows = x_windows.view(-1, self.window_size * self.window_size, C)\n\n        # W-MSA/SW-MSA\n        # attn_windows\u5c3a\u5bf8\u4e3a[nW*B, Mh*Mw, C]\n        attn_windows = self.attn(x_windows, mask=attn_mask)\n\n        # \u5c06\u5207\u5206\u7684\u7247\u518d\u5408\u5e76\uff0c\u5148\u5c06\u62c9\u76f4\u7684\u7279\u5f81\u53d8\u4e3apatch\u7684\u5f62\u5f0f\uff0c\u5c3a\u5bf8\u53d8\u4e3a [nW*B, Mh, Mw, C]\n        attn_windows = attn_windows.view(-1, self.window_size, self.window_size, C)\n        # \u4e4b\u540e\u518d\u5c06patch\u5408\u5e76\uff0c\u53d8\u4e3a\u7279\u5f81\u56fe\uff0c\u5c3a\u5bf8\u53d8\u4e3a[B, H', W', C]\n        shifted_x = window_reverse(attn_windows, self.window_size, Hp, Wp)\n\n        # reverse cyclic shift\n        # \u5982\u679c\u524d\u9762\u5e73\u79fb\u4e86\uff0c\u8fd9\u91cc\u9700\u8981\u518d\u79fb\u56de\u6765\n        if self.shift_size &gt; 0:\n            x = torch.roll(shifted_x, shifts=(self.shift_size, self.shift_size), dims=(1, 2))\n        else:\n            x = shifted_x\n\n        if pad_r &gt; 0 or pad_b &gt; 0:\n            # \u628a\u524d\u9762pad\u7684\u6570\u636e\u79fb\u9664\u6389\n            x = x[:, :H, :W, :].contiguous()\n\n        x = x.view(B, H * W, C)\n\n        # FFN\n        x = shortcut + self.drop_path(x)\n        x = x + self.drop_path(self.mlp(self.norm2(x)))\n\n        return x\n</code></pre>"},{"location":"transformer/Swin/#_8","title":"\u57fa\u7840\u6a21\u5757","text":"<pre><code>class BasicLayer(nn.Module):\n    \"\"\"\n    A basic Swin Transformer layer for one stage.\n\n    Args:\n        dim (int): Number of input channels.\n        depth (int): Number of blocks.\n        num_heads (int): Number of attention heads.\n        window_size (int): Local window size.\n        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.\n        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True\n        drop (float, optional): Dropout rate. Default: 0.0\n        attn_drop (float, optional): Attention dropout rate. Default: 0.0\n        drop_path (float | tuple[float], optional): Stochastic depth rate. Default: 0.0\n        norm_layer (nn.Module, optional): Normalization layer. Default: nn.LayerNorm\n        downsample (nn.Module | None, optional): Downsample layer at the end of the layer. Default: None\n        use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False.\n    \"\"\"\n\n    def __init__(self, dim, depth, num_heads, window_size,\n                 mlp_ratio=4., qkv_bias=True, drop=0., attn_drop=0.,\n                 drop_path=0., norm_layer=nn.LayerNorm, downsample=None, use_checkpoint=False):\n        super().__init__()\n        self.dim = dim\n        self.depth = depth\n        self.window_size = window_size\n        self.use_checkpoint = use_checkpoint\n        self.shift_size = window_size // 2\n\n        # build blocks\n        self.blocks = nn.ModuleList([\n            SwinTransformerBlock(\n                dim=dim,\n                num_heads=num_heads,\n                window_size=window_size,\n                shift_size=0 if (i % 2 == 0) else self.shift_size,\n                mlp_ratio=mlp_ratio,\n                qkv_bias=qkv_bias,\n                drop=drop,\n                attn_drop=attn_drop,\n                drop_path=drop_path[i] if isinstance(drop_path, list) else drop_path,\n                norm_layer=norm_layer)\n            for i in range(depth)])\n\n        # patch merging layer\n        if downsample is not None:\n            self.downsample = downsample(dim=dim, norm_layer=norm_layer)\n        else:\n            self.downsample = None\n\n    def forward(self, x, H, W):\n        # \u521b\u9020\u5faa\u73af\u79fb\u4f4d\u6240\u9700\u8981\u7684\u63a9\u7801\n        attn_mask = self.create_mask(x, H, W)  # [nW, Mh*Mw, Mh*Mw]\n        for blk in self.blocks:\n            blk.H, blk.W = H, W\n            if not torch.jit.is_scripting() and self.use_checkpoint:\n                x = checkpoint.checkpoint(blk, x, attn_mask)\n            else:\n                x = blk(x, attn_mask)\n        if self.downsample is not None:\n            # \u6267\u884c\u4e0b\u91c7\u6837\u64cd\u4f5c\uff0c\u7279\u5f81\u56fe\u5c3a\u5bf8\u51cf\u534a\uff0c\u901a\u9053\u6570\u53d8\u4e3a\u539f\u6765\u4e24\u500d\n            x = self.downsample(x, H, W)\n            H, W = (H + 1) // 2, (W + 1) // 2\n\n        return x, H, W\n</code></pre>"},{"location":"transformer/Swin/#msa","title":"\u521b\u5efaMSA\u63a9\u7801","text":"<p>\u53c2\u8003\uff1ahttps://www.bilibili.com/video/BV1yg411K7Yc</p> <pre><code>def create_mask(self, x, H, W):\n    # calculate attention mask for SW-MSA\n    # \u4fdd\u8bc1Hp\u548cWp\u662fwindow_size\u7684\u6574\u6570\u500d\uff0cwindow_size\u4e3a\u6bcf\u4e2a\u5c0f\u7a97\u53e3\u7684\u5927\u5c0f\uff0c\u5728\u5c0f\u7a97\u53e3\u5185\u505a\u6ce8\u610f\u529b\n    Hp = int(np.ceil(H / self.window_size)) * self.window_size\n    Wp = int(np.ceil(W / self.window_size)) * self.window_size\n    # \u62e5\u6709\u548cfeature map\u4e00\u6837\u7684\u901a\u9053\u6392\u5217\u987a\u5e8f\uff0c\u65b9\u4fbf\u540e\u7eedwindow_partition\n    img_mask = torch.zeros((1, Hp, Wp, 1), device=x.device)  # [1, Hp, Wp, 1]\n    h_slices = (slice(0, -self.window_size),\n                slice(-self.window_size, -self.shift_size),\n                slice(-self.shift_size, None))\n    w_slices = (slice(0, -self.window_size),\n                slice(-self.window_size, -self.shift_size),\n                slice(-self.shift_size, None))\n    cnt = 0\n    for h in h_slices:\n        for w in w_slices:\n            # img_mask\u7528\u4e8e\u4e3a\u6bcf\u4e2a\u4f4d\u7f6e\u6253\u4e0a\u533a\u57df\u6807\u7b7e\uff0c\u5e8f\u53f7\u4e3a0-8\n            img_mask[:, h, w, :] = cnt\n            cnt += 1\n    # img_mask\u5c3a\u5bf8\u4e3a[56,56,1]\n    # mask_windows\u5c3a\u5bf8\u4e3a[64, 7, 7, 1]\n    mask_windows = window_partition(img_mask, self.window_size)  # [nW, Mh, Mw, 1]\n    # \u4e4b\u540e\u518d\u62c9\u76f4\u7a97\u53e3\uff0c\u53d8\u4e3a[64,49]\n    mask_windows = mask_windows.view(-1, self.window_size * self.window_size)  # [nW, Mh*Mw]\n    # \u9010\u4f4d\u505a\u5dee\uff0c\u7ed3\u679c\u4e3a0\u7684\u4f4d\u7f6e\u4e3a\u76f8\u90bb\u4f4d\u7f6e\uff0c\u9700\u8981\u8ba1\u7b97\u6ce8\u610f\u529b\uff0c\u5bf9\u5e94\u7684\u63a9\u6a21\u6570\u636e\u5e94\u4e3a0\n    # \u53ef\u53c2\u8003:https://www.bilibili.com/video/BV1yg411K7Yc\n    attn_mask = mask_windows.unsqueeze(1) - mask_windows.unsqueeze(2)  # [nW, 1, Mh*Mw] - [nW, Mh*Mw, 1]\n    # [nW, Mh*Mw, Mh*Mw]\n    # \u5236\u4f5c\u63a9\u6a21\uff0c\u9700\u8981\u8ba1\u7b97\u6ce8\u610f\u529b\u7684\u4f4d\u7f6e\uff0c\u5bf9\u5e94\u6570\u636e\u4e3a0\uff0c\u4e0d\u9700\u8981\u8ba1\u7b97\u6ce8\u610f\u529b\u7684\u4f4d\u7f6e\uff0c\u5bf9\u5e94\u6570\u636e\u4e3a-100\uff08\u7ecf\u8fc7softmax\u4e4b\u540e\uff0c\u6ce8\u610f\u529b\u6743\u91cd\u7ea6\u7b49\u4e8e0\uff09\n    attn_mask = attn_mask.masked_fill(attn_mask != 0, float(-100.0)).masked_fill(attn_mask == 0, float(0.0))\n    return attn_mask\n</code></pre>"},{"location":"transformer/Swin/#_9","title":"\u7a97\u53e3\u6ce8\u610f\u529b\u6a21\u5757","text":"<pre><code>class WindowAttention(nn.Module):\n    r\"\"\" Window based multi-head self attention (W-MSA) module with relative position bias.\n    It supports both of shifted and non-shifted window.\n\n    Args:\n        dim (int): Number of input channels.\n        window_size (tuple[int]): The height and width of the window.\n        num_heads (int): Number of attention heads.\n        qkv_bias (bool, optional):  If True, add a learnable bias to query, key, value. Default: True\n        attn_drop (float, optional): Dropout ratio of attention weight. Default: 0.0\n        proj_drop (float, optional): Dropout ratio of output. Default: 0.0\n    \"\"\"\n\n    def __init__(self, dim, window_size, num_heads, qkv_bias=True, attn_drop=0., proj_drop=0.):\n\n        super().__init__()\n        self.dim = dim\n        self.window_size = window_size  # [Mh, Mw]\n        self.num_heads = num_heads\n        head_dim = dim // num_heads\n        self.scale = head_dim ** -0.5\n\n        # define a parameter table of relative position bias\n        # \u521b\u5efa\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\n        self.relative_position_bias_table = nn.Parameter(\n            torch.zeros((2 * window_size[0] - 1) * (2 * window_size[1] - 1), num_heads))  # [2*Mh-1 * 2*Mw-1, nH]\n\n        # get pair-wise relative position index for each token inside the window\n        coords_h = torch.arange(self.window_size[0])\n        coords_w = torch.arange(self.window_size[1])\n        coords = torch.stack(torch.meshgrid([coords_h, coords_w], indexing=\"ij\"))  # [2, Mh, Mw]\n        coords_flatten = torch.flatten(coords, 1)  # [2, Mh*Mw]\n        # [2, Mh*Mw, 1] - [2, 1, Mh*Mw]\n        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]  # [2, Mh*Mw, Mh*Mw]\n        relative_coords = relative_coords.permute(1, 2, 0).contiguous()  # [Mh*Mw, Mh*Mw, 2]\n        relative_coords[:, :, 0] += self.window_size[0] - 1  # shift to start from 0\n        relative_coords[:, :, 1] += self.window_size[1] - 1\n        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n        relative_position_index = relative_coords.sum(-1)  # [Mh*Mw, Mh*Mw]\n        self.register_buffer(\"relative_position_index\", relative_position_index)\n\n        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n        self.attn_drop = nn.Dropout(attn_drop)\n        self.proj = nn.Linear(dim, dim)\n        self.proj_drop = nn.Dropout(proj_drop)\n\n        nn.init.trunc_normal_(self.relative_position_bias_table, std=.02)\n        self.softmax = nn.Softmax(dim=-1)\n\n    def forward(self, x, mask: Optional[torch.Tensor] = None):\n        \"\"\"\n        Args:\n            x: input features with shape of (num_windows*B, Mh*Mw, C)\n            mask: (0/-inf) mask with shape of (num_windows, Wh*Ww, Wh*Ww) or None\n        \"\"\"\n        # [batch_size*num_windows, Mh*Mw, total_embed_dim]\n        B_, N, C = x.shape\n        # qkv(): -&gt; [batch_size*num_windows, Mh*Mw, 3 * total_embed_dim]\n        # reshape: -&gt; [batch_size*num_windows, Mh*Mw, 3, num_heads, embed_dim_per_head]\n        # permute: -&gt; [3, batch_size*num_windows, num_heads, Mh*Mw, embed_dim_per_head]\n        qkv = self.qkv(x).reshape(B_, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n        # [batch_size*num_windows, num_heads, Mh*Mw, embed_dim_per_head]\n        q, k, v = qkv.unbind(0)  # make torchscript happy (cannot use tensor as tuple)\n\n        # transpose: -&gt; [batch_size*num_windows, num_heads, embed_dim_per_head, Mh*Mw]\n        # @: multiply -&gt; [batch_size*num_windows, num_heads, Mh*Mw, Mh*Mw]\n        q = q * self.scale\n        attn = (q @ k.transpose(-2, -1))\n\n        # relative_position_bias_table.view: [Mh*Mw*Mh*Mw,nH] -&gt; [Mh*Mw,Mh*Mw,nH]\n        relative_position_bias = self.relative_position_bias_table[self.relative_position_index.view(-1)].view(\n            self.window_size[0] * self.window_size[1], self.window_size[0] * self.window_size[1], -1)\n        relative_position_bias = relative_position_bias.permute(2, 0, 1).contiguous()  # [nH, Mh*Mw, Mh*Mw]\n        attn = attn + relative_position_bias.unsqueeze(0)\n        # \u5982\u679c\u505a\u4e86\u5e73\u79fb\uff0c\u5219\u9700\u8981\u5229\u7528mask\u63a9\u6a21\u6765\u5f52\u96f6\u90e8\u5206\u4e0d\u76f8\u90bb\u7684\u6ce8\u610f\u529b\n        if mask is not None:\n            # mask: [nW, Mh*Mw, Mh*Mw]\n            nW = mask.shape[0]  # num_windows\n            # attn.view: [batch_size, num_windows, num_heads, Mh*Mw, Mh*Mw]\n            # mask.unsqueeze: [1, nW, 1, Mh*Mw, Mh*Mw]\n            attn = attn.view(B_ // nW, nW, self.num_heads, N, N) + mask.unsqueeze(1).unsqueeze(0)\n            attn = attn.view(-1, self.num_heads, N, N)\n            attn = self.softmax(attn)\n        else:\n            attn = self.softmax(attn)\n\n        attn = self.attn_drop(attn)\n\n        # @: multiply -&gt; [batch_size*num_windows, num_heads, Mh*Mw, embed_dim_per_head]\n        # transpose: -&gt; [batch_size*num_windows, Mh*Mw, num_heads, embed_dim_per_head]\n        # reshape: -&gt; [batch_size*num_windows, Mh*Mw, total_embed_dim]\n        x = (attn @ v).transpose(1, 2).reshape(B_, N, C)\n        x = self.proj(x)\n        x = self.proj_drop(x)\n        return x\n</code></pre>"},{"location":"transformer/Swin/#_10","title":"\u4e0b\u91c7\u6837\u6a21\u5757","text":"<pre><code>class PatchMerging(nn.Module):\n    r\"\"\" Patch Merging Layer.\n    \u7528\u4e8e\u5b9e\u73b0\u4e0b\u91c7\u6837\u64cd\u4f5c\n    Args:\n        dim (int): Number of input channels.\n        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm\n    \"\"\"\n\n    def __init__(self, dim, norm_layer=nn.LayerNorm):\n        super().__init__()\n        self.dim = dim\n        self.reduction = nn.Linear(4 * dim, 2 * dim, bias=False)\n        self.norm = norm_layer(4 * dim)\n\n    def forward(self, x, H, W):\n        \"\"\"\n        x: B, H*W, C\n        \"\"\"\n        B, L, C = x.shape\n        assert L == H * W, \"input feature has wrong size\"\n\n        x = x.view(B, H, W, C)\n\n        # padding\n        # \u5982\u679c\u8f93\u5165feature map\u7684H\uff0cW\u4e0d\u662f2\u7684\u6574\u6570\u500d\uff0c\u9700\u8981\u8fdb\u884cpadding\n        pad_input = (H % 2 == 1) or (W % 2 == 1)\n        if pad_input:\n            # to pad the last 3 dimensions, starting from the last dimension and moving forward.\n            # (C_front, C_back, W_left, W_right, H_top, H_bottom)\n            # \u6ce8\u610f\u8fd9\u91cc\u7684Tensor\u901a\u9053\u662f[B, H, W, C]\uff0c\u6240\u4ee5\u4f1a\u548c\u5b98\u65b9\u6587\u6863\u6709\u4e9b\u4e0d\u540c\n            x = F.pad(x, (0, 0, 0, W % 2, 0, H % 2))\n        # \u4e0d\u4f7f\u7528\u5e38\u89c4\u7684\u6c60\u5316\u65b9\u6cd5\uff0c\u8fd9\u91cc\u5148\u62c6\u5206\u7279\u5f81\uff0c\u518dcat\u5408\u5e76\n        x0 = x[:, 0::2, 0::2, :]  # [B, H/2, W/2, C]\n        x1 = x[:, 1::2, 0::2, :]  # [B, H/2, W/2, C]\n        x2 = x[:, 0::2, 1::2, :]  # [B, H/2, W/2, C]\n        x3 = x[:, 1::2, 1::2, :]  # [B, H/2, W/2, C]\n        x = torch.cat([x0, x1, x2, x3], -1)  # [B, H/2, W/2, 4*C]\n        x = x.view(B, -1, 4 * C)  # [B, H/2*W/2, 4*C]\n\n        x = self.norm(x)\n        x = self.reduction(x)  # [B, H/2*W/2, 2*C]\n\n        return x\n</code></pre> <p>\u6ce8\uff1a\u521d\u6b65\u5b8c\u7a3f\u4e8e2023\u5e745\u67084\u65e5</p>"},{"location":"transformer/ViT/","title":"ViT","text":""},{"location":"transformer/ViT/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aInternational Conference on Learning Representations, 2021 (ICLR, 2021)</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openreview.net/pdf?id=YicbFdNTTy</p> <p>\u8bba\u6587\u6e90\u7801\uff1ahttps://github.com/lucidrains/vit-pytorch\uff08\u975e\u5b98\u65b9\uff09</p>"},{"location":"transformer/ViT/#_2","title":"\u4ecb\u7ecd","text":""},{"location":"transformer/ViT/#_3","title":"\u7f51\u7edc\u7ed3\u6784","text":"<p> <p></p> <p></p> <p>\u56fe\u7247\u5f15\u81ea\uff1ahttps://github.com/lucidrains/vit-pytorch</p>"},{"location":"transformer/ViT/#_4","title":"\u6a21\u578b\u89c4\u683c","text":"<p>\u5e38\u89c1\u89c4\u683c\uff1a</p> Model Layers Hidden size D MLP size Heads Params ViT-Base 12 768 3072 12 86M ViT-Large 24 1024 4096 16 307M ViT-Huge 32 1280 5120 16 632M <p>\u53e6\u5916\uff0c\u8fd8\u4f1a\u6dfb\u52a0patch\u5927\u5c0f\uff0c\u4f8b\u5982\uff1aViT-L/16\u8868\u793a\u4f7f\u752816\\times16\u7684patch\u5927\u5c0f\u5207\u5206\u56fe\u7247\u3002</p>"},{"location":"transformer/ViT/#_5","title":"\u6e90\u7801\u5b9e\u73b0","text":"<pre><code>class ViT(nn.Module):\n    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool='cls', channels=3,\n                 dim_head=64, dropout=0., emb_dropout=0.):\n        super().__init__()\n        image_height, image_width = pair(image_size)\n        patch_height, patch_width = pair(patch_size)\n\n        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n\n        num_patches = (image_height // patch_height) * (image_width // patch_width)\n        patch_dim = channels * patch_height * patch_width\n        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n\n        self.to_patch_embedding = nn.Sequential(\n            Rearrange('b c (h p1) (w p2) -&gt; b (h w) (p1 p2 c)', p1=patch_height, p2=patch_width),\n            nn.LayerNorm(patch_dim),\n            nn.Linear(patch_dim, dim),\n            nn.LayerNorm(dim),\n        )\n        # \u4f4d\u7f6e\u7f16\u7801\n        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n        # \u7c7b\u522btoken\uff08\u7c7b\u4f3c\u7c7b\u522b\u67e5\u8be2\u5411\u91cf\uff09\n        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n        self.dropout = nn.Dropout(emb_dropout)\n\n        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n\n        self.pool = pool\n        self.to_latent = nn.Identity()\n\n        self.mlp_head = nn.Sequential(\n            nn.LayerNorm(dim),\n            nn.Linear(dim, num_classes)\n        )\n\n    def forward(self, img):\n        x = self.to_patch_embedding(img)\n        b, n, _ = x.shape\n        # \u7c7b\u522btoken\u5148\u4e0e\u7279\u5f81\u5408\u5e76\uff08\u6cbf\u5e8f\u5217\u65b9\u5411\u5408\u5e76\uff09\n        cls_tokens = repeat(self.cls_token, '1 1 d -&gt; b 1 d', b=b)\n        x = torch.cat((cls_tokens, x), dim=1)\n        # \u52a0\u4e0a\u4f4d\u7f6e\u7f16\u7801\uff0c\u7528\u4e8e\u8868\u793a\u56fe\u7247patch\u7684\u4f4d\u7f6e\n        x += self.pos_embedding[:, :(n + 1)]\n        x = self.dropout(x)\n\n        x = self.transformer(x)\n\n        x = x.mean(dim=1) if self.pool == 'mean' else x[:, 0]\n\n        x = self.to_latent(x)\n        return self.mlp_head(x)\n</code></pre> <p>\u521d\u6b65\u5b8c\u7a3f\u4e8e\uff1a2023\u5e745\u67089\u65e5</p>"},{"location":"transformer/ViT_Adapter/","title":"\u8bba\u6587\u7b14\u8bb0\u2014\u2014ViT Adapter","text":""},{"location":"transformer/ViT_Adapter/#_1","title":"\u7efc\u8ff0","text":"<p>\u4f1a\u8bae\u65f6\u95f4\uff1aICLR 2023</p> <p>\u8bba\u6587\u5730\u5740\uff1ahttps://openreview.net/pdf?id=plKu2GByCNW</p> <p>\u6e90\u7801\u5730\u5740\uff1ahttps://github.com/czczup/ViT-Adapter</p>"},{"location":"transformer/ViT_Adapter/#_2","title":"\u4e3b\u8981\u601d\u60f3","text":"<p>\u2003\u2003Transformer\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u9886\u57df\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6210\u529f\uff0c\u4e3b\u8981\u5f97\u76ca\u4e8etransformer\u7684\u52a8\u6001\u5efa\u6a21\u80fd\u529b\uff08dynamic modeling capability\uff09\u548c\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u957f\u8ddd\u79bb\u4f9d\u8d56\uff08long-range dependence\uff09\u7684\u5efa\u6a21\u80fd\u529b\uff0c\u540c\u65f6\u666e\u901a\u7684ViT\u53ef\u4ee5\u4f7f\u7528\u5927\u91cf\u591a\u6a21\u6001\u6570\u636e\u8fdb\u884c\u9884\u8bad\u7ec3\uff08\u5305\u62ec\u56fe\u50cf\u3001\u6587\u672c\u548c\u89c6\u9891\u7b49\u7b49\uff09\uff0c\u901a\u8fc7\u5229\u7528\u5927\u91cf\u5e76\u4e14\u591a\u7ef4\u5ea6\u7684\u6570\u636e\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u6a21\u578b\u5b66\u4e60\u4e30\u5bcc\u8bed\u4e49\u8868\u793a\u7684\u80fd\u529b\u3002\u7136\u800c\uff0c\u666e\u901a\u7684ViT\u5728\u5bc6\u96c6\u9884\u6d4b\u4efb\u52a1\u65b9\u9762\u6548\u679c\u5f80\u5f80\u4e0d\u662f\u5f88\u7406\u60f3\uff0c\u7531\u4e8e\u7f3a\u5c11\u56fe\u50cf\u76f8\u5173\u7684\u5148\u9a8c\u77e5\u8bc6\uff0c\u56e0\u6b64\u4f1a\u5bfc\u81f4\u6a21\u578b\u6536\u655b\u6162\uff0c\u5b9e\u9645\u5e94\u7528\u6027\u80fd\u6bd4\u8f83\u4f4e\u3002\u5728\u540e\u9762\u7684\u7814\u7a76\u4e2d\uff0c\u63a8\u51fa\u4e86\u4e00\u4e9b\u7279\u5b9a\u4e8e\u89c6\u89c9\u7684transformer\u7f51\u7edc\uff08vision-specific\uff0c\u4f8b\u5982\uff1aSwin transformer\u3001PVTv2\uff09\uff0c\u5229\u7528\u5c40\u90e8\u7684\u7a7a\u95f4\u64cd\u4f5c\u6765\u5f15\u5165\u89c6\u89c9\u7279\u5b9a\u7684\u5f52\u7eb3\u504f\u7f6e\uff08vision-specific inductive biases\uff09\uff0c\u4ece\u800c\u7f13\u89e3transformer\u6a21\u578b\u5728\u89c6\u89c9\u4efb\u52a1\u5e94\u7528\u4e2d\u7f3a\u5c11\u56fe\u50cf\u5148\u9a8c\u77e5\u8bc6\u7684\u95ee\u9898\uff0c\u4f46\u662f\u8fd9\u4e9b\u6a21\u578b\u7531\u4e8e\u662f\u89c6\u89c9\u7279\u5b9a\u7684\u6a21\u578b\uff0c\u56e0\u6b64\u53ea\u80fd\u5728\u56fe\u50cf\u6570\u636e\u4e0a\u505a\u9884\u8bad\u7ec3\uff0c\u65e0\u6cd5\u5728\u5176\u4ed6\u6570\u636e\u4e0a\u505a\u9884\u8bad\u7ec3\uff0c\u9650\u5236\u4e86\u6570\u636e\u6e90\u7684\u683c\u5f0f\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u672c\u6587\u53d7\u5230NLP\u9886\u57df\u4e2dadapters\u7684\u542f\u53d1\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u89c6\u89c9adapter\u7ed3\u6784\uff0c\u7528\u4e8e\u7f29\u5c0f\u5bc6\u96c6\u9884\u6d4b\u4efb\u52a1\u4e2d\uff0c\u666e\u901aViT\u548c\u89c6\u89c9\u7279\u5b9abackbone\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u5f02\u3002</p> <p>\u2003\u2003\u5bf9\u4e8e\u89c6\u89c9ViT adapter\uff0c\u4ed6\u662f\u4e00\u79cd\u53ef\u4ee5\u9644\u52a0\u5728\u666e\u901aViT\u7684\u6a21\u5757\uff0c\u53ef\u4ee5\u5728\u4e0d\u4fee\u6539\u539f\u59cb\u7ed3\u6784\u7684\u60c5\u51b5\u4e0b\u6709\u6548\u5730\u5c06\u666e\u901a\u7684ViT\u9002\u7528\u4e8e\u4e0b\u6e38\u7684\u5bc6\u96c6\u578b\u9884\u6d4b\u4efb\u52a1\uff0c\u5177\u4f53\u5730\u6765\u8bf4\uff0c\u4e3a\u4e86\u5c06\u89c6\u89c9\u7279\u5b9a\u7684\u5f52\u7eb3\u504f\u5dee\u5f15\u5165\u5230\u666e\u901a\u7684ViT\u4e2d\uff0c\u4f5c\u8005\u8bbe\u8ba1\u4e86\u4e09\u4e2a\u6a21\u5757\uff0c\u5305\u62ec\uff1a\u2460Spatial Prior Module\uff1a\u7528\u4e8e\u4ece\u56fe\u50cf\u4e2d\u6355\u83b7\u5c40\u90e8\u7684\u7a7a\u95f4\u8bed\u4e49\u7279\u5f81\uff1b\u2461Spatial Feature Injector\uff1a\u7528\u4e8e\u5c06\u7a7a\u95f4\u5148\u9a8c\u7279\u5f81\u878d\u5165ViT\u7279\u5f81\u4e2d\uff1b\u2462Multi-scale Feature Extractor\uff1a\u7528\u4e8e\u5f97\u5230\u5bc6\u96c6\u9884\u6d4b\u4efb\u52a1\u6240\u9700\u8981\u7684\u591a\u5c3a\u5ea6\u7279\u5f81\uff08\u5c06ViT\u7279\u5f81\u878d\u5165\u7a7a\u95f4\u5148\u9a8c\u7279\u5f81\u4e2d\uff09\u3002</p> <p>\u2003\u2003\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u4e0e\u4e4b\u524d\u7684\u8303\u5f0f\u76f8\u6bd4\uff08\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u9884\u8bad\u7ec3\uff0c\u7136\u540e\u5728\u5176\u4ed6\u4efb\u52a1\u4e0a\u505a\u5fae\u8c03\uff09\uff0c\u4f5c\u8005\u63d0\u51fa\u7684\u8303\u5f0f\u66f4\u52a0\u7075\u6d3b\u3002\u4e4b\u524d\u7684\u6846\u67b6\u7531\u4e8ebackbone\u662f\u89c6\u89c9\u7279\u5b9a\u7684\u7f51\u7edc\uff0c\u56e0\u6b64\u53ea\u80fd\u7528\u56fe\u50cf\u6570\u636e\u6765\u505a\u9884\u8bad\u7ec3\uff1b\u800c\u5728\u4f5c\u8005\u63d0\u51fa\u7684\u6846\u67b6\u4e2d\uff0cbackbone\u662f\u4e00\u4e2a\u901a\u7528\u7684\u6a21\u578b\uff08\u4f8b\u5982\u666e\u901a\u7684ViT\uff09\uff0c\u5b83\u4e0d\u4ec5\u53ef\u4ee5\u7528\u56fe\u50cf\u6765\u505a\u9884\u8bad\u7ec3\uff0c\u8fd8\u53ef\u4ee5\u5229\u7528\u591a\u6a21\u6001\u6570\u636e\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u800c\u5bf9\u4e8e\u5bc6\u96c6\u9884\u6d4b\u4efb\u52a1\u7684\u8fc1\u79fb\u5b66\u4e60\uff0c\u53ea\u4f7f\u7528\u968f\u673a\u521d\u59cb\u5316\u7684adapter\u6765\u5c06\u56fe\u50cf\u76f8\u5173\u7684\u5148\u9a8c\u77e5\u8bc6\uff08\u5f52\u7eb3\u504f\u5dee\uff09\u5f15\u5165\u9884\u8bad\u7ec3\u7684\u4e3b\u5e72\u7f51\u7edc\u4e2d\uff0c\u4f7f\u6a21\u578b\u53ef\u4ee5\u9002\u7528\u4e8e\u8fd9\u4e9b\u4efb\u52a1\uff0c\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff0c\u5728\u5bc6\u96c6\u9884\u6d4b\u4efb\u52a1\u4e2d\uff0c\u4ec5\u4f7f\u7528ViT\u4f5c\u4e3a\u9aa8\u5e72\u7f51\u7edc\uff0c\u5229\u7528\u4f5c\u8005\u7684\u6846\u67b6\u53ef\u4ee5\u5b9e\u73b0\u4e0eSwin\u7b49\u89c6\u89c9\u7279\u5b9a\u7684ViT\u7b97\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\u3002</p> <p> <p></p> <p></p>"},{"location":"transformer/ViT_Adapter/#_3","title":"\u65b9\u6cd5","text":"<p>\u2003\u2003\u6a21\u578b\u4e3b\u8981\u5206\u4e3a\u4e24\u4e2a\u90e8\u5206\uff0c\u5206\u522b\u4e3a\u666e\u901a\u7684ViT\u7f51\u7edc\u548c\u6240\u63d0\u7684ViT-Adapter\u6a21\u5757\uff0c\u5177\u4f53\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u2003\u2003\u5bf9\u4e8eViT\uff0c\u9996\u5148\u5c06\u56fe\u50cf\u8f93\u5165\u5230patch embedding\u4e2d\uff0c\u5c06\u56fe\u50cf\u5206\u5272\u621016\\times16\u5927\u5c0f\u7684\u4e0d\u91cd\u53e0patch\uff0c\u4e4b\u540e\u5c06\u8fd9\u4e9b\u7279\u5f81\u6295\u5f71\u6210d\u7ef4\u7684token\uff0c\u4e4b\u540e\u5c06\u8fd9\u4e9btoken\u52a0\u4e0a\u4f4d\u7f6e\u7f16\u7801\u3002</p> <p>\u2003\u2003\u5bf9\u4e8eViT-adapter\uff0c\u9996\u5148\u5c06\u8f93\u5165\u56fe\u50cf\u4f20\u5165\u7531CNN\u7ec4\u6210\u7684\u7a7a\u95f4\u5148\u9a8c\u6a21\u5757\u4e2d\uff0c\u5f97\u5230\u4e09\u79cd\u5206\u8fa8\u7387\u7684d\u7ef4\u7a7a\u95f4\u7279\u5f81\uff08\\frac18\u3001\\frac1{16}\u3001\\frac1{32}\uff09\uff0c\u4e4b\u540e\u5c06\u8fd9\u4e9b\u7279\u5f81\u6cbf\u7a7a\u95f4\u65b9\u5411\u62c9\u76f4\uff0c\u5e76\u8fde\u63a5\u8d77\u6765\uff0c\u4f5c\u4e3a\u7279\u5f81\u4ea4\u4e92\u7684\u8f93\u5165\u3002\u5177\u4f53\u5730\u6765\u8bf4\uff0c\u7ed9\u5b9a\u4ea4\u4e92\u6b21\u6570N\uff08\u901a\u5e38\u4e3a4\uff09\uff0c\u6211\u4eec\u5c06ViT\u7684transformer\u7f16\u7801\u5668\u5e73\u5747\u5206\u6210N\u4e2ablock\uff0c\u6bcf\u4e2ablock\u5305\u62ecL/N\u4e2atransformer\u6a21\u5757\uff0c\u5bf9\u4e8e\u7b2ci\u4e2a\u5757\uff0c\u9996\u5148\u901a\u8fc7\u7a7a\u95f4\u6ce8\u5165\u5668\u5411\u5176\u4e2d\u6ce8\u5165\u7a7a\u95f4\u5148\u9a8c\u7279\u5f81\uff0c\u4e4b\u540e\u901a\u8fc7\u591a\u5c3a\u5ea6\u7279\u5f81\u63d0\u53d6\u5668\u4ece\u5757\u7684\u8f93\u51fa\u4e2d\u63d0\u53d6\u591a\u5c3a\u5ea6\u5c42\u6b21\u7279\u5f81\u3002\u7ecf\u8fc7N\u6b21\u4ea4\u4e92\u4e4b\u540e\uff0c\u5f97\u5230\u9ad8\u8d28\u91cf\u7684\u591a\u5c3a\u5ea6\u7279\u5f81\uff0c\u4e4b\u540e\u5bf9\u7279\u5f81\u8fdb\u884c\u62c6\u5206\u548c\u91cd\u6784\uff0c\u5f97\u5230\u76ee\u6807\u5206\u8fa8\u7387\u4e3a\\frac18\u3001\\frac1{16}\u3001\\frac1{32}\u7684\u7279\u5f81\u3002\u6700\u540e\uff0c\u5229\u75282\\times2\u7684\u8f6c\u7f6e\u5377\u79ef\u5bf9\\frac18\u5c3a\u5ea6\u7684\u7279\u5f81\u56fe\u8fdb\u884c\u4e0a\u91c7\u6837\uff0c\u6784\u5efa\\frac14\u5c3a\u5ea6\u7684\u7279\u5f81\u56fe\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff0c\u4f1a\u83b7\u5f97\u4e0eResNet\u76f8\u4f3c\u5206\u8fa8\u7387\u7684\u7279\u5f81\u91d1\u5b57\u5854\uff0c\u53ef\u7528\u4e8e\u5404\u79cd\u5bc6\u96c6\u9884\u6d4b\u4efb\u52a1\u3002</p> <p>\u6ce8\uff1a\u4e00\u5171\u56db\u79cd\u5c3a\u5ea6\u7279\u5f81\uff0c\u5206\u522b\u4e3a\\frac14\u3001\\frac18\u3001\\frac1{16}\u3001\\frac1{32}\u3002</p>"},{"location":"transformer/ViT_Adapter/#_4","title":"\u7a7a\u95f4\u5148\u9a8c\u6a21\u5757","text":"<p>\u2003\u2003\u76f8\u6bd4\u4e8etransformer\u7ed3\u6784\uff0c\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5177\u6709\u66f4\u5f3a\u7684\u5c40\u90e8\u5efa\u6a21\u80fd\u529b\uff0c\u53ef\u4ee5\u5e2e\u52a9transformer\u66f4\u597d\u5730\u6355\u83b7\u5c40\u90e8\u7684\u7a7a\u95f4\u4fe1\u606f\uff0c\u53d7\u6b64\u542f\u53d1\uff0c\u4f5c\u8005\u5f15\u5165\u4e86\u7531CNN\u6784\u6210\u7684\u7a7a\u95f4\u5148\u9a8c\u6a21\u5757\uff08SPM\uff09\uff0c\u548c\u539fViT\u5206\u652f\u5e76\u884c\u5d4c\u5165\uff0c\u53ef\u4ee5\u5bf9\u56fe\u50cf\u7684\u5c40\u90e8\u7a7a\u95f4\u4e0a\u4e0b\u6587\u8fdb\u884c\u5efa\u6a21\u3002</p> <p>\u2003\u2003\u5177\u4f53\u7ed3\u6784\u4e0b\u56fe\u6240\u793a\uff0c\u53c2\u8003resnet\u7684\u6807\u51c6\u5377\u79ef\u7cfb\u7edf\uff0cStem\u7531\u4e09\u4e2a\u5377\u79ef\u5c42\u548c\u4e00\u4e2a\u6700\u5927\u6c60\u5316\u7ec4\u6210\uff08\u7b2c\u4e00\u4e2a\u5377\u79ef\u5c42\u6b65\u5e45\u4e3a2\uff0c\u5176\u4ed6\u4e3a1\uff09\uff0c\u4e4b\u540e\u4f9d\u6b21\u4f7f\u7528\u6b65\u5e45\u4e3a2\u76843\\times3\u5377\u79ef\u505a\u4e0b\u91c7\u6837\u64cd\u4f5c\uff08\u901a\u9053\u6570\u589e\u52a0\uff0c\u5e76\u4e14\u51cf\u5c0f\u7279\u5f81\u56fe\u5206\u8fa8\u7387\u5c3a\u5bf8\uff09\uff0c\u5c06\u6240\u5f97\u7684\u7279\u5f81\u4f20\u51651\\times1\u7684\u5377\u79ef\uff0c\u5c06\u7279\u5f81\u56fe\u7684\u901a\u9053\u6570\u5747\u8f6c\u4e3aD\uff08\u8ddfFPN\u91cc\u7684\u76ee\u7684\u4e00\u6837\uff0c\u5f97\u5230\u540c\u7279\u5f81\u7ef4\u6570\u4e0b\u7684\u591a\u5c3a\u5ea6\u7279\u5f81\uff09\uff0c\u6700\u7ec8\u4f1a\u5f97\u5230\u4e09\u79cd\u5c3a\u5ea6\u7684\u7279\u5f81F_1,F_2,F_3\uff0c\u5206\u8fa8\u7387\u5747\u4e3a\u539f\u56fe\u7684\\frac18,\\frac1{16},\\frac1{32}\uff0c\u4e4b\u540e\u5c06\u7279\u5f81\u56fe\u6cbf\u7a7a\u95f4\u62c9\u76f4\uff0c\u5f97\u5230\u7a7a\u95f4\u7279\u5f81F_{sp}^1\\in R^{(\\frac{HW}{8^2}+\\frac{HW}{16^2}+\\frac{HW}{32^2})\\times D}\u3002</p> <p> <p></p> <p></p>"},{"location":"transformer/ViT_Adapter/#_5","title":"\u7279\u5f81\u4ea4\u4e92\u6a21\u5757","text":"<p>\u2003\u2003\u7279\u5f81\u4ea4\u4e92\u6a21\u5757\u7531\u4e24\u4e2a\u6a21\u5757\u6784\u6210\uff0c\u4e3b\u8981\u7528\u4e8eViT\u7279\u5f81\u548c\u7a7a\u95f4\u7279\u5f81\u4e4b\u95f4\u7684\u7279\u5f81\u4ea4\u4e92\u3002</p> <p>\u7a7a\u95f4\u7279\u5f81\u6ce8\u5165\u5668</p> <p>\u2003\u2003\u8be5\u6a21\u5757\u7528\u4e8e\u5c06\u7a7a\u95f4\u5148\u9a8c\u7279\u5f81\u6ce8\u5165\u5230ViT\u7279\u5f81\u4e2d\uff0c\u5c06ViT\u7279\u5f81F_{vit}\u4f5c\u4e3a\u67e5\u8be2query\uff0c\u7a7a\u95f4\u7279\u5f81F_{sp}\u4f5c\u4e3a\u952e\u503c\u5bf9key-value\uff1a $$ \\hat{F}^i_{vit}=F^i_{vit}+\\gamma^iAttention(norm(F^i_{vit}),norm(F^i_{sp})) $$  \u5176\u4e2dnorm\u8868\u793aLayerNorm\u5c42\uff0c\u6ce8\u610f\u529b\u8fd0\u7b97\u6700\u597d\u4f7f\u7528\u7ebf\u6027\u590d\u6742\u5ea6\u7684\u7a00\u758f\u6ce8\u610f\u529b\uff08\u4f8b\u5982deformable attention\uff09\uff0c\u540c\u65f6\uff0c\u8fd9\u91cc\u5e94\u7528\u4e00\u4e2a\u53ef\u5b66\u4e60\u7684\u5411\u91cf\\gamma\u200b\u200b\u6765\u5e73\u8861\u6ce8\u610f\u529b\u5c42\u7684\u8f93\u51fa\u548c\u8f93\u5165\u7279\u5f81\uff0c\u5e76\u4e14\u521d\u59cb\u5316\u4e3a0\uff0c\u8fd9\u79cd\u521d\u59cb\u5316\u7b56\u7565\u4fdd\u8bc1\u4e86vit\u7684\u7279\u5f81\u5206\u5e03\u4e0d\u4f1a\u56e0\u4e3a\u7a7a\u95f4\u5148\u9a8c\u7684\u6ce8\u5165\u800c\u53d1\u751f\u5267\u70c8\u7684\u6539\u53d8\uff0c\u4ece\u800c\u53ef\u4ee5\u66f4\u597d\u5730\u5229\u7528vit\u7684\u9884\u8bad\u7ec3\u6743\u91cd\u3002</p> <p> <p></p> <p></p> <p>\u2003\u2003\u8fd9\u4e00\u64cd\u4f5c\u672c\u8d28\u4e0a\u662f\u7528ViT\u7279\u5f81\u67e5\u8be2\u7a7a\u95f4\u7279\u5f81\u4e2d\u5bf9\u81ea\u8eab\u6709\u7528\u7684\u7279\u5f81\uff0c\u76f8\u5f53\u4e8e\u5c06\u5177\u6709\u5c40\u90e8\u7a7a\u95f4\u4fe1\u606f\u7684\u7279\u5f81\u878d\u5165ViT\u7279\u5f81\u4e2d\uff0c\u505a\u4e0d\u540c\u9886\u57df\u7279\u5f81\u4e4b\u95f4\u7684\u878d\u5408\u3002</p> <p>\u591a\u5c3a\u5ea6\u7279\u5f81\u63d0\u53d6\u5668</p> <p>\u2003\u2003\u5728\u5411ViT\u6ce8\u5165\u7a7a\u95f4\u7279\u5f81\u4e4b\u540e\uff0c\u5c06\u6240\u5f97\u7684\\hat{F}^i_{vit}\u4f20\u5165\u7b2ci\u4e2atransformer\u7f16\u7801block\uff0c\u5f97\u5230F^{i+1}_{vit}\uff0c\u4e4b\u540e\u4f7f\u7528\u4ea4\u53c9\u6ce8\u610f\u529b\u548c\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u63d0\u53d6\u591a\u5c3a\u5ea6\u7279\u5f81\uff0c\u5c06\u7a7a\u95f4\u7279\u5f81F^i_{sp}\u4f5c\u4e3a\u67e5\u8be2query\uff0cViT\u7279\u5f81F^{i+1}_{vit}\u4f5c\u4e3a\u952e\u503c\u5bf9key-value $$ \\hat{F}^i_{sp}=F^i_{sp}+Attention(norm(F^i_{sp}),norm(F_{vit}^{i+1}))\\\\ F^{i+1}_{sp}=\\hat{F}^i_{sp}+FFN(norm(\\hat{F}^i_{sp})) $$  \u8fd9\u91cc\u540c\u6837\u6700\u597d\u4f7f\u7528\u7ebf\u6027\u590d\u6742\u5ea6\u7684\u7a00\u758f\u6ce8\u610f\u529b\uff0c\u5c06\u6240\u5f97\u7684\u7a7a\u95f4\u7279\u5f81F^{i+1}_{sp}\u200b\u4f5c\u4e3a\u4e0b\u4e00\u4e2a\u7a7a\u95f4\u7279\u5f81\u6ce8\u5165\u5668SFI\u7684\u8f93\u5165\u3002</p> <p> <p></p> <p></p> <p>\u2003\u2003\u8fd9\u4e00\u64cd\u4f5c\u672c\u8d28\u4e0a\u662f\u7528\u591a\u5c3a\u5ea6\u7684\u7a7a\u95f4\u7279\u5f81\u67e5\u8be2ViT\u7279\u5f81\u4e2d\u5bf9\u81ea\u8eab\u6709\u7528\u7684\u7279\u5f81\uff0c\u76f8\u5f53\u4e8e\u5c06\u8bed\u4e49\u4e30\u5bcc\u7684ViT\u7279\u5f81\u878d\u5165\u591a\u5c3a\u5ea6\u7a7a\u95f4\u7279\u5f81\u4e2d\uff0c\u8ba9\u6bcf\u4e2a\u7a7a\u95f4\u7279\u5f81\u90fd\u5177\u6709\u4e30\u5bcc\u7684\u8bed\u4e49\u4fe1\u606f\uff0c\u6700\u7ec8\u6240\u5f97\u7684\u7279\u5f81\u65e2\u6709\u591a\u5c3a\u5ea6\u8868\u5f81\u7684\u80fd\u529b\u4e5f\u6709\u521d\u59cbViT\u4e30\u5bcc\u8bed\u4e49\u7279\u5f81\u7684\u4f18\u52bf\u3002</p>"},{"location":"transformer/ViT_Adapter/#_6","title":"\u6a21\u578b\u89c4\u683c","text":"<p> <p></p> <p></p>"},{"location":"transformer/ViT_Adapter/#_7","title":"\u5b9e\u9a8c\u90e8\u5206","text":"<p>\u540c\u4e00\u6846\u67b6\u4e0b\uff08Mask R-CNN\uff09\u4e0d\u540cBackbone\u7684\u6bd4\u8f83</p> <p>\u4efb\u52a1\uff1a\u76ee\u6807\u68c0\u6d4b\u548c\u5b9e\u4f8b\u5206\u5272</p> <p> <p></p> <p></p> <p>\u4e0d\u540c\u6846\u67b6\u4e0b\u7684\u6bd4\u8f83</p> <p>\u4efb\u52a1\uff1a\u76ee\u6807\u68c0\u6d4b</p> <p> <p></p> <p></p> <p>\u8bed\u4e49\u5206\u5272</p> <p> <p></p> <p></p>"},{"location":"transformer/ViT_Adapter/#_8","title":"\u603b\u7ed3","text":"<p>\u2003\u2003\u672c\u5de5\u4f5c\u4e3b\u8981\u9488\u5bf9\u666e\u901aViT\u7f3a\u5c11\u89c6\u89c9\u7279\u5b9a\u7684\u5f52\u7eb3\u504f\u7f6e\u95ee\u9898\u505a\u6539\u8fdb\uff0c\u8bbe\u8ba1\u4e86ViT-Adapter\u6a21\u5757\uff0c\u5229\u7528\u4ea4\u53c9\u6ce8\u610f\u529b\uff0c\u5145\u5206\u5c06CNN\u4e2d\u5c40\u90e8\u7a7a\u95f4\u5efa\u6a21\u7684\u80fd\u529b\u878d\u5165\u5230ViT\u6a21\u578b\u4e2d\uff0c\u5728\u4fdd\u6301\u539f\u6709ViT\u67b6\u6784\u4e0d\u53d8\uff0c\u5373ViT\u8bed\u4e49\u7279\u5f81\u4e0d\u51cf\u5f31\u7684\u60c5\u51b5\u4e0b\uff0c\u7075\u6d3b\u5730\u5c06\u56fe\u50cf\u76f8\u5173\u7684\u5f52\u7eb3\u504f\u7f6e\u6ce8\u5165\u5230ViT\u6a21\u578b\u4e2d\uff0c\u91cd\u6784\u5bc6\u96c6\u9884\u6d4b\u4efb\u52a1\u6240\u9700\u8981\u7684\u7ec6\u7c92\u5ea6\u591a\u5c3a\u5ea6\u7279\u5f81\uff0c\u6700\u7ec8\u5b9e\u73b0\u4e0b\u6e38\u4efb\u52a1\u826f\u597d\u7684\u5e94\u7528\u3002</p> <p>\u4ee5\u4e0a\u4ec5\u662f\u7b14\u8005\u4e2a\u4eba\u89c1\u89e3\uff0c\u82e5\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u6307\u6b63</p> <p>\u6ce8\uff1a\u521d\u6b65\u5b8c\u7a3f\u4e8e2024\u5e742\u67084\u65e5\u3002</p>"},{"location":"transformer/transformer/","title":"Transformer","text":""},{"location":"transformer/transformer/#_1","title":"\u7efc\u8ff0","text":"<p>\u65f6\u95f4\u4f1a\u8bae\uff1aAdvances in Neural Information Processing Systems, 2017 (NIPS, 2017)</p> <p>\u8bba\u6587\u94fe\u63a5\uff1ahttp://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf</p>"},{"location":"transformer/transformer/#_2","title":"\u4ecb\u7ecd","text":"<p>\u2003\u2003transformer\u7ed3\u6784\u7684\u4f18\u70b9\uff1a</p> <ul> <li>\u957f\u7a0b\u4f9d\u8d56\u6027\u5904\u7406\u80fd\u529b\u5f3a\uff1a\u81ea\u6ce8\u610f\u529b\u673a\u5236\u53ef\u4ee5\u5b9e\u73b0\u5bf9\u6574\u5f20\u56fe\u7247\u8fdb\u884c\u5168\u5c40\u4fe1\u606f\u7684\u5efa\u6a21\uff1b</li> <li>\u5e76\u884c\u5316\u80fd\u529b\u5f3a\uff1a\u53ef\u4ee5\u5e76\u884c\u8ba1\u7b97\u8f93\u5165\u5e8f\u5217\u4e2d\u7684\u6240\u6709\u4f4d\u7f6e\uff1b</li> </ul> <p>\u200b       \u7f51\u7edc\u7ed3\u6784\u56fe\u5982\u4e0b\u6240\u793a\uff1a</p> <p> <p></p> <p></p> <p>\u5176\u4e2d\uff0c\u591a\u5934\u6ce8\u610f\u529b\u7f51\u7edc\u7ed3\u6784\u4e3a\uff1a</p> <p> <p></p> <p></p> <p>\u6ce8\u610f\u529b\u516c\u5f0f\uff1a $$ Attention(Q,K,V)=softmax(\\frac{QK^T}{\\sqrt{d_k}})V\\\\ MultiHead(Q,K,V)=Concat(head_1,\\dots,head_h)W^O\\\\ head_i=Attention(QW_i^Q,KW_i^K,VW_i^V) $$  \u5176\u4e2d\uff1a</p> <ul> <li> <p>Q\u4ee3\u8868query\uff0c\u540e\u7eed\u4f1a\u53bb\u548c\u6bcf\u4e00\u4e2ak\u8fdb\u884c\u5339\u914d\uff1b</p> </li> <li> <p>K\u4ee3\u8868key\uff0c\u540e\u7eed\u4f1a\u88ab\u6bcf\u4e2aq\u5339\u914d\uff1b</p> </li> <li>V\u4ee3\u8868\u8f93\u5165\u6570\u636e\uff0c\u53c8\u79f0\u4e3a\u7f16\u7801\u6570\u636eEmbedding\uff1b</li> <li>\u540e\u7eedQ\u548cK\u5339\u914d\u7684\u8fc7\u7a0b\u53ef\u4ee5\u7406\u89e3\u6210\u8ba1\u7b97\u4e24\u8005\u7684\u76f8\u5173\u6027\uff0c\u76f8\u5173\u6027\u8d8a\u5927\u5bf9\u5e94v\u7684\u6743\u91cd\u4e5f\u5c31\u8d8a\u5927\uff0c\u4e3b\u8981\u5c31\u662f\u7ed9V\u751f\u6210\u4e00\u7ec4\u6743\u91cd\uff1b</li> </ul> <p>\u591a\u5934\u6ce8\u610f\u529bK\u3001Q\u3001V\u89e3\u91ca\uff1a</p> <p>\u2003\u2003\u76ee\u524d\u6709\u591a\u7ec4\u952e\u503c\u5339\u914d\u5bf9k\u3001v\uff0c\u6bcf\u4e2ak\u5bf9\u5e94\u4e00\u4e2av\uff0c\u8ba1\u7b97q\u6240\u5bf9\u5e94\u7684\u503c\u3002\u601d\u8def\uff1a\u8ba1\u7b97q\u4e0e\u6bcf\u4e2ak\u7684\u76f8\u4f3c\u5ea6\uff0c\u5f97\u5230v\u7684\u6743\u91cd\uff0c\u4e4b\u540e\u5bf9v\u505a\u52a0\u6743\u6c42\u548c\uff0c\u5f97\u5230q\u5bf9\u5e94\u7684\u6570\u503c\u3002\u56e0\u6b64\u5728\u89e3\u7801\u8fc7\u7a0b\u4e2d\uff0c\u7b2c\u4e8c\u4e2a\u591a\u5934\u6ce8\u610f\u529b\u7684\u8f93\u5165\u4e2d\uff0ck\u3001v\u4f20\u5165\u7f16\u7801\u7279\u5f81\uff08\u662f\u5df2\u77e5\u7684\u7279\u5f81\u5339\u914d\u5bf9\uff09\uff0cq\u4f20\u5165\u89e3\u7801\u7279\u5f81\uff08\u53ef\u8fed\u4ee3\u4f20\u5165\uff09\uff0c\u6c42\u89e3\u7801\u5bf9\u5e94\u7684\u7279\u5f81\uff08\u6839\u636e\u7f16\u7801\u7279\u5f81\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6\u6c42\u89e3\u7801\u7684\u6ce8\u610f\u529b\u52a0\u6743\u7279\u5f81\uff09\u3002</p> <p>\u2003\u2003\u6ce8\uff1akqv\u7684\u5173\u7cfb\u7528\u4e00\u53e5\u8bdd\u6765\u8bf4\u5c31\u662f\u6839\u636ekv\u7684\u952e\u503c\u5339\u914d\u5173\u7cfb\uff0c\u9884\u6d4bq\u5bf9\u5e94\u7684\u6570\u503c\uff0c\u6839\u636ekq\u7684\u76f8\u4f3c\u5ea6\u5bf9v\u505a\u52a0\u6743\u6c42\u548c\u3002</p> <p>\u89c6\u9891\u53c2\u8003\uff1ahttps://www.bilibili.com/video/BV1dt4y1J7ov/?spm_id_from=333.788.recommend_more_video.2&amp;vd_source=b1b1710a3f74753e8bfc47c5c2e4d49e</p> <p>\u591a\u5934\u6ce8\u610f\u529b\u8ba1\u7b97\u8fc7\u7a0b\uff1a</p> <p>\u2003\u2003\u5148\u8ba9kqv\u505a\u7ebf\u6027\u6620\u5c04\uff0c\u4e4b\u540e\u6cbf\u7279\u5f81\u5411\u91cf\u7684\u65b9\u5411\u62c6\u5206\u6210\u4e0d\u540c\u7684\u201c\u5934\u201d\uff0c\u4e4b\u540e\u5229\u7528\u62c6\u5206\u7684\u5411\u91cf\u505a\u8fd0\u7b97\u2192q\u548ck\u505a\u77e9\u9635\u4e58\u6cd5\uff0c\u5f97\u5230\u6ce8\u610f\u529b\u6743\u91cd\u2192\u6ce8\u610f\u529b\u6743\u91cd\u9664\u4ee5\u7f29\u653e\u56e0\u5b50\\sqrt{d_k}\uff0cd_k\u8868\u793a\u6bcf\u4e2a\u5934\u7684\u7ef4\u5ea6\uff0c\u518d\u505aSoftmax\u8fd0\u7b97\u2192\u7ecf\u8fc7\u4e00\u6b21Dropout\u8fd0\u7b97\uff08\u53ef\u9009\uff09\u2192\u6240\u5f97\u7684\u6743\u91cd\u4e0ev\u505a\u77e9\u9635\u4e58\u6cd5\u2192\u5408\u5e76\u6240\u6709\u201c\u5934\u201d\uff0c\u6700\u540e\u7ecf\u8fc7\u4e00\u6b21\u7ebf\u6027\u6620\u5c04\uff1b</p>"},{"location":"transformer/transformer/#_3","title":"\u4ee3\u7801\u5b9e\u73b0","text":""},{"location":"transformer/transformer/#_4","title":"\u7f16\u7801\u6a21\u5757","text":"<pre><code>class TransformerEncoderLayer(nn.Module):\n\n    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1,\n                 activation=\"relu\"):\n        super().__init__()\n        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n        # Implementation of Feedforward model\n        self.linear1 = nn.Linear(d_model, dim_feedforward)\n\n        self.linear2 = nn.Linear(dim_feedforward, d_model)\n\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n\n        self.activation = _get_activation_fn(activation)\n\n    def with_pos_embed(self, tensor, pos: Optional[Tensor]):\n        return tensor if pos is None else tensor + pos\n\n    def forward(self,\n                     src,\n                     pos: Optional[Tensor] = None):\n        # \u7279\u5f81\u5148\u4e0e\u4f4d\u7f6e\u7f16\u7801\u76f8\u52a0\n        v = q = k = self.with_pos_embed(src, pos)\n        src2 = self.self_attn(q, k, v)[0]\n        src = src + src2\n        src = self.norm1(src)\n        src2 = self.linear2(self.activation(self.linear1(src)))\n        src = src + src2\n        src = self.norm2(src)\n        return src\n</code></pre>"},{"location":"transformer/transformer/#_5","title":"\u89e3\u7801\u6a21\u5757","text":"<pre><code>class TransformerDecoderLayer(nn.Module):\n\n    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1,\n                 activation=\"relu\"):\n        super().__init__()\n        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n        self.multihead_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n        # Implementation of Feedforward model\n        self.linear1 = nn.Linear(d_model, dim_feedforward)\n        self.linear2 = nn.Linear(dim_feedforward, d_model)\n\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.norm3 = nn.LayerNorm(d_model)\n\n        self.activation = _get_activation_fn(activation)\n\n    def with_pos_embed(self, tensor, pos: Optional[Tensor]):\n        return tensor if pos is None else tensor + pos\n\n    def forward(self, encoding, decoding, pos: Optional[Tensor] = None):\n        q = k = v = self.with_pos_embed(decoding, pos)\n        # \u89e3\u7801\u7279\u5f81\u5148\u505a\u4e00\u6b21\u81ea\u6ce8\u610f\u529b\u8fd0\u7b97\n        decoding2 = self.self_attn(q, k, v)[0]\n        decoding = decoding + decoding2\n        decoding = self.norm1(decoding)\n\n        decoding2 = self.multihead_attn(query=decoding, key=encoding, value=encoding)[0]\n        decoding = decoding + decoding2\n        decoding = self.norm2(decoding)\n        decoding2 = self.linear2(self.activation(self.linear1(decoding)))\n        decoding = decoding + decoding2\n        decoding = self.norm3(decoding)\n        return decoding\n</code></pre> <p>\u6ce8\uff1a\u6e90\u7801\u4e3a\u4e2a\u4eba\u5b9e\u73b0\uff0c\u82e5\u6709\u95ee\u9898\uff0c\u6b22\u8fce\u6307\u6b63</p> <p>\u521d\u6b65\u5b8c\u7a3f\u4e8e2023\u5e744\u670830\u65e5</p>"}]}